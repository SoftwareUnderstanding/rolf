{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1905.11946",
      "https://arxiv.org/abs/1811.06965",
      "https://arxiv.org/abs/1512.03385",
      "https://arxiv.org/abs/1512.03385"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xslidi/EfficientNets_ddl_apex",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-06T10:08:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-11T08:43:12Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9717875137101485
      ],
      "excerpt": "A PyTorch implementation of EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9846122866244538,
        0.8008071228545321,
        0.9413599531778414,
        0.8696545272143879,
        0.9809729325128956
      ],
      "excerpt": "Implement based on Official TF Repo and some other PyTorch implementations. Only opened EfficientNet is included. <br> \nThis repo not contains baseline network search(Mnas-Net) and compound coefficient search methods.<br> \n<b>Some details(HyperParams, transform, EMA ...) are different with Original repo.</b> \nIf you're new to EfficientNets, here is an explanation straight from the official TensorFlow implementation: \nEfficientNets are a family of image classification models, which achieve state-of-the-art accuracy, yet being an order-of-magnitude smaller and faster than previous models. We develop EfficientNets based on AutoML and Compound Scaling. In particular, we first use AutoML Mobile framework to develop a mobile-size baseline network, named as EfficientNet-B0; Then, we use the compound scaling method to scale up this baseline to obtain EfficientNet-B1 to B7. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.986383404716351,
        0.9726775843586937,
        0.9819980763163162,
        0.9791207993946961
      ],
      "excerpt": "EfficientNets achieve state-of-the-art accuracy on ImageNet with an order of magnitude better efficiency: \nIn high-accuracy regime, our EfficientNet-B7 achieves state-of-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet with 66M parameters and 37B FLOPS, being 8.4x smaller and 6.1x faster on CPU inference than previous best Gpipe. \nIn middle-accuracy regime, our EfficientNet-B1 is 7.6x smaller and 5.7x faster on CPU inference than ResNet-152, with similar ImageNet accuracy. \nCompared with the widely used ResNet-50, our EfficientNet-B4 improves the top-1 accuracy from 76.3% of ResNet-50 to 82.6% (+6.3%), under similar FLOPS constraint. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.92268057820455
      ],
      "excerpt": "Details about the models' performance retrained on ImageNet are below: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8715237653670386
      ],
      "excerpt": "Implementation of Resolution Change \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A Pytorch implementation of EfficientNet-B0 on ImageNet",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xslidi/EfficientNets_ddl_apex/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 09 Dec 2021 20:24:30 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/xslidi/EfficientNets_ddl_apex/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "xslidi/EfficientNets_ddl_apex",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "|    Name         |* \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "|    Name         |* \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/xslidi/EfficientNets_ddl_apex/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "EfficientNet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "EfficientNets_ddl_apex",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "xslidi",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xslidi/EfficientNets_ddl_apex/blob/master/readme.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 09 Dec 2021 20:24:30 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "efficientnet",
      "pytorch",
      "imagenet"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npython3 main.py -h\nusage: main.py [-h] --save_dir SAVE_DIR [--root ROOT] [--gpus GPUS]\n               [--num_workers NUM_WORKERS] [--model MODEL] [--epoch EPOCH]\n               [--batch_size BATCH_SIZE] [--val_batch_size VAL_BATCH_SIZE]\n               [--test] [--print_freq PRINT_FREQ] [--num_classes NUM_CLASSES]\n               [--ema] [--color_jitter COLOR_JITTER] [--pca]\n               [--crop_pct CROP_PCT] [--cool_down COOL_DOWN]\n               [--ema_decay EMA_DECAY] [--dropout_rate DROPOUT_RATE]\n               [--dropconnect_rate DROPCONNECT_RATE]\n               [--optim {rmsprop,rmsproptf,sgd}] [--lr LR] [--warmup WARMUP]\n               [--beta [BETA [BETA ...]]] [--momentum MOMENTUM] [--eps EPS]\n               [--decay DECAY] [--scheduler {exp,cosine,none}] [--amp]\n               [--dali] [--se_r SE_R] [--REGNET_WA REGNET_WA]\n               [--REGNET_W0 REGNET_W0] [--REGNET_WM REGNET_WM]\n               [--REGNET_DEPTH REGNET_DEPTH] [--REGNET_STRIDE REGNET_STRIDE]\n               [--REGNET_GROUP_W REGNET_GROUP_W]\n               [--REGNET_BOT_MUL REGNET_BOT_MUL]\n               [--REGNET_STEM_W REGNET_STEM_W]\n\nPytorch EfficientNet\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --save_dir SAVE_DIR   Directory name to save the model\n  --root ROOT           The Directory of data path.\n  --gpus GPUS           Select GPU Numbers | 0,1,2,3 |\n  --num_workers NUM_WORKERS\n                        Select CPU Number workers\n  --model MODEL         The type of Efficient net.\n  --epoch EPOCH         The number of epochs\n  --batch_size BATCH_SIZE\n                        The size of batch\n  --val_batch_size VAL_BATCH_SIZE\n                        The size of batch in val set\n  --test                Only Test\n  --print_freq PRINT_FREQ\n                        The iterations of print results\n  --num_classes NUM_CLASSES\n                        Number of classes\n  --ema                 Using exponential moving average for testing\n  --color_jitter COLOR_JITTER\n                        Color jitter factor (default: 0.0)\n  --pca                 add AlexNet - style PCA - based noise\n  --crop_pct CROP_PCT   Input image center crop percent (for validation only)\n  --cool_down COOL_DOWN\n                        epochs to cooldown LR at min_lr, after cyclic schedule\n                        ends\n  --ema_decay EMA_DECAY\n                        Exponential Moving Average Term\n  --dropout_rate DROPOUT_RATE\n  --dropconnect_rate DROPCONNECT_RATE\n  --optim {rmsprop,rmsproptf,sgd}\n  --lr LR               Base learning rate when train batch size is 256.\n  --warmup WARMUP\n  --beta [BETA [BETA ...]]\n  --momentum MOMENTUM\n  --eps EPS\n  --decay DECAY\n  --scheduler {exp,cosine,none}\n                        Learning rate scheduler type\n  --amp                 Use Native Torch AMP mixed precision\n  --dali                Use Naidiv DaLi library for loading\n  --se_r SE_R           Squeeze-and-Excitation rate\n  --REGNET_WA REGNET_WA\n                        Slop\n  --REGNET_W0 REGNET_W0\n                        Initial width\n  --REGNET_WM REGNET_WM\n                        Quantization\n  --REGNET_DEPTH REGNET_DEPTH\n                        Depth\n  --REGNET_STRIDE REGNET_STRIDE\n                        Stride of each stage\n  --REGNET_GROUP_W REGNET_GROUP_W\n                        Group width\n  --REGNET_BOT_MUL REGNET_BOT_MUL\n                        Bottleneck multiplier (bm = 1 / b from the paper)\n  --REGNET_STEM_W REGNET_STEM_W\n                        Stem width\n\n\n\n```\n\n<hr>\n\n",
      "technique": "Header extraction"
    }
  ]
}
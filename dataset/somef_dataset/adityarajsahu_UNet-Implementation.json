{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/adityarajsahu/UNet-Implementation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-10-10T13:06:00Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-10-27T12:53:54Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9935959838184482,
        0.9945970025859804,
        0.9215020716643582
      ],
      "excerpt": "UNet is a image classification model based on semantic segmentation. The goal of semantic image segmentation is to label each pixel of an image with a corresponding class of what is being represented. Because we\u2019re predicting for every pixel in the image, this task is commonly referred to as dense prediction. \nThe UNet model is based on encoder - decoder operation, where the input image is initially downsampled using Convolutional Neural Networks. Then, the downsampled image is again upsampled inorder to match it's feature vectors to that of the input mask. Here is the link to the research paper published on UNet. \nHere is the image representing the actual architecture of UNet, as published in the research paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9000168036061897
      ],
      "excerpt": "The dataset taken for this model training and validation is Oxford - IIIT Pet dataset. For downloading the dataset, type the commands that are mentioned below in your terminal :- \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8214390208290933
      ],
      "excerpt": "curl -O http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9706182611106225,
        0.9703082720131391,
        0.9618780780201058,
        0.9753290804033855,
        0.9269029016357938,
        0.9216411320744108,
        0.9714623423712248
      ],
      "excerpt": "For this project, I have resized the images and masks to 128 x 128 pixels for this model. \nEvery pixel in the mask is classified into one of the three categories :- \n- pixel outside the periphery of the body of animal. \n- pixel on the periphery of the body of animal. \n- pixel inside the periphery of the body of animal. \npycache : Contains the bytecode generated by the interpreter. \nannotations : Contains the masks for training, validating and testing our model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9618463805454712,
        0.957733312067874
      ],
      "excerpt": "README.md : Documentation of this repository. \ndataProcessor.py - Code for preprocessing our input data before training our model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This repository contains the code for implementing UNet Semantic Segmentation method from scratch.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/adityarajsahu/UNet-Implementation/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 07 Dec 2021 11:05:47 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/adityarajsahu/UNet-Implementation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "adityarajsahu/UNet-Implementation",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8611091229097486
      ],
      "excerpt": "tar -xf annotations.tar.gz \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9853815434476466
      ],
      "excerpt": "requirements.txt - Used to install dependencies. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8049224631100219
      ],
      "excerpt": "The folder images/ contains the input images and annotations/trimaps/ conatains output masks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8025073898425097,
        0.8178756641297572
      ],
      "excerpt": "images : Conatins the images for training, validating and testing our model. \nimg : Conatins images for README.md file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8332950450527723
      ],
      "excerpt": "modelTrainer.py - Code to train the model and save the weights. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/adityarajsahu/UNet-Implementation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Adityaraj Sahu\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "UNet-Implementation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "UNet-Implementation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "adityarajsahu",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/adityarajsahu/UNet-Implementation/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Some packages are required for running the codes in the repository. To install them write the following commands in the terminal :-\n\n```\npip install -r requirements.text\n```\n\nApart from this, we also need to install h5py package to save the weights after training.\n\n```\npip install -q pyyaml h5py\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 07 Dec 2021 11:05:47 GMT"
    },
    "technique": "GitHub API"
  }
}
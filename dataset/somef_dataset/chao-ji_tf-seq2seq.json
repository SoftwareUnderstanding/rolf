{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1508.04025](https://arxiv.org/abs/1508.04025",
      "https://arxiv.org/abs/1508.04025",
      "https://arxiv.org/abs/1409.0473](https://arxiv.org/abs/1409.0473",
      "https://arxiv.org/abs/1409.0473"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Effective Approaches to Attention-based Neural Machine Translation, Luong *et al.* [https://arxiv.org/abs/1508.04025](https://arxiv.org/abs/1508.04025)\n* Neural Machine Translation by Jointly Learning to Align and Translate, Bahdanau *et al.* [https://arxiv.org/abs/1409.0473](https://arxiv.org/abs/1409.0473)\n\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/chao-ji/tf-seq2seq",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-02-07T05:53:55Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-18T03:05:45Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9834192723209692,
        0.90736013752038
      ],
      "excerpt": "This is a TensorFlow 2.x implementation of the seq2seq model augmented with attention mechanism (Luong-style or Bahdanau-style) for neural machine translation. Follow this guide for a conceptual understanding about how seq2seq model works. \nUnlike Transformer, the seq2seq model augmented with attention mechanism involves only target-to-source attention. Shown below is the attention weights w.r.t each source token (English) when translating the target token (German) one at a time. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "TensorFlow implementation of seq2seq model",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/chao-ji/tf-seq2seq/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 06 Dec 2021 08:21:06 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/chao-ji/tf-seq2seq/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "chao-ji/tf-seq2seq",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The implementation in this repo is designed to have the same command line interface as the [Transformer](https://github.com/chao-ji/tf-transformer) implementation. Follow that link for detailed instructions on data preparation, training, evaluation and attention weights visualization.\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8979249514507349
      ],
      "excerpt": "  <img src=\"g3doc/files/seq2seq.png\" width=\"900\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979249514507349
      ],
      "excerpt": "  <img src=\"g3doc/files/alignment.png\" width=\"900\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/chao-ji/tf-seq2seq/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "TensorFlow seq2seq model",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "tf-seq2seq",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "chao-ji",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/chao-ji/tf-seq2seq/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Mon, 06 Dec 2021 08:21:06 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "tensorflow",
      "seq2seq",
      "attention-mechanism",
      "neural-machine-translation",
      "rnn",
      "language-model"
    ],
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2111.13822",
      "https://arxiv.org/abs/2111.14353",
      "https://arxiv.org/abs/2111.14341",
      "https://arxiv.org/abs/2111.13839",
      "https://arxiv.org/abs/2111.11646",
      "https://arxiv.org/abs/2111.11525",
      "https://arxiv.org/abs/2111.10344",
      "https://arxiv.org/abs/2111.10050",
      "https://arxiv.org/abs/2111.10487",
      "https://arxiv.org/abs/2111.10221",
      "https://arxiv.org/abs/2111.10827",
      "https://arxiv.org/abs/2111.04964",
      "https://arxiv.org/abs/2111.03911",
      "https://arxiv.org/abs/2111.03882",
      "https://arxiv.org/abs/2111.04073",
      "https://arxiv.org/abs/2111.04578",
      "https://arxiv.org/abs/2111.02682",
      "https://arxiv.org/abs/2110.13515",
      "https://arxiv.org/abs/2110.15946",
      "https://arxiv.org/abs/2110.15520",
      "https://arxiv.org/abs/2110.15701",
      "https://arxiv.org/abs/2110.15823",
      "https://arxiv.org/abs/2110.14509",
      "https://arxiv.org/abs/2110.14131",
      "https://arxiv.org/abs/2110.13395",
      "https://arxiv.org/abs/2110.12914",
      "https://arxiv.org/abs/2110.12812",
      "https://arxiv.org/abs/2110.12633",
      "https://arxiv.org/abs/2110.12216",
      "https://arxiv.org/abs/2110.12369",
      "https://arxiv.org/abs/2110.12997",
      "https://arxiv.org/abs/2110.10101",
      "https://arxiv.org/abs/2110.09641",
      "https://arxiv.org/abs/2110.08263",
      "https://arxiv.org/abs/2110.06014",
      "https://arxiv.org/abs/2110.05765",
      "https://arxiv.org/abs/2109.11798",
      "https://arxiv.org/abs/2109.06349",
      "https://arxiv.org/abs/2109.06604",
      "https://arxiv.org/abs/2109.06243",
      "https://arxiv.org/abs/2109.06422",
      "https://arxiv.org/abs/2109.05664",
      "https://arxiv.org/abs/2109.06165",
      "https://arxiv.org/abs/2109.05671",
      "https://arxiv.org/abs/2109.05676",
      "https://arxiv.org/abs/2109.03676",
      "https://arxiv.org/abs/2109.03775",
      "https://arxiv.org/abs/2109.02934",
      "https://arxiv.org/abs/2108.13602",
      "https://arxiv.org/abs/2108.13854",
      "https://arxiv.org/abs/2108.09473",
      "https://arxiv.org/abs/2108.10252",
      "https://arxiv.org/abs/2108.06129",
      "https://arxiv.org/abs/2108.05930",
      "https://arxiv.org/abs/2108.05988",
      "https://arxiv.org/abs/2108.04443",
      "https://arxiv.org/abs/2107.12626",
      "https://arxiv.org/abs/2108.03377",
      "https://arxiv.org/abs/2108.03267",
      "https://arxiv.org/abs/2108.03357",
      "https://arxiv.org/abs/2108.02870",
      "https://arxiv.org/abs/2108.02953",
      "https://arxiv.org/abs/2108.02959",
      "https://arxiv.org/abs/2108.02446",
      "https://arxiv.org/abs/2107.12919",
      "https://arxiv.org/abs/2107.04384",
      "https://arxiv.org/abs/2107.04231",
      "https://arxiv.org/abs/2107.04689",
      "https://arxiv.org/abs/2107.04805",
      "https://arxiv.org/abs/2107.04806",
      "https://arxiv.org/abs/2107.04983",
      "https://arxiv.org/abs/2103.03097",
      "https://arxiv.org/abs/1911.02685",
      "https://arxiv.org/abs/2009.00909",
      "https://arxiv.org/abs/2006.05525",
      "https://arxiv.org/abs/1903.04687",
      "https://arxiv.org/abs/1810.03944",
      "https://arxiv.org/abs/1804.10834",
      "https://arxiv.org/abs/1705.04058",
      "https://arxiv.org/abs/1707.08114",
      "https://arxiv.org/abs/1705.04396",
      "https://arxiv.org/abs/1811.09751",
      "https://arxiv.org/abs/2008.04510",
      "https://arxiv.org/abs/0902.3430"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@Misc{transferlearning.xyz,\nhowpublished = {\\url{http://transferlearning.xyz}},   \ntitle = {Everything about Transfer Learning and Domain Adapation},  \nauthor = {Wang, Jindong and others}  \n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9416585710174832,
        0.8940583111730483
      ],
      "excerpt": "  <a href=\"#2transfer-learning-areas-and-papers-\u7814\u7a76\u9886\u57df\u4e0e\u76f8\u5173\u8bba\u6587\">Research areas</a> \u2022 \n  <a href=\"#3theory-and-survey-\u7406\u8bba\u4e0e\u7efc\u8ff0\">Theory</a> \u2022 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9988011511555094
      ],
      "excerpt": "  <a href=\"#journals-and-conferences\">Journal/conference</a> \u2022 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9950896372754103
      ],
      "excerpt": "    Related repos\uff1aActivity recognition\uff5cMachine learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9858497036645443,
        0.9557677878172149
      ],
      "excerpt": "  - NeurIPS-21 [On Learning Domain-Invariant Representations for Transfer Learning with Multiple Sources](https://arxiv.org/abs/2111.13822) \n    - Theory and algorithm of domain-invariant learning for transfer learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9263507229983116
      ],
      "excerpt": "  - WACV-22 [Semi-supervised Domain Adaptation via Sample-to-Sample Self-Distillation](https://arxiv.org/abs/2111.14353) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9990143335393311
      ],
      "excerpt": "  - ICML-21 workshop [Towards Principled Disentanglement for Domain Generalization](https://arxiv.org/abs/2111.13839) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9931269212299904
      ],
      "excerpt": "  - NeurIPS-21 workshop [CytoImageNet: A large-scale pretraining dataset for bioimage transfer learning](https://arxiv.org/abs/2111.11646) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9991443902694768
      ],
      "excerpt": "  - NeurIPS-21 workshop [Component Transfer Learning for Deep RL Based on Abstract Representations](https://arxiv.org/abs/2111.11525) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9915152674733341
      ],
      "excerpt": "  - NeurIPS-21 workshop [Maximum Mean Discrepancy for Generalization in the Presence of Distribution and Missingness Shift](https://arxiv.org/abs/2111.10344) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9962676994057454
      ],
      "excerpt": "  - [Combined Scaling for Zero-shot Transfer Learning](https://arxiv.org/abs/2111.10050) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9788922376289179
      ],
      "excerpt": "  - [Federated Learning with Domain Generalization](https://arxiv.org/abs/2111.10487) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999228198976472
      ],
      "excerpt": "  - MICCAI-21 [Domain Generalization for Mammography Detection via Multi-style and Multi-view Contrastive Learning](https://arxiv.org/abs/2111.10827) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9966667017812681
      ],
      "excerpt": "  - [On Representation Knowledge Distillation for Graph Neural Networks](https://arxiv.org/abs/2111.04964) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9997564537493355,
        0.8698052340996203
      ],
      "excerpt": "  - BMVC-21 [Domain Attention Consistency for Multi-Source Domain Adaptation](https://arxiv.org/abs/2111.03911) \n    - Multi-source domain adaptation using attention consistency \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9998622366475151,
        0.9818963450106616
      ],
      "excerpt": "  - [Action Recognition using Transfer Learning and Majority Voting for CSGO](https://arxiv.org/abs/2111.03882) \n    - Using transfer learning and majority voting for action recognition \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.997066243825615
      ],
      "excerpt": "  - [Open-Set Crowdsourcing using Multiple-Source Transfer Learning](https://arxiv.org/abs/2111.04073) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.994483233440243
      ],
      "excerpt": "  - [Improved Regularization and Robustness for Fine-tuning in Neural Networks](https://arxiv.org/abs/2111.04578) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9993960720380287
      ],
      "excerpt": "  - [TimeMatch: Unsupervised Cross-Region Adaptation by Temporal Shift Estimation](https://arxiv.org/abs/2111.02682) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9990143335393311
      ],
      "excerpt": "  - NeurIPS-21 [Modular Gaussian Processes for Transfer Learning](https://arxiv.org/abs/2110.13515) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9979244841679135
      ],
      "excerpt": "  - [Estimating and Maximizing Mutual Information for Knowledge Distillation](https://arxiv.org/abs/2110.15946) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9809608644326057
      ],
      "excerpt": "  - [On Label Shift in Domain Adaptation via Wasserstein Distance](https://arxiv.org/abs/2110.15520) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9990769900635221
      ],
      "excerpt": "  - [Xi-Learning: Successor Feature Transfer Learning for General Reward Functions](https://arxiv.org/abs/2110.15701) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9613691922392172
      ],
      "excerpt": "  - [C-MADA: Unsupervised Cross-Modality Adversarial Domain Adaptation framework for medical Image Segmentation](https://arxiv.org/abs/2110.15823) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.998405804682982,
        0.9237727085035603
      ],
      "excerpt": "  - [Deep Transfer Learning for Multi-source Entity Linkage via Domain Adaptation](https://arxiv.org/abs/2110.14509) \n    - Domain adaptation for multi-source entiry linkage \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9992564489627815,
        0.9094440683647544
      ],
      "excerpt": "  - [Temporal Knowledge Distillation for On-device Audio Classification](https://arxiv.org/abs/2110.14131) \n    - Temporal knowledge distillation for on-device ASR \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9993226963325361
      ],
      "excerpt": "  - [Transferring Domain-Agnostic Knowledge in Video Question Answering](https://arxiv.org/abs/2110.13395) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9832231280418742
      ],
      "excerpt": "  - BMVC-21 [SILT: Self-supervised Lighting Transfer Using Implicit Image Decomposition](https://arxiv.org/abs/2110.12914) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9990911773109655,
        0.8820807460429729
      ],
      "excerpt": "  - [Domain Adaptation in Multi-View Embedding for Cross-Modal Video Retrieval](https://arxiv.org/abs/2110.12812) \n    - Domain adaptation for cross-modal video retrieval \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9996218892904083
      ],
      "excerpt": "  - [Age and Gender Prediction using Deep CNNs and Transfer Learning](https://arxiv.org/abs/2110.12633) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.803923309675049
      ],
      "excerpt": "  - [Domain Adaptation for Rare Classes Augmented with Synthetic Samples](https://arxiv.org/abs/2110.12216) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.997194255112787
      ],
      "excerpt": "  - WACV-22 [AuxAdapt: Stable and Efficient Test-Time Adaptation for Temporally Consistent Video Semantic Segmentation](https://arxiv.org/abs/2110.12369) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9970996737473418
      ],
      "excerpt": "  - NeurIPS-21 [Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning](https://arxiv.org/abs/2110.12997) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999552840736888
      ],
      "excerpt": "  - WACV-21 [Domain Generalization through Audio-Visual Relative Norm Alignment in First Person Action Recognition](https://arxiv.org/abs/2110.10101) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9960689582453647
      ],
      "excerpt": "  - BMVC-21 [Dynamic Feature Alignment for Semi-supervised Domain Adaptation](https://arxiv.org/abs/2110.09641) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9996843371012525
      ],
      "excerpt": "  - NeurIPS-21 [FlexMatch: Boosting Semi-Supervised Learning with Curriculum Pseudo Labeling](https://arxiv.org/abs/2110.08263) [\u77e5\u4e4e\u89e3\u8bfb](https://zhuanlan.zhihu.com/p/422930830) [code](https://github.com/TorchSSL/TorchSSL) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9895858351313597
      ],
      "excerpt": "  - [Rethinking supervised pre-training for better downstream transferring](https://arxiv.org/abs/2110.06014) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944484218006108
      ],
      "excerpt": "  - [Music Sentiment Transfer](https://arxiv.org/abs/2110.05765) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9699584263169131
      ],
      "excerpt": "  - NeurIPS-21 [Model Adaptation: Historical Contrastive Learning for Unsupervised Domain Adaptation without Source Data](http://arxiv.org/abs/2110.03374) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.996721984201643
      ],
      "excerpt": "  - [Dynamically Decoding Source Domain Knowledge For Unseen Domain Generalization](http://arxiv.org/abs/2110.03027) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9861764050629834
      ],
      "excerpt": "  - [Scale Invariant Domain Generalization Image Recapture Detection](http://arxiv.org/abs/2110.03496) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9997733582220364,
        0.8324396639683825
      ],
      "excerpt": "  - IEEE TIP-21 [Joint Clustering and Discriminative Feature Alignment for Unsupervised Domain Adaptation](https://ieeexplore.ieee.org/abstract/document/9535218) \n    - Clustering and discriminative alignment for DA \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9993974172952028
      ],
      "excerpt": "  - IEEE TNNLS-21 [Entropy Minimization Versus Diversity Maximization for Domain Adaptation](https://ieeexplore.ieee.org/abstract/document/9537640) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9960689582453647
      ],
      "excerpt": "  - [Adversarial Domain Feature Adaptation for Bronchoscopic Depth Estimation](https://arxiv.org/abs/2109.11798) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9930607805422754
      ],
      "excerpt": "  - EMNLP-21 [Few-Shot Intent Detection via Contrastive Pre-Training and Fine-Tuning](https://arxiv.org/abs/2109.06349) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9976668427861677,
        0.8568217992087697
      ],
      "excerpt": "  - EMNLP-21 [Non-Parametric Unsupervised Domain Adaptation for Neural Machine Translation](https://arxiv.org/abs/2109.06604) \n    - UDA for machine translation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.990521762486522
      ],
      "excerpt": "  - [KroneckerBERT: Learning Kronecker Decomposition for Pre-trained Language Models via Knowledge Distillation](https://arxiv.org/abs/2109.06243) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9934653889615016
      ],
      "excerpt": "  - [Cross-Region Domain Adaptation for Class-level Alignment](https://arxiv.org/abs/2109.06422) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9980255660105066
      ],
      "excerpt": "  - [Unsupervised domain adaptation for cross-modality liver segmentation via joint adversarial learning and self-learning](https://arxiv.org/abs/2109.05664) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.993717632380165
      ],
      "excerpt": "  - [CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation](https://arxiv.org/abs/2109.06165) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.987115451605939
      ],
      "excerpt": "  - ICCV-21 [Shape-Biased Domain Generalization via Shock Graph Embeddings](https://arxiv.org/abs/2109.05671) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9926083698414653
      ],
      "excerpt": "  - [Domain and Content Adaptive Convolution for Domain Generalization in Medical Image Segmentation](https://arxiv.org/abs/2109.05676) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9795187663973746
      ],
      "excerpt": "  - [Class-conditioned Domain Generalization via Wasserstein Distributional Robust Optimization](https://arxiv.org/abs/2109.03676) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9895098518614193
      ],
      "excerpt": "  - [FedZKT: Zero-Shot Knowledge Transfer towards Heterogeneous On-Device Models in Federated Learning](https://arxiv.org/abs/2109.03775) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9444023723367748
      ],
      "excerpt": "  - [Fishr: Invariant Gradient Variances for Out-of-distribution Generalization](https://arxiv.org/abs/2109.02934) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9891063347747424
      ],
      "excerpt": "  - [How Does Adversarial Fine-Tuning Benefit BERT?](https://arxiv.org/abs/2108.13602) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9871793888638364
      ],
      "excerpt": "  - [Contrastive Domain Adaptation for Question Answering using Limited Text Corpora](https://arxiv.org/abs/2108.13854) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.993618782283189
      ],
      "excerpt": "  - [Robust Ensembling Network for Unsupervised Domain Adaptation](https://arxiv.org/abs/2108.09473) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9964073958329444,
        0.8786044417622563
      ],
      "excerpt": "  - [Federated Multi-Task Learning under a Mixture of Distributions](https://arxiv.org/abs/2108.10252) \n    - Federated multi-task learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8891193958749688
      ],
      "excerpt": "  - [Fine-tuning is Fine in Federated Learning](http://arxiv.org/abs/2108.07313) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9970681164345253,
        0.9449187648369126
      ],
      "excerpt": "  - [Federated Multi-Target Domain Adaptation](http://arxiv.org/abs/2108.07792) \n    - Federated multi-target DA \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9911984053471814
      ],
      "excerpt": "  - [Learning Transferable Parameters for Unsupervised Domain Adaptation](https://arxiv.org/abs/2108.06129) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9980549281682063
      ],
      "excerpt": "  - MICCAI-21 [A Systematic Benchmarking Analysis of Transfer Learning for Medical Image Analysis](https://arxiv.org/abs/2108.05930) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9991192980025485,
        0.8944898729238315
      ],
      "excerpt": "  - [TVT: Transferable Vision Transformer for Unsupervised Domain Adaptation](https://arxiv.org/abs/2108.05988) \n    - Vision transformer for domain adaptation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999048380072825
      ],
      "excerpt": "  - CIKM-21 [AdaRNN: Adaptive Learning and Forecasting of Time Series](https://arxiv.org/abs/2108.04443) [Code](https://github.com/jindongwang/transferlearning/tree/master/code/deep/adarnn) [\u77e5\u4e4e\u6587\u7ae0](https://zhuanlan.zhihu.com/p/398036372) [Video](https://www.bilibili.com/video/BV1Gh411B7rj/) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9909980892991569,
        0.8221223869978854
      ],
      "excerpt": "  - TKDE-21 [Unsupervised Deep Anomaly Detection for Multi-Sensor Time-Series Signals](https://arxiv.org/abs/2107.12626) \n    - Anomaly detection using semi-supervised and transfer learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9975585887853464
      ],
      "excerpt": "  - SemDIAL-21 [Generating Personalized Dialogue via Multi-Task Meta-Learning](https://arxiv.org/abs/2108.03377) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9946661432129781
      ],
      "excerpt": "  - ICCV-21 [BiMaL: Bijective Maximum Likelihood Approach to Domain Adaptation in Semantic Scene Segmentation](https://arxiv.org/abs/2108.03267) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9937080029380634
      ],
      "excerpt": "  - [A Survey on Cross-domain Recommendation: Taxonomies, Methods, and Future Directions](https://arxiv.org/abs/2108.03357) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9430702385666204
      ],
      "excerpt": "  - [A Data Augmented Approach to Transfer Learning for Covid-19 Detection](https://arxiv.org/abs/2108.02870) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977792281807432
      ],
      "excerpt": "  - [Dual-Tuning: Joint Prototype Transfer and Structure Regularization for Compatible Feature Learning](https://arxiv.org/abs/2108.02959) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9862519854993977
      ],
      "excerpt": "  - [Finetuning Pretrained Transformers into Variational Autoencoders](https://arxiv.org/abs/2108.02446) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9993956330831455,
        0.9541892734014897
      ],
      "excerpt": "  - [Domain Adaptor Networks for Hyperspectral Image Recognition](http://arxiv.org/abs/2108.01555) \n    - Finetune for hyperspectral image recognition \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9277320040810587
      ],
      "excerpt": "  - CVPR-21 [Efficient Conditional GAN Transfer With Knowledge Propagation Across Classes](https://openaccess.thecvf.com/content/CVPR2021/html/Shahbazi_Efficient_Conditional_GAN_Transfer_With_Knowledge_Propagation_Across_Classes_CVPR_2021_paper.html) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9631169385980524,
        0.87858349814074
      ],
      "excerpt": "  - CVPR-21 [Ego-Exo: Transferring Visual Representations From Third-Person to First-Person Videos](https://openaccess.thecvf.com/content/CVPR2021/html/Li_Ego-Exo_Transferring_Visual_Representations_From_Third-Person_to_First-Person_Videos_CVPR_2021_paper.html) \n    - Transfer learning from third-person to first-person video \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9945233369203008
      ],
      "excerpt": "  - [Toward Co-creative Dungeon Generation via Transfer Learning](http://arxiv.org/abs/2107.12533) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9932679998012028
      ],
      "excerpt": "  - [Transfer Learning in Electronic Health Records through Clinical Concept Embedding](https://arxiv.org/abs/2107.12919) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8780257473396069
      ],
      "excerpt": "  - CVPR-21 [Conditional Bures Metric for Domain Adaptation](https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Conditional_Bures_Metric_for_Domain_Adaptation_CVPR_2021_paper.html) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9866311617293235,
        0.9172022428769973
      ],
      "excerpt": "  - CVPR-21 [Wasserstein Barycenter for Multi-Source Domain Adaptation](https://openaccess.thecvf.com/content/CVPR2021/html/Montesuma_Wasserstein_Barycenter_for_Multi-Source_Domain_Adaptation_CVPR_2021_paper.html) \n    - Use Wasserstein Barycenter for multi-source domain adaptation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8868183352878298
      ],
      "excerpt": "  - CVPR-21 [Reducing Domain Gap by Reducing Style Bias](https://openaccess.thecvf.com/content/CVPR2021/html/Nam_Reducing_Domain_Gap_by_Reducing_Style_Bias_CVPR_2021_paper.html) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.988971265625527
      ],
      "excerpt": "  - 20210716 ICML-21 [Continual Learning in the Teacher-Student Setup: Impact of Task Similarity](https://arxiv.org/abs/2107.04384) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9901087270882659
      ],
      "excerpt": "  - 20210716 BMCV-extend [Exploring Dropout Discriminator for Domain Adaptation](https://arxiv.org/abs/2107.04231) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9986742225513756
      ],
      "excerpt": "  - 20210716 TPAMI-21 [Lifelong Teacher-Student Network Learning](https://arxiv.org/abs/2107.04689) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9456255068125268
      ],
      "excerpt": "  - 20210716 MICCAI-21 [Few-Shot Domain Adaptation with Polymorphic Transformers](https://arxiv.org/abs/2107.04805) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9990005928990231,
        0.8778969354790295
      ],
      "excerpt": "  - 20210716 InterSpeech-21 [Speech2Video: Cross-Modal Distillation for Speech to Video Generation](https://arxiv.org/abs/2107.04806) \n    - Cross-model distillation for video generation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9995439963673799
      ],
      "excerpt": "  - 20210716 ICML-21 workshop [Leveraging Domain Adaptation for Low-Resource Geospatial Machine Learning](https://arxiv.org/abs/2107.04983) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9320836846800284
      ],
      "excerpt": "Multi-source domain adaptation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8786044417622563
      ],
      "excerpt": "Multi-task learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9109347581007231
      ],
      "excerpt": "2020 \u8fc1\u79fb\u5b66\u4e60\u6700\u65b0survey\uff0c\u6765\u81ea\u4e2d\u79d1\u9662\u8ba1\u7b97\u6240\u5e84\u798f\u632f\u56e2\u961f\uff0c\u53d1\u8868\u5728Proceedings of the IEEE: A Comprehensive Survey on Transfer Learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9524130631085533,
        0.8492404428354492,
        0.9501523211812867,
        0.980962830661362,
        0.9748570003684383,
        0.9883751410887264,
        0.9636860457552628,
        0.9888467279867075,
        0.9019632321793939
      ],
      "excerpt": "2019 \u4e00\u7bc7\u65b0survey\uff1aTransfer Adaptation Learning: A Decade Survey \n2018 \u4e00\u7bc7\u8fc1\u79fb\u5ea6\u91cf\u5b66\u4e60\u7684\u7efc\u8ff0: Transfer Metric Learning: Algorithms, Applications and Outlooks \n2018 \u4e00\u7bc7\u6700\u8fd1\u7684\u975e\u5bf9\u79f0\u60c5\u51b5\u4e0b\u7684\u5f02\u6784\u8fc1\u79fb\u5b66\u4e60\u7efc\u8ff0\uff1aAsymmetric Heterogeneous Transfer Learning: A Survey \n2018 Neural style transfer\u7684\u4e00\u4e2asurvey\uff1aNeural Style Transfer: A Review \n2018 \u6df1\u5ea6domain adaptation\u7684\u4e00\u4e2a\u7efc\u8ff0\uff1aDeep Visual Domain Adaptation: A Survey \n2017 \u591a\u4efb\u52a1\u5b66\u4e60\u7684\u7efc\u8ff0\uff0c\u6765\u81ea\u9999\u6e2f\u79d1\u6280\u5927\u5b66\u6768\u5f3a\u56e2\u961f\uff1aA survey on multi-task learning \n2017 \u5f02\u6784\u8fc1\u79fb\u5b66\u4e60\u7684\u7efc\u8ff0\uff1aA survey on heterogeneous transfer learning \n2017 \u8de8\u9886\u57df\u6570\u636e\u8bc6\u522b\u7684\u7efc\u8ff0\uff1aCross-dataset recognition: a survey \n2016 A survey of transfer learning\u3002\u5176\u4e2d\u4ea4\u4ee3\u4e86\u4e00\u4e9b\u6bd4\u8f83\u7ecf\u5178\u7684\u5982\u540c\u6784\u3001\u5f02\u6784\u7b49\u5b66\u4e60\u65b9\u6cd5\u4ee3\u8868\u6027\u6587\u7ae0\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8834794637026091
      ],
      "excerpt": "2010 A survey on transfer learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9200020374065359,
        0.9724867277393163
      ],
      "excerpt": "\u89c6\u89c9domain adaptation\u7efc\u8ff0\uff1aVisual Domain Adaptation: A Survey of Recent Advances \n\u8fc1\u79fb\u5b66\u4e60\u5e94\u7528\u4e8e\u884c\u4e3a\u8bc6\u522b\u7efc\u8ff0\uff1aTransfer Learning for Activity Recognition: A Survey \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8803856903012346,
        0.8356013927728488
      ],
      "excerpt": "\u591a\u4e2a\u6e90\u57df\u8fdb\u884c\u8fc1\u79fb\u7684\u7efc\u8ff0\uff1aA Survey of Multi-source Domain Adaptation\u3002 \nTheory \uff08\u7406\u8bba\u6587\u7ae0\uff09: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336221125029482
      ],
      "excerpt": "CVPR-19 Characterizing and Avoiding Negative Transfer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9760330759708156,
        0.9349788254008606
      ],
      "excerpt": "ICML-20 On Learning Language-Invariant Representations for Universal Machine Translation \nTheory for universal machine translation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9274409132073548
      ],
      "excerpt": "NIPS-08 Learning Bounds for Domain Adaptation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9554441738822752
      ],
      "excerpt": "Visual Domain Adaptation Challenge (VisDA) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9829698642002277
      ],
      "excerpt": "Computer vision \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "Natural language processing \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9677640385174676
      ],
      "excerpt": "Human activity recognition \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jindongwang/transferlearning",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Anyone interested in transfer learning is welcomed to contribute to this repo (by pull request):\n\nYou can add the latest publications / tools / tutorials directly to readme.md and awesome_paper.md.\nYou can add code to the code directory. You are welcomed to place the code of your published paper in this repo!\nYou are welcomed to update anything helpful.\n\n\u5982\u679c\u4f60\u5bf9\u672c\u9879\u76ee\u611f\u5174\u8da3\uff0c\u975e\u5e38\u6b22\u8fce\u4f60\u52a0\u5165\uff01\n\n\u53ef\u4ee5\u63a8\u8350\u6700\u65b0\u7684\u76f8\u5173\u8bba\u6587/\u5de5\u5177/\u8bb2\u5ea7\uff0c\u5c06\u4fe1\u606f\u901a\u8fc7pull request\u7684\u65b9\u5f0f\u66f4\u65b0\u5230readme.md\u548cawesome_paper.md\u4e2d\u3002\n\u63a8\u8350\u4ee3\u7801\u5230code\u6587\u4ef6\u5939\u4e2d\u3002\u6b22\u8fce\u5c06\u4f60\u8bba\u6587\u4e2d\u7684\u4ee3\u7801\u5f00\u6e90\u5230\u672c\u9879\u76ee\u4e2d\uff01\n\u4efb\u4f55\u6709\u7528\u7684\u5efa\u8bae\u90fd\u53ef\u8fdb\u884c\u8d21\u732e\u3002\n\n\u6b22\u8fce!",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-04-30T11:32:21Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-06T08:46:01Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8354094364721761
      ],
      "excerpt": "<h4 align=\"center\">Everything about Transfer Learning.</h4> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8030093847302596
      ],
      "excerpt": "Paperweekly: A website to recommend and read paper notes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.950453872383005
      ],
      "excerpt": "    - Theory and algorithm of domain-invariant learning for transfer learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9261843093717581
      ],
      "excerpt": "    - Deep transfer learning for RL \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "    - MMD for covariate shift \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8502382318458633
      ],
      "excerpt": "    - Scaling up for zero-shot transfer learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8491610462427096
      ],
      "excerpt": "    - Modular Gaussian process for transfer learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8488718047273945
      ],
      "excerpt": "    - Temporal knowledge distillation for on-device ASR \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8700255982753755
      ],
      "excerpt": "    - Age and gender prediction using transfer learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8547380212087043
      ],
      "excerpt": "    - \u5bf9\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684sim-to-real transfer\u8fdb\u884c\u7406\u8bba\u4e0a\u7684\u5206\u6790 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.978027802044922
      ],
      "excerpt": "    - Clustering and discriminative alignment for DA \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8161118482580927
      ],
      "excerpt": "    - Few-shot intent detection using pretrain and finetune \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8186080777957052
      ],
      "excerpt": "    - Using Kronecker decomposition and knowledge distillation for pre-trained language models compression \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8241937162285112
      ],
      "excerpt": "    - Zero-shot transfer in heterogeneous federated learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8272945003240391
      ],
      "excerpt": "    - Finetuning in federated learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8161163993054549
      ],
      "excerpt": "    - Learning partial transfer parameters for DA \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9467141537591017
      ],
      "excerpt": "    - A benchmark of transfer learning for medical image \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9710923095061601
      ],
      "excerpt": "    - A new perspective to using transfer learning for time series analysis \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9746741878760007
      ],
      "excerpt": "    - Data augmentation to transfer learning for COVID \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "    - Finetune transformer to VAE \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8055722654527032
      ],
      "excerpt": "    - Transfer conditional GANs to unseen classes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8241937162285112
      ],
      "excerpt": "    - Transfer learning in electronic health record \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8014107703633306
      ],
      "excerpt": "    - Investigating task similarity in teacher-student learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8160924980336532
      ],
      "excerpt": "    - Using domain adaptation for geospatial ML \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9299158345156783
      ],
      "excerpt": "Here are some articles on transfer learning theory and survey. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.892975970790139
      ],
      "excerpt": "2020 \u8fc1\u79fb\u5b66\u4e60\u6700\u65b0survey\uff0c\u6765\u81ea\u4e2d\u79d1\u9662\u8ba1\u7b97\u6240\u5e84\u798f\u632f\u56e2\u961f\uff0c\u53d1\u8868\u5728Proceedings of the IEEE: A Comprehensive Survey on Transfer Learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9808838810420036
      ],
      "excerpt": "\u7528transfer learning\u8fdb\u884csentiment classification\u7684\u7efc\u8ff0\uff1aA Survey of Sentiment Analysis Based on Transfer Learning  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.832397285522735
      ],
      "excerpt": "2016 A survey of transfer learning\u3002\u5176\u4e2d\u4ea4\u4ee3\u4e86\u4e00\u4e9b\u6bd4\u8f83\u7ecf\u5178\u7684\u5982\u540c\u6784\u3001\u5f02\u6784\u7b49\u5b66\u4e60\u65b9\u6cd5\u4ee3\u8868\u6027\u6587\u7ae0\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8526177550256799
      ],
      "excerpt": "2010 A survey on transfer learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8804991338113212
      ],
      "excerpt": "\u8fc1\u79fb\u5b66\u4e60\u4e0e\u589e\u5f3a\u5b66\u4e60\uff1aTransfer Learning for Reinforcement Learning Domains: A Survey \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8083083097989325
      ],
      "excerpt": "The first work on causal transfer learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9422030898654988,
        0.8079473670511783
      ],
      "excerpt": "ICML-20 On Learning Language-Invariant Representations for Universal Machine Translation \nTheory for universal machine translation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9495397936828833
      ],
      "excerpt": "NIPS-06 Analysis of Representations for Domain Adaptation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "Unified codebases for: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.907698633808481,
        0.881368042295641
      ],
      "excerpt": "More: see HERE and HERE for an instant run using Google's Colab. \nHere are some transfer learning scholars and labs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8987032372548496,
        0.8953091366767342
      ],
      "excerpt": "Please note that this list is far not complete. A full list can be seen in here. Transfer learning is an active field. If you are aware of some scholars, please add them here. \nHere are some popular thesis on transfer learning. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9520391133514541
      ],
      "excerpt": "Please see HERE for the popular transfer learning datasets and benchmark results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9817143423343162
      ],
      "excerpt": "See here for a full list of related journals and conferences. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "Medical and healthcare \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9158491565257129
      ],
      "excerpt": "See HERE for transfer learning applications. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8638590573069994
      ],
      "excerpt": "Advances in Transfer Learning: Theory, Algorithms, and Applications, DDL: October 2021 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Transfer learning / domain adaptation / domain generalization / multi-task learning etc. Papers, codes, datasets, applications, tutorials.-\u8fc1\u79fb\u5b66\u4e60",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jindongwang/transferlearning/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2940,
      "date": "Mon, 06 Dec 2021 09:30:16 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/jindongwang/transferlearning/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "jindongwang/transferlearning",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/notebooks/deep_transfer_tutorial.ipynb",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/notebooks/traditional_transfer_learning.ipynb",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/deep/CSG/test/distr_test.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/DeepDA/DANN/DANN.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/DeepDA/BNM/BNM.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/DeepDA/DSAN/DSAN.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/DeepDA/DAN/DAN.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/DeepDA/DeepCoral/DeepCoral.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/DeepDA/DAAN/DAAN.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/deep/CSG/a-imageclef/prepare_data.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/deep/CSG/a-imageclef/run_da.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/deep/CSG/a-imageclef/run_ood.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/deep/CSG/a-mnist/makedata.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/deep/CSG/a-mnist/run_da.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/deep/CSG/a-mnist/run_ood.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/deep/CSG/utils/reprun.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/deep/CSG/a-domainbed/prepare_data.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/deep/CSG/a-domainbed/run_da.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/deep/CSG/a-domainbed/run_ood.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/deep/DAAN/scripts/train.sh",
      "https://raw.githubusercontent.com/jindongwang/transferlearning/master/code/DeepDG/scripts/run.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8215695104513924
      ],
      "excerpt": "NOTE: You can directly open the code in Gihub Codespaces on the web to run them without downloading! Also, try github.dev. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9287268636971922
      ],
      "excerpt": "  <img src=\"png/logo.jpg\" alt=\"Overleaf\" width=\"500\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/jindongwang/transferlearning/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "MATLAB",
      "Jupyter Notebook",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright (C) 2020 KodeWorker\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "\u8fc1\u79fb\u5b66\u4e60 Transfer Learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "transferlearning",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "jindongwang",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jindongwang/transferlearning/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8382,
      "date": "Mon, 06 Dec 2021 09:30:16 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "transferlearning",
      "domainadaptation",
      "domain-adaptation",
      "transfer-learning",
      "survey",
      "deep-learning",
      "generalization",
      "few-shot",
      "tutorial-code",
      "theory",
      "papers",
      "few-shot-learning",
      "meta-learning",
      "domain-generalization",
      "representation-learning",
      "unsupervised-learning",
      "machine-learning",
      "self-supervised-learning",
      "paper",
      "style-transfer"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Want to quickly learn transfer learning\uff1f\u60f3\u5c3d\u5feb\u5165\u95e8\u8fc1\u79fb\u5b66\u4e60\uff1f\u770b\u4e0b\u9762\u7684\u6559\u7a0b\u3002\n\n- Books \u4e66\u7c4d\n  - **\u300a\u8fc1\u79fb\u5b66\u4e60\u300b\uff08\u6768\u5f3a\uff09** [[Buy](https://item.jd.com/12930984.html)] [[English version](https://www.cambridge.org/core/books/transfer-learning/CCFFAFE3CDBC245047F1DEC71D9EF3C7)]\n  - **\u300a\u8fc1\u79fb\u5b66\u4e60\u5bfc\u8bba\u300b(\u738b\u664b\u4e1c\u3001\u9648\u76ca\u5f3a\u8457)** [[Homepage](http://jd92.wang/tlbook)] [[Buy](https://item.jd.com/13283188.html)]\n\n- Blogs \u535a\u5ba2\n  - [Zhihu blogs - \u77e5\u4e4e\u4e13\u680f\u300a\u5c0f\u738b\u7231\u8fc1\u79fb\u300b\u7cfb\u5217\u6587\u7ae0](https://zhuanlan.zhihu.com/p/130244395)\n\t\n- Video tutorials \u89c6\u9891\u6559\u7a0b \n  - [Recent advance of transfer learning - 2021\u5e74\u6700\u65b0\u8fc1\u79fb\u5b66\u4e60\u53d1\u5c55\u73b0\u72b6\u63a2\u8ba8](https://www.bilibili.com/video/BV1N5411T7Sb)\n  - [Definitions of transfer learning area - \u8fc1\u79fb\u5b66\u4e60\u9886\u57df\u540d\u8bcd\u89e3\u91ca](https://www.bilibili.com/video/BV1fu411o7BW) [[Article](https://zhuanlan.zhihu.com/p/428097044)]\n  - [Domain generalization - \u8fc1\u79fb\u5b66\u4e60\u65b0\u5174\u7814\u7a76\u65b9\u5411\u9886\u57df\u6cdb\u5316](https://www.bilibili.com/video/BV1ro4y1S7dd/)\n  \n  - [Domain adaptation - \u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5(\u4e2d\u6587)](https://www.bilibili.com/video/BV1T7411R75a/) \n  - [Transfer learning by Hung-yi Lee @ NTU - \u53f0\u6e7e\u5927\u5b66\u674e\u5b8f\u6bc5\u7684\u89c6\u9891\u8bb2\u89e3(\u4e2d\u6587\u89c6\u9891)](https://www.youtube.com/watch?v=qD6iD4TFsdQ)\n\n- Brief introduction and slides \u7b80\u4ecb\u4e0eppt\u8d44\u6599\n\n  - [Recent advance of transfer learning](http://jd92.wang/assets/files/l15_jiqizhixin.pdf)\n  \n  - [Domain generalization survey](http://jd92.wang/assets/files/DGSurvey-ppt.pdf)\n  \n  - [Brief introduction in Chinese](https://github.com/jindongwang/transferlearning/blob/master/doc/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B.md)\n\t- [PPT (English)](http://jd92.wang/assets/files/l03_transferlearning.pdf) | [PPT (\u4e2d\u6587)](http://jd92.wang/assets/files/l08_tl_zh.pdf)\n\t\n  - \u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5 Domain adaptation: [PDF](http://jd92.wang/assets/files/l12_da.pdf) \uff5c [Video on Bilibili](https://www.bilibili.com/video/BV1T7411R75a/) | [Video on Youtube](https://www.youtube.com/watch?v=RbIsHNtluwQ&t=22s)\n\t\n  - Tutorial on transfer learning by Qiang Yang: [IJCAI'13](http://ijcai13.org/files/tutorial_slides/td2.pdf) | [2016 version](http://kddchina.org/file/IntroTL2016.pdf)\n\n- Talk is cheap, show me the code \u52a8\u624b\u6559\u7a0b\u3001\u4ee3\u7801\u3001\u6570\u636e \n  - [Pytorch\u5b98\u65b9\u8fc1\u79fb\u5b66\u4e60\u793a\u610f\u4ee3\u7801](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n\t- [Pytorch\u7684finetune Fine-tune based on Alexnet and Resnet](https://github.com/jindongwang/transferlearning/tree/master/code/AlexNet_ResNet)\n\t- [\u7528Pytorch\u8fdb\u884c\u6df1\u5ea6\u7279\u5f81\u63d0\u53d6](https://github.com/jindongwang/transferlearning/tree/master/code/feature_extractor)\n\t- [\u66f4\u591a More...](https://github.com/jindongwang/transferlearning/tree/master/code)\n\n- [Transfer Learning Scholars and Labs - \u8fc1\u79fb\u5b66\u4e60\u9886\u57df\u7684\u8457\u540d\u5b66\u8005\u3001\u4ee3\u8868\u5de5\u4f5c\u53ca\u5b9e\u9a8c\u5ba4\u4ecb\u7ecd](https://github.com/jindongwang/transferlearning/blob/master/doc/scholar_TL.md)\n\n- [Negative transfer - \u8d1f\u8fc1\u79fb](https://www.zhihu.com/question/66492194/answer/242870418)\n\n- - -\n\n",
      "technique": "Header extraction"
    }
  ]
}
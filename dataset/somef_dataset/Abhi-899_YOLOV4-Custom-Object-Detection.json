{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Abhi-899/YOLOV4-Custom-Object-Detection",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-07T10:42:59Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-19T10:33:06Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8668397078004768
      ],
      "excerpt": "In this project we will train the YOLOv4 network on 3 classes 'Ambulance' , 'Car' , 'Person' with the Google open image dataset  and run the detection on a real video caught on a moving traffic camera. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8637633652513648
      ],
      "excerpt": "YOLO stands for You Only Look Once. It\u2019s an object detection model used in deep learning use cases, of which there are mainly 2 main families: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9707721569435673,
        0.9655332901670455,
        0.9556369920274208,
        0.9414980343600332
      ],
      "excerpt": "YOLO belongs to the family of One-Stage Detectors. In a sliding window + classification approach, you look at the image and classify it for every window.Compared to YOLOv3,  YOLOv4 has improved again in terms of accuracy (average precision) and speed (FPS), the two metrics we generally use to qualify an object detection algorithm as shown in the below graph: \nAnd the best part of the YOLOv4 model is that model training can be done on a single GPU. \nGiven below is the architecture of the model: \nFor more one can look into the YOLOv4 model paper.THe link is given below: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8744490392776082
      ],
      "excerpt": "The images are very diverse and often contain complex scenes with several objects (8.4 per image on average). It contains image-level labels annotations, object bounding boxes, object segmentations, visual relationships, localized narratives, and more. It contains  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665581132984138
      ],
      "excerpt": "Step3: For running on google colab \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8155035929287642
      ],
      "excerpt": "The first thing we have to do is cloning and building the darknet.The following cells will clone darknet from AlexeyAB's famous repository, adjust the Makefile to enable OPENCV and GPU for darknet and then build darknet. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9763648215069847,
        0.9246386226130426
      ],
      "excerpt": "Now we need to edit the .cfg to fit our needs based on our object detector. Open it up in a code or text editor to do so. \nIf we downloaded cfg to google drive we can use the built in Text Editor by going to our google drive and double clicking on yolov4-obj.cfg and then clicking on the Open with drop down and selectin Text Editor. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9203947533493815
      ],
      "excerpt": "Make the rest of the changes to the cfg based on how many classes you are training your detector on. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8700521074575059
      ],
      "excerpt": "How to Configure Your Variables: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8344949477498043
      ],
      "excerpt": "We will be testing our model on a video taken by a moving traffic camera. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8362004788401967
      ],
      "excerpt": "Note that you would have to change your class names and paths given according to your model. Now remember that you have to give permission to your YOLO model for execution. That can be done using the following code: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9267555245643094
      ],
      "excerpt": "The testing could have been done better by adding the -thresh flag. We could easily see after running the output1.avi that a black van was also detected as an ambulance but with a lower threshold. Now that can be improved by: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9722912768949329
      ],
      "excerpt": "Now, YOLOv4 can also return the co-ordinates of the bounding boxes. In order to know how to perform object tracking and counting in a given area, Please click on the link below to my repository on vehicle tracking and counting: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "In this project we will train the YOLOV4 network on 3 classes 'Ambulance' , 'Car' , 'Person' with the Google open image dataset  and run the detection on a real video caught on a moving traffic camera",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Abhi-899/YOLOV4-Custom-Object-Detection/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 12 Dec 2021 23:48:34 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Abhi-899/YOLOV4-Custom-Object-Detection/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Abhi-899/YOLOV4-Custom-Object-Detection",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Abhi-899/YOLOV4-Custom-Object-Detection/main/Yolov4_obj_detect.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8004465962750761
      ],
      "excerpt": "2) One-Stage Detectors \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8072927247693391,
        0.984982798320422
      ],
      "excerpt": "To download a dataset from OID: \nStep 1: Install git \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9893272198983933
      ],
      "excerpt": "         git clone https://github.com/EscVM/OIDv4_Toolkit.git \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9893272198983933
      ],
      "excerpt": "       !git clone https://github.com/EscVM/OIDv4_Toolkit.git \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9527812871111235
      ],
      "excerpt": "One will get the OID repo here: https://g.co/dataset/open-images \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.999746712887969
      ],
      "excerpt": "!pip install icrawler \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8511482504193127,
        0.9879863063452118
      ],
      "excerpt": "The first thing we have to do is cloning and building the darknet.The following cells will clone darknet from AlexeyAB's famous repository, adjust the Makefile to enable OPENCV and GPU for darknet and then build darknet. \n!git clone https://github.com/AlexeyAB/darknet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.870221687725207
      ],
      "excerpt": "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8059533841295182
      ],
      "excerpt": "Note that you would have to change your class names and paths given according to your model. Now remember that you have to give permission to your YOLO model for execution. That can be done using the following code: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8178738193298204
      ],
      "excerpt": "To download a dataset from OID: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8972350352179124
      ],
      "excerpt": "         python main.py downloader --classes Ambulance Car Person --type_csv train --multiclass 1 --limit 100 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8972350352179124
      ],
      "excerpt": "       !python main.py downloader --classes Ambulance Car Person --type_csv train --multiclass 1 --limit 100 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516,
        0.8792929221100471
      ],
      "excerpt": "from icrawler.builtin import GoogleImageCrawler \ngoogle_Crawler = GoogleImageCrawler(storage = {'root_dir': r'write the name of the directory you want to save to here'}) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9157850784907856,
        0.8831473626008295,
        0.9251550994939332,
        0.8888610676275175
      ],
      "excerpt": "Now we have to make the dataset directory structure suitable for YOLOv4. So first we have to run the annotation.py and the( train and test creation.py) which would create text files containing the data about the images. \n!python annotation.py \n!python train and test creation.py \nEach image file will have a corresponding text file named <image name>.txt along with the train.txt , the test.txt files wuth the absolute paths of the train and test images. It also creates the image_data.data file which contains the no. of classes, paths to train.txt and test.txt and also the backup folder where the weights files for checkpoints after every 1000 steps will be stored along with the weights of the last checkpoint. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8483187088188731,
        0.8577423981008783
      ],
      "excerpt": "Now run the following command to train the model. The -dont_show flag stops streaming during training \n!./darknet detector train data/Person_Car_Ambulance/image_data.data cfg/yolov4_train.cfg yolov4.conv.137 -dont_show \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8156482000523162
      ],
      "excerpt": "!./darknet detector demo data/Person_Car_Ambulance/image_data.data cfg/yolov4_test.cfg /content/drive/MyDrive/YOLO_V4/darknet/backup/yolov4_train_last.weights -dont_show /content/drive/MyDrive/YOLO_V4/test.mp4  -i 0 -out_filename /content/drive/MyDrive/YOLO_V4/output.avi \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Abhi-899/YOLOV4-Custom-Object-Detection/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Abhi-899\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "YOLOV4-Custom-Object-Detection",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "YOLOV4-Custom-Object-Detection",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Abhi-899",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Abhi-899/YOLOV4-Custom-Object-Detection/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 12 Dec 2021 23:48:34 GMT"
    },
    "technique": "GitHub API"
  }
}
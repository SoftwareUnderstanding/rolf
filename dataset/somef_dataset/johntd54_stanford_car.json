{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1608.06993\n- Weakly-Supervised Data Augmentation Network: https://arxiv.org/abs/1901.09891\n\nAdditionally, some techniques are also employed to improve training and prediction:\n\n- Super-Convergence: https://arxiv.org/abs/1708.07120. Inspired by cyclical learning rate schedule, this technique cuts training time by nearly a half, while increaseing final accuracy.\n- Temperature scaling: https://arxiv.org/abs/1706.04599. Deep learning models are usually over-confident. Temperature scaling calibrates the confidence score of model prediction, so that it is less likely for the incorrect prediction to have high confidence score. In doing so, most incorrect predictions will have low confidence score, which allows human double checking if necessary.\n- Add more output logits than the number of classes in dataset. This model has 500 units in the output layer, even though the Stanford dataset only has 196 classes. Through experiments on this dataset, I consistently observed higher accuracy for the larger model. Moreover, by adding more units into the output layer, it would be easier to fine-tune model whenever we want to incorporate new car classes (which should happen very regularly in the real world",
      "https://arxiv.org/abs/1901.09891\n\nAdditionally, some techniques are also employed to improve training and prediction:\n\n- Super-Convergence: https://arxiv.org/abs/1708.07120. Inspired by cyclical learning rate schedule, this technique cuts training time by nearly a half, while increaseing final accuracy.\n- Temperature scaling: https://arxiv.org/abs/1706.04599. Deep learning models are usually over-confident. Temperature scaling calibrates the confidence score of model prediction, so that it is less likely for the incorrect prediction to have high confidence score. In doing so, most incorrect predictions will have low confidence score, which allows human double checking if necessary.\n- Add more output logits than the number of classes in dataset. This model has 500 units in the output layer, even though the Stanford dataset only has 196 classes. Through experiments on this dataset, I consistently observed higher accuracy for the larger model. Moreover, by adding more units into the output layer, it would be easier to fine-tune model whenever we want to incorporate new car classes (which should happen very regularly in the real world",
      "https://arxiv.org/abs/1708.07120. Inspired by cyclical learning rate schedule, this technique cuts training time by nearly a half, while increaseing final accuracy.\n- Temperature scaling: https://arxiv.org/abs/1706.04599. Deep learning models are usually over-confident. Temperature scaling calibrates the confidence score of model prediction, so that it is less likely for the incorrect prediction to have high confidence score. In doing so, most incorrect predictions will have low confidence score, which allows human double checking if necessary.\n- Add more output logits than the number of classes in dataset. This model has 500 units in the output layer, even though the Stanford dataset only has 196 classes. Through experiments on this dataset, I consistently observed higher accuracy for the larger model. Moreover, by adding more units into the output layer, it would be easier to fine-tune model whenever we want to incorporate new car classes (which should happen very regularly in the real world",
      "https://arxiv.org/abs/1706.04599. Deep learning models are usually over-confident. Temperature scaling calibrates the confidence score of model prediction, so that it is less likely for the incorrect prediction to have high confidence score. In doing so, most incorrect predictions will have low confidence score, which allows human double checking if necessary.\n- Add more output logits than the number of classes in dataset. This model has 500 units in the output layer, even though the Stanford dataset only has 196 classes. Through experiments on this dataset, I consistently observed higher accuracy for the larger model. Moreover, by adding more units into the output layer, it would be easier to fine-tune model whenever we want to incorporate new car classes (which should happen very regularly in the real world"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8314474212345958
      ],
      "excerpt": "This is submission for the Computer Vision challenge. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944484218006108,
        0.9389946808544437
      ],
      "excerpt": "DenseNet: https://arxiv.org/abs/1608.06993 \nWeakly-Supervised Data Augmentation Network: https://arxiv.org/abs/1901.09891 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8225105224127793
      ],
      "excerpt": "Super-Convergence: https://arxiv.org/abs/1708.07120. Inspired by cyclical learning rate schedule, this technique cuts training time by nearly a half, while increaseing final accuracy. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/johntd54/stanford_car",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-16T05:41:06Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-09T13:49:56Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9375333606670029
      ],
      "excerpt": "The model employs some of the common deep learning techniques in computer vision: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8308082024182541
      ],
      "excerpt": "Additionally, some techniques are also employed to improve training and prediction: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9268165726362411,
        0.8983849930850079
      ],
      "excerpt": "Temperature scaling: https://arxiv.org/abs/1706.04599. Deep learning models are usually over-confident. Temperature scaling calibrates the confidence score of model prediction, so that it is less likely for the incorrect prediction to have high confidence score. In doing so, most incorrect predictions will have low confidence score, which allows human double checking if necessary. \nAdd more output logits than the number of classes in dataset. This model has 500 units in the output layer, even though the Stanford dataset only has 196 classes. Through experiments on this dataset, I consistently observed higher accuracy for the larger model. Moreover, by adding more units into the output layer, it would be easier to fine-tune model whenever we want to incorporate new car classes (which should happen very regularly in the real world). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Classification model for fine-grained visual classification on the Stanford Car dataset.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/johntd54/stanford_car/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Wed, 08 Dec 2021 08:43:57 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/johntd54/stanford_car/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "johntd54/stanford_car",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/johntd54/stanford_car/master/LimeVisualization.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The evaluation script can take in image or folder of images (recursively). Please look at the folder *`./data/samples`* in this repo to see an example input image folder. After evaluation, the script will generate a csv file, with the leftmost column is the image filename, and all other columns contain the confidence score for corresponding class.\n\nThe pretrained model can be downloaded either from [Dropbox](https://www.dropbox.com/s/pskw0fsjhnrlmyj/010.ckpt?dl=1) (wget-friendly) or  [Gdrive](https://drive.google.com/open?id=1znFK4xtXkNrcRBVF9NCUHHjKMMawgKf0).\n\n```bash\n#: clone this repo\ngit clone https://github.com/johntd54/stanford_car\ncd stanford_car\n\n#: create a new python 3.7 environment with conda\nconda create -n stanford_car_eval python=3.7\nconda activate stanford_car_eval\n\nmkdir ckpt\nwget https://www.dropbox.com/s/pskw0fsjhnrlmyj/010.ckpt?dl=1 -O ckpt/010.ckpt\n#: download the pre-trained model into folder `ckpt`\n#: or GDrive: https://drive.google.com/open?id=1znFK4xtXkNrcRBVF9NCUHHjKMMawgKf0\n\n#: install supporting libraries\npip install -r requirements.txt\nconda install pytorch torchvision cudatoolkit=10.0 -c pytorch\n#: or `pip install torch torchvision` if gpu is not available\n\n#: take note of the evaluation folder and run the evaluation script\n#: the result will be stored at ./data/result.csv and ./data/confidence.csv\n#: remove the `--gpu` parameter on non-gpu machine\npython evaluate.py [image_folder] --ckpt [checkpoint_path] --gpu\n```\n\nThe above step-by-step operation will output 2 files:\n- *`./data/confidence.csv`*: this file contains 197 columns, the first column is filename, the other 196 columns are confidence score for corresponding class. The class label can be obtained at *`./data/meta.json`*.\n- *`./data/result.csv`*: this file contains 3 columns, the first column is filename, the second column is the class index, and the third column is class label (looked up from `./data/meta.json`.\n\n",
      "technique": "Header extraction"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/johntd54/stanford_car/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Stanford Training",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "stanford_car",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "johntd54",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/johntd54/stanford_car/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Wed, 08 Dec 2021 08:43:57 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@inproceedings{\nivanov2021boost,\ntitle={Boost then Convolve: Gradient Boosting Meets Graph Neural Networks},\nauthor={Sergei Ivanov and Liudmila Prokhorenkova},\nbooktitle={International Conference on Learning Representations (ICLR)},\nyear={2021},\nurl={https://openreview.net/forum?id=ebS5NUfoMKL}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{\nivanov2021boost,\ntitle={Boost then Convolve: Gradient Boosting Meets Graph Neural Networks},\nauthor={Sergei Ivanov and Liudmila Prokhorenkova},\nbooktitle={International Conference on Learning Representations (ICLR)},\nyear={2021},\nurl={https://openreview.net/forum?id=ebS5NUfoMKL}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nd7141/bgnn",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-18T16:50:56Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-04T12:22:53Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9442916438191991,
        0.9586434091951394
      ],
      "excerpt": "The code and data for the ICLR 2021 paper: Boost then Convolve: Gradient Boosting Meets Graph Neural Networks \nThis code contains implementation of the following models for graphs:  \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nd7141/bgnn/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 25,
      "date": "Tue, 07 Dec 2021 19:31:00 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/nd7141/bgnn/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "nd7141/bgnn",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To run the models you have to download the repo, install the requirements, and extract the datasets.\n\nFirst, let's create a python environment:\n```bash\nmkdir envs\ncd envs\npython -m venv bgnn_env\nsource bgnn_env/bin/activate\ncd ..\n```\n---\nSecond, let's download the code and install requirements\n```bash\ngit clone https://github.com/nd7141/bgnn.git \ncd bgnn\nunzip datasets.zip\nmake install\n```\n---\nNext we need to install a proper version of [PyTorch](https://pytorch.org/) and [DGL](https://www.dgl.ai/), depending on the cuda version of your machine.\nWe strongly encourage to use GPU-supported versions of DGL (the speed up in training can be 100x).\n\nFirst, determine your cuda version with `nvcc --version`. \nThen, check installation instructions for [pytorch](https://pytorch.org/get-started/locally/).\nFor example for cuda version 9.2, install it as follows:\n```bash\npip install torch==1.7.1+cu92 torchvision==0.8.2+cu92 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n```\n\nIf you don't have GPU, use the following: \n```bash\npip install torch==1.7.1+cpu torchvision==0.8.2+cpu torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n```\n---\nSimilarly, you need to install [DGL library](https://docs.dgl.ai/en/0.4.x/install/). \nFor example, cuda==9.2:\n\n```bash\npip install dgl-cu92\n```\n\nFor cpu version of DGL: \n```bash\npip install dgl\n```\n\nTested versions of `torch` and `dgl` are:\n* torch==1.7.1+cu92\n* dgl_cu92==0.5.3\n\n",
      "technique": "Header extraction"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/nd7141/bgnn/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "## Boosted Graph Neural Networks",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "bgnn",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "nd7141",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nd7141/bgnn/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Starting point is file `scripts/run.py`:\n```bash\npython scripts/run.py dataset models \n    (optional) \n            --save_folder: str = None\n            --task: str = 'regression',\n            --repeat_exp: int = 1,\n            --max_seeds: int = 5,\n            --dataset_dir: str = None,\n            --config_dir: str = None\n```\nAvailable options for dataset: \n* house (regression)\n* county (regression)\n* vk (regression)\n* wiki (regression)\n* avazu (regression)\n* vk_class (classification)\n* house_class (classification)\n* dblp (classification)\n* slap (classification)\n* path/to/your/dataset\n    \nAvailable options for models are `catboost`, `lightgbm`, `gnn`, `resgnn`, `bgnn`, `all`.\n\nEach model is specifed by its config. Check [`configs/`](https://github.com/nd7141/bgnn/tree/master/configs/model) folder to specify parameters of the model and run.\n\nUpon completion, the results wil be saved in the specifed folder (default: `results/{dataset}/day_month/`).\nThis folder will contain `aggregated_results.json`, which will contain aggregated results for each model.\nEach model will have 4 numbers in this order: `mean metric` (RMSE or accuracy), `std metric`, `mean runtime`, `std runtime`.\nFile `seed_results.json` will have results for each experiment and each seed. \nAdditional folders will contain loss values during training. \n\n---\n\n###Examples\n\nThe following script will launch all models on `House` dataset.  \n```bash\npython scripts/run.py house all\n```\n\nThe following script will launch CatBoost and GNN models on `SLAP` classification dataset.  \n```bash\npython scripts/run.py slap catboost gnn --task classification\n```\n\nThe following script will launch LightGBM model for 5 splits of data, repeating each experiment for 3 times.  \n```bash\npython scripts/run.py vk lightgbm --repeat_exp 3 --max_seeds 5\n```\n\nThe following script will launch resgnn and bgnn models saving results to custom folder.  \n```bash\npython scripts/run.py county resgnn bgnn --save_folder ./county_resgnn_bgnn\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "To run the code on your dataset, it's necessary to prepare the files in the right format. \n\nYou can check examples in `datasets/` folder. \n\nThere should be at least `X.csv` (node features), `y.csv` (target labels), `graph.graphml` (graph in graphml format).\n\nMake sure to keep _these_ filenames for your dataset.\n\nYou can also have `cat_features.txt` specifying names of categorical columns.\n\nYou can also have `masks.json` specifying train/val/test splits. \n\nAfter that run the script as usual: \n```bash\npython scripts/run.py path/to/your/dataset gnn catboost \n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 106,
      "date": "Tue, 07 Dec 2021 19:31:00 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        0.9869405348645832
      ],
      "excerpt": "cited from https://arxiv.org/pdf/1609.04802.pdf \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Hayashi-Yudai/SRGAN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-23T13:56:05Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-03T06:59:04Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Super resolution GAN",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Hayashi-Yudai/SRGAN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 13 Dec 2021 10:21:49 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Hayashi-Yudai/SRGAN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Hayashi-Yudai/SRGAN",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Make the following directory tree for your dataset on the project root and place original images in `train/high_resolution` and `validate/high_resolution/` directories.\n\n```\n.datasets\n\u2514\u2500\u2500 (your dataset name)\n    \u251c\u2500\u2500 test\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 high_resolution\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 low_resolution\n    \u251c\u2500\u2500 train\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 high_resolution\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 low_resolution\n    \u2514\u2500\u2500 validate\n        \u251c\u2500\u2500 high_resolution\n        \u2514\u2500\u2500 low_resolution\n```\n\nNext, make low resolution images which have quarter size of original ones and place them in `low_resolution` directories.\n\nThis program request TFRecords as dataset. I prepare a function for you. Fix `dataset_name` and `extension` in the src/datasets.py and execute it from project root.\n\n```bash\npython src/dataset.py\n```\n\nMake sure there exists `train.tfrecords` and `valid.tfrecords` in the `datasets/(your dataset name)` directory.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "Python 3.9.6 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.868734979367755
      ],
      "excerpt": "Start training with the following command \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.909864344228492
      ],
      "excerpt": "$ pipenv run train  #: If you use pipenv \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.868734979367755
      ],
      "excerpt": "Start training with the following command \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8507001641402145
      ],
      "excerpt": "TRAIN_DATA_PATH: ./datasets/train.tfrecords \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9752168458474206
      ],
      "excerpt": "$ python src/train.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8507001641402145
      ],
      "excerpt": "TRAIN_DATA_PATH: ./datasets/train.tfrecords \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9752168458474206
      ],
      "excerpt": "$ python src/train.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Hayashi-Yudai/SRGAN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SRGAN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SRGAN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Hayashi-Yudai",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Hayashi-Yudai/SRGAN/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Mon, 13 Dec 2021 10:21:49 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "machine-learning",
      "gan",
      "super-resolution",
      "computer-vision",
      "tensorflow",
      "python3"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can download pre-trained weight from [here](https://drive.google.com/drive/folders/1LE1AK0HVHN-_x9S3-aCUeA0mFT-D68VW?usp=sharing). These weights are trained with 32x32 images.\n\n![](https://github.com/Hayashi-Yudai/SRGAN/blob/main/assets/test_data.png)\n",
      "technique": "Header extraction"
    }
  ]
}
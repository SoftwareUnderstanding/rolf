{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1409.1556\n.. _Keras: https://keras.io\n.. _ImageNet: http://www.image-net.org/\n.. _alexcnwy: https://github.com/alexcnwy\n.. _hc: https://en.wikipedia.org/wiki/Hierarchical_clustering\n.. _dendro: https://en.wikipedia.org/wiki/Dendrogram\n.. _holiday: http://lear.inrialpes.fr/~jegou/data.php\n.. _curse: https://en.wikipedia.org/wiki/Curse_of_dimensionality\n.. _gh_beleidy: https://github.com/beleidy/unsupervised-image-clustering\n.. _commit_pfx: https://github.com/elcorto/libstuff/blob/master/commit_prefixes"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8492696827861188
      ],
      "excerpt": "functions called. If you do this and find settings which perform much better -- \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944484218006108
      ],
      "excerpt": ".. _VGG16: https://arxiv.org/abs/1409.1556 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9201869887197545,
        0.9105368110547479,
        0.9278824608274014,
        0.9278824608274014
      ],
      "excerpt": ".. _ImageNet: http://www.image-net.org/ \n.. _alexcnwy: https://github.com/alexcnwy \n.. _hc: https://en.wikipedia.org/wiki/Hierarchical_clustering \n.. _dendro: https://en.wikipedia.org/wiki/Dendrogram \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/leenaali1114/Hierarchical-Image-Clustering---Unsupervised-Learning",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-02T08:56:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-19T12:16:09Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9822449537367244,
        0.9438438947107513,
        0.934236093081645,
        0.8607795654164069
      ],
      "excerpt": "parameter 0...1, y-axis) to create clusters of images with that level of \nsimilarity. sim=0 is the root of the dendrogram (top in the plot) where \nthere is only one node (= all images in one cluster). sim=1 is equal to the \nend of the dendrogram tree (bottom in the plot), where each image is its own \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9841570071607827
      ],
      "excerpt": "The task of the fingerprints (feature vectors) is to represent an image's \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8987344716585309
      ],
      "excerpt": "representation of objects in higher layers, which we use for that purpose. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.916601147083043
      ],
      "excerpt": "placed into ~/.keras/models/. The network was trained on ImageNet_ and is \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8238061506762827
      ],
      "excerpt": "use (thanks for the hint! &lt;alexcnwy_&gt;_) the activations of the second to last \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8262340521136832
      ],
      "excerpt": "of shape (4096,)) by default. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9319038852186592,
        0.8078322598326056
      ],
      "excerpt": "put into clusters. The others are not assigned to any cluster. Technically they \nare in clusters of size 1, which we don't report by default (unless you use \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9029362161011478
      ],
      "excerpt": "find a good balance of clustering accuracy and the tolerable amount of \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9725529472023591,
        0.8369479062717236
      ],
      "excerpt": "Also, the parameters of the clustering method itself are worth tuning. ATM, we \nexpose only some in calc.cluster(). We tested several distance metrics and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.973805411324217
      ],
      "excerpt": "See calc.cluster() for \"method\", \"metric\" and \"criterion\" and the scipy \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.839118402967267,
        0.8659857354778275,
        0.8207449095203577
      ],
      "excerpt": "Additionally, some other implementations do not use any of the inner fully \nconnected layers as features, but instead the output of the last pooling \nlayer (layer 'flatten' in Keras' VGG16). We tested that briefly (see \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9393887369671685,
        0.8766194000978597,
        0.8780909546394801
      ],
      "excerpt": "'flatten' seems to do worse. But again, a quantitative analysis is in order. \nPCA: Because of the Curse of dimensionality &lt;curse_&gt;, it may be helpful to \nperform a PCA on the fingerprints before clustering to reduce the feature \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8898028682943548
      ],
      "excerpt": "in clustering results, in accordance to what others have found \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/leenaali1114/Hierarchical-Image-Clustering---Unsupervised-Learning/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 08 Dec 2021 17:03:47 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/leenaali1114/Hierarchical-Image-Clustering---Unsupervised-Learning/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "leenaali1114/Hierarchical-Image-Clustering---Unsupervised-Learning",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/leenaali1114/Hierarchical-Image-Clustering---Unsupervised-Learning/master/doc/generate-apidoc.sh",
      "https://raw.githubusercontent.com/leenaali1114/Hierarchical-Image-Clustering---Unsupervised-Learning/master/examples/inria_holiday.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": ".. code:: sh\n\n    $ pip3 install -e .\n\nor if you have the ``requirements.txt`` already installed (e.g. by your system's\npackage manager)\n\n.. code:: sh\n\n    $ pip3 install -e . --no-deps\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8415337485154393
      ],
      "excerpt": "One can now cut through the dendrogram tree at a certain height (sim \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.945543242127874
      ],
      "excerpt": "calc.cluster(..., min_csize=1)). One can now start to lower sim to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8013989761286194
      ],
      "excerpt": "Contributions are welcome. To streamline the git log, consider using one of \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8918974083095406
      ],
      "excerpt": ".. _alexcnwy: https://github.com/alexcnwy \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/leenaali1114/Hierarchical-Image-Clustering---Unsupervised-Learning/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright (c) 2019, Steve Schmerler &#103;&#105;&#116;&#64;&#101;&#108;&#99;&#111;&#114;&#116;&#111;&#46;&#99;&#111;&#109;\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n3. Neither the name of the copyright holder nor the names of its contributors\\n   may be used to endorse or promote products derived from this software\\n   without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# IMAGE CLUSTERING\nAbout",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Hierarchical-Image-Clustering---Unsupervised-Learning",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "leenaali1114",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/leenaali1114/Hierarchical-Image-Clustering---Unsupervised-Learning/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 08 Dec 2021 17:03:47 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The package is designed as a library. Here is what you can do: Enter the python interactive mode or create a python file with the following code\n\n.. code:: python\n\n    from imagecluster import calc as ic\n    from imagecluster import postproc as pp\n\n    # Create image database in memory. This helps to feed images to the NN model\n    # quickly.\n    ias = ic.image_arrays('pics/', size=(224,224))\n\n    # Create Keras NN model.\n    model = ic.get_model()\n\n    # Feed images through the model and extract fingerprints (feature vectors).\n    fps = ic.fingerprints(ias, model)\n\n    # Optionally run a PCA on the fingerprints to compress the dimensions. Use a\n    # cumulative explained variance ratio of 0.95.\n    fps = ic.pca(fps, n_components=0.95)\n\n    # Run clustering on the fingerprints.  Select clusters with similarity index\n    # sim=0.5\n    clusters = ic.cluster(fps, sim=0.5)\n\n    # Create dirs with links to images. Dirs represent the clusters the images\n    # belong to.\n    pp.make_links(clusters, 'pics/imagecluster/clusters')\n\n    # Plot images arranged in clusters.\n    pp.visualize(clusters, ias)\n\nSee also ``imagecluster.main.main()``. It does the same as the code above, but\nalso saves/loads the image database and the fingerprints to/from disk, such\nthat you can re-run the clustering and post-processing again without\nre-calculating fingerprints.\n\nExample session:\n\n.. code:: python\n\n    >>> from imagecluster import main\n    >>> main.main('pics/', sim=0.5, vis=True)\n    no fingerprints database pics/imagecluster/fingerprints.pk found\n    create image array database pics/imagecluster/images.pk\n    pics/140301.jpg\n    pics/140601.jpg\n    pics/140101.jpg\n    pics/140400.jpg\n    pics/140801.jpg\n    [...]\n    running all images through NN model ...\n    pics/140301.jpg\n    pics/140503.jpg\n    pics/140601.jpg\n    pics/140901.jpg\n    pics/140101.jpg\n    [...]\n    clustering ...\n    #images : #clusters\n    2 : 7\n    3 : 1\n    #images in clusters total:  17\n    cluster dir: pics/imagecluster/clusters\n\nIf you run this again on the same directory, only the clustering (which is very\nfast) and the post-processing (links, visualization) will be repeated.\n\nFor this example, we use a very small subset of the `Holiday image dataset\n<holiday_>`_ (25 images (all named 140*.jpg) of 1491 total images in the\ndataset).\n\nHave a look at the clusters (as dirs with symlinks to the relevant files):\n\n.. code:: sh\n\n    $ tree pics/imagecluster/clusters/\n    pics/imagecluster/clusters/\n    \u251c\u2500\u2500 cluster_with_2\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 cluster_0\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 140100.jpg -> /path/to/pics/140100.jpg\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 140101.jpg -> /path/to/pics/140101.jpg\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 cluster_1\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 140600.jpg -> /path/to/pics/140600.jpg\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 140601.jpg -> /path/to/pics/140601.jpg\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 cluster_2\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 140400.jpg -> /path/to/pics/140400.jpg\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 140401.jpg -> /path/to/pics/140401.jpg\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 cluster_3\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 140501.jpg -> /path/to/pics/140501.jpg\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 140502.jpg -> /path/to/pics/140502.jpg\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 cluster_4\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 140000.jpg -> /path/to/pics/140000.jpg\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 140001.jpg -> /path/to/pics/140001.jpg\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 cluster_5\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 140300.jpg -> /path/to/pics/140300.jpg\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 140301.jpg -> /path/to/pics/140301.jpg\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 cluster_6\n    \u2502\u00a0\u00a0     \u251c\u2500\u2500 140200.jpg -> /path/to/pics/140200.jpg\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 140201.jpg -> /path/to/pics/140201.jpg\n    \u2514\u2500\u2500 cluster_with_3\n        \u2514\u2500\u2500 cluster_0\n            \u251c\u2500\u2500 140801.jpg -> /path/to/pics/140801.jpg\n            \u251c\u2500\u2500 140802.jpg -> /path/to/pics/140802.jpg\n            \u2514\u2500\u2500 140803.jpg -> /path/to/pics/140803.jpg\n\nSo there are some clusters with 2 images each, and one with 3 images. Lets look\nat the clusters:\n\n.. image:: doc/clusters.png\n\nHere is the result of using a larger subset of 292 images from the same dataset.\n\n.. image:: doc/clusters_many.png\n\n",
      "technique": "Header extraction"
    }
  ]
}
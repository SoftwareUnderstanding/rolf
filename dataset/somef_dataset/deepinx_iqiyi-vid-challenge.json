{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The code is adapted based on an intial fork from the [insightface](https://github.com/deepinsight/insightface) repository.\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1801.07698"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@article{deng2018arcface,\ntitle={ArcFace: Additive Angular Margin Loss for Deep Face Recognition},\nauthor={Deng, Jiankang and Guo, Jia and Niannan, Xue and Zafeiriou, Stefanos},\njournal={arXiv:1801.07698},\nyear={2018}\n}\n\n@inproceedings{Najibi2017SSH,\n  title={SSH: Single Stage Headless Face Detector},\n  author={Najibi, Mahyar and Samangouei, Pouya and Chellappa, Rama and Davis, Larry S.},\n  booktitle={IEEE International Conference on Computer Vision},\n  year={2017},\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{Najibi2017SSH,\n  title={SSH: Single Stage Headless Face Detector},\n  author={Najibi, Mahyar and Samangouei, Pouya and Chellappa, Rama and Davis, Larry S.},\n  booktitle={IEEE International Conference on Computer Vision},\n  year={2017},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{deng2018arcface,\ntitle={ArcFace: Additive Angular Margin Loss for Deep Face Recognition},\nauthor={Deng, Jiankang and Guo, Jia and Niannan, Xue and Zafeiriou, Stefanos},\njournal={arXiv:1801.07698},\nyear={2018}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/deepinx/iqiyi-vid-challenge",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-02-18T03:45:55Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-06T12:28:55Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8782414527902468,
        0.9114009610024908
      ],
      "excerpt": "Recently www.iqiyi.com released a great video person dataset called IQIYI_VID and also launched a person search competition on it. It is a very large and real dataset worth trying to verify your face model accuracy precisely. \nThis repository contains the code for IQIYI-VID(IQIYI video person identification) Challenge. The methods are implemented in Python and MXNet. The Enhanced SSH (ESSH) from enhanced-ssh-mxnet is applied for face detection and alignment. Insightface scheme is used for face recognition. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code for IQIYI-VID(IQIYI Video Person Identification) Challenge Implemented in Python and MXNet",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/deepinx/iqiyi-vid-challenge/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 13,
      "date": "Wed, 08 Dec 2021 12:19:37 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/deepinx/iqiyi-vid-challenge/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "deepinx/iqiyi-vid-challenge",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1.  Prepare the environment.\n\n2.  Clone the repository.\n    \n3.  Type  `make`  to build necessary cxx libs.\n\n4.  Download the pre-trained model and place it in *`./model/`*\n\n5.  Download the IQIYI-VID Datasets from [IQIYI_VID](http://challenge.ai.iqiyi.com/detail?raceId=5afc36639689443e8f815f9e) and unzip them to `data/iqiyi_vid` directory. \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8310094638319588,
        0.9231861072284046,
        0.8837680365796365
      ],
      "excerpt": "Pre-trained models can be downloaded on BaiduCloud or GoogleDrive. \nThis repository has been tested under the following environment: \nPython 2.7  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/deepinx/iqiyi-vid-challenge/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C",
      "Cuda",
      "Makefile",
      "C++"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Code for IQIYI-VID Challenge based on ESSH and Insightface",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "iqiyi-vid-challenge",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "deepinx",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/deepinx/iqiyi-vid-challenge/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 44,
      "date": "Wed, 08 Dec 2021 12:19:37 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "face-detection",
      "face-alignment",
      "face-recognition",
      "mxnet"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1.  Detect faces on train+val dataset and test dataset respectively using ESSH model.  Model `model-r50-gg` is used to judge the quality of the detected faces.\n```\npython detect.py --model ./model/model-r50-gg/model,0 --output ./output/det_trainval --dataset ./data/iqiyi_vid --gpu 0 --stage trainval\npython detect.py --model ./model/model-r50-gg/model,0 --output ./output/det_test --dataset ./data/iqiyi_vid --gpu 0 --stage test\n```\n\n2. Extract features to the detected faces of train+val and test dataset respectively using `model-r100-gg` model.\n```\npython feature.py --model ./model/model-r100-gg/model,0 --input ./output/det_trainval --output ./output/feat_trainval  --gpu 0\npython feature.py --model ./model/model-r100-gg/model,0 --input ./output/det_test --output ./output/feat_test --gpu 0\n```\n3.  Re-save the extracted face features for training the MLP network.\n```\npython genfeat.py --inputs ./output/feat_trainval --output ./output/trainval\n```\n4. Train the MLP network for face ID recognition using train+val datasets.\n```\npython train_mlp.py --data ./output/trainval --prefix ./model/iqiyi --ckpt 1 --network r50 --lr 0.2 --per-batch-size 1024\n```\n5.  Predict face ID from features of the test dataset using the pre-trained MLP network.\n```\npython predict.py --model ./model/iqiyi,40 --gpu 0 --inputs ./output/feat_test --output ./output/pred_test\n```\n6. Run ``python submit.py`` to generate the final submissions for IQIYI-VID Challenge.\n\n",
      "technique": "Header extraction"
    }
  ]
}
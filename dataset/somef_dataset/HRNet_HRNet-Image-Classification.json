{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1904.04514"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] Deep High-Resolution Representation Learning for Visual Recognition. Jingdong Wang, Ke Sun, Tianheng Cheng, \n    Borui Jiang, Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, Wenyu Liu, Bin Xiao. Accepted by TPAMI.  [download](https://arxiv.org/pdf/1908.07919.pdf)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this work or code is helpful in your research, please cite:\n````\n@inproceedings{SunXLW19,\n  title={Deep High-Resolution Representation Learning for Human Pose Estimation},\n  author={Ke Sun and Bin Xiao and Dong Liu and Jingdong Wang},\n  booktitle={CVPR},\n  year={2019}\n}\n\n@article{WangSCJDZLMTWLX19,\n  title={Deep High-Resolution Representation Learning for Visual Recognition},\n  author={Jingdong Wang and Ke Sun and Tianheng Cheng and \n          Borui Jiang and Chaorui Deng and Yang Zhao and Dong Liu and Yadong Mu and \n          Mingkui Tan and Xinggang Wang and Wenyu Liu and Bin Xiao},\n  journal   = {TPAMI}\n  year={2019}\n}\n````\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{WangSCJDZLMTWLX19,\n  title={Deep High-Resolution Representation Learning for Visual Recognition},\n  author={Jingdong Wang and Ke Sun and Tianheng Cheng and \n          Borui Jiang and Chaorui Deng and Yang Zhao and Dong Liu and Yadong Mu and \n          Mingkui Tan and Xinggang Wang and Wenyu Liu and Bin Xiao},\n  journal   = {TPAMI}\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{SunXLW19,\n  title={Deep High-Resolution Representation Learning for Human Pose Estimation},\n  author={Ke Sun and Bin Xiao and Dong Liu and Jingdong Wang},\n  booktitle={CVPR},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9353051976633957
      ],
      "excerpt": "[2020/03/13] Our paper is accepted by TPAMI: Deep High-Resolution Representation Learning for Visual Recognition. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8334316807263773
      ],
      "excerpt": "| HRNet-W30-C | 37.7M | 7.55 | 21.8% | 5.8% |OneDrive/BaiduYun(Access Code:ajc1)| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9606712260438129
      ],
      "excerpt": "Human pose estimation \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/HRNet/HRNet-Image-Classification",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-10T06:41:39Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-08T07:34:35Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This is the official code of [high-resolution representations for ImageNet classification](https://arxiv.org/abs/1904.04514). \nWe augment the HRNet with a classification head shown in the figure below. First, the four-resolution feature maps are fed into a bottleneck and the number of output channels are increased to 128, 256, 512, and 1024, respectively. Then, we downsample the high-resolution representations by a 2-strided 3x3 convolution outputting 256 channels and add them to the representations of the second-high-resolution representations. This process is repeated two times to get 1024 channels over the small resolution. Last, we transform 1024 channels to 2048 channels through a 1x1 convolution, followed by a global average pooling operation. The output 2048-dimensional representation is fed into the classifier.\n\n![](figures/cls-hrnet.png)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9570636454608743,
        0.8457206412686356
      ],
      "excerpt": "[2020/03/13] Our paper is accepted by TPAMI: Deep High-Resolution Representation Learning for Visual Recognition. \nPer request, we provide two small HRNet models. #parameters and GFLOPs are similar to ResNet18. The segmentation resutls using the two small models are also available at https://github.com/HRNet/HRNet-Semantic-Segmentation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9045979605008851,
        0.9360260149718572
      ],
      "excerpt": "In the above Table, the first 2 checkpoints are trained with CosineLR, CutMix data augmentation and for longer epochs, i.e., 300epochs. The other two checkpoints are converted \nfrom PaddleClas. Please refer to SSLD tutorial for more details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8814657183921047
      ],
      "excerpt": "For example, train the HRNet-W18 on ImageNet with a batch size of 128 on 4 GPUs: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Train the HRNet model on ImageNet",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/HRNet/HRNet-Image-Classification/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 168,
      "date": "Wed, 08 Dec 2021 19:26:16 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/HRNet/HRNet-Image-Classification/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "HRNet/HRNet-Image-Classification",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can follow the Pytorch implementation:\nhttps://github.com/pytorch/examples/tree/master/imagenet\n\nThe data should be under ./data/imagenet/images/.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Install PyTorch=0.4.1 following the [official instructions](https://pytorch.org/)\n2. git clone https://github.com/HRNet/HRNet-Image-Classification\n3. Install dependencies: pip install -r requirements.txt\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8875423703415672
      ],
      "excerpt": "[2021/01/20] Add some stronger ImageNet pretrained models, e.g., the HRNet_W48_C_ssld_pretrained.pth achieved top-1 acc 83.6%. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8221123305238724
      ],
      "excerpt": "HRNetV2 ImageNet pretrained models are now available! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8654291654758604
      ],
      "excerpt": "For example, train the HRNet-W18 on ImageNet with a batch size of 128 on 4 GPUs: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9197138544944952,
        0.8095665736254976
      ],
      "excerpt": "python tools/train.py --cfg experiments/cls_hrnet_w18_sgd_lr5e-2_wd1e-4_bs32_x100.yaml \nFor example, test the HRNet-W18 on ImageNet on 4 GPUs: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8954973588296683
      ],
      "excerpt": "python tools/valid.py --cfg experiments/cls_hrnet_w18_sgd_lr5e-2_wd1e-4_bs32_x100.yaml --testModel hrnetv2_w18_imagenet_pretrained.pth \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/HRNet/HRNet-Image-Classification/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Microsoft Corporation\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "High-resolution networks (HRNets) for Image classification",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "HRNet-Image-Classification",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "HRNet",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/HRNet/HRNet-Image-Classification/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "PkuRainBow",
        "body": "+ HRNet_W18_C_ssld_pretrained.pth with Top-1 Acc 81.2% on ImageNet. \r\n+ HRNet_W48_C_ssld_pretrained.pth with Top-1 Acc 83.6% on ImageNet.\r\n+ HRNet_W18_C_cosinelr_cutmix_300epoch.pth.tar with Top-1 Acc 78% on ImageNet.\r\n+ HRNet_W48_C_cosinelr_cutmix_300epoch.pth.tar with Top-1 Acc 81.1% on ImageNet.\r\n+ HRNet-W18-C with Top-1 Acc 76.8% on ImageNet.\r\n+ HRNet-W48-C with Top-1 Acc 79.3% on ImageNet.",
        "dateCreated": "2020-03-26T04:10:54Z",
        "datePublished": "2021-01-20T01:33:43Z",
        "html_url": "https://github.com/HRNet/HRNet-Image-Classification/releases/tag/PretrainedWeights",
        "name": "Add ImageNet pretrained weights",
        "tag_name": "PretrainedWeights",
        "tarball_url": "https://api.github.com/repos/HRNet/HRNet-Image-Classification/tarball/PretrainedWeights",
        "url": "https://api.github.com/repos/HRNet/HRNet-Image-Classification/releases/36632017",
        "zipball_url": "https://api.github.com/repos/HRNet/HRNet-Image-Classification/zipball/PretrainedWeights"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 734,
      "date": "Wed, 08 Dec 2021 19:26:16 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "image-classification",
      "imagenet",
      "hrnets",
      "high-resolution-net"
    ],
    "technique": "GitHub API"
  }
}
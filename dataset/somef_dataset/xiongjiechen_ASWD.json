{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2006.08812",
      "https://arxiv.org/abs/1706.08500",
      "https://arxiv.org/abs/2006.08812",
      "https://arxiv.org/abs/2006.08812"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this code useful for your research, please cite our paper:\n```\n@article{chen2020augmented,\n    title={Augmented Sliced Wasserstein Distance},\n    author={Chen, Xiongjie and Yang, Yongxin and Li, Yunpeng},\n    journal={arXiv preprint arXiv:2006.08812},\n    year={2020}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{chen2020augmented,\n    title={Augmented Sliced Wasserstein Distance},\n    author={Chen, Xiongjie and Yang, Yongxin and Li, Yunpeng},\n    journal={arXiv preprint arXiv:2006.08812},\n    year={2020}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xiongjiechen/ASWD",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-22T22:25:17Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-09-02T15:39:42Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Two experiments are included in this repository, where benchmarks are from the paper [Generalized Sliced Wasserstein Distances](http://papers.nips.cc/paper/8319-generalized-sliced-wasserstein-distances) and the paper [Distributional Sliced-Wasserstein and Applications to Generative Modeling](https://arxiv.org/pdf/2002.07367.pdf), respectively. The first one is on the task of sliced Wasserstein flow, and the second one is on generative modellings with GANs. For more details and setups, please refer to the original paper **[Augmented Sliced Wasserstein Distances](https://arxiv.org/abs/2006.08812)**.\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9608344626122263
      ],
      "excerpt": "This repository provides the code to reproduce the experimental results in the paper Augmented Sliced Wasserstein Distances by Xiongjie Chen, Yongxin Yang and Yunpeng Li. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8535343518638301
      ],
      "excerpt": "Two datasets are used in this repository, namely the CIFAR10 dataset and CELEBA dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.898881066212001
      ],
      "excerpt": "To calculate the Fr\u00e9chet Inception Distance (FID score), precalculated statistics for datasets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.857599597826528,
        0.9356596286185364
      ],
      "excerpt": "- utils.py : contains implementations of different sliced-based Wasserstein distances. \n- TransformNet.py : edit this file to modify architectures of neural networks used to map samples.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8398053792837931,
        0.8420718266673336
      ],
      "excerpt": "- DCGANAE.py : neural network architectures and optimization objective for training GANs. \n- fid_score.py : functions for calculating statistics (mean & covariance matrix) of distributions of images and the FID score between two distributions of images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.910433064166383,
        0.9550574770024107,
        0.8299488375810373
      ],
      "excerpt": "--niter number of iteration, available for the ASWD, MSWD and DSWD, default as 5. \n--lam coefficient of regularization term, available for the ASWD and DSWD, default as 0.5. \n--r parameter in the circular defining function, available for GSWD, default as 1000. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9383221315665046
      ],
      "excerpt": "We conduct the sliced Wasserstein flow experiment on eight different datasets and the experimental results are presented in the following figure. The first and third columns in the figure below are target distributions. The second and fourth columns are log 2-Wasserstein distances between the target distribution and the source distribution. The horizontal axis show the number of training iterations. Solid lines and shaded areas represent the average values and 95% confidence intervals of log 2-Wasserstein distances over 50 runs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9774124120525532
      ],
      "excerpt": "The table below provides FID scores of generative models trained with different distance metrics. Lower scores indicate better image qualities. In what follows, *L* is the number of projections, we run each experiment 10 times and report the average values and standard errors of FID scores for CIFAR10 dataset and CELEBA dataset. The running time per training iteration for one batch containing 512 samples is computed based on a computer with an Intel (R) Xeon (R) Gold 5218 CPU 2.3 GHz and 16GB of RAM, and a RTX 6000 graphic card with 22GB memories. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.931476593257404
      ],
      "excerpt": "With *L*=1000 projections, the following figure shows the convergence rate of FID scores of generative models trained with different metrics on CIFAR10 and CELEBA datasets. The error bar represents the standard deviation of the FID scores at the specified training epoch among 10 simulation runs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9883185103623223,
        0.8201051770382274
      ],
      "excerpt": "The code of generative modelling example is based on the implementation of DSWD by VinAI Research. \nThe pytorch code for calculating the FID score is from https://github.com/mseitzer/pytorch-fid. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Augmented Sliced Wasserstein Distances",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xiongjiechen/ASWD/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Mon, 13 Dec 2021 16:17:14 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/xiongjiechen/ASWD/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "xiongjiechen/ASWD",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/xiongjiechen/ASWD/master/Sliced%20Waaserstein%20Flow.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9989972212380818,
        0.9979947896609701
      ],
      "excerpt": "To install the required python packages, run the following command: \npip install -r requirements.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9584505993919413
      ],
      "excerpt": "The pytorch code for calculating the FID score is from https://github.com/mseitzer/pytorch-fid. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8114508465543033
      ],
      "excerpt": "CIFAR 10 (calculated on all training samples) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8035586247279871
      ],
      "excerpt": "./result/CIFAR/ model's weights and losses in the CIFAR10 experiment are stored in this directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8957058170296036
      ],
      "excerpt": "- main.py : run this file to conduct experiments. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/xiongjiechen/ASWD/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 xiongjiechen\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Augmented-Sliced-Wasserstein-Distances",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ASWD",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "xiongjiechen",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xiongjiechen/ASWD/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Mon, 13 Dec 2021 16:17:14 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The generative modelling experiment evaluates the performances of GANs trained with different sliced-based Wasserstein metrics. To train and evaluate the model, run the following command:\n\n```\npython main.py  --model-type ASWD --dataset CIFAR --epochs 200 --num-projection 1000 --batch-size 512 --lr 0.0005\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[image1]: ./examples/car_not_car.png\n[image2]: ./examples/hog_1.png\n[image2-1]: ./examples/hog_2.png\n[image3]: ./examples/search_windows.png\n[image4]: ./examples/heat_map1.png\n[image5]: ./examples/heat_map2.png\n[image6]: ./examples/labels_map.png\n[image7]: ./examples/svn_1.png\n[image8]: ./examples/yolo_1.png\n[image_yolo1]: ./examples/yolo1.png\n[image_yolo2]: ./examples/yolo2.png\n[video1]: ./project_video.mp4\n[demo1_gif]: ./examples/demo1.gif\n[demo2_gif]: ./examples/demo2.gif\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9499963145257574
      ],
      "excerpt": "Date 18 April 2017 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8824264439431111
      ],
      "excerpt": "Date 31 March 2017 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8586718319963604
      ],
      "excerpt": " KITTI vision benchmark suite. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "spatial_size = (32, 32) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JunshengFu/vehicle-detection",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-03-21T03:18:13Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-08T03:58:22Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9577528736504057,
        0.842209437904578
      ],
      "excerpt": "Others are the same as in the repository of Lane Departure Warning System: \n* calibration.py contains the script to calibrate camera and save the calibration results \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8329877426589312
      ],
      "excerpt": "svm_pipeline.py contains the code for the svm pipeline. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9215238182924667,
        0.8879600080362582
      ],
      "excerpt": "A color transform is applied to the image and append binned color features, as well as histograms of color, to HOG feature vector.  \nNormalize your features and randomize a selection for training and testing. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8086069284241176
      ],
      "excerpt": "Run pipeline on a video stream and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9134009770073415
      ],
      "excerpt": "The code for this step is contained in the function named extract_features and codes from line 464 to 552 in svm_pipeline.py.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9141596023524886
      ],
      "excerpt": "Otherwise, I started by reading in all the vehicle and non-vehicle images, around 8000 images in each category.  These datasets are comprised of  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9744064109092886
      ],
      "excerpt": " Here is an example of one of each of the vehicle and non-vehicle classes: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9663042960371602
      ],
      "excerpt": "Here is an example using the RGB color space and HOG parameters of orientations=9, pixels_per_cell=(8, 8) and cells_per_block=(2, 2): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8650384844485381,
        0.824081875942428,
        0.8291660437792333
      ],
      "excerpt": "To optimize the HoG extraction, I extract the HoG feature for the entire image only once. Then the entire HoG image \nis saved for further processing. (see line 319 to 321 in  svm_pipeline.py) \nI tried various combinations of parameters and choose the final combination as follows  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8009512079859675
      ],
      "excerpt": "hog_channel = \"ALL\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9101319048027565,
        0.9356889357080969,
        0.9143034387199757
      ],
      "excerpt": "All the features are normalized by line 511 to 513 in svm_pipeline.py, which is a critical step. Otherwise, classifier  \nmay have some bias toward to the features with higher weights. \nI randomly select 20% of images for testing and others for training, and a linear SVM is used as classifier (see line \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.907352577924278
      ],
      "excerpt": "For this SVM-based approach, I use two scales of the search window (64x64 and 128x128, see line 41) and search only between  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9563884084044394
      ],
      "excerpt": "For every window, the SVM classifier is used to predict whether it contains a car nor not. If yes, save this window (see  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9058015021323403
      ],
      "excerpt": "svm_pipeline.py) is used to generate a heatmap. Then a threshold is used to filter out the false positives. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9388864161194651
      ],
      "excerpt": "For video, we could further utilize neighbouring frames to filter out the false positives, as well as to smooth  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8329877426589312,
        0.8814971141432716
      ],
      "excerpt": "yolo_pipeline.py contains the code for the yolo pipeline.  \nYOLO is an object detection pipeline baesd on Neural Network. Contrast to prior work on object detection with classifiers  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8646121070185229
      ],
      "excerpt": "* threshold the resulting detections by the model\u2019s confidence \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9769615057404729,
        0.9130045732252544,
        0.9720623528700881,
        0.9086753450101367,
        0.9028820678871754,
        0.9090767213765755,
        0.9737612115972004,
        0.9934966343818902,
        0.9033980645679112,
        0.9267025282317043
      ],
      "excerpt": "yolo_pipeline.py is modified and integrated based on this tensorflow implementation of YOLO. \nSince the \"car\" is known to YOLO, I use the precomputed weights directly and apply to the entire input frame. \nFor the SVM based approach, the accuray is good, but the speed (2 fps) is an problem due to the fact of sliding window approach  \nis time consuming! We could use image downsampling, multi-threads, or GPU processing to improve the speed. But, there are probably \na lot engineering work need to be done to make it running real-time. Also, in this application, I limit the vertical searching  \nrange to control the number of searching windows, as well as avoid some false positives (e.g. cars on the tree). \nFor YOLO based approach, it achieves real-time and the accuracy are quite satisfactory. Only in some cases, it may failure to \n detect the small car thumbnail in distance. My intuition is that the original input image is in resolution of 1280x720, and it needs to be downscaled \n to 448x448, so the car in distance will be tiny and probably quite distorted in the downscaled image (448x448). In order to  \n correctly identify the car in distance, we might need to either crop the image instead of directly downscaling it, or retrain  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Created vehicle detection pipeline with two approaches: (1) deep neural networks (YOLO framework) and (2) support vector machines ( OpenCV + HOG).",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JunshengFu/vehicle-detection/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 230,
      "date": "Fri, 10 Dec 2021 18:44:53 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/JunshengFu/vehicle-detection/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "JunshengFu/vehicle-detection",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8409505396488579
      ],
      "excerpt": "* examples folder contains the sample images and videos \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][image1] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749,
        0.8359299706379749
      ],
      "excerpt": "![alt text][image2] \n![alt text][image2-1] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8497400287400448
      ],
      "excerpt": "(see line 16-27 in svm_pipeline.py): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984,
        0.8594142235991984,
        0.8594142235991984
      ],
      "excerpt": "spatial_feat = True \nhist_feat = True \nhog_feat = True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8622815661018643
      ],
      "excerpt": "520 to 531 in svm_pipeline.py) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9264766893637243
      ],
      "excerpt": "line 314 in svm_pipeline.py).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][image3] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][image_yolo2] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][image_yolo1] \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/JunshengFu/vehicle-detection/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "GNU General Public License v3.0",
      "url": "https://api.github.com/licenses/gpl-3.0"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "**Vehicle Detection for Autonomous Driving**",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "vehicle-detection",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "JunshengFu",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JunshengFu/vehicle-detection/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Anaconda is used for managing my [**dependencies**](https://github.com/udacity/CarND-Term1-Starter-Kit).\n* You can use provided [environment-gpu.yml](environment-gpu.yml) to install the dependencies.\n* OpenCV3, Python3.5, tensorflow, CUDA8  \n* OS: Ubuntu 16.04\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "(1) Download weights for YOLO\n\nYou can download the weight from [here](https://drive.google.com/open?id=0B5WIzrIVeL0WS3N2VklTVmstelE) and save it to\nthe [weights](weights) folder.\n\n(2) If you want to run the demo, you can simply run:\n```sh\npython main.py\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 493,
      "date": "Fri, 10 Dec 2021 18:44:53 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "vehicle-detection",
      "svm",
      "yolov1"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "![alt text][image7]\n\n---\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "![alt text][image8]\n\n---\n\n",
      "technique": "Header extraction"
    }
  ]
}
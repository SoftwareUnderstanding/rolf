{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<a id=\"1\">[1]</a>\nRonneberger, O., Fischer, P., & Brox, T. (2015).\nU-Net: Convolutional Networks for Biomedical Image Segmentation.\nMICCAI.\n\n<a id=\"1\">[2]</a>\nIgnacio Arganda-Carreras, Srinivas C. Turaga, Daniel R. Berger, Dan Ciresan, Alessandro Giusti, Luca M. Gambardella, J\u00fcrgen Schmidhuber, Dmtry Laptev, Sarversh Dwivedi, Joachim M. Buhmann, Ting Liu, Mojtaba Seyedhosseini, Tolga Tasdizen, Lee Kamentsky, Radim Burget, Vaclav Uher, Xiao Tan, Chanming Sun, Tuan D. Pham, Eran Bas, Mustafa G. Uzunbas, Albert Cardona, Johannes Schindelin, and H. Sebastian Seung.\nCrowdsourcing the creation of image segmentation algorithms for connectomics.\nFrontiers in Neuroanatomy, vol. 9, no. 142, 2015.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.923281454680061
      ],
      "excerpt": "\"U-Net: Convolutional Networks for Biomedical Image Segmentation\" by Olaf Ronneberger, Philipp Fischer, and Thomas Brox (2015) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hayashimasa/UNet-PyTorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-12-09T13:16:23Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-09T12:48:18Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "U-Net is a fully convolutional neural network with an encoder-decoder structure designed for sementic image segmantation on biomedical images. [[1]](#1) It is a very effective meta-network architecture that has been adapted to incorporate other convolutional neural network architecture designs.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9620250056770464
      ],
      "excerpt": "This is a PyTorch implementation of the U-Net architecture. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8709158920396153,
        0.9752357104229649,
        0.9194066326038668,
        0.9830851027869347,
        0.9788656858065087,
        0.9337760357732157,
        0.9918983469328955
      ],
      "excerpt": "Use ResNet or other CNN architectures as encoder/decoder \nThe data is from the 2012 ISBI challenge for segmentation of neuronal structures in electron microscopic stack. It is the same dataset used in the original paper. \nThe training data is a set of 30 sections from a serial section Transmission Electron Microscopy (ssTEM) dataset of the Drosophila first instar larva ventral nerve cord (VNC). The microcube measures 2 x 2 x 1.5 microns approx., with a resolution of 4x4x50 nm/pixel.[2] Each image has 512x512 pixels. \nThe corresponding binary labels are provided in an in-out fashion, i.e. white for the pixels of segmented objects and black for the rest of pixels (which correspond mostly to membranes). \nThe network has a symmetric encoder-decoder structure. Images are first downsampled through a series of convolutional blocks consists of convolutional, non-linear activation, and max-pooling layers. The downsampled featured map is then symmetrically upsampled by a series of transposed convolutions in order to obatin a high resolution feature map that is close to the size of the original images. The most interesting feature of the architecture is the concatenation of high resolution feature maps from the contracting path and the corresponding upsampled feature maps from the expanding path. This design allows the network to leverage both high and low resolution information to learn the structure of the image. In order to increase efficiency and flexibility, a convolutional layer instead of a fully connected layer is used to output the final prediction. Each convolutional filter corresponding to an object classes. \nThe implementation of the network architecture is in unet.py. \nData are scarced in the field of medical imaging (only 30 supervised image in this dataset); however, neural networks often rely on a large amount of supervised data to obtain good results; therefore, data augmentation is heavily utilized. The author suggests not only the typical affine transformation such as translation, rotation, and cropping, but also the use of elastic deformation. Deformation is a widely adopted technique for biomedical image segmentation tasks, since objects like cells and organs often have non-rigid structures. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.991604919598072,
        0.9649273009246748,
        0.8339816065115904
      ],
      "excerpt": "During training, all augmentations are chosen stochastically; for each image and label, the augmentation is a composite of different combinations of transformations. For elastic deformation, the alpha parameter is chosen between 100-300, and the sigma parameter is chosen between 10-15. \nThe implementation of various data augmentation methods is in augmentation.py. \nSince this is a segmentic segmentation task, a pixel-loss is calculated through a softmax function combined with cross entropy over the final feature map. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.92717848919159
      ],
      "excerpt": "A vectorized implementation of the weighted function is in celldata.py. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8560746385148243
      ],
      "excerpt": "                        number of workers to load data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9263994397942544
      ],
      "excerpt": "  --model MODEL         model to retrain \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9035090407320232
      ],
      "excerpt": "The model was trained on 90% of the training data (27 images) and tested on 10% of the data (3 images) with the following hyperparameters: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9739457504751274
      ],
      "excerpt": "IOU and training loss stagnate after roughly 30 epochs, and model reaches peak test performance at the 33rd epoch. Different batch sizes and learning rates were experimented to train the model for up to 50 more epochs, which is a total of 100 epochs. Training loss decreases but doesn't yield any improvement in segmentation performance; the model is likely overtraining. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "\u251c\u2500\u2500 data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "PyTorch implementation of the U-Net architecture",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hayashimasa/UNet-PyTorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 09 Dec 2021 19:07:54 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hayashimasa/UNet-PyTorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "hayashimasa/UNet-PyTorch",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8050101163534564
      ],
      "excerpt": "Include sample images for data augmentation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9372484191755237
      ],
      "excerpt": "python train.py --epoch 50 --batch-size 3 --save \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8475740828080995,
        0.879514810073631,
        0.802212722025675
      ],
      "excerpt": "  --batch-size N        input batch size for training (default: 3) \n  --test-batch-size N   input batch size for testing (default: 3) \n  --epochs N            number of epochs to train (default: 10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8229774869411682
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 train-labels.tif \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9336801098518991,
        0.9336801098518991,
        0.950563948951535,
        0.8096560770562421,
        0.9336801098518991
      ],
      "excerpt": "\u251c\u2500\u2500 celldata.py \n\u251c\u2500\u2500 augmentation.py \n\u251c\u2500\u2500 unet.py \n\u251c\u2500\u2500 train.py \n\u251c\u2500\u2500 loss.py \n\u251c\u2500\u2500 metric.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hayashimasa/UNet-PyTorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Masahiro Hayashi\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "UNet-PyTorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "UNet-PyTorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "hayashimasa",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hayashimasa/UNet-PyTorch/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Thu, 09 Dec 2021 19:07:54 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "medical-imaging",
      "image-segmentation",
      "pytorch",
      "convolutional-neural-networks"
    ],
    "technique": "GitHub API"
  }
}
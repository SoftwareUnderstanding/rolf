{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1810.04805",
      "https://arxiv.org/abs/1810.04805. [online](https://arxiv.org/abs/1810.04805)\n- Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, \u0141. and Polosukhin, I., 2017. Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008). [online](https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)\n- Olah, C. 2015. Understanding LSTM Networks. [online](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n- Ng, A. 2019. The EM algorithm. CS229, Lecture Notes [online](https://see.stanford.edu/materials/aimlcs229/cs229-notes8.pdf)\n- Griffiths, M. and Steyvers. 2004. Finding Scientific topics [online](https://www.pnas.org/content/pnas/101/suppl_1/5228.full.pdf)\n- Blei, D. 2012. Probabilistic Topic Models [online](http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf)\n- Rocca, J. 2019. Understanding Variational Autoencoders [online](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73).\n\nThe literature list might change slightly during the course.\n\n### Video material\n\n- Chen, T. (2016) XGBoost: A scalable Tree Boosting System  [online](https://www.youtube.com/watch?v=Vly8xGnNiWs)\n- ISLV: Hastie and Tibshirani, Introduction to Statistical Learning (Video material) [online access](http://auapps.american.edu/alberto/www/analytics/ISLRLectures.html)\n- 3B1B: Three Blue One Brown on Neural Networks [online access](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)\n- Dirac, L. (2019) LSTM is dead! Long live Transformers. [online access](https://www.youtube.com/watch?v=S27pHKBEp30) \n- Ng, Andrew (2017) One convolutional layer. [online access](https://www.youtube.com/watch?v=jPOAS7uCODQ&list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&index=7) \n- Hand, Paul, Variational Autoencoders [online](https://www.youtube.com/watch?app=desktop&v=c27SHdQr4lw)\n\n## Recommended workflow for each block/assignment\n\n1. Read the literature according to the rough course plan\n2. Watch the videos to get more indepth knowledge/understanding (however, optional)\n3. Do the assignment\n\n## Course practicalities\n\nOnline course discussions will be held through Slack. See Studium for details on how to log in.\n\n### Location\n\nThe course will have 1-2 guest lectures that the guest lecturers will give through Zoom. Otherwise, the course will be held on campus. You can find information and support for students on Zoom [here](https://mp.uu.se/c/perm/link?p=267521030). \n\n## Teachers\n\nMain Teacher: M\u00e5ns Magnusson\nTeaching assistant: Andreas \u00d6stling\n\n## Course structure\n\n### Main part\nThe course consists of rougly 8 blocks (weeks) of material. Each week consists of the following (expected workload in parenthesis):\n- Two lectures/computer labs (approx. 2-4h per week)\n- Online video material and reading assignments (approx. 2-6 h per week)\n- An individual computer assignment (approx. 10-16 h per week)\n\n### Computer assignments\nEach week an individual computer assignment is done with a focus on implementing the main part of the material. Each assignment is completed individually and should follow the computer assignment template.\n\nStudents should return the computer assignments no later than **Sunday 23.59 each week**. A second possibility to turn in assignments is possible at the end of the course. For a detailed list of deadlines, see the [rough course plan](https://docs.google.com/spreadsheets/d/1HC_QN2mCq9bkCPzmkP8RaR3RokFQCWo9oPuU7rFyR8Y/edit?usp=sharing).\n\nAfter the last (second) possible time to turn in the assignment no more chances will be given. In this case, you will be failed on the course and you will need to retake the course next year.\n\nEach assignment will be graded and evaluated within 10 working days.\n\n### Machine Learning, AI and ethics\nA guest lecture will be given on AI and ethics by [Karim Jebari](https://www.iffs.se/en/research/researchers/karim-jebari/).\n\n## Course Project\nThe last two weeks will focus on a course project where 2-3 students choose their data and create a supervised machine learning predictor for a real-world dataset. \n\nYou can find details and instructions on the project work [here](https://github.com/MansMeg/IntroML/blob/master/project/).\n\n\n## Frequently Asked Questions (FAQ)\n\nFrequently asked questions will be collected [here](https://github.com/MansMeg/IntroML/blob/master/FAQ.md).\n"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9665271888223802,
        0.808388904359395
      ],
      "excerpt": "DL: Goodfellow, Ian, Bengio, Yoshua, and Courville, Aaron. Deep learning. MIT Press, 2017. online access \nDLR: Chollet, Fran\u00e7ois, and Joseph J. Allaire. Deep Learning with R. Manning, 2018.  online access \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9615443569623978,
        0.9966202487036179
      ],
      "excerpt": "Efron, B. (2020). Prediction, Estimation, and Attribution. Journal of the American Statistical Association, 115(530), 636-655. online access \nSalganik, M. J. et al. Measuring the predictability of life outcomes with a scientific mass collaboration. Proceedings of the National Academy of Sciences Apr 2020, 117 (15) 8398-8403; DOI: 10.1073/pnas.1915006117 online access \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999614081057138
      ],
      "excerpt": "Devlin, J., Chang, M.W., Lee, K. and Toutanova, K., 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805. online \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8990000916808355
      ],
      "excerpt": "Griffiths, M. and Steyvers. 2004. Finding Scientific topics online \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8824264439431111
      ],
      "excerpt": "Rocca, J. 2019. Understanding Variational Autoencoders online. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8866976106892408
      ],
      "excerpt": "Chen, T. (2016) XGBoost: A scalable Tree Boosting System  online \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MansMeg/IntroML",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-20T08:28:53Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-11T13:09:18Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Welcome to the GitHub repo for the introduction course in Introduction to Machine Learning at Uppsala University. This repo contains all necessary material and information for the course.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9300700705727871,
        0.9144820753502902,
        0.991746046396862,
        0.8550760759682854,
        0.9610545499024538,
        0.8441517241081807,
        0.8909624495378389,
        0.9520975768252695
      ],
      "excerpt": "The course is graded with U (Underk\u00e4nd/Fail), G (Godk\u00e4nd/Pass), VG (v\u00e4l godk\u00e4nd/Pass with distinction). \nTo pass, you should pass all assignments and the mini-project.  \nTo get the grade VG on the course, a total of 7 or more VG points is needed. Each assignment has an additional task to complete to get VG on the assignment (and one VG-point). If the final mini-project gets VG, the students are awarded 2 VG points for the mini-project. \nBelow are the main references for the course. All books are available free online. Some articles may need access from an Uppsala University network. \nESL: Hastie, Trevor, Tibshirani, Robert, and Friedman, Jerome. The elements of statistical learning: data mining, inference, and prediction. 2nd Edition. Springer Science & Business Media, 2009. online access \nDL: Goodfellow, Ian, Bengio, Yoshua, and Courville, Aaron. Deep learning. MIT Press, 2017. online access \nDLR: Chollet, Fran\u00e7ois, and Joseph J. Allaire. Deep Learning with R. Manning, 2018.  online access \nSutton, R. S., and Barto, A. G. Reinforcement learning: An introduction. MIT Press, 2020. online access \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8480339684685347,
        0.9320621035718049
      ],
      "excerpt": "Efron, B. (2020). Prediction, Estimation, and Attribution. Journal of the American Statistical Association, 115(530), 636-655. online access \nSalganik, M. J. et al. Measuring the predictability of life outcomes with a scientific mass collaboration. Proceedings of the National Academy of Sciences Apr 2020, 117 (15) 8398-8403; DOI: 10.1073/pnas.1915006117 online access \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9345227386912134,
        0.878217309152082
      ],
      "excerpt": "Kingma DP and Welling M. An Introduction to Variational Autoencoders, 2019. online access \nSmyth, P. The EM algorithm for Gaussian Mixtures, 2020. online access \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8504570551313989
      ],
      "excerpt": "Alamar, J. The illustrated BERT, Elmo, and co. (How NLP Cracked Transfer Learning), 2018c. online \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9002362734247958
      ],
      "excerpt": "ISLV: Hastie and Tibshirani, Introduction to Statistical Learning (Video material) online access \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8560003582473337
      ],
      "excerpt": "Online course discussions will be held through Slack. See Studium for details on how to log in. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9110542565955906
      ],
      "excerpt": "The course consists of rougly 8 blocks (weeks) of material. Each week consists of the following (expected workload in parenthesis): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8973678517165966,
        0.9614317605576228
      ],
      "excerpt": "Each week an individual computer assignment is done with a focus on implementing the main part of the material. Each assignment is completed individually and should follow the computer assignment template. \nStudents should return the computer assignments no later than Sunday 23.59 each week. A second possibility to turn in assignments is possible at the end of the course. For a detailed list of deadlines, see the rough course plan. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Introductory course in Machine Learning for master students in Statistics at Uppsala University",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MansMeg/IntroML/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Frequently asked questions will be collected [here](https://github.com/MansMeg/IntroML/blob/master/FAQ.md).\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Sun, 12 Dec 2021 16:38:15 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/MansMeg/IntroML/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "MansMeg/IntroML",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/MansMeg/IntroML/master/additional_material/colab_nb/RandTensorFlow.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8775333476306468,
        0.8233959669338244
      ],
      "excerpt": "You can find a rough course plan with reading instructions here. \nYou can find the course schedule on TimeEdit here (search for course code 2ST122). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8615767515483386
      ],
      "excerpt": "Watch the videos to get more indepth knowledge/understanding (however, optional) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8142835995138061
      ],
      "excerpt": "Main Teacher: M\u00e5ns Magnusson \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/MansMeg/IntroML/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "TeX",
      "Jupyter Notebook",
      "R",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'YEAR: 2020\\nCOPYRIGHT HOLDER: Mans Magnusson\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Introduction Course in Machine Learning at Uppsala University",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "IntroML",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "MansMeg",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MansMeg/IntroML/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "See course syllabus [here](https://www.uu.se/en/admissions/freestanding-courses/course-syllabus/?kpid=39843&type=1).\n\nRoughly the course assumes basic knowledge in linear algebra, calculus, probability theory and programming (with R or Python).\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Sun, 12 Dec 2021 16:38:15 GMT"
    },
    "technique": "GitHub API"
  }
}
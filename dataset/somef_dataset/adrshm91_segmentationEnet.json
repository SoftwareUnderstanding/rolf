{
  "citation": [
    {
      "confidence": [
        0.8821219420838257,
        0.8143453088594287
      ],
      "excerpt": "TensorFlow implementation of ENet (https://arxiv.org/pdf/1606.02147.pdf) based on the official Torch implementation (https://github.com/e-lab/ENet-training) and the Keras implementation by PavlosMelissinos (https://github.com/PavlosMelissinos/enet-keras), trained on the Cityscapes dataset (https://www.cityscapes-dataset.com/). \nYoutube video of results (https://youtu.be/HbPhvct5kvs): \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/adrshm91/segmentationEnet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-29T10:30:29Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-30T13:43:09Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9136008093039311
      ],
      "excerpt": "For all other hyperparameters I used the same values as in the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9710324568256126,
        0.9068188630071268
      ],
      "excerpt": "The results in the video above was obtained with the model at epoch 23, for which a checkpoint is included in segmentation/training_logs/best_model in the repo. \nTo train the model, I used an NC6 virtual machine on Microsoft Azure. Below I have listed what I needed to do in order to get started, and some things I found useful. For reference, my username was 'fregu856': \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490037945672047
      ],
      "excerpt": "Reboot the VM \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9177688444941141
      ],
      "excerpt": "To commit changes to the image: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8995641295601214
      ],
      "excerpt": "To stop the image when it\u2019s running: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.826071389507188
      ],
      "excerpt": "To get back into a running image: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8178605607419503
      ],
      "excerpt": "To open more than one terminal window at the same time: \n",
      "technique": "Supervised classification"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "preprocess_data.py:  \n- ASSUMES: that all Cityscapes training (validation) image directories have been placed in data_dir/cityscapes/leftImg8bit/train (data_dir/cityscapes/leftImg8bit/val) and that all corresponding ground truth directories have been placed in data_dir/cityscapes/gtFine/train (data_dir/cityscapes/gtFine/val).\n- DOES: script for performing all necessary preprocessing of images and labels.\n*****\n\nmodel.py:  \n- ASSUMES: that preprocess_data.py has already been run.\n- DOES: contains the ENet_model class.\n*****\n\nutilities.py:  \n- ASSUMES: -\n- DOES: contains a number of functions used in different parts of the project.\n*****\n\ntrain.py:  \n- ASSUMES: that preprocess_data.py has already been run.\n- DOES: script for training the model.\n*****\n\nrun_on_sequence.py:  \n- ASSUMES: that preprocess_data.py has already been run.\n- DOES: runs a model checkpoint (set in line 56) on all frames in a Cityscapes demo sequence directory (set in line 30) and creates a video of the result.\n\n****\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/adrshm91/segmentationEnet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sat, 11 Dec 2021 01:49:09 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/adrshm91/segmentationEnet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "adrshm91/segmentationEnet",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/adrshm91/segmentationEnet/master/Run_me_on_colab.ipynb",
      "https://raw.githubusercontent.com/adrshm91/segmentationEnet/master/preprocess_data.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8096422022825122
      ],
      "excerpt": "- Download Cityscapes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8621525162395621,
        0.8433789804981825,
        0.9623668047804587,
        0.9278465188028105,
        0.9824821683147638,
        0.8547792722058898
      ],
      "excerpt": "$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - \n$ sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" \n$ sudo apt-get update \n$ sudo apt-get install -y docker-ce \nInstall CUDA drivers (see \"Install CUDA drivers for NC VMs\" in https://docs.microsoft.com/en-us/azure/virtual-machines/linux/n-series-driver-setup): \n$ CUDA_REPO_PKG=cuda-repo-ubuntu1604_8.0.61-1_amd64.deb \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9623668047804587,
        0.9897130673766528
      ],
      "excerpt": "$ sudo apt-get update \n$ sudo apt-get install cuda-drivers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "        --name \"$NAME\"\"$GPUIDS\" \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.933885153911117
      ],
      "excerpt": "        tensorflow/tensorflow:latest-gpu bash \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.904495155159127
      ],
      "excerpt": "/root/ will now be mapped to /home/fregu856 (i.e., $ cd -- takes you to the regular home folder).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9321456973716636
      ],
      "excerpt": "$ sudo sh start_docker_image.sh  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233038266765852
      ],
      "excerpt": "Open a new terminal window. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9094208962649689
      ],
      "excerpt": "To open more than one terminal window at the same time: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.810870454768102
      ],
      "excerpt": "- Download Cityscapes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "        --name \"$NAME\"\"$GPUIDS\" \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/adrshm91/segmentationEnet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Fredrik Gustafsson\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "segmentation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "segmentationEnet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "adrshm91",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/adrshm91/segmentationEnet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 11 Dec 2021 01:49:09 GMT"
    },
    "technique": "GitHub API"
  }
}
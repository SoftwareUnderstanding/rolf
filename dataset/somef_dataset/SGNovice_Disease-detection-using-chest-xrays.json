{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "https://arxiv.org/pdf/1705.02315.pdf\n\nhttp://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.pdf\n\nhttps://www.kaggle.com/ingusterbets/nih-chest-x-rays-analysis\n\nhttps://github.com/digantamisra98/Mila\n\nhttps://github.com/digantamisra98/Beta-Mish\n\nhttps://nihcc.app.box.com/v/ChestXray-NIHCC/folder/37178474737\n\nhttps://nihcc.app.box.com/v/ChestXray-NIHCC/file/219760887468\n\nhttps://link.springer.com/chapter/10.1007/978-3-540-75402-2_4\n\nhttps://openreview.net/pdf?id=rkBBChjiG\n\nhttps://arxiv.org/pdf/1711.05225\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9423520739005966
      ],
      "excerpt": "Project Repository Link --> https://github.com/SGNovice/Disease-detection-using-chest-xrays/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "natural language processing. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9105368110547479,
        0.9105368110547479,
        0.9105368110547479,
        0.9105368110547479,
        0.9105368110547479,
        0.9105368110547479,
        0.9626356225854676,
        0.9105368110547479,
        0.9105368110547479,
        0.9105368110547479
      ],
      "excerpt": "Victor Mawusi Ayi | https://github.com/ayivima \nAnju Mercian | https://github.com/amalphonse \nGeorge Christopoulos | https://github.com/geochri \nAshish Bairwa  | https://github.com/ashishbairwa \nPooja Vinod | https://github.com/poojavinod100  \nIngus Terbets | https://github.com/ingus-t \nAlexander Villasoto | https://github.com/anvillasoto \nOlivia Milgrom | https://github.com/OliviaMil \nTuan Hung Truong | https://github.com/tuanhung94 \nMarwa Qabeel | https://github.com/MarwaQabeel \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/SGNovice/Disease-detection-using-chest-xrays/master/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SGNovice/Disease-detection-using-chest-xrays",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-08-19T14:37:58Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-20T17:49:30Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Deep learning, also known as hierarchical learning or deep structured learning, \nis a type of machine learning that uses a layered algorithmic architecture to analyze data. \nUnlike other types of machine learning, deep learning has an added advantage of being able to make decisions with \nsignificantly less human intervention. While basic machine learning requires a programmer to identify whether a conclusion \nis correct or not, deep learning can gauge the accuracy of its answers on its own due to the nature of its multi-layered structure. \nThe emergence of modern frameworks like PyTorch, has also made preprocessing of data more convenient. \nMany of the filtering and normalization tasks that would involve a lot of manual tasks while\nusing other machine learning techniques, are taken up automatically.\n\nThe essential characteristics of deep learning make it an ideal tool for giving the much needed impetus, \nto the field of automated medical diagnosis. With the right expertise, it can be leveraged to overcome several \nlimitations of conventional diagnosis done by medical practitioners, and take the dream of accurate and efficient \nautomated disease diagnosis to the realm of reality.\n\nGiven the team's vision to make healthcare better for everyone, everywhere, and having paid attention to the trends and \nrecent breakthroughs with deep learning, we decided to experiment with several variations of convolutional neural networks for this project. \nRecent work has shown that convolutional networks can be substantially deeper, more accurate, \nand efficient to train if they contain shorter connections between layers close to the input and output. \nWe embraced this observation, and leveraged the power of the Dense Convolutional Network (DenseNet), \nwhich connects each layer to every other layer in a feed-forward fashion. \nWhereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - \nour network had L(L+1)/2 direct connections. We also experimented with other architectures, including residual networks, and used our \nmodel variations as controls to validate each other.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8567202184387864
      ],
      "excerpt": "The project utilizes a new chest X-ray database, namely \u201cChestX-ray8\u201d, to build a lung disease detection system. The ChestX-ray8 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9181718624797318,
        0.973263308361108,
        0.8231425889904066
      ],
      "excerpt": "Chest X-Rays are considerably reliable radiobiological imprints of patients, which are widely used to diagnose an array  \nof common diseases affecting organs within the chest. For too long, vast accumulations of image data and their  \nassociated diagnoses have been stored in the Picture Archiving and Communication Systems (PACS) of several hospitals and  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9741326627271939,
        0.9702506925644693,
        0.8576231635414021,
        0.9670704016243915,
        0.9496901877505017,
        0.8541331282930223,
        0.8850674581475502,
        0.9260496084645155,
        0.9431820001321105,
        0.8842770311994508
      ],
      "excerpt": "Meanwhile, data-hungry deep learning systems lie in wait of voluminous databases like these,  \nat the cusp of fulfilling the promise of automated and accurate disease diagnosis.  \nThrough this project, we hope to unite one such vast database, the \u201cChestX-ray8\" dataset,  \nwith a powerful deep Learning system, and automate the diagnosis of 14 common lung conditions.  \nFor this project phase, we focus on detecting three conditions -  \nCardiomegaly, Effusion, Emphysema - in addition to healthy states. \nAmong the several benefits artificial intelligence promises to bring to healthcare, these are worth highlighting. \n  * More affordable treatment: Diagnosis is faster and more accurate with automation; doctors will be able  \n  to recommend the right treatments to patients or intervene appropriately before illnesses aggravate leading to more expensive treatment options. \n  * Safer solutions: More accurate diagnosis means there will be a lower risk of complications associated with  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.935080189995348,
        0.8137776351207737,
        0.8596610439356027,
        0.8745408362035663,
        0.9340748236120984,
        0.9328051638898041,
        0.9685464150343701,
        0.980657044234984,
        0.9515539667641197,
        0.9528944155321875,
        0.9231002570044716,
        0.9775465807243171,
        0.9350233634326781,
        0.902400044318176,
        0.9903271471884852,
        0.9976385278790401
      ],
      "excerpt": "  * More patients treated: A reduction in the time it takes to complete a diagnostic analyses means  \n  laboratories can perform more tests. This will lead to coverage for more patients within shorter duration.  \n  * Addressing the global \u2018Physician Shortage\u2019: The growing deficit between the demand for physicians and the supply, has  \n  been a growing concern for many countries around the world. The World Health Organization (WHO) estimates that there is  \n  a global shortage of 4.3 million physicians, nurses, and other health professionals.  \n  The shortage is often starkest in developing nations due to the limited numbers and  \n  capacity of medical schools in these countries. Additionally, these nations have many more rural and remote areas,  \n  which complicates the issue with other challenges like lack of good transportation. The growing need for more qualified  \n  medical personnel worldwide is like an  \n  incomplete jigsaw puzzle; training human personnel is expensive and will take significant amount of time to meet the demand. \n   Automation with deep learning systems provide a comparably faster, scalable and a comparably low cost complement for salvaging the situation. \nThere is no denying the fact that with an ever-growing global population, we are going to need alternative AI-based medical  \npersonnel to assist us in achieving the sustainable development goal of  \nproviding \u201cAffordable, Accurate and Adequate Healthcare for All\u201d. \nThis project is borne out of the team's vision to make healthcare better for everyone, anywhere. \nGiven our time constraint, we chose to divide ourselves into sub-teams corresponding to the demarcated phases of this project.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8507402462800693,
        0.8517004665067796
      ],
      "excerpt": "facilitate better outcomes for a subsequent phase - and speed due to parallel implementations at the various phases. \nWe also adopted a scrum model, where the entire period was a sprint, and stand-up sessions within 2-day intervals served  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9830526444301201,
        0.860059181823877,
        0.9725279559188702
      ],
      "excerpt": "Finally, our team model allowed us to use initial cycles as an exploration to inform our final data selection and preprocessing, and  \nmodel strategies.  \nWith each cycle, we redefined our goals while maintaining the general objective of facilitating faster lung X-ray assessments. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9400618681894269
      ],
      "excerpt": "for our timeline, and we had to derive a better-balanced sample.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.967076665468842,
        0.9662035204371402
      ],
      "excerpt": "We initially tested our strategies for classifying all 15 conditions and redefined our goals through exploration,  \nuntil in addition to identifying Healthy X-rays (No Finding), the model could more accurately  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9864482264714813
      ],
      "excerpt": "For our final round, and based on clinical considerations, we proceeded with two sets: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8333913622188237
      ],
      "excerpt": "* Version 4.2 - containing images taken using PA for Effusion and healthy (No finding) classes, and AP and PA for cardiomegaly.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9639590496392276,
        0.9061741273683657,
        0.9736482859501292
      ],
      "excerpt": "Our dataset covered medical conditions, the manifestations of which could be present at edges of X-ray images and we exercised  \ncaution with our transformations. After several deliberations and clinical considerations, we would avoid  \ncropping and extreme random rotations and kept to these: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9667746318778111
      ],
      "excerpt": "* Resize: to a size of 224 by 224 to match our densenet model input size \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8674822143054275,
        0.8485656140146127
      ],
      "excerpt": "* Conversion To Pytorch floatTensor type: This minimalistic approach was our shot at preserving as much information  \nthat would be clinically relevant for diagnosing our target conditions. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9138985037007555,
        0.8716907620253721,
        0.9011163372956922,
        0.9581245485006337,
        0.9054231850012817,
        0.9235636463033623
      ],
      "excerpt": "The modeling stage was characterized by several iterative cycles that called for new sampling and processing strategies on demand.  \nNotwithstanding, the team model facilitated swift responses so that we could re-orient quickly without disrupting overall progress. \nWe also had the technical expertise that allowed us to try novel activation functions - namely mila, mish and beta mish \u2013  \nwhich we believe contributed greatly to our results. \nActivation functions are important features of artificial neural networks. They determine whether  \na neuron should be activated or not; whether the information that a neuron is receiving is relevant for the  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9025005787926715
      ],
      "excerpt": "It is an uni-parametric activation inspired by the Mish activation function - when \u03b2=1, \u03b2-Mish becomes the standard version of  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944410658513235
      ],
      "excerpt": "The parameter \u03b2 is used to control the concavity of the Global Minima of the Activation  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9508555495980443
      ],
      "excerpt": "reduces the concavity and vice versa. \u03b2 is introduced to tackle gradient death scenarios due to the  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9229570758024671,
        0.8911017716556152,
        0.834878891768306,
        0.9173247954681216
      ],
      "excerpt": "The mathematical function of Mila is shown as below: \nThis activation function uses the square operator to introduce the required non-linearity as compared with  \nthe use of an exponential term in the popular TanSig. Smaller computational operation count characterizes  \nthe proposed activation function. The key to the effectiveness of this function is a faster convergence when  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8004501408693611,
        0.8614689108238959,
        0.8138109409848462
      ],
      "excerpt": "the function is linear, resulting in a quicker gradient computation. \nReLu Stands for Rectified Linear Unit. It is the most widely used activation function, and is chiefly implemented in  \nhidden layers of neural networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8892154649531154
      ],
      "excerpt": "* Nature :- Non-linear, which means we can easily backpropagate the errors and have multiple layers of neurons being  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8957383032524704,
        0.8247958339548178,
        0.959857096614524
      ],
      "excerpt": "* Uses :- ReLu is less computationally expensive than tanh and sigmoid because it involves simpler mathematical operations.  \nAt a time, only a few neurons are activated making the network sparse, and computationally efficient. \nThe softmax function is also a type of sigmoid function but is handy when we are trying to handle classification problems. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9170643940739694,
        0.821770793771818,
        0.8561220487896727
      ],
      "excerpt": "class between 0 and 1 and would also divide by the sum of the outputs. \n* Output:- The softmax function is ideally used in the output layer of the classifier where we are actually trying to  \nattain the probabilities to define the class of each input. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9500717526560091,
        0.9928043999335266,
        0.9422455311011558,
        0.9155906222980752
      ],
      "excerpt": "the advantages of large image capacity, various multi-label losses, and pooling strategies. In lieu of this, we experimented  \nwith the architectures outlined below, in a bid to explore and appreciate their suitability for this project. \nA DenseNet is a stack of dense blocks followed by transition layers.  \nDense blocks consist of a series of units.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8248817544957024
      ],
      "excerpt": "fixed-size feature vector. A parameter, described as the growth rate, controls how much new information  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9808987929385004
      ],
      "excerpt": "Transition layers, on the other hand, are very simple components designed to perform downsampling of the features  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9757404633815726,
        0.909332432767165,
        0.9087075049101271
      ],
      "excerpt": "A deep residual network (deep ResNet) is a type of specialized neural network that helps to handle more sophisticated  \ndeep learning tasks, by facilitating better outcomes with deeper architectures. It has received growing attention in recent  \ntimes, for its effectiveness for training deep networks. ResNet-50 is a 50-layer deep convolutional neural network  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9769012359468578,
        0.9312118766624501,
        0.8560125138915727
      ],
      "excerpt": "One problem with deep networks composed of dozens of layers, as commonly cited by professionals, is that accuracy can become  \nsaturated, and some degradation can occur. Others are also concerned about the \"vanishing gradient\" problem, which is characterised by  \ngradients becoming too small to be immediately useful. The other obvious reason is overfitting, where models learn intricate  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9471402347852819,
        0.9118772542704796,
        0.9812888413617051,
        0.8856856969280701,
        0.9269110562509428
      ],
      "excerpt": "The deep residual network deals with some of these problems by using residual blocks,  \nwhich take advantage of residual mapping to preserve inputs. By utilizing deep residual learning frameworks,  \nwe could harness the power of deep networks and minimize the weaknesses. \nResNeXt is a simple, highly modularized network architecture for image classification. The network is constructed by  \nrepeating a building block that aggregates a set of transformations with the same topology. This simple design results in a  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9756817380454165,
        0.8361610190656033,
        0.9812531843736061,
        0.9730568884976242,
        0.973336862820892,
        0.9944897088222844,
        0.8259554256447333,
        0.9787274128889398,
        0.8487245954687298
      ],
      "excerpt": "which we call \u201ccardinality\u201d (the size of the set of transformations), as an essential factor in addition to the dimensions  \nof depth and width. \nHealthcare data is particularly sensitive, and we face the risk of exposing sensitive patient data through projects like ours.  \nFor ensuring security and privacy of the dataset, we implemented a class which would allow encryption of model and  \ndata on-demand using websockets and the PySyft library.  \nA link to the our implementation is provided in the appendix of this document. \nWith varied approaches for data sampling, activation function selection and hyperparameter tuning, we trained and tested six models,  \ncodenamed Aurora, Ava, Auden, Venus, Armadillo, and Atlas. Our results are given below in descending order of model performance. \nWe trained and tested densenet161 with beta-mish and mila activations, on classifying Cardiomegaly, Effusion, and No Finding,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8367225462112312
      ],
      "excerpt": "for Cardiomegaly(mixed AP/PA), Effusion(PA), and No-Finding(PA) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9160481756524861
      ],
      "excerpt": "We trained and tested densenet161 with sqnl activation, on classifying Emphesyma and No-Finding, irrespective of X-ray position. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9160481756524861
      ],
      "excerpt": "We trained and tested resnet50 with mila activation, on classifying Pneumothorax and No-Finding, irrespective of X-ray position. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8075589383232605,
        0.8735668079491955
      ],
      "excerpt": "We trained and tested densenet161 with mila activation on classifying Cardiomegaly, Effusion, and No-Finding,  \nirrespective of X-ray position. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8521381283883158,
        0.8735668079491955,
        0.9411083659449101
      ],
      "excerpt": "We trained and tested resNext50 with traditional ReLU and Softmax activations on classifying Cardiomegaly, Effusion, and No-Finding,  \nirrespective of X-ray position. \nEvidently, our most accurate model was AURORA, achieving an accuracy of 82.3%, on PA images for Effusion and  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9082309278982558,
        0.9964461993285683,
        0.9266923713397331,
        0.9717620580507769
      ],
      "excerpt": "In comparison with similar work dedicated to lung disease detection using the same dataset we used, we have had better accuracies.  \nThere is a general appreciation of the difficulty of the task we gave ourselves in this project, and we recognise that we cleared a  \nmilestone that opens up many possibilities. We had our fair share of difficulties, notwithstanding. We ran into significant challenges  \nin our  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9412074485540733
      ],
      "excerpt": "training a successful deep learning model. While many factors can be taken into account for this complication, the root  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9027355116209979
      ],
      "excerpt": "Data Acquisition, Pre-processing and Modelling teams alike.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8958240140448539,
        0.8473986562193462
      ],
      "excerpt": "For example, there was a huge disparity between the image counts for the top class(No Finding) with more than 60,000  \nand the bottom class(Hernia) with only 110.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8976758177254616,
        0.9232144260417379,
        0.8462520252279814
      ],
      "excerpt": "Since many of the diseases in our dataset were sensitive to such positions, we were torn between splitting each class  \ninto two smaller ones - AP and PA - or more ideally, retaining only PA pictures. <br> \nThe latter approach, nevertheless, had one major disadvantage: we needed to take into account the number of pictures in the PA  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9961770640750578,
        0.9806628490043687,
        0.8457601920329385,
        0.926096793479135,
        0.9645337913384773
      ],
      "excerpt": "impact on the accuracy of our model. \nProceeding with data augmentation:  \nEven a small rotation or central crop could result in loss of important diagnostic information and lead to inaacurate predictions.  \nAfter extensive research on the dataset, the reported performance of past models, and several rounds of experimentation,  \nwe reduced the number of classes in the wrangled and modified dataset to only three - CardioMegaly, Effusion, and No finding.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.989571132862045
      ],
      "excerpt": "After consulting with the subject matter expert in our team, we found that for conditions that tend to look similar  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9372114414960975,
        0.9160244122115426,
        0.9757027824521365
      ],
      "excerpt": "such as white count and temperature to make a formal diagnosis. Unfortunately, that information was not available in our  \ndataset. In fact, in the original paper, all the aforementioned diseases performed poorly and recorded a high prediction  \nerror rate from the model, which helped to reinforce our earlier finding. We would resort to focusing of xray samples of  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.922824738294948,
        0.8225040094527597,
        0.965233205135238,
        0.9711956852118449,
        0.9842746170291234
      ],
      "excerpt": "Although the authors had gone the extra mile in mitigating the risk of wrong labeling, by crafting a variety of custom rules  \nand then applying them in the pre-processing step, the problem of defective labels was not entirely eliminated.  \nSpecifically, we can refer to \u201cTable 2. Evaluation of image labeling results on OpenI dataset.\u201d on page 4 of the paper  \nfor a detailed assessment on this phenomenon. The vast majority of classes exhibited varying degrees of being mislabeled,  \nfrom \"Effusion\" with 0.93 precision rate, to \"Infiltration\" with a modest score of 0.74. Owing to this imperfection,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8476457414337177,
        0.9854901650125462,
        0.9125740309338887
      ],
      "excerpt": "Ignoring the fourth channel: The original image data had an extra alpha(transparency) channel, which is supposed to help  \nwith the assessment of manifestations of some conditions. Due to the constraints of compute resources, however, we had to reduce the  \nchannels to three, to reduce the computational cost. This may have contirbuted to some  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9990103616504994,
        0.9988786426829309,
        0.9843332073442331,
        0.9994165096445442,
        0.9867134076503794,
        0.9842626532943038,
        0.9320126760421353,
        0.9940637289706511
      ],
      "excerpt": "Our project adds emphasis to the immense potential to be harnessed from the intersection of Deep Learning and Medical Diagnostics. The outcomes achieved within the short span of time were commendable. We also appreciated the technicalities of medical imaging, and more importantly, the challenges with automated diagnosis leveraging analysis of x-ray images by deep neural networks. \nOur goal is to build a full system that leverages federated learning and full blown secure and privacy preserving technologies, to make smart diagnosis accessible in the browser, on phones and tablets - the web interface is up and functional, while the mobile platforms are underway. We have also designed a roadmap which will allow us to improve the overall quality and accuracy of our system on available datasets for chest X-rays. Ultimately, we hope to build on this project for other diagnoses outside our current target of 14 lung conditions. \nThe team would like to extend the project to make it suitable for use in institutions and facilities, where aid to diagnosis  \nis of utmost importance. \nCurrently, the project is limited to the public domain dataset and to the best-effort analyses of health records via  \nnatural language processing. The idea here is to improve the current accuracy of the model by augmenting it  \nwith real-world datasets which are available from medical institutions. Due to the sensitive nature  \nof these datasets and concerns for privacy, these are currently being kept private. With the power of  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9213154069880508,
        0.9424212146207903,
        0.9512806639070497
      ],
      "excerpt": "private datasets to a central server, which might lead to privacy leakage. Instead, we open an interface  \nfor them to feed the data within the institution, train the model on-site and only transmit gradients and other  \nmodel information to the central server which we have access and do model aggregation accordingly.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9780458384878175,
        0.9058220700173459,
        0.921299335385041,
        0.9596407337624828
      ],
      "excerpt": "For this, we think of Raspberry Pi 3 devices, small, lightweight and powerful enough to perform the  \nlocal training needed. We plan on creating a headless setup to each Raspberry Pi device, with the web  \nserver connected to their local network. This web server can be accessed by representatives in-house to  \nfeed X-ray data and other relevant information pertinent to local training. We make sure that the data to  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8277981358042763
      ],
      "excerpt": "PySyft\u2019s secure model parameter aggregation, leveraging mathematical techniques per actor to encrypt model  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9860345498775147,
        0.8270799257026792,
        0.9963628911864612
      ],
      "excerpt": "full cooperation of hospitals, clinics and radiologic facilities who have quality datasets to join our planned  \nIoT-enabled ecosystem for this use case. In return, we will enable an intuitive interface to help doctors in diagnosis. \nWe already deployed the model to the web for demonstration, and our xray detection service is accessible at https://xrayeyes.onrender.com. We have also started work on the apps for android, iOS and the new ipadOS. Additionally, these mobile apps may be used in the home, and we have designed functionality that can link patients to nearby clinics or hospitals. Mocks of this is shown below: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "For the demo. Click on the link.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SGNovice/Disease-detection-using-chest-xrays/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 25,
      "date": "Sun, 05 Dec 2021 17:00:16 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/SGNovice/Disease-detection-using-chest-xrays/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "SGNovice/Disease-detection-using-chest-xrays",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8044594614251275
      ],
      "excerpt": "* Version 4.1 - for images taken using both antero-posterior position (AP) and postero-anterior position (PA). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8868116545162763
      ],
      "excerpt": "The distribution for Version 4.1 finally settled at: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8868116545162763
      ],
      "excerpt": "The distribution for Version 4.2 finally settled at: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8046286685327338
      ],
      "excerpt": "irrespective of X-ray position using dataset version 4.2. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8918974083095406,
        0.8918974083095406,
        0.8918974083095406,
        0.8918974083095406,
        0.8918974083095406,
        0.8918974083095406
      ],
      "excerpt": "Victor Mawusi Ayi | https://github.com/ayivima \nAnju Mercian | https://github.com/amalphonse \nGeorge Christopoulos | https://github.com/geochri \nAshish Bairwa  | https://github.com/ashishbairwa \nPooja Vinod | https://github.com/poojavinod100  \nIngus Terbets | https://github.com/ingus-t \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8918974083095406,
        0.8918974083095406,
        0.8918974083095406
      ],
      "excerpt": "Olivia Milgrom | https://github.com/OliviaMil \nTuan Hung Truong | https://github.com/tuanhung94 \nMarwa Qabeel | https://github.com/MarwaQabeel \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8260014061402702
      ],
      "excerpt": "* Value Range :- [0, inf] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8953572141128514
      ],
      "excerpt": "Pneumothorax | 45% (45/100) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": "prevent training bias. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/SGNovice/Disease-detection-using-chest-xrays/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "HTML",
      "Python",
      "CSS"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 SGNovice\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Disease detection Project using Chest X-ray Database",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Disease-detection-using-chest-xrays",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "SGNovice",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SGNovice/Disease-detection-using-chest-xrays/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 65,
      "date": "Sun, 05 Dec 2021 17:00:16 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Convolutional Neural Networks are inherently designed for image processing, and this sets them up for handling and gathering \ninsights from large images more efficiently.\n\nCurrently, some CNNs have approached, and even surpassed, the accuracy of human diagnosticians in identifying important \nfeatures, according to a number of diagnostic imaging studies. In June of 2018, a study in the Annals of Oncology \nshowed that a convolutional neural network trained to analyze dermatology images identified melanoma with ten percent \nmore specificity than medical practitioners.Additionally, researchers at the Mount Sinai Icahn School of Medicine have \ndeveloped a deep neural network capable of diagnosing crucial neurological conditions, such as stroke and brain hemorrhage, \n150 times faster than human radiologists. The tool took just 1.2 seconds to process the image, analyze its contents, \nand alert providers of a problematic clinical finding.\n\nEvidently, there is great potential for the future of healthcare with smart tools which integrate deep learning.\n\n",
      "technique": "Header extraction"
    }
  ]
}
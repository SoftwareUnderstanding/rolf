{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nPlease cite our paper if you use VDA in your work:\r\n\r\n```bibtex\r\n@inproceedings{zhou2021vda,\r\n  author    = {Kun Zhou, Wayne Xin Zhao, Sirui Wang, Fuzheng Zhang, Wei Wu and Ji-Rong Wen},\r\n  title     = {Virtual Data Augmentation: A Robust and General Framework for Fine-tuning Pre-trained Models},\r\n  booktitle = {{EMNLP} 2021},\r\n  publisher = {The Association for Computational Linguistics},\r\n}\r\n```\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{zhou2021vda,\n  author    = {Kun Zhou, Wayne Xin Zhao, Sirui Wang, Fuzheng Zhang, Wei Wu and Ji-Rong Wen},\n  title     = {Virtual Data Augmentation: A Robust and General Framework for Fine-tuning Pre-trained Models},\n  booktitle = {{EMNLP} 2021},\n  publisher = {The Association for Computational Linguistics},\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RUCAIBox/VDA",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-10T03:42:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-02T03:42:44Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9453304210828588
      ],
      "excerpt": "This repository contains the code for our paper VDA (public in EMNLP2021 main conference) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9811967218037856,
        0.9774332283241937,
        0.8566823317359566,
        0.8205746367071287
      ],
      "excerpt": "We propose a general framework Virtual Data Augmentation (VDA) for robustly fine-tuning Pre-trained Language Models for downstream tasks. Our VDA utilizes a masked language model with Gaussian noise to augment virtual examples for improving the robustness, and also adopts regularized training to further guarantee the semantic relevance and diversity. \nIn the following section, we describe how to train a model with VDA by using our code. \nFor evaluation of our VDA, we use 6 text classification datasets, i.e. Yelp, IMDB, AGNews, MR, QNLI and MRPC datasets. These datasets can be downloaded from the GoogleDisk \nAfter download the two ziped files, users should unzip the data fold that contains the training, validation and test data of the 6 datasets. While the Robust fold contains the examples for test the robustness. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9104142393392575
      ],
      "excerpt": "We provide example scripts for both training and test of our VDA on the 6 datasets. In run_train.sh, we provide 6 example for training on the yelp and qnli datasets. This script calls text_classifier_xxx.py for training (xxx refers to the base model). We explain the arguments in following: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9313482336431191,
        0.9456143166110951,
        0.9828669940996897,
        0.9716168251009033
      ],
      "excerpt": "* --variance: The variance of the Gaussian noise. \nFor results in the paper, we use Nvidia Tesla V100 32G and Nvidia 3090 24G GPUs to train our models. Using different types of devices or different versions of CUDA/other softwares may lead to slightly different performance. \nDuring training, our model file will show the original accuracy on the test set of the 6 datasets, which evaluates the accuracy performance of our model. \nOur evaluation code for robustness is based on a modified version of BERT-Attack. It outputs Attack Accuracy, Query Numbers and Perturbation Ratio metrics. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9529668806947278
      ],
      "excerpt": "Based on the checkpoint of the fine-tuned models, we use therun_test.sh script for test the robustness on yelp and qnli datasets. It is based on bert_robust.py file. We explain the arguments in following: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Virtual Data Augmentation: A Robust and General Framework for Fine-tuning Pre-trained Models",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rucaibox/vda/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 07 Dec 2021 10:56:49 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/RUCAIBox/VDA/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "RUCAIBox/VDA",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/rucaibox/vda/main/run_test.sh",
      "https://raw.githubusercontent.com/rucaibox/vda/main/run_train.sh"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "Train VDA \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8176178213217389
      ],
      "excerpt": "After download the two ziped files, users should unzip the data fold that contains the training, validation and test data of the 6 datasets. While the Robust fold contains the examples for test the robustness. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8389385689694543,
        0.8101554971016965
      ],
      "excerpt": "text_classifier.py and text_pair_classifier.py: BERT-base+VDA \ntext_classifier_freelb.py and text_pair_classifier_freelb.py: FreeLB+VDA on BERT-base \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8971091044538458
      ],
      "excerpt": "* --dataset: Training file path. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8784881929444998
      ],
      "excerpt": "* --data_path: Training file path. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/RUCAIBox/VDA/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Virtual Data Augmentation: A Robust and General Framework for Fine-tuning Pre-trained Models",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "VDA",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "RUCAIBox",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RUCAIBox/VDA/blob/main/ReadME.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Tue, 07 Dec 2021 10:56:49 GMT"
    },
    "technique": "GitHub API"
  }
}
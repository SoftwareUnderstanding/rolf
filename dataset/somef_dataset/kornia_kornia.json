{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you are using kornia in your research-related documents, it is recommended that you cite the paper. See more in [CITATION](https://github.com/kornia/kornia/blob/master/CITATION.md).\n\n  ```bibtex\n  @inproceedings{eriba2019kornia,\n    author    = {E. Riba, D. Mishkin, D. Ponsa, E. Rublee and G. Bradski},\n    title     = {Kornia: an Open Source Differentiable Computer Vision Library for PyTorch},\n    booktitle = {Winter Conference on Applications of Computer Vision},\n    year      = {2020},\n    url       = {https://arxiv.org/pdf/1910.02190.pdf}\n  }\n  ```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9668858682913047
      ],
      "excerpt": "Forums: discuss implementations, research, etc. GitHub Forums \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/kornia/kornia/master/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kornia/kornia",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-08-22T10:31:37Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-10T13:32:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9002195261811611,
        0.934023311214731
      ],
      "excerpt": "Inspired by existing packages, this library is composed by a subset of packages containing operators that can be inserted within neural networks to train models to perform image transformations, epipolar geometry, depth estimation, and low-level image processing such as filtering and edge detection that operate directly on tensors. \nAt a granular level, Kornia is a library that consists of the following components: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8327296667852387,
        0.8708680517117765,
        0.910410270455338
      ],
      "excerpt": "| kornia.augmentation | a module to perform data augmentation in the GPU                                                                                      | \n| kornia.color               | a set of routines to perform color space conversions                                                                                  | \n| kornia.contrib           | a compilation of user contrib and experimental operators                                                                              | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8477132736584256
      ],
      "excerpt": "| kornia.filters           | a module to perform image filtering and edge detection                                                                                | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9607827826658334
      ],
      "excerpt": "We appreciate all contributions. If you are planning to contribute back bug-fixes, please do so without any further discussion. If you plan to contribute new features, utility functions or extensions, please first open an issue and discuss the feature with us. Please, consider reading the CONTRIBUTING notes. The participation in this open source project is subject to Code of Conduct. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Open Source Differentiable Computer Vision Library",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://kornia.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kornia/kornia/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 541,
      "date": "Fri, 10 Dec 2021 16:24:51 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kornia/kornia/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "kornia/kornia",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/kornia/kornia/master/docker/Dockerfile",
      "https://raw.githubusercontent.com/kornia/kornia/master/docker/tpu-tests/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/kornia/kornia/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/kornia/kornia/master/examples/feature_detection/local-feature-adversarial-attack.ipynb",
      "https://raw.githubusercontent.com/kornia/kornia/master/examples/feature_detection/local_feature_detection_example.ipynb",
      "https://raw.githubusercontent.com/kornia/kornia/master/examples/feature_detection/extract_local_patches.ipynb",
      "https://raw.githubusercontent.com/kornia/kornia/master/examples/augmentation/kornia_augmentation.ipynb",
      "https://raw.githubusercontent.com/kornia/kornia/master/examples/depth_regression/Depth_regression.ipynb",
      "https://raw.githubusercontent.com/kornia/kornia/master/examples/depth_warper/Depth_warper.ipynb",
      "https://raw.githubusercontent.com/kornia/kornia/master/examples/homography_regression/homography.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/kornia/kornia/master/setup_dev_env.sh",
      "https://raw.githubusercontent.com/kornia/kornia/master/packaging/build_wheel.sh",
      "https://raw.githubusercontent.com/kornia/kornia/master/docker/build.sh",
      "https://raw.githubusercontent.com/kornia/kornia/master/docker/tpu-tests/docker-entrypoint.sh",
      "https://raw.githubusercontent.com/kornia/kornia/master/examples/depth_regression/download_data.sh",
      "https://raw.githubusercontent.com/kornia/kornia/master/examples/depth_warper/download_data.sh",
      "https://raw.githubusercontent.com/kornia/kornia/master/examples/depth_warper/install_dependencies.sh",
      "https://raw.githubusercontent.com/kornia/kornia/master/examples/homography_regression/download_data.sh",
      "https://raw.githubusercontent.com/kornia/kornia/master/examples/homography_regression/install_dependencies.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.999746712887969,
        0.9537917442865446
      ],
      "excerpt": "  pip install kornia \n  pip install kornia[x]  #: to get the training API ! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9820226428242687,
        0.999746712887969,
        0.9989505157564216
      ],
      "excerpt": "  python setup.py install \n  pip install -e . \n  pip install git+https://github.com/kornia/kornia \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8883324025718666
      ],
      "excerpt": "GitHub Issues: bug reports, feature requests, install issues, RFCs, thoughts, etc. OPEN \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kornia/kornia/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "Dockerfile",
      "Makefile",
      "Jsonnet",
      "PHP"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/kornia/kornia/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'                                 Apache License\\n                           Version 2.0, January 2004\\n                        http://www.apache.org/licenses/\\n\\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\\n\\n   1. Definitions.\\n\\n      \"License\" shall mean the terms and conditions for use, reproduction,\\n      and distribution as defined by Sections 1 through 9 of this document.\\n\\n      \"Licensor\" shall mean the copyright owner or entity authorized by\\n      the copyright owner that is granting the License.\\n\\n      \"Legal Entity\" shall mean the union of the acting entity and all\\n      other entities that control, are controlled by, or are under common\\n      control with that entity. For the purposes of this definition,\\n      \"control\" means (i) the power, direct or indirect, to cause the\\n      direction or management of such entity, whether by contract or\\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\\n      outstanding shares, or (iii) beneficial ownership of such entity.\\n\\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\\n      exercising permissions granted by this License.\\n\\n      \"Source\" form shall mean the preferred form for making modifications,\\n      including but not limited to software source code, documentation\\n      source, and configuration files.\\n\\n      \"Object\" form shall mean any form resulting from mechanical\\n      transformation or translation of a Source form, including but\\n      not limited to compiled object code, generated documentation,\\n      and conversions to other media types.\\n\\n      \"Work\" shall mean the work of authorship, whether in Source or\\n      Object form, made available under the License, as indicated by a\\n      copyright notice that is included in or attached to the work\\n      (an example is provided in the Appendix below).\\n\\n      \"Derivative Works\" shall mean any work, whether in Source or Object\\n      form, that is based on (or derived from) the Work and for which the\\n      editorial revisions, annotations, elaborations, or other modifications\\n      represent, as a whole, an original work of authorship. For the purposes\\n      of this License, Derivative Works shall not include works that remain\\n      separable from, or merely link (or bind by name) to the interfaces of,\\n      the Work and Derivative Works thereof.\\n\\n      \"Contribution\" shall mean any work of authorship, including\\n      the original version of the Work and any modifications or additions\\n      to that Work or Derivative Works thereof, that is intentionally\\n      submitted to Licensor for inclusion in the Work by the copyright owner\\n      or by an individual or Legal Entity authorized to submit on behalf of\\n      the copyright owner. For the purposes of this definition, \"submitted\"\\n      means any form of electronic, verbal, or written communication sent\\n      to the Licensor or its representatives, including but not limited to\\n      communication on electronic mailing lists, source code control systems,\\n      and issue tracking systems that are managed by, or on behalf of, the\\n      Licensor for the purpose of discussing and improving the Work, but\\n      excluding communication that is conspicuously marked or otherwise\\n      designated in writing by the copyright owner as \"Not a Contribution.\"\\n\\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\\n      on behalf of whom a Contribution has been received by Licensor and\\n      subsequently incorporated within the Work.\\n\\n   2. Grant of Copyright License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      copyright license to reproduce, prepare Derivative Works of,\\n      publicly display, publicly perform, sublicense, and distribute the\\n      Work and such Derivative Works in Source or Object form.\\n\\n   3. Grant of Patent License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      (except as stated in this section) patent license to make, have made,\\n      use, offer to sell, sell, import, and otherwise transfer the Work,\\n      where such license applies only to those patent claims licensable\\n      by such Contributor that are necessarily infringed by their\\n      Contribution(s) alone or by combination of their Contribution(s)\\n      with the Work to which such Contribution(s) was submitted. If You\\n      institute patent litigation against any entity (including a\\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\\n      or a Contribution incorporated within the Work constitutes direct\\n      or contributory patent infringement, then any patent licenses\\n      granted to You under this License for that Work shall terminate\\n      as of the date such litigation is filed.\\n\\n   4. Redistribution. You may reproduce and distribute copies of the\\n      Work or Derivative Works thereof in any medium, with or without\\n      modifications, and in Source or Object form, provided that You\\n      meet the following conditions:\\n\\n      (a) You must give any other recipients of the Work or\\n          Derivative Works a copy of this License; and\\n\\n      (b) You must cause any modified files to carry prominent notices\\n          stating that You changed the files; and\\n\\n      (c) You must retain, in the Source form of any Derivative Works\\n          that You distribute, all copyright, patent, trademark, and\\n          attribution notices from the Source form of the Work,\\n          excluding those notices that do not pertain to any part of\\n          the Derivative Works; and\\n\\n      (d) If the Work includes a \"NOTICE\" text file as part of its\\n          distribution, then any Derivative Works that You distribute must\\n          include a readable copy of the attribution notices contained\\n          within such NOTICE file, excluding those notices that do not\\n          pertain to any part of the Derivative Works, in at least one\\n          of the following places: within a NOTICE text file distributed\\n          as part of the Derivative Works; within the Source form or\\n          documentation, if provided along with the Derivative Works; or,\\n          within a display generated by the Derivative Works, if and\\n          wherever such third-party notices normally appear. The contents\\n          of the NOTICE file are for informational purposes only and\\n          do not modify the License. You may add Your own attribution\\n          notices within Derivative Works that You distribute, alongside\\n          or as an addendum to the NOTICE text from the Work, provided\\n          that such additional attribution notices cannot be construed\\n          as modifying the License.\\n\\n      You may add Your own copyright statement to Your modifications and\\n      may provide additional or different license terms and conditions\\n      for use, reproduction, or distribution of Your modifications, or\\n      for any such Derivative Works as a whole, provided Your use,\\n      reproduction, and distribution of the Work otherwise complies with\\n      the conditions stated in this License.\\n\\n   5. Submission of Contributions. Unless You explicitly state otherwise,\\n      any Contribution intentionally submitted for inclusion in the Work\\n      by You to the Licensor shall be under the terms and conditions of\\n      this License, without any additional terms or conditions.\\n      Notwithstanding the above, nothing herein shall supersede or modify\\n      the terms of any separate license agreement you may have executed\\n      with Licensor regarding such Contributions.\\n\\n   6. Trademarks. This License does not grant permission to use the trade\\n      names, trademarks, service marks, or product names of the Licensor,\\n      except as required for reasonable and customary use in describing the\\n      origin of the Work and reproducing the content of the NOTICE file.\\n\\n   7. Disclaimer of Warranty. Unless required by applicable law or\\n      agreed to in writing, Licensor provides the Work (and each\\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\\n      implied, including, without limitation, any warranties or conditions\\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\\n      PARTICULAR PURPOSE. You are solely responsible for determining the\\n      appropriateness of using or redistributing the Work and assume any\\n      risks associated with Your exercise of permissions under this License.\\n\\n   8. Limitation of Liability. In no event and under no legal theory,\\n      whether in tort (including negligence), contract, or otherwise,\\n      unless required by applicable law (such as deliberate and grossly\\n      negligent acts) or agreed to in writing, shall any Contributor be\\n      liable to You for damages, including any direct, indirect, special,\\n      incidental, or consequential damages of any character arising as a\\n      result of this License or out of the use or inability to use the\\n      Work (including but not limited to damages for loss of goodwill,\\n      work stoppage, computer failure or malfunction, or any and all\\n      other commercial damages or losses), even if such Contributor\\n      has been advised of the possibility of such damages.\\n\\n   9. Accepting Warranty or Additional Liability. While redistributing\\n      the Work or Derivative Works thereof, You may choose to offer,\\n      and charge a fee for, acceptance of support, warranty, indemnity,\\n      or other liability obligations and/or rights consistent with this\\n      License. However, in accepting such obligations, You may act only\\n      on Your own behalf and on Your sole responsibility, not on behalf\\n      of any other Contributor, and only if You agree to indemnify,\\n      defend, and hold each Contributor harmless for any liability\\n      incurred by, or claims asserted against, such Contributor by reason\\n      of your accepting any such warranty or additional liability.\\n\\n   END OF TERMS AND CONDITIONS\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Overview",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "kornia",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "kornia",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kornia/kornia/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "## :rocket: [0.6.2] - 2021-12-03\r\n### :new:  New Features\r\n- Add face detection API (#1469)\r\n- Add `ObjectDetectorTrainer` (#1414)\r\n- Add container operation weights and `OneOf` documentation (#1443)\r\n- Add oriented contraint check to Homography RANSAC (#1453)\r\n- Add background color selection in `warp_perspective` (#1452)\r\n- Add `draw_line` image utility (#1456)\r\n- Add Bounding Boxes API (#1304)\r\n- Add histogram_matching functionality (#1395)\r\n\r\n### :lady_beetle:  Bug fixes\r\n- fix catch type for torch.svd error (#1431)\r\n- Fix for nested AugmentationSequential containers (#1467)\r\n- Use common bbox format xywh (#1472)\r\n\r\n### :exclamation: Changes\r\n- Add padding_mode for RandomElasticTransform augmentation (#1439)\r\n- Expose inliers sum to HomographyTracker (#1463)\r\n\r\n### :zap:  Improvements\r\n- Switch to one-way error RANSAC for speed-up (#1454)\r\n- Few improvements on homography tracking (#1434)\r\n- Enable all bandit tests, add separate hook for tests (#1437)\r\n- Merge homography_warp to warp_perspective (#1438)\r\n- Random generator refactor (#1459)\r\n\r\n:woman_technologist: :man_technologist: We would like to thank all contributors for this new release !\r\n@ducha-aiki @edgarriba @chinhsuanwu @chinhsuanwu @dobosevych  @shijianjian  @rvorias  @rvorias @fmiotello @hal-314 @trysomeway  @miquelmarti  @calmdown13  @twsl Abdelrhman-Hosny\r\n\r\nIf we forgot someone let us know :sunglasses:",
        "dateCreated": "2021-12-03T21:20:29Z",
        "datePublished": "2021-12-03T21:27:30Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.6.2",
        "name": "Kornia 0.6.2: Face Detection, Bounding Box API, histogram matching, drawing and more.",
        "tag_name": "v0.6.2",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.6.2",
        "url": "https://api.github.com/repos/kornia/kornia/releases/54577622",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.6.2"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "## :rocket: Release Note (``0.6.1``)\r\n\r\n-  Fixes PyPI tarball missing required files #1421\r\n-  hotfix: remove mutable object in constructor #1423",
        "dateCreated": "2021-10-22T19:53:25Z",
        "datePublished": "2021-10-22T21:47:19Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.6.1",
        "name": "Kornia 0.6.1 - Packaging hotfix",
        "tag_name": "v0.6.1",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.6.1",
        "url": "https://api.github.com/repos/kornia/kornia/releases/51881841",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.6.1"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "## :rocket: Release Note (``0.6.0``)\r\n\r\n> Release time: 2021-10-22\r\n\r\n### :new:  New Features\r\n- Add Training API (#1307) \r\n- Added combine patches (#1309) \r\n- Add semantic segmentation trainer (#1323) \r\n- Add vanilla LO-RANSAC (#1335) \r\n- Add Lambda function module (#1346)\r\n- Add support for YUV420 and YUV422 to complement current YUV444 (#1360)\r\n- Add raw to rgb color conversion (#1380)\r\n- Implement separable_filter2d (#1385) \r\n- Add MobileViT to contrib (#1388) \r\n- Add solve_pnp_dlt (#1349) \r\n- Add function image_list_to_tensor to utils (#1393)\r\n- Add undistort_image function (#1303) \r\n- Create kormia.metrics submodule (#1325)\r\n- Add Image Stitching API (#1358) \r\n- Add Homography Tracker API (#1389) \r\n\r\n### :exclamation: Changes\r\n- Refactor library namespaces [pre-release][0.6-rc1] (#1412) \r\n- Deprecate PyTorch 1.6/1.7 and add 1.9.1 (#1399) \r\n\r\n### :zap:  Improvements\r\n- Improve bbox_to_mask (#1351) \r\n- Refactor unfold->conv for morphology backbone (#1107) \r\n- Improve focal loss for numerical stability (#1362) \r\n- Add more border_type options for filter2D (#1375) \r\n- Replace deprecated torch.qr (#1376) \r\n- Add special case hardcoded implementtion for local features speed up (#1387)\r\n- Enable non/batched connected components (#1193) \r\n- Remove warnings during testing (#1401) \r\n\r\n### :lady_beetle:  Bug fixes\r\n- Fix binary focal loss (#1313) \r\n- Fix kornia.geometry.subpix.spatial_soft_argmax imports (#1318) \r\n- Fixed a simple typo in __init__.py (#1319) \r\n- Fix path to dev requirements file in a setup_dev_env.sh (#1324) \r\n- Fix bug in create_meshgrid3d along depth (#1330) \r\n- Fix anisotropic scale error (#1340) \r\n- Fix rgb_to_hsv for onnx (#1329) \r\n- Fixed useless return in ransac.py (#1352) \r\n- Fixed classificationhead typo and leave out some of the guesswork (#1354)\r\n- Fix clahe differentiability and tests (#1356)\r\n- Fixes singular matrix inverse/solve for RANSAC and ConvQuad3d (#1408) \r\n- Change intermediate datatype to fix imgwarp (#1413)\r\n\r\n:woman_technologist: :man_technologist: We would like to thank all contributors for this new release !\r\n @AK391  @cclauss @edgarriba @ducha-aiki @isaaccorley @justanhduc @jatentaki @shijianjian @shiyangc-intusurg  @SravanChittupalli @thatbrguy @nvshubhsharma @PWhiddy @oskarflordal @tacoelho @YanivHollander @jhacsonmeza\r\n\r\nIf we forgot someone let us know :sunglasses:",
        "dateCreated": "2021-10-22T12:49:12Z",
        "datePublished": "2021-10-22T13:34:15Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.6.0",
        "name": "Kornia 0.6.0 - High Level and experimental training APIs, bug fixes and much more",
        "tag_name": "v0.6.0",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.6.0",
        "url": "https://api.github.com/repos/kornia/kornia/releases/51851284",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.6.0"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "## :rocket: Release Note (``0.5.11``)\r\n\r\n> Release time: 2021-09-19\r\n\r\n### :new:  New Features\r\n- Add Vision Transformer (ViT) ([#1296](https://github.com/kornia/kornia/pull/1296))\r\n- Add ImageRegistrator API ([#1253](https://github.com/kornia/kornia/pull/1253))\r\n- Add LoFTR inference ([#1218](https://github.com/kornia/kornia/pull/1218))\r\n- Added differentiable Hausdorff Distance (HD) loss ([#1254](https://github.com/kornia/kornia/pull/1254))\r\n- Add PadTo to kornia.augmentation ([#1286](https://github.com/kornia/kornia/pull/1286))\r\n  \r\n### :zap:  Code refactor\r\n- Return all learned modules by default in eval() mode ([#1266](https://github.com/kornia/kornia/pull/1266))\r\n- Enable ImageSequential and VideoSequential to AugmentationSequential (#1231)\r\n- Specify that angles are in radians ([#1287](https://github.com/kornia/kornia/pull/1287))\r\n- Removed deprecated codes for v6.0 ([#1281](https://github.com/kornia/kornia/pull/1281)) \r\n\r\n### :lady_beetle:  Bug fixes\r\n- Fix save_pointcloud_ply fn counting point with inf coordinates ([#1263](https://github.com/kornia/kornia/pull/1263))\r\n- Fixes torch version parse and add temporal packaging dependency ([#1284](https://github.com/kornia/kornia/pull/1284))\r\n- Fix issue of image_histogram2d ([#1295](https://github.com/kornia/kornia/pull/1295))\r\n\r\n:woman_technologist: :man_technologist: We would like to thank all contributors for this new release !\r\n@Abdelrhman-Hosny @ducha-aiki @edgarriba @EStorm21 @lyhyl @shijianjian @thatbrguy\r\n\r\nIf we forgot someone let us know :sunglasses:",
        "dateCreated": "2021-09-19T20:51:12Z",
        "datePublished": "2021-09-19T21:40:37Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/0.5.11",
        "name": "Vision Transformer (ViT), Image Registration, Image Matching APIs and  Hausdorff Distance loss",
        "tag_name": "0.5.11",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/0.5.11",
        "url": "https://api.github.com/repos/kornia/kornia/releases/49812639",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/0.5.11"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "## Kornia release\r\n### [0.5.8] - 2021-08-06\r\n\r\n### Added\r\n- Add the connected components labeling algorithm ([#1184](https://github.com/kornia/kornia/pull/1184))\r\n\r\n### Fixed\r\n- Partial fix for horizontal and vertical flips ([#1166](https://github.com/kornia/kornia/pull/1166))\r\n- Fix even kernel and add test ([#1183](https://github.com/kornia/kornia/pull/1183))\r\n- Fix wrong source points for RandomThinPlateSpline ([#1187](https://github.com/kornia/kornia/pull/1187))\r\n- Fix RandomElasticTransform ignores same_on_batch ([#1189](https://github.com/kornia/kornia/pull/1189))\r\n- Fixed bugs in patchsequential. Remove fill_diagonal operation for better ONNX support ([#1178](https://github.com/kornia/kornia/pull/1178))\r\n\r\n### Changed\r\n- Differentiable image histogram using kernel density estimation ([#1172](https://github.com/kornia/kornia/pull/1172))\r\n\r\n### Contributors\r\n@bkntr @bsuleymanov @ducha-aiki @edgarriba @hal-314 @kingsj0405 @shijianjian\r\n\r\n*If we forgot someone let us know* :sunglasses: ",
        "dateCreated": "2021-08-06T17:43:55Z",
        "datePublished": "2021-08-06T17:47:07Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/0.5.8",
        "name": "Connected Components Labelling algorithm, Differentiable image histogram, and bug fixes",
        "tag_name": "0.5.8",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/0.5.8",
        "url": "https://api.github.com/repos/kornia/kornia/releases/47440045",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/0.5.8"
      },
      {
        "authorType": "User",
        "author_name": "shijianjian",
        "body": "## Kornia 0.5.7 release\r\n\r\n## [0.5.7] - 2021-07-27\r\n\r\n ### Added\r\n - Grayscale to RGB image conversion. ([#1162](https://github.com/kornia/kornia/pull/1162))\r\n - Add keepdim param to tensor_to_image function.  ([#1168](https://github.com/kornia/kornia/pull/1168))\r\n\r\n ### Fixed\r\n - Fix checks on wrong tensor shape condition in depth.py ([#1164](https://github.com/kornia/kornia/pull/1164))\r\n\r\n### Contributors\r\n@bsuleymanov @dhernandez0 @ducha-aiki\r\n\r\n*If we forgot someone let us know* :sunglasses: ",
        "dateCreated": "2021-07-26T17:18:07Z",
        "datePublished": "2021-07-26T17:42:02Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/0.5.7",
        "name": "Grayscale to RGB image conversion. Add keepdim param to tensor_to_image function. ",
        "tag_name": "0.5.7",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/0.5.7",
        "url": "https://api.github.com/repos/kornia/kornia/releases/46785095",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/0.5.7"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "## Kornia 0.5.6 release\r\n\r\n## [0.5.6] - 2021-07-12\r\n\r\n### Added\r\n- Added mix augmentations in containers ([#1139](https://github.com/kornia/kornia/pull/1139))\r\n\r\n### Fixed\r\n- Fixed non-4-dim input error for sequential ([#1146](https://github.com/kornia/kornia/pull/1146))\r\n\r\n### Changed\r\n- Moving bbox-related functionality to bbox module ([#1103](https://github.com/kornia/kornia/pull/1103))\r\n- Optimized version of hls_to_rgb and rgb_to_hls ([#1154](https://github.com/kornia/kornia/pull/1154))\r\n\r\n### Removed\r\n- Remove numpy dependency ([#1136](https://github.com/kornia/kornia/pull/1136))\r\n\r\n### Contributors\r\n@dkoguciuk @edgarriba @lferraz @shijianjian \r\n\r\n*If we forgot someone let us know* :sunglasses: ",
        "dateCreated": "2021-07-12T10:02:31Z",
        "datePublished": "2021-07-12T10:03:43Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/0.5.6",
        "name": "Add Bounding Boxes module, remove Numpy from core and RGB to HLS optimisations",
        "tag_name": "0.5.6",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/0.5.6",
        "url": "https://api.github.com/repos/kornia/kornia/releases/46023770",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/0.5.6"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "## Kornia 0.5.5 release\r\n\r\n### [0.5.5] - 2021-06-27\r\n\r\n### Added\r\n- Added Stereo camera class ([#1102](https://github.com/kornia/kornia/pull/1102))\r\n- Added auto-generated images in docs ([#1105](https://github.com/kornia/kornia/pull/1105)) ([#1108](https://github.com/kornia/kornia/pull/1108)) ([#1127](https://github.com/kornia/kornia/pull/1127)) ([#1128](https://github.com/kornia/kornia/pull/1128)) ([#1129](https://github.com/kornia/kornia/pull/1129)) ([#1131](https://github.com/kornia/kornia/pull/1131))\r\n- Added chinese version README ([#1112](https://github.com/kornia/kornia/pull/1112))\r\n- Added random_apply to augmentaton containers ([#1125](https://github.com/kornia/kornia/pull/1125))\r\n\r\n### Changed\r\n- Change GaussianBlur to RandomGaussianBlur ([#1118](https://github.com/kornia/kornia/pull/1118))\r\n- Update ci with pytorch 1.9.0 ([#1120](https://github.com/kornia/kornia/pull/1120))\r\n- Changed option for mean and std to be tuples in normalization ([#987](https://github.com/kornia/kornia/pull/987))\r\n- Adopt torch.testing.assert_close ([#1031](https://github.com/kornia/kornia/pull/1031)) \r\n\r\n### Removed\r\n- Remove numpy import ([#1116](https://github.com/kornia/kornia/pull/1116))\r\n\r\n### Contributors\r\n@copaah @ducha-aiki @edgarriba @eugene87222 @JoanFM @justanhduc @pmeier @shijianjian \r\n\r\n*If we forgot someone let us know* :sunglasses: ",
        "dateCreated": "2021-06-27T20:29:00Z",
        "datePublished": "2021-06-27T20:53:53Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/0.5.5",
        "name": "PyTorch 1.9.0, Stereo Camera and auto-images in documentation",
        "tag_name": "0.5.5",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/0.5.5",
        "url": "https://api.github.com/repos/kornia/kornia/releases/45272669",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/0.5.5"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "## Kornia 0.5.4 release\r\n### [0.5.4] - 2021-06-11\r\n\r\n### Added\r\n- Add Canny edge detection ([#1020](https://github.com/kornia/kornia/pull/1020))\r\n- Added Batched forward function ([#1058](https://github.com/kornia/kornia/pull/1058))\r\n- Added denormalize homography function [(#1061](https://github.com/kornia/kornia/pull/1061))\r\n- Added more augmentations containers ([#1014](https://github.com/kornia/kornia/pull/1014))\r\n- Added calibration module and Undistort 2D points function ([#1026](https://github.com/kornia/kornia/pull/1026))\r\n- Added patch augmentation container ([#1095](https://github.com/kornia/kornia/pull/1095))\r\n\r\n### Fixed\r\n- Remove lena ([#1059](https://github.com/kornia/kornia/pull/1059)) :)\r\n\r\n### Changed\r\n- Resize regardless of number of dims, considering the last two dims as image ([#1047](https://github.com/kornia/kornia/pull/1047))\r\n- Raise error if converting to unit8 image to gray with float weights ([#1057](https://github.com/kornia/kornia/pull/1057))\r\n- Filter 2D->2d, 3D->3d ([#1069](https://github.com/kornia/kornia/pull/1069))\r\n- Removed augmentation functional module. ([#1067](https://github.com/kornia/kornia/pull/1067))\r\n- Make Morphology compatible with both OpenCV and Scipy ([#1084](https://github.com/kornia/kornia/pull/1084))\r\n\r\n### Contributors\r\n\r\n @asottile @Borda @ducha-aiki @edgarriba  @jhacsonmeza @justanhduc @Manza12 @priba @shijianjian \r\n\r\nSpecial thanks to @Borda @carmocca @asottile for the help to improve the code health of the package.\r\n\r\n*If we forgot someone let us know* :sunglasses: ",
        "dateCreated": "2021-06-11T21:53:51Z",
        "datePublished": "2021-06-11T21:57:47Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/0.5.4",
        "name": "Camera Calibration, Canny edge detection and more adavanced augmentation containers",
        "tag_name": "0.5.4",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/0.5.4",
        "url": "https://api.github.com/repos/kornia/kornia/releases/44489088",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/0.5.4"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "# Kornia 0.5.3 release\r\n\r\n## [0.5.3] - 2021-05-29\r\n\r\n### Added\r\n- Added inverse for augmentations (#1013)\r\n- Add advanced augmentations: RandomFisheye, RandomElasticTransform, RandomThinPlateSpline, RandomBloxBlur ([#1015](https://github.com/kornia/kornia/pull/1015))\r\n\r\n### Fixed\r\n- Correct Sobel test_noncontiguous. Nothing was tested before. ([#1018](https://github.com/kornia/kornia/pull/1018))\r\n- Fixing #795: find_homography_dlt_iterated sometimes fails ([#1022](https://github.com/kornia/kornia/pull/1022))\r\n\r\n### Changed\r\n- Refactorization of the morphology package ([#1034](https://github.com/kornia/kornia/pull/1034))\r\n- Optimised clipping in clahe and some other minor optimisation ([#1035](https://github.com/kornia/kornia/pull/1035))\r\n\r\n\r\n### Contributors\r\n\r\n@Borda @dkoguciuk @edgarriba @Manza12 @lferraz @priba @shijianjian \r\n\r\n*If we forgot someone let us know* :sunglasses: \r\n",
        "dateCreated": "2021-05-30T08:01:30Z",
        "datePublished": "2021-05-30T08:40:56Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/0.5.3",
        "name": "More augmentations, inverse augmentations and optimised CLAHE",
        "tag_name": "0.5.3",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/0.5.3",
        "url": "https://api.github.com/repos/kornia/kornia/releases/43800779",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/0.5.3"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "# Kornia 0.5.2 release\r\n\r\n## [0.5.2] - 2021-05-14\r\n\r\n### Added\r\n- Added unsharp mask filtering ([#1004](https://github.com/kornia/kornia/pull/1004))\r\n\r\n### Fixed\r\n- Fixed angle axis to quaternion order bug ([#926](https://github.com/kornia/kornia/pull/926)) \r\n- Fixed type error for lab_to_rgb conversion when using coremltools. ([#1002](https://github.com/kornia/kornia/pull/1002))\r\n\r\n### Changed\r\n- Mask with unbatched motion from essential choose solution ([#998](https://github.com/kornia/kornia/pull/998)) \r\n\r\n-------------------\r\n\r\nthanks to all your contributions @amonszpart @AnimeshMaheshwari22 @askaradeniz @edgarriba @jatentaki \r\n\r\nThe Kornia Team :nerd_face: \r\n",
        "dateCreated": "2021-05-14T15:23:22Z",
        "datePublished": "2021-05-14T15:24:40Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/0.5.2",
        "name": "Angle axis and Quaternion fixes, added Unsharped Mask",
        "tag_name": "0.5.2",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/0.5.2",
        "url": "https://api.github.com/repos/kornia/kornia/releases/42924152",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/0.5.2"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "# Kornia 0.5.1 release\r\n\r\n## Highlights\r\n\r\nIn this patch release we include the following features\r\n- Fast version of `RandomCropResize`, `RandomCrop`\r\n- Add antialias support in `kornia.geometry.resize`\r\n- Added `HardNet8` deep features\r\n- Experimental support for `torch.float16`\r\n- Added the following modules for augmentations:\r\n   - `ImageToTensor`\r\n   - `RandomInvert`\r\n   - `RandomChannelShuffle`\r\n   - `RandomGaussianNoise`\r\n\r\n## [0.5.1] - 2021-04-30\r\n\r\n### Added\r\n- Added dtype for create_mesh ([#919](https://github.com/kornia/kornia/pull/919))\r\n- Added Hardnet8 ([#955](https://github.com/kornia/kornia/pull/955))\r\n- Added normalize boolean for remap ([#921](https://github.com/kornia/kornia/pull/921))\r\n- Added custom weights option for rgb2gray ([#944](https://github.com/kornia/kornia/pull/944))\r\n- Added fp16 support ([#963](https://github.com/kornia/kornia/pull/963))\r\n- Added ImageToTensor module and resize for non-batched images ([#978](https://github.com/kornia/kornia/pull/978))\r\n- Add more augmentations ([#960](https://github.com/kornia/kornia/pull/960))\r\n- Anti alias resize ([#989](https://github.com/kornia/kornia/pull/989))\r\n\r\n### Changed\r\n- Improve kornia porphology ([#965](https://github.com/kornia/kornia/pull/965))\r\n- Improve cuda ci workflow speed ([#975](https://github.com/kornia/kornia/pull/975))\r\n- Refactor augmentation module ([#948](https://github.com/kornia/kornia/pull/948))\r\n- Implement fast version of crop function in augmentations ([#967](https://github.com/kornia/kornia/pull/967)) \r\n- Implement missing jit ops in kornia.geometry.transform ([#981](https://github.com/kornia/kornia/pull/981)) \r\n\r\n### Fixed\r\n- Fixed RandomAffine translation range check ([#917](https://github.com/kornia/kornia/pull/917) \r\n- Fixed the issue of NaN gradients by adding epsilon in focal loss ([#924](https://github.com/kornia/kornia/pull/924))\r\n- Allow crop size greater than input size. ([#957](https://github.com/kornia/kornia/pull/957))\r\n- Fixed RandomCrop bug ([#951](https://github.com/kornia/kornia/pull/951)) \r\n\r\n### Removed\r\n-  Deprecate some augmentation functionals ([#943](https://github.com/kornia/kornia/pull/943)) ",
        "dateCreated": "2021-04-30T11:57:59Z",
        "datePublished": "2021-04-30T12:07:47Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/0.5.1",
        "name": "Bug fixes, augmentations, fp16 and more",
        "tag_name": "0.5.1",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/0.5.1",
        "url": "https://api.github.com/repos/kornia/kornia/releases/42261912",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/0.5.1"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "# Kornia 0.5.0 release\r\n\r\nIn this release we have focus in bringing more classic Computer Vision functionalities to the PyTorch ecosystem, like morphological operators and more diversity with Deep Local Descriptors, color conversions and drawing functions. In addition, we have worked towards improving the integration with TPU and better support with Torchscript.\r\n\r\n## Highlights\r\n\r\n### Morphological Operators\r\n\r\nAs a highlight we include a [`kornia.morphology`](https://kornia.readthedocs.io/en/latest/morphology.html) that implements several functionalities to work with morphological operators on high-dimensional tensors and differentiability. Contributed by @Juclique \r\n\r\nMorphology implements the following methods: `dilation`, `erosion`, `open`, `close`, `close`, `gradient`, `top_hat` and `black_hat`.\r\n\r\n```python\r\nfrom kornia import morphology as morph\r\n\r\ndilated_image = morph.dilation(tensor, kernel) # Dilation\r\nplot_morph_image(dilated_image) # Plot\r\n```\r\n![image](https://user-images.githubusercontent.com/5157099/111034527-73b01a80-8416-11eb-9012-976db14ef826.png)\r\n\r\nSee a full tutorial here: https://github.com/kornia/tutorials/blob/master/source/morphology_101.ipynb\r\n\r\n### Deep Descriptors\r\n\r\nWe have added a set of local feature-related models: [`MKDDescriptor`](https://kornia.readthedocs.io/en/latest/feature.html#kornia.feature.MKDDescriptor) #841 by implemented and ported to kornia by @manyids2; also we ported [`TFeat`](https://kornia.readthedocs.io/en/latest/feature.html#kornia.feature.TFeat), [`AffNet`](https://kornia.readthedocs.io/en/latest/feature.html?highlight=orinet#kornia.feature.LAFAffNetShapeEstimator), [`OriNet`](https://kornia.readthedocs.io/en/latest/feature.html?highlight=orinet#kornia.feature.OriNet) from authors repos #846.\r\n\r\nHere is [notebook](https://github.com/kornia/kornia-examples/blob/master/MKD_TFeat_descriptors_in_kornia.ipynb),  showing the usage and benefits of new features. We also show how to seamlessly integrate kornia and opencv code via new conversion library [kornia_moons](https://ducha-aiki.github.io/kornia_moons/).\r\n\r\nAlso: exposed `set_laf_orientation` function #869\r\n\r\n![image](https://user-images.githubusercontent.com/4803565/111051654-19827a00-8455-11eb-9edd-d965f3446088.png)\r\n\r\n\r\n### Video Augmentations\r\n\r\nWe include a new operator to perform augmentations with videos [`VideoSequential`](https://kornia.readthedocs.io/en/latest/augmentation.container.html#video-data-augmentation). The module is based in `nn.Sequential` and has the ability to concatenate our existing `kornia.augmentations` for multi-dimensional video tensors. Contributed by @shijianjian \r\n\r\n```python\r\nimport kornia\r\nimport torchvision\r\n\r\nclip, _, _ = torchvision.io.read_video(\"drop.avi\")\r\nclip = clip.permute(3, 0, 1, 2)[None] / 255.  # To BCTHW\r\ninput = torch.randn(2, 3, 1, 5, 6).repeat(1, 1, 4, 1, 1)\r\n\r\naug_list = VideoSequential(\r\n    kornia.augmentation.ColorJitter(0.1, 0.1, 0.1, 0.1, p=1.0),\r\n    kornia.augmentation.RandomAffine(360, p=1.0),\r\n    data_format=\"BTCHW\",\r\n    same_on_frame=False)\r\n)\r\n\r\nout = aug(input)\r\n```\r\n![image](https://user-images.githubusercontent.com/5157099/111078400-7c2b5280-84f5-11eb-854f-71c5e87bc4c3.png)\r\n\r\nSee a full example in the following Colab:\r\nhttps://colab.research.google.com/drive/12dmHNkvEQrG-PHElbCXT9FgCr_aAGQSI?usp=sharing\r\n\r\n### Draw functions\r\n\r\nWe include an experimental functionality [`draw rectangle`](https://kornia.readthedocs.io/en/latest/utils.html#kornia.utils.draw_rectangle) implemented in pure torch.tensor. Contributed by @mmathew23\r\n\r\n```python\r\nrects = torch.tensor([[[110., 50., 310., 275.], [325., 100., 435., 275.]]])\r\ncolor = torch.tensor([255., 0., 0.])\r\n\r\nx_out = K.utils.draw_rectangle(x_rgb, rects, color)\r\n```\r\n![image](https://user-images.githubusercontent.com/5157099/111036305-e2917180-841e-11eb-8884-2e4d89177fe8.png)\r\n\r\nSee full example here: https://colab.research.google.com/drive/1me_DxgMvsHIheLh-Pao7rmrsafKO5Lg3?usp=sharing\r\n\r\n### More user contrib\r\n\r\n- [`binary_focal_loss_with_logits`](https://kornia.readthedocs.io/en/latest/losses.html?highlight=binary_focal_loss#kornia.losses.binary_focal_loss_with_logits) #830 by @xen0f0n\r\n- [`rgb_to_lab`](https://kornia.readthedocs.io/en/latest/color.html?highlight=rgb_to_lab#kornia.color.rgb_to_lab) #823 by @cceyda \r\n- [`GaussianBlur`](https://kornia.readthedocs.io/en/latest/augmentation.module.html?highlight=GaussianBlur#kornia.augmentation.GaussianBlur) augmentation #773 by @ZhiyuanChen \r\n- [`get_gaussian_erf_kernel1d`](https://kornia.readthedocs.io/en/latest/filters.html?highlight=discrete#kornia.filters.get_gaussian_erf_kernel1d), [`get_gaussian_discrete`](https://kornia.readthedocs.io/en/latest/filters.html?highlight=discrete#kornia.filters.get_gaussian_discrete_kernel1d) #736 by @wyli\r\n- [`equalize_clahe`](https://kornia.readthedocs.io/en/latest/enhance.html#kornia.enhance.equalize_clahe) #895 by @lferraz \r\n- `blur_pool2d` #894 by @shijianjian \r\n- [`get_tps_transform`](https://kornia.readthedocs.io/en/latest/geometry.transform.html#kornia.geometry.transform.get_tps_transform),  [`warp_points_tps`](https://kornia.readthedocs.io/en/latest/geometry.transform.html#kornia.geometry.transform.warp_points_tps), [`warp_image_tps`](https://kornia.readthedocs.io/en/latest/geometry.transform.html#kornia.geometry.transform.warp_image_tps) #897 by @catalys1 \r\n-  [`elastic transform 2d`](https://kornia.readthedocs.io/en/latest/geometry.transform.html#kornia.geometry.transform.elastic_transform2d) #853 by @IssamLaradji @edgarriba \r\n\r\n### Infrastructure\r\n\r\n- Update CI to pytorch 1.7.x  and 1.8.0 @edgarriba \r\n- Improve testing matrix with different versions\r\n- TPU support @edgarriba @shijianjian \r\n- Better JIT support @edgarriba  @shijianjian @ducha-aiki \r\n- Improved and test docs @shijianjian @edgarriba \r\n\r\n## Deprecations\r\n\r\n- Deprecated `kornia.geometry.warp` module.\r\n  - `DepthWarper` is now in `kornia.geometry.depth`\r\n  - `HomographyWarper` and related functions are now inside `kornia.geometry.transform`.\r\n- Deprecated `kornia.contrib` module.\r\n  - `max_pool_blurd2d` is now in `kornia.filters`\r\n- Dropped support of Pytorch 1.5.1 #854\r\n\r\n### Warp and Crop\r\n\r\nWe refactored the interface of the functions `warp_perspective`, `warp_affine`, `center_crop`, `crop_and_resize` and `crop_by_boxes` in order to expose to the user the needed parameters by `grid_sample` [`mode`, `padding_mode`, `align_corners`]. #896\r\n\r\nThe param `align_corners` has been set by default to None that maps to True in case the user does not specify.\r\nThis comes from the motivation to match the behavior of the warping functions with OpenCV.\r\n\r\nExample of `warp_perspective`:\r\n```python\r\ndef warp_perspective(src: torch.Tensor, M: torch.Tensor, dsize: Tuple[int, int],\r\n                     mode: str = 'bilinear', padding_mode: str = 'zeros',\r\n                     align_corners: Optional[bool] = None) -> torch.Tensor:\r\n```\r\n\r\n----\r\n\r\nPlease review the full release notes here: https://github.com/kornia/kornia/blob/master/CHANGELOG.md\r\n\r\n## Thanks to all our contributors !!! :tada: :sunglasses: \r\n",
        "dateCreated": "2021-03-17T06:46:39Z",
        "datePublished": "2021-03-17T09:09:56Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.5.0",
        "name": "Morphological operators, Deep descriptors, Video Augmentations and more",
        "tag_name": "v0.5.0",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.5.0",
        "url": "https://api.github.com/repos/kornia/kornia/releases/36444390",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.5.0"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "# Kornia 0.4.1 release\r\n\r\n## Highlights\r\n\r\nWe include new features for 3D augmentations:\r\n\r\n- `RandomCrop3D`\r\n- `CenterCrop3D`\r\n- `RandomMotionBlur3D`\r\n- `RandomEqualize3D`\r\n\r\nFew more core functionalities to work on 3D volumetric tensors:\r\n- `warp_affine3d`\r\n- `warp_perspective3d`\r\n- `get_perspective_transform3d`\r\n- `crop_by_boxes3d`\r\n- `motion_blur3d`\r\n- `equalize3d`\r\n- `warp_grid3d`\r\n\r\n## Details changes\r\n\r\n### Added\r\n- Update docs for `get_affine_matrix2d` and `get_affine_matrix3d` ([#618](https://github.com/kornia/kornia/pull/618))\r\n- Added docs for `solarize`, `posterize`, `sharpness`, `equalize` ([#623](https://github.com/kornia/kornia/pull/623))\r\n- Added tensor device conversion for solarize params ([#624](https://github.com/kornia/kornia/pull/624))\r\n- Added rescale functional and transformation ([#631](https://github.com/kornia/kornia/pull/631))\r\n- Added Mixup data augmentation ([#609](https://github.com/kornia/kornia/pull/609))\r\n- Added `equalize3d` ([#639](https://github.com/kornia/kornia/pull/639))\r\n- Added `decompose 3x4projection matrix` ([#650](https://github.com/kornia/kornia/pull/650))\r\n- Added `normalize_min_max` functionality ([#684](https://github.com/kornia/kornia/pull/684))\r\n- Added `random equalize3d` ([#653](https://github.com/kornia/kornia/pull/653))\r\n- Added 3D motion blur ([#713](https://github.com/kornia/kornia/pull/713))\r\n- Added 3D volumetric crop implementation ([#689](https://github.com/kornia/kornia/pull/689))\r\n  - `warp_affine3d`\r\n  - `warp_perspective3d`\r\n  - `get_perspective_transform3d`\r\n  - `crop_by_boxes3d`\r\n  - `warp_grid3d`\r\n\r\n\r\n### Changed\r\n- Replace convolution with `unfold` in `contrib.extract_tensor_patches` ([#626](https://github.com/kornia/kornia/pull/626))\r\n- Updates Affine scale with non-isotropic values ([#646](https://github.com/kornia/kornia/pull/646))\r\n- Enabled param p for each augmentation ([#664](https://github.com/kornia/kornia/pull/664))\r\n- Enabled RandomResizedCrop batch mode when same_on_batch=False ([#683](https://github.com/kornia/kornia/pull/683))\r\n- Increase speed of transform_points ([#687](https://github.com/kornia/kornia/pull/687))\r\n- Improves `find_homography_dlt` performance improvement and weights params made optional ([#690](https://github.com/kornia/kornia/pull/690))\r\n- Enable variable side resizing in `kornia.resize` ([#628](https://github.com/kornia/kornia/pull/628))\r\n- Added `Affine` transformation as `nn.Module` ([#630](https://github.com/kornia/kornia/pull/630))\r\n- Accelerate augmentations ([#708](https://github.com/kornia/kornia/pull/708))\r\n\r\n### Fixed\r\n- Fixed error in normal_transform_pixel3d ([#621](https://github.com/kornia/kornia/pull/621))\r\n- Fixed pipelining multiple augmentations return wrong transformation matrix (#645)([645](https://github.com/kornia/kornia/pull/645))\r\n- Fixed flipping returns wrong transformation matrices ([#648](https://github.com/kornia/kornia/pull/648))\r\n- Fixed 3d augmentations return wrong transformation matrix ([#665](https://github.com/kornia/kornia/pull/665))\r\n-  Fix the SOSNet loading bug ([#668](https://github.com/kornia/kornia/pull/668))\r\n- Fix/random perspective returns wrong transformation matrix ([#667](https://github.com/kornia/kornia/pull/667))\r\n- Fixes Zca inverse transform ([#695](https://github.com/kornia/kornia/pull/695))\r\n- Fixes Affine scale bug ([#714](https://github.com/kornia/kornia/pull/714))\r\n\r\n## Removed\r\n- Removed `warp_projective` ([#689](https://github.com/kornia/kornia/pull/689))\r\n\r\n## Contributors\r\n@gaurav104 @shijianjian @mshalvagal @pmeier @ducha-aiki @qxcv @FGeri @vribeiro1 @ChetanPatil28 @alopezgit @jatentaki @dkoguciuk @ceroytres @ag14774 \r\n",
        "dateCreated": "2020-10-20T19:19:45Z",
        "datePublished": "2020-10-20T19:22:02Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.4.1",
        "name": "Improve 3D augmentations and 3D transforms low level API",
        "tag_name": "v0.4.1",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.4.1",
        "url": "https://api.github.com/repos/kornia/kornia/releases/32763154",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.4.1"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "# Kornia 0.4.0 release\r\n\r\nIn this release we are including the following main features:\r\n- Support to PyTorch v1.6.0.\r\n- Local descriptors matching, homography and epipolar geometry API.\r\n- 3D augmentations and low level API to work with volumetric data.\r\n\r\n![kornia_medical](http://drive.google.com/uc?export=view&id=1hIiHSPISGSu3k91-NVBUbFd0jztZSRK2)\r\n\r\n# Highlights\r\n\r\n## Local features matching\r\n\r\nWe include an [`kornia.feature.matching`](https://kornia.readthedocs.io/en/latest/feature.html#matching) API to perform local descriptors matching such classical and derived version of the nearest neighbour (NN).\r\n\r\n- [`match_nn`](https://kornia.readthedocs.io/en/latest/feature.html#kornia.feature.match_nn)\r\n- [`match_mnn`](https://kornia.readthedocs.io/en/latest/feature.html#kornia.feature.match_mnn)\r\n- [`match_snn`](https://kornia.readthedocs.io/en/latest/feature.html#kornia.feature.match_snn)\r\n- [`match_smnn`](https://kornia.readthedocs.io/en/latest/feature.html#kornia.feature.match_smnn)\r\n\r\n```python\r\nimport torch\r\nimport kornia as K\r\n\r\ndesc1 = torch.rand(2500, 128)\r\ndesc2 = torch.rand(2500, 128)\r\n\r\ndists, idxs = K.feature.matching.match_nn(desc1, desc2)  # 2500 / 2500x2\r\n```\r\n## Homography and epipolar geometry\r\n\r\nWe also introduce [`kornia.geometry.homography`](https://kornia.readthedocs.io/en/latest/geometry.homography.html) including different functionalities to work with homographies and differentiable estimators based on the DLT formulation and the iteratively-reweighted least squares (IRWLS).\r\n```python \r\n\r\nimport torch\r\nimport kornia as K\r\n\r\npts1 = torch.rand(1, 8, 2)\r\npts2 = torch.rand(1, 8, 2)\r\nH = K.find_homography_dlt(pts1, pts2, weights=torch.rand(1, 8))  # 1x3x3\r\n```\r\n\r\nIn addition, we have ported some of the existing algorithms from [opencv.sfm](https://docs.opencv.org/master/d8/d8c/group__sfm.html) to PyTorch under [`kornia.geometry.epipolar`](https://kornia.readthedocs.io/en/latest/geometry.epipolar.html) that includes different functionalities to work with **Fundamental**, **Essential** or **Projection** matrices, and **Triangulation** methods useful for Structure from Motion problems.\r\n\r\n## 3D augmentations and volumetric\r\n\r\nWe expand the [`kornia.augmentaion`](https://kornia.readthedocs.io/en/latest/augmentation.html) with a series of operators to perform 3D augmentations for volumetric data `BxCxDxHxW`. In this release, we include the following first set of geometric 3D augmentations methods:\r\n\r\n- RandomDepthicalFlip3D (along depth axis)\r\n- RandomVerticalFlip3D (along height axis)\r\n- RandomHorizontalFlip3D (along width axis)\r\n- RandomRotation3D\r\n- RandomAffine3D\r\n\r\nThe API for 3D augmentation work same as with 2D image augmentations:\r\n\r\n```python\r\nimport torch\r\nimport kornia as K\r\n\r\nx = torch.eye(3).repeat(3, 1, 1)\r\naug = K.augmentation.RandomVerticalFlip3D(p=1.0)\r\n\r\nprint(aug(x))\r\n\r\ntensor([[[[[0., 0., 1.],\r\n            [0., 1., 0.],\r\n            [1., 0., 0.]],\r\n<BLANKLINE>\r\n            [[0., 0., 1.],\r\n            [0., 1., 0.],\r\n            [1., 0., 0.]],\r\n<BLANKLINE>\r\n            [[0., 0., 1.],\r\n            [0., 1., 0.],\r\n            [1., 0., 0.]]]]])\r\n```\r\n\r\nFinally, we introduce also a low level API to perform 4D features transformations [`kornia.warp_projective`](https://kornia.readthedocs.io/en/latest/geometry.transform.html#kornia.geometry.transform.warp_projective) and extending the filtering operators to support 3D kernels [`kornia.filter3D`](https://kornia.readthedocs.io/en/latest/filters.html#kornia.filters.filter3D).\r\n\r\n## More 2d operators\r\n\r\nWe expand as well the list of the 2D image augmentations based on the paper [`AutoAugment: Learning Augmentation Policies from Data`](https://arxiv.org/pdf/1805.09501.pdf).\r\n\r\n  - `Solarize`\r\n  - `Posterize`\r\n  - `Sharpness`\r\n  - `Equalize`\r\n  - `RandomSolarize`\r\n  - `RandomPosterize`\r\n  - `RandomShaprness`\r\n  - `RandomEqualize`\r\n\r\n# Improvements\r\n- add zca whitening (#458)\r\n- add epipolar geometry package (#569) \r\n- Jit warp perspective (#574) \r\n- Autoaugment functions. (#571) \r\n- Dog and fix features (#591)\r\n- implement filter3D (#575) \r\n- Implement warp_projective (#587) \r\n- Feature matching and H/F/E estimation for SFM (#552) \r\n- 3D augmentations (#592)\r\n\r\n# Breaking changes\r\n- Create `kornia.enhance` submodule (#614) -> see details in [here](https://github.com/kornia/kornia/pull/614#issue-464264914)\r\n\r\n# Bugs/Fixes\r\n- fixed affine 2d shearing matrix translations (#612)\r\n- Now SIFTdesc throws and exception when the input parameters are incompatible (#598)\r\n- back to group conv backend for filter2d (#600) \r\n- updates sosnet git paths (#606) \r\n\r\n# Docs\r\n- Updated doc & example for augmentation (#583)\r\n- fix Tversky equation (#579)\r\n- clean docs warnings (#604) \r\n-  add kornia.geometry.homography docs (#608) \r\n-  create kornia.geometry.subpix (#610) \r\n\r\n# Dev\r\n- improve conftest fixtures and remove device, dtype imports (#568)\r\n- pin versions for pytest plugins and fix flake8 issues (#580) \r\n- made kornia versions explicit to pytorch version (#597)\r\n",
        "dateCreated": "2020-08-06T23:42:26Z",
        "datePublished": "2020-08-06T23:44:20Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.4.0",
        "name": "3D augmentations, local features matching, homographies and epipolar geometry",
        "tag_name": "v0.4.0",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.4.0",
        "url": "https://api.github.com/repos/kornia/kornia/releases/29261650",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.4.0"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "# Kornia 0.3.2 release\r\n\r\nThis release is just a checkpoint for the features in v0.4.0 with support to PyTorch 1.5.1.\r\n\r\nTo see the new set of features check the [release notes](https://github.com/kornia/kornia/releases/tag/v0.4.0) for Kornia 0.4.0.",
        "dateCreated": "2020-08-06T23:11:03Z",
        "datePublished": "2020-08-06T23:12:32Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.3.2",
        "name": "Kornia 0.3.2 release",
        "tag_name": "v0.3.2",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.3.2",
        "url": "https://api.github.com/repos/kornia/kornia/releases/29261635",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.3.2"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "# Kornia 0.3.1 release\r\n\r\nThis release mainly introduces the following items:\r\n- Add support to Python 3.8\r\n- Exposes and fixes issues around `align_corners`.\r\n- Improve testing infrastructure adding parametrize for different devices and dtype and flake8/mypy support throw pytest by caching intermediate results. Test usage example:\r\n\r\n    ```pytest -v --device cpu,cuda --dtype float16,float32,float64 --flake8 --mypy```\r\n\r\n# Improvements\r\n- Update to python 3.8 (#550)\r\n- Improve testing framework (#560)\r\n- Local feature fixes and nms improvements (#545)\r\n- Random motion blur improvments (#562)\r\n\r\n# Fixes\r\n- Expose align_corners everywhere, where interpolation occurs (#546)\r\n- Soft-argmax test fixes, renaming and enables jit (#553)\r\n\r\n# Bugs\r\n- Fix tests in TestSpatialSoftArgmax2d (#544) \r\n\r\n# Docs\r\n- Updated docstring for augmentation module (#554)",
        "dateCreated": "2020-05-10T12:39:46Z",
        "datePublished": "2020-05-10T13:14:02Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.3.1",
        "name": "Expose align corners, add support to Python 3.8 and more fixes",
        "tag_name": "v0.3.1",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.3.1",
        "url": "https://api.github.com/repos/kornia/kornia/releases/26344811",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.3.1"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "# Kornia 0.3.0 release\r\n\r\nToday we released 0.3.0 which aligns with PyTorch releases cycle and includes:\r\n\r\n- Full support to PyTorch v1.5.\r\n- Semi-automated GPU tests coverage.\r\n- Documentation has been reorganized [[docs]](https://kornia.readthedocs.io/en/latest/)\r\n- Data augmentation API compatible with torchvision v0.6.0.\r\n- Well integration with ecosystem e.g. Pytorch-Lightning.\r\n\r\nFor more detailed changes check out [v0.2.1](https://github.com/kornia/kornia/releases/tag/v0.2.1) and [v0.2.2](https://github.com/kornia/kornia/releases/tag/v0.2.2).\r\n\r\n# Highlights\r\n\r\n## Data Augmentation\r\n\r\nWe provide [`kornia.augmentation`](https://kornia.readthedocs.io/en/latest/augmentation.html#) a high-level framework that implements `kornia-core` functionalities and is fully compatible with torchvision supporting batched mode, multi device cpu, gpu, and xla/tpu (comming), auto differentiable and able to retrieve (and chain) applied geometric transforms. To check how to reproduce torchvision in kornia refer to this [Colab: Kornia vs. Torchvision](https://colab.research.google.com/drive/1T20UNAG4SdlE2n2wstuhiewve5Q81VpS#revisionId=0B4unZG1uMc-WdzZqaStjVzZ1U0hHOHphQkgvcGFCZ1RlUzJvPQ/) @shijianjian \r\n\r\n\r\n```python\r\nimport kornia as K\r\nimport torchvision as T\r\n\r\n# kornia\r\n\r\ntransform_fcn = torch.nn.Sequential(\r\n  K.augmentation.RandomAffine(\r\n    [-45., 45.], [0., 0.5], [0.5, 1.5], [0., 0.5], return_transform=True),\r\n  K.color.Normalize(0.1307, 0.3081),\r\n)\r\n\r\n# torchvision\r\n\r\ntransform_fcn = T.transforms.Compose([\r\n  T.transforms.RandomAffine(\r\n    [-45., 45.], [0., 0.5], [0.5, 1.5], [0., 0.5]),\r\n  T.transforms.ToTensor(),\r\n  T.transforms.Normalize((0.1307,), (0.3081,)),\r\n])\r\n```\r\n\r\n## Ecosystem compatibility\r\n\r\nKornia has been designed to be very flexible in order to be integrated in other existing frameworks. See the example below about how easy you can define a custom data augmentation pipeline to later be integrated into any training framework such as [Pytorch-Lighting](https://pytorch-lightning.readthedocs.io/en/latest/). We provide examples in [[here]](https://github.com/kornia/kornia-examples/blob/master/kornia_lightning_mnist_gpu.ipynb) and [[here]](https://github.com/PyTorchLightning/lightning-Covid19/blob/master/lightning_covid19/model/densenet.py#L44).\r\n\r\n```python\r\nclass DataAugmentatonPipeline(nn.Module):\r\n    \"\"\"Module to perform data augmentation using Kornia on torch tensors.\"\"\"\r\n    def __init__(self, apply_color_jitter: bool = False) -> None:\r\n        super().__init__()\r\n        self._apply_color_jitter = apply_color_jitter\r\n\r\n        self._max_val: float = 1024.\r\n\r\n        self.transforms = nn.Sequential(\r\n            K.augmentation.Normalize(0., self._max_val),\r\n            K.augmentation.RandomHorizontalFlip(p=0.5)\r\n        )\r\n\r\n        self.jitter = K.augmentation.ColorJitter(0.5, 0.5, 0.5, 0.5)\r\n\r\n    @torch.no_grad()  # disable gradients for effiency\r\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\r\n        x_out = self.transforms(x)\r\n        if self._apply_color_jitter:\r\n            x_out = self.jitter(x_out)\r\n        return x_out\r\n```\r\n\r\n## GPU tests\r\n\r\nNow easy to run GPU tests with `pytest --typetest cuda`\r\n",
        "dateCreated": "2020-04-27T08:47:32Z",
        "datePublished": "2020-04-27T09:25:45Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.3.0",
        "name": "PyTorch 1.5 support, accelerated Data Augmentation, stable GPU testing and easy ecosystem integration",
        "tag_name": "v0.3.0",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.3.0",
        "url": "https://api.github.com/repos/kornia/kornia/releases/25911197",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.3.0"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "# Kornia 0.2.2 Release Notes\r\n\r\nThis release is a checkpoint with minimum data augmentation API stability plus fixing some GPU tests before kornia upgrades to PyTorch v.1.5.0.\r\n\r\n* API changes\r\n* Improvements\r\n* Bug Fixes\r\n* Documentation\r\n\r\n# API changes\r\n- Decoupled return_transform from apply_* function (#534)\r\n\r\n# Improvements\r\n-  improve setup packaging and build manywheel script (#543) \r\n\r\n# Bug Fixes\r\n- fix broken gpu tests (#538)\r\n- update sosnet urls (#541) \r\n\r\n# Documentation\r\n- reorganises color docs and adds ycbcr (#540) \r\n- reorganise documenation in subsections (#542) ",
        "dateCreated": "2020-04-26T14:12:21Z",
        "datePublished": "2020-04-26T14:35:55Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.2.2",
        "name": "Data augmentation and GPU tests checkpoint before PyTorch v1.5.0",
        "tag_name": "v0.2.2",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.2.2",
        "url": "https://api.github.com/repos/kornia/kornia/releases/25895257",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.2.2"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "# Kornia 0.2.1 Release Notes\r\n\r\n* Highlights\r\n* API changes\r\n* New Features\r\n* Improvements\r\n* Bug Fixes\r\n* Performance\r\n\r\n# Highlights\r\n\r\nIn this release we support compatibility between `kornia.augmentation` and `torchvision.transforms`. \r\n\r\nWe now support all the same existing operations with torch.Tensor in the GPU with extra features such as returning for each operator the transformation matrix generated to produce such transformation.\r\n\r\n```python\r\nimport kornia as K\r\nimport torchvision as T\r\n\r\n# kornia\r\n\r\ntransform_fcn = torch.nn.Sequential(\r\n  K.augmentation.RandomAffine(\r\n    [-45., 45.], [0., 0.5], [0.5, 1.5], [0., 0.5], return_transform=True),\r\n  K.color.Normalize(0.1307, 0.3081),\r\n)\r\n\r\n# torchvision\r\n\r\ntransform_fcn = T.transforms.Compose([\r\n  T.transforms.RandomAffine(\r\n    [-45., 45.], [0., 0.5], [0.5, 1.5], [0., 0.5]),\r\n  T.transforms.ToTensor(),\r\n  T.transforms.Normalize((0.1307,), (0.3081,)),\r\n])\r\n```\r\nCheck the online documentations with the updated API [[DOCS]](https://kornia.readthedocs.io/en/latest/augmentation.html)\r\n\r\nCheck this Google Colab to see how to reproduce same results [[Colab]](https://colab.research.google.com/drive/1T20UNAG4SdlE2n2wstuhiewve5Q81VpS#revisionId=0B4unZG1uMc-WdzZqaStjVzZ1U0hHOHphQkgvcGFCZ1RlUzJvPQ)\r\n\r\n## `kornia.augmentation` as a framework\r\n\r\nIn addition, we have re-designed `kornia.augmentation` such in a way that users can easily contribute with more operators, or just use it as a framework to create their custom operators.\r\n\r\nEach of the `kornia.augmentation` modules inherit from [`AugmentationBase`](https://github.com/kornia/kornia/blob/master/kornia/augmentation/augmentation.py#L23) and one can easily define a new operator by creating a subclass and overriding a couple of methods.\r\n\r\nLet's take a look at a custom `MyRandomRotation` . The class inherits from `AugmentationBase` making it a `nn.Module` so that can be stacked in a `nn.Sequential` to compute chained transformations.\r\n\r\nTo implement a new functionality two things needed: override **`get_params`** and **`apply`** \r\n\r\nThe `get_params` receives the shape of the input tensor and returns a dictionary with the parameters to use in the `apply` function.\r\n\r\nThe `apply`function receives as input a tensor and the dictionary defined in `get_params`; and returns a tuple with the transformed input and the transformation applied to it.\r\n\r\n```python\r\nclass MyRandomRotation(AugmentationBase):\r\n    def __init__(self, angle: float, return_transform: bool = True) -> None:\r\n      super(MyRandomRotation, self).__init__(self.apply, return_transform)\r\n      self.angle = angle\r\n\r\n    def get_params(self, batch_shape: torch.Size) -> Dict[str, torch.Tensor]:\r\n      angles_rad torch.Tensor = torch.rand(batch_shape) * K.pi\r\n      angles_deg = kornia.rad2deg(angles_rad) * self.angle\r\n      return dict(angles=angles_deg)\r\n\r\n    def apply(self, input: torch.Tensor, params: Dict[str, torch.Tensor]):\r\n      # compute transformation\r\n      angles: torch.Tensor = params['angles'].type_as(input)\r\n      center = torch.tensor([[W / 2, H / 2]]).type_as(input)\r\n      transform = K.get_rotation_matrix2d(\r\n        center, angles, torch.ones_like(angles))\r\n\r\n      # apply transformation\r\n      output = K.warp_affine(input, transform, (H, W))\r\n\r\n      return (output, transform)\r\n\r\n# how to use it\r\n\r\n# load an image and cast to tensor\r\nimg1: torch.Tensor = imread(...)  # BxDxHxW\r\n\r\n# instantiate and apply the transform\r\naug = MyRandomRotation(45., return_transformation=True)\r\n\r\nimg2, transform = aug(img1)  # BxDxHxW - Bx3x3\r\n```\r\n\r\n# New Features\r\n## kornia.color\r\n- Implement RGB to XYZ (#436) \r\n- Implement RGB to LUV (#442)\r\n- Implement histogramd2 (#530)\r\n\r\n## kornia.feature\r\n- Implement hardnet descriptor (#498) \r\n- Implement deep descriptor sosnet (#521) \r\n\r\n## kornia.jit\r\n- Create kornia.jit module and exposes rgb_to_grayscale (#261) \r\n\r\n# API Changes\r\n- Remove PIL dependency (#512) \r\n- Remove float casting in image_to_tensor (#497) \r\n\r\n#  Improvements\r\n- Adds gradcheck for RandomCrop and RandomResizedCrop (#439)\r\n- Update spatial_soft_argmax.py (#496) \r\n- Add epsilon value to make hessian matrix robust (#504) \r\n- Add normalize_points flag in depth to 3d (#511) \r\n- Functional augmentation performance test against Torchvision (#482)\r\n- AffineTransformation alignment and other fixes (#514) \r\n\r\n# Performance\r\n- Filter speed up conditional (#433)\r\n  - Improves by far the time performance for filtering.\r\n-  Speed-up warp_affine and fix bugs in RandomAffine (#474)\r\n- Improve homography warper (#528)\r\n\r\n## Docs\r\n- Make link work for PSNRLoss (#449) \r\n- Change psnr to psnr_loss in docs (#450) \r\n- Fix import problem and fix docs for LuvToRgb and PSNR (#447) \r\n- Fix outdated example (#465) \r\n- Update color_adjust.py (#479) \r\n- Missing commas in bibtex (#500) \r\n\r\n## Bug fixes\r\n- Fix device problem in test (#456)\r\n- Bug fixed in device tests (#475) \r\n- Add epsilon value to sobel to improve backprop stability (#513) ",
        "dateCreated": "2020-04-21T05:17:28Z",
        "datePublished": "2020-04-21T08:24:44Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.2.1",
        "name": "Data augmentation framework, deep descriptors and more.",
        "tag_name": "v0.2.1",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.2.1",
        "url": "https://api.github.com/repos/kornia/kornia/releases/25627106",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.2.1"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "# Kornia 0.2.0 Release Notes\r\n\r\n* Highlights\r\n* New Features\r\n  * kornia.color\r\n  * kornia.feature\r\n  * kornia.geometry\r\n  * kornia.losses\r\n* Improvements\r\n* Bug Fixes\r\n\r\nKornia v0.2.0 release is now available.\r\n\r\nThe release contains over 50 commits and updates support to PyTorch 1.4. This is the result of a huge effort in the desing of the new data augmentation module, improvements in the set of the color space conversion algorithms and a refactor of the testing framework that allows to test the library using the cuda backend.\r\n\r\n# Highlights\r\n\r\n## Data Augmentation API\r\n\r\nFrom this point forward, we will give support to the new data augmentation API. The [`kornia.augmentation`](https://kornia.readthedocs.io/en/latest/augmentation.html) module mimics the best of the existing data augmentation frameworks such `torchvision` or `albumentations` all re-implemented assuming as input `torch.Tensor` data structures that will allowing to run the standard transformations (geometric and color) in batch mode in the GPU and backprop through it.\r\n\r\nIn addition, a very interesting feature we are very proud to include, is the ability to return the transformation matrix for each of the transform which will make easier to concatenate and optimize the transforms process.\r\n\r\nA quick overview of its usage:\r\n```python\r\n\r\nimport torch\r\nimport kornia\r\n\r\ninput: torch.Tensor = load_tensor_data(....)  # BxCxHxW\r\n\r\ntransforms = torch.nn.Sequential(\r\n    kornia.augmentation.RandomGrayscale(),\r\n    kornia.augmentation.RandomAffine(degrees=(-15, 15)),\r\n)\r\n\r\nout: torch.Tensor = transforms(input)         # CPU\r\nout: torch.Tensor = transforms(input.cuda())  # GPU\r\n\r\n# same returning the transformation matrix\r\n\r\ntransforms = torch.nn.Sequential(\r\n    kornia.augmentation.RandomGrayscale(return_transformation=True),\r\n    kornia.augmentation.RandomAffine(degrees=(-15, 15), return_transformation=True),\r\n)\r\n\r\nout, transform = transforms(input) # BxCxHxW , Bx3x3\r\n```\r\n\r\nThis are the following features found we introduce in the module:\r\n\r\n* BaseAugmentation (#407)\r\n* ColorJitter (#329)\r\n* RandomHorizontalFlip (#309)\r\n* MotionBlur (#328)\r\n* RandomVerticalFlip (#375)\r\n* RandomErasing (#344)\r\n* RandomGrayscale (#384)\r\n* Resize (#394)\r\n* CenterCrop (#409)\r\n* RandomAffine (#403)\r\n* RandomPerspective (#403)\r\n* RandomRotation (#397, #418)\r\n* RandomCrop (#408)\r\n* RandomResizedCrop (#408)\r\n* Grayscale\r\n\r\n## GPU Test\r\n\r\nWe have refactored our testing framework and we can now easily integrate GPU tests within our library. At this moment, this features is only available to run locally but very soon we will integrate with CircleCI and AWS infrastructure so that we can automate the process.\r\n\r\nFrom root one just have to run:  `make test-gpu`\r\n\r\nTests look like this:\r\n```python\r\nimport torch\r\nfrom test.common import device\r\n\r\ndef test_rgb_to_grayscale(self, device):\r\n        channels, height, width = 3, 4, 5\r\n        img = torch.ones(channels, height, width).to(device)\r\n        assert kornia.rgb_to_grayscale(img).shape == (1, height, width)\r\n```\r\nRef PR:\r\n* parametrize test functions to accept torch.device cpu/cuda @edgarriba @ducha-aiki da793cd 0fcb85e\r\n\r\n# New Features\r\n\r\n## kornia.color\r\n\r\nWe have added few more algorithms for color space conversion:\r\n\r\n* rgb_to_hsv (#299)\r\n* rgb_to_hls (#342)\r\n* rgb_to_ycbcr (#345)\r\n* ycbcr_to_rgb (#345)\r\n* rgb_to_yuv (#337)\r\n* yuv_to_rgb (#337)\r\n* rgb_to_rgba (#401)\r\n* rgba_to_rgb (#401)\r\n* bgr_to_bgra (#401)\r\n* bgra_to_bgr (#401)\r\n* bgr_to_gray (#266)\r\n* add_weighted (#295)\r\n\r\n## kornia.geometry\r\n\r\n* Implement `kornia.hflip`, `kornia.vflip` and `kornia.rot180` (#268)\r\n* Implement `kornia.transform_boxes` (#368)\r\n\r\n## kornia.losses\r\n\r\n* Implements to total_variation loss (#250)\r\n* Implement PSNR loss (#272)\r\n\r\n## kornia.feature\r\n\r\n* Added convenience functions for work with LAF: get keypoint, orientation (#340)\r\n\r\n# Improvements\r\n\r\n* Fixed conv_argmax2d/3d behaviour for even-size kernel and added test (#227)\r\n* Normalize accepts floats and allows broadcast over channel dimension (#236)\r\n* Single value support for normalize function (#301) \r\n* Added boundary check function to local features detector (#254)\r\n* Correct crop_and_resize on aspect ratio changes. (#305)\r\n* Correct adjust brightness and contrast (#304)\r\n* Add tensor support to Hue, Saturation and Gamma (#324)\r\n* Double image option for scale pyramid (#351) \r\n* Filter2d speedup for older GPUs (#356)\r\n* Fix meshgrid3d function (#357)\r\n* Added support for even-sized filters in filter2d (#374)\r\n* Use latest version of CircleCI (#373)\r\n* Infer border and padding mode to homography warper (#379)\r\n* Apply normalization trick to conv_softmax (#383)\r\n* Better nms (#371)\r\n  * added spatial gradient 3d\r\n  * added hardnms3d and tests for hardnms 2d\r\n  * quadratic nms interp\r\n  * update the tests because of changed gaussian blur kernel size in scale pyramid calculation\r\n  * no grad for spatial grad\r\n* Focal loss flat (#393)\r\n* Add optional mask parameter in scale space (#389)\r\n* Update to PyTorch 1.4 (#402)\r\n\r\n# Bug fixes\r\n\r\n* Add from homogeneous zero grad test and fix it (#369)\r\n* Filter2d failed with noncontiguous input (view --> reshape) (#377)\r\n* Add ceil_mode to maxblur pool to be able to be used in resnets (#395) \r\n\r\n# Breaking Changes\r\n\r\n* crop_and_resize\r\nbefore: \"The tensor must have the shape of Bx4x2, where each box is defined in the following order: top-left, top-right, bottom-left and bottom-right. The coordinates order must be in y, x respectively\"\r\nafter: \"The tensor must have the shape of Bx4x2, where each box is defined in the following (clockwise) order: top-left, top-right, bottom-right and bottom-left. The coordinates must be in the x, y order.\"\r\n\r\n\r\n\r\n\r\nAs usual, thanks to the community to keep this project growing.\r\nHappy coding ! :sunrise_over_mountains:",
        "dateCreated": "2020-01-27T15:21:16Z",
        "datePublished": "2020-01-27T18:23:47Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.2.0",
        "name": "Data augmentation API, color conversion improvements, GPU tests and more",
        "tag_name": "v0.2.0",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.2.0",
        "url": "https://api.github.com/repos/kornia/kornia/releases/23120148",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.2.0"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "# Table of Contents\r\n\r\nWe have just released **Kornia: a differentiable computer vision library for PyTorch.**\r\n\r\nIt consists of a set of routines and differentiable modules to solve generic computer vision problems. At its core, the package uses PyTorch as its main backend both for efficiency and to take advantage of the reverse-mode auto-differentiation to define and compute the gradient of complex functions.\r\n\r\nInspired by OpenCV, this library is composed by a subset of packages containing operators that can be inserted within neural networks to train models to perform image transformations, epipolar geometry, depth estimation, and low level image processing such as filtering and edge detection that operate directly on tensors.\r\n\r\nIt has over 300 commits and majorly refactors the whole library including over than 100 functions to solve generic Computer Vision problems. \r\n\r\n## Highlights\r\n\r\nVersion 0.1.4 includes a reorganization of the internal API grouping functionalities that consists of the following components:\r\n\r\n- **kornia** | a Differentiable Computer Vision library like OpenCV, with strong GPU support.\r\n- **kornia.color** | a set of routines to perform color space conversions.\r\n- **kornia.contrib** | a compilation of user contrib and experimental operators.\r\n- **kornia.feature** | a module to perform local feature detection.\r\n- **kornia.filters** | a module to perform image filtering and edge detection.\r\n- **kornia.geometry** | a geometric computer vision library to perform image  transformations, 3D linear algebra and conversions using differen  camera models.\r\n- **kornia.losses** | a stack of loss functions to solve different vision tasks.\r\n- **kornia.utils** | image to tensor utilities and metrics for vision problems.\r\n\r\nBig contribution in `kornia.features`:\r\n\r\n- Implemented anti-aliased local patch extraction.\r\n- Implemented classical local features cornerness functions: Harris, Hessian, Good Features To Track.\r\n- Implemented basic functions for work with local affine features and their patches.\r\n- Implemented convolutional soft argmax 2d and 3d operators for differentable non-maxima suppression.\r\n- implemented second moment matrix affine shape estimation, dominant gradient orientation and SIFT patch descriptor.\r\n\r\n## Infrastructure\r\n\r\n- Migration to CircleCI towards GPU testing 30099b4b0481f4151b893f77d7bf297ee47d268b\r\n- Added [Code of Conduct](https://github.com/arraiyopensource/kornia/blob/master/CODE_OF_CONDUCT.md) file 5e0848a2d41780d632632afb81e0371e9dca6a33\r\n- Redefined the [CONTRIBUTING](https://github.com/arraiyopensource/kornia/blob/master/CONTRIBUTING.rst) notes\r\n- Enforce python minimal Python 3.6 usage 34e21e5f81a0376fc8bb45da52003f20a101d591\r\n- Creation of an external  [repo](https://github.com/arraiyopensource/arraiyopensource.github.io) to host the website [www.kornia.org](www.kornia.org).\r\n\r\n## Breaking Changes\r\n\r\n- Removed nms and normalization from Harris response function 2209807ce8db8fe82eabbe6ca51e6370beea2934\r\n- Renames `GaussianBlur -> GaussianBlur2d` and added an input to specify pad b0c522e60ef4c82a3d1881dd5901a25d7a4a02c5\r\n- Chaneged batch support for tensor2img and img2tensor 705a82f1ca308087b7d62d8ce452cde1aeeaabae\r\n- Fixed torch.clamp for homogeneous division 506b0c98ed245373544732dd49fc4612d7075501\r\n\r\n## New Features\r\n\r\n- Several functionalities for Local Affine Frame (LAF): `extract_patches_from_pyramid`, `extract_patches_simple`, `normalize_laf`, `ellipse_to_laf`, `make_upright`, `scale_laf`, `get_laf_scale` 0a3cbb02850ac78059e0615da93144b5a64d3330\r\n- Differentiable SIFT descriptor 7f0eb809f1509c452d85000fd002b12c22e358ca\r\n- Added implementation of the differentiable spatial to numerical (DSNT) layer and related operations. abb4afabe1a37082e8938cfe7f227e57042d9803\r\n- Spatial gradient 1d 362adfc1af06e0abd945e84bf00c5b8a437f3aa3\r\n- Scale pyramid for local features detection 413051eb4c1b36fe3548a65cee9ab2d8ba45086f\r\n- Added `geometry.depth` submodule including: `depth_to_3d`, `depth_to_normals`, `warp_frame_depth` d1dedb8d37f99b752467ed4acaf4f767afbbad49\r\n- Implement Gaussian Pyramid bc586cb4bf8454d33fed721bc6f045767191374e\r\n- Implement `Filter2D` to apply arbitrary depthwise 2d kernels 94b56f2d43ed87a259aca3e6313d0f7a1222baf5\r\n- Implement to save/load pointclouds 4f32351c0dfd2d0d1779e9eb1d0028e3d3b904ab\r\n- implement `project_points` 636f4f5338e4fc1b6d32140c6f1febae3b64eb96\r\n- Implement `unproject_points` b02f403feaf1fdeb574fb87e1d70157ec0b4dbff\r\n- Implement `denormalize_coordinates` b07ec45410f45469bad2067ce03b83dddcabb7c0\r\n- Implement `harris_corner` detector 977a1f6a8c7beef9c339fdd695032dec2705c7d3\r\n- Implement `non_maxima_suppression_2d` 84cc1287fcd9df2a437a2d25a61f171097047a76\r\n- Implement `median_filter` 6b6cf0543028dcf3bfb25a0ae9104e6ade26037e\r\n- Implement `blur_filter` d4c8df933570fa95546e84517a6d676e302e6e7d\r\n- Implement `sobel_filter` operator 9abe4c5afdbe486baadf07b427ad5468d57da603\r\n- Implement `max_blur_pool_2d` 621be3b59055f000896c45fe33a28fa3ca680841\r\n- Implement `pyrup` and `pyrdown` a4e110cd47dd6c7792751fb7294d068b7655486a\r\n- Implemen `crop_and_resize` 41b4fed573c37c7310e4d7e03b73a54bce1eb2ab\r\n- Implement `center_crop` b1188d50f7ecae001832e05e606ca55d0d630ae6\r\n- Implement `inverse_affine_matrix` 6e10fb9a0859ef35f82b6e2dfd58af828bda7a8c\r\n- Implement opencv like `remap` function b0401deac4b54e201095705ec8c18eabe943cd2b\r\n- Implement `affine` ceb3faf3b89596ba23bdc7e0f616b218edf997df\r\n- Implement `shear` 81c5a2798f00663ee64ff74db87340daa6edb08d\r\n- Implement `scale` 75a84a373e9ce142fb4a1ac0d7fde8f3790b861c\r\n- Implement `translate` 11af4dde591258e057d1973bb00529f49fa6d63f\r\n- Implement `rotate` 89c6d964c5a18254adf73a5f8da00d8a5068e7bc\r\n- Implement Laplacian filter 5e3a89a2e630ae9d0199ff388217e2d5a11c4f86\r\n- Implement `rgb_to_gray` 9a2bea6057f4cf99eb6c16c96d5a1c952d95b4b2\r\n- Implement vectorised `confusion_matrix` f30606209f20f9f2d879b2eaec80215cc274a80a\r\n- Implement `normalization` on tensors 4c3f8fa52d3b9d86843716a99d5c833e80929212\r\n- Implement `rgb_to_bgr` e25f6a4900ede8786a0eee38f58f4ffd0908535a\r\n- Implement `hsv_to_rgb` 9726872019d71c3b9a3e7cabaf51e77a96220a45\r\n- Implement `adjust_brightness` b8fd8b6bce1707ea8a0b2fd5ba9498fe10d586b8\r\n\r\n## Bug Fixes\r\n\r\n- Normalize filtering functions kernels a301e3cf6192aff4cbbadda979cc48b17504684f\r\n- Fix the bug in spatial gradient with padding 5635e45830461d9f40da68a3318755d50a425b17\r\n- Disable JIT tests 464931720d7b2609ca25f95f29b7a47ba5af2e2f\r\n- Fix `pyrdown` with `avg_pool2d` b83514302232cf8bc31c30f3981a168dd7b55e39\r\n- Fix formulation issue in `rotation_matrix_to_quaternion` 58c6e8e7038ad1ca4d9051e04b54b6a42fd72a74\r\n- Switch `torch.gesv -> torch.solve` in `get_perspective_transform` c347a41e85eae78d73ea821b06623383d7a142a4\r\n- Fix and refactor `test_warp_perspective` d19121effb69d4c17d53f6bea010941cb7730f32\r\n- Fixed and updated the `quaternion` related docs to reflect `quaternions` 0161f65831ab9f975575586c4c1b1aec6e8a6b11\r\n- Remove some unused test functions a64a8fb80e5e666caefc806325a2c338ee50f81f\r\n\r\n## Contributors\r\n- @anibali \r\n- @carlosb1 \r\n- @ducha-aiki \r\n- @dvd42 \r\n- @edgarriba \r\n- @jiangwei221\r\n- @priba \r\n- @varunagrawal ",
        "dateCreated": "2019-10-02T12:43:28Z",
        "datePublished": "2019-10-05T10:57:00Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.1.4",
        "name": "Kornia: Open Source Differentiable Computer Vision Library for PyTorch",
        "tag_name": "v0.1.4",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.1.4",
        "url": "https://api.github.com/repos/kornia/kornia/releases/20366870",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.1.4"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "Package\r\n=======\r\n- Migrated the project to Arraiy Open Source Organization: https://github.com/arraiyopensource/torchgeometry. 48ad11f39f69be95fe35c164414ad58e0034f5d4\r\n- Update with support of PyTorch v1.0.1. In fact, we test each time against nightly builds. 5c9d9ae1ccf13fc2381d62be6f5b4c81c265608b\r\n- Fix issue with pip package PyTorch minimal version. Now we require at least v1.0.0. 6e16734d68074f22fb67a8b1c4418e4917e5b1f1\r\n- Package version file is auto-generate and too keep tracked ``sha``. f337b3c131b2482a961f5aa895a9b344814bff5a\r\n- Added codecov support  to keep tracked tested code. e609b2112f25806d02364681d57a29b977950f59\r\n\r\nBreaking Changes\r\n===============\r\n- Refactor ``DepthWarper`` API - now accepts ``PinholeCamera`` objects as parameters:\r\n```python\r\n>>> # pinholes camera models\r\n>>> pinhole_dst = tgm.PinholeCamera(...)\r\n>>> pinhole_src = tgm.PinholeCamera(...)\r\n>>> # create the depth warper, compute the projection matrix\r\n>>> warper = tgm.DepthWarper(pinhole_dst, height, width)\r\n>>> warper.compute_projection_matrix(pinhole_src)\r\n>>> # warp the destionation frame to reference by depth\r\n>>> depth_src = torch.ones(1, 1, 32, 32)  # Nx1xHxW\r\n>>> image_dst = torch.rand(1, 3, 32, 32)  # NxCxHxW\r\n>>> image_src = warper(depth_src, image_dst)  # NxCxHxW\r\n```\r\n\r\nNew Features\r\n===========\r\n - Added new ``PinholeCamera`` API to represent pinhole camera models. b6ec592bc4d00ba942d0f3d2085534acdefd783f\r\n![pinhole_model](https://user-images.githubusercontent.com/5157099/54354104-1847c800-4656-11e9-9fad-867cbcd67fa7.png)\r\n- Refactor and moved code from ``conversions.py`` and created a dedicated module for linear transforms ``transformations.py``. a1c25b1c5e3a5ac4e5109ea0e1b7256ba8e4ee56\r\n  - ``boxplus_transformation``, ``boxminus_transformation``, ``inverse_transformation``, ``transform_points``.\r\n- Added a collection of losses:\r\n  - Image: SSIM f08812168984174d6054c5b21298963cdf421cd8\r\n  - Depth: InverseDepthSmoothnessLoss 42a1d22df0691444664c182eae7fc10acaa428cc\r\n  - Semantic segmentation:\r\n    - ``Diceloss`` 9b0fddf9055cb9a948856d087b52073551c44129\r\n    - ``TerskyLoss`` 89246d269739f89ed0731f52ff543863882efa48\r\n    - ``FocalLoss`` ffe4cb1b74ecb81baef05f97fe6c62f176336fd7\r\n- Added ``SpatialSoftArgmax2d`` operator to extract 2D coordinates from probability maps. cf7bb292dbe19242e0b207a8747da601a27e4cf3\r\n- Added ``extract_tensor_patches`` routine similar to ``tf.extract_image_patches`` but for multidimensional tensors instead of images. f60fa57b4dcf9462e443ee71bf571cc6e31a7939\r\n- Added ``boxplus_transform`` and ``boxminus_transform`` to compose or compute relative pose functions. e0882ea32bb13e62275b678ddb60915058397d35\r\n\r\nBug Fixes\r\n========\r\n- Fixed ``DepthWarper`` in order to accept mini-batch computation. 7175b4f93f5cb855eb8ab4011c33e79cb32bf3fa\r\n- Added missing tests for ``warp_affine``. 57cbd29aa291dc0cf60e6cff6b0665c91db39330\r\n- Fixed and refactored ``quaternion_to_axis_angle`` and ``axis_angle_to_quaternion`` to avoid nans. 4aa0bca9cd2ab95b3edb7d043ff16d473b2e04b7\r\n\r\nTest\r\n====\r\n- Updated code with python typing: https://docs.python.org/3/library/typing.html to perform static analysis tests using MyPy: http://mypy-lang.org 3c02b58e1d4de3e7583020c332a7b982c9e97d74\r\n- Added pytest fixtures to split between CPU/CUDA tests. Additionally, we added Makefile commands to launch the tests. 1aff7f65d6535e88abc0d5383846be75d37e4af9\r\n- Improved ``InversePose`` tests. d6a508c7600e5e464d6910028f7771f8d18fe722\r\n- Improved ``HomographyWarper`` tests.  43bd8c2ea669d89d57a063998b491be18d2ab39a\r\n\r\ncontributors:\r\n- @edgarriba \r\n- @carlosb1 \r\n- @Wizaron \r\n- @prlz77 \r\n- @kajal-puri \r\n",
        "dateCreated": "2019-03-12T12:48:55Z",
        "datePublished": "2019-03-14T11:50:57Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.1.2",
        "name": "support for PyTorch v1.0.1, PinholeCamera API, losses collections: FocalLoss, DiceLoss, SpatialSoftArgmax2d, MyPy static analysis and Homogeneous transforms module.",
        "tag_name": "v0.1.2",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.1.2",
        "url": "https://api.github.com/repos/kornia/kornia/releases/16073209",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.1.2"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "Table of Contents\r\n-------------------------\r\n  - Breaking Changes\r\n  - New Features\r\n  - Bug Fixes\r\n  - Documentation improvements\r\n\r\nBreaking Changes\r\n---------------------------\r\n- `tgm.inverse` has been removed since now Pytorch supports batched version for `torch.inverse` f6c210d87ef63e6a07917cdf88b44091c52ede69\r\n\r\nNew Features\r\n--------------------\r\n- Added `tgm.warp_perspective` matching OpenCV interface d53cbce5d779fbc92b3449ed3c3c88f55f8b88ec\r\n- Added `tgm.get_perspective_transform` matching OpenCV interface \r\na7db348c5978efc7870c649757947123bfbf78fb\r\n- Added `tgm.get_rotation_matrix2d` matching OpenCV interface \r\n876b2c601d4d5028ab84cc2735fa3fbb018b4c1b\r\n\r\nBug Fixes\r\n--------------\r\n- Fixed bug for inplace operation in `tgm.inverse_pose` 0aba15d0b3ea79cfc3ed6a31ba088f86db643658\r\n\r\nDocumentation improvements\r\n------------------------------------------\r\n- Added notebook tutorial for `tgm.warp_affine` and `tgm.warp_pesrpective` 894bf52b6c1be9780e190051e8d7b9b679733e2e\r\n\r\nOther improvements\r\n----------------------------\r\n- Update to Pytorch v1.0.0 3ee14c83285f05ce8d29725a0489d0c9f8b058ed\r\n- Refactor in testing framework. Removed `unittest` and now using `pytest` since it's easy to parametrize unit tests.\r\n  - parametrized tests for different batch sizes\r\n  - parametrized tests for device types: cpu and cuda. Note: need to test on cuda yet.\r\n- Now we have official `pip` package to install the library: `pip install torchgeometry`\r\n  - URL: https://pypi.org/project/torchgeometry/0.1.1",
        "dateCreated": "2019-01-08T15:26:31Z",
        "datePublished": "2019-01-08T15:47:39Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.1.1",
        "name": "warp_perspective, get_perspective_transform, get_rotation_matrix2d, update to PyTorch v1.0.0, update test with pytest and pip package release",
        "tag_name": "v0.1.1",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.1.1",
        "url": "https://api.github.com/repos/kornia/kornia/releases/14858057",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.1.1"
      },
      {
        "authorType": "User",
        "author_name": "edgarriba",
        "body": "**This is the initial release of the torchvision package.**\r\n\r\nIt contains a set of routines and modules for geometric computer vision implementing multi-view reprojection primitives that work on images and feature maps warping. In addition, we provide routines for conversions and utilities for the pinhole model cameras.\r\n\r\n# Table of Contents\r\n-  [API](api)\r\n- [Test](test)\r\n- [Documentation](documentation)\r\n- [Examples](examples)\r\n\r\n## API\r\n- Pinhole\r\n    - inverse_pose 001097c\r\n    - pinhole_matrix 063b0c6\r\n    - inverse_pinhole_matrix 063b0c6\r\n    - scale_pinhole 063b0c6\r\n    - homography_i_H_ref 063b0c6\r\n- Conversions\r\n    - pi fb56c9c\r\n    - rad2deg fb56c9c\r\n    - deg2rad fb56c9c\r\n    - convert_points_from_homogeneous f13c462\r\n    - convert_points_to_homogeneous f13c462\r\n    - transform_points 1a1511c\r\n    - angle_axis_to_rotation_matrix 4c929d5\r\n    - rtvec_to_pose 4c929d5\r\n    - rotation_matrix_to_angle_axis f999165\r\n    - rotation_matrix_to_quaternion f999165\r\n    - quaternion_to_angle_axis f999165\r\n- Warping\r\n    - HomographyWarper 2e54229\r\n    - DepthWarper cd03569\r\n- Utils\r\n    - tensor_to_image 3ad7d05\r\n    - image_to_tensor 3ad7d05\r\n    - inverse 1a1511c\r\n\r\n## Test\r\n- docker kit ae8d9e1\r\n- automated test with TravisCI c213e3e\r\n- lint tests c213e3e \r\n\r\n## Documentation\r\n- sphinx documentation b9251ab\r\n- development e800c36\r\n\r\n## Examples:\r\n- homography regression ce1524d\r\n- image warped by depth f999165\r\n- jupiter notebooks 3c96835",
        "dateCreated": "2018-10-02T21:46:40Z",
        "datePublished": "2018-10-03T15:24:35Z",
        "html_url": "https://github.com/kornia/kornia/releases/tag/v0.1.0",
        "name": "v0.1.0 Package initial release",
        "tag_name": "v0.1.0",
        "tarball_url": "https://api.github.com/repos/kornia/kornia/tarball/v0.1.0",
        "url": "https://api.github.com/repos/kornia/kornia/releases/13225258",
        "zipball_url": "https://api.github.com/repos/kornia/kornia/zipball/v0.1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5500,
      "date": "Fri, 10 Dec 2021 16:24:51 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "computer-vision",
      "image-processing",
      "machine-learning",
      "pytorch",
      "deep-learning",
      "neural-network",
      "python",
      "artificial-intelligence",
      "hacktoberfest",
      "hacktoberfest2021"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Run our Jupyter notebooks [tutorials](https://kornia-tutorials.readthedocs.io/en/latest/) to learn to use the library.\n\n<div align=\"center\">\n  <a href=\"https://colab.research.google.com/github/kornia/tutorials/blob/master/source/hello_world_tutorial.ipynb\" target=\"_blank\">\n    <img src=\"https://raw.githubusercontent.com/kornia/data/main/hello_world_arturito.png\" width=\"75%\" height=\"75%\">\n  </a>\n</div>\n\n:triangular_flag_on_post: **Updates**\n- :white_check_mark: Integrated to [Huggingface Spaces](https://huggingface.co/spaces) with [Gradio](https://github.com/gradio-app/gradio). See [Gradio Web Demo](https://huggingface.co/spaces/akhaliq/Kornia-LoFTR).\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "citation": [
    {
      "confidence": [
        0.909179168496864
      ],
      "excerpt": "    Either combine it together. You may get inspiration from https://arxiv.org/pdf/1905.11946.pdf. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8043073075947367
      ],
      "excerpt": "    if self.verbose: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8680035758244715
      ],
      "excerpt": "grade = 4 * (`compression rate` / 10) + 4 * (`speed up rate` / 10)  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/iamilyasedunov/key_word_spotting",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-09T18:05:28Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-23T09:33:11Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8654834590054918,
        0.9868269059144993
      ],
      "excerpt": "On the contrary, you will be able to write down all the code in notebooks, but with a lot of comments and graphs :). \nThe purpose of the work is to explore various ways to accelerate NNs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8985691730092233,
        0.9356362043788419
      ],
      "excerpt": "      and make a prediction on them. And the next step is to read the T + 1 frame's, \n      run the neural network just for it, and make a prediction based on it and the T - 1 of the previous frames. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490244768550471
      ],
      "excerpt": "  1. define `max_window_length` and restrict you buffer with this parameter. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8035460506924867
      ],
      "excerpt": "  2. share `hidden state` of GRU between steps \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8383515142480275
      ],
      "excerpt": "  To demonstrate the work in streaming mode, take two random audio tracks of 10-20 seconds and glue them together so that your \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.929499955149828
      ],
      "excerpt": "  The most suituble way to visualize is notebook. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8200497033782297
      ],
      "excerpt": "     You are free in the methods of achieving the goal, but to make it easier, you can start with: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9572659020792249
      ],
      "excerpt": "        Design the smaller model with same topology and distill it with teacher (base model). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9341385367453613
      ],
      "excerpt": "        Design the smaller attention mechanism and distill it by optimizing KL divergence between propability vectors of teacher and student \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9905063616372105
      ],
      "excerpt": "        Quantize weights of model to lower precision (fp16/qint8). Pay attention to QAT and official PyTorch tutorial about Quantization. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9418817565066818
      ],
      "excerpt": "        Pay attention to official PyTorch tutorial about Pruning. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9141769767588733,
        0.9259474557624582
      ],
      "excerpt": " 1. The quality of the **base model** is `~0.0025`, so your optimized model should not have a quality less than \"~0.0025 * 0.95\". \n 2. You should try at least 6 settings of model optimization (speed up and/or compression) and visualize it in two ways: Metric-FLOPs and Metric-Memory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8206413237078153,
        0.8191155365016498,
        0.8547471483404273
      ],
      "excerpt": "      5. and so on \n    Note that, for example, the temperature change during distillation is not a new setting:) \nOne of the way to easly estimate running time \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "def get_size_in_megabytes(model): \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/iamilyasedunov/key_word_spotting/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 10 Dec 2021 10:28:36 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/iamilyasedunov/key_word_spotting/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "iamilyasedunov/key_word_spotting",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/iamilyasedunov/key_word_spotting/main/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/iamilyasedunov/key_word_spotting/main/KWS_seminar.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/iamilyasedunov/key_word_spotting/main/docker_start.sh",
      "https://raw.githubusercontent.com/iamilyasedunov/key_word_spotting/main/bins/run_container.sh",
      "https://raw.githubusercontent.com/iamilyasedunov/key_word_spotting/main/bins/build_image.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    1) git clone https://github.com/iamilyasedunov/key_word_spotting.git\n    2) cd key_word_spotting\n    3) bash docker_start.sh\n    4) docker attach ISedunov-kws_report\n    5) cd /home/key_word_spotting/key_word_spotting\n    6) python train.py\n    7) python test.py\n\n-------\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9307425075066118
      ],
      "excerpt": "  When you implement streaming mode note that you need to: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8418426356390782
      ],
      "excerpt": "    self.name = name \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9493651992633111
      ],
      "excerpt": "from thop import profile  #: !pip install thop \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8431503258367834
      ],
      "excerpt": "    Examples of settings: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8396948529258378
      ],
      "excerpt": "import time \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8399995283233033,
        0.812998327792582
      ],
      "excerpt": "def __init__(self, name: str, verbose=False): \n    self.name = name \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8172044000852604
      ],
      "excerpt": "def __exit__(self, type, value, traceback): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8166402391308393
      ],
      "excerpt": "        print(f\"{self.name.capitalize()} | Elapsed time : {self.t:.2f}\") \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/iamilyasedunov/key_word_spotting/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook",
      "Dockerfile",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Ilya Sedunov\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Homework 2 (KWS)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "key_word_spotting",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "iamilyasedunov",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/iamilyasedunov/key_word_spotting/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We don't accept homework if any of the following requirements are not satisfied:\n* The code and report should be situated in a public github (or gitlab) repository\n* All necessary resources (such as model checkpoints, and logs) should be downloadable with a script. \n  Mention the script (or lines of code) in the `README.md`\n* Attech a report. That includes:\n  * Description and result of each experiment\n  * How to reproduce your model?\n  * Attach training logs to show how fast did you network train\n  * What worked and what didn't work?\n  * What were the major challenges?\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Fri, 10 Dec 2021 10:28:36 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "keyword-spotting",
      "kws",
      "distillation-loss",
      "teacher-student-learning",
      "soft-labels-distillation",
      "distillation"
    ],
    "technique": "GitHub API"
  }
}
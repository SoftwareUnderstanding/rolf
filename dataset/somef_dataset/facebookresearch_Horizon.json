{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1811.00260",
      "https://arxiv.org/abs/1509.06461",
      "https://arxiv.org/abs/1511.06581",
      "https://arxiv.org/abs/1710.02298",
      "https://arxiv.org/abs/1707.06887",
      "https://arxiv.org/abs/1710.10044",
      "https://arxiv.org/abs/1802.09477",
      "https://arxiv.org/abs/1801.01290",
      "https://arxiv.org/abs/2006.15134",
      "https://arxiv.org/abs/1707.06347",
      "https://arxiv.org/abs/1810.02019",
      "https://arxiv.org/abs/1905.12767",
      "https://arxiv.org/abs/1612.01205",
      "https://arxiv.org/abs/1511.03722",
      "https://arxiv.org/abs/1604.00923",
      "https://arxiv.org/abs/0809.4882",
      "https://arxiv.org/abs/1003.0146",
      "https://arxiv.org/abs/2102.12425",
      "https://arxiv.org/abs/1811.00260"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@article{gauci2018horizon,\n  title={Horizon: Facebook's Open Source Applied Reinforcement Learning Platform},\n  author={Gauci, Jason and Conti, Edoardo and Liang, Yitao and Virochsiri, Kittipat and Chen, Zhengxing and He, Yuchen and Kaden, Zachary and Narayanan, Vivek and Ye, Xiaohui},\n  journal={arXiv preprint arXiv:1811.00260},\n  year={2018}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{gauci2018horizon,\n  title={Horizon: Facebook's Open Source Applied Reinforcement Learning Platform},\n  author={Gauci, Jason and Conti, Edoardo and Liang, Yitao and Virochsiri, Kittipat and Chen, Zhengxing and He, Yuchen and Kaden, Zachary and Narayanan, Vivek and Ye, Xiaohui},\n  journal={arXiv preprint arXiv:1811.00260},\n  year={2018}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "- Critic Regularized Regression (CRR) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8768594116348547
      ],
      "excerpt": "Multi-Arm and Contextual Bandits: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/facebookresearch/Horizon/main/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/ReAgent",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to ReAgent\nWe want to make contributing to this project as easy and transparent as\npossible.\nPull Requests\nWe actively welcome your pull requests.\n\nFork the repo and create your branch from master.\nIf you've added code that should be tested, add tests.\nIf you've changed APIs, update the documentation.\nEnsure the test suite passes.\nMake sure your code lints.\nIf you haven't already, complete the Contributor License Agreement (\"CLA\").\n\nContributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\nComplete your CLA here: https://code.facebook.com/cla\nIssues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\nLicense\nBy contributing ReAgent, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-07-27T17:53:21Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-05T05:59:10Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9968837687576133,
        0.8209177343196394
      ],
      "excerpt": "ReAgent is an open source end-to-end platform for applied reinforcement learning (RL) developed and used at Facebook. ReAgent is built in Python and uses PyTorch for modeling and training and TorchScript for model serving. The platform contains workflows to train popular deep RL algorithms and includes data preprocessing, feature transformation, distributed training, counterfactual policy evaluation, and optimized serving. For more detailed information about ReAgent see the release post here and white paper here. \nThe platform was once named \"Horizon\" but we have adopted the name \"ReAgent\" recently to emphasize its broader scope in decision making and reasoning. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016,
        0.9394449182630016
      ],
      "excerpt": "- Doubly Robust (for bandits) \n- Doubly Robust (for sequential decisions) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A platform for Reasoning systems (Reinforcement Learning, Contextual Bandits, etc.)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/Horizon/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 443,
      "date": "Sun, 05 Dec 2021 13:26:26 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/facebookresearch/ReAgent/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "facebookresearch/ReAgent",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/facebookresearch/Horizon/tree/main/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/facebookresearch/Horizon/main/reagent/ope/test/notebooks/contextual_bandit_randomized_experiments.ipynb",
      "https://raw.githubusercontent.com/facebookresearch/Horizon/main/reagent/ope/test/notebooks/GridWorldExperiments.ipynb",
      "https://raw.githubusercontent.com/facebookresearch/Horizon/main/reagent/ope/test/notebooks/CartpoleExperiments.ipynb",
      "https://raw.githubusercontent.com/facebookresearch/Horizon/main/reagent/ope/test/notebooks/contextual_bandit_experiments.ipynb",
      "https://raw.githubusercontent.com/facebookresearch/Horizon/main/reagent/notebooks/PPO_for_CartPole_Control.ipynb",
      "https://raw.githubusercontent.com/facebookresearch/Horizon/main/reagent/notebooks/REINFORCE_for_CartPole_Control.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/facebookresearch/Horizon/main/scripts/recurring_training_sac_offline.sh",
      "https://raw.githubusercontent.com/facebookresearch/Horizon/main/docs/build.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "ReAgent can be installed via. Docker or manually. Detailed instructions on how to install ReAgent can be found [here](docs/installation.rst).\n\n",
      "technique": "Header extraction"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/facebookresearch/ReAgent/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook",
      "C++",
      "Scala",
      "CMake",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\n\\nCopyright (c) 2017-present, Facebook, Inc. All rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without modification,\\nare permitted provided that the following conditions are met:\\n\\n * Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n * Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n * Neither the name Facebook nor the names of its contributors may be used to\\n   endorse or promote products derived from this software without specific\\n   prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "## Applied Reinforcement Learning @ Facebook",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ReAgent",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "facebookresearch",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/ReAgent/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3067,
      "date": "Sun, 05 Dec 2021 13:26:26 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "ReAgent is designed for large-scale, distributed recommendation/optimization tasks where we don\u2019t have access to a simulator.\nIn this environment, it is typically better to train offline on batches of data, and release new policies slowly over time.\nBecause the policy updates slowly and in batches, we use off-policy algorithms. To test a new policy without deploying it,\nwe rely on counter-factual policy evaluation (CPE), a set of techniques for estimating a policy based on the actions of another policy.\n\nWe also have a set of tools to facilitate applying RL in real-world applications:\n- Domain Analysis Tool, which analyzes state/action feature importance and identifies whether the problem is a suitable for applying batch RL\n- Behavior Cloning, which clones from the logging policy to bootstrap the learning policy safely\n\nDetailed instructions on how to use ReAgent can be found [here](docs/usage.rst).\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
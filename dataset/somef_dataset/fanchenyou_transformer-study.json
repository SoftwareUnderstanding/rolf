{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1810.04805",
      "https://arxiv.org/abs/1810.04805"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8654671031158477
      ],
      "excerpt": "* Sentence Order Prediction \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fanchenyou/transformer-study",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-09-22T17:54:41Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-06T13:00:31Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8849677122871403
      ],
      "excerpt": "* 2. simple toy example showing the idea of Transformer-XL which uses additional memory to encode history     \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8640730324995234
      ],
      "excerpt": "  - the output of the previous hidden layer of that segment \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9207289714241538
      ],
      "excerpt": "* Complete implementation of Transformer-XL \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8991129316125765
      ],
      "excerpt": "* Add more comments for understanding \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9436741717934743,
        0.893047822937386,
        0.9470478150481486
      ],
      "excerpt": "* The task is two-fold, see paper section 3.1 \n    1) to predict the second part of a sentence (Next Sentence Prediction) \n    2) to predict the masked words of a sentence (Masked LM) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9271038393682435
      ],
      "excerpt": "* See transformer_bert_from_scratch_5.py for more details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9392496724227882
      ],
      "excerpt": "* Utilize official Pytorch API to implement the interface of using existing code and pre-trained model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9737954296600401
      ],
      "excerpt": "* A Lite BERT which reduces BERT params to ~20% \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9555631212027157
      ],
      "excerpt": "   - the default decision for ALBERT is to share all parameters across layers (see paper section 3.1 !!) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Transformer network variants tutorials",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fanchenyou/transformer-study/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 13 Dec 2021 19:50:03 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/fanchenyou/transformer-study/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "fanchenyou/transformer-study",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/fanchenyou/transformer-study/master/data/getdata.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9322609392449874
      ],
      "excerpt": "* PyTorch 1.2 + TorchText \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9096104964140866
      ],
      "excerpt": "* 2.1 Build Transformer-XL + MultiAttention heads \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9758159882059685,
        0.914549150184554,
        0.9096104964140866
      ],
      "excerpt": "* Requirements: Python 3 + Pytorch v1.2  \n* TODO: Add GPU support \n* Build Bert - Bidirectional Transformer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9096104964140866
      ],
      "excerpt": "* Build Bert - Bidirectional Transformer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9910210531727922
      ],
      "excerpt": "* pip install transformers tb-nightly \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/fanchenyou/transformer-study/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Several Transformer network variants tutorials",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "transformer-study",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "fanchenyou",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fanchenyou/transformer-study/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Python = 2.7 and 3.6\n\nPyTorch = 1.2+ [[here]](https://pytorch.org/) for both python versions\n\nGPU training with 4G+ memory, testing with 1G+ memory.\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Mon, 13 Dec 2021 19:50:03 GMT"
    },
    "technique": "GitHub API"
  }
}
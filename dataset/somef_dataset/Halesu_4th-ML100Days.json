{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1311.2524\n            * R-CNN \u7684\u76ee\u6a19\u662f\uff1a\u5c0e\u5165\u4e00\u5f35\u5716\u7247\uff0c\u901a\u904e\u65b9\u6846\u6b63\u78ba\u8b58\u5225\u4e3b\u8981\u7269\u9ad4\u5728\u5716\u50cf\u7684\u54ea\u500b\u5730\u65b9\u3002\n                * \u8f38\u5165\uff1a\u5716\u50cf\n                * \u8f38\u51fa\uff1a\u65b9\u6846 + \u6bcf\u500b\u7269\u9ad4\u7684\u6a19\u7c64\n            * \u4f46\u600e\u9ebc\u77e5\u9053\u9019\u4e9b\u65b9\u6846\u61c9\u8a72\u5728\u54ea\u88e1\u5462\uff1f\n                * R-CNN \u7684\u8655\uf9e4\u65b9\u5f0f \u2014 \u5728\u5716\u50cf\u4e2d\u641e\u51fa\u4e00\u5927\u5806\u65b9\u6846\uff0c\u770b\u770b\u662f\u5426\u6709\u4efb\u4f55\u4e00\u500b\u8207\u67d0\u500b\u7269\u9ad4\u91cd\u758a\n                * \u751f\u6210\u9019\u4e9b\u908a\u6846\u3001\u6216\u8005\u8aaa\u662f\u63a8\u85a6\u5c40\u57df\uff0cR-CNN \u63a1\u7528\u7684\u662f\u4e00\u9805\u540d\u70ba Selective Search \u7684\u6d41\u7a0b\n                    * Selective Search \u901a\u904e\u4e0d\u540c\u5c3a\u5bf8\u7684\u7a97\u53e3\uf92d\u67e5\u770b\u5716\u50cf\n                    * \u5c0d\u65bc\u6bcf\u4e00\u500b\u5c3a\u5bf8\uff0c\u5b83\u901a\u904e\u7d0b\uf9e4\u3001\u8272\u5f69\u6216\u5bc6\u5ea6\u628a\u76f8\u9130\u50cf\u7d20\u5283\u70ba\u4e00\u7d44\uff0c\uf92d\u9032\u884c\u7269\u9ad4\u8b58\u5225\u3002\n                    * \u7576\u908a\u6846\u65b9\u6848\u751f\u6210\u4e4b\u5f8c\uff0cR-CNN \u628a\u9078\u53d6\u5340\u57df\u8b8a\u5f62\u70ba\u6a19\u6e96\u7684\u65b9\u5f62\n                    * \u5728 CNN \u7684\u6700\u5f8c\u4e00\u5c64\uff0cR-CNN \u52a0\u5165\uf9ba\u4e00\u500b\u652f\u6301\u5411\uf97e\u6a5f\uff0c\u5b83\u8981\u505a\u7684\u4e8b\u5f88\u7c21\u55ae\uff1a\u5c0d\u9019\u662f\u5426\u662f\u4e00\u500b\u7269\u9ad4\u9032\ufa08\u5206\u985e\uff0c\u5982\u679c\u662f\uff0c\u662f\uf9fd\u9ebc\u7269\u9ad4\u3002\n                * \u662f\u5426\u80fd\u7e2e\u5c0f\u908a\u6846\uff0c\u8b93\u5b83\uf901\u7b26\u5408\u7269\u9ad4\u7684\u4e09\u7dad\u5c3a\u5bf8\uff1f\n                    * \u7b54\u6848\u662f\u80af\u5b9a\u7684\uff0c\u9019\u662f R-CNN \u7684\u6700\u5f8c\u4e00\u6b65\u3002\n                * R-CNN \u5728\u63a8\u85a6\u5340\u57df\u4e0a\u904b\ufa08\u4e00\u500b\u7c21\u55ae\u7684\u7dda\u6027\u56de\u6b78\uff0c\u751f\u6210\uf901\u7dca\u7684\u908a\u6846\u5750\u6a19\u4ee5\u5f97\u5230\u6700\u7d42\u7d50\u679c\u3002\n                    * \u56de\u6b78\u6a21\u578b\u7684\u8f38\u5165\u548c\u8f38\u51fa\uff1a\n                        * \u8f38\u5165\uff1a\u5c0d\u61c9\u7269\u9ad4\u7684\u5716\u50cf\u5b50\u5340\u57df\n                        * \u8f38\u51fa\uff1a\u91dd\u5c0d\u8a72\u7269\u9ad4\u7684\u65b0\u908a\u6846\u7cfb\u7d71\n            * \u6982\u62ec\u4e0b\uf92d\uff0cR-CNN \u53ea\u662f\u4ee5\u4e0b\u9019\u5e7e\u500b\u6b65\u9a5f\uff1a\n                * \u751f\u6210\u5c0d\u908a\u6846\u7684\u63a8\u85a6\n                * \u5728\u9810\u8a13\u7df4\u7684 AlexNet \u4e0a\u904b\ufa08\u65b9\u6846\u88e1\u7684\u7269\u9ad4\u3002\u7528\u652f\u6301\u5411\uf97e\u6a5f\uf92d\u770b\u908a\u6846\u88e1\u7684\u7269\u9ad4\u662f\uf9fd\u9ebc\u3002\n                * \u5728\u7dda\u6027\u56de\u6b78\u6a21\u578b\u4e0a\u8dd1\u8a72\u908a\u6846\uff0c\u5728\u7269\u9ad4\u5206\u985e\u4e4b\u5f8c\u8f38\u51fa\uf901\u7dca\u7684\u908a\u6846\u7684\u5ea7\u6a19\n* **Day_106 : \u96fb\u8166\u8996\u89ba\u5e38\u7528\u516c\u958b\u8cc7\u6599\u96c6**\n    * \u641c\u96c6\u8207\u6a19\u6ce8\u8cc7\u6599\u662f\u8017\u6642\u52de\uf98a\u7684\u5de5\u4f5c\n    * \uf974\u5c08\u6848\u7684\u76ee\u6a19\u76f8\u8fd1\uff0c\u7db2\u8def\u4e0a\u662f\u6709\u975e\u5e38\u591a\u516c\u958b\u4e14\u6a19\u6ce8\u597d\u7684\u8cc7\u6599\u96c6\u53ef\u4ee5\u4f7f\u7528\uff01\n        * Kaggle\n        * ImageNet dataset\n        * COCO dataset\n    * Kaggle\n        * \u5404\u5f0f\u5404\u6a23\u7684\u5f71\u50cf\u8fa8\u8b58\u984c\u76ee\uff0c\uf9b5\u5982[\u6578\u6d77\u7345\u6578\uf97e](https://zhuanlan.zhihu.com/p/29096434"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "object : \u5305\u542b\u5b57\u4e32\uff0c\u8868\u793a\u985e\u5225\u578b\u8b8a\u6578 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8179493569047226
      ],
      "excerpt": "    pd.merge(df1,df2,on='id',how='outer') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8179493569047226
      ],
      "excerpt": "    pd.merge(df1,df2,on='id',how='inner') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "sub_df = df.tail(10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "sub_df = df.sample(n=10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.934079999077463
      ],
      "excerpt": "    plt.figure(figsize=(10,30)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906174419333412
      ],
      "excerpt": "    * [\u53e6\u985e\u2f26\u5b50\u5716 Seaborn.jointplot](https://seaborn.pydata.org/generated/seaborn.jointplot.html) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9707925318074234
      ],
      "excerpt": "    plt.title('Correlation Heatmap') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173,
        0.8714162992508173
      ],
      "excerpt": "Day_21 : \u6a21\u578b\u521d\u9ad4\u9a57 - Logistic Regression \nLogistic Regression \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9285966407781958
      ],
      "excerpt": "    if df[c].dtype == 'object': \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9681875236301641
      ],
      "excerpt": "    * [\u504f\u5ea6\u8207\u5cf0\u5ea6](https://blog.csdn.net/u013555719/article/details/78530879) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9285966407781958
      ],
      "excerpt": "    if dtype == 'object': \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9681875236301641
      ],
      "excerpt": "    * [\u6a19\u7c64\u7de8\u78bc\u8207\u7368\u71b1\u7de8\u78bc](https://blog.csdn.net/u013555719/article/details/78530879) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8179493569047226
      ],
      "excerpt": "    df = pd.merge(df, count_df, on=['Ticket'], how='left') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": "df_temp['Ticket_Hash'] = df['Ticket'].map(lambda x:hash(x) % 10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    df['day_cycle'] = df['pickup_hour']/12 + df['pickup_minute']/720 + df['pickup_second']/43200 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8179493569047226,
        0.8179493569047226,
        0.8179493569047226,
        0.8179493569047226
      ],
      "excerpt": "    temp = pd.merge(mean_df, mode_df, how='left', on=['Ticket']) \n    temp = pd.merge(temp, median_df, how='left', on=['Ticket']) \n    temp = pd.merge(temp, max_df, how='left', on=['Ticket']) \n    temp = pd.merge(temp, min_df, how='left', on=['Ticket']) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559,
        0.8955886365383559
      ],
      "excerpt": "    | 1     | 110413 | 36\\.333333 | 18\\.000000 | 39\\.000000  | 52\\.0    | 18\\.000000 | \n    | 2     | 110465 | 38\\.349559 | 29\\.699118 | 38\\.349559  | 47\\.0    | 29\\.699118 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "    * \u4f7f\u7528 Lasso Regression \u6642\uff0c\u8abf\u6574\u4e0d\u540c\u7684\u6b63\u898f\u5316\u7a0b\u5ea6\uff0c\u5c31\u6703\u81ea\u7136\u4f7f\u5f97\u4e00\u90e8\u5206\u7279\u5fb5\u4fc2\u6578\u70ba 0\uff0c\u56e0\u6b64\u522a\u9664\u4fc2\u6578\u662f 0 \u7684\u7279\u5fb5\uff0c\u4e0d\u9808\u984d\u5916\u6307\u5b9a\u9580\u6abb\uff0c\u4f46\u9700\u8abf\u6574\u6b63\u898f\u5316\u7a0b\u5ea6 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "rf = RandomForestClassifier(n_estimators=20, min_samples_split=10, min_samples_leaf=5,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8592871015078041,
        0.914435315552148
      ],
      "excerpt": "    * [Algorithm-GBDT Encoder](https://zhuanlan.zhihu.com/p/31734283) \n    * [\u5206\u89e3\u6a5f\uff0cFactorization Machine\uff0cFM](https://kknews.cc/code/62k4rml.html) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "Day_35 : Regression & Classification \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "\u591a\u5143\u5206\u985e vs. \u591a\u6a19\u7c64(multi-label) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.971679416046096
      ],
      "excerpt": "Multi-class vs. Multi-label  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "Day_37 : Regression \u6a21\u578b \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "Logistic Regression (\u7f85\u5409\u65af\u56de\u6b78) : \u5206\u985e\u6a21\u578b\uff0c\u5c07\u7dda\u6027\u6a21\u578b\u7d50\u679c\u52a0\u4e0a sigmoid \u51fd\u6578\uff0c\u5c07\u9810\u6e2c\u503c\u9650\u5236\u5728 0~1 \u4e4b\u9593\uff0c\u5373\u70ba\u9810\u6e2c\u6a5f\u7387\u503c \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8786044417622563,
        0.8714162992508173
      ],
      "excerpt": "Andrew Ng \u6559\u4f60 Linear Regression \nLogistic Regression \u6578\u5b78\u539f\u7406 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173,
        0.8714162992508173,
        0.8714162992508173
      ],
      "excerpt": "Logistic Regression \u8a73\u7d30\u4ecb\u7d39 \n\u4f60\u53ef\u80fd\u4e0d\u77e5\u9053\u7684 Logistic Regression \nDay_38 : Regression \u6a21\u578b  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "* Logistic Regression \u53c3\u6578 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9681875236301641,
        0.9917157944634919
      ],
      "excerpt": "    * *Solver* : \u5c0d\u640d\u5931\u51fd\u6578\u7684\u512a\u5316\u65b9\u6cd5\uff0c\u8a73\u7d30\u53c3\u8003[\u9023\u7d50](https://blog.csdn.net/lc574260570/article/details/82116197) \n    * *Multi-class* : \u9078\u64c7 one-vs-rest \u6216 multi-nominal \u5206\u985e\u65b9\u5f0f\uff0c\uf974\u6709 10 class\uff0c ovr \u662f\u8a13\u7df4 10 \u500b\u4e8c\u5206\u985e\u6a21\u578b\uff0c\u7b2c\u4e00\u500b\u6a21\u578b\u8ca0\u8cac\u5206\u985e (class1, non-class1)\uff1b\u7b2c\u4e8c\u500b\u8ca0\u8cac(class2, non-class2)\uff0c\u4ee5\u6b64\u985e\u63a8\u3002multi-nominal \u662f\u76f4\u63a5\u8a13\u7df4\u591a\u5206\u985e\u6a21\u578b\u3002\u8a73\u7d30\uf96b\u8003[\u9023\u7d50](https://www.quora.com/What-is-the-difference-between-one-vs-all-binary-logistic-regression-and-multinomial-logistic-regression) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9989376135348945,
        0.9822909767460124,
        0.8714162992508173
      ],
      "excerpt": "    * [\u66f4\u591a Linear regression \u548c Logistic regression \u7bc4\u4f8b](https://github.com/trekhleb/homemade-machine-learning) \n    * [\u6df1\u5165\u4e86\u89e3 multi-nominal Logistic Regresson \u539f\u7406](http://dataaspirant.com/2017/05/15/implement-multinomial-logistic-regression-python/) \nDay_39 : LASSO, Ridge regression \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173,
        0.8714162992508173
      ],
      "excerpt": "PCA \u8207 Ridge regression \u7684\u95dc\u4fc2 \nDay_40 : LASSO, Ridge regression  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8729393277090676
      ],
      "excerpt": "How Random Forest Algorithm Works \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "        n_estimators=10, #\u6c7a\u7b56\u6a39\u7684\u6578\u91cf\uf97e \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "        max_depth=10, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "Day_45 : \u68af\u5ea6\u63d0\u5347\u6a5f Gradient Boosting Machine \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9159607236864106
      ],
      "excerpt": "    * [how to tune machine learning models](https://cambridgecoding.wordpress.com/2016/04/03/scanning-hyperspace-how-to-tune-machine-learning-models/) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "\u5982\u679c\u662f\u4f9d\u7167\u4f30\u8a08\u8aa4\u5dee\u7684\u6b98\u5dee\u9805\u8abf\u6574\u65b0\u76ee\u6a19\u503c\uff0c\u5247\u5c31\u662f\u68af\u5ea6\u63d0\u5347\u6a5f (Gradient Boosting Machine) \u7684\u4f5c\u6cd5\uff0c\u53ea\u662f\u68af\u5ea6\u63d0\u5347\u6a5f\u9084\u52a0\u4e0a\u7528\u68af\u5ea6\uf92d\u9078\u64c7\u6c7a\u7b56\u6a39\u5206\u652f \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8511535834563826
      ],
      "excerpt": "Andrew Ng - Unsupervised learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9195926162616405
      ],
      "excerpt": "Unsupervised machine learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "clusterer = KMeans(n_clusters=n_clusters, random_state=10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8511535834563826,
        0.8955886365383559
      ],
      "excerpt": "single-link : \u7fa4\u805a\u8207\u7fa4\u805a\u9593\u7684\u8ddd\u96e2\u53ef\u4ee5\u5b9a\u7fa9\u70ba\u4e0d\u540c\u7fa4\u805a\u4e2d\u6700\u63a5\u8fd1\uf978\u9ede\u9593\u7684\u8ddd\u96e2\u3002 \ncomplete-link : \u7fa4\u805a\u9593\u7684\u8ddd\u96e2\u5b9a\u7fa9\u70ba\u4e0d\u540c\u7fa4\u805a\u4e2d\u6700\u9060\uf978\u9ede\u9593\u7684\u8ddd\u96e2\uff0c\u9019\u6a23\u53ef\u4ee5\u4fdd\u8b49\u9019\uf978\u500b\u96c6\u5408\u4f75\u5f8c\uff0c\u4efb\u4f55\u4e00\u5c0d\u7684\u8ddd\u96e2\u4e0d\u6703\u5927\u65bc d\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.934079999077463
      ],
      "excerpt": "        'pca__n_components': [4, 10, 20, 30, 40, 50, 64], \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    ax0.legend(prop=dict(size=12)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "tsne = manifold.TSNE(n_components=2, random_state=0, init='pca', learning_rate=200., early_exaggeration=12.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "* \u985e\u795e\u7d93\u7684\u61c9\u7528\u66fe\u6c89\u5bc2\u4e8c\u4e09\u5341\uf98e\uff0c\u76f4\u5230 2012 \uf98e AlexNet \u5728 ImageNet \u5716\u50cf\u5206\u985e\u7af6\u8cfd\u7372\u5f97\u9a5a\u8277\u8868\u73fe\u5f8c\uff0c\u624d\u91cd\u56de\u4e3b\u6d41\u821e\u53f0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "    * \u8cc7\u6599\u96c6\u5207\u63db\uff1a\u5206\u985e\u8cc7\u6599\u96c6(\u53f3\u4e0b) - \u87ba\u65cb\u96d9\u81c2\uff0c\u7279\u5fb5\u5168\u9078\uff0c\u96b1\u85cf\u5c641\u5c64 / 8\u795e\u7d93\u5143\uff0c\u6279\u6b21\u5927\u5c0f\u56fa\u5b9a 10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "    * \u8cc7\u6599\u96c6\u5207\u63db : \u5206\u985e\u8cc7\u6599\u96c6(\u53f3\u4e0b) - \u87ba\u65cb\u96d9\u81c2\uff0c\u7279\u5fb5\u5168\u9078\uff0c\u96b1\u85cf\u5c641\u5c64 / 8\u795e\u7d93\u5143\uff0c\u6279\u6b21\u5927\u5c0f\u56fa\u5b9a 10\uff0c\u5b78\u7fd2\u901f\u7387\u56fa\u5b9a 1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "    * \u8cc7\u6599\u96c6\u5207\u63db : \u5206\u985e\u8cc7\u6599\u96c6(\u53f3\u4e0b) - \u87ba\u65cb\u96d9\u81c2\uff0c\u7279\u5fb5\u5168\u9078\uff0c\u96b1\u85cf\u5c641\u5c64 / 8\u795e\u7d93\u5143\uff0c\u6279\u6b21\u5927\u5c0f\u56fa\u5b9a 10\uff0c\u5b78\u7fd2\u901f\u7387\u56fa\u5b9a 0.3\uff0c\u555f\u52d5\u51fd\u6578\u8a2d\u70ba Tanh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8915395832237684
      ],
      "excerpt": "\u6578\u64da\u96c6 50,000 \u5f35 32x32 \u5f69\u8272\u8a13\u7df4\u5716\u50cf\uff0c\u6a19\u8a3b\u8d85\u904e 10 \u500b\u985e\u5225\uff0c10,000 \u5f35\u6e2c\u8a66\u5716\u50cf\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9629329729245205
      ],
      "excerpt": "\u6578\u64da\u96c6\u5305\u542b 10 \u500b\u6578\u5b57\u7684 60,000 \u500b 28x28 \u7070\u5ea6\u5716\u50cf\uff0c\u4ee5\u53ca 10,000 \u500b\u5716\u50cf\u7684\u6e2c\u8a66\u96c6\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9629329729245205
      ],
      "excerpt": "\u6578\u64da\u96c6\u5305\u542b 10 \u500b\u6642\u5c1a\u985e\u5225\u7684 60,000 \u500b 28x28 \u7070\u5ea6\u5716\u50cf\uff0c\u4ee5\u53ca 10,000 \u500b\u5716\u50cf\u7684\u6e2c\u8a66\u96c6\u3002\u9019\u500b\u6578\u64da\u96c6\u53ef\u4ee5\u7528\u4f5c MNIST \u7684\u76f4\u63a5\u66ff\u63db\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266,
        0.9030859728368266
      ],
      "excerpt": "    num_classes = 10 \n    epochs = 10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8444342525991423
      ],
      "excerpt": "Day_70 : Multi-layer Perception \u7c21\u4ecb \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9593299683604384
      ],
      "excerpt": "                              epochs=10, batch_size=32,verbose=1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9815649454650704
      ],
      "excerpt": "        plt.title('Train History') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8187756947909643
      ],
      "excerpt": "\u5728\u56de\u6b78\u554f\u984c\u7a31\u70ba\u300c\u6b98\u5dee (residual)\u300d \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8187756947909643
      ],
      "excerpt": "$$ loss/residual = y - \\hat{y}$$ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9028399248104376
      ],
      "excerpt": "\u6df1\u5ea6\u5b78\u7fd2\u7684\u57fa\u672c\u539f\u7406\u662f\u57fa\u65bc\u4eba\u5de5\u795e\u7d93\u7db2\u8def\uff0c\u4fe1\u865f\u5f9e\u4e00\u500b\u795e\u7d93\u5143\u9032\u5165\uff0c\u7d93\u904e\u975e\u7dda\u6027\u7684 activation function\uff0c\u5982\u6b64\u5faa\u74b0\u5f80\u5fa9\u76f4\u5230\u8f38\u51fa\u5c64\uff0c\u6b63\u662f\u7531\u65bc\u9019\u4e9b\u975e\u7dda\u6027\u51fd\u6578\u7684\u53cd\u8986\u758a\u52a0\uff0c\u5c64\u4f7f\u5f97\u795e\u7d93\u5f80\u5fa9\u6709\u8db3\u5920\u7684\u80fd\u529b\u4f86\u6293\u53d6\u8907\u96dc\u7684 pattern \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9795566917838262
      ],
      "excerpt": "$$ f(x))= \\begin{cases} x & \\text {, if $x > 0$} \\ a(e^x-1) & \\text{, if $x \\leq 0$} \\end{cases} $$ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9681875236301641
      ],
      "excerpt": "    * [\u4f18\u5316\u5668\u5982\u4f55\u9009\u62e9](https://blog.csdn.net/qq_35860352/article/details/80772142) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8300861446546642,
        0.8300861446546642,
        0.8300861446546642,
        0.8300861446546642
      ],
      "excerpt": "        train_loss = model.history.history[\"loss\"] \n        valid_loss = model.history.history[\"val_loss\"] \n        train_acc = model.history.history[\"accuracy\"] \n        valid_acc = model.history.history[\"val_accuracy\"] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9707925318074234
      ],
      "excerpt": "        plt.title(\"Loss\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9707925318074234
      ],
      "excerpt": "        plt.title(\"Accuracy\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9841453496665767
      ],
      "excerpt": "    * [Overfitting in Machine Learning](https://elitedatascience.com/overfitting-in-machine-learning) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "        if flatten: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266,
        0.8043073075947352
      ],
      "excerpt": "    def preproc_y(y, num_classes=10): \n        if y.shape[-1] == 1: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "    def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "            if i == 0: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8300861446546642,
        0.8300861446546642,
        0.8300861446546642,
        0.8300861446546642
      ],
      "excerpt": "train_loss = model.history.history[\"loss\"] \n        valid_loss = model.history.history[\"val_loss\"] \n        train_acc = model.history.history[\"accuracy\"] \n        valid_acc = model.history.history[\"val_accuracy\"] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9707925318074234
      ],
      "excerpt": "    plt.title(\"Loss\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9707925318074234
      ],
      "excerpt": "    plt.title(\"Accuracy\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9681875236301641
      ],
      "excerpt": "    * [\u4f18\u5316\u65b9\u6cd5\u603b\u7ed3](https://blog.csdn.net/u010089444/article/details/76725843) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8546616431601454
      ],
      "excerpt": "Regularization in Machine Learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128], l1_ratio=0.0, l2_ratio=0.0): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "    if i == 0: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "    EPOCHS = 10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.8356013927728488
      ],
      "excerpt": "    L1_EXP = [1e-2, 1e-4, 1e-8, 1e-12, 0.0] \n    L2_EXP = [1e-2, 1e-4, 1e-8, 1e-12, 0.0] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8300861446546642,
        0.8300861446546642,
        0.8300861446546642,
        0.8300861446546642
      ],
      "excerpt": "train_loss = model.history.history[\"loss\"] \n        valid_loss = model.history.history[\"val_loss\"] \n        train_acc = model.history.history[\"accuracy\"] \n        valid_acc = model.history.history[\"val_accuracy\"] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128], drp_ratio=0.2): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "    if i == 0: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128], pre_activate=False): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "    if i == 0: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "        if pre_activate: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "        if pre_activate: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "        if flatten: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266,
        0.8043073075947352
      ],
      "excerpt": "    def preproc_y(y, num_classes=10): \n        if y.shape[-1] == 1: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "                output_units=10,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "            if i == 0: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "                if use_bn: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "                if use_bn: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8130052599129608,
        0.8300861446546642
      ],
      "excerpt": "        results[exp_name_tag] = {'train-loss': model.history.history[\"loss\"], \n                                'valid-loss': model.history.history[\"val_loss\"], \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8300861446546642
      ],
      "excerpt": "                                'valid-acc': model.history.history[\"val_accuracy\"]} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "                                min_lr=1e-12,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8300861446546642
      ],
      "excerpt": "valid_f1sc = model.history.history['val_f1sc'] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9707925318074234
      ],
      "excerpt": "    plt.title(\"F1-score\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8300861446546642,
        0.8300861446546642
      ],
      "excerpt": "    valid_tp = model.history.history['val_tp'] \n    valid_tn = model.history.history['val_tn'] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9681875236301641,
        0.9681875236301641
      ],
      "excerpt": "    * [Keras\u81ea\u5b9a\u4e49Loss\u51fd\u6570](https://blog.csdn.net/A_a_ron/article/details/79050204) \n    * [focal loss](https://blog.csdn.net/u014380165/article/details/77019084) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8568217992087697
      ],
      "excerpt": "            \"\"\"Focal loss for multi-classification \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8568217992087697
      ],
      "excerpt": "            \"\"\"Focal loss for multi-classification \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9559715772848645
      ],
      "excerpt": "        histSize\uff1a\u8981\u5207\u5206\u7684\u50cf\u7d20\u5f37\u5ea6\u503c\u7bc4\u570d\uff0c\u9810\u8a2d\u70ba256\u3002\u6bcf\u500bchannel\u7686\u53ef\u6307\u5b9a\u4e00\u500b\u7bc4\u570d\u3002\u4f8b\u5982\uff0c[32,32,32] \u8868\u793aRGB\u4e09\u500bchannels\u7686\u5207\u5206\u70ba32\u5340\u6bb5\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9707925318074234
      ],
      "excerpt": "        plt.title(\"Grayscale Histogram\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9707925318074234
      ],
      "excerpt": "        plt.title(\"'Flattened' Color Histogram\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9660991539358709,
        0.989333157434365,
        0.8906174419333412,
        0.9905510346969181
      ],
      "excerpt": "    * [\u56fe\u50cf\u5206\u7c7b|\u6df1\u5ea6\u5b66\u4e60PK\u4f20\u7edf\u673a\u5668\u5b66\u4e60](https://cloud.tencent.com/developer/article/1111702) \n    * [OpenCv - \u76f4\u65b9\u5716](https://chtseng.wordpress.com/2016/12/05/opencv-histograms%E7%9B%B4%E6%96%B9%E5%9C%96/) \n    * [OpenCv - \u6559\u5b78\u6587\u6a94](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html) \n    * [Introduction to Computer Vision](https://www.udacity.com/course/introduction-to-computer-vision--ud810) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999998645212095,
        0.9999998645212095
      ],
      "excerpt": "bin_cells = bins[:10,:10], bins[10:,:10], bins[:10,10:], bins[10:,10:] \n        mag_cells = mag[:10,:10], mag[10:,:10], mag[:10,10:], mag[10:,10:] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    ax.set_ylim(0,30) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8043073075947367
      ],
      "excerpt": "if mode == \"max\": \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.811975171133565,
        0.9848179726092176
      ],
      "excerpt": "\u5982\u540c\u5148\u524d\u8ab2\u7a0b\u4e2d\u7684 Scikit-learn.datasets\uff0c\u6df1\u5ea6\u5b78\u7fd2\u7684\u5f71\u50cf\u8cc7\u6599\u96c6\u4ee5 MNIST (\u624b\u5beb\u6578\u5b57\u8fa8\u8b58) \u8207 Cifar-10 (\u81ea\u7136\u5f71\u50cf\u5206\u985e) \u4f5c\u70ba\u5e38\ufa0a \nCifar-10 \u662f 10 \u500b\u985e\u5225\uff0c\u5f71\u50cf\u5927\u5c0f\u70ba 32x32 \u7684\u4e00\u500b\u8f15\uf97e\u8cc7\u6599\u96c6\uff0c\u975e\u5e38\u9069\u5408\u62ff\uf92d\u505a\u6df1\u5ea6\u5b78\u7fd2\u7684\u7df4\u7fd2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266,
        0.9030859728368266
      ],
      "excerpt": "num_classes = 10 \nepochs = 10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "Cifar-10 \u8cc7\u6599\u96c6\u76f8\u5c0d\u65bc\u5e38\u7528\u5230\u7684\u5f71\u50cf\uf92d\u8aaa\u662f\u975e\u5e38\u5c0f\uff0c\u6240\u4ee5\u53ef\u4ee5\u5148\u628a\u8cc7\u6599\u96c6\u5168\u90e8\u8b80\u9032\u8a18\u61b6\u9ad4\u88e1\u9762\uff0c\u8981\u4f7f\u7528\u6642\u76f4\u63a5\u5f9e\u8a18\u61b6\u9ad4\u4e2d\u5b58\u53d6\uff0c\u901f\u5ea6\u6703\u76f8\u7576\u5feb \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266,
        0.9030859728368266
      ],
      "excerpt": "num_classes = 10 \nepochs = 10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266,
        0.9030859728368266
      ],
      "excerpt": "num_classes = 10 \nepochs = 10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "    augment_generator = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8444342525991423
      ],
      "excerpt": "* [\u7c21\u55ae\u4f7f\u7528 Keras \u5b8c\u6210 Transfer learning](https://ithelp.ithome.com.tw/articles/10190971) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9846982194102245
      ],
      "excerpt": "Deep Residual Learning for Image Recognition \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.834614754083959
      ],
      "excerpt": "Identity Mappings in Deep Residual Networks \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "    num_classes = 10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "if subtract_pixel_mean: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8456806903995955
      ],
      "excerpt": "        if epoch &gt; 180: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "        if conv_first: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "            if batch_normalization: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "            if batch_normalization: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "def resnet_v1(input_shape, depth, num_classes=10): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "        if (depth - 2) % 6 != 0: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9933821412722575
      ],
      "excerpt": "Activity Recognition : CNNs + LSTM \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.881848456479086
      ],
      "excerpt": "ImageNet-10k (10,000 \u500b\u985e\u5225\u5206\u985e) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9146894306581498
      ],
      "excerpt": "\u7269\u4ef6\u5075\u6e2c Object Detection \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Halesu/4th-ML100Days",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-18T00:07:58Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-06T13:44:33Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* **Day_01 : \u8cc7\u6599\u4ecb\u7d39\u8207\u8a55\u4f30\u6307\u6a19**\n    * \u63a2\u7d22\u6d41\u7a0b : \u627e\u5230\u554f\u984c -> \u521d\u63a2 -> \u6539\u9032 -> \u5206\u4eab -> \u7df4\u7fd2 -> \u5be6\u6230\n    * \u601d\u8003\u95dc\u9375\u9ede :\n        * \u70ba\u4ec0\u9ebc\u9019\u500b\u554f\u984c\u91cd\u8981\uff1f\n        * \u8cc7\u6599\u5f9e\u4f55\u800c\u4f86\uff1f\n        * \u8cc7\u6599\u578b\u614b\u662f\u4ec0\u9ebc\uff1f\n        * \u56de\u7b54\u554f\u984c\u7684\u95dc\u9375\u6307\u6a19\u662f\u4ec0\u9ebc\uff1f\n* **Day_02 : \u6a5f\u5668\u5b78\u7fd2\u6982\u8ad6**\n    * \u6a5f\u5668\u5b78\u7fd2\u7bc4\u7587 : **\u6df1\u5ea6\u5b78\u7fd2 (Deep Learning)** \u2282 **\u6a5f\u5668\u5b78\u7fd2 (Machine Learning)** \u2282 **\u4eba\u5de5\u667a\u6167 (Artificial Intelligence)**\n    * \u6a5f\u5668\u5b78\u7fd2\u662f\u4ec0\u9ebc :\n        * \u8b93\u6a5f\u5668\u5f9e\u8cc7\u6599\u627e\u5c0b\u898f\u5f8b\u8207\u8da8\u52e2\uff0c\u4e0d\u9700\u8981\u7d66\u5b9a\u7279\u6b8a\u898f\u5247\n        * \u7d66\u5b9a\u76ee\u6a19\u51fd\u6578\u8207\u8a13\u7df4\u8cc7\u6599\uff0c\u5b78\u7fd2\u51fa\u80fd\u8b93\u76ee\u6a19\u51fd\u6578\u6700\u4f73\u7684\u6a21\u578b\u53c3\u6578\n    * \u6a5f\u5668\u5b78\u7fd2\u7e3d\u985e :\n        * **\u76e3\u7763\u662f\u5b78\u7fd2 (Supervised Learning)** : \u5716\u50cf\u5206\u985e (Classification)\u3001\u8a50\u9a19\u5075\u6e2c (Fraud detection)\uff0c\u9700\u6210\u5c0d\u8cc7\u6599 (x,y)\n        * **\u975e\u76e3\u7763\u662f\u5b78\u7fd2 (Unsupervised Learning)** : \u964d\u7dad (Dimension Reduction)\u3001\u5206\u7fa4 (Clustering)\u3001\u58d3\u7e2e\uff0c\u53ea\u9700\u8cc7\u6599 (x)\n        * **\u5f37\u5316\u5b78\u7fd2 (Reinforcement Learning)** : \u4e0b\u570d\u68cb\u3001\u6253\u96fb\u73a9\uff0c\u900f\u904e\u4ee3\u7406\u6a5f\u5668\u4eba (Agent) \u8207\u74b0\u5883 (Environment) \u4e92\u52d5\uff0c\u5b78\u7fd2\u5982\u4f55\u7372\u53d6\u6700\u9ad8\u734e\u52f5 (Reward)\uff0c\u4f8b\u5982 Alpha GO\n* **Day_03 : \u6a5f\u5668\u5b78\u7fd2\u6d41\u7a0b\u8207\u6b65\u9a5f**\n    * **\u8cc7\u6599\u8490\u96c6\u3001\u524d\u8655\u7406**\n        * \u653f\u5e9c\u516c\u958b\u8cc7\u6599\u3001Kaggle \u8cc7\u6599\n            * \u7d50\u69cb\u5316\u8cc7\u6599 : Excel \u6a94\u3001CSV \u6a94\n            * \u975e\u7d50\u69cb\u5316\u8cc7\u6599 : \u5716\u7247\u3001\u5f71\u97f3\u3001\u6587\u5b57\n        * \u4f7f\u7528 Python \u5957\u4ef6\n            * \u958b\u555f\u5716\u7247 : `PIL`\u3001`skimage`\u3001`open-cv`\n            * \u958b\u555f\u6587\u4ef6 : `pandas`\n        * \u8cc7\u6599\u524d\u8655\u7406 :\n            * \u7f3a\u5931\u503c\u586b\u88dc\n            * \u96e2\u7fa4\u503c\u8655\u7406\n            * \u6a19\u6e96\u5316\n    * **\u5b9a\u7fa9\u76ee\u6a19\u8207\u8a55\u4f30\u6e96\u5247**\n        * \u56de\u6b78\u554f\u984c\uff1f\u5206\u985e\u554f\u984c\uff1f\n        * \u9810\u6e2c\u76ee\u6a19\u662f\u4ec0\u9ebc\uff1f(target or y)\n        * \u7528\u4ec0\u9ebc\u8cc7\u6599\u9032\u884c\u9810\u6e2c\uff1f(predictor or x)\n        * \u5c07\u8cc7\u6599\u5206\u70ba :\n            * \u8a13\u7df4\u96c6\uff0ctraining set\n            * \u9a57\u8b49\u96c6\uff0cvalidation set\n            * \u6e2c\u8a66\u96c6\uff0ctest set\n        * \u8a55\u4f30\u6307\u6a19\n            * \u56de\u6b78\u554f\u984c (\u9810\u6e2c\u503c\u70ba\u5be6\u6578)\n                * RMSE : Root Mean Squeare Error\n                * MAE : Mean Absolute Error\n                * R-Square\n            * \u5206\u985e\u554f\u984c (\u9810\u6e2c\u503c\u70ba\u985e\u5225)\n                * Accuracy\n                * [F1-score](https://en.wikipedia.org/wiki/F1_score)\n                * [AUC](https://zh.wikipedia.org/wiki/ROC%E6%9B%B2%E7%BA%BF)\uff0cArea Under Curve\n    * **\u5efa\u7acb\u6a21\u578b\u8207\u8abf\u6574\u53c3\u6578**\n        * Regression\uff0c\u56de\u6b78\u6a21\u578b\n        * Tree-base model\uff0c\u6a39\u6a21\u578b\n        * Neural network\uff0c\u795e\u7d93\u7db2\u8def\n        * Hyperparameter\uff0c\u6839\u64da\u5c0d\u6a21\u578b\u4e86\u89e3\u548c\u8a13\u7df4\u60c5\u5f62\u9032\u884c\u8abf\u6574\n    * **\u5c0e\u5165**\n        * \u5efa\u7acb\u8cc7\u6599\u8490\u96c6\u3001\u524d\u8655\u7406(Preprocessing)\u7b49\u6d41\u7a0b\n        * \u9001\u9032\u6a21\u578b\u9032\u884c\u9810\u6e2c\n        * \u8f38\u51fa\u9810\u6e2c\u7d50\u679c\n        * \u8996\u5c08\u6848\u9700\u6c42\u8abf\u6574\u524d\u5f8c\u7aef\n* **Day_04 : \u8b80\u53d6\u8cc7\u6599\u8207\u5206\u6790\u6d41\u7a0b (EDA\uff0cExploratory Data Analysis)**   \n    * \u900f\u904e\u8996\u89ba\u5316\u548c\u7d71\u8a08\u5de5\u5177\u9032\u884c\u5206\u6790\n        * \u4e86\u89e3\u8cc7\u6599 : \u7372\u53d6\u8cc7\u6599\u5305\u542b\u7684\u8cc7\u8a0a\u3001\u7d50\u69cb\u3001\u7279\u9ede\n        * \u767c\u73fe outlier \u6216\u7570\u5e38\u6578\u503c : \u6aa2\u67e5\u8cc7\u6599\u662f\u5426\u6709\u8aa4\n        * \u5206\u6790\u5404\u8b8a\u6578\u9593\u7684\u95dc\u806f\u6027 : \u627e\u51fa\u91cd\u8981\u7684\u8b8a\u6578\n    * \u6536\u96c6\u8cc7\u6599 -> \u6578\u64da\u6e05\u7406 -> \u7279\u5fb5\u8403\u53d6 -> \u8cc7\u6599\u8996\u89ba\u5316 -> \u5efa\u7acb\u6a21\u578b -> \u9a57\u8b49\u6a21\u578b -> \u6c7a\u7b56\u61c9\u7528\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "        data = f.readlines() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8161101012817469
      ],
      "excerpt": "    plt.xlabel('Age Group (years)') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "for c in df.columns: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8396203625063012
      ],
      "excerpt": "for dtype, feature in zip(df.dtypes, df.columns): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "for c in df.columns: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.9560187895509076
      ],
      "excerpt": "    data = pd.concat([df[:train_num], train_Y], axis=1) \n    for c in df.columns: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8952741728839457
      ],
      "excerpt": "        data = pd.merge(data, mean_df, on=c, how='left') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9005816946135743
      ],
      "excerpt": "\u7fa4\u805a\u7de8\u78bc (Group by Encoding) : \u985e\u5225\u7279\u5fb5\u8207\u6578\u503c\u7279\u5fb5\u53ef\u4ee5\u4f7f\u7528\u7fa4\u805a\u7de8\u78bc\u7d44\u5408\u51fa\u65b0\u7684\u7279\u5fb5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9005816946135743
      ],
      "excerpt": "    | \u540d\u7a31                  | \u5747\u503c\u7de8\u78bc Encoding | \u7fa4\u805a\u7de8\u78bc Group by Encoding | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "    for train_index, test_index in kf.split(X): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.860059181823877
      ],
      "excerpt": "model = LinearRegression() \nmodel.fit(X, y) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123426876692197
      ],
      "excerpt": "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=50, random_state=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9159643228425749
      ],
      "excerpt": "\u4f7f\u7528 scikit-learn \u5957\u4ef6 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8022246123064651
      ],
      "excerpt": "\u6211\u5011\u53ef\u4ee5\u5f9e\u69cb\u5efa\u6a39\u7684\u904e\u7a0b\u4e2d\uff0c\u900f\u904e feature \u88ab\u7528\uf92d\u5207\u5206\u7684\u6b21\u6578\uff0c\uf92d\u5f97\u77e5\u54ea\u4e9b features \u662f\u76f8\u5c0d\u6709\u7528\u7684 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8930901044020226
      ],
      "excerpt": "        max_features=\"auto\", #\u5982\u4f55\u9078\u53d6 features        \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "Blending and Stacking \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "\u975e\u7d50\u69cb\u5316\u8cc7\u6599\u5206\u6790 : \u975e\u7d50\u69cb\u5316\u8cc7\u6599\u5982\u6587\u5b57\u3001\u5f71\u50cf\u7b49\uff0c\u53ef\u4ee5\u85c9\u7531\u4e00\u4e9b\u975e\u76e3\u7763\u5f0f\u5b78\u7fd2\u7684\u6280\u8853\uff0c\u5e6b\u52a9\u5448\u73fe\u53ca\u63cf\u8ff0\u8cc7\u6599\uff0c\u4f8b\u5982\u4e3b\u984c\u6a21\u578b (topic model) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9363031195295716
      ],
      "excerpt": "scikit-learn unsupervised learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9160101096309535
      ],
      "excerpt": "            \"The average silhouette_score is :\", silhouette_avg) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8485417044315646
      ],
      "excerpt": "K-means : \u9700\u8981\u5b9a\u7fa9\u7fa4\u6578 (n of clusters) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "X = iris.data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9255310243355104
      ],
      "excerpt": "\u6e1b\u5c11 RAM or disk space \u4f7f\u7528\uff0c\u6709\u52a9\u65bc\u52a0\u901f learning algorithm \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.942663053578573
      ],
      "excerpt": "\u7279\u5fb5\u592a\u591a\u6642\uff0c\u5f88\u96e3 visualize data\uff0c\u4e0d\u5bb9\uf9e0\u89c0\u5bdf\u8cc7\u6599\u3002\u628a\u8cc7\u6599\u7dad\u5ea6 (\u7279\u5fb5) \u964d\u5230 2 \u5230 3 \u500b\uff0c\u5247\u80fd\u5920\u7528\u4e00\u822c\u7684 2D \u6216 3D \u5716\u8868\u5448\u73fe\u8cc7\u6599 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8930901044020226
      ],
      "excerpt": "\u65b0 features \u70ba\u820a features \u7684\u7dda\u6027\u7d44\u5408\uff0c\u4e14\u5f7c\u6b64\u4e0d\u76f8\u95dc \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8930901044020226
      ],
      "excerpt": "\u4e0d\u5efa\u8b70\u5728\u65e9\u671f\u6642\u505a\uff0c\u5426\u5247\u53ef\u80fd\u6703\u4e1f\u5931\u91cd\u8981\u7684 features \u800c underfitting          \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.875620952400372
      ],
      "excerpt": "    * \u624b\u5beb\u8fa8\u8b58\u8cc7\u6599\u96c6\u7684\uf92d\u6e90 : \u624b\u5beb\u8fa8\u8b58\u8cc7\u6599\u96c6 (MNIST, Modified National Institute of Standards and Technology databas) \u539f\u59cb\uf92d\u6e90\u7684 NIST\uff0c\u61c9\u8a72\u662f\uf92d\u81ea\u65bc\u7f8e\u570b\u4eba\u53e3\u666e\u67e5\u5c40\u7684\u54e1\u5de5\u4ee5\u53ca\u5b78\u751f\u624b\u5beb\u6240\u5f97\uff0c\u5176\u4e2d\u7684 Modified \u6307\u7684\u662f\u8cc7\u6599\u96c6\u70ba\uf9ba\u9069\u5408\u6a5f\u5668\u5b78\u7fd2\u505a\uf9ba\u4e00\u4e9b\u8abf\u6574 : \u5c07\u539f\u59cb\u5716\u6848\u4e00\uf9d8\u8f49\u6210\u9ed1\u5e95\u767d\u5b57\uff0c\u505a\uf9ba\u5c0d\u61c9\u7684\u6297\u92f8\u9f52\u7684\u8abf\u6574\uff0c\u6700\u5f8c\u5b58\u6210 28x28 \u7684\u7070\u968e\u5716\u6848\uff0c\u6210\u70ba\uf9ba\u76ee\u524d\u6700\u5e38\u807d\u5230\u7684\u57fa\u790e\u5f71\u50cf\u8cc7\u6599\u96c6 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "    X_digits = digits.data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "for i, perplexity in enumerate(perplexities): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8214898973097775
      ],
      "excerpt": "|       | \u985e\u795e\u7d93\u7db2\u8def<br>(Neural Network)                        | \u6df1\u5ea6\u5b78\u7fd2<br>(Deep Learning)     | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112
      ],
      "excerpt": "        * \u7db2\u8def\u7d50\u69cb\uff1aCNN \u8207 RNN \u7b49\u7d50\u69cb\u5728\u795e\u7d93\u9023\u7d50\u4e0a\u505a\u6709\u610f\u7fa9\u7684\u7cbe\u7701\uff0c\u4f7f\u5f97\u8a08\u7b97\uf98a\u5f97\u4ee5\u7528\u5728\u5200\u53e3\u4e0a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8350687443705064
      ],
      "excerpt": "    * \u5377\u7a4d\u795e\u7d93\u7db2\uf937 (CNN, Convolutional Neural Network) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112,
        0.9627487715650112
      ],
      "excerpt": "* \u7d50\u69cb\u6539\u9032\uff1aCNN \uf96b\u8003\u50cf\u7d20\u9060\u8fd1\u7701\uf976\u795e\u7d93\u5143\uff0c\u4e26\u4e14\u7528\u5f71\u50cf\u7279\u5fb5\u7684\u5e73\u79fb\u4e0d\u8b8a\u6027\uf92d\u5171\u7528\u6b0a\u91cd\uff0c\u5927\u5e45\u6e1b\u5c11\uf9ba\u5f71\u50cf\u8a08\u7b97\u7684\u8ca0\u64d4 \n* \u884d\u4f38\u61c9\u7528\uff1a\u53ea\u8981\u7b26\u5408\u4e0a\u8ff0\uf978\u7a2e\u7279\u6027\u7684\u61c9\u7528\uff0c\u90fd\u53ef\u4ee5\u4f7f\u7528 CNN \u4f86\uf92d\u8a08\u7b97\uff0c\uf9b5\u5982 AlphaGo \u7684 v18 \u7248\u7684\uf978\u500b\u4e3b\u7db2\uf937\u90fd\u662f CNN \u5716\u7247 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8434862789565257
      ],
      "excerpt": "* Understanding neural networks with TensorFlow Playground \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8189582089620309
      ],
      "excerpt": "\u4e0b\u8f09\u5f8c\u9810\u8a2d\u5b58\u5132\u76ee\u9304 C:Users\\Administrator\\.keras\\datasets \u4e0b\u7684\u540c\u540d\u6a94\uff0c\u6ce8\u610f\u6709\u500b\u9ede .keras \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9400736744340845
      ],
      "excerpt": "    model = Sequential([Dense(32, _input_shap=(784,)), Activation(\u201crelu\u201d)]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.9298775026294136,
        0.8341589559722501
      ],
      "excerpt": "    model = Sequential() \n    model.add(Dense(32, _input_dim=784)) \n    model.add(Activation(\u201crelu\u201d)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8568522329397267,
        0.9196241412598118
      ],
      "excerpt": "2D \u7684\u7db2\u8def\u5c64\uff0c\u5982 Dense\uff0c\u5141\u8a31\u5728\u5c64\u7684\u69cb\u9020\u51fd\u6578\u7684 input_dim \u4e2d\u6307\u5b9a\u8f38\u5165\u7684\u7dad\u5ea6\u3002 \n\u5c0d\u65bc\u67d0\u4e9b 3D \u6642\u9593\u5c64\uff0c\u53ef\u4ee5\u5728\u69cb\u9020\u51fd\u6578\u4e2d\u6307\u5b9a input_dim \u548c input_length \u4f86\u5be6\u73fe\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.8341589559722501
      ],
      "excerpt": "* Model \u5ba3\u544a \n* model.add \u6dfb\u52a0\u5c64 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "* model.fit \u6a21\u578b\u8a13\u7df4\u53c3\u6578\u8a2d\u7f6e+\u8a13\u7df4 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9566902600437371
      ],
      "excerpt": "* Getting started with Keras Sequential model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "model = Sequential() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.9298775026294136,
        0.8341589559722501,
        0.8341589559722501,
        0.9298775026294136,
        0.8341589559722501
      ],
      "excerpt": "    model.add(Activation('relu')) \n    model.add(Conv2D(64, (5, 5))) \n    model.add(Activation('relu')) \n    model.add(Conv2D(128, (5, 5))) \n    model.add(Activation('relu')) \n    model.add(MaxPooling2D(pool_size=(2, 2))) \n    model.add(Dropout(0.25)) \n    model.add(Flatten()) \n    model.add(Dense(1024)) \n    model.add(Activation('relu')) \n    model.add(Dropout(0.25)) \n    model.add(Dense(num_classes)) \n    model.add(Activation('softmax')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "\u8f38\u5165\u662f\u5f35\uf97e\uff0c\u8f38\u51fa\u4e5f\u662f\u5f35\uf97e\u7684\u4e00\u500b\u6846\u67b6\u5c31\u662f\u4e00\u500b\u6a21\u578b\uff0c\u901a\u904e Model \u5b9a\u7fa9\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8577302739126875,
        0.8577302739126875
      ],
      "excerpt": "x = Dense(64, activation='relu')(x) \n    x = Dense(64, activation='relu')(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8577302739126875,
        0.8577302739126875
      ],
      "excerpt": "    x = Dense(64, activation='relu')(x) \n    x = Dense(64, activation='relu')(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8577302739126875,
        0.8577302739126875
      ],
      "excerpt": "x = Dense(64, activation='relu')(x) \n    x = Dense(64, activation='relu')(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model.summary() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8864184287814117
      ],
      "excerpt": "\u591a\u5c64\u611f\u77e5\u6a5f\u662f\u4e00\u7a2e\u524d\u5411\u50b3\u905e\u985e\u795e\u7d93\u7db2\uf937\uff0c\u81f3\u5c11\u5305\u542b\u4e09\u5c64\u7d50\u69cb (\u8f38\u5165\u5c64\u3001\u96b1\u85cf\u5c64\u548c\u8f38\u51fa\u5c64)\uff0c\u4e26\u4e14\uf9dd\u7528\u5230\u300c\u5012\u50b3\u905e\u300d\u7684\u6280\u8853\u9054\u5230\u5b78\u7fd2 (model learning) \u7684\u76e3\u7763\u5f0f\u5b78\u7fd2\uff0c\u4ee5\u4e0a\u662f\u50b3\u7d71\u7684\u5b9a\u7fa9\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model = Sequential() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8223311309099285
      ],
      "excerpt": "    model.add(Dense(units=256,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    train_history = model.fit(x=x_Train_normalize, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112
      ],
      "excerpt": "ReLU \u555f\u52d5\u51fd\u6578\u5c0d\u68af\u5ea6\u6d88\u5931\u554f\u984c\u6709\u4e00\u5b9a\u5c64\u5ea6\u7684\u89e3\u6c7a\uff0c\u5c24\u5176\u662f\u5728 CNN \u6a21\u578b\u4e2d \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762,
        0.9693233393948762
      ],
      "excerpt": "$\\to$ \u62c6\u89e3\u795e\u7d93\u7db2\u8def\u70ba\u5c40\u90e8\u8a2d\u8a08\u7b97\u55ae\u5143  \n$\\to$  \u7d66\u5b9a\u8a08\u7b97\u55ae\u5143  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "$\\to$ \u89e3\u51fd\u6578\u5fae\u5206  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8503829381739865
      ],
      "excerpt": "\u6df1\u5ea6\u5b78\u7fd2(Deep Learning)-\u53cd\u5411\u50b3\u64ad \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8430911133714853
      ],
      "excerpt": "    dtotal_price = 1 #this is linear function, which y=x, dy/dx=1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8487006637211075
      ],
      "excerpt": "model = Sequential() model.add(Dense(64, kernel_initializer='uniform', input_shape=(10,)))model.add(Activation('softmax\u2019))  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9852366115951547
      ],
      "excerpt": "            features is (50000, 400)  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9891785691729262
      ],
      "excerpt": "            batch_size is 128 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "            model = Sequential()  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501
      ],
      "excerpt": "            model.add(Activation('softmax\u2019)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9180837533376582
      ],
      "excerpt": "                Root mean square (RMS) of all Gradient \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8585052040793523
      ],
      "excerpt": "        * This optimizer is usually a good choice for recurrent neural networks.Arguments \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "            model = Sequential()  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501
      ],
      "excerpt": "            model.add(Activation('softmax\u2019)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9976340428791698
      ],
      "excerpt": "        * amsgrad\uff1aboolean. \u662f\u5426\u61c9\u7528\u6b64\u6f14\u7b97\u6cd5\u7684 AMSGrad \u8b8a\u7a2e\uff0c\uf92d\u81ea\u8ad6\u6587\u300cOn the Convergence of Adam and Beyond\u300d \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "        model = Sequential()  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501
      ],
      "excerpt": "        model.add(Activation('softmax\u2019)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "model.fit(x_train, y_train,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "model.fit(x_train, y_train,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.8169815468012596,
        0.860059181823877
      ],
      "excerpt": "        valid_loss = model.history.history[\"val_loss\"] \n        train_acc = model.history.history[\"accuracy\"] \n        valid_acc = model.history.history[\"val_accuracy\"] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8948916935560638,
        0.860059181823877
      ],
      "excerpt": "Model Graph\uff1a\u6a21\u578b\u7684\u67b6\u69cb\u662f\u5426\u5982\u9810\u671f\u6240\u60f3? \nmodel.summary() \u53ef\u4ee5\u770b\u5230\u6a21\u578b\u5806\u758a\u7684\u67b6\u69cb \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8087291026189342
      ],
      "excerpt": "Troubleshooting Deep Neural Networks \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9158914558056062
      ],
      "excerpt": "Gradient step computation is based on x + momentum \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8236729971225358
      ],
      "excerpt": "Estimating an Optimal Learning Rate For a Deep Neural Network \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "        for i, n_units in enumerate(num_neurons): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8277151318992411,
        0.860059181823877
      ],
      "excerpt": "        model = keras.models.Model(inputs=[input_layer], outputs=[out]) \n        return model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "        model.summary() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "        model.fit(x_train, y_train,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.8169815468012596,
        0.860059181823877
      ],
      "excerpt": "        valid_loss = model.history.history[\"val_loss\"] \n        train_acc = model.history.history[\"accuracy\"] \n        valid_acc = model.history.history[\"val_accuracy\"] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9107201691432821
      ],
      "excerpt": "    for i, cond in enumerate(results.keys()): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9107201691432821
      ],
      "excerpt": "    for i, cond in enumerate(results.keys()): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8067155780522604
      ],
      "excerpt": "$\\to$ \u5c0d input \u8b8a\u5316\u6bd4\u8f03\u4e0d\u654f\u611f \u2794 better generalization \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "for i, n_units in enumerate(num_neurons): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8277151318992411,
        0.860059181823877
      ],
      "excerpt": "model = keras.models.Model(inputs=[input_layer], outputs=[out]) \nreturn model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8539685378419594
      ],
      "excerpt": "    for l1r, l2r in itertools.product(L1_EXP, L2_EXP): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "        model.summary() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "        model.fit(x_train, y_train,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.8169815468012596,
        0.860059181823877
      ],
      "excerpt": "        valid_loss = model.history.history[\"val_loss\"] \n        train_acc = model.history.history[\"accuracy\"] \n        valid_acc = model.history.history[\"val_accuracy\"] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8710674309052164
      ],
      "excerpt": "Dropout in (Deep) Machine learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "for i, n_units in enumerate(num_neurons): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8277151318992411,
        0.860059181823877
      ],
      "excerpt": "model = keras.models.Model(inputs=[input_layer], outputs=[out]) \nreturn model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233198152388715,
        0.8249583491016954
      ],
      "excerpt": "Input : Values of x over a mini-batch : $B = {x_{1...m}}$; \n            Parameters to be learn : $\\gamma, \\beta$ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "for i, n_units in enumerate(num_neurons): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8277151318992411,
        0.860059181823877
      ],
      "excerpt": "model = keras.models.Model(inputs=[input_layer], outputs=[out]) \nreturn model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "        for i, n_units in enumerate(num_neurons): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8277151318992411,
        0.860059181823877
      ],
      "excerpt": "        model = keras.models.Model(inputs=[input_layer], outputs=[out]) \n        return model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8539685378419594
      ],
      "excerpt": "    for i, (use_bn, drp_ratio, l2_ratio) in enumerate(itertools.product(USE_BN, DRP_RATIO, L2_RATIO)): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "        model.summary() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "        model.fit(x_train, y_train,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "                                'valid-acc': model.history.history[\"val_accuracy\"]} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model.fit(x_train, y_train,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.860059181823877
      ],
      "excerpt": "Day_86 : \u8a13\u7df4\u795e\u7d93\u7db2\u8def\u7684\u7d30\u7bc0\u8207\u6280\u5de7 - \u4f7f\u7528 callbacks \u51fd\u6578\u5132\u5b58 model \nModel CheckPoint \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model.fit(x_train, y_train,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model.save_weights(\"model_weights.h5\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model.fit(x_train, y_train,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "            for i in record_items: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model.fit(x_train, y_train,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "valid_f1sc = model.history.history['val_f1sc'] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "            for i in record_items: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model.fit(x_train, y_train,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.860059181823877
      ],
      "excerpt": "    valid_tp = model.history.history['val_tp'] \n    valid_tn = model.history.history['val_tn'] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model.summary() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model.fit(x_train, y_train,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "    for i, ce_w in enumerate(ce_weights_list): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "        model.summary() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "        model.fit(x_train, y_train,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "        for chan in chans: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "        for chan in chans: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "        hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9652735290268716
      ],
      "excerpt": "    ax.set_title('cifar10 by SVM with different features') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "        for rect in rects: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8434944177421086
      ],
      "excerpt": "Day_92 : \u5377\u7a4d\u795e\u7d93\u7db2\uf937(Convolution Neural Network, CNN) \u7c21\u4ecb \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8684117340027778,
        0.9627487715650112
      ],
      "excerpt": "\u5176\u5be6\u662f\u900f\u904e\u8cc7\u6599\u5b78\u7fd2\u800c\uf92d\u7684! \u9019\u4e5f\u5c31\u662f CNN \u6a21\u578b\u4e2d\u7684\uf96b\u6578 (\u6216\u53eb\u6b0a\u91cd weights) \nCNN \u6703\u81ea\u52d5\u5f9e\u8a13\u7df4\u8cc7\u6599\u4e2d\u5b78\u7fd2\u51fa\u9069\u5408\u7684\u6ffe\u6ce2\u5668\uf92d\u5b8c\u6210\u4f60\u7684\u4efb\u52d9 (\u5206\u985e\u3001\u5075\u6e2c\u7b49) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8480124186250417
      ],
      "excerpt": "\u6df1\u5ea6\u5b78\u7fd2\uff08Deep learning\uff09\u4e2d\u7684 CNN \u8f03\u50b3\u7d71\u7684 DNN \u591a\uf9ba Convolutional\uff08\u5377\u7a4d\uff09\u53ca\u6c60\u5316\uff08Pooling\uff09\uf978\u5c64 layer\uff0c\u7528\u4ee5\u7dad\u6301\u5f62\uf9fa\u8cc7\u8a0a\u4e26\u4e14\u907f\u514d\uf96b\u6578\u5927\u5e45\u589e\u52a0\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8477678735851494
      ],
      "excerpt": "model = models.Sequential() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501
      ],
      "excerpt": "`Model.add(Convolution2D(32, 3, 3), input_shape=(1, 28, 28), strides=2, padding='valid\u2019)` \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112
      ],
      "excerpt": "    * \u5377\u7a4d\u795e\u7d93\u7db2\uf937 (CNN) \u7279\u6027 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112
      ],
      "excerpt": "    * CNN \u91dd\u5c0d\u5f71\u50cf\u8fa8\u8b58\u7684\u7279\u6027\uff0c\u7279\u5225\u8a2d\u8a08\u904e\uff0c\uf92d\u6e1b\u5c11\uf96b\u6578 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9077517730725372
      ],
      "excerpt": "* AlphaGo \u4e5f\u7528\uf9ba CNN\uff0c\u4f46\u662f\u6c92\u6709\u7528 Max Pooling (\u6240\u4ee5\u4e0d\u554f\u984c\u9700\u8981\u4e0d\u540c model) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8624481107953429
      ],
      "excerpt": "        X_pad -- image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C) \u505a\u5b8czero-padding \u7684\u7d50\u679c \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "        hparameter \u8d85\u53c3\u6578 --  \"f\" and \"stride\" \u6240\u5f62\u6210\u7684python \u5b57\u5178 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model.summary() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112
      ],
      "excerpt": "CNN \u76f8\u6bd4 DNN\uff0c\uf901\u9069\u5408\u7528\u4f86\uf92d\u8655\uf9e4\u5f71\u50cf\u7684\u8cc7\u6599\u96c6 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.9298775026294136,
        0.8341589559722501,
        0.9298775026294136,
        0.8341589559722501,
        0.9298775026294136,
        0.860059181823877
      ],
      "excerpt": "    model = Sequential() \n    model.add(Dense(512, activation='relu', input_shape=(3072,))) \n    model.add(Dropout(0.2)) \n    model.add(Dense(512, activation='relu')) \n    model.add(Dropout(0.2)) \n    model.add(Dense(num_classes, activation='softmax')) \n    model.summary() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    history = model.fit(x_train, y_train, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.807631595615733
      ],
      "excerpt": "    score = model.evaluate(x_test, y_test, verbose=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model = Sequential() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501
      ],
      "excerpt": "    model.add(Activation('relu')) \n    model.add(Conv2D(32, (3, 3))) \n    model.add(Activation('relu')) \n    model.add(MaxPooling2D(pool_size=(2, 2))) \n    model.add(Dropout(0.25)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.9298775026294136,
        0.8341589559722501,
        0.8341589559722501,
        0.9298775026294136,
        0.8341589559722501,
        0.860059181823877
      ],
      "excerpt": "    model.add(Activation('relu')) \n    model.add(Conv2D(64, (3, 3))) \n    model.add(Activation('relu')) \n    model.add(MaxPooling2D(pool_size=(2, 2))) \n    model.add(Dropout(0.25)) \n    model.add(Flatten()) \n    model.add(Dense(512)) \n    model.add(Activation('relu')) \n    model.add(Dropout(0.5)) \n    model.add(Dense(num_classes)) \n    model.add(Activation('softmax')) \n    model.summary() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    history = model.fit(x_train, y_train, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.807631595615733
      ],
      "excerpt": "    score = model.evaluate(x_test, y_test, verbose=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9078931312685983
      ],
      "excerpt": "\u4f46\u662f\u5982\u679c\u6211\u5011\u8981\u8655\uf9e4\u7684\u8cc7\u6599\u96c6\u8d85\u904e\u96fb\u8166\u8a18\u61b6\u9ad4\u7684\u5bb9\uf97e\u5462\uff1f\u684c\u4e0a\u96fb\u8166\u7684\u8a18\u61b6\u9ad4\u591a\u70ba 32, 64, 128 GB\uff0c\u7576\u8655\uf9e4\u8d85\u5927\u5716\u7247\u30013D \u5f71\u50cf\u6216\u5f71\u7247\u6642\uff0c\u5c31\u53ef\u80fd\u9047\u5230 Out of Memory error \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model = Sequential() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501
      ],
      "excerpt": "    model.add(Activation('relu')) \n    model.add(Conv2D(32, (3, 3))) \n    model.add(Activation('relu')) \n    model.add(MaxPooling2D(pool_size=(2, 2))) \n    model.add(Dropout(0.25)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.9298775026294136,
        0.8341589559722501,
        0.8341589559722501,
        0.9298775026294136,
        0.8341589559722501,
        0.860059181823877
      ],
      "excerpt": "    model.add(Activation('relu')) \n    model.add(Conv2D(64, (3, 3))) \n    model.add(Activation('relu')) \n    model.add(MaxPooling2D(pool_size=(2, 2))) \n    model.add(Dropout(0.25)) \n    model.add(Flatten()) \n    model.add(Dense(512)) \n    model.add(Activation('relu')) \n    model.add(Dropout(0.5)) \n    model.add(Dense(num_classes)) \n    model.add(Activation('softmax')) \n    model.summary() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "history = model.fit_generator(train_generator, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.807631595615733
      ],
      "excerpt": "    score = model.evaluate(x_test, y_test, verbose=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8979411005071259
      ],
      "excerpt": "\u9664\u4e86\u7e7c\u7e8c\u641c\u96c6\u8cc7\u6599\u4ee5\u5916\uff0c\u8cc7\u6599\u589e\u5f37 (Data augmentation) \u662f\u5f88\u5e38\u2f92\u7684\u2f45\u6cd5\u4e4b\u2f00 \n\u8cc7\u6599\u589e\u5f37 (Data augmentation)  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model = Sequential() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501
      ],
      "excerpt": "    model.add(Activation('relu')) \n    model.add(Conv2D(32, (3, 3))) \n    model.add(Activation('relu')) \n    model.add(MaxPooling2D(pool_size=(2, 2))) \n    model.add(Dropout(0.25)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.9298775026294136,
        0.8341589559722501,
        0.8341589559722501,
        0.9298775026294136,
        0.8341589559722501,
        0.860059181823877
      ],
      "excerpt": "    model.add(Activation('relu')) \n    model.add(Conv2D(64, (3, 3))) \n    model.add(Activation('relu')) \n    model.add(MaxPooling2D(pool_size=(2, 2))) \n    model.add(Dropout(0.25)) \n    model.add(Flatten()) \n    model.add(Dense(512)) \n    model.add(Activation('relu')) \n    model.add(Dropout(0.5)) \n    model.add(Dense(num_classes)) \n    model.add(Activation('softmax')) \n    model.summary() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.807631595615733
      ],
      "excerpt": "    score = model.evaluate(x_test, y_test, verbose=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112
      ],
      "excerpt": "\u524d\u9762 CNN \u7684\u8ab2\u7a0b\u6709\u63d0\u5230\uff0cCNN \u6dfa\u5c64\u7684\u904e\u6ffe\u5668 (filter) \u662f\u7528\u4f86\u5075\u6e2c\u7dda\u689d\u8207\u984f\u8272\u7b49\u7c21\u55ae\u7684\u5143\u7d20\u3002\u56e0\u6b64\u4e0d\u7ba1\u5716\u50cf\u662f\u4ec0\u9ebc\u985e\u578b\uff0c\u57fa\u672c\u7684\u7d44\u6210\u61c9\u8a72\u8981\u662f\u4e00\u6a23\u7684 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8891713841937107
      ],
      "excerpt": "Transfer learning in Keras: ResNet-50 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8100573613878744,
        0.8535411499964382,
        0.8154104550603786
      ],
      "excerpt": "        Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs. \n        Called automatically every epoch as part of callbacks during training. \nepoch (int): The number of epochs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421230500230114
      ],
      "excerpt": "            num_filters (int): Conv2D number of filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9968029537584643
      ],
      "excerpt": "        Stacks of 2 x (3 x 3) Conv2D-BN-ReLU \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9099430284623684,
        0.9484155754554303
      ],
      "excerpt": "        At the beginning of each stage, the feature map size is halved (downsampled) \n        by a convolutional layer with strides=2, while the number of filters is \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9023136079000657
      ],
      "excerpt": "        Features maps sizes: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9673758155101186
      ],
      "excerpt": "        The Number of parameters is approx the same as Table 6 of [a]: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.81892906468534
      ],
      "excerpt": "input_shape (tensor): shape of input image tensor \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8483267776137055
      ],
      "excerpt": "model (Model): Keras model instance \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8014716303298044
      ],
      "excerpt": "for stack in range(3): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "        return model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model.summary() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112,
        0.9627487715650112
      ],
      "excerpt": "Day_105 : CNN \u5377\u7a4d\u7db2\uf937\u6f14\u9032\u548c\u61c9\u7528 \n\u5377\u7a4d\u7db2\uf937 CNN \u7684\u9032\u5c55\u7c21\u5716 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112,
        0.8290778173733818
      ],
      "excerpt": "CNN \u5716\u50cf\u8655\uf9e4\u4e0a\u6709\u4e0d\u540c\u7684\u6a21\u578b \n\u4e3b\u8981\u7684\u5143\u7d20\uff1aROI, CNN feature map, anchor boxes, mask \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222116477513647
      ],
      "excerpt": "Image Description : CNN + LSTM \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112
      ],
      "excerpt": "R-CNN (Regional CNN) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112
      ],
      "excerpt": "R-CNN \u7684\u76ee\u6a19\u662f\uff1a\u5c0e\u5165\u4e00\u5f35\u5716\u7247\uff0c\u901a\u904e\u65b9\u6846\u6b63\u78ba\u8b58\u5225\u4e3b\u8981\u7269\u9ad4\u5728\u5716\u50cf\u7684\u54ea\u500b\u5730\u65b9\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112,
        0.9627487715650112
      ],
      "excerpt": "R-CNN \u7684\u8655\uf9e4\u65b9\u5f0f \u2014 \u5728\u5716\u50cf\u4e2d\u641e\u51fa\u4e00\u5927\u5806\u65b9\u6846\uff0c\u770b\u770b\u662f\u5426\u6709\u4efb\u4f55\u4e00\u500b\u8207\u67d0\u500b\u7269\u9ad4\u91cd\u758a \n\u751f\u6210\u9019\u4e9b\u908a\u6846\u3001\u6216\u8005\u8aaa\u662f\u63a8\u85a6\u5c40\u57df\uff0cR-CNN \u63a1\u7528\u7684\u662f\u4e00\u9805\u540d\u70ba Selective Search \u7684\u6d41\u7a0b \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112,
        0.9627487715650112
      ],
      "excerpt": "\u7576\u908a\u6846\u65b9\u6848\u751f\u6210\u4e4b\u5f8c\uff0cR-CNN \u628a\u9078\u53d6\u5340\u57df\u8b8a\u5f62\u70ba\u6a19\u6e96\u7684\u65b9\u5f62 \n\u5728 CNN \u7684\u6700\u5f8c\u4e00\u5c64\uff0cR-CNN \u52a0\u5165\uf9ba\u4e00\u500b\u652f\u6301\u5411\uf97e\u6a5f\uff0c\u5b83\u8981\u505a\u7684\u4e8b\u5f88\u7c21\u55ae\uff1a\u5c0d\u9019\u662f\u5426\u662f\u4e00\u500b\u7269\u9ad4\u9032\ufa08\u5206\u985e\uff0c\u5982\u679c\u662f\uff0c\u662f\uf9fd\u9ebc\u7269\u9ad4\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112,
        0.9627487715650112
      ],
      "excerpt": "\u7b54\u6848\u662f\u80af\u5b9a\u7684\uff0c\u9019\u662f R-CNN \u7684\u6700\u5f8c\u4e00\u6b65\u3002 \nR-CNN \u5728\u63a8\u85a6\u5340\u57df\u4e0a\u904b\ufa08\u4e00\u500b\u7c21\u55ae\u7684\u7dda\u6027\u56de\u6b78\uff0c\u751f\u6210\uf901\u7dca\u7684\u908a\u6846\u5750\u6a19\u4ee5\u5f97\u5230\u6700\u7d42\u7d50\u679c\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112
      ],
      "excerpt": "\u6982\u62ec\u4e0b\uf92d\uff0cR-CNN \u53ea\u662f\u4ee5\u4e0b\u9019\u5e7e\u500b\u6b65\u9a5f\uff1a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.911478160601604
      ],
      "excerpt": "Labeled Face in the wilds \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Halesu/4th-ML100Days/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Thu, 09 Dec 2021 09:36:47 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Halesu/4th-ML100Days/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Halesu/4th-ML100Days",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_081_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_004_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_016_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_024_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_087_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_034_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_026_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_019_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_014_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_022_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_094_CNN_Convolution_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_043_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_031_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_029_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_084_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_095_CNN_Pooling_Padding_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_078_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_040_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_033_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_020_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_091_classification_with_cv_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_003_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_011_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_072_Activation_function_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_085_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_063_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_100_transfer_learning_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_077_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_013_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_069_keras_Module_API_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_074_Gradient_Descent_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_005_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_080_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_039_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_045_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_101_Final-term_2.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_001_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_050_Stacking_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_066_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_090_color_histogram_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_079_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_023_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_096_Keras_CNN_layers.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_070_Keras_Mnist_MLP_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_028_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_032_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_036_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_093_CNN_Brief_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_049_Blending_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_002_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_064_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_098_Python_generator.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_035_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_012_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_018_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_038_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_088_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_105_CNN_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_008_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_021_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_065_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_007_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_082_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_061_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_067_Keras_Dataset_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_058_hierarchical_clustering_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_097_Keras_CNN_vs_DNN.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_046_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_060_PCA_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_073_Gradient_Descent_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_042_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_071_%E4%BD%BF%E7%94%A8%E6%90%8D%E5%A4%B1%E5%87%BD%E6%95%B8_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_041_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_006_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_075_Back_Propagation_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_027_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_044_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_055_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_059_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_017_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_092_CNN_theory.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_051_Mid-term.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_054_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_009_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_030_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_015_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_010_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_068_Keras_Sequential_Model_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_056_kmean_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_099_data_augmentation.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_083_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_101_Final-term.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_037_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_086_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_047_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_076_optimizer_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_025_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_057_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_048_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_104_ConvNetJS_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_089_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/Day_062_tsne_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_004_first_EDA_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_061_tsne_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_073_Gradient_Descent_Ans.ipynb.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_019_EDA_subplots_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_044_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_065_Experience_of_DNN2_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_036_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_072_Activation_function.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_014_correlation_example.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_076_optimizer_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_100_transfer_learning.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_040_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_038_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_017_discretizing_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_013_dataFrame_operation.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_049_Blending.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_070_Keras_Mnist_MLP_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_093_CNN_Brief.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_027_DayTime_Features.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_071_%E4%BD%BF%E7%94%A8%E6%90%8D%E5%A4%B1%E5%87%BD%E6%95%B8.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_042_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_012_Fill_NaN_and_Scalers_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_057_hierarchical_clustering_sample.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_043_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_094_CNN_Convolution%20.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_080_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_005-2_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_035_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_007_Feature_Types_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_055_kmean_sample.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_024_LabelEncoder_and_OneHotEncoder.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_066_Win10_InstallTensorFlow_gpu%26Keras.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_019_EDA_subplots.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_099_data_augmentation_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_089_CustomizedLoss_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_058_hierarchical_clustering_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_015_correlation_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_066_Keras_Introduction.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_075_Back_Propagation_Advanced.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_095_CNN_Pooling_Padding_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_067_Keras_Dataset_Introduce.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_022_Introduction_of_Feature%20Engineering.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_104_ConvNetJS.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_082_Dropout.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_028_Feature_Combination.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_076_optimizer_example.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_058_hierarchical_clustering.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_073_Gradient%20Descent.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_009_outliers_detection_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_042_decision_tree.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_091_classification_with_cv_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_087_CB_ReduceLR.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_047_hyper_parameter_tunning.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_078_CheckBeforeTrain_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_084_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_004_first_EDA.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_030_Feature_Selection.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_079_LearningRateEffect_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_069_keras_Module_API_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_034_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_005-2_read_and_write_files.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_009_outliers_detection.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_088_CB_CustomizedCallbacks.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_007_Feature_Types.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_044_random_forest.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_055_kmean_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_001_example_of_metrics.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_005-1_build_dataframe_from_scratch.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_057_hierarchical_clustering_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_064_Experience_of_DNN1_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_090_color_histogram.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_089_CustomizedLoss.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_086_CB_ModelCheckPoint.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_105_CNN_sample.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_028_Feature_Combination_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_018_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_032_Leaf_Encoding.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_068_Keras_Sequential_Model.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_025_Mean_Encoder.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_056_kmean.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_105_CNN_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_062_tsne_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_047_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_020_EDA_heatmap.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_029_GroupBy_Encoder_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_091_classification_with_cv.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_069_keras_Module_API.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_001_example_of_metrics_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_079_LearningRateEffect.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_074_Gradient%20Descent_Math.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_050_Stacking_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_037_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_078_CheckBeforeTrain.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_015-supplementary_correlation_and_plot_with_different_range.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_038_regression_model.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_046_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_096_Keras_CNN_layers_solution.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_056_kmean_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_104_ConvNetJS_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_016_EDA_KDEplots_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_074_Gradient%20Descent_%E6%95%B8%E5%AD%B8%E5%BC%8F%E8%AA%AA%E6%98%8E.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_092_CNN_theory_solution.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_003_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_083_BatchNorm_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_054_Clustering_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_040_lasso_ridge_regression.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_086_CB_ModelCheckPoint_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_070_Keras_Mnist_MLP_Sample.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_039_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_029_GroupBy_Encoder.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_081_Regulization.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_023_Reduce_Skewness.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_074_Gradient_Descent_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_085_CB_EarlyStop_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_006_column_data_type_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_098_Python_generator_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_017_discretizing.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_036_evaluation_metrics.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_005-1_HW.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_087_CB_ReduceLR_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_088_CB_CustomizedCallbacks_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_013_dataFrame_operation_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_002_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_023_Reduce_Skewness_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_026_CountEncoder_and_FeatureHash.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_066_Keras_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_067_Keras_Dataset_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_100_transfer_learning_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_062_tsne.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_010_Outliers.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_093_CNN_Brief_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_031_Feature_Importance.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_005-3_read_and_write_files.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_075_Back_Propagation_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_059_PCA_sample.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_008_distribution_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_066_Introduction_of_Keras.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_095_CNN_Pooling_Padding.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_076_Optimizers_%E9%80%B2%E9%9A%8E.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_063_Intro_of_DNN_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_011_handle_outliers_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_041_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_090_color_histogram_%20Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_075_Back_Propagation.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_020_EDA_heatmap_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_033_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_082_Dropout_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_060_PCA_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_046_gradient_boosting_machine.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_060_PCA.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_081_Regulization_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_072_Activation_function_Ans%20.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_083_BatchNorm.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_022_Introduction_of_Feature%20Engineering_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_014_correlation_example_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_034_train_test_split.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_010_Outliers_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_059_PCA_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_049_Blending_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_061_tsne_sample.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_094_CNN_convolution_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_050_Stacking.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_077_overfitting.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_024_LabelEncoder_and_OneHotEncoder_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_097_Keras_CNN_vs_DNN_solution.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_016_EDA_KDEplots.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_085_CB_EarlyStop.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_012_Fill_NaN_and_Scalers.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_027_DayTime_Features_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_068_Keras_Sequential_Model_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_077_overfitting_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_011_handle_outliers.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_021_first_model.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_005-2_read_and_write_files_Ans.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_006_column_data_type.ipynb",
      "https://raw.githubusercontent.com/Halesu/4th-ML100Days/master/homework/samples_ans/Day_032_Leaf_Encoding_Ans.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "            preprocessing_function=None,\n            ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "            rescale=None,\n            ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "            fill_mode='nearest',\n            ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "            channel_shift_range=0.,\n            ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "            zoom_range=0.,\n            ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "            shear_range=0.,\n            ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "            samplewise_center=False,\n            ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "            featurewise_center=False,\n            ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n        print('x_train shape:', x_train.shape)\n        print(x_train.shape[0], 'train samples')\n        print(x_test.shape[0], 'test samples')\n\n        ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "Python npy \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9204365296776966
      ],
      "excerpt": "    %matplotlib notebook #: \u4e92\u52d5\u65b9\u5f0f \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.827951219365835
      ],
      "excerpt": "    from scipy.stats import mode \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8133896863190215
      ],
      "excerpt": "    * [Python Graph Gallery](https://python-graph-gallery.com/) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8369973887646881
      ],
      "excerpt": "    * [matplotlib \u5b98\u2f45\u65b9\u7bc4\u4f8b\uf9b5](https://matplotlib.org/examples/pylab_examples/subplots_demo.html) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8562669461127935
      ],
      "excerpt": "    * [\u57fa\u672c Heatmap](https://matplotlib.org/gallery/images_contours_and_fields/image_annotated_heatmap.html) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8071993489396445
      ],
      "excerpt": "    from scipy import stats \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8732089505944296
      ],
      "excerpt": "    * [\u7279\u5fb5\u4ea4\u53c9](https://segmentfault.com/a/1190000014799038) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8732089505944296
      ],
      "excerpt": "    * [\u7279\u5fb5\u9078\u64c7](https://zhuanlan.zhihu.com/p/32749489) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8732089505944296
      ],
      "excerpt": "    * [\u66f4\u591a\u8a55\u4f30\u6307\u6a19](https://zhuanlan.zhihu.com/p/30721429) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8820234121644812
      ],
      "excerpt": "Kernels \u53ef\u4ee5\u770b\ufa0a\u8a31\u591a\u9ad8\u624b\u5011\u5206\u4eab\u7684\u7a0b\u5f0f\u78bc\u8207\u7d50\u679c\uff0c\u591a\u534a\u6703\u4ee5 jupyter notebook \u5448\u73fe \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9748709027320682
      ],
      "excerpt": "        * \u5716\u5f62\u8655\uf9e4\u5668 (GPU) \u7684\u8a95\u751f\uff0c\u6301\u7e8c\uf9ba\u6676\u7247\u6469\u723e\u5b9a\uf9d8\uff0c\u8b93\u8a08\u7b97\u6210\u70ba\u53ef\ufa08 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9436981238821197
      ],
      "excerpt": "TensorFlow \u5c07\u6df1\u5ea6\u5b78\u7fd2\u4e2d\u7684 GPU/CPU \u6307\u4ee4\u5c01\u88dd\u4f86\uf92d\uff0c\u6e1b\u5c11\u8a9e\u6cd5\u5dee\uf962\uff0cKeras \u5247\u662f\u5c07\u524d\u8005\uf901\u8fd1\u4e00\u6b65\u5c01\u88dd\u6210\u55ae\u4e00\u5957\u4ef6\uff0c\u7528\u5c11\uf97e\u7684\u7a0b\u5f0f\uf965\u80fd\u5be6\u73fe\u7d93\u5178\u6a21\u578b \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9748709027320682,
        0.9748709027320682
      ],
      "excerpt": "* \u662f\u5426\u6709 GPU :  \n    * \u56e0\u70ba\u6709 GPU \u5247\u9700\u8981\u5148\u88dd GPU \u7684\u6307\u4ee4\u96c6\uff0c\u6240\u4ee5\u6709 GPU \u5247\u9700\u8981 4 \u500b\u6b65\u9a5f\uff0c\u6c92\u6709\u5c31\u53ea\u9700\u8981 2 \u6b65\u9a5f \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9888341170895307
      ],
      "excerpt": "    * \u56e0\u70ba\u4e0d\u540c\u4f5c\u696d\u7cfb\u7d71\u9593\uff0cGPU \u7684\u5b89\u88dd\u6b65\u9a5f\u6703\u56e0\u4ecb\u9762\u6216\u6307\u4ee4\u6709\u6240\u4e0d\u540c\uff0c\u6240\u4ee5\u6211\u5011\u6703\u5206 Windows / Linux (\u4ee5Ubuntu\u70ba\uf9b5) / Mac \u5206\u5225\u4ecb\u7d39\u6d41\u7a0b \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9704956814041731,
        0.8709543750133144,
        0.9748709027320682
      ],
      "excerpt": "    * \u7531\u65bc GPU \u7684 CUDA / cuDNN \u7248\u672c\u7d93\u5e38\u5347\u7d1a\uff0c\u56e0\u6b64 TensorFlow / Keras \u7684\u7248\u672c\u4e5f\u9700\u8981\u983b\u7e41\uf901\u63db\u7248\u672c\uff0c\u56e0\u6b64\u5efa\u8b70\u4ee5\u5b89\u88dd\u7576\u6642\u7684\u5b98\u7db2\u8cc7\u8a0a\u70ba\u6e96 \n\u5b89\u88dd Keras \u5927\u81f4\u4e0a\u5206\u70ba\u56db\u500b\u6b65\u9a5f : \u4f9d\u5e8f\u5b89\u88dd CUDA / cuDNN / TensorFlow / Keras\uff0c\u53ea\u8981\u6ce8\u610f\u56db\u500b\u7a0b\u5f0f\u9593\u7684\u7248\u672c\u554f\u984c\u4ee5\u53ca\u865b\u64ec\u74b0\u5883\u554f\u984c\uff0c\u57fa\u672c\u4e0a\u61c9\u8a72\u80fd\u9806\uf9dd\u5b89\u88dd\u5b8c\u6210 \n\u5b89\u88dd\u6d41\u7a0b - \u6c92\u6709 GPU \u7248 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9967777177014457,
        0.8170236979371944
      ],
      "excerpt": "    pip install tensorflow \nUbuntu \u524d\u9762\u52a0\u4e0a sudo \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.999746712887969,
        0.9854410232187837,
        0.9748709027320682
      ],
      "excerpt": "    pip install keras \nPython \u627e\u4e0d\u5230 pip \u6307\u4ee4\uff0c\u53ef\u4ee5\u63a1\u7528 pip3 \u4ee3\u66ff\u57f7\ufa08\u5b89\u88dd \n\u5b89\u88dd\u6d41\u7a0b - \u6709 GPU \u7248 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8871431638691084,
        0.9990696733218749
      ],
      "excerpt": "Step 3 - \u5b89\u88dd TensorFlow GPU \u7248 \n    pip install tensorflow-gpu \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.999746712887969
      ],
      "excerpt": "    pip install keras \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9338153368532566,
        0.8669546328421279,
        0.9096944792198101,
        0.8411004553040458
      ],
      "excerpt": "(\u53ea\u6709 Windows \u9700\u8981, \u5176\u4ed6\u4f5c\u696d\u7cfb\u7d71\u8acb\u8df3\u904e) \u5982\u679c\u662f Win10\uff0c\u53ef\u5f9e\u958b\u59cb / \u63a7\u5236\u53f0 / \u7cfb\u7d71\u958b\u555f\u8996\u7a97\u5f8c\uff0c\u9ede\u9078\"\u9032\u968e\"\u5206\u9801\u6700\u4e0b\u9762\u7684\u6309\u9215\"\u74b0\u5883\u8b8a\u6578\"\uff0c\u6703\u8df3\u51fa\u4e0b\u5217\uf99c\u8996\u7a97\uff0c\u8acb\u5728\u4e0b\u534a\u8996\u7a97\u4e2d\u5c0b\u627e\"Path\"\u8b8a\u6578\uff0c\u628a\u4e0b\u5217\uf99c\uf978\u500b\uf937\u5f91\u52a0\u5165 \n    C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin \n    C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\libnvvp \n    \u9805\u76ee\u9593\u8981\u7528\u5206\u865f ; \u9694\u958b / CUDA \u7248\u865f\u8acb\u4f9d Step1 \u5be6\u969b\u5b89\u88dd\u7248\u672c\u70ba\u6e96 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "\u5ba3\u544a\u4e00\u500b NAME \u53bb\u5b9a\u7fa9Input \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8820234121644812
      ],
      "excerpt": "\u9069\u7528\u65bc Jupyter Notebook, \u5ba3\u544a\u76f4\u63a5\u5728cell \u5167\u5370\u51fa\u57f7\u884c\u7d50\u679c \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8516685309054747
      ],
      "excerpt": "            #\u5be6\uf9b5\u5316\u4e00\u500b\u512a\u5316\u5668\u5c0d\u8c61\uff0c\u7136\u5f8c\u5c07\u5b83\u50b3\u5165model.compile() , \u53ef\u4ee5\u4fee\u6539\uf96b\u6578  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8516685309054747
      ],
      "excerpt": "            #\u5be6\uf9b5\u5316\u4e00\u500b\u512a\u5316\u5668\u5c0d\u8c61\uff0c\u7136\u5f8c\u5c07\u5b83\u50b3\u5165model.compile() , \u53ef\u4ee5\u4fee\u6539\uf96b\u6578 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8789379168032526
      ],
      "excerpt": "    * [Overfitting vs. Underfitting](https://towardsdatascience.com/overfitting-vs-underfitting-a-complete-example-d05dd7e19765) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9748709027320682
      ],
      "excerpt": "\u8a13\u7df4\u6a21\u578b\u7684\u6642\u9593\u8ddf\u6210\u672c\u90fd\u5f88\u5927 (\u5982 GPU quota & \u4f60/\u59b3\u7684\u4eba\u751f) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9790147179179336
      ],
      "excerpt": "\u4f7f\u7528\u7684\u88dd\u7f6e\uff1a\u662f\u4f7f\u7528 CPU or GPU / \u60f3\u8981\u4f7f\u7528\u7684 GPU \u662f\u5426\u5df2\u7d93\u88ab\u5225\u4eba\u4f54\u7528? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "\u83ab\u7169 Python - \u5132\u5b58\u8207\u8f09\u56de\u6a21\u578b \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8089438626674299
      ],
      "excerpt": "    * [OpenCv - \u6559\u5b78\u6587\u6a94](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233588558014837
      ],
      "excerpt": "            A -- \u8f38\u51fa\u7684\u6c60\u5316\u5c64, \u7dad\u5ea6\u70ba (m, n_H, n_W, n_C) \u7684 numpy \u9663\u5217 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8630727482803922,
        0.8837680365796365
      ],
      "excerpt": "\u5982\u540c\u8a13\u7df4\u795e\u7d93\u7db2\uf937\u6642\uff0cBatch (\u6279\u6b21) \u7684\u6982\uf9a3\u4e00\u6a23\u3002\u6211\u5011\u53ef\u4ee5\u5c07\u8cc7\u6599\u4e00\u6279\u4e00\u6279\u7684\u8b80\u9032\u8a18\u61b6\u9ad4\uff0c\u7576\u5f9e GPU/CPU \u8a13\u7df4\u5b8c\u5f8c\uff0c\u5c07\u9019\u6279\u8cc7\u6599\u5f9e\u8a18\u61b6\u9ad4\u91cb\u51fa\uff0c\u5728\u8b80\u53d6\u4e0b\u4e00\u6279\u8cc7\u6599 \n\u5982\u4f55\u7528 Python \u64b0\u5beb\u6279\u6b21\u8b80\u53d6\u8cc7\u6599\u7684\u7a0b\u5f0f\u78bc \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9717106327039013
      ],
      "excerpt": "version = 1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "            activation (string): activation name \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8426108987628628
      ],
      "excerpt": "COCO dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8426108987628628
      ],
      "excerpt": "COCO dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8426108987628628
      ],
      "excerpt": "COCO dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8426108987628628
      ],
      "excerpt": "COCO dataset \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8985138738463141,
        0.8985138738463141
      ],
      "excerpt": "    df = pd.read_csv('example.csv') #: sep=',' \n    df = pd.read_table('example.csv') #: sep='\\t' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8734287870286652
      ],
      "excerpt": "    py \n    with open('example.txt','r') as f: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9464855012054318
      ],
      "excerpt": "    print(data) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9180062578030207,
        0.9021884057538777,
        0.8455022021407247,
        0.9464855012054318
      ],
      "excerpt": "    py \n    import json \n    with open('example.json','r') as f: \n        data = json.load(f) \n    print(data) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8516345462373837,
        0.8769413968174535,
        0.8744379363971947,
        0.9336801098518991,
        0.9133368656218674,
        0.8837354980060818
      ],
      "excerpt": "    py \n    import scipy.io as sio \n    data = sio.load('example.mat') \n\u5716\u50cf\u6a94 (PNG/JPG...) \n    py \n    import cv2 \n    image = cv2.imread('example.jpg') #: Cv2 \u6703\u4ee5 GBR \u8b80\u5165 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9457175861910134,
        0.9020641176012351
      ],
      "excerpt": "    py \n    import numpy as np \n    arr = np.load('example.npy')     \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8214055523315815,
        0.8431966986287792
      ],
      "excerpt": "    py \n    import pickle \n    with open('example.pkl','rb') as f: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8768801849289117
      ],
      "excerpt": "\u4e8c\u5143\u578b\u7279\u5fb5 : True/False\uff0c\u53ef\u7576\u985e\u5225\u6216\u6578\u503c\u8655\u7406 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9068127677393759,
        0.8804651131324065
      ],
      "excerpt": "    py \n    import matplotlib.pyplot as plt \n    %matplotlib inline #: \u5167\u5d4c\u65b9\u5f0f\uff0c\u4e0d\u9700\u8981 plt.show() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9012248701992861
      ],
      "excerpt": "    py \n    import seaborn as sns \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8963349340329686
      ],
      "excerpt": "    py \n    df.plot.hist()  #: \u76f4\u65b9\u5716 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8399182114982942
      ],
      "excerpt": "    plt.plot(list(df.index), df/df.max())   #: \u6b21\u6578\u7d2f\u7a4d\u5716 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8997243352845468,
        0.8997243352845468
      ],
      "excerpt": "\u4e2d\u4f4d\u6578 (median) : np.median(df[col]) \n\u5206\u4f4d\u6578 (quantiles) : np.quantile(df[col],q=...) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8478393887014588
      ],
      "excerpt": "    py \n    from scipy.stats import mode \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8346312675757274
      ],
      "excerpt": "\u5e73\u5747\u6578 (mean) : np.mean(df[col]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003751159116907,
        0.8462184100078407
      ],
      "excerpt": "        sub_df = df.sample(frac=0.5) \nsub_df = df.sample(n=10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "        ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731562459058029,
        0.9336801098518991
      ],
      "excerpt": "    * \u6b04\u4f4d\u4e2d\u5305\u542b value \n        ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "        ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "        ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8845797301725157
      ],
      "excerpt": "        df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "        ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "        ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "        ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "        ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "        ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8272102957395783
      ],
      "excerpt": "    $$r=\\frac{1}{n-1} \\sum_{i=1}^n\\frac{(x_i-\\bar{x})}{s_x}\\frac{(y_i-\\bar{y})}{s_y}$$ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9082341967090495
      ],
      "excerpt": "    py \n    df = pd.DataFrame(np.concatenate([np.random.randn(20).reshape(-1,1),np.random.randint(0,2,20).reshape(-1,1)],axis=1), columns=[\"X\",\"y\"]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8997243352845468
      ],
      "excerpt": "    np.corrcoef(df)     \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9068127677393759,
        0.9012248701992861,
        0.8302857394325267
      ],
      "excerpt": "    ```py \n    import matplotlib.pyplot as plt \n    import seaborn as sns \nplt.hist(df[col], edgecolor = 'k', bins = 25) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9129270638341896
      ],
      "excerpt": "    plt.xticks(rotation=45) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8354667997135233
      ],
      "excerpt": "\u7b49\u5bec\u5283\u5206 pd.cut()\uff0c\u53ef\u4f7f\u7528 np.linspace() \u9032\u884c\u7b49\u8ddd\u5207\u5206 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8355986768525016,
        0.8960751190095168,
        0.8497768636728816
      ],
      "excerpt": "    plt.figure(figsize = (8, 8)) \nplt.bar(range(len(age_groups.index)), age_groups['TARGET']) \nplt.xticks(range(len(age_groups.index)), age_groups.index, rotation = 75) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8310159060815993,
        0.8891089638153641,
        0.8310159060815993,
        0.8310159060815993,
        0.8891089638153641,
        0.8310159060815993
      ],
      "excerpt": "    plt.subplot(321) \n    plt.plot([0,1],[0,1], label = 'I am subplot1') \n    plt.legend() \n    plt.subplot(322) \n    plt.plot([0,1],[1,0], label = 'I am subplot2') \n    plt.legend() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8718059921288088
      ],
      "excerpt": "    plt.figure(figsize=(10,30)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8310159060815993
      ],
      "excerpt": "        plt.subplot(nrows, ncols, i+1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.949777128992407
      ],
      "excerpt": "Day_20 : Heatmap & Grid-plot \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8355986768525016,
        0.8427333871214094
      ],
      "excerpt": "plt.figure(figsize = (8, 6)) \nsns.heatmap(df.corr(), cmap = plt.cm.RdYlBu_r, vmin = -1.0, annot = True, vmax = 1.0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8838297384185549
      ],
      "excerpt": "    ```py \n    import seaborn as sns; sns.set(style=\"ticks\", color_codes=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8310159060815993,
        0.8261366541058346
      ],
      "excerpt": "    g = g.map_diag(plt.hist) \ng = g.map_offdiag(plt.scatter) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8801854956928516
      ],
      "excerpt": "    ```py \n    from sklearn.linear_model import LogisticRegression \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633989807152664
      ],
      "excerpt": "log_reg_pred = log_reg.predict_proba(test)[:, 1] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8997243352845468,
        0.814565850844877,
        0.8381469422456794
      ],
      "excerpt": "df_fixed['Fare'] = np.log1p(df_fixed['Fare']) \ndf['score'] = np.sqrt(df['score']) * 10 \n    from scipy import stats \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8194137536195615
      ],
      "excerpt": "    py \n    data = pd.concat([df[:train_num], train_Y], axis=1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8316389165953678,
        0.8089867336274301
      ],
      "excerpt": "        data = data.drop([c] , axis=1) \n    data = data.drop(['target'] , axis=1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8518962814096417
      ],
      "excerpt": "    py \n    count_df = df.groupby(['Ticket'])['Name'].agg({'Ticket_Count':'size'}).reset_index() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import datetime \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import math \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "    import math \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.802584310007831
      ],
      "excerpt": "\u5e38\u898b\u7684\u7d44\u5408\u65b9\u5f0f\u6709 mean,mdian,mode,max,min,count \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9012248701992861,
        0.9068127677393759
      ],
      "excerpt": "    ```py \nimport seaborn as sns \n    import matplotlib.pyplot as plt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8668258580770863
      ],
      "excerpt": "    plt.show() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8801854956928516
      ],
      "excerpt": "    ```py \n    from sklearn.linear_model import Lasso \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.83049730899982
      ],
      "excerpt": "from itertools import compress \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8801854956928516
      ],
      "excerpt": "    ```py \n    from sklearn.ensemble import RandomForestRegressor \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516,
        0.8801854956928516
      ],
      "excerpt": "from sklearn.linear_model import LogisticRegression \nfrom sklearn.ensemble import RandomForestClassifier \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "                        max_features=4, max_depth=3, bootstrap=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8801854956928516
      ],
      "excerpt": "    py \n    from sklearn.model_selection import train_test_split \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8801854956928516,
        0.9241022411340848,
        0.9241022411340848
      ],
      "excerpt": "    py \n    from sklearn.model_selection import KFold \n    X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]]) \n    y = np.array([1, 2, 3, 4]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9699283786193839
      ],
      "excerpt": "        print(\"TRAIN:\", train_index, \"TEST:\", test_index) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516,
        0.8801854956928516
      ],
      "excerpt": "from sklearn.linear_model import LinearRegression \nfrom sklearn.model_selection import train_test_split \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8127791514879013
      ],
      "excerpt": "prediction = model.predict(X) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8297084623472101
      ],
      "excerpt": "    y_pred = np.random.random((50,)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8801854956928516
      ],
      "excerpt": "    ```py \n    from sklearn.linear_model import LinearRegression, LogisticRegression \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8213380337316241,
        0.8937424779024458
      ],
      "excerpt": "    y_pred = reg.predict(x_test) \n    print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8213380337316241
      ],
      "excerpt": "    y_pred = logreg.predict(x_test) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8757982359298006,
        0.8801854956928516
      ],
      "excerpt": "    ```py \n    from sklearn import datasets \n    from sklearn.linear_model import Lasso, Ridge \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8213380337316241
      ],
      "excerpt": "y_pred = lasso.predict(x_test) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8213380337316241
      ],
      "excerpt": "y_pred = regr.predict(x_test) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8856290700471949
      ],
      "excerpt": "\u4f7f\u7528 numpy \u8b80\u53d6 txt \u6a94 : np.loadtxt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8384252206064038,
        0.9213716497003656
      ],
      "excerpt": "\u6aa2\u67e5\u8cc7\u6599\u6578\u91cf : data.shape \n\u5c07\u8cc7\u6599\u5207\u5206\u70ba\u8a13\u7df4 (train) \u8207\u6e2c\u8a66\u96c6 (test) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8213380337316241
      ],
      "excerpt": "    py \n    clf.predict(x_test) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8801854956928516,
        0.8801854956928516
      ],
      "excerpt": "    ```py \n    from sklearn.tree_model import DecisionTreeRegressor \n    from sklearn.tree_model import DecisionTreeClassifier \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8213380337316241
      ],
      "excerpt": "y_pred = clf.predict(x_test) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "        ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8801854956928516,
        0.8801854956928516
      ],
      "excerpt": "    ```py \n    from sklearn.ensemble import RandomForestClassifier \n    from sklearn.ensemble import RandomForestRegressor \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8213380337316241
      ],
      "excerpt": "y_pred = clf.predict(x_test) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8213380337316241,
        0.8937424779024458
      ],
      "excerpt": "y_pred = regr.predict(x_test) \nprint(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8801854956928516,
        0.8801854956928516
      ],
      "excerpt": "    ```py \n    from sklearn.ensemble import GradientBoostingClassifier \n    from sklearn.ensemble import GradientBoostingRegressor \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8213380337316241
      ],
      "excerpt": "y_pred = clf.predict(x_test) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8981524067900627
      ],
      "excerpt": "\u7aae\u8209\u6cd5 (Grid Search) : \u76f4\u63a5\u6307\u5b9a\u8d85\u53c3\u6578\u7684\u7bc4\u570d\u7d44\u5408\uff0c\u6bcf\u4e00\u7d44\u53c3\u6578\u90fd\u8a13\u7df4\u5b8c\u6210\uff0c\u518d\u6839\u64da\u9a57\u8b49\u96c6\u7684\u7d50\u679c\u9078\u64c7\u6700\u4f73\u53c3\u6578 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516,
        0.8801854956928516
      ],
      "excerpt": "from sklearn.model_selection import train_test_split, KFold, GridSearchCV \nfrom sklearn.ensemble import GradientBoostingRegressor \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8213380337316241
      ],
      "excerpt": "y_pred = clf_bestparam.predict(x_test) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9033133848190578,
        0.8801854956928516
      ],
      "excerpt": "* A7 :\u300c\u5206\u985e\u554f\u984c\u300d\u7684 Stacking \u8981\u6ce8\u610f\uf978\u4ef6\u4e8b\uff1a\u8a18\u5f97\u52a0\u4e0a use_probas=True (\u8f38\u51fa\u7279\u5fb5\u624d\u6703\u662f\u6a5f\u7387\u503c)\uff0c\u4ee5\u53ca\u8f38\u51fa\u7684\u7e3d\u7279\u5fb5\u6578\u6703\u662f\uff1a\u6a21\u578b\u6578\uf97e*\u5206\u985e\u6578\uf97e (\u56de\u6b78\u554f\u984c\u7279\u5fb5\u6578=\u6a21\u578b\u6578\u91cf\uf97e)py \nfrom mlxtend.classifier import StackingClassifier \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8158748477340755
      ],
      "excerpt": "stacking = StackingClassifier(classifiers =[lr, gdbt, rf], use_probas=True, meta_classifier=meta_estimator) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8498348001993667
      ],
      "excerpt": "\u4f7f\u7528 val / test data \uf92d\uf9ba\u89e3\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u7684\u8a13\u7df4\u60c5\u5f62 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8712525628618968,
        0.8800810681199904,
        0.810518471620563
      ],
      "excerpt": "\u5c0d\u6bcf\u4e00\u500b training example \u6839\u64da\u5b83\u8ddd\u96e2\u54ea\u4e00\u500b cluster centroid \u8f03\u8fd1\uff0c\u6a19\u8a18\u7232\u5176\u4e2d\u4e4b\u4e00 (cluster assignment) \n\u7136\u5f8c\u628a centroid \u79fb\u5230\u540c\u4e00\u7fa4 training examples \u7684\u4e2d\u5fc3\u9ede (update centroid) \n\u53cd\u8986\u9032\ufa08 cluster assignment \u53ca update centroid, \u76f4\u5230 cluster assignment \u4e0d\u518d\u5c0e\u81f4 training example \u88ab assign \u7232\u4e0d\u540c\u7684\u6a19\u8a18 (\u7b97\u6cd5\u6536\u6582) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from sklearn.cluster import KMeans   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from sklearn.cluster import KMeans \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8998860383552423
      ],
      "excerpt": "        print(\"For n_clusters =\", n_clusters, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516,
        0.8757982359298006
      ],
      "excerpt": "from sklearn.cluster import AgglomerativeClustering \nfrom sklearn import datasets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8757982359298006
      ],
      "excerpt": "from sklearn import cluster, datasets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8711197750819002
      ],
      "excerpt": "no_structure = np.random.rand(n_samples, 2), None \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from sklearn import decomposition \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9457175861910134,
        0.9068127677393759
      ],
      "excerpt": "import numpy as np \n    import matplotlib.pyplot as plt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8757982359298006,
        0.8801854956928516,
        0.8801854956928516
      ],
      "excerpt": "    from sklearn import datasets \n    from sklearn.decomposition import PCA \n    from sklearn.linear_model import SGDClassifier \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516,
        0.9133368656218674
      ],
      "excerpt": "    from sklearn.model_selection import GridSearchCV \n    import warnings \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8144661985917674,
        0.8997243352845468
      ],
      "excerpt": "        'pca__n_components': [4, 10, 20, 30, 40, 50, 64], \n        'logistic__alpha': np.logspace(-4, 4, 5), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936606094659785
      ],
      "excerpt": "    print(search.best_params_) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9269056235222607,
        0.8392642043407771
      ],
      "excerpt": "    fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6)) \n    ax0.plot(pca.explained_variance_ratio_, linewidth=2) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9475033249778422
      ],
      "excerpt": "    best_clfs.plot(x=components_col, y='mean_test_score', yerr='std_test_score', legend=False, ax=ax1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8310159060815993,
        0.8668258580770863
      ],
      "excerpt": "    plt.tight_layout() \n    plt.show() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8024320410801663
      ],
      "excerpt": "perplexities = [4, 6, 9, 14, 21, 30, 45, 66, 100] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9080831333823435
      ],
      "excerpt": "print(\"S-curve, perplexity=%d in %.2g sec\" % (perplexity, t1 - t0)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.850302460584936
      ],
      "excerpt": "* \u96b1\u85cf\u5c64 (output layer)\uff1a\u9664\uf9ba\u4e0a\u8ff0\uf978\u5c64\u5916\uff0c\u5176\u4ed6\u5c64\u90fd\u7a31\u70ba\u96b1\u85cf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9000504886472166,
        0.9133368656218674
      ],
      "excerpt": "    py \n    import tensorflow \n    import keras \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import keras \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "\u57f7\ufa08\u4e0b\u8f09\u6642\uff0c\u8981 import \u76f8\u61c9\u7684\u6a21\u7d44\uff0c\uf9dd\u7528\u8cc7\u6599\u96c6\u6a21\u7d44\u63d0\u4f9b\u7684\u51fd\u6578\u4e0b\u8f09\u8cc7\u6599 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8811103033681846
      ],
      "excerpt": "    from keras.datasets import cifar10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8757982359298006
      ],
      "excerpt": "    py \n    from keras.datasets import cifar100 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8757982359298006
      ],
      "excerpt": "    py \n    from keras.datasets import mnist \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8757982359298006
      ],
      "excerpt": "    from keras.datasets import fashion_mnsit \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8757982359298006
      ],
      "excerpt": "    py \n    from keras.datasets import boston_housing    \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8642004267835298
      ],
      "excerpt": "from keras.datasets import imdb \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8757982359298006
      ],
      "excerpt": "    py \n    from keras.datasets import reuters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8900486270063179
      ],
      "excerpt": "    py \n    from keras.models import Sequential \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.8811103033681846,
        0.8900486270063179
      ],
      "excerpt": "import keras \n    from keras.datasets import cifar10 \n    from keras.models import Sequential, load_model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8385128887712422
      ],
      "excerpt": "    from keras.layers import Conv2D, MaxPooling2D \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8924976426181745,
        0.8924976426181745
      ],
      "excerpt": "y_train = keras.utils.to_categorical(y_train, num_classes) \n    y_test = keras.utils.to_categorical(y_test, num_classes) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8330008239856044
      ],
      "excerpt": "    model.add(Conv2D(128, (5, 5))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8168925031511495
      ],
      "excerpt": "    model.add(Dropout(0.25)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8168925031511495
      ],
      "excerpt": "    model.add(Dropout(0.25)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9316937895561977
      ],
      "excerpt": "    print(model.summary()) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9040368155137037
      ],
      "excerpt": "from keras.models import Model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179,
        0.9054100096109314
      ],
      "excerpt": "\u5ba3\u544a\u4e00\u500b NAME \u53bb\u5b9a\u7fa9Input \nmain_input = Input(shape=(100,), dtype='int32', name='main_input') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.8848188974363315
      ],
      "excerpt": "    import keras \n    news_input = Input(shape=(5,), name='news_in') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.8848188974363315
      ],
      "excerpt": "    import keras \n    news_input = Input(shape=(5,), name='news_in') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9416522774131079,
        0.9457175861910134
      ],
      "excerpt": "from keras.utils import np_utils \nimport numpy as np \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8757982359298006
      ],
      "excerpt": "from keras.datasets import mnist \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8900486270063179
      ],
      "excerpt": "    from keras.models import Sequential \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9316937895561977
      ],
      "excerpt": "    print(model.summary()) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9068127677393759,
        0.8101682020937845,
        0.8896621500122356,
        0.8499808485919489
      ],
      "excerpt": "    import matplotlib.pyplot as plt \n    def show_train_history(train_history,train,validation): \n        plt.plot(train_history.history[train]) \n        plt.plot(train_history.history[validation]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9040909135961734,
        0.8539464288592398,
        0.8819126912114895,
        0.8668258580770863
      ],
      "excerpt": "        plt.ylabel(train) \n        plt.xlabel('Epoch') \n        plt.legend(['train', 'validation'], loc='upper left') \n        plt.show() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8361406602442122
      ],
      "excerpt": "from keras import losses \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8405210537621255
      ],
      "excerpt": "\u6574\u6578\u76ee\u6a19\uff1aSparse categorical_crossentropy \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8361406602442122
      ],
      "excerpt": "from keras import losses \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8361406602442122
      ],
      "excerpt": "from keras import losses \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9000107903124189
      ],
      "excerpt": "$$ f(x) = max(ax, x)$$ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9457175861910134
      ],
      "excerpt": "import numpy as np \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.866156314546033
      ],
      "excerpt": "    return (1 / (1 + np.exp(-x))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8803270049269614
      ],
      "excerpt": "    return np.exp(x) / float(sum(np.exp(x))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8797253875503244
      ],
      "excerpt": "    return(np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8508304875538868
      ],
      "excerpt": "    return 1 - np.square(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9457175861910134,
        0.9068127677393759
      ],
      "excerpt": "import numpy as np \nimport matplotlib.pyplot as plt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8508304875538868
      ],
      "excerpt": "        return np.square(x+3) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731562459058029
      ],
      "excerpt": "            :param w_init: w\u7684init value     \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8552678291877044
      ],
      "excerpt": "        xs = np.zeros(epochs+1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8612630503664754
      ],
      "excerpt": "    lr = 0.01 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936606094659785
      ],
      "excerpt": "    print (x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8719861090822298,
        0.8828665034782968,
        0.9223462766780322,
        0.9012283875514494,
        0.8639937436246811,
        0.8310159060815993,
        0.8668258580770863
      ],
      "excerpt": "    from numpy import arange \n    t = arange(-6.0, 6.0, 0.01) \n    plt.plot(t, func(t), c='b') \n    plt.plot(x, func(x), c=color, label='lr={}'.format(lr))     \n    plt.scatter(x, func(x), c=color, )     \n    plt.legend() \n    plt.show() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8347306400897082,
        0.9068127677393759
      ],
      "excerpt": "import matplotlib \nimport matplotlib.pyplot as plt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8286650517545485,
        0.9457175861910134,
        0.9188150264059814
      ],
      "excerpt": "import random as random \nimport numpy as np \nimport csv \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8958424973533752,
        0.8997243352845468,
        0.9073737899904375
      ],
      "excerpt": "    x = np.arange(-200,-100,1) #\u7d66\u5b9abias \n    y = np.arange(-5,5,0.1) #\u7d66\u5b9aweight \n    Z =  np.zeros((len(x), len(y))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8997243352845468
      ],
      "excerpt": "    X, Y = np.meshgrid(x, y) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8172342705654815
      ],
      "excerpt": "            Z[j][i] = Z[j][i]/len(x_data) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9295405530505548,
        0.889775107429349,
        0.8673079625263127,
        0.8310159060815993,
        0.8296970695067121,
        0.8296970695067121,
        0.8668258580770863
      ],
      "excerpt": "    plt.plot([-188.4], [2.67], 'x', ms=12, markeredgewidth=3, color='orange') \n    plt.plot(b_history, w_history, 'o-', ms=3, lw=1.5, color='black') \n    plt.xlim(-200,-100) \n    plt.ylim(-5,5) \n    plt.xlabel(r'$b$', fontsize=16) \n    plt.ylabel(r'$w$', fontsize=16) \n    plt.show() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8357900979989564
      ],
      "excerpt": "$\\to$ \u5efa\u7acb\u795e\u7d93\u7db2\u8def (Input\u3001Hidden\u3001Output) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8081367031088285
      ],
      "excerpt": "$\\to$ \u53d6\u5f97 OUTPUT  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8867492726730952
      ],
      "excerpt": "keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from keras import optimizers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.841476194311783
      ],
      "excerpt": "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) model.compile(loss='mean_squared_error', optimizer=sgd) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8106215220826399
      ],
      "excerpt": "            * batchsize = whole training set  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8778487586960795
      ],
      "excerpt": "        * Example: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8612828683797754
      ],
      "excerpt": "        `keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)` \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8801854956928516
      ],
      "excerpt": "            ```py \n            from keras import optimizers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8576296972212415
      ],
      "excerpt": "            opt = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8801854956928516
      ],
      "excerpt": "            ```py \n            from keras import optimizers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8112841462183467
      ],
      "excerpt": "            * the first moment (the mean) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8801854956928516
      ],
      "excerpt": "        ```py \n        from keras import optimizers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "                shuffle=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "                shuffle=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9068127677393759
      ],
      "excerpt": "        ```py \nimport matplotlib.pyplot as plt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9303023526082512,
        0.8918207203450169,
        0.8310159060815993
      ],
      "excerpt": "        plt.plot(range(len(train_loss)), train_loss, label=\"train loss\") \n        plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\") \n        plt.legend() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8668258580770863,
        0.9171167074139458,
        0.8735627015703136,
        0.8310159060815993
      ],
      "excerpt": "        plt.show() \n        plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\") \n        plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\") \n        plt.legend() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8668258580770863
      ],
      "excerpt": "        plt.show() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401558704798054,
        0.9133368656218674,
        0.9133368656218674,
        0.9117485216975647
      ],
      "excerpt": "import os \nimport keras \nimport itertools \ntrain, test = keras.datasets.cifar10.load_data() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8924976426181745
      ],
      "excerpt": "            y = keras.utils.to_categorical(y, num_classes) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137,
        0.8633989807152664
      ],
      "excerpt": "    x_train, y_train = train \n    x_test, y_test = test \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8587836997795965,
        0.8224580716165858
      ],
      "excerpt": "print(\"Experiment with LR = %.6f, Optimizer = %s\" % (lr, str(opti))) \n        model = build_mlp(input_shape=x_train.shape[1:]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "                shuffle=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "                                'train-acc': train_acc, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8756831816265702
      ],
      "excerpt": "    Plot results \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9068127677393759
      ],
      "excerpt": "    import matplotlib.pyplot as plt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8317108674180005
      ],
      "excerpt": "    NUM_COLORS = len(results.keys()) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8355986768525016
      ],
      "excerpt": "    plt.figure(figsize=(8,6)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9258144727335917,
        0.8671025211618442
      ],
      "excerpt": "        plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i]) \n        plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8668258580770863,
        0.8355986768525016
      ],
      "excerpt": "    plt.show() \n    plt.figure(figsize=(8,6)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9509917453271853,
        0.8929175082947385
      ],
      "excerpt": "        plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i]) \n        plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8668258580770863
      ],
      "excerpt": "    plt.show() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from keras.regularizers import l1_l2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8569477895337253
      ],
      "excerpt": "                            name=\"hidden_layer\"+str(i+1),  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8569477895337253
      ],
      "excerpt": "                            name=\"hidden_layer\"+str(i+1), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8499706526085989,
        0.8224580716165858
      ],
      "excerpt": "print(\"Experiment with L1 = %.6f, L2 = %.6f\" % (l1r, l2r)) \n        model = build_mlp(input_shape=x_train.shape[1:], l1_ratio=l1r, l2_ratio=l2r) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.83763653038625
      ],
      "excerpt": "        optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "                shuffle=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "                                'train-acc': train_acc, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8385128887712422
      ],
      "excerpt": "from keras.layers import Dropout \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8569477895337253
      ],
      "excerpt": "                            name=\"hidden_layer\"+str(i+1))(input_layer) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8569477895337253
      ],
      "excerpt": "                            name=\"hidden_layer\"+str(i+1))(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8243112196109952
      ],
      "excerpt": "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128], pre_activate=False): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8569477895337253
      ],
      "excerpt": "                            name=\"hidden_layer\"+str(i+1))(input_layer) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8569477895337253
      ],
      "excerpt": "                            name=\"hidden_layer\"+str(i+1))(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8401558704798054,
        0.9133368656218674,
        0.9133368656218674,
        0.9117485216975647
      ],
      "excerpt": "    *py \nimport os \nimport keras \nimport itertools \ntrain, test = keras.datasets.cifar10.load_data() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8924976426181745
      ],
      "excerpt": "            y = keras.utils.to_categorical(y, num_classes) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137,
        0.8633989807152664
      ],
      "excerpt": "    x_train, y_train = train \n    x_test, y_test = test \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "                use_bn=True, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8569477895337253
      ],
      "excerpt": "                                    name=\"hidden_layer\"+str(i+1))(input_layer) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8569477895337253
      ],
      "excerpt": "                                    name=\"hidden_layer\"+str(i+1))(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8044290599680651
      ],
      "excerpt": "    BATCH_SIZE = 128 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8768801849289117
      ],
      "excerpt": "    USE_BN = [True, False] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8964255208449897,
        0.8224580716165858
      ],
      "excerpt": "        print(\"Numbers of exp: %i, with bn: %s, drp_ratio: %.2f, l2_ratio: %.2f\" % (i, use_bn, drp_ratio, l2_ratio)) \n        model = build_mlp(input_shape=x_train.shape[1:], use_bn=use_bn, drp_ratio=drp_ratio, l2_ratio=l2_ratio) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "                shuffle=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "    from keras.callbacks import EarlyStopping \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "            shuffle=True, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8048195900317339,
        0.8440605933876145
      ],
      "excerpt": "Model CheckPoint \n\u70ba\u4f55\u8981\u4f7f\u7528 Model Check Point? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "    from keras.callbacks import ModelCheckpoint \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "                                save_best_only=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "            shuffle=True, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8525645461651434,
        0.82984372402833,
        0.8525645461651434
      ],
      "excerpt": "    pred_final = model.predict(x_test) \nmodel = keras.models.load_model(\"./tmp.h5\") \n    pred_loadback = model.predict(x_test) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8213380337316241
      ],
      "excerpt": "    new_model_pred = new_model.predict(x_test) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8213380337316241
      ],
      "excerpt": "    new_model_pred = new_model.predict(x_test) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "    from keras.callbacks import ReduceLROnPlateau \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "            shuffle=True, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from keras.callbacks import Callback \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "    from keras.callbacks import Callback \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "            shuffle=True, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9068127677393759
      ],
      "excerpt": "    import matplotlib.pyplot as plt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9022653735865811,
        0.8310159060815993
      ],
      "excerpt": "    plt.plot(range(len(valid_f1sc)), valid_f1sc, label=\"valid f1-score\") \n    plt.legend() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8668258580770863
      ],
      "excerpt": "    plt.show() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8801854956928516
      ],
      "excerpt": "    ```py \nfrom keras.callbacks import Callback \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "            shuffle=True, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8289669050403863
      ],
      "excerpt": "\u6700\u5167\u5c64\u51fd\u5f0f\u7684\uf96b\u6578\u8f38\u5165\u9808\u6839\u64da output tensor \u800c\u5b9a\uff0c\u8209\uf9b5\uf92d\u8aaa\uff0c\u5728\u5206\u985e\u6a21\u578b\u4e2d\u9700\u8981\u6709 y_true, y_pred \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.925671696398174
      ],
      "excerpt": "    ```py \n    import tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432,
        0.8292651357740108,
        0.8628078589057694,
        0.8458458056901498,
        0.8252454392355707,
        0.84760898352076,
        0.8069275751695314
      ],
      "excerpt": "            y_true = tf.convert_to_tensor(y_true, tf.float32) \n            y_pred = tf.convert_to_tensor(y_pred, tf.float32) \n            model_out = tf.add(y_pred, epsilon) \n            ce = tf.multiply(y_true, -tf.log(model_out)) \n            weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma)) \n            fl = tf.multiply(alpha, tf.multiply(weight, ce)) \n            reduced_fl = tf.reduce_max(fl, axis=1) \n            return tf.reduce_mean(reduced_fl) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8224580716165858
      ],
      "excerpt": "    model = build_mlp(input_shape=x_train.shape[1:]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.83763653038625
      ],
      "excerpt": "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "            shuffle=True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.925671696398174
      ],
      "excerpt": "    ```py \nimport tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432,
        0.8292651357740108,
        0.8628078589057694,
        0.8458458056901498,
        0.8252454392355707,
        0.84760898352076
      ],
      "excerpt": "            y_true = tf.convert_to_tensor(y_true, tf.float32) \n            y_pred = tf.convert_to_tensor(y_pred, tf.float32) \n            model_out = tf.add(y_pred, epsilon) \n            ce = tf.multiply(y_true, -tf.log(model_out)) \n            weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma)) \n            fl = tf.multiply(alpha, tf.multiply(weight, ce)) \n            reduced_fl = tf.reduce_max(fl, axis=1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8069275751695314
      ],
      "excerpt": "            return (ce_weights*ce_loss) + (fcl_weights*tf.reduce_mean(reduced_fl) ) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "    import itertools \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9018976366441824,
        0.8224580716165858
      ],
      "excerpt": "        print(\"Numbers of exp: %i, ce_weight: %.2f\" % (i, ce_w)) \n        model = build_mlp(input_shape=x_train.shape[1:]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.83763653038625
      ],
      "excerpt": "        optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "                shuffle=True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401558704798054,
        0.9133368656218674,
        0.9133368656218674,
        0.9068127677393759,
        0.9117485216975647
      ],
      "excerpt": "import os \nimport keras \nimport cv2 \nimport matplotlib.pyplot as plt \n        train, test = keras.datasets.cifar10.load_data() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8355986768525016
      ],
      "excerpt": "        plt.figure() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8310159060815993,
        0.8310159060815993
      ],
      "excerpt": "        plt.xlabel(\"Bins\") \n        plt.ylabel(\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8668258580770863
      ],
      "excerpt": "        plt.show() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8355986768525016
      ],
      "excerpt": "        plt.figure() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8310159060815993,
        0.8310159060815993,
        0.8062240177700305
      ],
      "excerpt": "        plt.xlabel(\"Bins\") \n        plt.ylabel(\" \nfor (chan, color) in zip(chans, colors): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9018264854250958
      ],
      "excerpt": "plt.plot(hist, color = color) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8668258580770863
      ],
      "excerpt": "        plt.show() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401558704798054,
        0.9133368656218674,
        0.925671696398174,
        0.9457175861910134,
        0.9133368656218674,
        0.9068127677393759,
        0.9117485216975647,
        0.8589534893990137,
        0.8633989807152664
      ],
      "excerpt": "import os \nimport keras \nimport tensorflow as tf \nimport numpy as np \nimport cv2 \nimport matplotlib.pyplot as plt \n    train, test = keras.datasets.cifar10.load_data() \n    x_train, y_train = train \n    x_test, y_test = test \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9241022411340848,
        0.9241022411340848
      ],
      "excerpt": "    x_train_histogram = np.array(x_train_histogram) \n    x_test_histogram = np.array(x_test_histogram) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8898368543585656
      ],
      "excerpt": "        bins = np.int32(bin_n*ang/(2*np.pi)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837745054983516,
        0.8997243352845468,
        0.8484017803320507,
        0.8904513523851831,
        0.8904513523851831
      ],
      "excerpt": "        hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)] \n        hist = np.hstack(hists) \nreturn hist.astype(np.float32) \n    x_train_hog = np.array([hog(x) for x in x_train]) \n    x_test_hog = np.array([hog(x) for x in x_test]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174540907975313,
        0.8589534893990137,
        0.8213380337316241,
        0.8213380337316241
      ],
      "excerpt": "    #training \n    SVM_hist.train(x_train_histogram, cv2.ml.ROW_SAMPLE, y_train) \n_, y_hist_train = SVM_hist.predict(x_train_histogram) \n    _, y_hist_test = SVM_hist.predict(x_test_histogram) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174540907975313,
        0.8589534893990137,
        0.8213380337316241,
        0.8213380337316241,
        0.8407521237878647,
        0.8407521237878647,
        0.8407521237878647,
        0.8407521237878647,
        0.9457175861910134
      ],
      "excerpt": "    #training \n    SVM_hog.train(x_train_hog, cv2.ml.ROW_SAMPLE, y_train) \n_, y_hog_train = SVM_hog.predict(x_train_hog) \n    _, y_hog_test = SVM_hog.predict(x_test_hog) \nacc_hist_train = (sum(y_hist_train == y_train) / len(y_hist_train))[0] * 100 \n    acc_hog_train = (sum(y_hog_train == y_train) / len(y_hog_train))[0] * 100 \n    acc_hist_test = (sum(y_hist_test == y_test) / len(y_hist_test))[0] * 100 \n    acc_hog_test = (sum(y_hog_test == y_test) / len(y_hog_test))[0] * 100 \n    import numpy as np \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8636889924149893
      ],
      "excerpt": "    x = np.arange(len(labels)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9371031865737048,
        0.8755097657704062,
        0.8725396068749254
      ],
      "excerpt": "fig, ax = plt.subplots() \n    rects1 = ax.bar(x - width/2, hist_acc, width, label='histogram') \n    rects2 = ax.bar(x + width/2, hog_acc, width, label='HOG') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8718231725240865,
        0.9000107903124189
      ],
      "excerpt": "    ax.set_ylim(0,30) \n    ax.set_xticks(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9000107903124189
      ],
      "excerpt": "    ax.legend() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8493612739643502
      ],
      "excerpt": "        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9001507179983895
      ],
      "excerpt": "            ax.annotate('{0:.3f}'.format(height), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8668258580770863
      ],
      "excerpt": "    plt.show() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.8385128887712422,
        0.8900486270063179,
        0.8900486270063179
      ],
      "excerpt": "import keras \nfrom keras import layers \nfrom keras import models \nfrom keras.models import Sequential \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8100760890838519
      ],
      "excerpt": "model.add(layers.Conv2D(25, (3, 3))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8639258741734444
      ],
      "excerpt": "* Depth (kernels\u7684\u7e3d\u6578) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8025796386816414,
        0.8025796386816414
      ],
      "excerpt": "        * channels_last \u4ee3\u8868\u5c3a\u5bf8\u662f (batch, height, width, channels) \u7684\u8f38\u5165\u5f35\uf97e\u3002 \n        * channels_first \u4ee3\u8868\u5c3a\u5bf8\u662f (batch, channels, height, width) \u7684\u8f38\u5165\u5f35\uf97e\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8476351441325767
      ],
      "excerpt": "        X -- python numpy array, \u5448\u73fe\u7dad\u5ea6 (m, n_H, n_W, n_C), \u4ee3\u8868\u4e00\u6279 m \u500b\u5716\u50cf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8464194530756914
      ],
      "excerpt": "X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant', constant_values=(0, 0)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8826917448272372
      ],
      "excerpt": "A = np.zeros((m, n_H, n_W, n_C)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8997243352845468
      ],
      "excerpt": "                            A[i, h, w, c] = np.max(a_prev_slice) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8813516794690208
      ],
      "excerpt": "                            A[i, h, w, c] = np.mean(a_prev_slice) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8385128887712422
      ],
      "excerpt": "    py \n    from keras.layers import Conv2D \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8608503699745261,
        0.9040368155137037
      ],
      "excerpt": "from keras.layers import Conv2D, SeparableConv2D, Input \nfrom keras.models import Model, Sequential \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.906614234580968
      ],
      "excerpt": "Layer (type)                 Output Shape              Param \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.861037605172377
      ],
      "excerpt": "    Total params: 19,392 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.906614234580968
      ],
      "excerpt": "    Layer (type)                 Output Shape              Param \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8934745846565956
      ],
      "excerpt": "    Total params: 2,555 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9133368656218674,
        0.8811103033681846,
        0.8900486270063179
      ],
      "excerpt": "    ```py \n    import keras \n    from keras.datasets import cifar10 \n    from keras.models import Sequential \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8385128887712422,
        0.8801854956928516,
        0.8044290599680651
      ],
      "excerpt": "    from keras.layers import Conv2D, MaxPooling2D \n    from keras.optimizers import RMSprop, Adam \nbatch_size = 128 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8952752021235695,
        0.9505213542467355,
        0.9511511668343321,
        0.8924976426181745,
        0.8924976426181745
      ],
      "excerpt": "    print('x_train shape:', x_train.shape) \n    print(x_train.shape[0], 'train samples') \n    print(x_test.shape[0], 'test samples') \ny_train = keras.utils.to_categorical(y_train, num_classes) \n    y_test = keras.utils.to_categorical(y_test, num_classes) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9505213542467355,
        0.9511511668343321
      ],
      "excerpt": "    print(x_train.shape[0], 'train samples') \n    print(x_test.shape[0], 'test samples') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.888062915772347,
        0.8607606436540951
      ],
      "excerpt": "    print('Test loss:', score[0]) \n    print('Test accuracy:', score[1]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8952752021235695,
        0.9505213542467355,
        0.9511511668343321
      ],
      "excerpt": "    print('x_train shape:', x_train.shape) \n    print(x_train.shape[0], 'train samples') \n    print(x_test.shape[0], 'test samples') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8924976426181745,
        0.8924976426181745
      ],
      "excerpt": "y_train = keras.utils.to_categorical(y_train, num_classes) \n    y_test = keras.utils.to_categorical(y_test, num_classes) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8168925031511495,
        0.8004262088789489
      ],
      "excerpt": "    model.add(Dropout(0.25)) \n    model.add(Conv2D(64, (3, 3), padding='same')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8168925031511495
      ],
      "excerpt": "    model.add(Dropout(0.25)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.888062915772347,
        0.8607606436540951
      ],
      "excerpt": "    print('Test loss:', score[0]) \n    print('Test accuracy:', score[1]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8811103033681846
      ],
      "excerpt": "from keras.datasets import cifar10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.809726610547402,
        0.8200053651991791
      ],
      "excerpt": "    while True: \n        for indexs in range(0, len(image_array), batch_size): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.8811103033681846,
        0.8900486270063179
      ],
      "excerpt": "import keras \nfrom keras.datasets import cifar10 \nfrom keras.models import Sequential \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8385128887712422,
        0.8801854956928516,
        0.8044290599680651
      ],
      "excerpt": "from keras.layers import Conv2D, MaxPooling2D \nfrom keras.optimizers import RMSprop, Adam \nbatch_size = 128 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8952752021235695,
        0.9505213542467355,
        0.9511511668343321
      ],
      "excerpt": "    print('x_train shape:', x_train.shape) \n    print(x_train.shape[0], 'train samples') \n    print(x_test.shape[0], 'test samples') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8924976426181745,
        0.8924976426181745
      ],
      "excerpt": "y_train = keras.utils.to_categorical(y_train, num_classes) \n    y_test = keras.utils.to_categorical(y_test, num_classes) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8168925031511495,
        0.8004262088789489
      ],
      "excerpt": "    model.add(Dropout(0.25)) \n    model.add(Conv2D(64, (3, 3), padding='same')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8168925031511495
      ],
      "excerpt": "    model.add(Dropout(0.25)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9416522774131079
      ],
      "excerpt": "    from sklearn.utils import shuffle \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.809726610547402,
        0.8200053651991791
      ],
      "excerpt": "        while True: \n            for idx in range(0, len(x), batch_size): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8369238415880416
      ],
      "excerpt": "                        steps_per_epoch=int(len(x_train)/batch_size), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.888062915772347,
        0.8607606436540951
      ],
      "excerpt": "    print('Test loss:', score[0]) \n    print('Test accuracy:', score[1]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9213716497003656
      ],
      "excerpt": "\u53e6\u5916\u9700\u7279\u5225\u6ce8\u610f\u8981\u5148\u5c0d\u8cc7\u6599\u505a train/test split \u5f8c\u518d\u505a\u8cc7\u6599\u589e\u5f37\uff01\u5426\u5247\u5176\u5be6\u90fd\u662f\u540c\u6a23\u7684\u5f71\u50cf\uff0c\u8aa4\u4ee5\u70ba\u6a21\u578b\u8a13\u7df4\u5f97\u975e\u5e38\u597d \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.8811103033681846
      ],
      "excerpt": "import keras \nfrom keras.datasets import cifar10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8900486270063179
      ],
      "excerpt": "from keras.models import Sequential \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8385128887712422,
        0.8801854956928516,
        0.8044290599680651
      ],
      "excerpt": "from keras.layers import Conv2D, MaxPooling2D \nfrom keras.optimizers import RMSprop, Adam \nbatch_size = 128 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8952752021235695,
        0.9505213542467355,
        0.9511511668343321
      ],
      "excerpt": "    print('x_train shape:', x_train.shape) \n    print(x_train.shape[0], 'train samples') \n    print(x_test.shape[0], 'test samples') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8924976426181745,
        0.8924976426181745
      ],
      "excerpt": "y_train = keras.utils.to_categorical(y_train, num_classes) \n    y_test = keras.utils.to_categorical(y_test, num_classes) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8168925031511495,
        0.8004262088789489
      ],
      "excerpt": "    model.add(Dropout(0.25)) \n    model.add(Conv2D(64, (3, 3), padding='same')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8168925031511495
      ],
      "excerpt": "    model.add(Dropout(0.25)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8840094786355988
      ],
      "excerpt": "    augment_generator = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8369238415880416
      ],
      "excerpt": "                        steps_per_epoch=int(len(x_train)/batch_size), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.888062915772347,
        0.8607606436540951
      ],
      "excerpt": "    print('Test loss:', score[0]) \n    print('Test accuracy:', score[1]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    ```py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8289669050403863
      ],
      "excerpt": "last_featuremaps = resnet_model.output \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import keras \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8608503699745261,
        0.8801854956928516,
        0.8801854956928516,
        0.8801854956928516
      ],
      "excerpt": "from keras.layers import AveragePooling2D, Input, Flatten \nfrom keras.optimizers import Adam \nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler \nfrom keras.callbacks import ReduceLROnPlateau \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from keras.regularizers import l2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9040368155137037,
        0.8811103033681846,
        0.9457175861910134,
        0.8401558704798054,
        0.8044290599680651
      ],
      "excerpt": "from keras.models import Model \nfrom keras.datasets import cifar10 \nimport numpy as np \nimport os \nbatch_size = 128   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "    data_augmentation = True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "subtract_pixel_mean = True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8639258741734444
      ],
      "excerpt": "depth = n * 6 + 2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8973550643270167
      ],
      "excerpt": "        x_train_mean = np.mean(x_train, axis=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8952752021235695,
        0.9505213542467355,
        0.9511511668343321,
        0.8952752021235695,
        0.8924976426181745,
        0.8924976426181745
      ],
      "excerpt": "print('x_train shape:', x_train.shape) \n    print(x_train.shape[0], 'train samples') \n    print(x_test.shape[0], 'test samples') \n    print('y_train shape:', y_train.shape) \ny_train = keras.utils.to_categorical(y_train, num_classes) \n    y_test = keras.utils.to_categorical(y_test, num_classes) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984,
        0.8594142235991984
      ],
      "excerpt": "                    batch_normalization=True, \n                    conv_first=True): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8163523035541307
      ],
      "excerpt": "x (tensor): tensor as input to the next layer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.836576240852918
      ],
      "excerpt": "def resnet_v1(input_shape, depth, num_classes=10): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341177043401105
      ],
      "excerpt": "        num_res_blocks = int((depth - 2) / 6) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8842318195854884
      ],
      "excerpt": "model = resnet_v1(input_shape=input_shape, depth=depth) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936606094659785
      ],
      "excerpt": "    print(model_type) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9028689906312073
      ],
      "excerpt": "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8326988075830488
      ],
      "excerpt": "    print('Using real-time data augmentation.') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8369238415880416
      ],
      "excerpt": "                        steps_per_epoch=int(len(x_train)//batch_size), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8541491651345257,
        0.820249358723407
      ],
      "excerpt": "    print('Test loss:', scores[0]) \n    print('Test accuracy:', scores[1]) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Halesu/4th-ML100Days/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "4th-ML100Days",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "4th-ML100Days",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Halesu",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Halesu/4th-ML100Days/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Thu, 09 Dec 2021 09:36:47 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2002.02126"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9999987951241576,
        0.9994678658584983
      ],
      "excerpt": "SIGIR 2020. Xiangnan He, Kuan Deng ,Xiang Wang, Yan Li, Yongdong Zhang, Meng Wang(2020). LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation, Paper in arXiv. \nAuthor: Prof. Xiangnan He (staff.ustc.edu.cn/~hexn/) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/tanya525625/LightGCN-PyTorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-07T15:55:22Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-07T16:06:16Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "In this work, we aim to simplify the design of GCN to make it more concise and appropriate for recommendation. We propose a new model named LightGCN,including only the most essential component in GCN\u2014neighborhood aggregation\u2014for collaborative filtering\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.993831558822675
      ],
      "excerpt": "This is the Pytorch implementation for our SIGIR 2020 paper: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9090797016795135
      ],
      "excerpt": "(Also see Tensorflow implementation) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860902582081311
      ],
      "excerpt": "see more in dataloader.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.927406756410915
      ],
      "excerpt": "all metrics is under top-20 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "(for seed=2020) \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/tanya525625/LightGCN-PyTorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 06 Dec 2021 21:22:48 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/tanya525625/LightGCN-PyTorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "tanya525625/LightGCN-PyTorch",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8710104398874935
      ],
      "excerpt": "pytorch version results (stop at 1000 epochs): \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8263326502526759,
        0.8423831999833603,
        0.8224103631413249
      ],
      "excerpt": "If you want to run lightGCN on your own dataset, you should go to dataloader.py, and implement a dataloader inherited from BasicDataset.  Then register it in register.py. \nIf you want to run your own models on the datasets we offer, you should go to model.py, and implement a model inherited from BasicModel.  Then register it in register.py. \nIf you want to run your own sampling methods on the datasets and models we offer, you should go to Procedure.py, and implement a function. Then modify the corresponding code in main.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/tanya525625/LightGCN-PyTorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "## LightGCN-pytorch\n\nThis is the Pytorch implementation for our SIGIR 2020 paper:\n\n>SIGIR 2020. Xiangnan He, Kuan Deng ,Xiang Wang, Yan Li, Yongdong Zhang, Meng Wang(2020). LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation, [Paper in arXiv](https://arxiv.org/abs/2002.02126).\n\nAuthor: Prof. Xiangnan He (staff.ustc.edu.cn/~hexn/)\n\n(Also see Tensorflow [implementation](https://github.com/kuandeng/LightGCN))\n\n## Introduction\n\nIn this work, we aim to simplify the design of GCN to make it more concise and appropriate for recommendation. We propose a new model named LightGCN,including only the most essential component in GCN\u2014neighborhood aggregation\u2014for collaborative filtering\n\n\n\n## Enviroment Requirement\n\n`pip install -r requirements.txt`\n\n\n\n## Dataset\n\nWe provide three processed datasets: Gowalla, Yelp2018 and Amazon-book and one small dataset LastFM.\n\nsee more in `dataloader.py`\n\n## An example to run a 3-layer LightGCN\n\nrun LightGCN on **Gowalla** dataset:\n\n* command\n\n` cd code && python main.py --decay=1e-4 --lr=0.001 --layer=3 --seed=2020 --dataset=\"gowalla\" --topks=[20] --recdim=64`\n\n* log output\n\n```shell\n...",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "LightGCN-PyTorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "tanya525625",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/tanya525625/LightGCN-PyTorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "`pip install -r requirements.txt`\n\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "run LightGCN on **Gowalla** dataset:\n\n* command\n\n` cd code && python main.py --decay=1e-4 --lr=0.001 --layer=3 --seed=2020 --dataset=\"gowalla\" --topks=[20] --recdim=64`\n\n* log output\n\n```shell\n...\n======================\nEPOCH[5/1000]\nBPR[sample time][16.2=15.84+0.42]\n[saved][[BPR[aver loss1.128e-01]]\n[0;30;43m[TEST][0m\n{'precision': array([0.03315359]), 'recall': array([0.10711388]), 'ndcg': array([0.08940792])}\n[TOTAL TIME] 35.9975962638855\n...\n======================\nEPOCH[116/1000]\nBPR[sample time][16.9=16.60+0.45]\n[saved][[BPR[aver loss2.056e-02]]\n[TOTAL TIME] 30.99874997138977\n...\n```\n\n*NOTE*:\n\n1. Even though we offer the code to split user-item matrix for matrix multiplication, we strongly suggest you don't enable it since it will extremely slow down the training speed.\n2. If you feel the test process is slow, try to increase the ` testbatch` and enable `multicore`(Windows system may encounter problems with `multicore` option enabled)\n3. Use `tensorboard` option, it's good.\n4. Since we fix the seed(`--seed=2020` ) of `numpy` and `torch` in the beginning, if you run the command as we do above, you should have the exact output log despite the running time (check your output of *epoch 5* and *epoch 116*).\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 06 Dec 2021 21:22:48 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "run LightGCN on **Gowalla** dataset:\n\n* command\n\n` cd code && python main.py --decay=1e-4 --lr=0.001 --layer=3 --seed=2020 --dataset=\"gowalla\" --topks=[20] --recdim=64`\n\n* log output\n\n```shell\n...\n======================\nEPOCH[5/1000]\nBPR[sample time][16.2=15.84+0.42]\n[saved][[BPR[aver loss1.128e-01]]\n[0;30;43m[TEST][0m\n{'precision': array([0.03315359]), 'recall': array([0.10711388]), 'ndcg': array([0.08940792])}\n[TOTAL TIME] 35.9975962638855\n...\n======================\nEPOCH[116/1000]\nBPR[sample time][16.9=16.60+0.45]\n[saved][[BPR[aver loss2.056e-02]]\n[TOTAL TIME] 30.99874997138977\n...\n```\n\n*NOTE*:\n\n1. Even though we offer the code to split user-item matrix for matrix multiplication, we strongly suggest you don't enable it since it will extremely slow down the training speed.\n2. If you feel the test process is slow, try to increase the ` testbatch` and enable `multicore`(Windows system may encounter problems with `multicore` option enabled)\n3. Use `tensorboard` option, it's good.\n4. Since we fix the seed(`--seed=2020` ) of `numpy` and `torch` in the beginning, if you run the command as we do above, you should have the exact output log despite the running time (check your output of *epoch 5* and *epoch 116*).\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
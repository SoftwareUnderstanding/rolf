{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1801.07698",
      "https://arxiv.org/abs/1801.07698",
      "https://arxiv.org/abs/1512.03385",
      "https://arxiv.org/abs/1801.07698",
      "https://arxiv.org/abs/1801.04381",
      "https://arxiv.org/abs/1801.07698",
      "https://arxiv.org/abs/1512.03385",
      "https://arxiv.org/abs/1801.07698",
      "https://arxiv.org/abs/1801.04381",
      "https://arxiv.org/abs/1801.07698"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": ":hamburger:\n\nThanks for these source codes porviding me with knowledges to complete this repository.\n\n- https://github.com/deepinsight/insightface (Official)\n    - Face Analysis Project on MXNet http://insightface.ai\n- https://github.com/zzh8829/yolov3-tf2\n    - YoloV3 Implemented in TensorFlow 2.0\n- https://github.com/ZhaoJ9014/face.evoLVe.PyTorch\n    - face.evoLVe: High-Performance Face Recognition Library based on PyTorch\n- https://github.com/luckycallor/InsightFace-tensorflow\n    - Tensoflow implementation of InsightFace (ArcFace: Additive Angular Margin Loss for Deep Face Recognition).\n- https://github.com/dmonterom/face_recognition_TF2\n    - Training a face Recognizer using ResNet50 + ArcFace in TensorFlow 2.0\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9521604751129622
      ],
      "excerpt": "Original Paper: &nbsp; Arxiv &nbsp; CVPR2019 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/peteryuX/arcface-tf2",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-08-24T03:11:22Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-07T14:45:23Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8743374787689624,
        0.9702200492773748
      ],
      "excerpt": ":fire: ArcFace (Additive Angular Margin Loss for Deep Face Recognition, published in CVPR 2019) implemented in Tensorflow 2.0+. This is an unofficial implementation. :fire: \nAdditive Angular Margin Loss(ArcFace) has a clear geometric interpretation due to the exact correspondence to the geodesic distance on the hypersphere, and consistently outperforms the state-of-the-art and can be easily implemented with negligible computational overhead. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "Data Preparing \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8179619458099548
      ],
      "excerpt": ": Binary Image: convert really slow, but loading faster when traning. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.935043939647535
      ],
      "excerpt": "head_type: ArcHead #: or 'NormHead': FC to targets. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9164702277426373
      ],
      "excerpt": "train_dataset: './data/ms1m_bin.tfrecord' #: or './data/ms1m.tfrecord' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233741740337305,
        0.908733562838046,
        0.8322211584008948,
        0.9688954084487127,
        0.8646782111036414
      ],
      "excerpt": "- The sub_name is the name of outputs directory used in checkpoints and logs folder. (make sure of setting it unique to other models) \n- The head_type is used to choose ArcFace head or normal fully connected layer head for classification in training. (see more detail in ./modules/models.py) \n- The is_ccrop means doing central-cropping on both trainging and testing data or not. \n- The binary_img is used to choose the type of training data, which should be according to the data type you created in the Data-Preparing. \nHere have two modes for training your model, which should be perform the same results at the end. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.918710271024835
      ],
      "excerpt": ": traning with tf.GradientTape(), great for debugging. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.867271294038045
      ],
      "excerpt": ": training with model.fit(). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9310081799090121
      ],
      "excerpt": "You can also encode image into latent vector by model. For example, encode the image from ./data/BruceLee.jpg and save to ./output_embeds.npy as following. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9243528409633959
      ],
      "excerpt": "Verification results (%) of different backbone, head tpye, data augmentation and loss function. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9456973371052921
      ],
      "excerpt": "- The 'CCrop' tag above means doing central-cropping on both trainging and testing data, which could eliminate the redundant boundary of intput face data (especially for AgeDB-30). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "ArcFace unofficial Implemented in Tensorflow 2.0+ (ResNet50, MobileNetV2). \"ArcFace: Additive Angular Margin Loss for Deep Face Recognition\" Published in CVPR 2019. With Colab.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/peteryuX/arcface-tf2/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 44,
      "date": "Sat, 11 Dec 2021 12:21:58 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/peteryuX/arcface-tf2/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "peteryuX/arcface-tf2",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/peteryuX/arcface-tf2/master/notebooks/colab-github-demo.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": ":beer:\n\nAll datasets used in this repository can be found from [face.evoLVe.PyTorch's Data-Zoo](https://github.com/ZhaoJ9014/face.evoLVe.PyTorch#Data-Zoo).\n\nNote:\n\n- Both training and testing dataset are \"Align_112x112\" version.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": ":pizza:\n\nCreate a new python virtual environment by [Anaconda](https://www.anaconda.com/) or just use pip in your python environment and then clone this repository as following.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9893272198983933,
        0.9906248903846466,
        0.9632347459754548,
        0.9770335174395833,
        0.9979947896609701
      ],
      "excerpt": "git clone https://github.com/peteryuX/arcface-tf2.git \ncd arcface-tf2 \nconda env create -f environment.yml \nconda activate arcface-tf2 \npip install -r requirements.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8172984194111891,
        0.8896212899863158
      ],
      "excerpt": "- You can run python ./dataset_checker.py to check if the dataloader work. \nDownload LFW, Aged30 and CFP-FP datasets, then extract them to /your/path/to/test_dataset. These testing data are already binary files, so it's not necessary to do any preprocessing. The directory structure should be like bellow. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.895222649498447
      ],
      "excerpt": "test_dataset: '/your/path/to/test_dataset' \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8601387411103122
      ],
      "excerpt": "<img src=\"photo/architecture.JPG\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8140020261316089
      ],
      "excerpt": "Training and Testing \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8799103507643875
      ],
      "excerpt": "Download MS-Celeb-1M datasets, then extract and convert them to tfrecord as traning data as following. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9060935986199549
      ],
      "excerpt": "python data/convert_train_binary_tfrecord.py --dataset_path=\"/path/to/ms1m_align_112/imgs\" --output_path=\"./data/ms1m_bin.tfrecord\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9060935986199549
      ],
      "excerpt": "python data/convert_train_tfrecord.py --dataset_path=\"/path/to/ms1m_align_112/imgs\" --output_path=\"./data/ms1m.tfrecord\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8044290599680651
      ],
      "excerpt": "batch_size: 128 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": ": train \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8828665034782968
      ],
      "excerpt": "base_lr: 0.01 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633989807152664
      ],
      "excerpt": ": test \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9216610392576469
      ],
      "excerpt": "python train.py --mode=\"eager_tf\" --cfg_path=\"./configs/arc_res50.yaml\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8958425283399728
      ],
      "excerpt": "python train.py --mode=\"fit\" --cfg_path=\"./configs/arc_res50.yaml\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8762677784868108
      ],
      "excerpt": "You can download my trained models for testing from Benchmark and Models without training it yourself. And, evaluate the models you got with the corresponding cfg file on the testing dataset. The testing code in ./modules/evaluations.py were modified from face.evoLVe. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9207402124239462
      ],
      "excerpt": "python test.py --cfg_path=\"./configs/arc_res50.yaml\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9558605642621665
      ],
      "excerpt": "python test.py --cfg_path=\"./configs/arc_res50.yaml\" --img_path=\"./data/BruceLee.jpg\" \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/peteryuX/arcface-tf2/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Kuan-Yu Huang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "[arcface-tf2](https://github.com/peteryuX/arcface-tf2)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "arcface-tf2",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "peteryuX",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/peteryuX/arcface-tf2/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 172,
      "date": "Sat, 11 Dec 2021 12:21:58 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "tensorflow",
      "face-recognition",
      "arcface",
      "arcface-tf2",
      "deep-face-recognition",
      "tf2",
      "colab-notebook",
      "colab"
    ],
    "technique": "GitHub API"
  }
}
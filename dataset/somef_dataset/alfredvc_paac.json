{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1705.04862",
      "https://arxiv.org/abs/1312.5602"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use PAAC in your research, we ask that you please cite our paper:\n```\n@ARTICLE{2017arXiv170504862C,\n   author = {{Clemente}, A.~V. and {Castej{\\'o}n}, H.~N. and {Chandra}, A.\n\t},\n    title = \"{Efficient Parallel Methods for Deep Reinforcement Learning}\",\n  journal = {ArXiv e-prints},\narchivePrefix = \"arXiv\",\n   eprint = {1705.04862},\n primaryClass = \"cs.LG\",\n keywords = {Computer Science - Learning},\n     year = 2017,\n    month = may,\n   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170504862C},\n  adsnote = {Provided by the SAO/NASA Astrophysics Data System}\n}\n```\n\nThe paper has been accepted as a poster to [The Multi-disciplinary Conference on Reinforcement Learning and Decision Making](http://rldm.org/) (citation to come).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@ARTICLE{2017arXiv170504862C,\n   author = {{Clemente}, A.~V. and {Castej{\\'o}n}, H.~N. and {Chandra}, A.\n    },\n    title = \"{Efficient Parallel Methods for Deep Reinforcement Learning}\",\n  journal = {ArXiv e-prints},\narchivePrefix = \"arXiv\",\n   eprint = {1705.04862},\n primaryClass = \"cs.LG\",\n keywords = {Computer Science - Learning},\n     year = 2017,\n    month = may,\n   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170504862C},\n  adsnote = {Provided by the SAO/NASA Astrophysics Data System}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "If running locally, skip step 2. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Alfredvc/paac",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-03-11T20:23:53Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-22T01:40:00Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9841123666613467,
        0.9105537438958073
      ],
      "excerpt": "This repository contains an open source implementation of the PAAC algorithm presented in Efficient Parallel Methods for Deep Reinforcement Learning. \nPAAC is a conceptually simple advantage actor-critic algorithm designed to run efficiently on a GPU, offering A3C like performance in under 12 hours of training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8840469944074224
      ],
      "excerpt": "For pong, the agent will begin to learn after about 5 million frames, and will learn an optimal policy after about 15 million frames. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8382118220103457
      ],
      "excerpt": "Attach to the running docker container with docker exec -it CONTAINER_NAME bash \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9163288716080384,
        0.9482782916557458
      ],
      "excerpt": "These models can be used as starting points for training on the same game, other games, or to generate gifs. \nThis codebase was designed to be easily modified to new environments and new neural network architectures. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772070953383964,
        0.9641087156348539
      ],
      "excerpt": "create a new class that inherits from BaseEnvironment and modify environment_creator.py to create an instance of your new environment. \nThe codebase contains currently two neural network architectures, the architecture used in Playing Atari with Deep Reinforcement Learning, and the architecture from Human-level control through deep reinforcement learning. Both adapted to an actor-critic algorithm. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9773289847077535
      ],
      "excerpt": "The code in this repository is not the code used to generate the results from the paper, but should give similar results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Open source implementation of the PAAC algorithm presented in Efficient Parallel Methods for Deep Reinforcement Learning",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/alfredvc/paac/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 55,
      "date": "Fri, 10 Dec 2021 21:06:07 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Alfredvc/paac/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Alfredvc/paac",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9260731723037967
      ],
      "excerpt": "On a setup with an Intel i7-4790k CPU and an Nvidia GTX 980 Ti GPU with default settings, you can expect around 3000 timesteps (global steps) per second. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8502743991527736,
        0.9294774597450448
      ],
      "excerpt": "To train an agent to play, for example, pong run \n* python3 train.py -g pong -df logs/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9257168827374989
      ],
      "excerpt": "Training can be stopped, for example by using Ctrl+c, and then resumed again by running python3 train.py -g pong -df logs/. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.830268849963189
      ],
      "excerpt": "Attach to the running docker container with docker exec -it CONTAINER_NAME bash \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9177265513165227,
        0.811776127714334
      ],
      "excerpt": "To test the performance of a trained agent run python3 test.py -f logs/ -tc 5 \nPerformed 5 tests for seaquest. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9475909272724197
      ],
      "excerpt": "python3 test.py -f pretrained/breakout/ -gn breakout \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.844893277344299
      ],
      "excerpt": "* Entropy regularization constant default changed from 0.01 to 0.02. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Alfredvc/paac/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Efficient Parallel Methods for Deep Reinforcement Learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "paac",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Alfredvc",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Alfredvc/paac/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Follow the instructions to install [nvidia-docker](https://github.com/NVIDIA/nvidia-docker/)\n2. Clone this repository\n3. Run the container with ```nvidia-docker run -it -v <absolute-path>/paac:/root/paac -p 6006:6006 alfredvc/tf1-ale```.\n\nA CPU version of the docker container is also provided and can be run with ```docker run -it -v <absolute-path>/paac:/root/paac -p 6006:6006 alfredvc/tf1-ale:cpu```.\nWhen running on the CPU pass the device flag ```-d '/cpu:0'``` to the training script.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Requirements\n* Python 3.4+\n* TensorFlow 1.0+\n* [Arcade-Learning-Environment](https://github.com/mgbellemare/Arcade-Learning-Environment)\n* cython (pip3 package)\n* scikit-image (pip3 package)\n* python3-tk\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 197,
      "date": "Fri, 10 Dec 2021 21:06:07 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "reinforcement",
      "learning",
      "reinforcement-learning",
      "paac",
      "machine-learning",
      "atari",
      "tensorflow",
      "open-source"
    ],
    "technique": "GitHub API"
  }
}
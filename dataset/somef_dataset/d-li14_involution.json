{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2103.06255"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@InProceedings{Li_2021_CVPR,\n    author = {Li, Duo and Hu, Jie and Wang, Changhu and Li, Xiangtai and She, Qi and Zhu, Lei and Zhang, Tong and Chen, Qifeng},\n    title = {Involution: Inverting the Inherence of Convolution for Visual Recognition},\n    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n    month = {June},\n    year = {2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9328133643279853,
        0.9999993829151833
      ],
      "excerpt": "Official implementation of a neural operator as described in Involution: Inverting the Inherence of Convolution for Visual Recognition (CVPR'21) \nBy Duo Li, Jie Hu, Changhu Wang, Xiangtai Li, Qi She, Lei Zhu, Tong Zhang, and Qifeng Chen \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.999969947236658
      ],
      "excerpt": "If you find our work useful in your research, please cite: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/d-li14/involution",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-29T15:16:07Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-10T06:26:31Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9610987470253269
      ],
      "excerpt": "Official implementation of a neural operator as described in Involution: Inverting the Inherence of Convolution for Visual Recognition (CVPR'21) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9738928567675919
      ],
      "excerpt": "TL; DR. involution is a general-purpose neural primitive that is versatile for a spectrum of deep learning models on different vision tasks. involution bridges convolution and self-attention in design, while being more efficient and effective than convolution, simpler than self-attention in form.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9871966889620285
      ],
      "excerpt": "The parameters/FLOPs&#8595; and performance&#8593; compared to the convolution baselines are marked in the parentheses. Part of these checkpoints are obtained in our reimplementation runs, whose performance may show slight differences with those reported in our paper. Models are trained with 64 GPUs on ImageNet, 8 GPUs on COCO, and 4 GPUs on Cityscapes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "[CVPR 2021] Involution: Inverting the Inherence of Convolution for Visual Recognition, a brand new neural operator",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/d-li14/involution/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 160,
      "date": "Sun, 12 Dec 2021 19:02:42 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/d-li14/involution/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "d-li14/involution",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8788196294771108
      ],
      "excerpt": "<p align=\"center\"><img src=\"fig/involution.png\" width=\"500\" /></p> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8828968360330183
      ],
      "excerpt": "<p align=\"center\"><img src=\"fig/complexity.png\" width=\"400\" /><img src=\"fig/parameter.png\" width=\"400\" /></p> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8064976730923982
      ],
      "excerpt": "|         Model         | Params(M) | FLOPs(G) | Top-1 (%) | Top-5 (%) | Config | Download | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8335008418440818
      ],
      "excerpt": "| RedNet-26             |  9.23<sub>(32.8%&#8595;)</sub>     | 1.73<sub>(29.2%&#8595;)</sub>     | 75.96 | 93.19 | config | model &#124; log | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8192859245686362,
        0.8234646208348033
      ],
      "excerpt": "| RedNet-50             | 15.54<sub>(39.5%&#8595;)</sub>     | 2.71<sub>(34.1%&#8595;)</sub>     | 78.35 | 94.13 | config | model &#124; log | \n| RedNet-101            | 25.65<sub>(42.6%&#8595;)</sub>     | 4.74<sub>(40.5%&#8595;)</sub>     | 78.92 | 94.35 | config | model &#124; log | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8406739745848308
      ],
      "excerpt": "Before finetuning on the following downstream tasks, download the ImageNet pre-trained RedNet-50 weights and set the pretrained argument in det/configs/_base_/models/*.py or seg/configs/_base_/models/*.py to your local path. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/d-li14/involution/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Duo Li\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "involution",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "involution",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "d-li14",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/d-li14/involution/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1203,
      "date": "Sun, 12 Dec 2021 19:02:42 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "involution",
      "operator",
      "pytorch",
      "image-classification",
      "object-detection",
      "instance-segmentation",
      "semantic-segmentation",
      "cvpr2021",
      "pre-trained-model"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This repository is fully built upon the [OpenMMLab](https://openmmlab.com/) toolkits. For each individual task, the config and model files follow the same directory organization as [mmcls](https://github.com/open-mmlab/mmclassification), [mmdet](https://github.com/open-mmlab/mmdetection), and [mmseg](https://github.com/open-mmlab/mmsegmentation) respectively, so just copy-and-paste them to the corresponding locations to get started.\n\nFor example, in terms of evaluating detectors\n```shell\ngit clone https://github.com/open-mmlab/mmdetection #: and install\n\n#: copy model files\ncp det/mmdet/models/backbones/* mmdetection/mmdet/models/backbones\ncp det/mmdet/models/necks/* mmdetection/mmdet/models/necks\ncp det/mmdet/models/dense_heads/* mmdetection/mmdet/models/dense_heads\ncp det/mmdet/models/roi_heads/* mmdetection/mmdet/models/roi_heads\ncp det/mmdet/models/roi_heads/mask_heads/* mmdetection/mmdet/models/roi_heads/mask_heads\ncp det/mmdet/models/utils/* mmdetection/mmdet/models/utils\ncp det/mmdet/datasets/* mmdetection/mmdet/datasets\n\n#: copy config files\ncp det/configs/_base_/models/* mmdetection/configs/_base_/models\ncp det/configs/_base_/schedules/* mmdetection/configs/_base_/schedules\ncp det/configs/involution mmdetection/configs -r\n\n#: evaluate checkpoints\ncd mmdetection\nbash tools/dist_test.sh ${CONFIG_FILE} ${CHECKPOINT_FILE} ${GPU_NUM} [--out ${RESULT_FILE}] [--eval ${EVAL_METRICS}]\n```\n\nFor more detailed guidance, please refer to the original [mmcls](https://github.com/open-mmlab/mmclassification), [mmdet](https://github.com/open-mmlab/mmdetection), and [mmseg](https://github.com/open-mmlab/mmsegmentation) tutorials.\n\nCurrently, we provide an memory-efficient implementation of the involuton operator based on [CuPy](https://cupy.dev/). Please install this library in advance. A customized CUDA kernel would bring about further acceleration on the hardware. Any contribution from the community regarding this is welcomed!\n\n",
      "technique": "Header extraction"
    }
  ]
}
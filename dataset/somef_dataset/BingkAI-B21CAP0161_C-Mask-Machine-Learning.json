{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.06870\n- Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., &amp; Adam, H. (2017, April 17",
      "https://arxiv.org/abs/1704.04861\n- Karras, T., Laine, S., &amp; Aila, T. (2019, February 6",
      "https://arxiv.org/abs/1812.04948\n- Singh, S., Ahuja, U., Kumar, M., Kumar, K., &amp; Sachdeva, M. (2021"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Cabani, A., Hammoudi, K., Benhabiles, H., &amp; Melkemi, M. (2020). MaskedFace-Net \u2013 A dataset of correctly/incorrectly masked face images in the context of COVID-19. Smart Health, 19, 100144. https://doi.org/10.1016/j.smhl.2020.100144\n- Hammoudi, K., Cabani, A., Benhabiles, H., &amp; Melkemi, M. (2020). Validating the correct wearing of protection mask by taking a selfie: design of a mobile application \"CheckYourMask\" to limit the spread of COVID-19. Computer Modeling in Engineering &amp; Sciences, 124(3), 1049\u20131059. https://doi.org/10.32604/cmes.2020.011663\n- He, K., Gkioxari, G., Doll\u00e1r, P., &amp; Girshick, R. (2018, January 24). Mask R-CNN. arXiv.org. https://arxiv.org/abs/1703.06870\n- Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., &amp; Adam, H. (2017, April 17). MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. arXiv.org. https://arxiv.org/abs/1704.04861\n- Karras, T., Laine, S., &amp; Aila, T. (2019, February 6). A Style-Based Generator Architecture for Generative Adversarial Networks. arXiv.org. https://arxiv.org/abs/1812.04948\n- Singh, S., Ahuja, U., Kumar, M., Kumar, K., &amp; Sachdeva, M. (2021). Face mask detection using YOLOv3 and faster R-CNN models: COVID-19 environment. Multimedia Tools and Applications, 80(13), 19753\u201319768. https://doi.org/10.1007/s11042-021-10711-8\n\n- [https://d2l.ai/chapter_computer-vision/rcnn.html](https://d2l.ai/chapter_computer-vision/rcnn.html)\n- [https://linkinpark213.com/2019/03/17/rcnns/](https://linkinpark213.com/2019/03/17/rcnns/)\n- [https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/](https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/)\n- [https://towardsdatascience.com/transfer-learning-using-mobilenet-and-keras-c75daf7ff299](https://towardsdatascience.com/transfer-learning-using-mobilenet-and-keras-c75daf7ff299)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{matterport_maskrcnn_2017,\n  title={Mask R-CNN for object detection and instance segmentation on Keras and TensorFlow},\n  author={Waleed Abdulla},\n  year={2017},\n  publisher={Github},\n  journal={GitHub repository},\n  howpublished={\\url{https://github.com/matterport/Mask_RCNN}},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{make ml,\ntitle={Mask Dataset},\nurl={https://makeml.app/datasets/mask},\njournal={Make ML}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BingkAI-B21CAP0161/C-Mask-Machine-Learning",
    "technique": "GitHub API"
  },
  "contributor": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [Kc-codetalker](https://github.com/Kc-codetalker)\n- [mohfaisal25](https://github.com/mohfaisal25)",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-05T07:54:04Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-06T01:41:48Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9430089638887433,
        0.9841048589125498,
        0.8975061207050122,
        0.9602056717911118
      ],
      "excerpt": "For Back-End project using the trained models, see here for classification and here for object detection. \nFor Front-End project of C-Mask, see here. \nC-Mask is an app that can detect whether people are wearing masks correctly. There are two measures, first by single face classification and another one by faces object detection. App is created for Android devices, and the inferences are done in cloud back-end. \nFace classification is done by using custom CNN model. The output is binary label prediction. Faces object detection is done by using Mask R-CNN architecture. The output of inferences is a list of coordinates for each bounding box and labels for each bounding box. Researches are executed using Jupyter Notebooks and Google Colaboratory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8247072559683575,
        0.9399148494591374,
        0.9616363884236353
      ],
      "excerpt": "1. Modelling includes notebooks for building, training, and evaluating machine learning models. \nFor classification, we first used MaskedFace-Net dataset which consists of 2 classes, CMFD (Correctly Masked) and IMFD (Incorrectly Masked). The images are faces of people patched with generated medical masks, not real masks. The IMFD images can be further splited into three classes, uncovered chin, uncovered nose, and uncovered nose and chin. We also combine it with Flickr Faces HQ dataset for no mask faces. Thus we had 5 labels for this combined dataset which can be found here. \nAfter facing overfitting, due to the dataset only contains single variant of mask and all of them are generated by computer, we switch to new dataset. Face mask dataset by omkargurav contains more diverse masks and also different image shapes. This dataset improves prediction on new images, especially with diverse face masks. We further tried the third dataset by prithwirajmitra and combine it with the second dataset. The combined dataset can be found here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.98225358153381,
        0.9881974678114932,
        0.9800205146286896,
        0.9377861031555301,
        0.9070552539351711
      ],
      "excerpt": "For classification, we first tried transfer learning using MobileNet. We tried MobileNetV2 and MobileNetV3Large with various scenarios. All of them overfits on the training and fails to predict new images correctly. The most frequent problem we found is the training and validation accuracy and loss are high on training, but when we evaluate afterward the model predicts all images as the same label, even on training and validation datasets. \nWe then tried creating custom CNN model in hope having a better performance. It did much better than previous MobileNets, as it didn't fall into overfitting. But as the first dataset only contains images with uniform generated masks, it failed to predict random mask faces. When we use 2nd and 3rd datasets, we gain improvement on predictions on new images. But, for this scenario, the model can only classifying two classes which are correctly masked and no mask classes. \nFor the last trial, we decided to try make a model that can classify 5 classes. These classes are divided to be correctly masked, no mask, uncovered chin, uncovered nose, and uncovered nose and mouth. For this scenario, we used MaskedFace-Net dataset and combine with Flickr Faces HQ dataset. To obtain a good model then we use transfer learning method using pre-trained model MobileNetV2 and add some layer such as Conv2D Layer and Dropout Layer. Finally, those layer can bring the model to avoid previous overfitting and obtain good accuracy for training, validation, and testing. This model also can classify all 5 classes. \nFor object detection, we tried transfer learning using Mask R-CNN by Matterport and use face mask detection dataset. This Mask R-CNN architecture library already provides functions to create Dataset object, create Config for the model, as well as training and evaluating the model. We refer a tutorial by Jason Brownlee for learning to use the library. \nThe latest model used for C-Mask classification is MobileNetV2_retrain_best_model.h5, trained using combined MaskedFace-Net dataset and Flickr Faces HQ dataset for 8 epochs. The latest model used for C-Mask object detection is face_mask_detection_config_50_epoch_128_steps, trained using face mask detection dataset on Mask R-CNN model for 50 epochs. They can be found in the v1.0.0 release. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Machine Learning codes, notebooks, and models for C-Mask app.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BingkAI-B21CAP0161/C-Mask-Machine-Learning/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 08 Dec 2021 13:30:57 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/BingkAI-B21CAP0161/C-Mask-Machine-Learning/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "BingkAI-B21CAP0161/C-Mask-Machine-Learning",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/BingkAI-B21CAP0161/C-Mask-Machine-Learning/master/Masked_Face_Classification/Preprocessing/Arrange_IMFD_Images.ipynb",
      "https://raw.githubusercontent.com/BingkAI-B21CAP0161/C-Mask-Machine-Learning/master/Masked_Face_Classification/Preprocessing/Extract_Dataset.ipynb",
      "https://raw.githubusercontent.com/BingkAI-B21CAP0161/C-Mask-Machine-Learning/master/Masked_Face_Classification/Preprocessing/arrange_CMFD_dataset.ipynb",
      "https://raw.githubusercontent.com/BingkAI-B21CAP0161/C-Mask-Machine-Learning/master/Masked_Face_Classification/Preprocessing/arrange_no_mask_dataset.ipynb",
      "https://raw.githubusercontent.com/BingkAI-B21CAP0161/C-Mask-Machine-Learning/master/Masked_Face_Classification/Modelling/Custom_CNN.ipynb",
      "https://raw.githubusercontent.com/BingkAI-B21CAP0161/C-Mask-Machine-Learning/master/Masked_Face_Classification/Modelling/MobileNet_without_retrain.ipynb",
      "https://raw.githubusercontent.com/BingkAI-B21CAP0161/C-Mask-Machine-Learning/master/Masked_Face_Classification/Modelling/MobileNetV3_retrain.ipynb",
      "https://raw.githubusercontent.com/BingkAI-B21CAP0161/C-Mask-Machine-Learning/master/Masked_Face_Classification/Modelling/MobileNetV2_retrain.ipynb",
      "https://raw.githubusercontent.com/BingkAI-B21CAP0161/C-Mask-Machine-Learning/master/Masked_Face_Object_Detection/Modelling/Mask_R_CNN_Object_Detection.ipynb",
      "https://raw.githubusercontent.com/BingkAI-B21CAP0161/C-Mask-Machine-Learning/master/Masked_Face_Object_Detection/Modelling/Example_Mask_R-CNN_Object_Detection_Kangaroo.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/BingkAI-B21CAP0161/C-Mask-Machine-Learning/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "C-Mask Machine Learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "C-Mask-Machine-Learning",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "BingkAI-B21CAP0161",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BingkAI-B21CAP0161/C-Mask-Machine-Learning/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "Kc-codetalker",
        "body": "`MobileNetV2_retrain_best_model.h5` is the __HDF5__ file for classification model. This file can be loaded using [__TensorFlow__](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model).\r\n\r\n`face_mask_detection_config_50_epoch_128_steps` is the saved model for object detection model using [__Mask R-CNN by Matterport__](https://github.com/matterport/Mask_RCNN). `mask_rcnn_face_mask_detection_config_0050.h5` is the saved model for 50th epoch. This file need to be loaded using the Mask R-CNN library utilities.",
        "dateCreated": "2021-06-07T17:35:42Z",
        "datePublished": "2021-06-08T09:12:59Z",
        "html_url": "https://github.com/BingkAI-B21CAP0161/C-Mask-Machine-Learning/releases/tag/v1.0.0",
        "name": "Saved Models for Classification and Object Detection models.",
        "tag_name": "v1.0.0",
        "tarball_url": "https://api.github.com/repos/BingkAI-B21CAP0161/C-Mask-Machine-Learning/tarball/v1.0.0",
        "url": "https://api.github.com/repos/BingkAI-B21CAP0161/C-Mask-Machine-Learning/releases/44262546",
        "zipball_url": "https://api.github.com/repos/BingkAI-B21CAP0161/C-Mask-Machine-Learning/zipball/v1.0.0"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We need to have `Python 3` and `Jupyter` on the environment where you'd like to run these notebooks. We used `Google Colaboratory` for researching on all these notebooks. We also need to install external packages that are imported inside each notebook, including, but not limited to `tensorflow`, `numpy`, `matplotlib`, and others.\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Run the notebook on prepared environment. Each notebook can be run independently.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Wed, 08 Dec 2021 13:30:57 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        0.9061036823472083
      ],
      "excerpt": "Temporal Difference learning (TD-learning): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906174419333412
      ],
      "excerpt": "Trust Region Policy Optimization (TRPO): \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kshitij-ingale/Reinforcement-Learning",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-10-24T20:34:15Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-14T07:42:15Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9880088963453436
      ],
      "excerpt": "Reinforcement learning is a class of machine learning problems which involve learning to act in an environment. The machine learning agent learns to perform actions based on the reward (feedback), it receives from the environment such that it maximizes certain criteria (usually, discounted future rewards obtained). Based on the objective and/or type of environment, there are various reinforcement learning algorithms, some of them are as follows:   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9835346063974715
      ],
      "excerpt": "These planning based methods assume complete knowledge of environment and exploit that to evaluate each state encountered in environment. Based on this evaluation, agent can learn a policy to act in the environment such that required criterion (cumulative rewards obtained with the policy) is maximized.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9154177272029226
      ],
      "excerpt": "These methods rely on simulating many episodes exploring different actions in an environment in order to approximate value of states encoutered during simulation. This can be then be used to learn a policy maximizing expected rewards in environment. Note that this method don't require complete knowledge of model, however, it does rely on simulating agent in environment many times which may not be always feasible. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.992837234203169,
        0.8126736051923733,
        0.922316382433485
      ],
      "excerpt": "These methods are like a combination of Monte-Carlo and Dynamic programming based planning. In this method, agent interacts with environment for a few steps and later uses bootstrapping with planning based method to get expected future return at the states encountered. In this way, after evaluating different states, agent learns to choose actions which maximize the required criterion. \nDeep Q networks (DQN): \nThese methods bring in the function approximators to predict expected future returns for each action in a given state of environment. The agent can then learn a policy to perform actions in the encountered states to maximize future rewards. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9786764649087742
      ],
      "excerpt": "These methods attempt to directly learn the policy as opposed to earlier approaches of evaluating states and performing actions with best states. Policy gradients algorithms parameterize policy with function approximators and learn parameters such that agent learns to execute actions that maximize expected returns from states encountered in the environment. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9923596717499189
      ],
      "excerpt": "This is like an extension to vanilla policy gradients focusing more on step size for updates to parameters of policy appoximators ensuring better performance on updates to policy parameters. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation for Reinforcement learning algorithms using python and tensorflow",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kshitij-ingale/Reinforcement-Learning/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 13 Dec 2021 21:06:02 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kshitij-ingale/Reinforcement-Learning/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "kshitij-ingale/Reinforcement-Learning",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/kshitij-ingale/Reinforcement-Learning/master/02_Monte_Carlo/Blackjack.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kshitij-ingale/Reinforcement-Learning/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Reinforcement-Learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Reinforcement-Learning",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "kshitij-ingale",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kshitij-ingale/Reinforcement-Learning/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 13 Dec 2021 21:06:02 GMT"
    },
    "technique": "GitHub API"
  }
}
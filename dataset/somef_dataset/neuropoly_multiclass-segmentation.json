{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1505.04597"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] Ronneberger O, Fischer P, Brox T. U-Net: Convolutional Networks for Biomedical Image Segmentation. [arXiv](https://arxiv.org/abs/1505.04597) \\[cs.CV] 2015.  \n[2] Badrinarayanan V, Handa A, Cipolla R. SegNet: A Deep Convolutional Encoder-Decoder Architecture for Robust Semantic Pixel-Wise Labelling. [arXiv](https://arxiv.org/pdf/1511.00561.pdf) \\[cs.CV] 2015.  \n[3] Perone CS, Calabrese E, Cohen-Adad J. Spinal cord gray matter segmentation using deep dilated convolutions. Sci. Rep. 2018;8:5966. [arXiv](https://arxiv.org/pdf/1710.01269.pdf)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this repository useful in your research, please cite the following paper:\n\n```\n@ARTICLE{Paugam2019-mf,\n  title    = \"Open-source pipeline for multi-class segmentation of the spinal\n              cord with deep learning\",\n  author   = \"Paugam, Fran{\\c c}ois and Lefeuvre, Jennifer and Perone,\n              Christian S and Gros, Charley and Reich, Daniel S and Sati, Pascal\n              and Cohen-Adad, Julien\",\n  abstract = \"This paper presents an open-source pipeline to train neural\n              networks to segment structures of interest from MRI data. The\n              pipeline is tailored towards homogeneous datasets and requires\n              relatively low amounts of manual segmentations (few dozen, or\n              less depending on the homogeneity of the dataset). Two use-case\n              scenarios for segmenting the spinal cord white and grey matter\n              are presented: one in marmosets with variable numbers of lesions,\n              and the other in the publicly available human grey matter\n              segmentation challenge [1]. The pipeline is\n              freely available at:\n              https://github.com/neuropoly/multiclass-segmentation.\",\n  journal  = \"Magn. Reson. Imaging\",\n  month    =  apr,\n  year     =  2019,\n  keywords = \"MRI; segmentation; deep learning; u-net; cnn; spinal cord;\n              marmoset\"\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@ARTICLE{Paugam2019-mf,\n  title    = \"Open-source pipeline for multi-class segmentation of the spinal\n              cord with deep learning\",\n  author   = \"Paugam, Fran{\\c c}ois and Lefeuvre, Jennifer and Perone,\n              Christian S and Gros, Charley and Reich, Daniel S and Sati, Pascal\n              and Cohen-Adad, Julien\",\n  abstract = \"This paper presents an open-source pipeline to train neural\n              networks to segment structures of interest from MRI data. The\n              pipeline is tailored towards homogeneous datasets and requires\n              relatively low amounts of manual segmentations (few dozen, or\n              less depending on the homogeneity of the dataset). Two use-case\n              scenarios for segmenting the spinal cord white and grey matter\n              are presented: one in marmosets with variable numbers of lesions,\n              and the other in the publicly available human grey matter\n              segmentation challenge [1]. The pipeline is\n              freely available at:\n              https://github.com/neuropoly/multiclass-segmentation.\",\n  journal  = \"Magn. Reson. Imaging\",\n  month    =  apr,\n  year     =  2019,\n  keywords = \"MRI; segmentation; deep learning; u-net; cnn; spinal cord;\n              marmoset\"\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/neuropoly/multiclass-segmentation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-05-10T01:14:31Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-28T16:11:22Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The hyper-parameters are divided in 4 categories. \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "This pipeline's purpose is to train a neural network to segment NifTi files from examples.  \nSince the training requires example, the first step consists in producing manual segmentations of a fraction of the files. 10 to 50% of the files should be a good proportion, however this sample must be representative of the rest of the dataset. Datasets with great variability might require bigger fractions to be manually segmented.  \nThe network is trained through a gradient back-propagation algorithm on the loss. The loss quantifies the difference between the predictions of the network and the manual segementations.  \nOnce trained, the network can be used to automtically segment the entire dataset.\n\nFor training and inference, the volumes are sliced along the vertical axis and treated as collections of 2D images. Thus the image processing operations are 2D operations. Data augmentation is used on the training data. It consists in random modifications of the images and their corresponding GT to create more various examples. \n\n<img src=\"./media/process.png\" alt=\"process schema\" width=\"600\"/>\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9511368655534647
      ],
      "excerpt": "\u26a0\ufe0f\u200e\u200e This repository is no more maintained. If you would like to perform deep learning experiment and train models, please use ivadomed, which is more up-to-date and is actively maintained. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661809521273257
      ],
      "excerpt": "It is intended to segment homogeneous databases from a small amount of manual examples. In a typical scenario, the user segments manually 5 to 10 percents of his images, trains the network on these examples, and then uses the network to segment the remaining images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8808450456955831,
        0.8808450456955831,
        0.8808450456955831
      ],
      "excerpt": "input ./data/subject_1.nii.gz csf ./data/subject_1_manual_csf.nii.gz gm ./data/subject_1_manual_gm.nii.gz wm ./data/subject_1_manual_wm.nii.gz \ninput ./data/subject_2.nii.gz csf ./data/subject_2_manual_csf.nii.gz gm ./data/subject_2_manual_gm.nii.gz wm ./data/subject_2_manual_wm.nii.gz \ninput ./data/subject_3.nii.gz csf ./data/subject_3_manual_csf.nii.gz gm ./data/subject_3_manual_gm.nii.gz wm ./data/subject_3_manual_wm.nii.gz \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.923623875355973,
        0.9330136535146631
      ],
      "excerpt": "The files registered in the training_data.txt file will be used to train the network, and the ones in the validation_data_template.txt will only be used to compute the loss without modifying the network. This validation dataset is useful to detect overfitting. It is also recommanded to keep some manually segmented data for an evaluation dataset to use after the training for its evaluation. A good rule of thumb is to manually segment 10 % of your dataset and use 70/15/15 % of these manually segmented images for training/validation/evaluation. \nTensorboard is a tool to visualize in a web browser the evolution of training and validation loss during the training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9789316991028197,
        0.8245483058110069
      ],
      "excerpt": "When the training is over, two models are saved in ./runs/\\<timestamp>_<machine_name> folder. One is best_model.pt and corresponds to the weights giving the smallest loss on the validation dataset, the other is final_model.pt and corresponds to the weights at the last epoch. \nTo use your trained model on new data, execute the segment.py script with the following arguments : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.849388388242712
      ],
      "excerpt": "Remark : the input files must share the same resolution and orientation as the ones used in training. To check which are these resolution and orientation, you can either check the parameters.json file copied in the directory where the model was saved, or use the show_res_ori.py script with the --model (-m) argument providing the path to the model, e.g. : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9921354476821671,
        0.848202256380823,
        0.9532735478132253,
        0.9767287046761778,
        0.8583610742201638,
        0.9186067577520086,
        0.84063691493423,
        0.8716044904302136
      ],
      "excerpt": "This category contains the parameters related to the data augmentation. The data augmentation operation is the combination of 5 transformations : rotation, elastic deformation, vertical symmetry, channel shift and scaling.  \nflip_rate (float) : probability to apply the vertical symmetry. Default value is 0.5. \nscale_range (tuple) : range of size of the origin size cropped for scaling. Default value is (0.08, 1.0). \nratio_range (tuple) : range of aspect ratio of the origin aspect ratio cropped for scaling. Default value is (3./4., 4./3.). \nmax_angle (float or tuple) : angle range of the rotation in degrees (if it is a single float a, the range will be [-a,a]). \nelastic_rate (float) : probability of applying the elastic deformation. Default value is 0.5. \nalpha_range (tuple) : range of alpha value for the elastic deformation. \nsigma_range (tuple) : range of sigma value for the elastic deformation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9024266076132054
      ],
      "excerpt": "optimizer (string) : optimizer used to update the network's weights. Possible values are \"sgd\" for simple gradient descent and \"adam\" for the Adam optimizer. Default value is \"adam\". \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9127308819266652,
        0.9354000220135392,
        0.8591636320739763
      ],
      "excerpt": "lr_schedule (string) : schedule of the learning rate. Possible values are \"constant\" for a constant learning rate, \"cosine\" for a cosine annealing schedule and \"poly\" for the poly schedule. Default value is \"constant\". \npoly_schedule_p (float) : power of the poly schedule (only used for poly learning rate schedule). Default value is 0.9. \nRemark : the poly schedule is defined as follows \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8700034967331783,
        0.9631866659826891,
        0.9827542253063487
      ],
      "excerpt": "  where \u03bb is the learning rate, i the number of the current epoch, n the total number of epochs to run and p the parameter poly_schedule_p. \nThis category contains the the hyper-parameters used to define and parameterize the network model. \nmodel (string) : architecture model of the network. Possible values are \"unet\" for the U-Net[1], \"smallunet\" for a modified U-Net with half less filters and one stage less deep, \"segnet\" for the SegNet[2] and \"nopoolaspp\" for the NoPoolASPP[3]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9743390340521911
      ],
      "excerpt": "This category contains the data specifications used to check that all the loaded files share the same specifications, and hyper-parameters to format the data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.992717104560436,
        0.9253742933823841
      ],
      "excerpt": "matrix_size (tuple) : size of the center-cropping to apply on every slice. For the models with pooling (SmallUNet and UNet) the sizes should be multiple of 2^p where p is the number of pooling operations (resp. 3 and 4).  \nresolution (string) : resolution in the axial planes. It should be in the following format : \"axb\" where a is the resolution in the left/right axis and b in the anterior/posterior axis, e.g. \"0.15x0.15\". \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Repository for the code related to the NIH marmoset longitudinal segmentation project.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/neuropoly/multiclass-segmentation/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Sat, 11 Dec 2021 06:29:35 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/neuropoly/multiclass-segmentation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "neuropoly/multiclass-segmentation",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Rename the *parameters_template.json* file to *parameters.json* and modify the values with the hyper-parameters you want.  \nSee the section **Description of the hyper-parameters** below for a complete description of their functions.  \nA copy of the *parameters.json* file is added to the folder of the run where the model is saved. \n  \n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Clone the repo: \n\n``` bash\ngit clone https://github.com/neuropoly/multiclass-segmentation\ncd multiclass-segmentation\n```\n\nThe required librairies can be easily installed with pip:\n\n``` bash\npip install -r requirements.txt\n```\n\n  > Note: To use tensorboard you must also install tensorflow with \n  > ``` pip install tensorflow```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9206314919883254
      ],
      "excerpt": "You can use the --cuda option to use cuda (thus running on GPU), and the --GPU_id argument (int) to define the id of the GPU to use (default is 0). For example :  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8778487586960795
      ],
      "excerpt": "Example : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8856584692842955
      ],
      "excerpt": "Execute the training.py script. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833615947399328
      ],
      "excerpt": "python training.py --cuda --GPU_id 5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8845874263203706
      ],
      "excerpt": "- --output (-o) : path to write the files, \"_<class name>_seg\" suffixes will be added to the file name. This argument is optional, if not provided, the input path will be used. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8778487586960795
      ],
      "excerpt": "Example :  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8510345694173961,
        0.911110030725422
      ],
      "excerpt": "channel_shift_range (int) : percentage of the max value to use for the channel shift range (e.g. for a value a, the range of the shiffting value is [-a/100*max(input),a/100*max(input)]). \n<img src=\"./media/data_augmentation.png\" alt=\"data augmentation example\" width=\"800\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8203342209050244
      ],
      "excerpt": "batch_size (int) : number of images in each batch.  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/neuropoly/multiclass-segmentation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Multiclass segmentation pipeline",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "multiclass-segmentation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "neuropoly",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/neuropoly/multiclass-segmentation/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The pipeline uses Python 2.7. A decent amount of RAM (at least 8GB) is necessary to load the data during training. Although the training can be done on the CPU, it is sensibly more efficient on a GPU (with cuda librairies installed).\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 15,
      "date": "Sat, 11 Dec 2021 06:29:35 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "object SparqlConstruct { \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/agnos-ai/reactive-sparql",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2015-09-27T21:51:58Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-08T18:07:09Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8716487666020294,
        0.9294906031627522,
        0.9588036422936015,
        0.9514576332897872,
        0.9330856176394612
      ],
      "excerpt": "Working with Sparql query solutions (rows of result bindings as returned by a SELECT statement) is not always suitable. This is because the result \nis not plain RDF. \nUse of SPARQL CONSTRUCTs is suitable in cases where we are only interested in triples (i.e. not \nquads, where the graph IRI is missing) \nAt the moment there is no way to write the following statement, so that the resulting RDF is returned in \"quads\" format (N-QUADS or JSON-LD) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9489885245956167,
        0.8910979133803575
      ],
      "excerpt": "This flow has been created to circumvent the problem. It is an extension of the API used in Flavour #1. \nInstead of a SparqlQuery() this flow works with a SparqlConstruct() inside the SparqlRequest() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9796427597662353,
        0.9826426010571138,
        0.9633882288821147
      ],
      "excerpt": "By specifying a set of matching resource, property and/or graph IRIs, we limit the number of results that are returned. \nInternally this flow will generate a reified SELECT statement that allows us to capture all 4 properties of the RDF Model, including the graph IRI. \nThe flow responds with a SparqlModelResult(model: Model) within a SparqlResult() which contains the RDF4J Model (Graph) instance. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.876045711859291,
        0.8295625935991243,
        0.9579665389882137
      ],
      "excerpt": "for more detail. \nThis flow allows for basic graph manipulation, as defined by the graph-store protocol. \nNot all aspects of the protocol are supported, however it is possible to: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8729869184827247
      ],
      "excerpt": "If no graphIri is specified the query returns the contents of the DEFAULT graph. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9778516066976275,
        0.8149107004260434
      ],
      "excerpt": "Insert the contents of an RDF Model into the specified graph. There are 3 variants: \nInsertGraphFromModel(graphModel: Model, graphUri: Option[URI]): inserts an in-memory RDF Model; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9861856371116161
      ],
      "excerpt": "All the operations above return a GraphStoreResponse which contains the success status of the operation and a optional model (for GetGraph() queries only) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9889996624341679
      ],
      "excerpt": "There is a mergeGraphs: Boolean parameter for all insert messages, that allows us to control how the resulting graph will deal with \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.924757529158124
      ],
      "excerpt": "mergeGraphs = true will perform a HTTP PUT operation, which merges the content of the graph being sent with the graph that \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9747324823715846
      ],
      "excerpt": "mergeGraphs = false is the DEFAULT option and will perform a HTTP POST operation, which replaces the content of the graph with \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A Reactive Sparql Client written in Scala and Akka",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/modelfabric/reactive-sparql/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Mon, 20 Dec 2021 12:53:04 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/agnos-ai/reactive-sparql/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "agnos-ai/reactive-sparql",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.836692864042986
      ],
      "excerpt": "InsertGraphFromPath(filePath: Path, graphUri: Option[URI], format: RDFFormat): inserts the contents of the specified file in the given RDF format; \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/agnos-ai/reactive-sparql/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Scala"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License (MIT)\\n\\nCopyright (c) 2015 ModelFabric\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "reactive-sparql",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "reactive-sparql",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "agnos-ai",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/agnos-ai/reactive-sparql/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Use the `SparqlQuery(stmt: String)` or `SparqlUpdate(stmt: String)` case class and embed it in a `SparqlRequest()` to be passed to the flow. On the other end a\n`SparqlResponse()` pops out. Support for custom mappings is available, where the resulting values get marshaled to a custom domain object.\nThis is however not mandatory, there is a default result mapper available that will return a [standard\nresult set model](src/main/scala/ai/agnos/sparql/api/SparqlResult.scala#L25) based on the `application/sparql-results+json` content type.\n\nIt is possible to use a single wrapper flow of [`Flow[SparqlRequest, SparqlResponse, _]`](src/main/scala/ai/agnos/sparql/stream/client/SparqlRequestFlowBuilder.scala)\nto run both `SparqlUpdate()` and `SparqlQuery()` statements. There is an option to use specialised [query](src/main/scala/ai/agnos/sparql/stream/client/SparqlQueryFlowBuilder.scala)\nand [update](src/main/scala/ai/agnos/sparql/stream/client/SparqlUpdateFlowBuilder.scala) flows as well.\n\nThe underlying implementation communicates with the triple store via the HTTP endpoints, as documented here\nfor [queries](https://www.w3.org/TR/2013/REC-sparql11-query-20130321/)\nand [updates](https://www.w3.org/TR/2013/REC-sparql11-update-20130321/).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```scala\n/* Define domain case class and mappings */\nobject Person extends ResultMapper[Person] {\n  override def map(qs: QuerySolution): Person = {\n    Person(qs.uri(\"g\").get, qs.string(\"c\").get)\n  }\n}\ncase class Person(id: URI, name: String) extends SparqlResult\n\n/* Create a bespoke SparqlQuery with a mapping to a Person */\nval mappingQuery2Get = SparqlQuery( \"\"\"\n  |SELECT ?g ?b ?c\n  |FROM NAMED <urn:test:agnos:data>\n  |WHERE {\n  |  GRAPH ?g {\n  |   <urn:test:whatever> ?b ?c\n  |  }\n  |}\"\"\", mapping = Person, reasoningEnabled = true)\n\n/* Create the Flow and Probes */\nval sparqlRequestFlowUnderTest = SparqlRequestFlowBuilder.sparqlRequestFlow(testServerEndpoint)\nval (source, sink) = TestSource.probe[SparqlRequest]\n  .via(sparqlRequestFlowUnderTest)\n  .toMat(TestSink.probe[SparqlResponse])(Keep.both)\n  .run()\n\n/* Send the request to the stream and expect the result */\nsink.request(1)\nsource.sendNext(SparqlRequest(mappingQuery2Get))\nsink.expectNext(receiveTimeout) match {\n  case SparqlResponse(_, true, results, None) =>\n    val persons: Seq[Person] = results //the  mapped collection is returned\n    assert(persons.contains(...)\n  case r@_ =>\n    fail(r)\n}\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Mon, 20 Dec 2021 12:53:04 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```scala\n/* Define domain case class and mappings */\nobject Person extends ResultMapper[Person] {\n  override def map(qs: QuerySolution): Person = {\n    Person(qs.uri(\"g\").get, qs.string(\"c\").get)\n  }\n}\ncase class Person(id: URI, name: String) extends SparqlResult\n\n/* Create a bespoke SparqlQuery with a mapping to a Person */\nval mappingQuery2Get = SparqlQuery( \"\"\"\n  |SELECT ?g ?b ?c\n  |FROM NAMED <urn:test:agnos:data>\n  |WHERE {\n  |  GRAPH ?g {\n  |   <urn:test:whatever> ?b ?c\n  |  }\n  |}\"\"\", mapping = Person, reasoningEnabled = true)\n\n/* Create the Flow and Probes */\nval sparqlRequestFlowUnderTest = SparqlRequestFlowBuilder.sparqlRequestFlow(testServerEndpoint)\nval (source, sink) = TestSource.probe[SparqlRequest]\n  .via(sparqlRequestFlowUnderTest)\n  .toMat(TestSink.probe[SparqlResponse])(Keep.both)\n  .run()\n\n/* Send the request to the stream and expect the result */\nsink.request(1)\nsource.sendNext(SparqlRequest(mappingQuery2Get))\nsink.expectNext(receiveTimeout) match {\n  case SparqlResponse(_, true, results, None) =>\n    val persons: Seq[Person] = results //the  mapped collection is returned\n    assert(persons.contains(...)\n  case r@_ =>\n    fail(r)\n}\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "citation": [
    {
      "confidence": [
        0.8283216015784888
      ],
      "excerpt": "asq -e http://dbpedia.org/sparql -p dbpedia.prefixes -q dbpedia-musicians.sparql \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.9709901549696905,
        0.8356013927728488
      ],
      "excerpt": "     ?person dbo:birthPlace :Berlin . \n     ?person &lt;http://purl.org/dc/terms/subject&gt; &lt;http://dbpedia.org/resource/Category:German_musicians&gt; . \n     ?person dbo:birthDate ?birth . \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "     ?person rdfs:comment ?description . \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8302556419090275
      ],
      "excerpt": "asq -r http://www.w3.org/2009/08/skos-reference/skos.rdf -p skos.prefixes \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8302556419090275
      ],
      "excerpt": "asq -r http://www.w3.org/2009/08/skos-reference/skos.rdf -p skos.prefixes \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8283216015784888
      ],
      "excerpt": "asq -e http://dbpedia.org/sparql -p dbpedia.prefixes \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8283216015784888
      ],
      "excerpt": "asq -e http://dbpedia.org/sparql -p dbpedia.prefixes \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/gklyne/asqc",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2012-04-07T17:42:39Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-16T21:05:33Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9295884919063955
      ],
      "excerpt": "This example comes from the DBpedia front page.  It returns a list of musicians born in Berlin, by sending a SPARQL query to the DBpedia SPARQL endpoint. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8989769359878046
      ],
      "excerpt": "And dbpedia.prefixes contains: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8492987158470069
      ],
      "excerpt": "This example retrieves the SKOS ontology RDF file and runs the SPARQL query locally.  It returns a list of classes defined by the ontology. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8623247905793969
      ],
      "excerpt": "A similar query using CONSTRUCT returns the information as an RDF graph: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9102514539236529
      ],
      "excerpt": "This example uses DBpedia and BBC Backstage SPARQL endpoints to create a list of actors from Japan who appear in BBC television programmes: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955093629934305,
        0.9291899078216905
      ],
      "excerpt": "The query to the BBC backstage endpoint can take a little time to complete (about 30 seconds) \nThese queries work in part because BBC backstage makes extensive use of the DBpedia ontologies \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9701417247258051
      ],
      "excerpt": "Joining queries in this way when sending queries to different endpoints is not scalable in the current implementation of ASQ: all available results are retrieved from both services, then joined in the ASQ client.  (I am thinking about possible ways to use the results from one query to limit what comes from the next.  When querying RDF resources, results from one query are used directly to constrain the results of the next query.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A SPARQL query client (pronounced \"ask\")",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Right now, this is pretty much it.  For a usage summary:\n\n    asq --help\n\nSee also the examples described below.\n\nCurrently, RDF data is supported as RDF/XML only, and SPARQL SELECT query results as JSON.  Support for other formats is on the TODO list.\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/gklyne/asqc/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 20 Dec 2021 12:54:04 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/gklyne/asqc/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "gklyne/asqc",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/gklyne/asqc/master/src/asqc/examples/restapi.sh",
      "https://raw.githubusercontent.com/gklyne/asqc/master/src/asqc/examples/rdfaprovo.sh",
      "https://raw.githubusercontent.com/gklyne/asqc/master/src/asqc/examples/rdfatest.sh",
      "https://raw.githubusercontent.com/gklyne/asqc/master/samples/runquery.sh",
      "https://raw.githubusercontent.com/gklyne/asqc/master/samples/runasq.sh",
      "https://raw.githubusercontent.com/gklyne/asqc/master/samples/showtypes.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    sudo pip install asqc\n\nIf older versions of rdflib and/or other utilities are installed, it may be necessary to force an upgrade, thus:\n\n    sudo pip install --upgrade asqc\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "This option assumes that the virtualenv package (http://pypi.python.org/pypi/virtualenv) has been installed.\n\nSelect working directory, then:\n\n    virtualenv testenv\n    source testenv/bin/activate\n    pip install asqc\n\nWhen finished, from the same directory:\n\n    deactivate\n    rm -rf testenv\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Assumes Python 2.7 installed; not yet tested with other versions.\n\nInstallation is from Python Package Index (PyPI).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8091908364719688
      ],
      "excerpt": "     ?person foaf:name ?name . \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8413883804447041
      ],
      "excerpt": "or, equivalently, piping bindings from one asq command straight to the next: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8176387605018226
      ],
      "excerpt": "0.1.2: Add examples and extended README \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8103748597696443
      ],
      "excerpt": "0.1.4: Add support for CSV output format for query result bindings \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/gklyne/asqc/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Installation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "asqc",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "gklyne",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/gklyne/asqc/blob/master/README.markdown",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 11,
      "date": "Mon, 20 Dec 2021 12:54:04 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This information is displayed by \"asq --help\":\n\n    Usage: \n      asq [options] [query]\n      asq --help      for an options summary\n      asq --examples  to display the path containing example queries\n\n    A sparql query client, designed to be used as a filter in a command pipeline.\n    Pipelined data can be RDF or query variable binding sets, depending on the\n    options used.\n\n    Options:\n      --version             show program's version number and exit\n      -h, --help            show this help message and exit\n      --examples            display path of examples directory and exit\n      -b BINDINGS, --bindings=BINDINGS\n                            URI or filename of resource containing incoming query\n                            variable bindings (default none). Specify '-' to use\n                            stdin. This option works for SELECT queries only when\n                            accessing a SPARQL endpoint.\n      -e ENDPOINT, --endpoint=ENDPOINT\n                            URI of SPARQL endpoint to query.\n      -f FORMAT, --format=FORMAT\n                            Format for input and/or output:\n                            RDFXML/N3/NT/TURTLE/JSONLD/RDFA/JSON/CSV/template.\n                            XML, N3, NT, TURTLE, JSONLD, RDFA apply to RDF data,\n                            others apply to query variable bindings.  Multiple\n                            comma-separated values may be specified; they are\n                            applied to RDF or variable bindings as appropriate.\n                            'template' is a python formatting template with\n                            '%(var)s' for query variable 'var'.  If two values are\n                            given for RDF or variable binding data, they are\n                            applied to input and output respectively.  Thus:\n                            RDFXML,JSON = RDF/XML and JSON result bindings;\n                            RDFXML,N3 = RDF/XML input and Turtle output; etc.\n      -o OUTPUT, --output=OUTPUT\n                            URI or filename of RDF resource for output (default\n                            stdout).Specify '-'to use stdout.\n      -p PREFIX, --prefix=PREFIX\n                            URI or filename of resource containing query prefixes\n                            (default ~/.asqc-prefixes)\n      -q QUERY, --query=QUERY\n                            URI or filename of resource containing query to\n                            execute. If not present, query must be supplied as\n                            command line argument.\n      -r RDF_DATA, --rdf-input=RDF_DATA\n                            URI or filename of RDF resource to query (default\n                            stdin or none). May be repeated to merge multiple\n                            input resources. Specify '-' to use stdin.\n      -v, --verbose         display verbose output\n      --query-type=QUERY_TYPE\n                            Type of query output: SELECT (variable bindings,\n                            CONSTRUCT (RDF) or ASK (status).  May be used when\n                            system cannot tell the kind of result by analyzing the\n                            query itself.  (Currently not used)\n      --format-rdf-in=FORMAT_RDF_IN\n                            Format for RDF input data:\n                            RDFXML/N3/NT/TURTLE/JSONLD/RDFA.\n      --format-rdf-out=FORMAT_RDF_OUT\n                            Format for RDF output data:\n                            RDFXML/N3/NT/TURTLE/JSONLD.\n      --format-var-in=FORMAT_VAR_IN\n                            Format for query variable binding input data:\n                            JSON/CSV.\n      --format-var-out=FORMAT_VAR_OUT\n                            Format for query variable binding output data:\n                            JSON/CSV/template.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "The directory \"examples\" contains some sample files containing queries and prefix declarations that can be used with the following commands.\n\nTo obtain the full path name of the examples directory, enter:\n\n    asq --examples\n\nCommands below for running the examples assume this is the current working directory.\n\n",
      "technique": "Header extraction"
    }
  ]
}
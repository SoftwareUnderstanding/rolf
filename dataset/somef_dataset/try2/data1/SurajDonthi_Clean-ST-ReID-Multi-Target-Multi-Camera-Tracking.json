{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1812.03282v1"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9987110022326064
      ],
      "excerpt": "  <i>Source: <a href=\"https://arxiv.org/pdf/1812.03282.pdf\">Spatial-Temporal Reidentification(ST-ReID)</a></i> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "    if args.re_rank: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "        Rank-10: {cmc[9]} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "if __name__ == \"__main__\": \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SurajDonthi/Multi-Camera-Person-Re-Identification",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-28T16:35:29Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-24T10:21:53Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9933390564263515,
        0.8951425268764156
      ],
      "excerpt": "This repository is inspired by the paper Spatial-Temporal Reidentification (ST-ReID)[1]. The state-of-the-art for Person Re-identification tasks. This repository offers a flexible, and easy to understand clean implementation of the model architecture, training and evaluation. \nThis repository has been trained & tested on DukeMTMTC-reID and Market-1501 datasets. The model can be easily trained on any new datasets with a few tweaks to parse the files! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8695086154819376
      ],
      "excerpt": "Below are the metrics on the various datasets. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.805090997142582
      ],
      "excerpt": "A pre-trained ResNet-50 backbone model with layers up until Adaptive Average Pooling(excluded) is used \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8052472441398495
      ],
      "excerpt": "The total loss of the 6 part predictions are calculated for backpropagation & weights update. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9618542262427483,
        0.887811457899213,
        0.8721069126581674
      ],
      "excerpt": "The feature vector of the query image is compared against all the feature vectors of the gallery images using a simple dot product & normalization. \nThe Spatio-Temporal distribution is used to calculate their spatio-temporal scores. \nThe joint score is then calculated from the feature score and the spatio-temporal scores. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "def generate_features(model, dataloader): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8620007613560474
      ],
      "excerpt": "    for batch in dataloader: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8428341063308927,
        0.8428341063308927
      ],
      "excerpt": "        features = model(x).detach().cpu() \n        features += model(fliplr(x, x.device)).detach.cpu() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.860059181823877,
        0.860059181823877
      ],
      "excerpt": "    model = PCB(num_classes=len(query_data.num_classes)) \n    model.load_state_dict(args.model_path) \n    model.eval() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "        model, query_dataloader) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "        model, gal_dataloader) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.974066599291244
      ],
      "excerpt": "Step 3: Compute the L2-Normed features that is generated from the model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8647747617927086
      ],
      "excerpt": "Step 5: Optionally perform Re-ranking of the Generated scores. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8890932537402708
      ],
      "excerpt": "[1] - Spatial-Temporal Reidentification(ST-ReID) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "State-of-the-art model for person re-identification in Multi-camera Multi-Target Tracking. Benchmarked on Market-1501 and DukeMTMTC-reID datasets.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SurajDonthi/Clean-ST-ReID-Multi-Target-Multi-Camera-Tracking/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 18,
      "date": "Mon, 27 Dec 2021 05:53:50 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/SurajDonthi/Multi-Camera-Person-Re-Identification/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "SurajDonthi/Multi-Camera-Person-Re-Identification",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/SurajDonthi/Clean-ST-ReID-Multi-Target-Multi-Camera-Tracking/master/demo.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8178166673430896,
        0.8719137500017187
      ],
      "excerpt": "Run the below command in the shell. \npython -m mtmct_reid.train --data_dir path/to/dataset/ --dataset 'market' \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8568873885248139
      ],
      "excerpt": "python -m mtmct_reid.train --data_dir path/to/dataset/ --dataset 'market' \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8491293197572523
      ],
      "excerpt": "Log files are created to track the training in a new folder logs. To monitor the training, run the below command in the shell \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8795052428762461
      ],
      "excerpt": "python -m mtmct_reid.eval model_path 'path/to/model' --dataset 'market' \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8523950660409677
      ],
      "excerpt": "    --batch_size 64 --num_workers 4 --re_rank True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516,
        0.9133368656218674
      ],
      "excerpt": "from argparse import Namespace \nimport joblib \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8878193409743138
      ],
      "excerpt": "from torch.utils.data import DataLoader \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9079185768576028
      ],
      "excerpt": "from mtmct_reid.data import ReIDDataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8934477375241742,
        0.8801854956928516,
        0.9416522774131079
      ],
      "excerpt": "from mtmct_reid.model import PCB \nfrom mtmct_reid.re_ranking import re_ranking \nfrom mtmct_reid.utils import fliplr, l2_norm_standardize \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984,
        0.8594142235991984
      ],
      "excerpt": "                                  shuffle=True, num_workers=args.num_workers, \n                                  pin_memory=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984,
        0.8594142235991984
      ],
      "excerpt": "                                shuffle=True, num_workers=args.num_workers, \n                                pin_memory=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.849817844003718,
        0.8278038455928625
      ],
      "excerpt": "    model = PCB(num_classes=len(query_data.num_classes)) \n    model.load_state_dict(args.model_path) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8977022716895233
      ],
      "excerpt": "    x-------------x TEST RESULT x-------------x \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936606094659785
      ],
      "excerpt": "    print(print_result) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.815691881966494
      ],
      "excerpt": "        model_path='path/to/model', \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "        re_rank=True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8142835995138061
      ],
      "excerpt": "    main(args) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/SurajDonthi/Multi-Camera-Person-Re-Identification/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Suraj Donthi\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Multi-Camera Person Re-Identification",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Multi-Camera-Person-Re-Identification",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "SurajDonthi",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SurajDonthi/Multi-Camera-Person-Re-Identification/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 77,
      "date": "Mon, 27 Dec 2021 05:53:50 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "computer-vision",
      "person-reidentification",
      "pytorch",
      "pytorch-lightning",
      "spatial-temporal",
      "convolutional-neural-networks",
      "multi-camera-tracking",
      "mtmct",
      "dukemtmc-reid",
      "market-1501"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Run the below commands in the shell.\r\n\r\n1. Clone this repo, cd into it & install setup.py: \r\n```sh\r\ngit clone https://github.com/SurajDonthi/MTMCT-Person-Re-Identification\r\n\r\ncd MTMCT-Person-Re-Identification\r\n\r\npip install -r requirements.txt\r\n```\r\n2. Download the datasets. (By default you can download & unzip them to `data/raw/` directory)\r\n\r\nYou can get started by training this model. Trained models will be available soon!\r\n\r\n*Dependencies*\r\n\r\nThis project requires `pytorch>=1.5.0`, `torchvision>=0.6.0`, `pytorch-lightning=1.1.1`, `tensorboard`, `joblib` and other common packages like `numpy`, `matplotlib` and `csv`.\r\n\r\nNOTE: This project uses [pytorch-lightning](https://pytorch-lightning.readthedocs.io/en/latest/introduction_guide.html) which is a high-level interface to abstract away repeating Pytorch code. It helps achieve clean, & easy to maintain code with hardly any learning curve!\r\n\r\n",
      "technique": "Header extraction"
    }
  ]
}
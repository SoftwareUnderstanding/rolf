{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1509.06461\n - Deep Reinforcement Learning with Double Q-learning [4]: https://arxiv.org/abs/1509.06461",
      "https://arxiv.org/abs/1509.06461"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Codernauti/Exploration-of-DQN-in-CartPole-Environment",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-08-03T12:49:30Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-29T15:48:15Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9971331593200533,
        0.9947512603434522
      ],
      "excerpt": "In this work we present an overview of a Deep Reinforcement Learning method using Q-learning that recently brought the state-of-the-art results in the Atari Emulator Environment. This method is called DQN algorithm that combines successfully a convolutional neural network with Q-learning. Successively it was improved with Double Q-learning and other valid techniques.  \nAttracted by this hot research area we replicated the DQN algorithm and run it in the CartPole environment, a famous toy control challenge that allowed us to deal with the main issues related to the implementation of DQN. In this paper we reported the results that we obtained, our consideration on them and some personal thoughts about the Deep Reinforcement Learning field. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9338858059499952
      ],
      "excerpt": "See the following repository: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Overview of a Deep Reinforcement Learning method using Q-learning that recently brought the state-of-the-art results in the Atari Emulator Environment",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Codernauti/Exploration-of-DQN-in-CartPole-Environment/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 22 Dec 2021 18:13:56 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Codernauti/Exploration-of-DQN-in-CartPole-Environment/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Codernauti/Exploration-of-DQN-in-CartPole-Environment",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Codernauti/Exploration-of-DQN-in-CartPole-Environment/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "TeX",
      "Batchfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Exploration and Evaluation of Deep Reinforcement Learning in the CartPole environment",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Exploration-of-DQN-in-CartPole-Environment",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Codernauti",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Codernauti/Exploration-of-DQN-in-CartPole-Environment/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "EduBic",
        "body": "# Abstract\r\nIn this work, we present an overview of a Deep Reinforcement\r\nLearning method using Q-learning that recently brought\r\nthe state-of-the-art results in the Atari Emulator Environment.\r\nThis method is called DQN algorithm that combines successfully\r\na convolutional neural network with Q-learning. Successively\r\nit was improved with Double Q-learning and other\r\nvalid techniques. Attracted by this hot research area we implemented\r\nthe DQN algorithm and run it in the CartPole environment,\r\na famous toy control challenge that allowed us to\r\ndeal with the main issues related to the implementation of\r\nDQN. In this paper, we reported the results that we obtained,\r\nour consideration of them and some personal thoughts about\r\nthe Deep Reinforcement Learning field.",
        "dateCreated": "2018-08-03T12:56:36Z",
        "datePublished": "2018-08-03T12:57:54Z",
        "html_url": "https://github.com/Codernauti/Exploration-of-DQN-in-CartPole-Environment/releases/tag/v1.0",
        "name": "Release",
        "tag_name": "v1.0",
        "tarball_url": "https://api.github.com/repos/Codernauti/Exploration-of-DQN-in-CartPole-Environment/tarball/v1.0",
        "url": "https://api.github.com/repos/Codernauti/Exploration-of-DQN-in-CartPole-Environment/releases/12242716",
        "zipball_url": "https://api.github.com/repos/Codernauti/Exploration-of-DQN-in-CartPole-Environment/zipball/v1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 22 Dec 2021 18:13:56 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "https://github.com/Codernauti/Exploration-of-DQN-in-CartPole-Environment/releases/download/v1.0/ExplorationAndEvaluationDRL_CartPole.environment.pdf\n\n",
      "technique": "Header extraction"
    }
  ]
}
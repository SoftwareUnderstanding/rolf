{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2103.10504",
      "https://arxiv.org/abs/2103.10504"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/davidiommi/Pytorch--3D-Medical-Images-Segmentation--SALMON",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-18T16:13:21Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T09:17:18Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9213925330322946,
        0.9733298655257786
      ],
      "excerpt": "SALMON is a computational toolbox for segmentation using neural networks (3D patches-based segmentation) \nSALMON is based on MONAI 0.7.0 : PyTorch-based, open-source frameworks for deep learning in healthcare imaging.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.808890916644561
      ],
      "excerpt": "This is my \"open-box\" version if I want to modify the parameters for some particular task, while the two above are hard-coded. The monai 0.5.0 folder contains the previous versions based on the old monai version. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8455522773026865
      ],
      "excerpt": "Labels are resampled and resized to the corresponding image, to avoid array size conflicts. You can set here a new image resolution for the dataset.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8284344003573364,
        0.907872878476191
      ],
      "excerpt": "check_loader_patches: Shows example of patches fed to the network during the training.   \nnetworks.py: The architectures available for segmentation are nn-Unet and UneTR (based on Visual transformers) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9173980099811081
      ],
      "excerpt": "predict_single_image.py: It launches the inference on a single input image chosen by the user. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.827787750932383
      ],
      "excerpt": "Modify the input parameters to select the two folders: images and labels folders with the dataset. Set the resolution of the images here before training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.828503850347204
      ],
      "excerpt": "Modify the \"init.py\" to set the parameters and start the training/testing on the data. Read the descriptions for each parameter. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8316736244156677
      ],
      "excerpt": "Check and modify the train_transforms applied to the images  in \"train.py\" for your specific case. (e.g. In the last update there is a HU windowing for CT images) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8596163359323032,
        0.9124043672424587
      ],
      "excerpt": "You can test the model on a new image, with different size and resolution from the training. The script will resample it before the inference and give you a mask \nwith same size and resolution of the source image. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9435571266767347,
        0.8440774071810232,
        0.9822791120445161
      ],
      "excerpt": "The \"networks.py\" calls the nn-Unet, which adapts itself to the input data (resolution and patches size). The script also saves the graph of you network, so you can visualize it.  \n\"networks.py\" includes also UneTR (based on Visual transformers). This is experimental. For more info check (https://arxiv.org/abs/2103.10504) and https://github.com/Project-MONAI/tutorials/blob/master/3d_segmentation/unetr_btcv_segmentation_3d.ipynb \nIs it possible to add other networks, but for segmentation the U-net architecture is the state of the art. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9905939657358988
      ],
      "excerpt": "Feature_size and pos_embed are the parameters that need to changed to adopt it for your application of interest. Other parameters that are mentioned come from Vision Transformer (ViT) default hyper-parameters (original architecture). In addition, the new revision of UNETR paper with more descriptions is now publicly available. Please check for more details: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Segmentation deep learning ALgorithm based on MONai toolbox: single and multi-label segmentation software developed by QIMP team-Vienna.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/davidiommi/Pytorch--3D-Medical-Images-Segmentation--SALMON/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Sat, 25 Dec 2021 00:46:27 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/davidiommi/Pytorch--3D-Medical-Images-Segmentation--SALMON/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "davidiommi/Pytorch--3D-Medical-Images-Segmentation--SALMON",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8727531553733484
      ],
      "excerpt": "organize_folder_structure.py: Organize the data in the folder structure (training,validation,testing) for the network.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9240494738802001
      ],
      "excerpt": "train.py: Runs the training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8330066068566971
      ],
      "excerpt": "Use first \"organize_folder_structure.py\" to create organize the data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "|   |   \u251c\u2500\u2500 train              \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633989807152664
      ],
      "excerpt": "|   |   \u2514\u2500\u2500 test              \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "|   |   \u251c\u2500\u2500 train              \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633989807152664
      ],
      "excerpt": "|   |   \u2514\u2500\u2500 test              \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8232209192049039,
        0.9060076926518256
      ],
      "excerpt": "Modify the \"init.py\" to set the parameters and start the training/testing on the data. Read the descriptions for each parameter. \nAfterwards launch the \"train.py\" for training. Tensorboard is available to monitor the training (\"runs\" folder created)    \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8067984542340384
      ],
      "excerpt": "Sample images: the following images show the segmentation of carotid artery from MRI sequence \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8164651944050013
      ],
      "excerpt": "Launch \"predict_single_image.py\" to test the network. Modify the parameters in the parse section to select the path of the weights, images to infer and result.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.818742249217233
      ],
      "excerpt": "Use and modify \"check_loader_patches.py\" to check the patches fed during training.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8151909984183066
      ],
      "excerpt": "python predict_single_image.py --image './Data_folder/image.nii' --label './Data_folder/label.nii' --result './Data_folder/prova.nii' --weights './best_metric_model.pth' \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/davidiommi/Pytorch--3D-Medical-Images-Segmentation--SALMON/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 David Iommi\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SALMON v.2: Segmentation deep learning ALgorithm based on MONai toolbox",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Pytorch--3D-Medical-Images-Segmentation--SALMON",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "davidiommi",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/davidiommi/Pytorch--3D-Medical-Images-Segmentation--SALMON/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Follow the steps in \"installation_commands.txt\". Installation via Anaconda and creation of a virtual env to download the python libraries and pytorch/cuda.\n*******************************************************************************\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 32,
      "date": "Sat, 25 Dec 2021 00:46:27 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "segmentation",
      "monai",
      "organs",
      "pytorch",
      "unet-pytorch",
      "unet",
      "unet-3d",
      "deep-learning",
      "monai-toolbox",
      "nnunet",
      "transformers",
      "unetr",
      "mri"
    ],
    "technique": "GitHub API"
  }
}
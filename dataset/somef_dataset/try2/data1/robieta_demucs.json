{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1809.07454",
      "https://arxiv.org/abs/1805.02410\n[demucs_arxiv]: https://hal.archives-ouvertes.fr/hal-02379796/document\n[musevalpth]: museval_torch.py\n[tasnet]: https://github.com/kaituoxu/Conv-TasNet\n[audio]: https://ai.honu.io/papers/demucs/index.html\n[spleeter]: https://github.com/deezer/spleeter\n[soundcloud]: https://soundcloud.com/voyageri/sets/source-separation-in-the-waveform-domain",
      "https://arxiv.org/abs/1911.13254"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@article{defossez2019music,\n  title={Music Source Separation in the Waveform Domain},\n  author={D{\\'e}fossez, Alexandre and Usunier, Nicolas and Bottou, L{\\'e}on and Bach, Francis},\n  journal={arXiv preprint arXiv:1911.13254},\n  year={2019}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{defossez2019music,\n  title={Music Source Separation in the Waveform Domain},\n  author={D{\\'e}fossez, Alexandre and Usunier, Nicolas and Bottou, L{\\'e}on and Bach, Francis},\n  journal={arXiv preprint arXiv:1911.13254},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8669112007448144
      ],
      "excerpt": "| [Wave-U-Net][waveunet]      | waveform | no | 3.2 | - | - | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8730726134075774
      ],
      "excerpt": "git clone https://github.com/facebookresearch/demucs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8730726134075774
      ],
      "excerpt": "git clone https://github.com/facebookresearch/demucs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": "python3 -m demucs.separate --dl -n demucs --shifts=10 PATH_TO_AUDIO_FILE_1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": "python3 -m demucs.raw [--workers=10] MUSDB_PATH RAW_PATH \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/robieta/demucs/master/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/robieta/demucs",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to Demucs\nPull Requests\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\nComplete your CLA here: https://code.facebook.com/cla\nDemucs is the implementation of a research paper.\nTherefore, we do not plan on accepting many pull requests for new features.\nWe certainly welcome them for bug fixes.\nIssues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\nLicense\nBy contributing to this repository, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-01T16:53:03Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-22T14:49:34Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9240181237500038,
        0.963227534174418,
        0.9415156139244913
      ],
      "excerpt": "We provide an implementation of Demucs and Conv-Tasnet for music source separation on the [MusDB][musdb] dataset. \nThey can separate drums, bass and vocals from the rest with state-of-the-art results, surpassing previous waveform or spectrogram based methods. \nThe architecture and results obtained are detailed in our paper \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8854933352232826,
        0.920976573734184,
        0.8174357057331715
      ],
      "excerpt": "Demucs is based on U-Net convolutional architecture inspired by [Wave-U-Net][waveunet] and \n[SING][sing], with GLUs, a BiLSTM between the encoder and decoder, specific initialization of weights \nand transposed convolutions in the decoder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.956252302997704,
        0.9258816826188394,
        0.8210370209506845,
        0.8321281966441197
      ],
      "excerpt": "is a separation model developed for speech which predicts a mask on a learnt over-complete linear representation \nusing a purely convolutional model with stride of 1 and dilated convolutional blocks. \nWe reused the code from the [kaituoxu/Conv-TasNet][tasnet] \nrepository and added support for multiple audio channels. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9344912254560033,
        0.9936005380241657
      ],
      "excerpt": "(MOS is 3.2 for Demucs, 2.9 for Conv-Tasnet). When trained with extra training data, \nDemucs and Conv-Tasnet obtain the same SDR. See [our paper][demucs_arxiv] Section 6 for more details or listen to our \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8015307257197332,
        0.8722582867453494
      ],
      "excerpt": "<img src=\"./demucs.png\" alt=\"Schema representing the structure of Demucs, \n    with a convolutional encoder, a BiLSTM, and a decoder based on transposed convolutions.\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8921675267351739,
        0.9489988163698513,
        0.8673946498746944
      ],
      "excerpt": "13/04/2020: Demucs released under MIT: We are happy to release Demucs under the MIT licence. \n    We hope that this will broaden the impact of this research to new applications. \n13/04/2020: New quantized models: New quantized 8 bit models, 4 times smaller and with \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925222020977216
      ],
      "excerpt": "with it. I have replaced all the pre-trained models using a more future proof serialization. It means \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9684915575131307,
        0.8232470379096757,
        0.844047506603911
      ],
      "excerpt": "Sorry for the inconveniance. \n31/01/2020: New light models: I have added a lighter version of Demucs, trained with the option --channels=64. \nThe overall SDR is a bit worse, but to the hear it sounds quite similar. The files are smaller to download (1GB), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9026943365093374
      ],
      "excerpt": "for the version trained on more data) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9932017951251412
      ],
      "excerpt": "An audio comparison of Demucs and Conv-Tasnet with other state-of-the-art methods such as [Wave-U-Net][waveunet], [OpenUnmix][openunmix] or \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9660652748308249
      ],
      "excerpt": "We provide hereafter a summary of the different metrics presented in the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.975340722488139,
        0.989810717816229,
        0.9807233190154289,
        0.991105879358287,
        0.9589040312974123
      ],
      "excerpt": "songs on our [soundcloud playlist][soundcloud]. \nOverall SDR is the mean of the SDR for each of the 4 sources, MOS Quality is a rating from 1 to 5 \nof the naturalness and absence of artifacts given by human listeners (5 = no artifacts), MOS Contamination \nis a rating from 1 to 5 with 5 being zero contamination by other sources. We refer the reader to our [paper][demucs_arxiv], Section 5 and 6, \nfor more details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9569087680399256
      ],
      "excerpt": "Parts of the code are untested on Windows (in particular, training a new model). If you don't have much experience with Anaconda, python or the shell, here are more detailed instructions. Note that Demucs is not supported on 32bits systems (as Pytorch is not available there). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9499060905829868
      ],
      "excerpt": "In order to try Demucs or Conv-Tasnet on your tracks, simply run from the root of this repository \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "python3 -m demucs.separate --dl -n demucs PATH_TO_AUDIO_FILE_1 [PATH_TO_AUDIO_FILE_2 ...] #: for Demucs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "python3 -m demucs.separate --dl -n tasnet PATH_TO_AUDIO_FILE_1 ... #: for Conv-Tasnet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490037945672047
      ],
      "excerpt": "The --dl \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8809112856706779
      ],
      "excerpt": "The model is 4 times smaller but quality might be a bit worse, especially for the other \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8645808039326406,
        0.8565312780933517,
        0.9876629584297069,
        0.952817495988505
      ],
      "excerpt": "The --shifts=SHIFTS performs multiple predictions with random shifts (a.k.a randomized \nequivariant stabilization) of the input and average them. This makes prediction SHIFTS times \nslower but improves the accuracy of Demucs by 0.2 points of SDR. \nIt has limited impact on Conv-Tasnet as the model is by nature almost time equivariant. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8871240955626613,
        0.8948712009898366
      ],
      "excerpt": "It is deactivated by default. \nThe metrics for our experiments are stored in the results folder. In particular \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9355818971880967
      ],
      "excerpt": "The std column shows the standard deviation divided by the square root of the number of runs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8470715847433267
      ],
      "excerpt": "It can be obtained on the [MusDB website][musdb]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.876789139919709,
        0.8992083209499359
      ],
      "excerpt": "The -b 4 flag will set the batch size to 4. The default is 4 and will crash on a single GPU. \nDemucs was trained on 8 V100 with 32GB of RAM. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9486055294460756
      ],
      "excerpt": "such a run, it is possible some of the children processes are not killed properly, be mindful of that. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9611117431454613
      ],
      "excerpt": "The optimizer state, the latest model and the best model on valid are stored. At the end of each \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9070536811702206
      ],
      "excerpt": "used. Refer to parser.py for more details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8816362917000663
      ],
      "excerpt": "a factor of 2 the number of iterations per second. It is possible to extract all data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9868503627173922
      ],
      "excerpt": "To reproduce the performance of the main Demucs model in our paper: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "python3 -m demucs.data MUSDB_PATH RAW_PATH \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.978027802044922
      ],
      "excerpt": ": Repeat for --seed = 43, 44, 45 and 46 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code for the paper Music Source Separation in the Waveform Domain",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/robieta/demucs/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 23 Dec 2021 01:06:44 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/robieta/demucs/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "robieta/demucs",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/robieta/demucs/master/run.sh",
      "https://raw.githubusercontent.com/robieta/demucs/master/run_overall.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Test set evaluations computed with [museval][museval] will be stored under\n`evals/EXPERIMENT NAME/results`. The experiment name\nis the first thing printed when running `python3 run.py`  or `python3 -m demucs`. If you used\nthe flag `--save`, there will also be a folder `evals/EXPERIMENT NAME/wavs` containing\nall the extracted waveforms.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9489101642369127
      ],
      "excerpt": "that you will get an error if you update the repo saying that the previously downloaded checkpoints \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8825946225273126
      ],
      "excerpt": "and it should run about 4x faster. I know quite a few people wanted to use Demucs on GPU, I hope this version \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9873055602179577,
        0.9770335174395833,
        0.9552373142125511,
        0.9415370872620579
      ],
      "excerpt": "conda env update -f environment-cuda.yml \nconda activate demucs \nThis will create a demucs environment with all the dependencies installed. \nIf you are using Windows, replace python3 by python.exe in all the commands provided hereafter :) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9681760990964189
      ],
      "excerpt": "First install Anaconda with Python 3.7, which you can find here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466,
        0.9995467759691481,
        0.9745978183701172,
        0.9906248903846466,
        0.9810993324890401,
        0.9770335174395833,
        0.8258575567217673,
        0.8734255054105501
      ],
      "excerpt": "cd %HOMEPATH% \nconda install git \ngit clone https://github.com/facebookresearch/demucs \ncd demucs \nconda env update -f environment-cpu.yml \nconda activate demucs \npython.exe -m demucs.separate -d cpu --dl \"PATH_TO_AUDIO_FILE_1\" [\"PATH_TO_AUDIO_FILE_2\" ...] \nThe \" around the filename are required if the path contains spaces. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466,
        0.9906248903846466,
        0.9770335174395833,
        0.8258575567217673
      ],
      "excerpt": "cd %HOMEPATH% \ncd demucs \nconda activate demucs \npython.exe -m demucs.separate -d cpu --dl \"PATH_TO_AUDIO_FILE_1\" ... \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740495727626812
      ],
      "excerpt": "conda install -c defaults intel-openmp -f. Then try again to run the demucs.separate command. If it still doesn't work, you can try to run first set CONDA_DLL_SEARCH_MODIFICATION_ENABLE=1, then again the demucs.separate command and hopefully it will work \ud83d\ude4f. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9827871580343895,
        0.8914743953509107
      ],
      "excerpt": "If you do not already have Anaconda installed or much experience with the terminal on Mac OS X here are some detailed instructions: \nDownload Anaconda 3.7 64 bits for MacOS: https://www.anaconda.com/distribution/#download-section \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466,
        0.9995467759691481,
        0.9745978183701172,
        0.9906248903846466,
        0.9810993324890401,
        0.9770335174395833
      ],
      "excerpt": "cd ~ \nconda install git \ngit clone https://github.com/facebookresearch/demucs \ncd demucs \nconda env update -f environment-cpu.yml \nconda activate demucs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466,
        0.9770335174395833
      ],
      "excerpt": "cd ~/demucs \nconda activate demucs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8557703983382536
      ],
      "excerpt": ": Demucs with randomized equivariant stabilization (10x slower, suitable for GPU, 0.2 extra SDR) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9300572779181543
      ],
      "excerpt": "If you have a GPU, but you run out of memory, please add -d cpu to the command line. See the section hereafter for more details on the memory requirements for GPU acceleration. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9946314156838832,
        0.9610436994027313
      ],
      "excerpt": "If you want to export as MP3 (at 320 kb/s), first install lameenc (on Windows python.exe -m pip install -U lameenc,  \non Linux/OSX python3 -m pip install -U lameenc, and use the --mp3 flag. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8273459348339982,
        0.8619463644839362
      ],
      "excerpt": "It can be obtained on the [MusDB website][musdb]. \nTo start training on a single GPU or CPU, use: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8634458923329178
      ],
      "excerpt": "You can then train using the --raw RAW_PATH flag, for instance: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9226057173927578,
        0.8769984756123511
      ],
      "excerpt": "you can also try adapting it to run on your own. \nIf you do not want to always specify the path to MUSDB, you can export the following variables: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8833921682668171
      ],
      "excerpt": "<img src=\"./demucs.png\" alt=\"Schema representing the structure of Demucs, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8963005418717753,
        0.8058273402992138
      ],
      "excerpt": "flag will automatically download a pretrained model into ./models. There will be one folder \nper audio file, reusing the name of the track without the extension. Each folder will contain four stereo wav files sampled at 44.1 kHz: drums.wav, bass.wav, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8203045373958288
      ],
      "excerpt": "the first one will be used. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.837420610946311
      ],
      "excerpt": "museval json evaluations are stored in results/evals/EXPERIMENT NAME/results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8535725553709174
      ],
      "excerpt": "python3 result_table.py -p #: show SDR on test set, aggregated with multiple random seeds \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9364541555520881,
        0.854836075929819
      ],
      "excerpt": "python3 run.py --musdb MUSDB_PATH [EXTRA_FLAGS] \nThis will launch one process per GPU and report the output of the first one. When interrupting \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8626729730022313
      ],
      "excerpt": "Demucs will automatically generate an experiment name from the command line flags you provided. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8315411685667546
      ],
      "excerpt": "command first: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.898614942634294
      ],
      "excerpt": "python3 run.py --raw RAW_PATH --musdb MUSDB_PATH \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9065911510153849,
        0.8963430147497204
      ],
      "excerpt": "python3 run.py --seed 42 #: for Demucs \npython3 run.py --seed 42 --tasnet --X=10 --samples=80000 --epochs=180 --split_valid #: for Conv-Tasnet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8559967282660699,
        0.9521174821235511
      ],
      "excerpt": "python3 valid_table.py #: compare validation losses \npython3 result_table.py #: compare test SDR \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/robieta/demucs/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) Facebook, Inc. and its affiliates.\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Music Source Separation in the Waveform Domain",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "demucs",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "robieta",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/robieta/demucs/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you have anaconda installed, you can run from the root of this repository:\n\n    conda env update -f environment-cpu.yml ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "If you want to use GPU acceleration, you will need at least 8GB of RAM on your GPU for `demucs` and 4GB for `tasnet`. Sorry, the code for demucs is not super optimized for memory! If you do not have enough memory on your GPU, simply add `-d cpu` to the command line to use the CPU. With Demucs, processing time should be roughly equal to the duration of the track.\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you have a cluster available with Slurm, you can set the `run_slurm.py` as the target of a\nslurm job, using as many nodes as you want and a single task per node. `run_slurm.py` will\ncreate one process per GPU and run in a distributed manner. Multinode training is supported.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 23 Dec 2021 01:06:44 GMT"
    },
    "technique": "GitHub API"
  }
}
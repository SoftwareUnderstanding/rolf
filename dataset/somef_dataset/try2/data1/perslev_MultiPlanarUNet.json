{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1911.01764](https://arxiv.org/abs/1911.01764",
      "https://arxiv.org/abs/1911.01764",
      "https://arxiv.org/abs/2004.14003](https://arxiv.org/abs/2004.14003",
      "https://arxiv.org/abs/2004.14003",
      "https://arxiv.org/abs/1505.04597"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8723247378705271,
        0.9222383658450612,
        0.9922199467185766,
        0.9999520143362441
      ],
      "excerpt": "Segmentation. In: Medical Image Computing and Computer Assisted Intervention  \n(MICCAI), 2019 \nPre-print version: https://arxiv.org/abs/1911.01764 \nPublished version: https://doi.org/10.1007/978-3-030-32245-8_4# \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.926292766734398
      ],
      "excerpt": "The base model is a slightly modified 2D U-Net (https://arxiv.org/abs/1505.04597)  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9449187648369126
      ],
      "excerpt": "Multi-Planar Animation \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/perslev/MultiPlanarUNet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-01-10T10:17:27Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-16T14:13:32Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "A summary of the performance can be produced by invoking the following command\nfrom inside the ```my_project``` folder or ```predictions``` sub-folder:\n\n```\nmp summary\n\n>> [***] SUMMARY REPORT FOR FOLDER [***]\n>> ./my_project/predictions/csv/\n>> \n>> \n>> Per class:\n>> --------------------------------\n>>    Mean dice by class  +/- STD    min    max   N\n>> 1               0.856    0.060  0.672  0.912  34\n>> 2               0.891    0.029  0.827  0.934  34\n>> 3               0.888    0.027  0.829  0.930  34\n>> 4               0.802    0.164  0.261  0.943  34\n>> 5               0.819    0.075  0.552  0.926  34\n>> 6               0.863    0.047  0.663  0.917  34\n>> \n>> Overall mean: 0.853 +- 0.088\n>> --------------------------------\n>> \n>> By views:\n>> --------------------------------\n>> [0.8477811  0.50449719 0.16355361]          0.825\n>> [ 0.70659414 -0.35532932  0.6119361 ]       0.819\n>> [ 0.11799461 -0.07137918  0.9904455 ]       0.772\n>> [ 0.95572575 -0.28795306  0.06059151]       0.827\n>> [-0.16704373 -0.96459936  0.20406974]       0.810\n>> [-0.72188903  0.68418977  0.10373322]       0.819\n>> --------------------------------\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9448323282043786
      ],
      "excerpt": "Implementation of the Multi-Planar U-Net as described in:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8827438958278534,
        0.9416303202262377
      ],
      "excerpt": "This package implements fully autonomous deep learning based  \nsegmentation of any 3D medical image. It uses a fixed  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8051701858157146
      ],
      "excerpt": "required except for supplying the training data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.913430630581858,
        0.8645604746522856
      ],
      "excerpt": "This software may be used as-is and does not require deep learning expertise to \nget started. It may also serve as a strong baseline method for general purpose \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8620422202164943
      ],
      "excerpt": "trained under a multi-planar framework. Specifically, the 2D model is \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8907944189856956
      ],
      "excerpt": "At test-time, the model predict along each of the views and recreates a set of full segmentation volumes.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8707443387857271,
        0.9785781258363462
      ],
      "excerpt": "It is important that the .nii files store correct 4x4 affines for mapping \nvoxel coordinates to the scanner space. Specifically, the framework needs to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9735210591271218
      ],
      "excerpt": "in the scanner space. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8199984168383861
      ],
      "excerpt": "for a 256x256x256 image with 3 channels). Label maps should be identically  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336927900841754
      ],
      "excerpt": ": Initialize a project at 'my_folder' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9244274664309351,
        0.9206638252580853
      ],
      "excerpt": "However, note that a 3D model is also supported, which can be selected by  \nspecifying the --model=3D flag (default=---model=MultiPlanar). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8564050105667332
      ],
      "excerpt": "|- model/                #: Stores the best model parameters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8115245833725556,
        0.8122867531935128
      ],
      "excerpt": "When using the MultiPlanar model, a fusion model must  be computed after  \nthe base model has been trained. This model will learn to map the multiple  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8334114468926491
      ],
      "excerpt": "The model can also be used to predict on images stored in the predictions  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Multi-Planar UNet for autonomous segmentation of 3D medical images",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/perslev/MultiPlanarUNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 31,
      "date": "Mon, 20 Dec 2021 15:21:55 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/perslev/MultiPlanarUNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "perslev/MultiPlanarUNet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "In order to train a model to solve a specific task, a set of manually \nannotated images must be stored in a folder under the following structure:\n\n```\n./data_folder/\n|- train/\n|--- images/\n|------ image1.nii.gz\n|------ image5.nii.gz\n|--- labels/\n|------ image1.nii.gz\n|------ image5.nii.gz\n|- val/\n|--- images/\n|--- labels/\n|- test/\n|--- images/\n|--- labels/\n|- aug/ <-- OPTIONAL\n|--- images/\n|--- labels/\n```\n\nThe names of these folders may be customized in the parameter file (see below), \nbut default to those shown above. The image and corresponding label map files \nmust be identically named.\n\nThe ```aug``` folder may store additional images that can be included during \ntraining with a lower weight assigned in optimization.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n#: From GitHub\ngit clone https://github.com/perslev/MultiPlanarUNet\npip install -e MultiPlanarUNet\n```\n\nThis package is still frequently updated and it is thus recommended to install \nthe package with PIP with the -e ('editable') flag so that the package can be \nupdated with recent changes on GitHub without re-installing:\n\n```\ncd MultiPlanarUNet\ngit pull\n```\n\nHowever, the package is also occasionally updated on PyPi for install with:\n\n```\n#: Note: renamed MultiPlanarUNet -> mpunet in versions 0.2.4\npip install mpunet\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.836113299503159
      ],
      "excerpt": "mp init_project --name my_project --data_dir ./data_folder \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.949722645760987
      ],
      "excerpt": "Here, we prepare for a 5-CV setup. By default, the above command will create a \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.804330596750322
      ],
      "excerpt": "At test-time, the model predict along each of the views and recreates a set of full segmentation volumes.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.832158756766481
      ],
      "excerpt": "know the voxel size and axis orientations in order to sample isotrophic images  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "mp init_project --name my_project --data_dir ./data_folder \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8116132342804064
      ],
      "excerpt": "the project folder. Typically, after training, the folder will look as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8527232117585585
      ],
      "excerpt": "|- images/               #: Example segmentations through training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8258813802260424
      ],
      "excerpt": "|- train_hparams.yaml    #: The hyperparameters file \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.832191089496661
      ],
      "excerpt": "The trained model can now be evaluated on the testing data in  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8072062611019861
      ],
      "excerpt": "mp predict --num_GPUs=2 --out_dir predictions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8813732574147479,
        0.8213380337316241
      ],
      "excerpt": ": Predict on all images in 'test' folder without label files \nmp predict --no_eval \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8240482264684765,
        0.8484146042515222
      ],
      "excerpt": "split0, split1, ..., split5 each structured like the main data folder  \nwith sub-folders train, val, test and aug (optionally,  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/perslev/MultiPlanarUNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Multi-Planar U-Net",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "MultiPlanarUNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "perslev",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/perslev/MultiPlanarUNet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "A cross-validation experiment can now be performed. On systems with multiple\nGPUs, each fold can be assigned a given number of the total pool of GPUs'. In \nthis case, multiple folds will run in parallel and new ones automatically start\nwhen previous folds terminate.\n\nFirst, we create a new project folder. This time, we do not specify a data \nfolder yet:\n\n```\nmp init_project --name CV_experiment\n```\n\nWe also create a file named ```script```, giving the following folder structure:\n\n```\n./CV_experiment\n|- train_hparams.yaml\n|- script\n```\n\nThe train_hparams.yaml file will serve as a **template** that will be applied \nto all folds. We can set any parameters we want here, or let the framework \ndecide on proper parameters for each fold automatically. The **script** file \ndetails the ```mp``` commands (and optionally various arguments) to execute on \neach fold. For instance, a script file may look like:\n\n```\nmp train --no_images  #: Do not save example segmentations\nmp train_fusion\nmp predict --out_dir predictions\n```\n\nWe can now execute the 5-CV experiment by running:\n\n```\nmp cv_experiment --CV_dir=./data_dir/views/5-CV \\\n                 --out_dir=./splits \\\n                 --num_GPUs=2\n                 --monitor_GPUs_every=600\n```\n\nAbove, we assign 2 GPUs to each fold. On a system of 8 GPUs, 4 folds will be \nrun in parallel. We set ```--monitor_GPUs_every=600``` to scan the system for \nnew free GPU resources every 600 seconds (otherwise, only GPUs that we \ninitially available will be cycled and new free ones will be ignored).\n\nThe ```cv_experiment``` script will create a new project folder for each split \nlocated at ```--out_dir``` (```CV_experiment/splits``` in this case). For each\nfold, each of the commands outlined in the ```script``` file will be launched\none by one inside the respective project folder of the fold, so that the \npredictions are stored in ```CV_experiment/splits/split0/predictions``` for \nfold 0 etc.\n\nAfterwards, we may get a CV summary by invoking:\n\n```\nmp summary\n```\n\n... from inside the ```CV_experiment/splits``` folder.\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 144,
      "date": "Mon, 20 Dec 2021 15:21:55 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "python",
      "deep-learning",
      "medical-image-analysis",
      "fully-convolutional-network"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\nusage: mp [script] [script args...]\n\nMulti-Planar UNet (0.1.0)\n-------------------------\nAvailable scripts:\n- cv_experiment\n- cv_split\n- init_project\n- predict\n- predict_3D\n- summary\n- train\n- train_fusion\n...\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Project initialization, model training, evaluation, prediction etc. can be \nperformed using the scripts located in ```MultiPlanarUNet.bin```. The script \nnamed ```mp.py``` serves as an entry point to all other scripts, and it is used\nas follows:\n\n```bash\n#: Invoke the help menu\nmp --help\n\n#: Launch the train script\nmp train [arguments passed to 'train'...]\n\n#: Invoke the help menu of a sub-script\nmp train --help\n```\n\nYou only need to specify the training data in the format described \nbelow. Training, evaluation and prediction will be handled automatically if \nusing the above scripts.\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1807.10221",
      "https://arxiv.org/abs/1807.11590",
      "https://arxiv.org/abs/1807.10221"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find the code or the pretrained models useful, please consider to cite the following paper:\n\nUnified Perceptual Parsing for Scene Understanding. T. Xiao, Y. Liu, B. Zhou, Y. Jiang, and J. Sun. European Conference on Computer Vision (ECCV), 2018. (https://arxiv.org/abs/1807.10221)\n\n    @inproceedings{xiao2018unified,\n      title={Unified Perceptual Parsing for Scene Understanding},\n      author={Xiao, Tete and Liu, Yingcheng and Zhou, Bolei and Jiang, Yuning and Sun, Jian},\n      booktitle={European Conference on Computer Vision},\n      year={2018},\n      organization={Springer}\n    }\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{xiao2018unified,\n  title={Unified Perceptual Parsing for Scene Understanding},\n  author={Xiao, Tete and Liu, Yingcheng and Zhou, Bolei and Jiang, Yuning and Sun, Jian},\n  booktitle={European Conference on Computer Vision},\n  year={2018},\n  organization={Springer}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9031811701482705
      ],
      "excerpt": "Classify scene and parse objects, parts, materials and textures at a single and efficient forward. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CSAILVision/unifiedparsing",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-07-17T16:52:22Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-12T10:07:41Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9761449408991535
      ],
      "excerpt": "This is a pyTorch implementation of Unified Perceptual Parsing network on Broden+ dataset and ADE20K dataset. This work is published at ECCV'18 Unified Perceptual Parsing for Scene Understanding, to which Tete Xiao, Yingcheng Liu, and Bolei Zhou contribute equally. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9830046139704245
      ],
      "excerpt": "The human visual system is able to extract a remarkable amount of semantic information from a single glance. We not only instantly parse the objects contained within, but also identify the fine-grained attributes of objects, such as their parts, textures and materials. Motivated by this, we define the task of Unified Perceptual Parsing as the recognition of many visual concepts as possible from a given image. Possible visual concepts are organized into several levels: from scene labels, objects, and parts of objects, to materials and textures of objects. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8599146787192549,
        0.9207368816987324
      ],
      "excerpt": "Classify scene and parse objects, parts, materials and textures at a single and efficient forward. \nUse Precise RoI Pooling (PrRoIPooling) instead of Adaptive Pooling for Pyramid Pooling Module (PPM). See Acquisition of Localization Confidence for Accurate Object Detection paper for details about PrRoIPooling and github page for implementation details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8487254778310299,
        0.930195873169865,
        0.8588032913438295
      ],
      "excerpt": "Dynamic scales of input for training with multiple GPUs. \nSupport state-of-the-art PyTorch 1.0 \nThe code is developed under the following configurations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8107687071562779,
        0.9948772723150042,
        0.8633336125687068,
        0.8616328324129101
      ],
      "excerpt": "Warning: We don't support the outdated Python 2 anymore. PyTorch 0.4.0 or higher is required to run the code. \nWe have released the UPerNet with state-of-the-art performance proposed in our paper as baseline for parsing. UPerNet is based on Feature Pyramid Network (FPN) and Pyramid Pooling Module (PPM), with down-sampling rate of 4, 8 and 16. It doesn't need dilated convolution, a operator that is time-and-memory consuming. Without bells and whistles, it is comparable or even better compared with PSPNet, while requires much shorter training time and less GPU memory. E.g., you cannot train a PSPNet-101 on TITAN Xp GPUs with only 12GB memory, while you can train a UPerNet-101 on such GPUs. Please refer to semantic-segmentation-pytorch for codes and models. \nYou can use our pretrained models in PyTorch to segment input image. The usage is as follows: \nIf you're using PyTorch>=1.0 and on branch master or PyTorch 1.0, skip this step. If you're using 0.4<=PyTorch<1.0, please compile Precise RoI Pooling operator first. (Please check out to pytorch0.4 branch!!!) It requires PyTorch compiled with cffi and only supports CUDA (CPU mode is not implemented). To compile the essential components: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9082795056272426
      ],
      "excerpt": "Now you're good to go! Here is a simple demo to do inference on a single image: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Codebase and pretrained models for ECCV'18 Unified Perceptual Parsing",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CSAILVision/unifiedparsing/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 60,
      "date": "Sun, 26 Dec 2021 07:13:27 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/CSAILVision/unifiedparsing/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "CSAILVision/unifiedparsing",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/CSAILVision/unifiedparsing/master/demo_test.sh",
      "https://raw.githubusercontent.com/CSAILVision/unifiedparsing/master/download_Broden%2B.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8604498830753683,
        0.9176533436805182,
        0.92542056794358,
        0.9651095206913344
      ],
      "excerpt": "- Hardware: 2-8 GPUs (with at least 12G GPU memories) (change [--num_gpus NUM_GPUS] accordingly) \n- Software: Ubuntu 16.04.3 LTS, CUDA>=8.0, Python>=3.5, PyTorch>=0.4.0 (PyTorch 1.0 supported) \n- Library: opencv, scipy, colormath, tqdm, PyTorch compiled with cffi \nWarning: We don't support the outdated Python 2 anymore. PyTorch 0.4.0 or higher is required to run the code. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8610060783900381,
        0.953691433472028,
        0.8075011391408197,
        0.890244011698383,
        0.9512252725338339
      ],
      "excerpt": "If you're using PyTorch>=1.0 and on branch master or PyTorch 1.0, skip this step. If you're using 0.4<=PyTorch<1.0, please compile Precise RoI Pooling operator first. (Please check out to pytorch0.4 branch!!!) It requires PyTorch compiled with cffi and only supports CUDA (CPU mode is not implemented). To compile the essential components: \n    cd lib/nn/prroi_pool \n    ./travis.sh \nYou may need nvcc for this step. If it cannot find the path to cuda.h, do \n    export CPATH=/PATH/TO/YOUR/CUDA/include &amp;&amp; ./travis.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8468902673898102
      ],
      "excerpt": "chmod +x demo_test.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8468902673898102,
        0.9023697225149864
      ],
      "excerpt": "    chmod +w download_Broden+.sh \n    ./download_Broden+.sh \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9197735714648932
      ],
      "excerpt": "<img src=\"./teaser/upp_demo.jpg\" width=\"900\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9197735714648932
      ],
      "excerpt": "<img src=\"./teaser/result_samples.jpg\" width=\"900\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8066103730055433
      ],
      "excerpt": "Dynamic scales of input for training with multiple GPUs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8338554437693109,
        0.8241111207636134
      ],
      "excerpt": "This script downloads trained models and a test image, runs the test script, and saves predicted segmentation (.png) to the working directory. \nInput arguments: (see full input arguments via python3 test.py -h) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9400672003048504
      ],
      "excerpt": "usage: test.py [-h] --test_img TEST_IMG --model_path MODEL_PATH \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8278068381764189
      ],
      "excerpt": "               [--result RESULT] [--gpu_id GPU_ID] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.950563948951535
      ],
      "excerpt": "    python3 train.py --num_gpus 8 --arch_encoder resnet50 --arch_decoder upernet  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233673372258015
      ],
      "excerpt": "Input arguments: (see full input arguments via python3 train.py -h) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8942932624228215
      ],
      "excerpt": "usage: train.py [-h] [--id ID] [--arch_encoder ARCH_ENCODER] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8476742339111021
      ],
      "excerpt": "    python3 eval_multipro.py --arch_encoder resnet50 --arch_decoder upernet --id MODEL_ID \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/CSAILVision/unifiedparsing/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cuda",
      "MATLAB",
      "C",
      "Shell",
      "C++"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Unified Perceptual Parsing for Scene Understanding",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "unifiedparsing",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "CSAILVision",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CSAILVision/unifiedparsing/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 314,
      "date": "Sun, 26 Dec 2021 07:13:27 GMT"
    },
    "technique": "GitHub API"
  }
}
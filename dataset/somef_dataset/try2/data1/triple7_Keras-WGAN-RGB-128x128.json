{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1701.07875",
      "https://arxiv.org/abs/1905.11946"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/triple7/Keras-WGAN-RGB-128x128",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-05T00:01:36Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-09T14:30:15Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "WGAN networks were argued to have higher quality output thanks to the use of the Wasser-Stein loss, which:\n. avoids the vanishing/exploding gradient issue normally associated with the KL/JA divergence losses\n. Adds a score to the realism of an image, as opposed to the sigmoid binary output which effectively performs classification. \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9892769029127774,
        0.9875426676261698,
        0.9761304370658531
      ],
      "excerpt": "The critic is a traditional classifier using a conv2D > batchNormalisation > LeakyReLU activation starting with an input of mxnc tensor over a specified number of blocks before flattening to a dense layer and outputting using a sigmoid activation. \nThe generator takes a laten space vector, uniform random values of domain [0, 1], shaped into a tensor of 4x4xfeatures that passes through blocks of upsampling, convolutions, batchNormalisation, and LeakyReLU activations before the output layer which gives a generated image of the required size, starting at 64 features, and increasing until the required size, augmenting the feature space. \nThe WGAN stacks the generator and the critic. The critic's training is turned off, as it is done with a 5:1 ratio per step, dividing the batches per epoch for both critic and generator. The critic effectively trains 5 times more than the generator, to give it a more robust discriminant function, while the generator trains in the iteration, and is trained equally through the WGAN. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9236936202145384
      ],
      "excerpt": "The pros for considering this model are: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8902028367467438,
        0.9785213178063961,
        0.8620384906355103,
        0.9636087446742078,
        0.9600218510516559,
        0.9156112955359546
      ],
      "excerpt": ". The network is scalable \nSome of the cons from experiencing this model are: \n. loss gives no pertinent information about the quality of the generated image, so considering the distance of 2 distributions has no relevance and may require an extra function such as using critical t value from the differentiation of distributions.  \n. The model is very sensitive to hyper-parameters \n. In terms of real applications, this is not as useful as an image to image generation model such as the cycle GAN or the style GAN. \nCurrently, the defaults are: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9821312425108727
      ],
      "excerpt": "the random uniform initialisation of the kernel for both critic and generator are set to a standard deviation of 0.2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9035177686857245,
        0.9605769698111224
      ],
      "excerpt": "The learning rate is set to 0.00005 \nThe laten space vector is set to 100 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8303696086228435
      ],
      "excerpt": ". A plot of the loss for critic and WGAN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8354732510589535
      ],
      "excerpt": "Once the training is completed, you can run sonify.sh to run a sonification of the generated images to run some overall sound based debugging of the images. Not sure if this is useful outside the scope of blind users, but something that is available. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A Keras implementation of the Wasser-Stein Generative Adversarial Network for 128x128 RGB image generation",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/triple7/Keras-WGAN-RGB-128x128/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 06:38:02 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/triple7/Keras-WGAN-RGB-128x128/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "triple7/Keras-WGAN-RGB-128x128",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/triple7/Keras-WGAN-RGB-128x128/master/train.sh",
      "https://raw.githubusercontent.com/triple7/Keras-WGAN-RGB-128x128/master/dependencies.sh",
      "https://raw.githubusercontent.com/triple7/Keras-WGAN-RGB-128x128/master/sonify.sh"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/triple7/Keras-WGAN-RGB-128x128/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "keras implementation of the WGAN for colored images",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Keras-WGAN-RGB-128x128",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "triple7",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/triple7/Keras-WGAN-RGB-128x128/blob/master/readme.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This code depends on the Celeba-dataset available here(http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html).\nOnce downloaded, place in the root directory under \"./celeba-dataset\"\n\nnote: you will need to login first, and download the set using an auth key. Also, this data set is large (over 1.5 gb), so make sure to start with smaller numbers of samples if you are on single CPU setups or have restricted memory space access on your server.\n\nnote II: This setup was made particularly for the celeba dataset, however replacing the default path argument in load_images() will take any image directory for pre-processing.\n\nThe python dependencies are:\n1. tensorflow and keras\n2. numpy and scipy\n3. opencv-python\n4. pydub and pyttsx3 (if you intend to use the sonify.py tools)\n\nYou can run the ./dependencies.sh script to pip install the required modules\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Fri, 24 Dec 2021 06:38:02 GMT"
    },
    "technique": "GitHub API"
  }
}
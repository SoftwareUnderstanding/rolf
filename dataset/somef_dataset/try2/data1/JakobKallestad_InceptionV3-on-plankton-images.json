{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1603.07285v2.\n\n\n```python\nImage(url= \"https://miro.medium.com/max/441/1*BMngs93_rm2_BpJFH2mS0Q.gif\"",
      "https://arxiv.org/abs/1409.4842\n\n\n```python\nImage(url= \"https://miro.medium.com/max/1257/1*DKjGRDd_lJeUfVlY50ojOA.png\""
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9821300997599387
      ],
      "excerpt": "<li>InceptionV3 architecture</li> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9946082507881043
      ],
      "excerpt": "<li>InceptionV3 algorithm on Cifar10 dataset</li> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9946082507881043
      ],
      "excerpt": "<li>InceptionV3 algorithm on Plankton dataset</li> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9239290979129978
      ],
      "excerpt": "Image(url= \"https://miro.medium.com/max/441/1*BMngs93_rm2_BpJFH2mS0Q.gif\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8848747303040743
      ],
      "excerpt": "Image(url= \"https://miro.medium.com/max/1257/1*DKjGRDd_lJeUfVlY50ojOA.png\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8848747303040743
      ],
      "excerpt": "Image(url = \"https://miro.medium.com/max/1235/1*U_McJnp7Fnif-lw9iIC5Bw.png\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8848747303040743
      ],
      "excerpt": "Image(url = \"https://miro.medium.com/max/2591/1*53uKkbeyzJcdo8PE5TQqqw.png\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8848747303040743
      ],
      "excerpt": "Image(url = \"https://miro.medium.com/max/3012/1*ooVUXW6BIcoRdsF7kzkMwQ.png\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.968473386661761
      ],
      "excerpt": "<li>The Cifar10 dataset</li> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.961792842656265
      ],
      "excerpt": "<li>Data preprocessing and augmentation</li> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9967758733543715
      ],
      "excerpt": "<li>Training results</li> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9951138369574583
      ],
      "excerpt": "<li>Results on the testset</li> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9215003408107547,
        0.9948636820011255,
        0.9879105606724751
      ],
      "excerpt": "<li>Train: &emsp;&emsp; &emsp;&nbsp; 40 000 images</li> \n<li>Validation:&emsp;&nbsp; 10 000 images</li> \n<li>Test: &emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp; 10 000 images</li> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8088275851153562,
        0.8207940084462922
      ],
      "excerpt": "for j in range(10): \n    html_list.append(\"<td><center>{}</center><img src='{}'></td>\".format(class_names[j], link_list[j])) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8364066185740432
      ],
      "excerpt": "<li>Introduction to the plankton dataset</li> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.961792842656265
      ],
      "excerpt": "<li>Data preprocessing and augmentation</li> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9788914761692258
      ],
      "excerpt": "<li>Initial experiments</li> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.819969410067083
      ],
      "excerpt": "Image(url= \"http://33.media.tumblr.com/e8ed810ef98f555994cdcbfd6ec04ab3/tumblr_neot4s0EBL1s2ls31o1_400.gif\") \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JakobKallestad/InceptionV3-on-plankton-images",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-04T13:56:57Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-29T23:28:31Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The plankton dataset that we use contains 712 491 images of plankton spread __unevenly__ accross 65 different species. These are in turn divided into train, validation and test sets with the following ratios:\n<ul>\n<li>Train: &emsp;&emsp; &emsp;&nbsp; 699 491 images</li>\n<li>Validation:&emsp;&nbsp; 6500 images</li>\n<li>Test: &emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp; 6500 images</li>\n</ul>\n\nIn short we used the *train*, *validate* and *test* folders inside the *data-65* folder from the dataset given to us for this assignment. <br>\n\nHere is an overview of what the different species look like:\n\n\n```python\nclass_names = ['Acantharea', 'Acartiidae', 'Actinopterygii', 'Annelida', 'Bivalvia__Mollusca', 'Brachyura',\n              'bubble', 'Calanidae', 'Calanoida', 'calyptopsis', 'Candaciidae', 'Cavoliniidae', 'Centropagidae',\n              'Chaetognatha', 'Copilia', 'Corycaeidae', 'Coscinodiscus', 'Creseidae', 'cyphonaute', 'cypris',\n              'Decapoda', 'Doliolida', 'egg__Actinopterygii', 'egg__Cavolinia_inflexa', 'Eucalanidae', 'Euchaetidae',\n              'eudoxie__Diphyidae', 'Evadne', 'Foraminifera', 'Fritillariidae', 'gonophore__Diphyidae', 'Haloptilus',\n              'Harpacticoida', 'Hyperiidea', 'larvae__Crustacea', 'Limacidae', 'Limacinidae', 'Luciferidae', 'megalopa',\n              'multiple__Copepoda', 'nauplii__Cirripedia', 'nauplii__Crustacea', 'nectophore__Diphyidae', 'nectophore__Physonectae', \n              'Neoceratium', 'Noctiluca', 'Obelia', 'Oikopleuridae', 'Oithonidae', 'Oncaeidae', 'Ophiuroidea', 'Ostracoda', 'Penilia',\n              'Phaeodaria', 'Podon', 'Pontellidae', 'Rhincalanidae', 'Salpida', 'Sapphirinidae', 'scale', 'seaweed', 'tail__Appendicularia',\n              'tail__Chaetognatha', 'Temoridae', 'zoea__Decapoda']\nlink_list = ['https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/{}.jpg'.format(cn) for cn in class_names]\nhtml_list = [\"<table>\"]\nfor i in range(8):\n    html_list.append(\"<tr>\")\n    for j in range(8):\n        html_list.append(\"<td><center>{}</center><img src='{}'></td>\".format(class_names[i*8+j], link_list[i*8+j]))\n    html_list.append(\"</tr>\")\nhtml_list.append(\"</table>\")\n\ndisplay(HTML(''.join(html_list)))   \n```\n\n\n<table><tr><td><center>Acantharea</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Acantharea.jpg'></td><td><center>Acartiidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Acartiidae.jpg'></td><td><center>Actinopterygii</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Actinopterygii.jpg'></td><td><center>Annelida</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Annelida.jpg'></td><td><center>Bivalvia__Mollusca</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Bivalvia__Mollusca.jpg'></td><td><center>Brachyura</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Brachyura.jpg'></td><td><center>bubble</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/bubble.jpg'></td><td><center>Calanidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Calanidae.jpg'></td></tr><tr><td><center>Calanoida</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Calanoida.jpg'></td><td><center>calyptopsis</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/calyptopsis.jpg'></td><td><center>Candaciidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Candaciidae.jpg'></td><td><center>Cavoliniidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Cavoliniidae.jpg'></td><td><center>Centropagidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Centropagidae.jpg'></td><td><center>Chaetognatha</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Chaetognatha.jpg'></td><td><center>Copilia</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Copilia.jpg'></td><td><center>Corycaeidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Corycaeidae.jpg'></td></tr><tr><td><center>Coscinodiscus</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Coscinodiscus.jpg'></td><td><center>Creseidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Creseidae.jpg'></td><td><center>cyphonaute</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/cyphonaute.jpg'></td><td><center>cypris</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/cypris.jpg'></td><td><center>Decapoda</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Decapoda.jpg'></td><td><center>Doliolida</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Doliolida.jpg'></td><td><center>egg__Actinopterygii</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/egg__Actinopterygii.jpg'></td><td><center>egg__Cavolinia_inflexa</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/egg__Cavolinia_inflexa.jpg'></td></tr><tr><td><center>Eucalanidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Eucalanidae.jpg'></td><td><center>Euchaetidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Euchaetidae.jpg'></td><td><center>eudoxie__Diphyidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/eudoxie__Diphyidae.jpg'></td><td><center>Evadne</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Evadne.jpg'></td><td><center>Foraminifera</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Foraminifera.jpg'></td><td><center>Fritillariidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Fritillariidae.jpg'></td><td><center>gonophore__Diphyidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/gonophore__Diphyidae.jpg'></td><td><center>Haloptilus</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Haloptilus.jpg'></td></tr><tr><td><center>Harpacticoida</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Harpacticoida.jpg'></td><td><center>Hyperiidea</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Hyperiidea.jpg'></td><td><center>larvae__Crustacea</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/larvae__Crustacea.jpg'></td><td><center>Limacidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Limacidae.jpg'></td><td><center>Limacinidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Limacinidae.jpg'></td><td><center>Luciferidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Luciferidae.jpg'></td><td><center>megalopa</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/megalopa.jpg'></td><td><center>multiple__Copepoda</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/multiple__Copepoda.jpg'></td></tr><tr><td><center>nauplii__Cirripedia</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/nauplii__Cirripedia.jpg'></td><td><center>nauplii__Crustacea</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/nauplii__Crustacea.jpg'></td><td><center>nectophore__Diphyidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/nectophore__Diphyidae.jpg'></td><td><center>nectophore__Physonectae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/nectophore__Physonectae.jpg'></td><td><center>Neoceratium</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Neoceratium.jpg'></td><td><center>Noctiluca</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Noctiluca.jpg'></td><td><center>Obelia</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Obelia.jpg'></td><td><center>Oikopleuridae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Oikopleuridae.jpg'></td></tr><tr><td><center>Oithonidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Oithonidae.jpg'></td><td><center>Oncaeidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Oncaeidae.jpg'></td><td><center>Ophiuroidea</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Ophiuroidea.jpg'></td><td><center>Ostracoda</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Ostracoda.jpg'></td><td><center>Penilia</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Penilia.jpg'></td><td><center>Phaeodaria</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Phaeodaria.jpg'></td><td><center>Podon</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Podon.jpg'></td><td><center>Pontellidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Pontellidae.jpg'></td></tr><tr><td><center>Rhincalanidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Rhincalanidae.jpg'></td><td><center>Salpida</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Salpida.jpg'></td><td><center>Sapphirinidae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Sapphirinidae.jpg'></td><td><center>scale</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/scale.jpg'></td><td><center>seaweed</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/seaweed.jpg'></td><td><center>tail__Appendicularia</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/tail__Appendicularia.jpg'></td><td><center>tail__Chaetognatha</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/tail__Chaetognatha.jpg'></td><td><center>Temoridae</center><img src='https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/species/Temoridae.jpg'></td></tr></table>\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.994900311608437
      ],
      "excerpt": "For this exercise, we have chosen to go with the Inception V3 architecture, trained on the ImageNet dataset. Inception V3 is a CNN, convolutional neural network, a class of networks wich uses the mathematical operaitons pooling and convolutions. In CNNs, this works by applying a filter to the input of any layer. The filter works by doing some operations depending on the filter type and the input. For convolutional filters, the product of filter cells with corresponding cells of the input are added together. For Pooling filters, the maximum, minimum or average value that the filter \"covers\" are given as output. Under you can see an example of a 2x2 filter from \"A guide to convolution arithmetic for deep learning\"(Dumoulin & Visin) https://arxiv.org/abs/1603.07285v2. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9908302497254114,
        0.9595648573280058
      ],
      "excerpt": "The filter slides over the input with a predefined step size, called stride, and outputs one number for each position. These filters are usually used more than one at the time. What happens then is that the outputs of each filter is stacked on top of each other, making up the output channels. Each of the individual filter however takes into account all the input channels and adds them together. This gives an output size of OxO, O=(W-K+2P)/S + 1, independent of the number of channels in the input. P in the formula is the padding size. Padding is a technique where one adds \"empty\" pixels on the edges of the input, to effectively increase the effect of the outmost pixels. In our chosen architecture, the padding is \"same\", meaning that the padding varies so that the output has the same height and width dimensions as the output. \nInception V3 is as the name suggests a architecture of the Inception type. These are build up of so called Inception module, of which the idea is that instead of chosing a number of filters of one filtersize in a convolutional layer at a point, you chose multiple filter size, and then stack the outputs into one. This allows for detection of objects of different sizes in images in an effective way. The inception module is illustrated in the figure below, from the paper \"Going deeper with convolutions\"(Szegedy et al., 2014), where the inception network was first introduced. https://arxiv.org/abs/1409.4842 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9834843332391299,
        0.9731731360529786
      ],
      "excerpt": "Call this module, the model (a), the naive version. This uses 3 types convolutional filters of size 1x1, 3x3 and 5x5, and a pooling filter. To ensure the output is of the different filters are of the same size, a same padding is used on both the convolutional filter, but also the pooling filter. \nThis is however an operational costly layer, where the numbers of operations for each convolutional filter is the dimension of the input, height width number of channels, times the dimension of the filter, height width number of filters. To reduce the number of operation, module b is proposed. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.988567456792471,
        0.9153189606335207
      ],
      "excerpt": "Here the inventors have added a 1x1 filter before the 3x3 and 5x5 filters. Doing this, the dimension of the input are reduced, specifically the number of channels of the input is reduced, and the output of the 1x1 filters, have a number of channels equal to the number of 1x1 filters. Doing this, the cost of going from the input to the output of the 5x5 filters is reduced to the dimension of the input, height width number of channels, times 1x1 times number of 1x1 filters, plus the second filtering, through 5x5, which is equal to the original one in b, divided by the ratio of number of input channels / number of 1x1 filters. \nModules of the b types are used in the inception architecture from the paper, the Inception V1, ending in the architecture in the below figure(source: https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d#81e0). This is also the baseline for Inception V3, but there are multiple other alterings to the inception modules, which will soon be explained. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9016536021612134,
        0.9894691911500032
      ],
      "excerpt": "As we can see, the architecture consists of a stem, which consists of traditional pooling and convolutional layer, and then pooling layers in between inception modules. In the end, there is a pooling, a fully connected and a softmax layer. \nAs mentioned earlier, the Inception V3 as we use, is based on this Inception V1, but with a couple improvements. First of all, 5x5 filters are factorized into two 3x3 filters. As 5x5 filters are more then two times more computionally expensive than 3x3 filters, this decreases number of operations. nxn filters are further factorized into 1xn and nx1 filters, which is reported in the paper to be 33% cheaper than one nxn filter. To avoid the inception modules beeing to deep, the filters are instead spread, to widen the inception modules. The full network are shown in the figure below (source:https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d#81e0). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906236583733276
      ],
      "excerpt": "As we can see, the Inception V3 architecture also involves reduction modules, which in principle are the same as inception module, except that it is designed to decrease the dimensions of the input. In total the Inception V3 includes about 24M parameters. It is also worth mentioning that the V3 takes as default input 299x299x3, and uses a RSMProp optimizer. As this is designed for the ImageNet dataset, it outputs 1000 different classes, but as we use it for the plankton dataset, we change the last layers to fit to our desired output. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8617536908343005
      ],
      "excerpt": "In order to use less memory and processing time we downloded the dataset and saved it on disk with the code provided in 'create_cifar10data_images.ipynb' file. This code also upscales the images to size (75, 75, 3) because InceptionV3 requires this as a minimum size of training input. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8331430188606679,
        0.9605515085077715
      ],
      "excerpt": "We used the Adam optimizer because it is very robust and it is forgiving if you specify a non-optimal learning rate. \nInceptionV3 uses RMSProp as default, but after using RMSProp initially we noticed that we were getting better results with Adam, so ended up using that instead.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9328052726980406,
        0.9242712928343765
      ],
      "excerpt": "We ended up using a batch size of 64 \nThat is large enough to ensure a good representation of the 10 classes is each batch, and still not being too computationally heavy. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8435574409305987
      ],
      "excerpt": "(Instead of just padding the images with zeros)   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.991679230628497
      ],
      "excerpt": "We used these flip and rotational augmentations to decrease the risk of overfitting, and to increase the amount of data that we can train on. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9916516012671417
      ],
      "excerpt": "Since the training data is organized in order of category, we shuffle the data before every epoch. The model trains on the entire dataset for every epoch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9953256858680769
      ],
      "excerpt": "The spike of improvement at epoch 4 is because thats when we unfroze all the layers of the network. Not much improvement happened after about epoch 15 for the validation data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8182287791198384
      ],
      "excerpt": "Validation data accuracy : 95.00%   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8182287791198384
      ],
      "excerpt": "Validation data accuracy : 99.995% \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9093108935369719
      ],
      "excerpt": "The loss function indicates that we might be overfitting the model slightly in the last 10 epochs. However, the loss increase is insignicant and so we stop training and keep the model for testing. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9938976664941318,
        0.8511023660503612
      ],
      "excerpt": "When evaluating the model on our testset we got an accuracy of 95.42%. Very much what the model predicted on the validation data, indicating that we did not overfit during training. \n(The results are evaluated with the code in 'running_cifar10_model_on_testset.ipynb.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9458491666756614,
        0.9920935583015316,
        0.9379538449761112
      ],
      "excerpt": "From the confusion matrix we see that categories that most often are mistaken during evaluation are cats and dogs. And they are most likely to be mistaken for eachother. This should come as no surprise as, among these 10 categories, those two are probably the most similar. Even humans can mistake a dog for a cat if the image is of very low resolution. The original images are of size (32, 32). \nAfter about epoch 15, the model stopped improving on the validation data. To squeeze a better result out of this model we could try to lower the learning rate and increase the amount of augmentation used in the generator. \nHowever, our focus for this exercise was more geared towards the Plankton dataset which demanded most of our virtual machines running time, and so we settled for this result. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8331430188606679,
        0.9605515085077715
      ],
      "excerpt": "We used the Adam optimizer because it is very robust and it is forgiving if you specify a non-optimal learning rate. \nInceptionV3 uses RMSProp as default, but after using RMSProp initially we noticed that we were getting better results with Adam, so ended up using that instead.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9021592603616069,
        0.9901412799443087,
        0.9746012459871313,
        0.8099353894809248
      ],
      "excerpt": "We used a batch size of 128 \nWe wanted a high batch size as there are many classes in the dataset and it is also unbalanced which is not taken into account by the training generator and therefore poses a risk of having very unbalanced batches if they are small. \nWhen testing we found that using a batch size of 128 gave significantly better results than a batch size of 64. \nDue to memory constraint we were not able to test with a higher batch size than 128, but any higher than this might make training too slow anyway.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9837594032006792,
        0.959618359658438
      ],
      "excerpt": "As there are nearly 700 000 images in the training set and a batch size of 128 this gives us (128*1000)/700000 \u2248 0.2 which means that the model sees about 1/5 of the data per epoch. \nFor test and validation the steps_per_epoch are sufficiently high so that all the data is used to calculate validation and test accuracy/loss. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.970653786358578,
        0.8767968717796614
      ],
      "excerpt": "We used heavy augmentation on the training data. Having the ability to flip and rotate the images freely put us in a situation where we felt that the risk of overfitting was very low. \nThis meant that our main challenge for training a good model was having enough time to train it, and tuning the hyper parameters correctly.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8784998056938897,
        0.8323491835166236
      ],
      "excerpt": "The datagenerator shuffles the training data to hopefully create somewhat even batches. \nNote that it makes sure to go through all the training data before re-shuffeling.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9680677149950998
      ],
      "excerpt": "Finally, because the plankton dataset is only grayscale we used the argument color_mode='rgb' to duplicate the channel two times for a total of three equal channels which corresponds to a grayscale image.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8038968539064294,
        0.9661506656053573
      ],
      "excerpt": "we used sklearn.utils.class_weight.compute_class_weight to compute class_weights based on the number of samples per class. \nWe used this as an argument to the models fit method as: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9429563426630097,
        0.9608424570042204
      ],
      "excerpt": "This argument means that classes with less samples in are prioritized and therefore has a higher impact on computing the gradient than the classes with more samples. \nInitially we experimented with different settings and hyper parameters and we eventually found out that: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8491862029853113,
        0.9518000306888682,
        0.9840832283697993
      ],
      "excerpt": "- We set too few of the layers to be trainable for a long time \n- In addition to this the imagedatagenerator also used a \"zoom\" augmentation which we eventually decided to drop as the images are cropped quite uniformly in a way that made the zoom potentially harmfull for performance. \nWith some intuition learned from our initial experiments we set out to try and replicate the success of how our first model managed to reach 89% accuracy on the validation set, only faster. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9877081312565087
      ],
      "excerpt": "We started of with training only the top layers for 5 epochs and then trained another 10 epochs after that when all the layers were set to be trainable. We left this to run overnight and woke up to great results the next day. The training flattened out in the end with a learning rate of 1e-4, but already at this point it managed to acheive 88% accuracy on the validation set in less than 12 hours of training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9945771204138008
      ],
      "excerpt": "Finally we picked up the training once more and ran the model for 5 more epochs with a learning rate of 1e-5. This time we set steps_per_epoch from 1000 to 5450 so that the model went through all 700 000 images per epochs. The risk of overfitting was still small due to the heavy augmentation from the imagedatagenerator, so this increased the validation accuracy by a few additinal percents to a new best of 92%, our final best. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9803852556920242
      ],
      "excerpt": "We executed the same code again, only this time without loading the weights from imagenet when creating the inceptionV3 model. Then we ran our code overnight for 12 epochs so we could compare the results with and without transfer learning from imagenet. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8974498755637536
      ],
      "excerpt": "Our findings show that there was a significant difference between loading the weights from imagenet or leaving the weights to random initialization. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9791831560129737
      ],
      "excerpt": "Under is a comparison of the two models: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.974109151359478
      ],
      "excerpt": "It seems to be quite evenly distributed on all the classes. Taking a closer look at the confusion matrix we see that the model has over 96% accuracy on the top 20 classes, and about 78% accuracy on bottom 5 classes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8990611574428802
      ],
      "excerpt": "The top 2 classes (Calanoida and Foraminifera) has an accuracy of 100% and the worst class (Calanidae) has an accuracy of 69% \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JakobKallestad/InceptionV3-on-plankton-images/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 16:00:34 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/JakobKallestad/InceptionV3-on-plankton-images/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "JakobKallestad/InceptionV3-on-plankton-images",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/Report.ipynb",
      "https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/src/inceptionV3_on_cifar10.ipynb",
      "https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/src/create_cifar10data_images.ipynb",
      "https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/src/plankton_v4.ipynb",
      "https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/src/running_cifar10_model_on_testset.ipynb",
      "https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/src/plankton_v4_test.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\nImage(url= \"https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/test_set_scores.png\")\n```\n\n\n\n\n<img src=\"https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/test_set_scores.png\"/>\n\n\n\n<br>\nThe model managed 91.78% accuracy on the test set which is only a 0.5% decrease from what we observed from the validation data during training.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.852585323816112
      ],
      "excerpt": "Here are a few magic cells to view our models history via tensorboard interface. The logs folders can be dowloaded from 'https://github.com/JakobKallestad/InceptionV3-on-plankton-images'. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9957206392490309
      ],
      "excerpt": ": !pip install tensorboard \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.846597662561316
      ],
      "excerpt": "Example images from the dataset after upscaling: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8606043043125918
      ],
      "excerpt": "Red = validation data, Blue = training data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8606043043125918
      ],
      "excerpt": "Red = validation data, Blue = training data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "train: 1000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8241143149479984
      ],
      "excerpt": "test: 51 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8606043043125918
      ],
      "excerpt": "Red = validation data, Blue = training data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8321066677145347
      ],
      "excerpt": ": Run this first: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/JakobKallestad/InceptionV3-on-plankton-images/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Exercise 1 report",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "InceptionV3-on-plankton-images",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "JakobKallestad",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JakobKallestad/InceptionV3-on-plankton-images/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 27 Dec 2021 16:00:34 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<br>\n\n",
      "technique": "Header extraction"
    }
  ],
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<br>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- In the beginning the model only went over __less than 1%__ of the entire training set per epoch and only the top layers were trainable. This is why there are so many epochs in the graph.  \n  \n- The first peak was when we decided to __unfreeze more layers__ than just the top layers of inception and made them trainable which increased accuracy from about 8% to about 15%.  \n  \n- The second peak was when we realized that it helped to __increase the batch size and steps_per epoch__ so that the model  over about 20% of the entire training set per epoch.  \n  \n- The last __giant peak__ happened as soon as we __unfroze all the layers__ of inception for training.  \n  \nAt this point we decided to start from scratch in order to try and recreate the very quick increase in accuracy that the model achieved by the end, but achieve this in less epochs.  \n  \n\n```python\n#: Initial experiments with a maximum of 89% accuracy:\nImage(url= \"https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/original_acc.png\")\n```\n\n\n\n\n<img src=\"https://raw.githubusercontent.com/JakobKallestad/InceptionV3-on-plankton-images/master/images/plankton/original_acc.png\"/>\n\n\n\nRed = validation data, Blue = training data\n<br>\n<br>\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1706.03762\n```\nAll the options are as follows:\n```\n-fp [--filepath]:       This is the path to the research paper. Can be URL (both abs and pdf links are supported",
      "https://arxiv.org/abs/1706.03762\n```\nAll the options are as follows:\n```\n-fp [--filepath]:       This is the path to the research paper. Can be URL (both abs and pdf links are supported"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/harshit158/paper-dots",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "**paperdotsai@gmail.com**",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-08T22:20:55Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-10T23:23:04Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8012285333485244,
        0.8535975820697713,
        0.8586660942344577
      ],
      "excerpt": "Paper Dots is an automatic insights extraction tool from research papers, which  \n* Automatically annotates a research paper PDF with important keyphrases, ensuring faster skim-reading of papers \n* Builds cumulative Knowledge Graph on top of papers read so far, helping in tracking important concepts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9255433400065523
      ],
      "excerpt": "The end-to-end pipeline is shown below: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9298508382961627
      ],
      "excerpt": "There are 3 main components to the project: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9658758378503868
      ],
      "excerpt": "Implemented using Constituency Parsing (using AllenNLP pretrained model) followed by a rule based engine to refine the extracted keyphrases   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8439045253892321
      ],
      "excerpt": "* Further division of identified keyphrases into domain specific entities like Datasets, References, Algorithms, Metrics etc \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8211374208230072,
        0.9455621891785688
      ],
      "excerpt": "2) Knowledge Graph construction \nImplemented using Open Information Extraction (OPENIE pretrained model from AllenNLP). Extracted SVO triplets followed by refining, to generate the final nodes and edges for the knowledge graph. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9404929966977168
      ],
      "excerpt": "The papers are sampled from Arxiv corpus (hosted on Kaggle). To enable semantic search over the papers, we had to first obtain the embeddings for each of the papers in the corpus, for which we used Sentence-Transformers. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8688347378265607
      ],
      "excerpt": "Once the corpus embeddings are in place, a new paper can be sampled from the corpus using the seed paper as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "|   |   \u251c\u2500\u2500 data \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/harshit158/paper-dots/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 20:28:16 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/harshit158/paper-dots/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "harshit158/paper-dots",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/harshit158/paper-dots/main/src/paper_sampler/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/harshit158/paper-dots/tree/main/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/harshit158/paper-dots/main/notebooks/app2%20%7C%20AllenNLP%20Constituency%20Parsing.ipynb",
      "https://raw.githubusercontent.com/harshit158/paper-dots/main/notebooks/app1%20%7C%20Tf-IDF.ipynb",
      "https://raw.githubusercontent.com/harshit158/paper-dots/main/notebooks/approaches.ipynb",
      "https://raw.githubusercontent.com/harshit158/paper-dots/main/src/encoding%20arxiv%20files.ipynb",
      "https://raw.githubusercontent.com/harshit158/paper-dots/main/src/app2%20%7C%20AllenNLP%20Constituency%20Parsing.ipynb",
      "https://raw.githubusercontent.com/harshit158/paper-dots/main/src/knowledge_graph.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9033987252512259
      ],
      "excerpt": "|   |   \u251c\u2500\u2500 requirements.txt \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8243815956836604
      ],
      "excerpt": "  <img  src=\"docs/pipeline.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8739891000537701
      ],
      "excerpt": "  <img  src=\"docs/annotated.png\" width=600> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8364927555346229
      ],
      "excerpt": "  <img  src=\"docs/knowledge_graph_demo.gif\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8564554080110327,
        0.8289669050403863
      ],
      "excerpt": "\u251c\u2500\u2500 tests \n\u251c\u2500\u2500 output \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9151270764930737,
        0.8759955720239709,
        0.9336801098518991,
        0.9336801098518991,
        0.9336801098518991,
        0.9336801098518991,
        0.9336801098518991,
        0.9336801098518991,
        0.9336801098518991,
        0.9336801098518991,
        0.9336801098518991,
        0.9586232994076559
      ],
      "excerpt": "\u251c\u2500\u2500 src \n|   \u251c\u2500\u2500 config.py \n|   \u251c\u2500\u2500 information_extraction.py \n|   \u251c\u2500\u2500 extractor.py \n|   \u251c\u2500\u2500 constituency_parser.py \n|   \u251c\u2500\u2500 mail_sender.py \n|   \u251c\u2500\u2500 model_loader.py \n|   \u251c\u2500\u2500 mongo_utils.py \n|   \u251c\u2500\u2500 paper_walk.py \n|   \u251c\u2500\u2500 task_keyphrase_extraction.py \n|   \u251c\u2500\u2500 task_knowledge_graph.py \n|   \u251c\u2500\u2500 utils.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9586232994076559
      ],
      "excerpt": "|   |   \u251c\u2500\u2500 paper_sampler.py \n|   |   \u251c\u2500\u2500 utils.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/harshit158/paper-dots/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "HTML",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Harshit Sharma\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# What is Paper Dots ?",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "paper-dots",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "harshit158",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/harshit158/paper-dots/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 20:28:16 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Currently, the end-to-end pipeline is only configured for personal use, but we are working on it to make it available for public.\nHowever, you can send a mail to **paperdotsai@gmail.com** with the link of your seed paper, and we will onboard you in the next iteration.\n\nThe individual tasks of the Information Extraction sub-pipeline, however, can be used as follows:\n\n**Keyphrase Extraction**:  \n```\npython task_keyphrase_extraction.py -fp https://arxiv.org/abs/1706.03762\n```\nAll the options are as follows:\n```\n-fp [--filepath]:       This is the path to the research paper. Can be URL (both abs and pdf links are supported) or local path\n-ca [--clip_abstract]:  If true, clips the annotated abstract as an image file and doesnt do the annotation of entire PDF\n-sa [--save_abstract]:  If true, saves the annotated image at ANNOTATE_FILEPATH in config\n```\n\n**Knowledge Graph**:  \n```\npython task_knowledge_graph.py -fp https://arxiv.org/abs/1706.03762\n```\nAll the options are as follows:\n```\n-fp [--filepath]:       This is the path to the research paper. Can be URL (both abs and pdf links are supported) or local path\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
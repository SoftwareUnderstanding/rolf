{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1807.03748. \n\nThe code here includes a minimal implementation of Contrastive Predictive Coding (CPC"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/gbarello/CPCLibriSpeech",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-09-22T17:49:50Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-03T03:16:12Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8034293214720752,
        0.9191870303157479
      ],
      "excerpt": "This repo is a simple implementation of the approach proposed by Oord et. al. in https://arxiv.org/abs/1807.03748.  \nThe code here includes a minimal implementation of Contrastive Predictive Coding (CPC) for the LibriSpeech dataset (the first experiment in the Oord et. al. paper) and a model which defaults to the same architechture used in Oord et. al.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.973460228514999
      ],
      "excerpt": "You may have to change the defaults in options.py to make it work on your machine. In particular, I am running on 2 RTX 2080 TI GPUs which allows me to use a batch size of 176 and train 30 epochs in about 12 hours, which is enough to obtain performance similar to Oord et. al. In order to train on more/fewer GPUs and with a larger/smaller batch size, edit the dev_list and batch_size parameters in options.py. You may also want to adjust other parameters such as num_workers which I set to the number of processors on my machine. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A lightweight implementation of Contrastive Predictive Coding (CPC)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/gbarello/CPCLibriSpeech/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sat, 25 Dec 2021 08:38:04 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/gbarello/CPCLibriSpeech/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "gbarello/CPCLibriSpeech",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/gbarello/CPCLibriSpeech/master/setup.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9307010371656637
      ],
      "excerpt": "I have included a .yml file here for the environment I used to create and run this repo. I make no promises that it is at all minimal... but you can use it to recreate my environment if you like. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9026092508428294
      ],
      "excerpt": "In order to setup and run the code, first run setup.sh to download the data and create the nessecary folders. Then you can run train.py from the root directory of the repo and it should just work. The code will create a ./models/ folder and each run of train.py will create a new subfolder there (named by timestamp). Finally, to test your model after training, run test.py ./models/{model_timestamp}/ in order to calculate the linear separablity of speakers in your models learned representation, and a t-SNE plot of the recurrent and feedforward embeddings colored by speaker. i.e. run: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503189345333785,
        0.9498349058810335
      ],
      "excerpt": "$python train.py \n$python test.py ./models/{model_timestamp} \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/gbarello/CPCLibriSpeech/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Representation Learning with Contrastive Predictive Coding",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "CPCLibriSpeech",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "gbarello",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/gbarello/CPCLibriSpeech/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Sat, 25 Dec 2021 08:38:04 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "With the default parameters given here, I acheive results similar to those of Oord et. al. In particular, my linear separability scores for speakers are as follows (LogisticRegression is fit using 10\\% of the test data, and tested on the remaining 90\\%):\n\nEmbedding | Test Score | Train Score\n------------ | ------------- | ---------------\nRecurrent | 97.2% | 99.9%\nFeedforward | 37.5% | 52.6%\n\nHere is a sample t-SNE plot of a default run using this repo (and default t-SNE parameters from sklearn). It is created using only 18 speakers (10\\% of the 360-hour dataset, this fraction is also adjustable in `options.py`):\n\n<img src=\"./assets/tsne_embedding.jpg\" alt=\"tsne embedding\" width=\"600\"/>\n",
      "technique": "Header extraction"
    }
  ]
}
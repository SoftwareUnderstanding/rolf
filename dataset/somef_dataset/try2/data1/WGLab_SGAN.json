{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1406.2661",
      "https://arxiv.org/abs/1606.03498"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] https://github.com/etaoxing/semi-supervised-gan\n\n[2] https://github.com/opetrova/SemiSupervisedPytorchGAN\n\n[3] https://arxiv.org/abs/1606.03498\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/WGLab/SGAN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-01T04:08:09Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-14T01:52:41Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.982471194682671,
        0.9837157516023068
      ],
      "excerpt": "In this pilot study, we present a semi-supervised learning model to solve the classification problem with insufficient label data. The result indicates that the predictive performance is slightly improved compared to the existing softwares using 4,000 labeled data and 60,000 unlabeled data. \nOur semi-supervised model is based on unsupervised Generative Adversarial Networks (GANs). Goodfellow et. al firstly proposed GAN. GANs contain 2 parts: (1) generator and (2) discriminator. In a standard training process, the generator generated fake samples from noise vectors, and then, the discriminator is to distinguish whether the input sample is fake or real. The generator is supposed to fool the discriminator, which means the generator is trained to fit the underlying probability density function of real data.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9907960858609383
      ],
      "excerpt": "In our study, we can assume that the input data (interpretation scores from different guidelines and softwares) follows an unknown distribution (grep points). Then, the discriminator is to classify the data into 3 parts: benign (red point), oncogenic (blue point), and fake. Once the generator has been trained to generate synthtic samples following the underlying distribution, the discriminator can tell us the border of benign/oncogenic class with a small number of labeled data. The detail of our model is shown following: \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/WGLab/SGAN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Fri, 24 Dec 2021 04:56:43 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/WGLab/SGAN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "WGLab/SGAN",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/WGLab/SGAN/main/train.ipynb",
      "https://raw.githubusercontent.com/WGLab/SGAN/main/myLibs/feature_preprocess.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/WGLab/SGAN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Model performance and interpretability of semi-supervised generative adversarial networks to predict oncogenic variants with unlabeled data",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SGAN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "WGLab",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/WGLab/SGAN/blob/main/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We used conda to build environment and the code is implemented in Pytorch. You can train a model on jupyter notebook.\n\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 04:56:43 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Predicting meaningful events in the car racing footage using three-path approach. \n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1610.06906.pdf",
      "https://arxiv.org/abs/1708.02002"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Project team:\n* [Dmitry Soshnikov](https://github.com/shwars)\n* [Yana Valieva](https://github.com/vJenny)\n* [Tim Scarfe](https://github.com/ecsplendid)\n* [Evgeny Grigorenko](https://github.com/evgri243)\n* [Victor Kiselev](https://github.com/Gaploid)",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9255750022345589,
        0.9606143883081296,
        0.9979395704774404
      ],
      "excerpt": "Two-stream ConvNets for Action Recognition in Videos\u200b by Keren Simonyan, Andrew Zisserman \nReview of Action Recognition and Detection Methods\u200b by Soo Min Kang, Richard P. Wildes \nFocal Loss for Dense Object Detection\u200b by Tsung-Yi Lin, et. al. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9847549328295826
      ],
      "excerpt": "mv keras-retinanet/keras_retinanet/ race-events-recognition/research/retina/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9709277623234582
      ],
      "excerpt": "* Visual Studio 2017 Version 15.7.4 or Newer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8250738964239975
      ],
      "excerpt": "useful temporal information about scene structure. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sulasen/race-events-recognition-1",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-14T14:35:47Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-11-05T21:22:02Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This project is dedicated to the investigation of methods for predicting\nmeaningful events in footage of car racing. This repository is focused on the\nexploration of **collision detection** but contains a tool for the classification of  as well. During the work on this project we've also developed a\n**monadic pipeline** library [mPyPl](https://github.com/shwars/mPyPl) to\nsimplify tasks of data processing and creating complex data pipelines.   \nDue to the small amount of data in this problem; we could not rely on neural\nnetworks to learn representations as part of the training process. Instead; we\nneeded to design bespoke features, crafted with domain knowledge. After series\nof experiments, we've created a model based on features obtained using three\ndifferent approaches: \n\n* Dense Optical Flow\n* VGG16 embeddings \n* A special kind of Optical Flow - [Focused Optical Flow](#focused-optical-flow).  \n\n\n\u2139\ufe0f *After the release of mPyPl as a independent [pip-installable framework](https://pypi.org/project/mPyPl/), some experimental notebooks in the ```notebooks``` folder have not been updated, but may contain interesting things to explore.*\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9629962971611608,
        0.9968029537584643
      ],
      "excerpt": "Project   \nTable of Contents   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8439327219057434,
        0.871686181831332
      ],
      "excerpt": "Using Optical Flow for Stabilizing Image Sequences by Peter O\u2019Donovan \nOur solution consists of the three main paths (see illustration below). A video \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.826336967531451,
        0.8811324777057469
      ],
      "excerpt": "described in details in the Experiments section. Each output of \nthe three paths is processed by a separate neural network and then the results \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9926578598651804
      ],
      "excerpt": "This project was preceded by another one dedicated to the detection of racing cars using RetinaNet. RetinaNet was trained on Azure Batch AI using Horovod for distributed training. In the near future, we plan to implement the model inference using Azure Batch to reduce the time spent on video processing. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9235221704966612
      ],
      "excerpt": "In addition to the standard set of data science packages, we've used the following: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8918714504612804
      ],
      "excerpt": "* keras-retinanet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9730387266323969
      ],
      "excerpt": " and clone all the content of keras-retinanet repository to research/retina folder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9979103338483112
      ],
      "excerpt": "Our Dense Optical Flow approach originated from this tutorial. It is a complete vector field showing movement of every pixel between frames\u200b. Such features can show not only changes in the movement of the car, but also the style of the camera operator, which may be different during a normal race and an accident.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8306140272984255
      ],
      "excerpt": "In general, the process consists of the following steps:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9903391640058182
      ],
      "excerpt": "The strategy of Sparse Optical Flow is based on the same example. The main idea was to use the changes in the trajectory of a car as input features for the model. Our experiments showed that the flow for normal situation is different from the flow when an accident occurs.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9940579075498733
      ],
      "excerpt": "On the other hand, sometimes the standard Optical Flow approach tracks anything but the cars. The Optical Flow algorithm starts with detection of good features to track (regardless of the semantic of the frame) - just edge detection. Therefore, sometimes we do not get the flow of a car, but something extraneous. On the picture below, the algorithm is trying to track the scoreboard.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8106347717512123,
        0.9834660756360482
      ],
      "excerpt": "The improved Focused Optical Flow algorithm helps us to eliminate this drawback. \nThe main idea of the Focused Optical Flow is based on providing the standard Optical Flow algorithm with the correct areas of interest. For this purpose, we use a trained RetinaNet object detector. Focusing on the detected areas with cars, the algorithm can select appropriate points for tracking.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9559253015546275
      ],
      "excerpt": "So, the whole pipeline for the Focused Optical Flow looks is shown on the figure below and in general, the post-flow steps are similar to the Dense Flow approach: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9788844028897374,
        0.9586835019202552,
        0.9302325818121191,
        0.9805207183342558,
        0.8618542233877825
      ],
      "excerpt": "Matrix of cosines of \nnormalized VGG16 embeddings frames as a 2d feature for a CNN encoder. \nTheoretically; it's telling us about the regionality and structure of the video \nas a function of co-activation in the convolved embedding space. We intend to \nuse this an additional input to the overall model as it will likely capture some \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9905128303785844,
        0.894425827398959,
        0.9500223806996895
      ],
      "excerpt": "In this case we use pretrained VGG16 model to extract features for each frame of the video. After extraction, the features are stacked into two-dimensional vectors and fed into the CNN. \nThe application gives you the ability to score images and video files frame by frame based on onnx model. The model was trained using Custom Vision service and exported to be used in UWP APP written on C#. The app is based on example of Windows ML SDK from and extended to use with video files. \nThere are 6 different classes the model works with:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Predicting meaningful events in the car racing footage",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sulasen/race-events-recognition-1/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Tue, 21 Dec 2021 07:21:00 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sulasen/race-events-recognition-1/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "sulasen/race-events-recognition-1",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/video-pipeline.ipynb",
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/combined-training.ipynb",
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/notebooks/dense-flow-training.ipynb",
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/notebooks/optical-flow-training.ipynb",
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/notebooks/Basic%20Driver%20Notebook%20With%20DataStreams%20Class.ipynb",
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/notebooks/Tim%20DenseFlow%2B3dcnn.ipynb",
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/notebooks/video-prep.ipynb",
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/notebooks/DenseOpticalFlow.ipynb",
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/notebooks/Self%20Similarity%20Concept.ipynb",
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/notebooks/augmentation-idea.ipynb",
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/notebooks/Tim%2BMitya%20DenseFlow.ipynb",
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/notebooks/Basic%20Augmentation%20Run%2C%20Cleaner%20Code.ipynb",
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/notebooks/Test%20Driver.ipynb",
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/notebooks/optical-flow%2Bretina.ipynb",
      "https://raw.githubusercontent.com/sulasen/race-events-recognition-1/master/notebooks/optical-flow-investigation.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9143054177750861
      ],
      "excerpt": "* opencv-python \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9753178034688874,
        0.9979947896609701
      ],
      "excerpt": "To successfully run the collision recognition examples, you need to install all the requirements using  \npip install -r requirements.txt  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9893272198983933
      ],
      "excerpt": "git clone https://github.com/fizyr/keras-retinanet.git \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8295909406355624
      ],
      "excerpt": "To run the scene detection example, you need to have installed: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8968590870080099,
        0.9331645822748573
      ],
      "excerpt": "* Windows 10 - Build 17738 or higher \n* Windows SDK - Build 17738 or higher \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8099778987442274
      ],
      "excerpt": "<img src=\"content/ml-workflow.png\" height=\"450\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8532234492043306
      ],
      "excerpt": "  <img src=\"content/ml-cloud.png\" height=\"250\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.862451994106597
      ],
      "excerpt": "  <img src=\"content/dense1.jpg\" height=\"82\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.862451994106597
      ],
      "excerpt": "  <img src=\"content/dense2.jpg\" height=\"82\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.862451994106597
      ],
      "excerpt": "  <img src=\"content/dense3.jpg\" height=\"82\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8811284606866708
      ],
      "excerpt": "  <img src=\"content/denseflow.png\" height=\"110\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9135648424682137
      ],
      "excerpt": "  <img src=\"content/optical1.jpg\" height=\"100\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9135648424682137
      ],
      "excerpt": "  <img src=\"content/optical2.jpg\" height=\"100\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8950611634577968
      ],
      "excerpt": "  <img src=\"content/optical3.jpg\" height=\"102\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8950611634577968
      ],
      "excerpt": "  <img src=\"content/optical4.jpg\" height=\"102\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8811284606866708
      ],
      "excerpt": "  <img src=\"content/focusedflow.png\" height=\"110\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sulasen/race-events-recognition-1/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "C#"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Copyright (c) 2018 Yana Valieva,  Dmitry Soshnikov, Tim Scarfe, Victor Kiselev\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Race Events Recognition",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "race-events-recognition-1",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "sulasen",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sulasen/race-events-recognition-1/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 07:21:00 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* The **training** process is described in the ```combined-training.ipynb``` notebook. \n* To run the **inference** process use the ```video-pipeline.ipynb``` notebook.\n* All the working notebooks with our **experiments** are in ```notebooks``` folder (even though some notebooks are outdated, they contain interesting ideas).\n* The ```research``` folder contains our main **python modules**.  \n* The ```utils``` folder contains different **useful things** (e.g. visualization tools). \n\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1609.04802",
      "https://arxiv.org/abs/1609.04802",
      "https://arxiv.org/abs/1609.04802"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9999999999968168
      ],
      "excerpt": "Generator and Discriminator in SRGAN. Ledig, Christian, et al. \"Photo-realistic single image super-resolution using a generative adversarial network.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2017(https://arxiv.org/abs/1609.04802). <br> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pohwa065/SRGAN-for-Super-Resolution-and-Image-Enhancement",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-28T21:19:59Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-25T06:46:01Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.986276689513374,
        0.9467666380747478,
        0.841321545453199
      ],
      "excerpt": "A Tensorflow implementation of SRGAN based on CVPR 2017 paper Photo-realistic single image super-resolution using a generative adversarial network to generate high resolution (HR) images from low resolution (LR) image. In this work, we use SRGAN to up-scale 32x32 images to 128x128 pixels. Meanwhile, we evaluate the impact of different camera parameters on the quality of final up-scaled (high resolution) images and infer from these stimuli to understand what the network is able to learn. \nData processing and model training pipeline: Original image is processed with different camera parameters using ISET Camera Designer. These images are resized to 32x32x3 and served as the (LR) input to the generator. The target HR images are the original ones which are not processed. Total four models were trained:<br> \nModel_SR: SRGAN model that does super resolution only <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9573984161342045,
        0.8324453375578051
      ],
      "excerpt": "Model_SR_Pixel: SRGAN model that does super resolution and restore spatial resolution due to reduction of system MTF <br>  \nModel_SR_Deblur: SRGAN model that does super resolution and deblur<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9189888811926787
      ],
      "excerpt": "Camera setting 2- F/4; aperture diameter: 1mm, pixel size: 25umx25um. In general, large pixel size is desirable because it results in higher dynamic range and signal-to-noise ratio. However, the reduction in spatial resolution and system MTF introduce severe pixelated effect <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.806470792029946,
        0.9461359730459719,
        0.9245359701586084,
        0.8596916148592725
      ],
      "excerpt": "About 100 images, not necessarily cats and dogs, are used for evaluation. As an input to four trained models (Model_SR, Model_SR_Color, Model_SR_Pixel, and Model_SR_Deblur), these images went through the same camera settings and resized to 32x32x3 similar to the training dataset. \nIn this work, we use Tensorflow implementation of \"Photo-realistic single image super-resolution using a generative adversarial network.\". Small modifications in are done as follows:<br> \nPixelShuffler x2: This is for feature map upscaling. We use 2x \u2018deconv2d\u2019 Keras built-in function for implementation. <br> \nPRelu(Parameterized Relu): PRelu introduces learnable parameter that makes it possible to adaptively learn the negative part coefficient. We use Relu as activation function for simplicity. <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9641327435804706
      ],
      "excerpt": "We use as evaluation matrix of image quality. S-CIELAB is an extension of the CIE Lab* DeltaE color difference formula and provides human spatial sensitivity difference between a reference and a corresponding test image. The key components of calculating S-CIELAB representation include color transformation and the spatial filtering steps that simulates the human visual system before the standard CIELAB Delta E calculations.<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9746310260328737
      ],
      "excerpt": "SRGAN model is able to deal with missing/noise pixels (about 10% in our experiment) and generate HR images not only have smooth edges but also restore the details. <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8675666497593194,
        0.9023442963599277,
        0.9213022639053479,
        0.9622486756118993,
        0.9735136454041661
      ],
      "excerpt": "The following matrices summarize the results from all four trained SRGAN models. The 'input' rows shows the input LR images (original and processed images using three different camera settings as described in method section). Each cell in the matrix represent the result HR images generated by a given model from a given input LR. For example, in the each 4x4 matrix, the 3rd row, 2nd column image is the result generated by Model_SR_Pixel using LR images processed by camera setting1. It is obvious that the images in the diagonal have higher qualities (closer to the target images) compared with the off-diagonal images because these are how the models were originally trained for.<br> \nModel_SR: this model is trained to perform super resolution only. As expected, the result looks simply upscaled without changing other characteristics of the input images such as color and focus.<br> \nModel_SR_Color: the outline and details looks similar to Model_SR. Also, because this model is trained to do color correction, the color tone is different between the input and output images (becomes 'brighter' in general).<br> \nModel_SR_Pixel: unlike Model_SR and Model_SR_Color, result from this model looks relatively un-natural. However, when the input image is from camera setting 3 (reduction of system MTF due to large sensor pixel), the resulting HR image improved a lot - it learns how to restore spatial resolution to some extent.<br> \nModel_SR_Deblur: This model successfully learned how to de-blur. It is also interesting that all of its output images seems to remain in good focus regardless whether the input image is within/out of focus.<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9976440785611255
      ],
      "excerpt": "The S-CIELAB delta E maps show the difference between target images and the model generated images. Consider these difference as 'residue' (mainly at the edges) that the model can improve, it might be interesting in future work to replace/add S-CIELAB representation to the generator's loss function. The reason being, one of the major changes that a more advanced version of SRGAN model (called Enhanced SRGAN, SRGAN) have done is to use feature maps before activation for calculating content loss. As we extract feature maps from relatively deep layer in VGG19 layer, some of the features after activation becomes inactive and contains fewer information. It is possible that S-CIELAB can provide additional information, especially from human spatial sensitivity point of view, to the generator during training and create a new class of super resolution images that focus more on how accurate the reproduction of a color is to the original when viewed by a human observer.<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Super-Resolution Generative Adversarial Networks (SRGAN) is a deep learning application to generate high resolution (HR) images from low resolution (LR) image. In this work, we use SRGAN to up-scale 32x32 images to 128x128 pixels. Meanwhile, we evaluate the impact of different camera parameters on the quality of final up-scaled (high resolution) images and infer from these stimuli to understand what the network is able to learn.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pohwa065/Deep-Learning-for-Super-Resolution-and-Image-Enhancement/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 26 Dec 2021 16:02:58 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/pohwa065/SRGAN-for-Super-Resolution-and-Image-Enhancement/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "pohwa065/SRGAN-for-Super-Resolution-and-Image-Enhancement",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8162987094898027
      ],
      "excerpt": "Camera setting 3- F/22; aperture diameter: 0.176mm; pixel size: 1umx1um. Images looks much blurry compared with original images because they becomes diffraction limited at small aperture value <br> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/pohwa065/SRGAN-for-Super-Resolution-and-Image-Enhancement/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SRGAN-for-Super-Resolution-and-Image-Enhancement",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SRGAN-for-Super-Resolution-and-Image-Enhancement",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "pohwa065",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pohwa065/SRGAN-for-Super-Resolution-and-Image-Enhancement/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Sun, 26 Dec 2021 16:02:58 GMT"
    },
    "technique": "GitHub API"
  }
}
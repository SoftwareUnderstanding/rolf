{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1706.08500",
      "https://arxiv.org/abs/1706.08500\n\nhttps://www.tensorflow.org/tutorials/generative/dcgan\n\nhttps://www.kaggle.com/spandan2/cats-faces-64x64-for-generative-models\n\nhttps://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/\n\nhttps://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "https://arxiv.org/abs/1706.08500\n\nhttps://www.tensorflow.org/tutorials/generative/dcgan\n\nhttps://www.kaggle.com/spandan2/cats-faces-64x64-for-generative-models\n\nhttps://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/\n\nhttps://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/candicexxx-droid/PIC16B---GAN-Project-",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-16T02:27:11Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-14T06:59:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9567036922407235,
        0.8912168717851779,
        0.8234787019054183,
        0.9246498112279765,
        0.9159890612514521,
        0.8069888594559725
      ],
      "excerpt": "Our project implements a deep convolutional adversarial network (DCGAN) using \nthe keras library. The DCGAN is made by creating a generator and discriminator \nmodel. The generator takes a random noise vector and creates artificial images, while the discriminator acts as \na binary classifier during the training process to improve generators' performance. As the model trains, both the generator and discriminator \nweights are updated as they approach an equilibrium. To aid the models in \nreaching an equilibrium, each model was trained with a different learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9338474769866293
      ],
      "excerpt": "We trained our model on a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9247242187276153,
        0.8888689396499201
      ],
      "excerpt": "model took about 4 hours with 500 epochs. \nOur DCGAN model follows the standard model structure from the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9684146619161472,
        0.884398419899563,
        0.8798564761188671
      ],
      "excerpt": "The generator model takes an input noise vector of shape (100,) and maps it to \nan array with same shape as the training data (64,64,3). The generator model \nstarts with a dense layer, followed by 4 Conv2D Transpose layers that map an \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9203388792272205,
        0.8256881813500503,
        0.9613195696884336,
        0.9523404153414978,
        0.910867636157511,
        0.8951953731764837,
        0.8625986803873663
      ],
      "excerpt": "generator model can be found in the 'generator_model' method under the GAN \nclass definition from gan.py. The discriminator model is a binary classifier \nthat takes an input image of shape (64,64,3) and maps it to a number from 0 to 1. \nThe output value that is more closer to 1 means the input image is more \nlikely to be a 'real' image instead of a generated one. Hence, the \ndiscriminator model is made up of 5 Conv2D layers and a final dense layer. Its \ndefinition can be found in the 'discriminator_model' method under the GAN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9329199021861448
      ],
      "excerpt": "In a single training iteration, we firstly fix parameters of the generator we \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8947832874680798
      ],
      "excerpt": "optimization goal for discriminator is to train it to produce accurate \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9464780947426477,
        0.9309563593298835
      ],
      "excerpt": "better at distinguishing real and fake data, which also forces the generator \nto produce images that resemble more to the training data.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9101923818435056
      ],
      "excerpt": "The gif above shows our training process from epoch 5 to epoch 500. We could \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9650843053418873
      ],
      "excerpt": "To evaluate our GAN model, we applied the Frechet Inception Distance (FID). FID  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8972360776346419,
        0.9382998421380533,
        0.9803338650176352,
        0.9321824017580832
      ],
      "excerpt": "Frechet Inception Distance as described in the GANs Trained by a Two Time-Scale Update RuleConverge to a Local Nash Equilibrium \n,as an improvement for Inception Score. According to the paper, the distributions  \nof real data and generated data are assumed to follow a Gaussian distribution. \nHence, FID is a way of quantifying the difference between the two distributions. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8227732276502321,
        0.8022350514686069
      ],
      "excerpt": "real-world images. The formula for FID calculation, proposed by the paper,  \nis presented as follows, <br /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.853205173179296,
        0.987766597233973,
        0.9456017110455328
      ],
      "excerpt": "Before we dive into the FID score for generated images, following the appendix \nsection on FID score of the paper mentioned above, we studied how FID score \nchanges if we add different types of random noise to our own training data. We \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9108906904851556
      ],
      "excerpt": "random rectangles. All types of random noise are applied with different noise \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9861210777261831
      ],
      "excerpt": "applied 4 types of noise with different alpha values to all of our training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8693129095947177,
        0.8159933542995353
      ],
      "excerpt": "general, FID score increases as we increase alpha, which indicates that the \ndistribution of data with higher noise level has a much higher difference from \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.9211716728437582,
        0.875043247403637
      ],
      "excerpt": "data.  \nFID is evaluated for upper left: Gaussian noise\uff08choices of alpha: 0, 0.1, 0.25, 0.3, 0.4\uff09\\ \nupper right: Gaussian blur\uff08choices of alpha: 0, 1, 3, 4\uff09\\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8556310475749929,
        0.9939415472491284,
        0.9462271060143483
      ],
      "excerpt": "The disturbance level rises from zero and increases to the highest level. The FID captures the disturbance level very well by monotonically increasing. \nWe want to explore how FID score improves throughout training. We saved the generator models to calculate FID scores every 10 epochs. Hence, we obtained the graph below, where we see a desirable decrease in FID score, meaning that our generated data got closer to the distribution of the training data. Throughout training, the lowest FID score we obtained was 466, and the FID score for our final model is 676.094.  <br /> \nThe grid below shows how our generator model reacts to different inputs. Our generator model takes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9223775362361899
      ],
      "excerpt": "The GAN class is contained in the gan.py file. The following is a list of  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9550548811505056
      ],
      "excerpt": "summary() outputs a summary of GAN model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9265268228453597
      ],
      "excerpt": "FID(sample_size) evaluates the current generator model with the frechet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.871595037484384
      ],
      "excerpt": ": Prints the generator, discriminator, and GAN model summary \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8105091997988193
      ],
      "excerpt": ": print a summary of the generator, discriminator, and GAN model \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/candicexxx-droid/PIC16B---GAN-Project-/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sat, 25 Dec 2021 11:28:29 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/candicexxx-droid/PIC16B---GAN-Project-/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "candicexxx-droid/PIC16B---GAN-Project-",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8880156814830243
      ],
      "excerpt": "containing 15.7k images. Training the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8789613112270642
      ],
      "excerpt": "an array with same shape as the training data (64,64,3). The generator model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8614354933701942
      ],
      "excerpt": "input array of a smaller shape to an output array of a larger shape. The \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9062662487934794
      ],
      "excerpt": "noise_function.py, and test.py implements noise_function.py on our training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8036275422726289
      ],
      "excerpt": "an input vector containing 100 random variables initialized with a normal \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.835383114650485,
        0.8442399757794723
      ],
      "excerpt": "plot_generated_images(filename) plots a 4x4 grid of images generated by the \nmodel at filename \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9103404390245281
      ],
      "excerpt": "The main.py file demostrates how to load a previously trained GAN model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8147904644096936
      ],
      "excerpt": ": Load last trained model to skip training time \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8164291057946097
      ],
      "excerpt": ": save a 4x4 grid of images generated by the model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9300230330223704
      ],
      "excerpt": "The training.py file demonstrates how to create a model with specified \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8044290599680651
      ],
      "excerpt": "BATCH_SIZE = 128 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8120016068207946
      ],
      "excerpt": ": training the model from scratch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8164291057946097
      ],
      "excerpt": ": save a 4x4 grid of images generated by the model \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/candicexxx-droid/PIC16B---GAN-Project-/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "PIC16B GAN Project - Implementation of Generative Adversarial Neural Network (GAN) on Cat Dataset",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "PIC16B---GAN-Project-",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "candicexxx-droid",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/candicexxx-droid/PIC16B---GAN-Project-/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 11:28:29 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The following examples demonstrate how to use the GAN class. \n\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "citation": [
    {
      "confidence": [
        0.9999643494502671,
        0.9999859995280455,
        0.9957691784014127
      ],
      "excerpt": "If you find that this work has been useful for your research, please consider citing the following works: \nDolz J, Gopinath K, Yuan J, Lombaert H, Desrosiers C, Ben Ayed I. \"HyperDense-Net: A hyper-densely connected CNN for multi-modal image segmentation.\" IEEE TMI. 2018 Oct 30.Link \nDolz J, Desrosiers C, Wang L, Yuang J, Shen D, Ben Ayed I. \"Isointense Infant Brain Segmentation with a Hyper-dense Connected Convolutional Neural Network\". IEEE International Symposium on Biomedical Imaging (ISBI), 616-620 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9186665153711271
      ],
      "excerpt": "April,17th. 2018 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/josedolz/HyperDenseNet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-02-15T02:30:57Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-26T09:23:27Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9333371098448732
      ],
      "excerpt": "This repository will contain the code of HyperDenseNet, a hyper-densely connected CNN to segment medical images in multi-modal image scenarios. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9606801186942551
      ],
      "excerpt": "A detail of a section of the proposed HyperDenseNet. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8680150800423752
      ],
      "excerpt": "Imagine that after two days of training your model, and just before you have your new model ready to be evaluated, your computer breaks down. Do not panic!!! You will have only to re-start the training from the last epoch in which the model was saved (Let's say epoch 20) as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.892994383843448
      ],
      "excerpt": "HyperDenseNet processes multi-modal data in different branches which are densely connected (so far only two-modalities). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9489175809933016
      ],
      "excerpt": "Some qualitative results of the proposed HyperDenseNet compared to some baselines. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9894300364629931
      ],
      "excerpt": "Analysis of features reuse in the case of two image modalities. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This repository contains the code of HyperDenseNet, a hyper-densely connected CNN to segment medical images in multi-modal image scenarios.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/josedolz/HyperDenseNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 40,
      "date": "Sun, 26 Dec 2021 21:33:07 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/josedolz/HyperDenseNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "josedolz/HyperDenseNet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9225982373689515
      ],
      "excerpt": "A new pytorch version has been implemented here \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8790807899697968
      ],
      "excerpt": "To start with your own architecture, you have to modify the file \"LiviaNET_Config.ini\" according to your requirements. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.829485268091688
      ],
      "excerpt": "If you use GPU, after nearly 5 minutes you will have your trained model from the example. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9717106327039013
      ],
      "excerpt": "Version 1.0.  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8170567354422352
      ],
      "excerpt": "This will save, after each epoch, the updated trained model. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/josedolz/HyperDenseNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright (c) 2018 Jose Dolz\\n\\n  Permission is hereby granted, free of charge, to any person\\n  obtaining a copy of this software and associated documentation\\n  files (the \"Software\"), to deal in the Software without\\n  restriction, including without limitation the rights to use, copy,\\n  modify, merge, publish, distribute, sublicense, and/or sell copies\\n  of the Software, and to permit persons to whom the Software is\\n  furnished to do so, subject to the following conditions:\\n\\n  The above copyright notice and this permission notice shall be\\n  included in all copies or substantial portions of the Software.\\n  \\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\\n  EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\\n  OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\\n  NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\\n  HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\\n  WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\\n  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\\n  OTHER DEALINGS IN THE SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "HyperDenseNet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "HyperDenseNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "josedolz",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/josedolz/HyperDenseNet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- The code has been written in Python (2.7) and requires [Theano](http://deeplearning.net/software/theano/)\n- You should also have installed [scipy](https://www.scipy.org/)\n- (Optional) The code allows to load images in Matlab and Nifti formats. If you wish to use nifti formats you should install [nibabel](http://nipy.org/nibabel/) \n- Since, as you might now, sharing medical data is not a good-practice, I did not include any sample in the corresponding folders. To make your experiments you must include your data in the repositories indicated in the config file (LiviaNET_Config.ini and LiviaNET_Segmentation.ini)\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Running the code actually works in the same way that LiviaNet. Just a reminder if you do not want to check the documentation from that net :)\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 132,
      "date": "Sun, 26 Dec 2021 21:33:07 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "cnn",
      "fcn",
      "3d-cnn",
      "convolutional-neural-networks",
      "hyperdensenet",
      "medical-image-processing",
      "segmentation",
      "image-segmentation",
      "deep-learning",
      "deep-neural-networks",
      "theano",
      "segment-medical-images",
      "3d-convolutional-network",
      "deep-learning-algorithms",
      "brain-segmentation",
      "multi-modal-imaging",
      "densenet",
      "neural-networks",
      "medical-image-analysis",
      "medical-image-segmentation"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Once you are satisfied with your training, you can evaluate it by writing this in the command line:\n\n```\npython ./networkSegmentation.py ./HyperDenseNet_Segmentation.ini ./outputFiles/HyperDenseNet/Networks/HyperDenseNet_EpochX\n```\nwhere X denotes the last (or desired) epoch in which the model was saved.\n\n",
      "technique": "Header extraction"
    }
  ]
}
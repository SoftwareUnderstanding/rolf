{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1809.07454\n[SI SDR]: https://arxiv.org/pdf/1811.02508.pdf\n[Authors]: https://github.com/kaituoxu/Conv-TasNet\n[Naplab]: https://github.com/naplab/Conv-TasNet\n[Jhuiac]: https://github.com/jhuiac/conv-tas-net\n\n## Authors\n\n- [Felix MICHAUD]\n- [Yliess HATI]\n- [Clement DUHART]\n\n[Felix MICHAUD]: https://github.com/FelixMichaud\n[Yliess HATI]: https://github.com/yliess86\n[Clement DUHART]: https://github.com/slash6475"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8634844918850189
      ],
      "excerpt": "    epochs=10,                        #: number of epoch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008247398284739,
        0.8008247398284739
      ],
      "excerpt": "Naplab - Github repository \nJhuiac - Github repository \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mitmedialab/WetlandAvianSourceSeparation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-19T19:41:58Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-01-27T15:30:46Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9826684767468179,
        0.8878265873239166
      ],
      "excerpt": "The repository is currently under development. \nThe Dataset is a simple class inheriting from torch.util.data.Dataset. It provides access to its length and items through a pythonic API. The class also offers ways to generate the Dataset, either from a configuration file (see Configuration section) or from default values (see code). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9707271716724744,
        0.8927661244042594
      ],
      "excerpt": "The Dataset is generated out of birds and ambient samples. Those samples are  \navailable in the data folder and contains ten bird species: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8979411005071259,
        0.94332824909102,
        0.94332824909102
      ],
      "excerpt": "    \"data/birds\", \n    \"data/ambient\", \n    label_size=(0, 8),         #: Range of samples for birds \n    ambient_size=(0, 2),       #: Range of samples for ambient \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8583909908752696
      ],
      "excerpt": "    focus=None                 #: Ability to extract list of labels only \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8979411005071259
      ],
      "excerpt": "label_directory: data/birds \nambient_directory: data/ambient \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9377155561158124
      ],
      "excerpt": "Training is performed through the use of the Solver class. The solver takes care of every part of the training, including: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9701037701337296
      ],
      "excerpt": "- Initializing the Model, Criterion, and Optimizer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9657275366828291
      ],
      "excerpt": "This is performed using configuration files, one for training information (see below in the Configuration section) that itself refers to the second concerning the Dataset Composer configuration (see above in the Dataset Section for this one). This choice allows for great flexibility for running different experiments with different parameters. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9533202805746719
      ],
      "excerpt": "As mentioned above, the solver uses the configuration in the same way the dataset generation is handled. The training configuration file contains all hyperparameter fields for training. Mapping with different ComposerConfig files is enabled for modularity. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8769304940127091
      ],
      "excerpt": "    n_workers=4,                      #: number of worker for dataloader \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9620180677024125,
        0.841829821505632,
        0.8989442715878023,
        0.9604230245505255
      ],
      "excerpt": "Inference is part of the repository for demonstration purposes. If you want to use a trained model prefer to export the model as a torch.script file using the provided (TODO) JIT compile and quantizer tool. This will allow you to use the model outside of the repository scope (see Optimization section TODO). \nNeverthless demo script is available for you to try a freshly trained model by providing the model path, the audio mixture path and the destination path to save the results as wave files (see above ath the begining of usage section). \nThis section is under development. \n[Conv-TasNet] - TasNet: Surpassing Ideal Time-Frequency Masking for Speech Separation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8716692804739435,
        0.8716692804739435,
        0.8716692804739435
      ],
      "excerpt": "Authors - Github repository \nNaplab - Github repository \nJhuiac - Github repository \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mitmedialab/unet4birds/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 30 Dec 2021 01:32:49 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mitmedialab/WetlandAvianSourceSeparation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "mitmedialab/WetlandAvianSourceSeparation",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To install all the necessary dependencies for this repository install all the python libraries using the `pip` command *(may require the use of sudo)*:\n```bash\n$ pip3 install -r requirements.txt\n```\n\n```txt\ntorch>=1.2.0\nnumpy>=1.13.3\ntorchaudio>=0.3.0\nmatplotlib>=2.1.1\ntqdm>=4.36.1\nPyYAML>=5.3\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8891401888405708
      ],
      "excerpt": ": Get datum \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365,
        0.8837680365796365,
        0.8837680365796365,
        0.8837680365796365
      ],
      "excerpt": "label_size: !!python/tuple [0, 8] \nambient_size: !!python/tuple [0, 2] \nlabel_scale: !!python/tuple [0.5, 1.5] \nambient_scale: !!python/tuple [0.4, 1.4] \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8932227647655261,
        0.806753978370331
      ],
      "excerpt": "from wass.dataset import CompositionDataset \n: Generate dataset from config \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8733450332610028
      ],
      "excerpt": "    \"dataset/train\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9393398804530788
      ],
      "excerpt": "print(len(train_dataset))   #: >>> 20000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8932227647655261
      ],
      "excerpt": "from wass.audio.dataset import ComposerConfig \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8029049629473649
      ],
      "excerpt": "config = ComposerConfig.load(\"path.yaml) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8482165829358999
      ],
      "excerpt": "Composer configuration files are provided in the config/composer folder. Here is an example of the default configuration file default.yaml: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8059900133471486
      ],
      "excerpt": "snr: !!python/tuple [0, 100] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8140020261316089
      ],
      "excerpt": "- Training and Testing Procedure \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8964943071137861,
        0.9287872159786905,
        0.8415251063639976,
        0.8478670945825909,
        0.8730887690243508
      ],
      "excerpt": "from wass.train import Solver \nfrom wass.train import TrainingConfig \n: Load Training Config file and check parameters \nconfig = TrainingConfig.load(\"config/training/default.yaml\") \nprint(config.dict, \"\\n\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9287872159786905
      ],
      "excerpt": "from wass.train import TrainingConfig \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.822112224815474
      ],
      "excerpt": "    batch_size=16,                    #: batch size \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.83239637647408,
        0.808622464322445
      ],
      "excerpt": "    n_train=20000,                    #: number of training samples \n    n_test=4000,                      #: number of testing samples \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8791883013214602
      ],
      "excerpt": "Training configuration files are provided in the config/training folder. Here is an example of the default configuration file default.yaml mapped with the default ComposerConfig: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8061955197717288
      ],
      "excerpt": "composer_conf_path: config/composer/default.yaml \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mitmedialab/WetlandAvianSourceSeparation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Wetland Avian Source Separation (WASS)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "WetlandAvianSourceSeparation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "mitmedialab",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mitmedialab/WetlandAvianSourceSeparation/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 30 Dec 2021 01:32:49 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Scripts must be used with the following command:\n```bash\n#: Help\n$ python3 -m wass [-h] \n\n#: Train\n$ pyfhon3 -m wass [-t] [--config CONFIG] [--gpu GPU [GPU ...]]\n\n#: Demo\n$ python3 -m wass [-d] [--model MODEL] [--mixture MIXTURE] [--dest DEST]\n```\n\n```bash\n$ python3 -m wass -h\nusage: wass [-h] [-t] [--config CONFIG] [--gpu GPU [GPU ...]] [-d]\n            [--model MODEL] [--mixture MIXTURE] [--dest DEST]\n\nWetland Avian Source Separation (WASS) -- Scripts\n\tSource Code:\n\t\thttps://github.com/mitmedialab/WetlandAvianSourceSeparation\n\tAuthors:\n\t\thttps://github.com/FelixMichaud\n\t\thttps://github.com/yliess86\n\t\thttps://github.com/slash6475\n    \n\noptional arguments:\n  -h, --help           show this help message and exit\n\n  -t, --train          training\n  --config CONFIG      training config file path\n  --gpu GPU [GPU ...]  cuda devices\n\n  -d, --demo           demonstration\n  --model MODEL        path to a trained model\n  --mixture MIXTURE    path to a mixture audio file\n  --dest DEST          path to save separated sources\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
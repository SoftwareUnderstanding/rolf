{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1710.10916",
      "https://arxiv.org/abs/1511.06434"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{Tao18attngan,\n  author    = {Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, Xiaodong He},\n  title     = {AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks},\n  Year = {2018},\n  booktitle = {{CVPR}}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{ruan2021dae,\n  title={DAE-GAN: Dynamic Aspect-aware GAN for Text-to-Image Synthesis},\n  author={Ruan, Shulan and Zhang, Yong and Zhang, Kun and Fan, Yanbo and Tang, Fan and Liu, Qi and Chen, Enhong},\n  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n  pages={13960--13969},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8763824218130438
      ],
      "excerpt": "Pytorch implementation for reproducing DAE-GAN results in the paper [DAE-GAN: Dynamic Aspect-aware GAN for Text-to-Image Synthesis] by Shulan Ruan, Yong Zhang, Kun Zhang, Yanbo Fan, Fan Tang, Qi Liu, Enhong Chen. (This work was performed when Ruan was an intern with Tencent AI Lab).  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hiarsal/DAE-GAN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-02T09:41:56Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T07:34:09Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9135002022200924
      ],
      "excerpt": "Pytorch implementation for reproducing DAE-GAN results in the paper [DAE-GAN: Dynamic Aspect-aware GAN for Text-to-Image Synthesis] by Shulan Ruan, Yong Zhang, Kun Zhang, Yanbo Fan, Fan Tang, Qi Liu, Enhong Chen. (This work was performed when Ruan was an intern with Tencent AI Lab).  \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hiarsal/dae-gan/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Fri, 24 Dec 2021 23:18:55 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hiarsal/DAE-GAN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "hiarsal/DAE-GAN",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hiarsal/DAE-GAN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Starlark"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "DAE-GAN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DAE-GAN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "hiarsal",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hiarsal/DAE-GAN/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "python 3.6\n\nPytorch\n\nIn addition, please add the project folder to PYTHONPATH and `pip install` the following packages:\n- `python-dateutil`\n- `easydict`\n- `pandas`\n- `torchfile`\n- `nltk`\n- `scikit-image`\n\n\n\n**Data**\n\n1. Download the [birds](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html) image data. Extract them to `data/birds/`\n2. Download [coco](http://cocodataset.org/#download) dataset and extract the images to `data/coco/`\n\n\n\n**Training**\n- Pre-train DAMSM models:\n  - For bird dataset: `python pretrain_DAMSM.py --cfg cfg/DAMSM/bird.yml --gpu 0`\n  - For coco dataset: `python pretrain_DAMSM.py --cfg cfg/DAMSM/coco.yml --gpu 0`\n \n- Train DAE-GAN models:\n  - For bird dataset: `python main.py --cfg cfg/bird_DAEGAN.yml --gpu 0`\n  - For coco dataset: `python main.py --cfg cfg/coco_DAEGAN.yml --gpu 0`\n\n- `*.yml` files are example configuration files for training/evaluation our models.\n\n\n\n**Pretrained Model**\n- [DAMSM for bird](https://drive.google.com/open?id=1GNUKjVeyWYBJ8hEU-yrfYQpDOkxEyP3V). Download and save it to `DAMSMencoders/`\n- [DAMSM for coco](https://drive.google.com/open?id=1zIrXCE9F6yfbEJIbNP5-YrEe2pZcPSGJ). Download and save it to `DAMSMencoders/`\n- [DAE-GAN for bird](https://pan.baidu.com/s/1kkh3V0az_H44fiUaPbt9gw). Download and save it to `models/` Passwd: 8ncq\n- [DAE-GAN for coco](https://pan.baidu.com/s/15Ye7dKSMqItjXvvB5O2g4g). Download and save it to `models/` Passwd: jcg8\n\n\n**Validation**\n- To generate images for all captions in the validation dataset, change B_VALIDATION to True in the eval_*.yml. and then run `python main.py --cfg cfg/eval_coco.yml --gpu 1`\n- We compute inception score for models trained on birds using [StackGAN-inception-model](https://github.com/hanzhanggit/StackGAN-inception-model).\n- We compute inception score for models trained on coco using [improved-gan/inception_score](https://github.com/openai/improved-gan/tree/master/inception_score).\n\n\n**Examples generated by DAE-GAN**\n\n<!--  bird example              |  coco example\n:-------------------------:|:-------------------------:\n![] -->\n<img src=\"comparison.png\" width=\"800px\" height=\"300px\"/>\n\n**Citing DAE-GAN**\n\nIf you find DAE-GAN useful in your research, please consider citing:\n```\n@inproceedings{ruan2021dae,\n  title={DAE-GAN: Dynamic Aspect-aware GAN for Text-to-Image Synthesis},\n  author={Ruan, Shulan and Zhang, Yong and Zhang, Kun and Fan, Yanbo and Tang, Fan and Liu, Qi and Chen, Enhong},\n  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n  pages={13960--13969},\n  year={2021}\n}\n```\n<!-- \n```\n@article{Tao18attngan,\n  author    = {Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, Xiaodong He},\n  title     = {AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks},\n  Year = {2018},\n  booktitle = {{CVPR}}\n}\n``` -->\n\n**Reference**\n\n- [StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks](https://arxiv.org/abs/1710.10916) [[code]](https://github.com/hanzhanggit/StackGAN-v2)\n- [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434) [[code]](https://github.com/carpedm20/DCGAN-tensorflow)\n- [AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks](https://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_AttnGAN_Fine-Grained_Text_CVPR_2018_paper.pdf) [[code]](https://github.com/taoxugit/AttnGAN)\n- [DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-to-Image Synthesis](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_DM-GAN_Dynamic_Memory_Generative_Adversarial_Networks_for_Text-To-Image_Synthesis_CVPR_2019_paper.pdf) [[code]](https://github.com/MinfengZhu/DM-GAN)\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 12,
      "date": "Fri, 24 Dec 2021 23:18:55 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "https://github.com/VITA-Group/GAN-LTH\n\nhttps://github.com/GongXinyuu/sngan.pytorch\n\nhttps://github.com/VITA-Group/AutoGAN\n\nhttps://github.com/POSTECH-CVLab/PyTorch-StudioGAN\n\nhttps://github.com/mit-han-lab/data-efficient-gans\n\nhttps://github.com/lucidrains/stylegan2-pytorch\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2103.00397"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@misc{chen2021ultradataefficient,\n      title={Ultra-Data-Efficient GAN Training: Drawing A Lottery Ticket First, Then Training It Toughly}, \n      author={Tianlong Chen and Yu Cheng and Zhe Gan and Jingjing Liu and Zhangyang Wang},\n      year={2021},\n      eprint={2103.00397},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}\n```\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{chen2021ultradataefficient,\n      title={Ultra-Data-Efficient GAN Training: Drawing A Lottery Ticket First, Then Training It Toughly}, \n      author={Tianlong Chen and Yu Cheng and Zhe Gan and Jingjing Liu and Zhangyang Wang},\n      year={2021},\n      eprint={2103.00397},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9993535071710706
      ],
      "excerpt": "Tianlong Chen, Yu Cheng, Zhe Gan, Jingjing Liu, Zhangyang Wang. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9546417193406636
      ],
      "excerpt": "SNGAN / CIFAR-10 / 10% Training Data / 10.74% Remaining Weights \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9788738416895523
      ],
      "excerpt": "SNGAN / CIFAR-10 / 10% Training Data / 10.74% Remaining Weights + AdvAug on G and D \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.869385880131757
      ],
      "excerpt": "BigGAN / CIFAR-10 / 10% Training Data / 13.42% Remaining Weights + DiffAug + AdvAug on G and D \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/VITA-Group/Ultra-Data-Efficient-GAN-Training",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-02-25T20:04:46Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T12:01:31Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9283515395904738
      ],
      "excerpt": "Training generative adversarial networks (GANs) with limited data generally results in deteriorated performance and collapsed models. To conquerthis challenge, we are inspired by the latest observation of Kalibhat et al. (2020); Chen et al.(2021d), that one can discover independently trainable and highly sparse subnetworks (a.k.a.,lottery tickets) from GANs. Treating this as aninductive prior, we decompose the data-hungry GAN training into two sequential sub-problems:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.810298098513021,
        0.8142337059324737
      ],
      "excerpt": "(ii) then training the found sparse subnetwork with aggressive data and feature augmentations. \nBoth sub-problems re-use the same small training set of real images. Such a coordinated framework enables us to focus on lower-complexity and more data-efficient sub-problems, effectively stabilizing trainingand improving convergence. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8700319108189173,
        0.9374287391301207,
        0.8279799952798534
      ],
      "excerpt": "More experiments can be found in our paper. \nFor the first step, finding the lottery tickets in GAN is referred to this repo. \nFor the second step, training GAN ticket toughly are provides as follow: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8259701277457006
      ],
      "excerpt": "R.K. Limited data training for SNGAN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9134495018423794
      ],
      "excerpt": "Example for full model training on 20% limited data (--ratio 0.2): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9780150941650223
      ],
      "excerpt": "Example for full model training on 20% limited data (--ratio 0.2) with AdvAug on G and D: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9487894221097258
      ],
      "excerpt": "Example for sparse model (i.e., GAN tickets) training on 20% limited data (--ratio 0.2) with AdvAug on G and D: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8259701277457006
      ],
      "excerpt": "R.K. Limited data training for BigGAN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9185400110319395,
        0.8730313449839465
      ],
      "excerpt": "--reduce_train_dataset: the size of used limited training data \n--gamma: hyperparameter for AdvAug. You can set it to 0 to git rid of AdvAug \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8144782046916392
      ],
      "excerpt": "BigGAN / Tiny-ImageNet / 10% Training Data / Full model + AdvAug on G and D \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "[NeurIPS'21] \"Ultra-Data-Efficient GAN Training: Drawing A Lottery Ticket First, Then Training It Toughly\", Tianlong Chen, Yu Cheng, Zhe Gan, Jingjing Liu, Zhangyang Wang ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Thu, 23 Dec 2021 16:27:18 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/VITA-Group/Ultra-Data-Efficient-GAN-Training/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "VITA-Group/Ultra-Data-Efficient-GAN-Training",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/0114_vita4_exp1.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/0112_vita3_exp2.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/0112_vita4_exp2.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/0113_vita3_exp1.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/0112_vita3_exp1.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/0112_train_random_less_8sparsity.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/0112_vita4_exp3.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/train_rt.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/train_ompg.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/0114_vita3_exp2.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/0112_vita4_exp1.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/0114_vita3_exp1.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/train_ompgd.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/0115_vita3_exp1.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/scripts/0113_vita4_exp1.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/exps/eval.sh",
      "https://raw.githubusercontent.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/main/SNGAN/exps/sngan_cifar10.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9932972026411354,
        0.9994466678157792,
        0.998181571644513,
        0.9983325892533219,
        0.999746712887969
      ],
      "excerpt": "conda install python3.6 \nconda install pytorch1.4.0 -c pytorch \npip install tensorflow-gpu==1.13 \npip install imageio \npip install tensorboardx \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9632347459754548
      ],
      "excerpt": "conda env create -f environment.yml studiogan \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8408011420158433
      ],
      "excerpt": "<img src = \"Figs/res.png\" align = \"center\" width=\"60%\" hight=\"60%\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8286691868160542
      ],
      "excerpt": "R.K. Limited data training for SNGAN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8826984753565522
      ],
      "excerpt": "Example for full model training on 20% limited data (--ratio 0.2): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9203838716931829,
        0.8303915035844968
      ],
      "excerpt": "python train_less.py -gen_bs 128 -dis_bs 64 --dataset cifar10 --img_size 32 --max_iter 50000 --model sngan_cifar10 --latent_dim 128 --gf_dim 256 --df_dim 128 --g_spectral_norm False --d_spectral_norm True --g_lr 0.0002 --d_lr 0.0002 --beta1 0.0 --beta2 0.9 --init_type xavier_uniform --n_critic 5 --val_freq 20 --exp_name sngan_cifar10_adv_gd_less_0.2 --init-path initial_weights --ratio 0.2 \nExample for full model training on 20% limited data (--ratio 0.2) with AdvAug on G and D: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9327410084016836,
        0.8585630429135584
      ],
      "excerpt": "python train_adv_gd_less.py -gen_bs 128 -dis_bs 64 --dataset cifar10 --img_size 32 --max_iter 50000 --model sngan_cifar10 --latent_dim 128 --gf_dim 256 --df_dim 128 --g_spectral_norm False --d_spectral_norm True --g_lr 0.0002 --d_lr 0.0002 --beta1 0.0 --beta2 0.9 --init_type xavier_uniform --n_critic 5 --val_freq 20 --exp_name sngan_cifar10_adv_gd_less_0.2 --init-path initial_weights --gamma 0.01 --step 1 --ratio 0.2 \nExample for sparse model (i.e., GAN tickets) training on 20% limited data (--ratio 0.2) with AdvAug on G and D: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8977620041575581
      ],
      "excerpt": "python train_with_masks_adv_gd_less.py -gen_bs 128 -dis_bs 64 --dataset cifar10 --img_size 32 --max_iter 50000 --model sngan_cifar10 --latent_dim 128 --gf_dim 256 --df_dim 128 --g_spectral_norm False --d_spectral_norm True --g_lr 0.0002 --d_lr 0.0002 --beta1 0.0 --beta2 0.9 --init_type xavier_uniform --n_critic 5 --val_freq 20 --exp_name sngan_cifar10_adv_gd_less_0.2 --init-path initial_weights --gamma 0.01 --step 1 --ratio 0.2 --rewind-path &lt;&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8286691868160542
      ],
      "excerpt": "R.K. Limited data training for BigGAN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8778487586960795
      ],
      "excerpt": "Example:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336595056313404
      ],
      "excerpt": "python main_ompg.py -t -e -c ./configs/TINY_ILSVRC2012/BigGAN_adv.json --eval_type valid --seed 42 --mask_path checkpoints/BigGAN-train-0.1 --mask_round 2 --reduce_train_dataset 0.1 --gamma 0.01 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8115007621982449
      ],
      "excerpt": "--reduce_train_dataset: the size of used limited training data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.922374401459181
      ],
      "excerpt": "python main_ompg.py -t -e -c ./configs/CIFAR100_less/DiffAugGAN_adv.json --ratio 0.2 --mask_path checkpoints/diffauggan_cifar100_0.2 --mask_round 9 --seed 42 --gamma 0.01 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8392445389402737
      ],
      "excerpt": "SNGAN / CIFAR-10 / 10% Training Data / 10.74% Remaining Weights \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8061953634137481
      ],
      "excerpt": "SNGAN / CIFAR-10 / 10% Training Data / 10.74% Remaining Weights + AdvAug on G and D \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8315790304986622
      ],
      "excerpt": "BigGAN / Tiny-ImageNet / 10% Training Data / Full model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8036281374192996
      ],
      "excerpt": "BigGAN / Tiny-ImageNet / 10% Training Data / 64% Remaining Weights \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/VITA-Group/Ultra-Data-Efficient-GAN-Training/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cuda",
      "Shell",
      "C++"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 VITA\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Ultra-Data-Efficient GAN Training: Drawing A Lottery Ticket First, Then Training It Toughly",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Ultra-Data-Efficient-GAN-Training",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "VITA-Group",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/VITA-Group/Ultra-Data-Efficient-GAN-Training/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 68,
      "date": "Thu, 23 Dec 2021 16:27:18 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "gan",
      "generative-adversarial-network",
      "lottery-ticket-hypothesis",
      "data-efficient",
      "augmentation",
      "data-efficient-gan-training"
    ],
    "technique": "GitHub API"
  }
}
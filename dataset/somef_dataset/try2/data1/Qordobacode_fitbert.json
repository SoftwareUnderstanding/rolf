{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Thanks to [NodoBird](https://instagram.com/nodobird?igshid=lqt5h1uicxsy) for letting us use the awesome portrait of Bert depicted above.\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1810.04805"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use FitBERT in your research, please cite with the following BibText\n\n```bibtext\n@misc{havens2019fitbert,\n    title  = {Use BERT to Fill in the Blanks},\n    author = {Sam Havens and Aneta Stal},\n    url    = {https://github.com/Qordobacode/fitbert},\n    year   = {2019}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{havens2019fitbert,\n    title  = {Use BERT to Fill in the Blanks},\n    author = {Sam Havens and Aneta Stal},\n    url    = {https://github.com/Qordobacode/fitbert},\n    year   = {2019}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/writerai/fitbert",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-27T00:39:59Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-15T17:41:49Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9929657702550023,
        0.8902522508604631,
        0.8812859243468054,
        0.976075804690447,
        0.8463714540658851
      ],
      "excerpt": "FitBert ((F)ill (i)n (t)he blanks, (BERT)) is a library for using BERT to fill in the blank(s) in a section of text from a list of options. Here is the envisioned usecase for FitBert: \nA service (statistical model or something simpler) suggests replacements/corrections for a segment of text \nThat service is specialized to a domain, and isn't good at the big picture, e.g. grammar \nThat service passes the segment of text, with the words to be replaced identified, and the list of suggestions \nFitBert crushes all but the best suggestion :muscle: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8461559041552273
      ],
      "excerpt": "s = \"This might be justified as a means of signalling the connection between drunken driving and fatal accidents.\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9582496729624881,
        0.9554001492596078
      ],
      "excerpt": "assert better_string == \"This might be justified to signalling the connection between drunken driving and fatal accidents.\", \"Notice 'as a means of' became 'to', but we didn't re-conjuagte signalling, or fix the spelling mistake\" \nassert span_to_change == (27, 37), \"This span is the start and stop of the characters for the substring 'signalling'.\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9131876996126483
      ],
      "excerpt": "The benefit to doing this over masking yourself is that if the internally used masking token changes, you don't have to know about that. Also, you don't need to make an instance of FitBert, so you don't have to incur the cost of downloading a pretrained Bert model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Use BERT to Fill in the Blanks",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Qordobacode/fitbert/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 11,
      "date": "Fri, 24 Dec 2021 20:45:31 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/writerai/fitbert/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "writerai/fitbert",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Qordobacode/fitbert/master/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Qordobacode/fitbert/master/build.sh",
      "https://raw.githubusercontent.com/Qordobacode/fitbert/master/release.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.999746712887969
      ],
      "excerpt": "pip install fitbert \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from fitbert import FitBert \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/writerai/fitbert/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Apache License 2.0",
      "url": "https://api.github.com/licenses/apache-2.0"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'WordNet Release 3.0\\n\\nThis software and database is being provided to you, the LICENSEE, by\\nPrinceton University under the following license.  By obtaining, using\\nand/or copying this software and database, you agree that you have\\nread, understood, and will comply with these terms and conditions.:\\n\\nPermission to use, copy, modify and distribute this software and\\ndatabase and its documentation for any purpose and without fee or\\nroyalty is hereby granted, provided that you agree to comply with\\nthe following copyright notice and statements, including the disclaimer,\\nand that the same appear on ALL copies of the software, database and\\ndocumentation, including modifications that you make for internal\\nuse or for distribution.\\n\\nWordNet 3.0 Copyright 2006 by Princeton University.  All rights reserved.\\n\\nTHIS SOFTWARE AND DATABASE IS PROVIDED \"AS IS\" AND PRINCETON\\nUNIVERSITY MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\\nIMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, PRINCETON\\nUNIVERSITY MAKES NO REPRESENTATIONS OR WARRANTIES OF MERCHANT-\\nABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE\\nOF THE LICENSED SOFTWARE, DATABASE OR DOCUMENTATION WILL NOT\\nINFRINGE ANY THIRD PARTY PATENTS, COPYRIGHTS, TRADEMARKS OR\\nOTHER RIGHTS.\\n\\nThe name of Princeton University or Princeton may not be used in\\nadvertising or publicity pertaining to distribution of the software\\nand/or database.  Title to copyright in this software, database and\\nany associated documentation shall at all times remain with\\nPrinceton University and LICENSEE agrees to preserve same.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "FitBERT",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "fitbert",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "writerai",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/writerai/fitbert/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 70,
      "date": "Fri, 24 Dec 2021 20:45:31 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "bert",
      "pytorch",
      "python",
      "nlp",
      "fill-in-the-blank"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[A Jupyter notebook with a short introduction is available here.](https://colab.research.google.com/drive/1WrYzy9l_arpnTlhCCKViiilPe4WKZJjq)\n\nFitBert will automatically use GPU if `torch.cuda.is_available()`. Or when you instantiate it, you can pass `FitBert(model_name=\"distilbert-base-uncased\", disable_gpu=True)`. Fastest batches are using distilbert on CPU with batch size one, maximum throughput is with GPU and larger batches.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\nfrom fitbert import FitBert\n\n\n#: currently supported models: bert-large-uncased and distilbert-base-uncased\n#: this takes a while and loads a whole big BERT into memory\nfb = FitBert()\n\nmasked_string = \"Why Bert, you're looking ***mask*** today!\"\noptions = ['buff', 'handsome', 'strong']\n\nranked_options = fb.rank(masked_string, options=options)\n#: >>> ['handsome', 'strong', 'buff']\n#: or\nfilled_in = fb.fitb(masked_string, options=options)\n#: >>> \"Why Bert, you're looking handsome today!\"\n```\n\nWe commonly find ourselves knowing what verb to suggest, but not what conjugation:\n\n```python\nfrom fitbert import FitBert\n\n\nfb = FitBert()\n\nmasked_string = \"Why Bert, you're ***mask*** handsome today!\"\noptions = ['looks']\n\nfilled_in = fb.fitb(masked_string, options=options)\n#: >>> \"Why Bert, you're looking handsome today!\"\n\n#: under the hood, we notice there is only one suggestion and act as if\n#: fitb was called with delemmatize=True:\nfilled_in = fb.fitb(masked_string, options=options, delemmatize=True)\n```\n\nIf you are already using `pytorch_pretrained_bert.BertForMaskedLM`, or `transformers.BertForMaskedLM` and have an instance of BertForMaskedLM already instantiated, you can pass pass it in to reuse it:\n\n```python\nBLM = pytorch_pretrained_bert.BertForMaskedLM.from_pretrained(model_name)\n#: or\nBLM = transfomers.BertForMaskedLM.from_pretrained(model_name)\nfb = FitBert(model=BLM)\n```\n\nYou can also have FitBert mask the string for you\n\n```python\nfrom fitbert import FitBert\n\n\nfb = FitBert()\n\nunmasked_string = \"Why Bert, you're looks handsome today!\"\nspan_to_mask = (17, 22)\nmasked_string, masked = fb.mask(unmasked_string, span_to_mask)\n#: >>> \"Why Bert, you're ***mask*** handsome today!\", 'looks'\n\n#: you can set options = [masked] or use any List[str]\noptions = [masked]\n\nfilled_in = fb.fitb(masked_string, options=options)\n#: >>> \"Why Bert, you're looking handsome today!\"\n```\n\nand there is a convenience method for doing this:\n\n```python\nunmasked_string = \"Why Bert, you're looks handsome today!\"\nspan_to_mask = (17, 22)\n\nfilled_in = fb.mask_fitb(unmasked_string, span_to_mask)\n#: >>> \"Why Bert, you're looking handsome today!\"\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1801.07698"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find *InsightFace* useful in your research, please consider to cite the following related papers:\n\n```\n@inproceedings{deng2019retinaface,\ntitle={RetinaFace: Single-stage Dense Face Localisation in the Wild},\nauthor={Deng, Jiankang and Guo, Jia and Yuxiang, Zhou and Jinke Yu and Irene Kotsia and Zafeiriou, Stefanos},\nbooktitle={arxiv},\nyear={2019}\n}\n\n@inproceedings{guo2018stacked,\n  title={Stacked Dense U-Nets with Dual Transformers for Robust Face Alignment},\n  author={Guo, Jia and Deng, Jiankang and Xue, Niannan and Zafeiriou, Stefanos},\n  booktitle={BMVC},\n  year={2018}\n}\n\n@article{deng2018menpo,\n  title={The Menpo benchmark for multi-pose 2D and 3D facial landmark localisation and tracking},\n  author={Deng, Jiankang and Roussos, Anastasios and Chrysos, Grigorios and Ververas, Evangelos and Kotsia, Irene and Shen, Jie and Zafeiriou, Stefanos},\n  journal={IJCV},\n  year={2018}\n}\n\n@inproceedings{deng2018arcface,\ntitle={ArcFace: Additive Angular Margin Loss for Deep Face Recognition},\nauthor={Deng, Jiankang and Guo, Jia and Niannan, Xue and Zafeiriou, Stefanos},\nbooktitle={CVPR},\nyear={2019}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{deng2018arcface,\ntitle={ArcFace: Additive Angular Margin Loss for Deep Face Recognition},\nauthor={Deng, Jiankang and Guo, Jia and Niannan, Xue and Zafeiriou, Stefanos},\nbooktitle={CVPR},\nyear={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{deng2018menpo,\n  title={The Menpo benchmark for multi-pose 2D and 3D facial landmark localisation and tracking},\n  author={Deng, Jiankang and Roussos, Anastasios and Chrysos, Grigorios and Ververas, Evangelos and Kotsia, Irene and Shen, Jie and Zafeiriou, Stefanos},\n  journal={IJCV},\n  year={2018}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{guo2018stacked,\n  title={Stacked Dense U-Nets with Dual Transformers for Robust Face Alignment},\n  author={Guo, Jia and Deng, Jiankang and Xue, Niannan and Zafeiriou, Stefanos},\n  booktitle={BMVC},\n  year={2018}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{deng2019retinaface,\ntitle={RetinaFace: Single-stage Dense Face Localisation in the Wild},\nauthor={Deng, Jiankang and Guo, Jia and Yuxiang, Zhou and Jinke Yu and Irene Kotsia and Zafeiriou, Stefanos},\nbooktitle={arxiv},\nyear={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8650239057784687
      ],
      "excerpt": "By Jia Guo and Jiankang Deng \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9966095042717282
      ],
      "excerpt": "2019.04.14: We will launch a Light-weight Face Recognition challenge/workshop on ICCV 2019. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9892740741085043,
        0.9196814658466638,
        0.8343848002233065
      ],
      "excerpt": "2019.02.08: Please check https://github.com/deepinsight/insightface/tree/master/recognition for our parallel training code which can easily and efficiently support one million identities on a single machine (8* 1080ti). \n2018.12.13: Inference acceleration TVM-Benchmark. \n2018.10.28: Light-weight attribute model Gender-Age. About 1MB, 10ms on single CPU core. Gender accuracy 96% on validation set and 4.1 age MAE. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278824608274014
      ],
      "excerpt": "Deep Face Recognition \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8090016440670298,
        0.8090016440670298,
        0.8090016440670298
      ],
      "excerpt": "       lfw.bin \n       cfp_fp.bin \n       agedb_30.bin \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8283216015784888
      ],
      "excerpt": "| Method  | LFW(%) | CFP-FP(%) | AgeDB-30(%) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8283216015784888
      ],
      "excerpt": "| Method           | m1   | m2   | m3   | LFW   | CFP-FP | AgeDB-30 | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zheng1weiyu/Insightface_for_FaceRecog",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n[Jia Guo](guojia[at]gmail.com)\n[Jiankang Deng](jiankangdeng[at]gmail.com)\n```\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-04-13T09:23:43Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-04-13T10:40:43Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "In this repository, we provide training data, network settings and loss designs for deep face recognition.\nThe training data includes the normalised MS1M, VGG2 and CASIA-Webface datasets, which were already packed in MXNet binary format.\nThe network backbones include ResNet, MobilefaceNet, MobileNet, InceptionResNet_v2, DenseNet, DPN.\nThe loss functions include Softmax, SphereFace, CosineFace, ArcFace and Triplet (Euclidean/Angular) Loss.\n\n\n![margin penalty for target logit](https://github.com/deepinsight/insightface/raw/master/resources/arcface.png)\n\nOur method, ArcFace, was initially described in an [arXiv technical report](https://arxiv.org/abs/1801.07698). By using this repository, you can simply achieve LFW 99.80%+ and Megaface 98%+ by a single model. This repository can help researcher/engineer to develop deep face recognition algorithms quickly by only two steps: download the binary dataset and run the training script.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8192505441185383
      ],
      "excerpt": "By Jia Guo and Jiankang Deng \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9261702495439417
      ],
      "excerpt": "2019.04.30: Our Face detector (RetinaFace) obtains state-of-the-art results on the WiderFace dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8968302389720788
      ],
      "excerpt": "report (name: Imperial-000 and Imperial-001). Our solution is based on [MS1MV2+DeepGlintAsian, ResNet100, ArcFace loss].  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8450070941881584
      ],
      "excerpt": "2018.10.28: Light-weight attribute model Gender-Age. About 1MB, 10ms on single CPU core. Gender accuracy 96% on validation set and 4.1 age MAE. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906128909950556
      ],
      "excerpt": "- Introduction \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8593554442301238
      ],
      "excerpt": "All face images are aligned by MTCNN and cropped to 112x112: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8862314582827862
      ],
      "excerpt": "Please check src/data/face2rec2.py on how to build a binary face dataset. Any public available MTCNN can be used to align the faces, and the performance should not change. We will improve the face normalisation step by full pose alignment methods recently. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.815444321573754
      ],
      "excerpt": "This model can achieve LFW 99.80+ and MegaFace 98.3%+. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278860269777196
      ],
      "excerpt": "(4). Fine-turn the above Softmax model with Triplet loss. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9583229686355454
      ],
      "excerpt": "Please check Model-Zoo for more pretrained models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.806386701014948
      ],
      "excerpt": "Results by using MS1M-IBUG(MS1M-V1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8617599490313199
      ],
      "excerpt": "In this part, we assume you are in the directory $INSIGHTFACE_ROOT/deploy/. The input face image should be generally centre cropped. We use RNet+ONet of MTCNN to further align the image before sending it to the feature embedding network. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8927898519411741
      ],
      "excerpt": "Put the model under $INSIGHTFACE_ROOT/models/. For example, $INSIGHTFACE_ROOT/models/model-r100-ii. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9796814996914888
      ],
      "excerpt": "For single cropped face image(112x112), total inference time is only 17ms on our testing server(Intel E5-2660 @ 2.00GHz, Tesla M40, LResNet34E-IR). \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zheng1weiyu/Insightface_for_FaceRecog/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 10:04:32 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/zheng1weiyu/Insightface_for_FaceRecog/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "zheng1weiyu/Insightface_for_FaceRecog",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9977752388963443,
        0.9985647484703379
      ],
      "excerpt": "Install MXNet with GPU support (Python 2.7). \npip install mxnet-cu90 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9799489993452795
      ],
      "excerpt": "git clone --recursive https://github.com/deepinsight/insightface.git \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8385975937262083
      ],
      "excerpt": "For training with m1=1.0, m2=0.3, m3=0.2, run following command: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9322609392449874,
        0.9322609392449874
      ],
      "excerpt": "PyTorch: InsightFace_Pytorch \nPyTorch: arcface-pytorch \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8668937975765546,
        0.8589534893990137,
        0.8245539886860519
      ],
      "excerpt": "- Training Data \n- Train \n- Pretrained Models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8113088190265606
      ],
      "excerpt": "Download the training set (MS1M-Arcface) and place it in $INSIGHTFACE_ROOT/datasets/. Each training dataset includes at least following 6 files: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137,
        0.8589534893990137
      ],
      "excerpt": "       train.idx \n       train.rec \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8927905239057822,
        0.8300446489733351
      ],
      "excerpt": "cp sample_config.py config.py \nvim config.py #: edit dataset path etc.. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8278121020599903
      ],
      "excerpt": "(1). Train ArcFace with LResNet100E-IR. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.850032781798308,
        0.8366887577325904
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES='0,1,2,3' python -u train.py --network r100 --loss arcface --dataset emore \nIt will output verification results of LFW, CFP-FP and AgeDB-30 every 2000 batches. You can check all options in config.py. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8278121020599903
      ],
      "excerpt": "(2). Train CosineFace with LResNet50E-IR. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.850032781798308,
        0.8278121020599903
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES='0,1,2,3' python -u train.py --network r50 --loss cosface --dataset emore \n(3). Train Softmax with LMobileNet-GAP. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.850032781798308
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES='0,1,2,3' python -u train.py --network m1 --loss softmax --dataset emore \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8847134236737256
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES='0,1,2,3' python -u train.py --network m1 --loss triplet --lr 0.005 --pretrained ./models/m1-softmax-emore,1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9209739772085854
      ],
      "excerpt": "You can use $INSIGHTFACE/src/eval/verification.py to test all the pre-trained models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8667726685541095,
        0.9095062552484893
      ],
      "excerpt": "Put the model under $INSIGHTFACE_ROOT/models/. For example, $INSIGHTFACE_ROOT/models/model-r100-ii. \nRun the test script $INSIGHTFACE_ROOT/deploy/test.py. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8420227656543805
      ],
      "excerpt": "TensorFlow: tf-insightface \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/zheng1weiyu/Insightface_for_FaceRecog/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "InsightFace: 2D and 3D Face Analysis Project",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Insightface_for_FaceRecog",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "zheng1weiyu",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zheng1weiyu/Insightface_for_FaceRecog/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 10:04:32 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[![ArcFace Demo](https://github.com/deepinsight/insightface/blob/master/resources/facerecognitionfromvideo.PNG)](https://www.youtube.com/watch?v=y-D1tReryGA&t=81s)\n\nPlease click the image to watch the Youtube video. For Bilibili users, click [here](https://www.bilibili.com/video/av38041494?from=search&seid=11501833604850032313).\n\n",
      "technique": "Header extraction"
    }
  ]
}
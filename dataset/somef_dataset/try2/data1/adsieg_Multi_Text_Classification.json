{
  "citation": [
    {
      "confidence": [
        0.9892256371205239,
        0.9609675417996785
      ],
      "excerpt": "    documents, Title Word Count in the Complete Essay \u2013 total number \n    of proper case (title) words in the documents \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999582833911902,
        0.925435137764074
      ],
      "excerpt": "<a href=\"https://arxiv.org/pdf/1705.08039.pdf\" class=\"uri\">https://arxiv.org/pdf/1705.08039.pdf</a> \n<a href=\"https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Poincare%20Tutorial.ipynb\" class=\"uri\">https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Poincare%20Tutorial.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "HasingTF + IDF + Logistic Regression \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999582833911902
      ],
      "excerpt": "    <a href=\"https://arxiv.org/pdf/1808.09772.pdf\" class=\"uri\">https://arxiv.org/pdf/1808.09772.pdf</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9323116436099254
      ],
      "excerpt": "    <a href=\"https://github.com/mdh266/DocumentClassificationNLP/blob/master/NLP.ipynb\" class=\"uri\">https://github.com/mdh266/DocumentClassificationNLP/blob/master/NLP.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9323116436099254
      ],
      "excerpt": "    <a href=\"https://github.com/Tixierae/deep_learning_NLP/blob/master/cnn_imdb.ipynb\" class=\"uri\">https://github.com/Tixierae/deep_learning_NLP/blob/master/cnn_imdb.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.988796398679384
      ],
      "excerpt": "    <a href=\"https://github.com/Tixierae/deep_learning_NLP/blob/master/HAN/HAN_final.ipynb\" class=\"uri\">https://github.com/Tixierae/deep_learning_NLP/blob/master/HAN/HAN_final.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "    logistic regression) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9955935092645852
      ],
      "excerpt": "    <a href=\"https://dzone.com/articles/machine-learning-text-feature-0\" class=\"uri\">https://dzone.com/articles/machine-learning-text-feature-0</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9606057259834543
      ],
      "excerpt": "    <a href=\"http://www.developintelligence.com/blog/2017/06/practical-neural-networks-keras-classifying-yelp-reviews/\" class=\"uri\">http://www.developintelligence.com/blog/2017/06/practical-neural-networks-keras-classifying-yelp-reviews/</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9949894347600978,
        0.9836970527620026
      ],
      "excerpt": "    <a href=\"http://www.davidsbatista.net/blog/2018/03/31/SentenceClassificationConvNets/\" class=\"uri\">http://www.davidsbatista.net/blog/2018/03/31/SentenceClassificationConvNets/</a> \n    <a href=\"https://github.com/davidsbatista/ConvNets-for-sentence-classification\" class=\"uri\">https://github.com/davidsbatista/ConvNets-for-sentence-classification</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9323116436099254
      ],
      "excerpt": "    <a href=\"https://github.com/makcedward/nlp/blob/master/sample/nlp-model_interpretation.ipynb\" class=\"uri\">https://github.com/makcedward/nlp/blob/master/sample/nlp-model_interpretation.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "    regression, naive bayes, svm, xgboost, grid search, word vectors, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9959010702156511
      ],
      "excerpt": "    <a href=\"https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/\" class=\"uri\">https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9993580912106143
      ],
      "excerpt": "    <a href=\"https://mlwhiz.com/blog/2019/02/08/deeplearning_nlp_conventional_methods/\" class=\"uri\">https://mlwhiz.com/blog/2019/02/08/deeplearning_nlp_conventional_methods/</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9323116436099254
      ],
      "excerpt": "    <a href=\"https://github.com/msahamed/yelp_comments_classification_nlp/blob/master/word_embeddings.ipynb\" class=\"uri\">https://github.com/msahamed/yelp_comments_classification_nlp/blob/master/word_embeddings.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9954828277588711
      ],
      "excerpt": "    <a href=\"https://karpathy.github.io/2015/05/21/rnn-effectiveness/\" class=\"uri\">https://karpathy.github.io/2015/05/21/rnn-effectiveness/</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8568217992087697
      ],
      "excerpt": "    Sentences & VDNN for Text Classification & Multi Channel \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999999591902915
      ],
      "excerpt": "    <a href=\"https://bicepjai.github.io/machine-learning/2017/11/10/text-class-part1.html\" class=\"uri\">https://bicepjai.github.io/machine-learning/2017/11/10/text-class-part1.html</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8854398367006624
      ],
      "excerpt": "    <a href=\"https://towardsdatascience.com/transformers-141e32e69591\" class=\"uri\">https://towardsdatascience.com/transformers-141e32e69591</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9717455075751278
      ],
      "excerpt": "    <a href=\"https://guillaumegenthial.github.io\" class=\"uri\">https://guillaumegenthial.github.io</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9717455075751278
      ],
      "excerpt": "    <a href=\"https://jalammar.github.io/\" class=\"uri\">https://jalammar.github.io/</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9717455075751278
      ],
      "excerpt": "    <a href=\"https://richliao.github.io/\" class=\"uri\">https://richliao.github.io/</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9949894347600978
      ],
      "excerpt": "    <a href=\"http://www.davidsbatista.net/blog/2018/03/31/SentenceClassificationConvNets/\" class=\"uri\">http://www.davidsbatista.net/blog/2018/03/31/SentenceClassificationConvNets/</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9323116436099254,
        0.8356013927728488,
        0.9202635357771027
      ],
      "excerpt": "    <a href=\"https://github.com/tthustla/setiment_analysis_pyspark/blob/master/Sentiment%20Analysis%20with%20PySpark.ipynb\" class=\"uri\">https://github.com/tthustla/setiment_analysis_pyspark/blob/master/Sentiment%20Analysis%20with%20PySpark.ipynb</a> \nRNN Text Generation : \n    <a href=\"https://github.com/priya-dwivedi/Deep-Learning/blob/master/RNN_text_generation/RNN_project.ipynb\" class=\"uri\">https://github.com/priya-dwivedi/Deep-Learning/blob/master/RNN_text_generation/RNN_project.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925435137764074
      ],
      "excerpt": "    <a href=\"https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_tutorial.ipynb\" class=\"uri\">https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_tutorial.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9960947075667199
      ],
      "excerpt": "    <a href=\"https://humboldt-wi.github.io/blog/research/information_systems_1819/group5_han/\" class=\"uri\">https://humboldt-wi.github.io/blog/research/information_systems_1819/group5_han/</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925435137764074,
        0.8714162992508173
      ],
      "excerpt": "    <a href=\"https://github.com/RaRe-Technologies/gensim/tree/develop/docs/notebooks\" class=\"uri\">https://github.com/RaRe-Technologies/gensim/tree/develop/docs/notebooks</a> \nDoc2Vec + Logistic Regression : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925435137764074
      ],
      "excerpt": "    <a href=\"https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-wikipedia.ipynb\" class=\"uri\">https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-wikipedia.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925435137764074
      ],
      "excerpt": "    <a href=\"https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Poincare%20Tutorial.ipynb\" class=\"uri\">https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Poincare%20Tutorial.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9875817838492165
      ],
      "excerpt": "    <a href=\"https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb\" class=\"uri\">https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8393424409501686
      ],
      "excerpt": "    <a href=\"https://github.com/Cdiscount/IT-Blog/tree/master/scripts/link-prediction\" class=\"uri\">https://github.com/Cdiscount/IT-Blog/tree/master/scripts/link-prediction</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8465331071253921
      ],
      "excerpt": "    <a href=\"https://markroxor.github.io/gensim/static/notebooks/WMD_tutorial.html\" class=\"uri\">https://markroxor.github.io/gensim/static/notebooks/WMD_tutorial.html</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9981860451224981
      ],
      "excerpt": "    <a href=\"https://jeremykun.com/2018/03/05/earthmover-distance/\" class=\"uri\">https://jeremykun.com/2018/03/05/earthmover-distance/</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9323116436099254
      ],
      "excerpt": "    <a href=\"https://github.com/stephenhky/PyWMD/blob/master/WordMoverDistanceDemo.ipynb\" class=\"uri\">https://github.com/stephenhky/PyWMD/blob/master/WordMoverDistanceDemo.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9717455075751278
      ],
      "excerpt": "    <a href=\"https://optimaltransport.github.io/pdf/ComputationalOT.pdf\" class=\"uri\">https://optimaltransport.github.io/pdf/ComputationalOT.pdf</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9699181134621796
      ],
      "excerpt": "    <a href=\"http://robotics.stanford.edu/~scohen/research/emdg/emdg.html\" class=\"uri\">http://robotics.stanford.edu/~scohen/research/emdg/emdg.html</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.81299965730896
      ],
      "excerpt": "    <a href=\"http://robotics.stanford.edu/~rubner/slides/sld014.htm\" class=\"uri\">http://robotics.stanford.edu/~rubner/slides/sld014.htm</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9323116436099254,
        0.9202635357771027
      ],
      "excerpt": "<a href=\"https://github.com/FelixChop/MediumArticles/blob/master/LDA-BBC.ipynb\" class=\"uri\">https://github.com/FelixChop/MediumArticles/blob/master/LDA-BBC.ipynb</a> \n<a href=\"https://github.com/priya-dwivedi/Deep-Learning/blob/master/topic_modeling/LDA_Newsgroup.ipynb\" class=\"uri\">https://github.com/priya-dwivedi/Deep-Learning/blob/master/topic_modeling/LDA_Newsgroup.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9960947075667199
      ],
      "excerpt": "    <a href=\"https://humboldt-wi.github.io/blog/research/information_systems_1819/is_lda_final/\" class=\"uri\">https://humboldt-wi.github.io/blog/research/information_systems_1819/is_lda_final/</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9872421892177753
      ],
      "excerpt": "    <a href=\"https://github.com/NicGian/text_VAE\" class=\"uri\">https://github.com/NicGian/text_VAE</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9202635357771027
      ],
      "excerpt": "    <a href=\"https://github.com/s4sarath/Deep-Learning-Projects/tree/master/variational_text_inference\" class=\"uri\">https://github.com/s4sarath/Deep-Learning-Projects/tree/master/variational_text_inference</a> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/adsieg/Multi_Text_Classification",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-17T13:17:07Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-17T01:45:41Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.968673195023743
      ],
      "excerpt": "    and quantify how similar and different these sets of word \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9429757752805895
      ],
      "excerpt": "    which words tend to follow others immediately, or that tend to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9755158798984114,
        0.9844064017055512,
        0.9427927277311563
      ],
      "excerpt": "Which word is associated with another word? Note that this is a \nvisualization of a Markov chain, a common model in text processing. In a \nMarkov chain, each choice of word depends only on the previous word. In \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9289704935578895,
        0.9575718543543862,
        0.8670585224140686,
        0.8691361722740515,
        0.9204897334605078,
        0.9608175461370053,
        0.9636865972223817,
        0.8509676284033253,
        0.9036619656098889,
        0.9515233092140115
      ],
      "excerpt": "word to the most common words that follow it. To make the visualization \ninterpretable, we chose to show only the most common word to word \nconnections, but one could imagine an enormous graph representing all \nconnections that occur in the text. \nDistribution of words: Want to show that there are similar \n    distributions for all texts, with many words that occur rarely and \n    fewer words that occur frequently. Here is the goal of Zip Law \n    (extended with Harmonic mean) - Zipf\u2019s Law is a statistical \n    distribution in certain data sets, such as words in a linguistic \n    corpus, in which the frequencies of certain words are inversely \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9637653452163217,
        0.9433794251179489,
        0.8409183141410158
      ],
      "excerpt": "How to spell variants of a given word \nChi-Square to see which words are associated to each category: \n    find the terms that are the most correlated with each of the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.982417539380795,
        0.908925214220865,
        0.9004683618077581,
        0.9650517631625084
      ],
      "excerpt": "Part of Speech Tags and Frequency distribution of POST: Noun \n    Count, Verb Count, Adjective Count, Adverb Count and Pronoun Count \nMetrics of words: Word Count of the documents \u2013 ie. total \n    number of words in the documents, Character Count of the documents \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9730614696331391
      ],
      "excerpt": "    of the documents \u2013 average length of the words used in the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9684665502802433
      ],
      "excerpt": "    of punctuation marks in the documents, Upper Case Count in the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8728496032382422
      ],
      "excerpt": "A - Frequency Based Embedding \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9526741572950502
      ],
      "excerpt": "Topic Model as features // LDA features \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8974548401644911,
        0.8144319443186686
      ],
      "excerpt": "Visualization provides a global view of the topics (and how they differ \nfrom each other), while at the same time allowing for a deep inspection \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9896391927858208,
        0.9888074535038374
      ],
      "excerpt": "method for choosing which terms to present to a user to aid in the task \nof topic interpretation, in which we define the relevance of a term to a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9315187780973959,
        0.9725910192533105,
        0.9967022434412286
      ],
      "excerpt": "The main innovation here is that these embeddings are learnt in \nhyperbolic space, as opposed to the commonly used Euclidean \nspace. The reason behind this is that hyperbolic space is more \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9199493314865412
      ],
      "excerpt": "in the graph. Embedding nodes into a Euclidean space while preserving \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.968448475531525
      ],
      "excerpt": "Learning representations of symbolic data such as text, graphs and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8523663817659233,
        0.8133731298248196
      ],
      "excerpt": "and artificial intelligence. For instance, word embeddings such as \nWORD2VEC, GLOVE and FASTTEXT are widely used for tasks \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9903437567008061,
        0.8381768822499891,
        0.8213785710523214,
        0.9822028643489282
      ],
      "excerpt": "Typically, the objective of embedding methods is to organize \nsymbolic objects (e.g., words, entities, concepts) in a way such that \ntheir similarity in the embedding space reflects their semantic or \nfunctional similarity. For this purpose, the similarity of objects is \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9425617618089757,
        0.9404010131224118,
        0.8996057480623779,
        0.8097489448615136,
        0.8451788558863829
      ],
      "excerpt": "product in the embedding space. For instance, Mikolov embed words in \nR<sup>d</sup> such that their inner product is maximized when \nwords co-occur within similar contexts in text corpora. This is \nmotivated by the distributional hypothesis, i.e., that the meaning \nof words can be derived from the contexts in which they appear. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8368375594559594
      ],
      "excerpt": "B - Deep Learning Methods \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8573607260185321,
        0.8573607260185321,
        0.8641829532814898,
        0.9731756955532208,
        0.8326315864389134
      ],
      "excerpt": "CNN + RNN + Attention Mechanism \nCNN + LSTM/GRU + Attention Mechanism \nGoal: explain predictions of arbitrary classifiers, including text \nclassifiers (when it is hard to get exact mapping between model \ncoefficients and text features, e.g.\u00a0if there is dimension reduction \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8119473266644903
      ],
      "excerpt": "All models : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.872744398657017
      ],
      "excerpt": "CNN Text Classification: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8072832801623843
      ],
      "excerpt": "CNN Multichannel Text Classification + Hierarchical attention + \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9381335654943147
      ],
      "excerpt": "Notes for Deep Learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8630792940860466
      ],
      "excerpt": "3 ways to interpretate your NLP model [Lime, ELI5, Skater] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8335069864246154
      ],
      "excerpt": "    <a href=\"https://towardsdatascience.com/3-ways-to-interpretate-your-nlp-model-to-management-and-customer-5428bc07ce15\" class=\"uri\">https://towardsdatascience.com/3-ways-to-interpretate-your-nlp-model-to-management-and-customer-5428bc07ce15</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503521831802232
      ],
      "excerpt": "Deep Learning for text made easy with AllenNLP \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "    and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9827369803382128
      ],
      "excerpt": "CNN + Word2vec and LSTM + Word2Vec : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9884502560754094,
        0.8930901044020226
      ],
      "excerpt": "Comparison of models [Bag of Words - Countvectorizer Features, \n    TFIDF Features, Hashing Features, Word2vec Features] : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112
      ],
      "excerpt": "Visualisation sympa pour comprendre CNN : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.872744398657017
      ],
      "excerpt": "Yelp comments classification [ LSTM, LSTM + CNN] : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9705753018722024
      ],
      "excerpt": "CNN for Sentence Classification & DCNN for Modelling \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9408611924055427
      ],
      "excerpt": "    Variable size CNN & Multi Group Norm Constraint CNN & RACNN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.847419850499468
      ],
      "excerpt": "    Linear SVM & SVM with non-linear kernel \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "    and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "    and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.802005779585118
      ],
      "excerpt": "[Bonus] Sentiment Analysis in PySpark : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8375433722918425
      ],
      "excerpt": "Finding similar documents with Word2Vec and Soft Cosine Measure: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9268656019241536
      ],
      "excerpt": "[ESSENTIAL for any NLP Project]: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9939700160973216
      ],
      "excerpt": "Graph Link predictions + Part-of-Speech tagging tutorial with the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9286987732125327
      ],
      "excerpt": "Finding similar documents with Word2Vec and WMD : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8779718730942327
      ],
      "excerpt": "Introduction to Wasserstein metric (earth mover\u2019s distance): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8096796081355454
      ],
      "excerpt": "    (given by samples, or differing observations, or clusters). For \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.944045936001135,
        0.9693233393948762,
        0.8506157035959768
      ],
      "excerpt": "    indicated by their colors, which is closer, blue to green, or blue \n    to red? \nWord Mover\u2019s distance calculation between word pairs of two \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "    and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Multi Text Classificaiton",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/adsieg/Multi_Text_Classification/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 39,
      "date": "Sun, 26 Dec 2021 20:38:30 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/adsieg/Multi_Text_Classification/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "adsieg/Multi_Text_Classification",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/adsieg/Multi_Text_Classification/master/%5BUnsupervised%5D%20LDA.ipynb",
      "https://raw.githubusercontent.com/adsieg/Multi_Text_Classification/master/%5BBasic%5D%20%5BDocument%20Similarity%5D%20%5BUnsupervised%5D%20-%20TFIDF%20-%20BoW%20-%20Bag%20of%20N-Grams%20-%20Kmeans%20-%20LDA.ipynb",
      "https://raw.githubusercontent.com/adsieg/Multi_Text_Classification/master/%5BSupervised%5D%20%5BDL%20method%5D%20GRU_HAN.ipynb",
      "https://raw.githubusercontent.com/adsieg/Multi_Text_Classification/master/%5BIntroduction%5D%20-%20Big%20tutorial%20-%20Text%20Classification.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8093639679465799
      ],
      "excerpt": "    <a href=\"https://github.com/mdh266/DocumentClassificationNLP/blob/master/NLP.ipynb\" class=\"uri\">https://github.com/mdh266/DocumentClassificationNLP/blob/master/NLP.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740456448280757
      ],
      "excerpt": "    <a href=\"https://github.com/Tixierae/deep_learning_NLP/blob/master/cnn_imdb.ipynb\" class=\"uri\">https://github.com/Tixierae/deep_learning_NLP/blob/master/cnn_imdb.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740456448280757
      ],
      "excerpt": "    <a href=\"https://github.com/Tixierae/deep_learning_NLP/blob/master/HAN/HAN_final.ipynb\" class=\"uri\">https://github.com/Tixierae/deep_learning_NLP/blob/master/HAN/HAN_final.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8129654635774441
      ],
      "excerpt": "    <a href=\"https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\" class=\"uri\">https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8350544163907428
      ],
      "excerpt": "    <a href=\"https://github.com/davidsbatista/ConvNets-for-sentence-classification\" class=\"uri\">https://github.com/davidsbatista/ConvNets-for-sentence-classification</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740456448280757
      ],
      "excerpt": "    <a href=\"https://github.com/msahamed/yelp_comments_classification_nlp/blob/master/word_embeddings.ipynb\" class=\"uri\">https://github.com/msahamed/yelp_comments_classification_nlp/blob/master/word_embeddings.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8051379479619364
      ],
      "excerpt": "    <a href=\"https://towardsdatascience.com/transformers-141e32e69591\" class=\"uri\">https://towardsdatascience.com/transformers-141e32e69591</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030393445688805
      ],
      "excerpt": "    <a href=\"https://github.com/irfanelahi-ds/document-classification-python/blob/master/document_classification_python_sklearn_nltk.ipynb\" class=\"uri\">https://github.com/irfanelahi-ds/document-classification-python/blob/master/document_classification_python_sklearn_nltk.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740456448280757
      ],
      "excerpt": "    <a href=\"https://github.com/tthustla/setiment_analysis_pyspark/blob/master/Sentiment%20Analysis%20with%20PySpark.ipynb\" class=\"uri\">https://github.com/tthustla/setiment_analysis_pyspark/blob/master/Sentiment%20Analysis%20with%20PySpark.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.898833478966904
      ],
      "excerpt": "    <a href=\"https://github.com/susanli2016/NLP-with-Python/blob/master/Doc2Vec%20Consumer%20Complaint_3.ipynb\" class=\"uri\">https://github.com/susanli2016/NLP-with-Python/blob/master/Doc2Vec%20Consumer%20Complaint_3.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740456448280757
      ],
      "excerpt": "    <a href=\"https://github.com/stephenhky/PyWMD/blob/master/WordMoverDistanceDemo.ipynb\" class=\"uri\">https://github.com/stephenhky/PyWMD/blob/master/WordMoverDistanceDemo.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8129654635774441,
        0.8740456448280757
      ],
      "excerpt": "    <a href=\"https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Xgboost_bow_tfidf.ipynb\" class=\"uri\">https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Xgboost_bow_tfidf.ipynb</a> \n<a href=\"https://github.com/FelixChop/MediumArticles/blob/master/LDA-BBC.ipynb\" class=\"uri\">https://github.com/FelixChop/MediumArticles/blob/master/LDA-BBC.ipynb</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8462532158560175
      ],
      "excerpt": "    <a href=\"https://github.com/NicGian/text_VAE\" class=\"uri\">https://github.com/NicGian/text_VAE</a> \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8013210936554058
      ],
      "excerpt": "    Complete Essay \u2013 total number of upper count words in the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "TF IDF \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "TF-IDF + SVM \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "Doc2Vec + Text similarity: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/adsieg/Multi_Text_Classification/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Multi-classes task classification and LDA-based topic Recommender System",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Multi_Text_Classification",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "adsieg",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/adsieg/Multi_Text_Classification/blob/master/Readme.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 80,
      "date": "Sun, 26 Dec 2021 20:38:30 GMT"
    },
    "technique": "GitHub API"
  }
}
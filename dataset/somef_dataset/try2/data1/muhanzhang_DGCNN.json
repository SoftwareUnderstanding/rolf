{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find the code useful, please cite our paper:\n    \n    @inproceedings{zhang2018end,\n        title={An End-to-End Deep Learning Architecture for Graph Classification},\n        author={Zhang, Muhan and Cui, Zhicheng and Neumann, Marion and Chen, Yixin},\n        booktitle={AAAI},\n        pages={4438--4445},\n        year={2018}\n    } \n\nMuhan Zhang, muhan@wustl.edu\n12/2/2017\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{zhang2018end,\n    title={An End-to-End Deep Learning Architecture for Graph Classification},\n    author={Zhang, Muhan and Cui, Zhicheng and Neumann, Marion and Chen, Yixin},\n    booktitle={AAAI},\n    pages={4438--4445},\n    year={2018}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.916945666810024,
        0.9999009871171517
      ],
      "excerpt": "M. Zhang,  Z. Cui,  M. Neumann,  and Y. Chen,  An End-to-End Deep Learning Architecture for \nGraph Classification,  Proc. AAAI Conference on Artificial Intelligence (AAAI-18). [PDF] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8940583111730483,
        0.9985646390570283
      ],
      "excerpt": "N. Shervashidze, P. Schweitzer, E. J. van Leeuwen, K. Mehlhorn, and K. M. Borgwardt. \nWeisfeiler-lehman graph kernels. Journal of Machine Learning Research, 12:2539-2561, 2011. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/muhanzhang/DGCNN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-11-21T07:08:34Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-17T17:04:23Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9087555372717513,
        0.9952200559757586,
        0.9034002242182421,
        0.8762550292617958
      ],
      "excerpt": "The PyTorch implementation of DGCNN is here https://github.com/muhanzhang/pytorch_DGCNN, for those who prefer using python. \nA powerful deep neural network toolbox for graph classification, named Deep-Graph-CNN (DGCNN). DGCNN features a propagation-based graph convolution layer to extract vertex features, as well as a novel SortPooling layer which sorts vertex representations instead of summing them up. The sorting enables learning from global graph topology, and retains much more node information than summing. The SortPooling layer supports backpropagation, and sorts vertices without using any preprocessing software such as Nauty, which enables an elegant end-to-end training framework. \nFor more information, please refer to: \nM. Zhang,  Z. Cui,  M. Neumann,  and Y. Chen,  An End-to-End Deep Learning Architecture for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8824267902099139
      ],
      "excerpt": "The DGCNN is written in Torch. MATLAB is required if you want to compare DGCNN with graph kernels. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8247742299074567
      ],
      "excerpt": "The kernel matrices of the compared graph kernels should be put into \"data/kernels\". Run:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9374338919115662
      ],
      "excerpt": "to compute the kernel matrices of PK (since the PK software uses a different graph format). We also provide the precomputed kernel matrices for downloading in case you don't want to compute them by yourselves. (Some of them take really long time!) [Kernel matrices] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8508345152357836
      ],
      "excerpt": "in MATLAB, then the accuracy results of all graph kernels will be reported. At the same time, a fixed data shuffling order will be generated and saved in \"data/shuffle\" for each dataset (thus their train/val/test splits are fixed). These shuffle orders are already included in this toolbox. Change the rand_start inside compare.m to generate your own shuffle orders. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.963135350802287,
        0.8996479112998991,
        0.908925214220865
      ],
      "excerpt": "To compare DGCNN with graph kernels, libsvm is required to be installed in \"software/libsvm-3.22\". A zip of libsvm is included in \"software/\" already, you can unzip it and compile the mex files according to its documentations. \nTo compare with graph kernels, the toolbox \"graphkernels\" and \"propagation_kernels-master\" have been included in software/ already, which come from the following papers: \nN. Shervashidze, P. Schweitzer, E. J. van Leeuwen, K. Mehlhorn, and K. M. Borgwardt. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code for \"M. Zhang, Z. Cui, M. Neumann, and Y. Chen, An End-to-End Deep Learning Architecture for Graph Classification, AAAI-18\".",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/muhanzhang/DGCNN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 36,
      "date": "Wed, 29 Dec 2021 11:59:24 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/muhanzhang/DGCNN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "muhanzhang/DGCNN",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/muhanzhang/DGCNN/master/run_all.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8929472256410967
      ],
      "excerpt": "The PyTorch implementation of DGCNN is here https://github.com/muhanzhang/pytorch_DGCNN, for those who prefer using python. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9066940036629516,
        0.9623542036816334,
        0.847429480213769
      ],
      "excerpt": "Torch libraries needed: paths, torch, nn, cunn, cutorch, optim. Install them using: \nluarocks install --local libraryName \nThe main folder contains other required modules: SortPooling, GraphConv, GraphReLU, GraphTanh, GraphSelectTable, GraphConcatTable. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8745775550868141
      ],
      "excerpt": "Run \"th main.lua\" to have a try of DGCNN! \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/muhanzhang/DGCNN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "MATLAB",
      "Lua",
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License (MIT)\\n\\nCopyright (c) 2012--2014 Roman Garnett, Marion Neumann\\n\\nPermission is hereby granted, free of charge, to any person obtaining\\na copy of this software and associated documentation files (the\\n\"Software\"), to deal in the Software without restriction, including\\nwithout limitation the rights to use, copy, modify, merge, publish,\\ndistribute, sublicense, and/or sell copies of the Software, and to\\npermit persons to whom the Software is furnished to do so, subject to\\nthe following conditions:\\n\\nThe above copyright notice and this permission notice shall be\\nincluded in all copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Deep Graph Convolutional Neural Network (DGCNN)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DGCNN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "muhanzhang",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/muhanzhang/DGCNN/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you do not have a deep learning environment yet, install cuda and Torch as follows (suppose you have a GPU):\n\nInstall cuda following: http://developer.nvidia.com/cuda-downloads\n\nInstall Torch following this link: http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions\n\nThen, install necessary Torch libraries: cutorch, cunn, in order by:\n\n    luarocks install --local libraryName\n\nNow, you should be able to run Torch-based neural networks.\n\nThe folder \"data/\" contains the .dat graph datasets read by DGCNN. There is already a \"MUTAG.dat\" included for demo. Other graph datasets need to be generated manually:\n\n    th utils/generate_torch_graphs.lua\n\nwhich transforms the .mat graph datasets in \"data/raw_data/\" into .dat format. The \"torch.matio\" is required to be installed:\n\n    1# OSX\n    brew install homebrew/science/libmatio\n    2# Ubuntu\n    sudo apt-get install libmatio2\n    luarocks install --local matio\n\nIn case you cannot install \"torch.matio\", we also provide the converted \".dat\" for downloading directly [\\[Torch graph datasets\\]](https://drive.google.com/open?id=1vx19a8UTfj7vboafaoRtgIFv-dIqvhxl).\n\nTo run DGCNN on dataset \"DD\" (whose maximum node label is 89), with learning rate 1e-5, maximum epoch number 100, just type:\n\n    th main.lua -dataName DD -maxNodeLabel 89 -learningRate 1e-5 -maxEpoch 100\n\nAppend \"-batch -batchSize 16\" to run mini-batch optimization.\n\nTo repeatedly run DGCNN on some dataset using different shuffle orders, you can use the provided run_all.sh script:\n\n    time ./run_all.sh XXX i\n\nwhich runs DGCNN on dataset XXX with the ith GPU of your machine for 100 times, using the shuffle orders stored in \"data/shuffle\" (matio is required).\n\nThe main program of DGCNN is in \"main.lua\", please refer to it for more advanced functions to play with!\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 137,
      "date": "Wed, 29 Dec 2021 11:59:24 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "DGCNN reads graph dataset in the format of dataset = {instance={i: {1: A_i, 2: X_i}}, label={i: label_i}}. You can check the format type:\n\n    dataset = torch.load(\"data/MUTAG.dat\")\n\nin the torch command line th.\n\nWe also provide a \"generate_torch_graphs.lua\" in \"utils/\" which converts standard WL kernel toolbox's graph format to DGCNN format.\n\nThere is an option \"-testNumber 200\" in \"main.lua\", which allows specifying that the last 200 examples in the dataset is the testing data. This is convenient when you put your testing data after the training data when constructing the dataset.\n\n",
      "technique": "Header extraction"
    }
  ]
}
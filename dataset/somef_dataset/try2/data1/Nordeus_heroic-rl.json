{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2002.06290",
      "https://arxiv.org/abs/1707.06347",
      "https://arxiv.org/abs/2002.06290"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bibtex\n@article{warchalski2020heroicrl,\n  title={Deep RL Agent for a Real-Time Strategy Game},\n  author={Warchalski, Micha\u0142 and Radojevi\u0107, Dimitrije and Milo\u0161evi\u0107, Milo\u0161},\n  journal={arXiv preprint arXiv:2002.06290},\n  year={2020}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{warchalski2020heroicrl,\n  title={Deep RL Agent for a Real-Time Strategy Game},\n  author={Warchalski, Micha\u0142 and Radojevi\u0107, Dimitrije and Milo\u0161evi\u0107, Milo\u0161},\n  journal={arXiv preprint arXiv:2002.06290},\n  year={2020}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Nordeus/heroic-rl",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-23T14:17:10Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-22T03:59:11Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This is the codebase that was used to train and evaluate reinforcement learning\nagents that can play [Heroic - Magic Duel](https://www.heroicgame.com/), a\nreal-time strategy player-versus-player mobile game.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9554722826766671
      ],
      "excerpt": "Code for the paper Deep RL Agent for a Real-Time Strategy \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865,
        0.8097457780065668
      ],
      "excerpt": "Radojevi\u0107, and Milo\u0161 Milo\u0161evi\u0107. \nThere are two components to the system: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8210405132292351,
        0.9289908140101977,
        0.8195767500463851,
        0.8021430330764354
      ],
      "excerpt": "   configuration, Gym environment etc. This repository contains agent codebase. \n2. Training/inference server, which applies agent's actions to battle, and \n   returns observed battle state. This component is provided as a Docker image. \nAgents communicate with servers via HTTP. Server exposes a RESTful API for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9566193947666309
      ],
      "excerpt": "Heroic environment, including serialization and communication with server, is \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9787403692023003
      ],
      "excerpt": "Experimental RNN policy is also available. An implementation of \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865,
        0.9201685051445075,
        0.8981790656406607
      ],
      "excerpt": "baselines and \nstable-baselines, is used. More \ndetails in the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8545598478444048
      ],
      "excerpt": "adversaries of varying difficulty, e.g. classical AI bots that are provided \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8150648892400891,
        0.8938736052270801
      ],
      "excerpt": "GPUs are used for rollouts and update steps, if available. MPI is used as \nbackend for distributed Adam optimizers for policy and value functions, and for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.885404116627998,
        0.8500913264601172
      ],
      "excerpt": "also limited battle rendering capability, in form of terminal-based UI. \nRun an instance of training/inference server with: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8395547919131954
      ],
      "excerpt": "specifying multiple servers for agents to connect to, each agent subprocess \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9251043998232891,
        0.8128072803826962
      ],
      "excerpt": "In order to access this server from host machine, in case of running the agent from \nthe source, container port that server is listening on should be mapped to a port \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9759999759302672,
        0.8137165794205039
      ],
      "excerpt": "It is recommended to create a separate Docker network for communication between \nagent and server: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8016874586268058
      ],
      "excerpt": "current working dir on the host machine to /app/data dir within the container. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8448544612964493
      ],
      "excerpt": "Python 3.6.1 or greater is required to run this project. GNU C compiler and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9582747684224256
      ],
      "excerpt": "This project uses Poetry for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9766957315474967,
        0.8156226479684705
      ],
      "excerpt": "Exit the shell with Ctrl-D. \nTo train an agent for 1000 epochs against utility-based AI adversary, using \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9149671752769755
      ],
      "excerpt": "server listening at localhost:8081, and sane defaults for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9154966339853133
      ],
      "excerpt": "progress.txt in each agent dir, which contains pretty much all data that is \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8923391757843985
      ],
      "excerpt": "Training can be interrupted with Ctrl+C at any time. In order to resume an \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Reinforcement Learning Agent that plays Heroic - Magic Duel",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Nordeus/heroic-rl/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 10:59:11 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Nordeus/heroic-rl/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Nordeus/heroic-rl",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Nordeus/heroic-rl/master/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Nordeus/heroic-rl/master/docker-entrypoint.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.843817785627637
      ],
      "excerpt": "the source, container port that server is listening on should be mapped to a port \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8340247969518606
      ],
      "excerpt": "by directly appending them to Docker run command from above. Environment \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9006241682183381
      ],
      "excerpt": "a few more things are also needed - assuming Ubuntu 18.04, these can be \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9577488217937685
      ],
      "excerpt": "sudo apt-get install python3-venv python3-setuptools python3-dev gcc libopenmpi-dev \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8870250534500592
      ],
      "excerpt": "dependency management and as build tool. To install Poetry for current user, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8939635423155454
      ],
      "excerpt": "curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.999833231880651,
        0.9112661291212801
      ],
      "excerpt": "poetry install \nPoetry will create a new virtualenv, and install required dependencies and helper \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9330399853344404
      ],
      "excerpt": "GPU support. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9660526416208798
      ],
      "excerpt": "following to upgrade pip to latest version - this will only affect pip within \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9984324254048687
      ],
      "excerpt": "poetry run pip install -U pip \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8114439164958883
      ],
      "excerpt": "actions are exchanged in JSON format. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8417883006003093
      ],
      "excerpt": "There are two ways to run the agent, as Docker container or directly from \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856803591224107
      ],
      "excerpt": "Main agent script, heroic-rl, can be run containerized with: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8290121539717297
      ],
      "excerpt": "docker run -it --gpus all quay.io/nordeus/heroic-rl-agent \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8303643693706579
      ],
      "excerpt": "-v $PWD/data:/app/data to Docker run command. This will mount data dir in \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8378673841210036
      ],
      "excerpt": "As a result, all files will be written to the host directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008331685760428
      ],
      "excerpt": "poetry run heroic-rl \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8117343208375764
      ],
      "excerpt": "format, each checkpoint having its own directory named after the epoch at which \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8402650080282458
      ],
      "excerpt": "epoch 300, running on a training server listening at localhost:8081, run: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Nordeus/heroic-rl/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Dockerfile",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Heroic RL: Deep RL Agent for a Real-Time Strategy Game",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "heroic-rl",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Nordeus",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Nordeus/heroic-rl/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Agent provides CLI entrypoint called `heroic-rl` that is used to invoke training,\ninference and other commands.\n\nAvailable commands can be listed by running `heroic-rl`, and help for for each\ncommand is displayed by running `heroic-rl <command> --help`. Defaults for each\noption are also displayed.\n\nIn a nutshell:\n- `train` is used for starting a fresh training experiment,\n- `resume` resumes an existing experiment, which was interrupted before\n  completion,\n- `simulate` is used to run inference on specified number of battles with a\n  provided agent checkpoint, against specified adversary\n- `render` can display actual battle, using provided agent checkpoint as left player,\n  in a terminal user interface, based on `curses`\n- `serve` starts a Flask service that exposes inference with provided agent\n  checkpoint via RESTful API\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Thu, 23 Dec 2021 10:59:11 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "reinforcement-learning",
      "deep-learning",
      "heroic",
      "tensorflow",
      "rl",
      "gym"
    ],
    "technique": "GitHub API"
  }
}
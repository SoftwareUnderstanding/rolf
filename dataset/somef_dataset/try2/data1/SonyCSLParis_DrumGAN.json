{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1710.10196",
      "https://arxiv.org/abs/1812.08466"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SonyCSLParis/DrumGAN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-16T14:32:48Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T06:57:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9844253742864914,
        0.8796027293902631,
        0.9841257546579386
      ],
      "excerpt": "This repo contains code for running DrumGAN, a Generative Adversarial Network that synthesizes drum sounds offering control over prcetpual features. You can find details about the specific architecture and the experiment in our ISMIR paper. Some of the codes are borrowed from Facebook's GAN zoo repo. \nTHIS REPO IS NOT UP TO DATE YET! Please, come back later. Sorry for the inconvenience. \nWe train our model on a private, non-publicly available dataset containing 300k sounds of drum sounds equally distributed across kicks, snares and cymbals. This repo contains code for training a model on your own data. You will have to create a data loader, specific to the structure of your own dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Synthesis of Drum Sounds With Perceptual Timbral Conditioning Using Generative Adversarial Networks",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SonyCSLParis/DrumGAN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Mon, 27 Dec 2021 20:31:55 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/SonyCSLParis/DrumGAN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "SonyCSLParis/DrumGAN",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/SonyCSLParis/DrumGAN/master/shell_scripts/run_test_configs_local.sh",
      "https://raw.githubusercontent.com/SonyCSLParis/DrumGAN/master/shell_scripts/fad.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1) Install requirements:\n\n```\npip install -r requirements.txt\n```\n2) In order to compute the Fr\u00e9chet Audio Distance (FAD) download and install google AI repo following the instructions [here](https://github.com/google-research/google-research/tree/master/frechet_audio_distance)\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9424859873106725
      ],
      "excerpt": "python train.py $ARCH -c $PATH/TO/CONFIG/FILE \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/SonyCSLParis/DrumGAN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "DrumGAN: Synthesis of Drum Sounds With Timbral Feature Conditioning Using Generative Adversarial Networks",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DrumGAN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "SonyCSLParis",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SonyCSLParis/DrumGAN/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 46,
      "date": "Mon, 27 Dec 2021 20:31:55 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The experiments are defined in a configuration file with JSON format.\n```\n{\n    \"name\": \"mag-if_test_config\",\n    \"comments\": \"dummy configuration\",\n    \"output_path\": \"/path/to/output/folder\",\n    \"loader_config\": {\n        \"dbname\": \"nsynth\",\n        \"data_path\": \"/path/to/nsynth/audio/folder\",\n        \"attribute_file\": \"/path/to/nsynth/examples.json\",\n        \"filter_attributes\": {\n            \"instrument_family_str\": [\"brass\", \"guitar\", \"mallet\", \"keyboard\"],\n            \"instrument_source_str\": [\"acoustic\"]\n        },\n        \"shuffle\": true,\n        \"attributes\": [\"pitch\", \"instrument_family_str\"],\n        \"balance_att\": \"instrument_family_str\",\n        \"pitch_range\": [44, 70],\n        \"load_metadata\": true,\n        \"size\": 1000\n    },\n        \n    \"transform_config\": {\n        \"transform\": \"specgrams\",\n        \"fade_out\": true,\n        \"fft_size\": 1024,\n        \"win_size\": 1024,\n        \"n_frames\": 64,\n        \"hop_size\": 256,\n        \"log\": true,\n        \"ifreq\": true,\n        \"sample_rate\": 16000,\n        \"audio_length\": 16000\n    },\n    \"model_config\": {\n        \"formatLayerType\": \"default\",\n        \"ac_gan\": true,\n        \"downSamplingFactor\": [\n            [16, 16],\n            [8, 8],\n            [4, 4],\n            [2, 2],\n            [1, 1]\n        ],\n        \"maxIterAtScale\": [\n            50,\n            50,\n            50,\n            50,\n            50\n        ],\n        \"alphaJumpMode\": \"linear\",\n        \"alphaNJumps\": [\n            600,\n            600,\n            600,\n            600,\n            1200\n        ],\n        \"alphaSizeJumps\": [\n            32,\n            32,\n            32,\n            32,\n            32\n        ],\n        \"transposed\": false,\n        \"depthScales\": [\n            5,\n            5,\n            5,\n            5,\n            5\n        ],\n        \"miniBatchSize\": [\n            2,\n            2,\n            2,\n            2,\n            2\n        ],\n        \"dimLatentVector\": 2,\n        \"perChannelNormalization\": true,\n        \"lossMode\": \"WGANGP\",\n        \"lambdaGP\": 10.0,\n        \"leakyness\": 0.02,\n        \"miniBatchStdDev\": true,\n        \"baseLearningRate\": 0.0006,\n        \"dimOutput\": 1,\n        \"weightConditionG\": 10.0,\n        \"weightConditionD\": 10.0,\n        \"attribKeysOrder\": {\n            \"pitch\": 0,\n            \"instrument_family\": 1\n        },\n        \"startScale\": 0,\n        \"skipAttDfake\": []\n    }\n}\n\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "[Here](https://sites.google.com/view/drumgan) you can listen to audios synthesized with DrumGAN under different conditonal settings.\n\n",
      "technique": "Header extraction"
    }
  ]
}
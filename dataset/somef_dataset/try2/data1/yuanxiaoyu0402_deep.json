{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1406.2661"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8450045395698996,
        0.9944484218006108
      ],
      "excerpt": "2014\u5e74\uff0c\u8499\u7279\u5229\u5c14\u5927\u5b66(University of Montreal)\u7684\u4f0a\u6069\u2022\u53e4\u5fb7\u8d39\u52d2(Ian Goodfellow)\u548c\u5305\u62ec\u7ea6\u8212\u4e9a\u2022\u672c\u5409\u5965(yoshu Bengio)\u5728\u5185\u7684\u7814\u7a76\u4eba\u5458\u5728\u4e00\u7bc7\u8bba\u6587 \n(https://arxiv.org/abs/1406.2661)\u4e2d\u4ecb\u7ecd\u4e86GANs\u3002\u8bf4\u5230GANs\uff0c\u8138\u4e66\u7684\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u4e3b\u7ba1\uff0c\u626c\u00b7\u52d2\u6069\uff08Yann LeCun\uff09\u79f0\uff0c\u8fd9\u662f\u5728\u8fc7\u53bb\u5341\u5e74\u7684\u673a\u5668\u5b66\u4e60\u4e2d\u6700 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8937710860532944
      ],
      "excerpt": "plt.title(\"Model Losses\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "rows, cols = 10, 6 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yuanxiaoyu0402/deep",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-11-21T13:06:02Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-12-03T11:15:55Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9968029537584643
      ],
      "excerpt": "2014\u5e74\uff0c\u8499\u7279\u5229\u5c14\u5927\u5b66(University of Montreal)\u7684\u4f0a\u6069\u2022\u53e4\u5fb7\u8d39\u52d2(Ian Goodfellow)\u548c\u5305\u62ec\u7ea6\u8212\u4e9a\u2022\u672c\u5409\u5965(yoshu Bengio)\u5728\u5185\u7684\u7814\u7a76\u4eba\u5458\u5728\u4e00\u7bc7\u8bba\u6587 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8646676424487083
      ],
      "excerpt": "-new music and new-artists-project-magenta.html)\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9552606102729632
      ],
      "excerpt": "Defining the model input for the generator and discrimator \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9765389810844974
      ],
      "excerpt": ": calculating the losses of the discrimnator and generator \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8473557095127644
      ],
      "excerpt": ": building the model optimizer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9758232579587192
      ],
      "excerpt": ": Getting the trainable_variables of the computational graph, split into Generator and Discrimnator parts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9319708861235405
      ],
      "excerpt": "with tf.Session() as sess: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8720503789567184
      ],
      "excerpt": "        #: Get images, reshape and rescale to pass to D \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "    for ax, gen_image in zip(axes.flatten(), g_samples[0][epoch_num]): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "for gen_sample, ax_row in zip(gen_samples[::int(len(gen_sample)/cols)], ax_row): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9319708861235405,
        0.8490037945672047
      ],
      "excerpt": "with tf.Session() as sess: \n    #:restoring the saved checkpoints \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yuanxiaoyu0402/deep/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Wed, 29 Dec 2021 07:50:17 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yuanxiaoyu0402/deep/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "yuanxiaoyu0402/deep",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "discrimator_real_dim), name=\u201dreal_discrminator_input\u201d ) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "name = \u201cgenerator_input_z\u201d) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9068127677393759,
        0.8224822248496663,
        0.9457175861910134,
        0.925671696398174
      ],
      "excerpt": "Import matplotlib.pyplot as plt \nImport pickle as pkl \nImport numpy as np \nImport tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9199746626461769
      ],
      "excerpt": "from tensorflow.example.tutorials.mnist import input_data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8293630417981156,
        0.8421074476017179,
        0.8293630417981156,
        0.8421074476017179
      ],
      "excerpt": "   real_discrminator_input = tf.placeholder(tf.float32, (None, \ndiscrimator_real_dim), name=\u201dreal_discrminator_input\u201d ) \n       generator_inputs_z = tf.placeholder(tf.float32, (None, gen_z_dim), \nname = \u201cgenerator_input_z\u201d) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8640813949842844,
        0.8123763140827432
      ],
      "excerpt": "def generator(gen_z,gen_out_dim,num_hiddern_units=128,reuse_vars=False,leaky_relu_alpha=0.01); \n\u6784\u5efa\u7f51\u7edc\u751f\u6210\u5668\u90e8\u5206,\u51fd\u6570\u53c2\u6570:gen_z:\u751f\u6210\u5668\u8f93\u5165\u5f20\u91cf;gen_out_dim:\u751f\u6210\u5668\u7684\u8f93\u51fa\u5f62\u72b6;num_hiddern_units:\u795e\u7ecf\u5143\u7684\u6570\u91cf/\u9690\u85cf\u5c42\u4e2d\u7684\u5355\u4f4d\uff1areuse_vars:tf.variable_scope\u4e2d\u7684\u91cd\u7528\u53d8\u91cf\uff1bleaky_relu:Leaky ReLU\u53c2\u6570;\u51fd\u6570\u8fd4\u56de:sigmoid_out;logits_layer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8540809412096545,
        0.8123763140827432
      ],
      "excerpt": "def discriminator(disc_input,num_hiddern_units=128,reuse_vars=False,leaky_relu_alpha=0.01) \n\u6784\u5efa\u7f51\u7edc\u5224\u522b\u5668\u90e8\u5206,\u51fd\u6570\u53c2\u6570:disc_input:\u5224\u522b\u5668\u8f93\u5165\u5f20\u91cf;num_hiddern_units:\u795e\u7ecf\u5143\u7684\u6570\u91cf/\u9690\u85cf\u5c42\u4e2d\u7684\u5355\u4f4d\uff1areuse_vars:tf.variable_scope\u4e2d\u7684\u91cd\u7528\u53d8\u91cf\uff1bleaky_relu_alpha:Leaky ReLU\u53c2\u6570;\u51fd\u6570\u8fd4\u56de:sigmoid_out;logits_layer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": " sigmoid_out=tf.nn.sigmoid(logits_layer) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8828665034782968
      ],
      "excerpt": " leaky_relu_alpha=0.01 #:\u63a7\u5236leak\u529f\u80fd\u7684leaky relu  alpha\u53c2\u6570 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": " tf.reset_default_graph() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "    tf.nn.sigmoid_cross_entropy_with_logits( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "disc_labels_real = tf.ones_like(disc_logits_real) * (1 - label_smooth) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432
      ],
      "excerpt": "disc_labels_real = tf.ones_like(disc_logits_real) * (1 - label_smooth) \ndisc_labels_fake = tf.zeros_like(disc_logits_fake) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "disc_loss = tf.reduce_mean(disc_loss_real + disc_loss_fake) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432
      ],
      "excerpt": "gen_loss = tf.reduce_mean( \n    tf.nn.sigmoid_cross_entropy_with_logits( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8478184596433345,
        0.8405803199081844,
        0.8936954105699045,
        0.8936954105699045
      ],
      "excerpt": "trainable_vars = tf.trainable_variables() \ngen_vars = [var for var in trainable_vars if var.name.startswith(\"generator\")] \ndisc_vars = [var for var in trainable_vars if var.name.startswith(\"discriminator\")] \ndisc_train_optimizer = tf.train.AdamOptimizer().minimize(disc_loss, var_list=disc_vars) \ngen_train_optimizer = tf.train.AdamOptimizer().minimize(gen_loss, var_list=gen_vars) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8936954105699045,
        0.8135654125968134,
        0.8670539095623045
      ],
      "excerpt": "saver = tf.train.Saver(var_list=gen_vars) \nwith tf.Session() as sess: \n    sess.run(tf.global_variables_initializer()) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "        input_batch = mnist_dataset.train.next_batch(train_batch_size) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8870850356999765,
        0.8008331685760428,
        0.8008331685760428
      ],
      "excerpt": "        gen_batch_z = np.random.uniform(-1, 1, size=(train_batch_size, gen_z_size)) \n        #: Run optimizers \n        _ = sess.run(disc_train_optimizer, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008331685760428
      ],
      "excerpt": "        _ = sess.run(gen_train_optimizer, feed_dict={generator_input_z: gen_batch_z}) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008331685760428
      ],
      "excerpt": "    train_loss_disc = sess.run(disc_loss, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9294184993106162
      ],
      "excerpt": "    print(\"Epoch {}/{}...\".format(e + 1, num_epochs), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8892402590147133,
        0.8008331685760428
      ],
      "excerpt": "    gen_sample_z = np.random.uniform(-1, 1, size=(16, gen_z_size)) \n    generator_samples = sess.run( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8119462732719988
      ],
      "excerpt": ": Save training generator samples \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9371031865737048,
        0.9241022411340848,
        0.8430239469891222,
        0.8569336070529349
      ],
      "excerpt": "fig, ax = plt.subplots() \nmodel_losses = np.array(model_losses) \nplt.plot(model_losses.T[0], label='Disc loss') \nplt.plot(model_losses.T[1], label='Gen loss') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9074429867739895,
        0.9312650322969277,
        0.8099617344552934,
        0.9010250244254832,
        0.9000107903124189
      ],
      "excerpt": "    fig, axes = plt.subplots(figsize=(7, 7), nrows=4, ncols=4, sharet = True, sharex = True) \n    print(gen_samples[epoch_num][1].shape) \n    for ax, gen_image in zip(axes.flatten(), g_samples[0][epoch_num]): \n        ax.xaxis.set_visible(False) \n        ax.yaxis.set_visible(Flase) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8904338393062002
      ],
      "excerpt": "fig, axes = plt.subplots(figsize=(7,12), nrows=rows, ncols=cols, sharex = True, sharey=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8372595496756373
      ],
      "excerpt": "for gen_sample, ax_row in zip(gen_samples[::int(len(gen_sample)/cols)], ax_row): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9010250244254832,
        0.9010250244254832
      ],
      "excerpt": "    ax.xaxis.set_visible(False) \n    ax.yaxis.set_visible(False) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8936954105699045,
        0.8135654125968134
      ],
      "excerpt": "saver = tf.train.Saver(var_list=g_vars) \nwith tf.Session() as sess: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8529696998462948,
        0.8892402590147133,
        0.8008331685760428
      ],
      "excerpt": "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints')) \n    gen_sample_z = np.random.uniform(-1, 1, size=(16, z_size)) \n    generated_samples = sess.run( \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yuanxiaoyu0402/deep/issues{/number}",
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# \u7b2c14\u7ae0\u751f\u6210\u5bf9\u6297\u7f51\u7edc",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "deep",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "yuanxiaoyu0402",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yuanxiaoyu0402/deep/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 07:50:17 GMT"
    },
    "technique": "GitHub API"
  }
}
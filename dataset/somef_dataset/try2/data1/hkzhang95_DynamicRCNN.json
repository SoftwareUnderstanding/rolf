{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [maskrcnn-benchmark](https://github.com/facebookresearch/maskrcnn-benchmark)\n- [light_head_rcnn](https://github.com/zengarden/light_head_rcnn)\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2004.06002"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please consider citing our paper in your publications if it helps your research:\n\n```\n@inproceedings{DynamicRCNN,\n    author = {Zhang, Hongkai and Chang, Hong and Ma, Bingpeng and Wang, Naiyan and Chen, Xilin},\n    title = {Dynamic {R-CNN}: Towards High Quality Object Detection via Dynamic Training},\n    booktitle = {ECCV},\n    year = {2020}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{DynamicRCNN,\n    author = {Zhang, Hongkai and Chang, Hong and Ma, Bingpeng and Wang, Naiyan and Chen, Xilin},\n    title = {Dynamic {R-CNN}: Towards High Quality Object Detection via Dynamic Training},\n    booktitle = {ECCV},\n    year = {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9978748560189858
      ],
      "excerpt": "By Hongkai Zhang, Hong Chang, Bingpeng Ma, Naiyan Wang, Xilin Chen. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hkzhang95/DynamicRCNN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-04-05T12:46:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-07T07:19:45Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9857990327980558,
        0.9842332917152871,
        0.9938729422016647
      ],
      "excerpt": "This project is based on maskrcnn-benchmark. \n[2020.7] Dynamic R-CNN is officially included in MMDetection V2.2, many thanks to @xvjiarui and @hellock for migrating the code. \nAlthough two-stage object detectors have continuously advanced the state-of-the-art performance in recent years, the training process itself is far from crystal. In this work, we first point out the inconsistency problem between the fixed network settings and the dynamic training procedure, which greatly affects the performance. For example, the fixed label assignment strategy and regression loss function cannot fit the distribution change of proposals and are harmful to training high quality detectors. Then, we propose Dynamic R-CNN to adjust the label assignment criteria (IoU threshold) and the shape of regression loss function (parameters of SmoothL1 Loss) automatically based on the statistics of proposals during training. This dynamic design makes better use of the training samples and pushes the detector to fit more high quality samples. Specifically, our method improves upon ResNet-50-FPN baseline with 1.9% AP and 5.5% AP90 on the MS COCO dataset with no extra overhead. For more details, please refer to our paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8308355721681991,
        0.9404919495062105,
        0.9238748362835445,
        0.9504859953250248
      ],
      "excerpt": "1x, 2x and 3x mean the model is trained for 90K, 180K and 270K iterations, respectively. \nFor Multi-scale training, the shorter side of images is randomly chosen from (400, 600, 800, 1000, 1200), and the longer side is 1400. We also extend the training time by 1.5x under this setting. \ndcnv2 denotes deformable convolutional networks v2. We follow the same setting as maskrcnn-benchmark. Note that the result of this version is slightly lower than that of mmdetection. \nAll results in the table are obtained using a single model with no extra testing tricks. Additionally, adopting multi-scale testing on model Dynamic_RCNN_r101_dcnv2_fpn_3x achieves 49.2% in AP on COCO test-dev. Please set TEST.BBOX_AUG.ENABLED = True in the config.py to enable multi-scale testing. Here we use five scales with shorter sides (800, 1000, 1200, 1400, 1600) and the longer side is 2000 pixels. Note that Dynamic R-CNN*(50.1% AP) in Table 9 is implemented using MMDetection v1.1, please refer to this link. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9064669786854567
      ],
      "excerpt": "Using -i to specify iteration for testing, default is the latest model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Dynamic R-CNN: Towards High Quality Object Detection via Dynamic Training, ECCV 2020",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hkzhang95/DynamicRCNN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 22,
      "date": "Sat, 25 Dec 2021 10:08:01 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hkzhang95/DynamicRCNN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "hkzhang95/DynamicRCNN",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\ncd ${DynamicRCNN_ROOT}\nmkdir data\nmkdir output\n```\n\nPrepare data and pretrained models:\n- [COCO dataset](http://cocodataset.org/#download)\n- [ImageNet Pretrained Models from Detectron](https://github.com/facebookresearch/Detectron/blob/master/MODEL_ZOO.md#imagenet-pretrained-models)\n\nThen organize them as follows:\n\n```\nDynamicRCNN\n\u251c\u2500\u2500 dynamic_rcnn\n\u251c\u2500\u2500 models\n\u251c\u2500\u2500 output\n\u251c\u2500\u2500 data\n\u2502   \u251c\u2500\u2500 basemodels/R-50.pkl\n\u2502   \u251c\u2500\u2500 coco\n\u2502   \u2502   \u251c\u2500\u2500 annotations\n\u2502   \u2502   \u251c\u2500\u2500 train2017(2014)\n\u2502   \u2502   \u251c\u2500\u2500 val2017(2014)\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9893272198983933,
        0.8690370344465135,
        0.9906248903846466,
        0.8255599467860235
      ],
      "excerpt": "git clone https://github.com/hkzhang95/DynamicRCNN.git \nPlease make sure your CUDA is successfully installed and be added to the PATH. I only test CUDA-9.0 for my experiments. \ncd ${DynamicRCNN_ROOT} \npython setup.py build develop \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9863323256182294
      ],
      "excerpt": "cd models/zhanghongkai/dynamic_rcnn/coco/dynamic_rcnn_r50_fpn_1x \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9863323256182294
      ],
      "excerpt": "cd models/zhanghongkai/dynamic_rcnn/coco/dynamic_rcnn_r50_fpn_1x \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8180214121464027
      ],
      "excerpt": "realpath log | xargs mkdir \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8216139382993012,
        0.869510629300804
      ],
      "excerpt": "python -m torch.distributed.launch --nproc_per_node=8 train.py \nTraining and testing logs will be saved automatically in the output directory following the same path as in models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8842360254549434
      ],
      "excerpt": "python config.py -log \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8228195331938243
      ],
      "excerpt": "python -m torch.distributed.launch --nproc_per_node=8 test.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8228195331938243
      ],
      "excerpt": "python -m torch.distributed.launch --nproc_per_node=8 test.py -i $iteration_number \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216270093103228
      ],
      "excerpt": ": example for Dynamic_RCNN_r50_fpn_1x \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8842360254549434
      ],
      "excerpt": "python config.py -log \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hkzhang95/DynamicRCNN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cuda",
      "C++"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Hongkai Zhang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Dynamic R-CNN: Towards High Quality Object Detection via Dynamic Training",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DynamicRCNN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "hkzhang95",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hkzhang95/DynamicRCNN/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- pytorch (v1.0.1.post2, other version have not been tested)\n- torchvision (v0.2.2.post3, other version have not been tested)\n- cocoapi\n- matplotlib\n- tqdm\n- cython\n- easydict\n- opencv\n\nAnaconda3 is recommended here since it integrates many useful packages. Please make sure that your conda is setup properly with the right environment. Then install `pytorch` and `torchvision` manually as follows:\n\n```bash\npip install torch==1.0.1.post2\npip install torchvision==0.2.2.post3\n```\n\nOther dependencies will be installed during `setup`.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 162,
      "date": "Sat, 25 Dec 2021 10:08:01 GMT"
    },
    "technique": "GitHub API"
  }
}
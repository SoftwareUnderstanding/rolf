{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2005.14165",
      "https://arxiv.org/abs/2005.14165",
      "https://arxiv.org/abs/2102.09690"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please consider citing our work if you found this code or our paper beneficial to your research.\n```\n@article{Zhao2021Calibrate,\t\n  Author = {Tony Z. Zhao and Eric Wallace and Shi Feng and Dan Klein and Sameer Singh},\t\n  Journal={arXiv preprint arXiv:2102.09690},\t\n  Year = {2021},\t\n  Title = {Calibrate Before Use: Improving Few-shot Performance of Language Models}\t\n}    \t\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{Zhao2021Calibrate, \n  Author = {Tony Z. Zhao and Eric Wallace and Shi Feng and Dan Klein and Sameer Singh}, \n  Journal={arXiv preprint arXiv:2102.09690},    \n  Year = {2021},    \n  Title = {Calibrate Before Use: Improving Few-shot Performance of Language Models} \n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/crazydigger/Callibration-of-GPT",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This code was developed by Tony Z. Zhao and Eric Wallace, contact available at tonyzhao0824@berkeley.edu and ericwallace@berkeley.edu.\t\n\nIf you'd like to contribute code, feel free to open a [pull request](https://github.com/tonyzhaozh/few-shot-learning/pulls). If you find an issue, please open an [issue](https://github.com/tonyzhaozh/few-shot-learning/issues).\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-11T10:30:31Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-23T14:52:56Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9686964387406665
      ],
      "excerpt": "This is a codebase to perform few-shot \"in-context\" learning using language models similar to the GPT-3 paper. In particular, a few training examples are placed into a natural language \"prompt\" and predictions are made by generating from the language model. See the GPT-3 paper and Calibrate Before Use for more information. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9877480757822289
      ],
      "excerpt": "Here is how to replicate the results from our paper for GPT-2. To replicate the results for classification tasks: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "--model=\"gpt2-xl\" \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9019665587031888
      ],
      "excerpt": "To replicate the results for extraction tasks: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "--model=\"gpt2-xl\" \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.974642609984308
      ],
      "excerpt": "To replicate the results for LAMA: \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/crazydigger/Callibration-of-GPT/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 06:05:55 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/crazydigger/Callibration-of-GPT/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "crazydigger/Callibration-of-GPT",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The easiest way to install the code is to create a fresh anaconda environment:\n```\nconda create -n fewshot python=3.6\nsource activate fewshot\npip install -r requirements.txt\n```\nNow you should be ready to go!\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8524457426084595
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0 python run_classification.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8524457426084595
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0 python run_extraction.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8524457426084595
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0 python run_lama.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/crazydigger/Callibration-of-GPT/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Few-shot Learning With Language Models",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Callibration-of-GPT",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "crazydigger",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/crazydigger/Callibration-of-GPT/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This code is written using PyTorch and [HuggingFace's Transformer repo](https://github.com/huggingface/pytorch-transformers). If you are running a model locally (e.g., GPT-2), the code requires a single GPU. Running these experiments is relatively lightweight (there is no training), so a single GPU is sufficient. It is technically possible to run the experiments without a GPU, but the runtime will be slow.\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The run scripts, e.g., `run_classification.py`, contain the code for randomly sampling the examples to use in the prompt, calling the models, the necessary evaluation metrics, and more. If you are adding a new task format (one that is not classification, QA) then you will need to write your own run script. Inside the run script, you can set the parameters for the experiments using the command line arguments.\n\nFor all experiments, we save and pickle the outputs of the model. This makes doing a post-hoc analysis of the accuracy / plotting results / etc. very fast. You can also use the saved outputs to evaluate how the accuracy would have changed if a different decision making function was used (e.g., accuracy with and without contextual calibration).\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Mon, 27 Dec 2021 06:05:55 GMT"
    },
    "technique": "GitHub API"
  }
}
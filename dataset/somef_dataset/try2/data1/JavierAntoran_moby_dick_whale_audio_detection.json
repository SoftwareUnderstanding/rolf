{
  "citation": [
    {
      "confidence": [
        0.8656070203791273
      ],
      "excerpt": "Contest winners repo: https://github.com/nmkridler/moby2 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JavierAntoran/moby_dick_whale_audio_detection",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-05-09T07:26:31Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-26T12:36:04Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.985617638357083
      ],
      "excerpt": "This repo contains our approach to to solving the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9284460791003223,
        0.8548791057151489,
        0.879159792831872,
        0.9608759433233642
      ],
      "excerpt": "is to identify North Atlantic Right Whale (NARW) upcalls from a dataset of audio recordings. These recordings \nare taken by microphones placed on buoys. \nThis makes the task difficult as sea movements introduce a lot of noise. \nAlso, NARWs and other marine mammals have calls which are hard to distinguish. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8545756738143057
      ],
      "excerpt": "HMMs, Neural Nets, and Gradient Boosting. We show a different \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9621544850564263,
        0.914685465491155,
        0.8072425600467609
      ],
      "excerpt": "This gives us frequency resolution up to 1kHz. NARW upcalls are generally in the range of 50-450 Hz. \nWe therefore apply a downsampling factor of 2 to all audio clips. \n The dataset is unbalanced with only 7027 positive examples (23.4%). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9106554909957684
      ],
      "excerpt": "For a more in depth overview see the project <a href=\"slides/whale_presentation.pdf\" download>slides</a>. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8824161394483883,
        0.9755581109115234,
        0.9889885431674708,
        0.9407579389945742
      ],
      "excerpt": "the gradient boosted trees. Another untested option is to give the neural network \nsome of the features used with the gradient booster as additional inputs. \nA summary of our results: \n| ROC-AUC | CNN 25ms | CNN 250ms |   HMM  | Grad Boosting | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9504713748653859
      ],
      "excerpt": "ROC curves obtained with our best performing method (Neural Net with wide FFT window). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8749547581451068,
        0.9797940352030073,
        0.8851091496907778
      ],
      "excerpt": "We represent sound clips as spectrograms, apply some basic image processing \nand feed them into our classifier CNN. \nNotebook for this section \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9837070495141336,
        0.9294380287854195,
        0.9413964448389762
      ],
      "excerpt": "size of 25ms and a time advance between frame starts of 10ms. These are \ntypical values for speech processing. However, because of the time-frequency uncertainty \nprinciple, <img src=\"https://latex.codecogs.com/gif.latex?\\Delta\\.t \\Delta\\.f \\geq \\frac{1}{4\\pi}  \" /> , with a small window, our estimation of frequency coefficient \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9495703676913093,
        0.9416915271131598
      ],
      "excerpt": "where whale upcalls reside. For this reason, we generate a second set of features \nwith a 250 ms frame and a 11 ms step between frame starts (this values is chosen in order to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9490664586551444,
        0.9881372738327651
      ],
      "excerpt": "We apply a hamming window and calculate the 256 point fft of every frame. \nWe keep the first 128 coefficients as our data is real and the rest of the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9544971507980408,
        0.9477000739631618
      ],
      "excerpt": "We generate a filter bank of 32 filters taken the region of 40-1000 Hz. In this range, \n the MFB weighs all frequencies almost linearly, with slightly more resolution \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.991544822940265,
        0.8911349808346106,
        0.9825001807226988
      ],
      "excerpt": " This is consistent with the energy distribution of whale upcalls. \n We choose 32 mel filter bands as maximum size of the receptive fields for individual units \n of our network will be of size 32x32. The whale filter bank matrix is shown in the following image: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9873942118063527,
        0.8745155780023287,
        0.9861616139279357
      ],
      "excerpt": "Finally, we compute the first and second derivatives of our features with respect to time (delta features). \nWe stack the spectrogram and its derivativ es as to form channels which we will \npass as input to our CNN. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8211668044577481
      ],
      "excerpt": "To parse the data with a 25ms window run the following commands: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8979411005071259
      ],
      "excerpt": "cp ../whale_traindata.npy data \ncp ../whale_trainlabels.npy data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8211668044577481
      ],
      "excerpt": "To parse the data with a 250ms window run the following commands: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8979411005071259
      ],
      "excerpt": "cp ../whale_traindata.npy data \ncp ../whale_trainlabels.npy data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9829093791373985
      ],
      "excerpt": "Our implementation, which is heavily based on this one, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9746071191328329
      ],
      "excerpt": "are Nx3x198x32 and Nx3x196x32. We use random cropping on the 25ms features to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8533924658445491
      ],
      "excerpt": "We separate our data into windows, we extract 30 multiresolution features from each window \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8251934405033443,
        0.9588409044654287
      ],
      "excerpt": "on negative examples. We calculate the probability of there being a whale call \nas the softmax of the normalized log likelihood of \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9331437576674337,
        0.9842028425234418
      ],
      "excerpt": "We use the stationary transform (SWT) to get around the time-frequency resolution \ntrade off while maintaining the length of our time series. This is important as we \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8060266023615605
      ],
      "excerpt": "window to each frequency band.\\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9387105821165874,
        0.9190765265644755
      ],
      "excerpt": "Instead of downsampling the signal as is done in the DWT, the SWT upsamples the filter after each step. \nThis is more computationally expensive but preserves signal length. The following schematic shows the SWT \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9014917442721606,
        0.8789133127413739
      ],
      "excerpt": "We keep the approximation signals (output of low pass filters) at levels 1, 2 and 3. \nWe then separate these signals into 250ms frames with a 10ms step between frame starts. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9611886068814681
      ],
      "excerpt": "our original signal is real valued, we obtain 128 frequency coefficients. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.949929629576803,
        0.9530826483865369
      ],
      "excerpt": "We then apply our whale filter bank to all three signals. We only keep coefficients \nthat are located in the passing band of their corresponding wavelet. We stack these \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8108124029526882,
        0.9491728016024054
      ],
      "excerpt": "We then apply a DCT transformation to each frame's frequency coefficients in order \nto obtain decorrelated features. Finally we normalize the features by \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8979411005071259
      ],
      "excerpt": "cp ../whale_traindata.npy data \ncp ../whale_trainlabels.npy data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8748618388217198,
        0.9566721925238014
      ],
      "excerpt": "them using the Viterbi algorithm. We place a Dirichlet prior on state transition \nprobabilities in order to aid training. This also assures that we end up with no \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8943564179593145,
        0.9001544475480718,
        0.8490037945672047
      ],
      "excerpt": "Our GMM implementation is also written in numpy and can be found in the HMM_solution/hmm/modules/GMM.py file. \nWe train our GMMs with two EM algorithm steps each time we pass our data through \nthe HMM. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9259373438971475
      ],
      "excerpt": "We obtain poor results with this method. Using a 10 hidden state HMMs with \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9651713950076515,
        0.8983877343556859,
        0.9974864595185978,
        0.9885162911770266
      ],
      "excerpt": "We generate 300 templates composed of lines of different lengths and inclinations \nin order to match the shape of whale upcalls. Calculate the cross correlation \n of these templates with our spectrograms in order to probe for different time-frequency \n shift rates in the data. This technique is a proof of concept. Similar results can \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8979411005071259
      ],
      "excerpt": "cp ../whale_traindata.npy data \ncp ../whale_trainlabels.npy data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9911105683635161
      ],
      "excerpt": "With 30000 spectrograms and 300 templates, processing all of our data will \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8976905242490141,
        0.9461966252542392
      ],
      "excerpt": "mean, std, skewness and kurtosis. This results in 3300 features per spectrogram. \nIn order to achieve task distribution, we make use of HTCondor(https://research.cs.wisc.edu/htcondor/) which was installed on the server. It is a software framework for coarse-grained distributed parallelization of computationally intensive tasks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8581130121282121,
        0.9270852887529117
      ],
      "excerpt": "We use the extracted features as inputs to a gradient boosting algorithm: XGboost. \nWe obtain decent results, especially considering the simplicity of our feature extraction \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.937786841575743
      ],
      "excerpt": "An assortment of publications related to Neural Nets, HMMs, Gradient Boosting and Marine \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8292046469200874
      ],
      "excerpt": "Simplenet paper: HasanPour, Seyyed Hossein et al. \u201cLet \u2019 s keep it simple : Using simple architectures to outperform deeper architectures.\u201d (2016).\\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8119541910778083
      ],
      "excerpt": "XGboost: website\\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": " Feature extraction, HMMs, Neural Nets, and Boosting for Kaggle Cornell Whale detection challenge. ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JavierAntoran/moby_dick_whale_audio_detection/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sat, 25 Dec 2021 15:48:54 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/JavierAntoran/moby_dick_whale_audio_detection/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "JavierAntoran/moby_dick_whale_audio_detection",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/JavierAntoran/moby_dick_whale_audio_detection/master/Notebooks/format_data_NN.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/JavierAntoran/moby_dick_whale_audio_detection/master/template_boosting_solution/condor_python_for.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "First download the dataset and extract the whale_data folder.\nRun the following script in order to save train samples and labels to .npy files.\n```bash\npython read_data.py\n```\nThis should generate two files: whale_traindata.npy and whale_trainlabels.npy. These will\nbe used as input to our feature extraction scripts.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd NN_solution \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd NN_solution \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd NN_solution/delta_spectrogram_simplenet/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd NN_solution/delta_spectrogram_simplenet/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd NN_solution/delta_spectrogram_simplenet/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd NN_solution/delta_spectrogram_simplenet/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.906860005714841
      ],
      "excerpt": "Pytorch models will be saved to the NN_solution/models directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8260846080544921
      ],
      "excerpt": " We train one on positive examples and the other one \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.836421126359174
      ],
      "excerpt": "We use the db2 wavelet which has the following form: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd HMM_solution/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9666287796935795,
        0.9906248903846466
      ],
      "excerpt": "To train both HMMs, run the following commands: \ncd HMM_solution/hmm \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd HMM_solution/hmm \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd /template_boosting_solution \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd template_boosting_solution \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd template_boosting_solution \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731638226107059
      ],
      "excerpt": "Contest winners repo: https://github.com/nmkridler/moby2 \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9156781332708049
      ],
      "excerpt": "<img src=\"images/spectrogram_comparison.png\" width=\"680\" height=\"350\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8430720552216758
      ],
      "excerpt": " The dataset is unbalanced with only 7027 positive examples (23.4%). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8411359759675264
      ],
      "excerpt": "deviation when running 10 fold cross validation using 10% of data for testing. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9059821652011756
      ],
      "excerpt": "<img src=\"images/best_ROC_250.png\" width=\"360\" height=\"290\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9059821652011756
      ],
      "excerpt": "<img src=\"images/fft_250_25ms.png\" width=\"700\" height=\"290\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9059821652011756
      ],
      "excerpt": "<img src=\"images/whale_filterbank.png\" width=\"360\" height=\"290\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9227741113294464
      ],
      "excerpt": "<img src=\"images/delta_feats.png\" width=\"400\" height=\"500\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python format_data_25ms.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python format_data_250ms.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8125693390643414
      ],
      "excerpt": "We use a 90/10% train/validation data split with 10 fold cross validation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9059821652011756
      ],
      "excerpt": "<img src=\"images/NN_results.png\" width=\"650\" height=\"290\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python run1_train.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python run2_cross_validate.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python run3_train_widewindow.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python run4_cross_validate_widewindow.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9227741113294464
      ],
      "excerpt": "<img src=\"images/wavelet_resolution.png\" width=\"400\" height=\"220\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156781332708049
      ],
      "excerpt": "<img src=\"images/swt_schematic.png\" width=\"600\" height=\"220\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9192247769614077
      ],
      "excerpt": "<img src=\"images/db2.png\" width=\"300\" height=\"200\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9192247769614077
      ],
      "excerpt": "<img src=\"images/swt_spectrograms.png\" width=\"700\" height=\"200\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156781332708049
      ],
      "excerpt": "<img src=\"images/multiresolution.png\" width=\"300\" height=\"250\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156781332708049
      ],
      "excerpt": "<img src=\"images/dct_multiresolution.png\" width=\"630\" height=\"280\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python format_data_wavelets_dct.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156781332708049
      ],
      "excerpt": "<img src=\"images/HMM_GMM.png\" width=\"380\" height=\"220\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9265874992101083
      ],
      "excerpt": "<img src=\"images/best_hmm_roc.jpg\" width=\"360\" height=\"290\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python run1_train_hmm.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python run2_eval_hmm.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156781332708049
      ],
      "excerpt": "<img src=\"images/template_xcorr.png\" width=\"660\" height=\"350\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8595478383164321,
        0.9265644979971633
      ],
      "excerpt": "python format_data.py #: Get spectrograms \npython paraidiots_data.py 10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8122627207904264
      ],
      "excerpt": "max value, mean value, std all values. We also extract the following axis wise (x, y) features: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.804642408471343
      ],
      "excerpt": "python generate_templates.py 3000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156781332708049
      ],
      "excerpt": "<img src=\"images/best_ROC_xcorr.png\" width=\"360\" height=\"300\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python gradient_booster.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python gradient_booster_crossvalidate.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/JavierAntoran/moby_dick_whale_audio_detection/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "MATLAB",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Javier Antoran, Alberto Mur\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "moby-dick Whale Detection",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "moby_dick_whale_audio_detection",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "JavierAntoran",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JavierAntoran/moby_dick_whale_audio_detection/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Sat, 25 Dec 2021 15:48:54 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "neural-network",
      "feature-extraction",
      "hmm",
      "cross-validation",
      "whale",
      "spectrogram",
      "mfcc",
      "extract-features",
      "gradient-boosting"
    ],
    "technique": "GitHub API"
  }
}
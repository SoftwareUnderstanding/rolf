{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1505.04597",
      "https://arxiv.org/abs/1505.04597",
      "https://arxiv.org/abs/1505.04597"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "U-Net quickstart \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8814848301044168
      ],
      "excerpt": "  <img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" width=\"500\" align=\"middle\"/> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cosmic-cortex/pytorch-UNet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-17T15:19:18Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-26T07:25:06Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9607607122464501
      ],
      "excerpt": "A tunable implementation of U-Net in PyTorch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8923858908958955,
        0.8627403263917426,
        0.8327127474102957
      ],
      "excerpt": "Utilities for training the model \nWrapper for training and inference \nDatasets and augmentation transforms \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8201676160653765
      ],
      "excerpt": "U-Net is a powerful encoder-decoder CNN architecture for semantic segmentation, developed by Olaf Ronneberger,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9086191304696811,
        0.9802271731436949,
        0.8780456827985742,
        0.9626890754263225
      ],
      "excerpt": "This repository was created to  \n1. provide a reference implementation of 2D and 3D U-Net in PyTorch, \n2. allow fast prototyping and hyperparameter tuning by providing an easily parametrizable model.  \nIn essence, the U-Net is built up using encoder and decoder blocks, each of them consisting of convolutional \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8211815030612573
      ],
      "excerpt": "Decoder and Last blocks, controlling the complexity and the number of these blocks.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9861167593162445
      ],
      "excerpt": "WARNING! The 3D U-Net implementation is currently untested! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8700597020296506
      ],
      "excerpt": "for images in the validation set and log of losses and metrics during training). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8105014929675205,
        0.9369812746122667,
        0.944094227187346
      ],
      "excerpt": "- --in_channels: the number of channels in your images. Defaults to 3. \n- --out_channels: the number of classes in your image. Defaults to 2. \n- --depth: controls the depth of the network. Defaults to 5. (For detailed explanation, see \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9542022035028054
      ],
      "excerpt": "- --width: the complexity of each block. More width = more filters learned per layer. Defaults to 32. (For detailed explanation, see \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8524623584337405
      ],
      "excerpt": "- --batch_size: the size of the minibatch during each training loop. Defaults to 1. You should tune this to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9979616161876773,
        0.9613286783522244
      ],
      "excerpt": "- --save_freq: the frequency of saving the model and predictions. Defaults to 0, which results in not saving \nthe model at all, only the logs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.896666592160751,
        0.8291764383463337
      ],
      "excerpt": "- --model_name: name of the model. Defaults to model. (Useful for parameter tuning.) \n- --learning_rate: the learning rate for training. Defaults to 1e-3. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9281757101126811,
        0.8372396012058242
      ],
      "excerpt": "Defaults to None, which results in no cropping. For example, if set to 256, the model is trained and \nvaldiated on (256, 256) sized random crops. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9342219582251634
      ],
      "excerpt": "This is quite arbitrary and it might not be the best architecture for your problem. With the implementation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936563705618703,
        0.8893217828380743
      ],
      "excerpt": "see in the next section. \nThe 2D U-Net architecture is implemented by the unet.unet.UNet2D \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8380380138082476,
        0.9462927150388236
      ],
      "excerpt": "The argument defaults to this structure. \nTo save time with writing the usual boilerplate PyTorch code for training, a dataset generator and a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9385482567759522
      ],
      "excerpt": "The wrapper is implemented in the unet.model.Model object. Upon initialization, you are required to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.853280770956841
      ],
      "excerpt": "- net: PyTorch model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9506886613875959,
        0.920024309655842
      ],
      "excerpt": "- device: The device on which the model and tensor should be located. The default device is the cpu. \nTo train the model, the .fit_dataset() method can be used. For details on how to use it, see its docstring. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394146526745363,
        0.9508735152822355,
        0.8984119163689169,
        0.9352896231538048
      ],
      "excerpt": "For training the U-Net, simple classes for augmentations and dataset input is implemented. The joint \naugmentation transform for image and mask is implemented in unet.dataset.JointTransform2D. This transform is \nused by the unet.dataset.ImageToImage2D. For more details on their usage, see their corresponding docstrings. \nTo get a good grip on U-Net and how it depends on hyperparameters, I have made a simple experiment using the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9678955167490447,
        0.9195301236507641,
        0.8289269354827171
      ],
      "excerpt": "the goal of the competition was instance based segmentation which is not exactly the proper use of U-Net, it \nactually won the race with some really clever tricks. (For details, see  \nthis post by the winner team, explaining \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8172871715475095
      ],
      "excerpt": "background, disregarding the differences between instances of nuclei. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "2D and 3D UNet implementation in PyTorch.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cosmic-cortex/pytorch-UNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 23,
      "date": "Tue, 28 Dec 2021 18:49:43 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/cosmic-cortex/pytorch-UNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "cosmic-cortex/pytorch-UNet",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/cosmic-cortex/pytorch-UNet/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8675549239260214
      ],
      "excerpt": "'cuda:0', 'cuda:1', etc. Defaults for 'cpu'. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8574525012759515
      ],
      "excerpt": "completely fill the memory of your GPU. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8442563478519616
      ],
      "excerpt": "- --dataset: path to the dataset for which you would like to save the predictions. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8675549239260214
      ],
      "excerpt": "'cuda:0', 'cuda:1', etc. Defaults for 'cpu'. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8053004128834041
      ],
      "excerpt": "For simplicity, the following experiments are focused on a simplified problem: segmenting out nuclei from the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8450688549340949
      ],
      "excerpt": "- --dataset_path: path to the downloaded dataset. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8414982804685278,
        0.8414982804685278
      ],
      "excerpt": "  <img src=\"docs/img/tissue_original.png\" width=\"256\" /> \n  <img src=\"docs/img/tissue_segmented.png\" width=\"256\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8417321887707672
      ],
      "excerpt": "For training, train.py should be used, where the required arguments are \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8271949337438169
      ],
      "excerpt": "- --val_dataset: path to the validation dataset, having the same structure as the training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8389405641228297
      ],
      "excerpt": "- --crop: integer describing the size of random crops taken from training and validation images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8676659107276912
      ],
      "excerpt": "kaggle_dsb18_preprocessing.py, in the kaggle_dsb18 folder. It requires two arguments: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/cosmic-cortex/pytorch-UNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Tivadar Danka\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "pytorch-UNet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pytorch-UNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "cosmic-cortex",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cosmic-cortex/pytorch-UNet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 76,
      "date": "Tue, 28 Dec 2021 18:49:43 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "deep-neural-networks",
      "semantic-segmentation",
      "pytorch",
      "unet",
      "convolutional-neural-networks"
    ],
    "technique": "GitHub API"
  }
}
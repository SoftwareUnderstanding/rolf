{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1905.11786",
      "https://arxiv.org/abs/1807.03748"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [Representation Learning with Contrastive Predictive Coding - Oord et al.](https://arxiv.org/abs/1807.03748)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Please cite our paper if you use this code in your own work:\n\n```\n@inproceedings{lowe2019putting,\n  title={Putting an End to End-to-End: Gradient-Isolated Learning of Representations},\n  author={L{\\\"o}we, Sindy and O'Connor, Peter and Veeling, Bastiaan},\n  booktitle={Advances in Neural Information Processing Systems},\n  pages={3039--3051},\n  year={2019}\n}\n```\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{lowe2019putting,\n  title={Putting an End to End-to-End: Gradient-Isolated Learning of Representations},\n  author={L{\\\"o}we, Sindy and O'Connor, Peter and Veeling, Bastiaan},\n  booktitle={Advances in Neural Information Processing Systems},\n  pages={3039--3051},\n  year={2019}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/loeweX/Greedy_InfoMax",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-27T13:27:34Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-02T09:50:36Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.970910835544861,
        0.9525653005498834
      ],
      "excerpt": "This repo provides the code for the experiments in our paper: \nSindy L\u00f6we, Peter O'Connor, Bastiaan S. Veeling - Putting An End to End-to-End: Gradient-Isolated Learning of Representations \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8935992493448063
      ],
      "excerpt": "What we found exciting is that despite each module being trained greedily, it improves upon the representation of the previous module. This enables you to keep stacking modules until downstream performance saturates. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9058647853454066
      ],
      "excerpt": "This will train the Greedy InfoMax model as well as evaluate it by training a linear image classifiers on top of it \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9646184512381255,
        0.9648805465698161
      ],
      "excerpt": "Some of the more important options are: \nin order to train the baseline CPC model with end-to-end backpropagation instead of the Greedy InfoMax model set:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8969069355062009
      ],
      "excerpt": "This will train the Greedy InfoMax model as well as evaluate it by training two linear classifiers on top of it - one for speaker and one for phone classification. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9646184512381255,
        0.9648805465698161
      ],
      "excerpt": "Some of the more important options are: \nin order to train the baseline CPC model with end-to-end backpropagation instead of the Greedy InfoMax model set:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9754142524650252
      ],
      "excerpt": "Check out my blog post for an intuitive explanation of Greedy InfoMax.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code for the paper:   Putting An End to End-to-End: Gradient-Isolated Learning of Representations",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/loeweX/Greedy_InfoMax/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 33,
      "date": "Tue, 28 Dec 2021 16:01:35 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/loeweX/Greedy_InfoMax/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "loeweX/Greedy_InfoMax",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/loeweX/Greedy_InfoMax/master/setup_dependencies.sh",
      "https://raw.githubusercontent.com/loeweX/Greedy_InfoMax/master/download_audio_data.sh",
      "https://raw.githubusercontent.com/loeweX/Greedy_InfoMax/master/vision_traineval.sh",
      "https://raw.githubusercontent.com/loeweX/Greedy_InfoMax/master/audio_traineval.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9554169436001461,
        0.9465718491881494
      ],
      "excerpt": "source activate infomax \nbash vision_traineval.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.955127569875682,
        0.833114516308531
      ],
      "excerpt": "If you want to save GPU memory, you can train layers sequentially, one at a time, by setting the module to be trained (0-2), e.g. \nbash  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9554169436001461,
        0.9465718491881494
      ],
      "excerpt": "source activate infomax \nbash audio_traineval.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9500515357658135,
        0.833114516308531
      ],
      "excerpt": "If you want to save GPU memory, you can train layers sequentially, one at a time, by setting the layer to be trained (0-5), e.g. \nbash  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8473463230273421
      ],
      "excerpt": "    <img src=\"./media/LatentClassification.png\" width=\"700\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8473728932296001
      ],
      "excerpt": "Download a GIM model pretrained on STL-10 here \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8048671042229312
      ],
      "excerpt": "If you want to save GPU memory, you can train layers sequentially, one at a time, by setting the layer to be trained (0-5), e.g. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/loeweX/Greedy_InfoMax/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Sindy L\\xc3\\xb6we\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Greedy InfoMax",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Greedy_InfoMax",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "loeweX",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/loeweX/Greedy_InfoMax/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [Python and Conda](https://www.anaconda.com/)\n- Setup the conda environment `infomax` by running:\n\n    ```bash\n    bash setup_dependencies.sh\n    ```\n\nAdditionally, for the audio experiments:\n- Install [torchaudio](https://github.com/pytorch/audio) in the `infomax` environment\n- Download audio datasets \n    ```bash \n    bash download_audio_data.sh\n    ```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 266,
      "date": "Tue, 28 Dec 2021 16:01:35 GMT"
    },
    "technique": "GitHub API"
  }
}
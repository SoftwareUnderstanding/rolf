{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bibtex\n@inproceedings{\nanonymous2022cosformer,\ntitle={cosFormer: Rethinking Softmax In Attention},\nauthor={Anonymous},\nbooktitle={Submitted to The Tenth International Conference on Learning Representations },\nyear={2022},\nurl={https://openreview.net/forum?id=Bl8CQrx2Up4},\nnote={under review}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{\nanonymous2022cosformer,\ntitle={cosFormer: Rethinking Softmax In Attention},\nauthor={Anonymous},\nbooktitle={Submitted to The Tenth International Conference on Learning Representations },\nyear={2022},\nurl={https://openreview.net/forum?id=Bl8CQrx2Up4},\nnote={under review}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/davidsvy/cosformer-pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-20T21:29:13Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-06T22:17:24Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "As many others, this paper buids on recent work on linear attention that is calculated as <img src=\"https://render.githubusercontent.com/render/math?math=\\phi(Q) \\left(\\phi(K)^T V\\right)\"> instead of <img src=\"https://render.githubusercontent.com/render/math?math=\\text{softmax}\\left(Q K^T\\right)V\">, where <img src=\"https://render.githubusercontent.com/render/math?math=\\phi\"> is a kernel function. This reduces the complexity from <img src=\"https://render.githubusercontent.com/render/math?math=\\mathcal{O}(N^2 D)\"> to <img src=\"https://render.githubusercontent.com/render/math?math=\\mathcal{O}(ND^2)\">. The authors propose to extend this mechanism by including relative distance information in the Q, K product as <img src=\"https://render.githubusercontent.com/render/math?math=\\phi(Q_i)\\phi(K_j)^T\\cos\\left(\\frac{\\pi}{2}\\times\\frac{i-j}{M}\\right)\">. After expanding the trigonometric identity, the full equation becomes:\n\n<p align=\"center\">\n  <img src=\"https://render.githubusercontent.com/render/math?math=\\text{Attention}(Q, K, V)  =  Q^{\\cos} \\left(K^{\\cos} V\\right) %2B Q^{\\sin} \\left(K^{\\sin} V\\right)\">\n</p>\n\nwhere <img src=\"https://render.githubusercontent.com/render/math?math=Q_i^{\\cos} = \\phi(Q_i)\\cos\\left(\\frac{\\pi i}{2M}\\right), Q_i^{\\sin} = \\phi(Q_i)\\sin\\left(\\frac{\\pi i}{2M}\\right)\"> etc.\n\nAs the author of this repo possesses neither the time nor the ability, only the non-causal version of this approach is implemented.\n\n\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Unofficial PyTorch implementation of the paper \"cosFormer: Rethinking Softmax In Attention\".",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/davidsvy/cosformer-pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 19:26:00 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/davidsvy/cosformer-pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "davidsvy/cosformer-pytorch",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/davidsvy/cosformer-pytorch/main/examples.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ git clone https://github.com/davidsvy/cosformer-pytorch\n$ cd cosformer-pytorch\n$ pip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9769420979004304
      ],
      "excerpt": "\u27a4 Installation \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8587476985249702
      ],
      "excerpt": "\u27a4 Usage \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/davidsvy/cosformer-pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 davidsvy\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "<h1 align=\"center\">\n  <b>cosFormer-PyTorch</b><br>\n</h1>\n\n<p align=\"center\">\n      <a href=\"https://www.python.org/\">\n        <img src=\"https://img.shields.io/badge/python-3.7-blue.svg\" /></a>\n       <a href= \"https://pytorch.org/\">\n        <img src=\"https://img.shields.io/badge/PyTorch-1.9-FF0000.svg\" /></a>\n       <a href= \"https://github.com/davidsvy/cosformer-pytorch/blob/main/LICENSE\">\n        <img src=\"https://img.shields.io/badge/license-MIT-white.svg\" /></a>\n</p>\n\nAn unofficial PyTorch implementation of the model proposed in the paper [cosFormer: Rethinking Softmax In Attention](https://openreview.net/pdf?id=Bl8CQrx2Up4) (Submitted to ICLR 2022).\n\n\n\n<p align=\"center\">\n  <img src=\"assets/matrix.png\" />\n  Image stolen from the paper.\n</p>\n\n\n\n\nTable of contents",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "cosformer-pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "davidsvy",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/davidsvy/cosformer-pytorch/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Thu, 23 Dec 2021 19:26:00 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "neural-network",
      "transformer",
      "pytorch",
      "attention-mechanism",
      "deep-learning",
      "artificial-intelligence",
      "efficient-attention",
      "iclr2022",
      "iclr"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\nfrom models.kernel_transformer import Kernel_transformer\nimport torch\n\nmodel = Kernel_transformer(\n    # Linear attention args:\n    use_cos=True,         # Whether to use the cosine reweighting mechanism prposed in the paper.\n    kernel='relu',        # Kernel that approximates softmax. Available options are 'relu' and 'elu'.\n    denom_eps=1e-5,       # Added to the denominator of linear attention for numerical stability.\n    # If use_cos=True & kernel='relu' the model is equivalent to https://openreview.net/pdf?id=Bl8CQrx2Up4\n    # If use_cos=False & kernel='elu' the model is equivalent to https://arxiv.org/pdf/2006.16236.pdf\n    # Vanilla transformer args:\n    d_model=512,\n    n_heads=8, \n    n_layers=6,\n    n_emb=20000, \n    ffn_ratio=4, \n    rezero=True,          # If True, use the ReZero architecture from https://arxiv.org/pdf/2003.04887.pdf, else the Pre-LN architecture from https://arxiv.org/pdf/2002.04745.pdf\n    ln_eps=1e-5, \n    bias=False, \n    dropout=0.2, \n    max_len=1024, \n    xavier=True\n)\n\ninput_ids = torch.randint(0, 20000, [4, 100])\nlengths = torch.randint(1, 100, [4])\nattention_mask = torch.arange(100)[None, :] < lengths[:, None]\n\noutput = model(\n    input_ids=input_ids,\n    lengths=lengths,\n    attention_mask=attention_mask,\n)\n```\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
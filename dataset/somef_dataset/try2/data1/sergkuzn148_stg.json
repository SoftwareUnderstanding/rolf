{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1706.08500"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] Mescheder, L., Geiger, A., & Nowozin, S. (2018). Which Training Methods for GANs do actually Converge? Retrieved from http://arxiv.org/abs/1801.04406\n\n[2] Karras, T., Aila, T., Laine, S., & Lehtinen, J. (2017). Progressive Growing of GANs for Improved Quality, Stability, and Variation. 1\u201326. Retrieved from http://arxiv.org/abs/1710.10196\n\n[3] Karras, T., Laine, S., & Aila, T. (2018). A Style-Based Generator Architecture for Generative Adversarial Networks. Retrieved from http://arxiv.org/abs/1812.04948",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sergkuzn148/stg",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-11-11T10:02:15Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-11-11T10:03:48Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9325214556082524
      ],
      "excerpt": "This is a simple but complete pytorch-version implementation of Nvidia's Style-based GAN[3]. We've train this model on our new anime face dataset and a subset of FFHQ, you can download our pre-trained model to evaluate or continue training by yourself. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9651322443697918
      ],
      "excerpt": "We provide you with two versions of implementations: the SGAN.ipynb for jupyter notebook with GUI and .pys for CLI only.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8570365805650295,
        0.8848325866048876
      ],
      "excerpt": "|learning_rate|a dict to indicate learning rate at different stage of training| \n|batch_size|a dict to indicate batch size at different stage of training| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8232755796202643,
        0.9520717622278507,
        0.8033326429517216
      ],
      "excerpt": "|n_fc|number of layers in the full-connected mapping network| \n|dim_latent|dimension of latent space| \n|dim_input|size of the first layer of generator| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9076097066804153
      ],
      "excerpt": "|max_step|maximum resolution of images is 2 ^ (max_step + 2)| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9324184005229498,
        0.8694698761596041
      ],
      "excerpt": "*With suffix like '_2gpus', which means this parameter should be used (by removing the suffix) while using this number of GPUs. \nOur implementation support save trained model and load a existed checkpoint to continue training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9828067133570927
      ],
      "excerpt": "We use Fr\u00e9chet Inception Distance to estimate the performance of our implementation. We use an edited version (changes to it will not affect the score it gives) of mseitzer's work to estimate our model's performance. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9696034645751825
      ],
      "excerpt": "TODO: Estimate performance of model with FID \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8881025265922948
      ],
      "excerpt": "5/25: Allow users to edit maximum resolution (step). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490310032279418
      ],
      "excerpt": "5/23: Divide codes into files \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8600378927558928,
        0.9689640799720843
      ],
      "excerpt": "5/23: DEBUG: Leak of VRAM \n5/23: DEBUG: The change of alpha (used to decide the degree of crossover between different layers) is set to be linear[2]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8596160372832695
      ],
      "excerpt": "5/16: DEBUG: Fix the bug that the full connected mapping layer does not participate in calculation and back-propagation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8465673241560111
      ],
      "excerpt": "5/14: DEBUG: Parallel conflict on Windows (Due to the speed limit, we migrate to Linux platform) \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sergkuzn148/stg/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Sun, 26 Dec 2021 15:22:00 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sergkuzn148/stg/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "sergkuzn148/stg",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/sergkuzn148/stg/master/SGAN.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.853558323401025
      ],
      "excerpt": "As we did not provide you with any optional command parameters, you can only change them inside our code to match your requirement. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8630746504165882
      ],
      "excerpt": "5/14: DEBUG: Parallel conflict on Windows (Due to the speed limit, we migrate to Linux platform) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8242194488247082
      ],
      "excerpt": "|n_gpu|number of GPUs used to train the model| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8184874259675459
      ],
      "excerpt": "|n_sample_total|how many samples will be used to train the whole model| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8564277190807548,
        0.8357279648608116
      ],
      "excerpt": "|is_train|set to True if you want to train the model| \n|is_continue|set to True if you want to load pre-trained model| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8543749151083674
      ],
      "excerpt": "When you train the model yourself, parameters of the model will be saved to ./checkpoint/trained.pth every 1000 iterations. You can set is_continue to True to continue training from your pre-trained model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8027133024627905
      ],
      "excerpt": "TODO: Generate preview images \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sergkuzn148/stg/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Siskon\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "StyleGAN-PyTorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "stg",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "sergkuzn148",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sergkuzn148/stg/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 15:22:00 GMT"
    },
    "technique": "GitHub API"
  }
}
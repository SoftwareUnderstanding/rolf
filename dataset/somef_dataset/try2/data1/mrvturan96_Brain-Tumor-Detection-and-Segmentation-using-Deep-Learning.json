{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1505.04597\n\n- [7] - Intelligent Scanning Using Deep Learning for MRI, https://medium.com/tensorflow/intelligent-scanning-using-deep-learning-for-mri-36dd620882c4\n\n- [VGG Image Annotator](http://www.robots.ox.ac.uk/~vgg/software/via/via_demo.html",
      "https://arxiv.org/abs/1811.02629 (2018)\n\n- [4] S. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J. Kirby, et al., \"Segmentation Labels and Radiomic Features for the Pre-operative Scans of the TCGA-GBM collection\", The Cancer Imaging Archive, 2017. DOI: 10.7937/K9/TCIA.2017.KLXWJJ1Q\n\n- [5] S. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J. Kirby, et al., \"Segmentation Labels and Radiomic Features for the Pre-operative Scans of the TCGA-LGG collection\", The Cancer Imaging Archive, 2017. DOI: 10.7937/K9/TCIA.2017.GJQ7R0EF\n\n- [6] U-Net: Convolutional Networks for Biomedical Image Segmentation, https://arxiv.org/abs/1505.04597\n\n- [7] - Intelligent Scanning Using Deep Learning for MRI, https://medium.com/tensorflow/intelligent-scanning-using-deep-learning-for-mri-36dd620882c4\n\n- [VGG Image Annotator](http://www.robots.ox.ac.uk/~vgg/software/via/via_demo.html)\n\n- [Mask RCNN](https://github.com/matterport/Mask_RCNN)\n\n- github.com/zsdonghao/u-net-brain-tumor, github.com/JooHyun-Lee/BraTs\n\n"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [1] B. H. Menze, A. Jakab, S. Bauer, J. Kalpathy-Cramer, K. Farahani, J. Kirby, et al. \"The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)\", IEEE Transactions on Medical Imaging 34(10), 1993\u20132024 (2015) DOI: 10.1109/TMI.2014.2377694\n\n- [2] S. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J.S. Kirby, et al., \"Advancing The Cancer Genome Atlas glioma MRI collections with expert segmentation labels and radiomic features\", Nature Scientific Data, 4:170117 (2017) DOI: 10.1038/sdata.2017.117\n\n- [3] S. Bakas, M. Reyes, A. Jakab, S. Bauer, M. Rempfler, A. Crimi, et al., \"Identifying the Best Machine Learning Algorithms for Brain Tumor Segmentation, Progression Assessment, and Overall Survival Prediction in the BRATS Challenge\", arXiv preprint arXiv:1811.02629 (2018)\n\n- [4] S. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J. Kirby, et al., \"Segmentation Labels and Radiomic Features for the Pre-operative Scans of the TCGA-GBM collection\", The Cancer Imaging Archive, 2017. DOI: 10.7937/K9/TCIA.2017.KLXWJJ1Q\n\n- [5] S. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J. Kirby, et al., \"Segmentation Labels and Radiomic Features for the Pre-operative Scans of the TCGA-LGG collection\", The Cancer Imaging Archive, 2017. DOI: 10.7937/K9/TCIA.2017.GJQ7R0EF\n\n- [6] U-Net: Convolutional Networks for Biomedical Image Segmentation, https://arxiv.org/abs/1505.04597\n\n- [7] - Intelligent Scanning Using Deep Learning for MRI, https://medium.com/tensorflow/intelligent-scanning-using-deep-learning-for-mri-36dd620882c4\n\n- [VGG Image Annotator](http://www.robots.ox.ac.uk/~vgg/software/via/via_demo.html)\n\n- [Mask RCNN](https://github.com/matterport/Mask_RCNN)\n\n- github.com/zsdonghao/u-net-brain-tumor, github.com/JooHyun-Lee/BraTs\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8445781236024663
      ],
      "excerpt": "* Source code of U-net \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mrvturan96/Brain-Tumor-Detection-and-Segmentation-using-Deep-Learning",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-12-13T11:46:06Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-01T10:03:32Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The aim of this project is to distinguish gliomas which are the most difficult brain tumors to be detected with deep learning algorithms. Because, for a skilled radiologist, analysis of multimodal MRI scans can take up to 20 minutes and therefore, making this process automatic is obviously useful. \n\nMRI can show different tissue contrasts through different pulse sequences, making it an adaptable and widely used imaging technique for visualizing regions of interest in the human brain. \nGliomas are the most commonly found tumors having irregular shape and ambiguous boundaries, making them one of the hardest tumors to detect. Detection of brain tumor using a segmentation approach is critical in cases, where survival of a subject depends on an accurate and timely clinical diagnosis.  \n\nWe present a fully automatic deep learning approach for brain tumor segmentation in multi-contrast magnetic resonance image. \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.99203862499195
      ],
      "excerpt": "Our team consisted of Mustafa Mert TUNALI, Merve TURAN, Feyza DO\u011eAN  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9829626615862088,
        0.9328830280660902,
        0.9901067024878076
      ],
      "excerpt": "DeepHealth - project is created in Project Oriented Deep Learning Training program. The program is organized by Deep Learning T\u00fcrkiye and supported by KWORKS. \nThe repository includes: \n* Source code of Mask R-CNN built on FCN and ResNet101. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9832249733536769
      ],
      "excerpt": "<sub><b>Figure 1: </b> Prediction of our solution with Mask R-CNN </sub> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9832249733536769,
        0.9587257602790082
      ],
      "excerpt": "<sub><b>Figure 2: </b> Prediction of our solution with Mask R-CNN </sub> \n<sub><b>Figure 4: </b> Prediction of our solution with U-Net </sub> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8137019100417193
      ],
      "excerpt": "Dice is a frequently used performance criterion to evaluate success in biomedical images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.811266144932007,
        0.824553566934079
      ],
      "excerpt": "Binary Crossentropy     \nModel Accuracy             |  Model Loss \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This repo includes Glioma Segmentation with Mask R-CNN and U-Net.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mrvturan96/Brain-Tumor-Detection-and-Segmentation-using-Deep-Learning/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 20,
      "date": "Wed, 29 Dec 2021 09:20:16 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mrvturan96/Brain-Tumor-Detection-and-Segmentation-using-Deep-Learning/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "mrvturan96/Brain-Tumor-Detection-and-Segmentation-using-Deep-Learning",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/mrvturan96/Brain-Tumor-Detection-and-Segmentation-using-Deep-Learning/master/Mask-RCNN/inspect_hgg_model.ipynb",
      "https://raw.githubusercontent.com/mrvturan96/Brain-Tumor-Detection-and-Segmentation-using-Deep-Learning/master/Mask-RCNN/inspect_hgg_weights.ipynb",
      "https://raw.githubusercontent.com/mrvturan96/Brain-Tumor-Detection-and-Segmentation-using-Deep-Learning/master/Mask-RCNN/inspect_hgg_data.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mrvturan96/Brain-Tumor-Detection-and-Segmentation-using-Deep-Learning/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "DeepHealth",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Brain-Tumor-Detection-and-Segmentation-using-Deep-Learning",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "mrvturan96",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mrvturan96/Brain-Tumor-Detection-and-Segmentation-using-Deep-Learning/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```buildoutcfg\n- Numpy\n- Scipy\n- Pillow\n- Cython\n- Matplotlib\n- Scikit-image\n- Tensorflow>=1.3.0\n- Keras>=2.0.8\n- OpenCV-Python\n- h5py\n- imgaug\n- IPython[all]\n```\n[Install Mask RCNN from here.](https://github.com/matterport/Mask_RCNN#installation)\n\n_**1. Prepare Data**_\n  \n  Download and unzip BraTS data from [braTS2019](https://www.med.upenn.edu/cbica/brats2019.html)\n    \n  Biomedical images generally have NIFTI format. NIFTI format is very high resolution. Therefore, we've converted these images to .png format. Before you start to train the model, you have to convert nii files to png. \n\n  These dataset contains only **t1ce** sequence.\n  \n  The data directories for this project are as following. Make sure you include corresponding annotations(.json) in correct directory. Train has **564** images. Val has **100** images.\n  \n![Dataset](MaskRCNN_Images/dataset.png)\n  \n  \n  \n  ***Note:*** VIA tool is used to label.\n    \n_**2. Build Model**_\n\nMask-RCNN/hgg.py shows how to train Mask R-CNN on HGG dataset.\n\n```buildoutcfg\n#:From Brain-Cancer-Detection-using-Pathological-Images/Mask-RCNN\npython3 hgg.py train --dataset=/Brain-Cancer-Detection-using-Pathological-Images/Mask-RCNN/hggImages --weights=coco\n```\n\n* inspect_hgg_data.ipynb provides step-by-step prediction and visualization on your own dataset. You can also roughly evaluate the model with metrics of overall accuracy and precision.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```buildoutcfg\n- Keras 2.2.4\n- Tensorflow 1.13.1\n- Matplotlib\n- SimpleITK\n- Numpy\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 43,
      "date": "Wed, 29 Dec 2021 09:20:16 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "_**1. Prepare Data**_\n  \n  Download and unzip BraTS data from [braTS2019](https://www.med.upenn.edu/cbica/brats2019.html)\n  \n  **NOTE:** BraTS dataset is in NIFTI format. So, this images have high resolution. We used the SimpleITK library to read images in this format.    \n  Images = 240x240 pixel and 60\u2013120 slides of each MRI image are used as training data due to the rest part of brain is very unlikely to have any tumor.    \n  U-Net contains only **flair** sequence. But other sequences can also be easily applied. We only use **LGG** images.\n \n_**2. Data Augmentation**_\n\n   We don't have many images. Therefore, data augmentation applied.\n   \n_**3. Build Model**_\n\n  We use only one U-net model to do three different segmentation tasks Full Tumor, Tumor Core, Enhancing Tumor. \n  \n  ![U-net](U-Net_Images/u-net.png)     \n  <sub><b>Figure 3: </b> U-net Architecture </sub> \n  \n",
      "technique": "Header extraction"
    }
  ]
}
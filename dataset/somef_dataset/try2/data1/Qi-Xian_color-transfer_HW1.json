{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Code is modified by [PyTorch-CycleGAN](https://github.com/aitorzip/PyTorch-CycleGAN). All credit goes to the authors of [CycleGAN](https://arxiv.org/abs/1703.10593), Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.\n=======\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.10593",
      "https://arxiv.org/abs/1703.10593"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9805712299079478
      ],
      "excerpt": "A clean and readable Pytorch implementation of CycleGAN (https://arxiv.org/abs/1703.10593) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Qi-Xian/color-transfer_HW1",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-04T06:40:42Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-06T14:24:27Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8130311971496856,
        0.9508539780503613
      ],
      "excerpt": "(Inference cycleGAN in personal image) \n(Compare with other method) \n",
      "technique": "Supervised classification"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "your need to create one folder named datasets\n```\nmkdir datasets\n```\n\nand then,\n```\ncd datasets\n```\nImplement the instruction\n```\nbash ./download_dataset.sh <dataset_name>\n```\nValid <dataset_name> are: apple2orange, summer2winter_yosemite, horse2zebra, monet2photo, cezanne2photo, ukiyoe2photo, vangogh2photo, maps, cityscapes, facades, iphone2dslr_flower, ae_photos (Here we use apple2roange)\n\nAlternatively you can build your own dataset by setting up the following directory structure:\n\n    .\n    \u251c\u2500\u2500 datasets                   \n    |   \u251c\u2500\u2500 <dataset_name>         ",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Qi-Xian/color-transfer_HW1/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 18:35:41 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Qi-Xian/color-transfer_HW1/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Qi-Xian/color-transfer_HW1",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8732995434911642
      ],
      "excerpt": "Start to train, type the command as follow:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.979492465956963
      ],
      "excerpt": "If you don't own one GPU, remove the --cuda option, but you had better get one, becaue it is faster than CPU ! \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": "(Training cycleGAN) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8513303432247888
      ],
      "excerpt": "Start to train, type the command as follow:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8106163294023978
      ],
      "excerpt": "After training, we can start to test. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8021759920731393,
        0.8340494702208944
      ],
      "excerpt": "This command will take the images under the dataroot/testA/ and dataroot/testB/ directory, run them through the generators and save the output under the ./output/&lt;dataset_name&gt;/ directories.  \nExamples of the generated outputs (default params) apple2orange, summer2winter_yosemite, horse2zebra dataset: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Qi-Xian/color-transfer_HW1/issues{/number}",
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Color-Tranfer Project\n\nA clean and readable Pytorch implementation of CycleGAN (https://arxiv.org/abs/1703.10593)\n\n## Goal\n1.  (Training cycleGAN)\n2.  (Inference cycleGAN in personal image)\n3.  (Compare with other method)\n\n## Getting Started\nPlease firstly install [Anaconda](https://anaconda.org), if you not understand how to install whole procedures on Ubuntu system, you can take this [link](https://stackoverflow.com/questions/28852841/install-anaconda-on-ubuntu-via-command-line) as reference.\n\n\nAfter finishing, you need to create an Anaconda environment using the environment.yml file.\n\n```\nconda env create -f environment.yml\n```\n\nAfter you create the environment, activate it.\n```\nsource activate hw1\n```\n\nOur current implementation supports GPU Card (Such as GTX-1060 up), you need to have one GPU (like GTX-1080-ti) and have CUDA libraries installed on your machine. \n\n**(Don't use VMs running on Ubuntu Operation, because VMs can not get the real GPU card)**\n\n## Training\n### 1. Download dataset\n\nyour need to create one folder named datasets\n```\nmkdir datasets\n```\n\nand then,\n```\ncd datasets\n```\nImplement the instruction\n```\nbash ./download_dataset.sh <dataset_name>\n```\nValid <dataset_name> are: apple2orange, summer2winter_yosemite, horse2zebra, monet2photo, cezanne2photo, ukiyoe2photo, vangogh2photo, maps, cityscapes, facades, iphone2dslr_flower, ae_photos (Here we use apple2roange)\n\nAlternatively you can build your own dataset by setting up the following directory structure:\n\n    .\n    \u251c\u2500\u2500 datasets                   \n    |   \u251c\u2500\u2500 <dataset_name>         # i.e. apple2orange\n    |   |   \u251c\u2500\u2500 trainA             # Contains domain A images (i.e. apple)\n    |   |   \u251c\u2500\u2500 trainB             # Contains domain B images (i.e. orange) \n    |   |   \u251c\u2500\u2500 testA              # Testing\n    |   |   \u2514\u2500\u2500 testB              # Testing\n    \n### 2. Train\n\nStart to train, type the command as follow: \n```\npython train.py --dataroot datasets/<dataset_name>/ --cuda\n```\n\nThis command would start a training session using the images under the *dataroot/train* directory with the hyperparameters that showed best results according to CycleGAN authors. \n\nBoth generators and discriminators weights will be saved ```./output/<dataset_name>/``` the output directory.\n\n**If you don't own one GPU, remove the --cuda option, but you had better get one, becaue it is faster than CPU !**\n\n## Testing\nAfter training, we can start to test.\n\nThe pre-trained file is on [Google drive](https://drive.google.com/open?id=17FREtttCyFpvjRJxd4v3VVlVAu__Y5do). Download the file and save it on  ```./output/<dataset_name>/netG_A2B.pth``` and ```./output/<dataset_name>/netG_B2A.pth```. \n\n```\npython test.py --dataroot datasets/<dataset_name>/ --cuda\n```\nThis command will take the images under the ```dataroot/testA/``` and ```dataroot/testB/``` directory, run them through the generators and save the output under the ```./output/<dataset_name>/``` directories. \n\nExamples of the generated outputs (default params) apple2orange, summer2winter_yosemite, horse2zebra dataset:\n\n![Alt text](./output/imgs/0167.png)\n![Alt text](./output/imgs/0035.png)\n![Alt text](./output/imgs/0111.png)\n\n\n\n## Acknowledgments\nCode is modified by [PyTorch-CycleGAN](https://github.com/aitorzip/PyTorch-CycleGAN). All credit goes to the authors of [CycleGAN](https://arxiv.org/abs/1703.10593), Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "color-transfer_HW1",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Qi-Xian",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Qi-Xian/color-transfer_HW1/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 18:35:41 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please firstly install [Anaconda](https://anaconda.org), if you not understand how to install whole procedures on Ubuntu system, you can take this [link](https://stackoverflow.com/questions/28852841/install-anaconda-on-ubuntu-via-command-line) as reference.\n\n\nAfter finishing, you need to create an Anaconda environment using the environment.yml file.\n\n```\nconda env create -f environment.yml\n```\n\nAfter you create the environment, activate it.\n```\nsource activate hw1\n```\n\nOur current implementation supports GPU Card (Such as GTX-1060 up), you need to have one GPU (like GTX-1080-ti) and have CUDA libraries installed on your machine. \n\n**(Don't use VMs running on Ubuntu Operation, because VMs can not get the real GPU card)**\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1801.06146",
      "https://arxiv.org/abs/1801.06146",
      "https://arxiv.org/abs/1801.06146",
      "https://arxiv.org/abs/1801.06146](https://arxiv.org/abs/1801.06146)."
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/anthonyckleung/Transfer-Learning-in-Sentiment-Tweets",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-07-07T19:34:42Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-07-08T00:16:08Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This notebook focuses on the so-called Universal Language Model Fine-tuning (ULMFiT) introduced by \nJeremy Howard and Sebastian Ruder [[1](https://arxiv.org/abs/1801.06146)]. \nThe ULMFiT model consists of three main stages in the building a language model (LM):\n\n1. **General-domain LM  pre-training**: Similar to the ImageNet database used in computer vision, \nthe idea is to pre-train a large corpus of text. The ULMFiT has a pre-trained model called the \n`Wikitext-103` where more than 20,000 Wikipedia articles was trained on. \nThis is alreadly included in the `fastai.text` API, thus, it is not necessary to carry out this step.\n\n2. **LM fine-tuning**: Because the target data (typically) comes from a different \ndistribution from the general-domain, it is necessary to fine-tune the LM to adapt to \nthe idosyncrasies of the target data. Howard and Ruder suggested *discriminative fine-tuning*\nand *slanted triangular learning rates* for fine-tuning the LM. These techniques are available \nin `fastai` and are described in [[1](https://arxiv.org/abs/1801.06146)].\n\n3. **Classifier fine-tuning**: Using the updated weights from the previous step, a classifier\ncan be fine-tuned. Howard and Ruder suggested a few techniques which include *concat pooling* \nand *gradual unfreezing*. The latter in particular is used in this demonstration. \nAgain, the `fastai` framework allows one to perform this technique.\n\n**Reference**\n\n[1] J. Howard and S. Ruder. 2018.*Universal Language Model Fine-tuning for Text Classification*. [arXiv:1801.06146](https://arxiv.org/abs/1801.06146).\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/anthonyckleung/Transfer-Learning-in-Sentiment-Tweets/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 20:41:34 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/anthonyckleung/Transfer-Learning-in-Sentiment-Tweets/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "anthonyckleung/Transfer-Learning-in-Sentiment-Tweets",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/anthonyckleung/Transfer-Learning-in-Sentiment-Tweets/master/ulmfit-sentiment-analysis.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/anthonyckleung/Transfer-Learning-in-Sentiment-Tweets/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Transfer-Learning-in-Sentiment-Tweets",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Transfer-Learning-in-Sentiment-Tweets",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "anthonyckleung",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/anthonyckleung/Transfer-Learning-in-Sentiment-Tweets/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Python 3\n* Jupyter notebook\n* fastai\n* pytorch\n* re\n* numpy, seaborn, pandas\n* data source: [Figure-Eight](https://www.figure-eight.com/data-for-everyone/)\n\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 20:41:34 GMT"
    },
    "technique": "GitHub API"
  }
}
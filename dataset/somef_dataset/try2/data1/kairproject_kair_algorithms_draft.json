{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1802.09477",
      "https://arxiv.org/abs/1801.01290",
      "https://arxiv.org/abs/1812.05905",
      "https://arxiv.org/abs/1707.08817"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We are currently writing a white paper to summarize the results. We will add a BibTeX entry below once the paper is finalized.\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9895125999203164
      ],
      "excerpt": "ArXiv Preprint \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9754940613249191,
        0.9353799258965515
      ],
      "excerpt": "ArXiv Preprint (Original SAC) \nArXiv Preprint (SAC with autotuned temperature) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9895125999203164
      ],
      "excerpt": "ArXiv Preprint \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kairproject/kair_algorithms_draft",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-02-03T08:17:28Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T12:04:44Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9026515412055279
      ],
      "excerpt": "The scripts folder contains implementations of a curated list of RL algorithms verified in MuJoCo environment. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9435518936283183
      ],
      "excerpt": "TD3 (Fujimoto et al., 2018) is an extension of DDPG (Lillicrap et al., 2015), a deterministic policy gradient algorithm that uses deep neural networks for function approximation. Inspired by Deep Q-Networks (Mnih et al., 2015), DDPG uses experience replay and target network to improve stability. TD3 further improves DDPG by adding clipped double Q-learning (Van Hasselt, 2010) to mitigate overestimation bias (Thrun & Schwartz, 1993) and delaying policy updates to address variance. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9816915658879359
      ],
      "excerpt": "SAC (Haarnoja et al., 2018a) incorporates maximum entropy reinforcment learning, where the agent's goal is to maximize expected reward and entropy concurrently. Combined with TD3, SAC achieves state of the art performance in various continuous control tasks. SAC has been extended to allow automatically tuning of the temperature parameter (Haarnoja et al., 2018b), which determines the importance of entropy against the expected reward. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9769215893722049
      ],
      "excerpt": "DDPGfD (Vecerik et al., 2017) is an imitation learning algorithm that infuses demonstration data into experience replay. DDPGfD also improved DDPG by (1) using prioritized experience replay (Schaul et al., 2015), (2) adding n-step returns, (3) learning multiple times per environment step, and (4) adding L2 regularizers to actor and critic losses. We incorporated these improvements to TD3 and SAC and found that it dramatically improves their performance. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Reinforcement learning algorithms for robot control tasks",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kairproject/kair_algorithms_draft/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 15,
      "date": "Thu, 23 Dec 2021 07:27:50 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kairproject/kair_algorithms_draft/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "kairproject/kair_algorithms_draft",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/kairproject/kair_algorithms_draft/master/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/kairproject/kair_algorithms_draft/master/docker_train.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To use the algorithms, first use the [requirements.txt](/scripts/requirements.txt) file to install appropriate Python packages from PyPI.\n\n```bash\ncd scripts\npip install -r requirements.txt\n```\n\nTo train [LunarLanderContinuous-v2](https://gym.openai.com/envs/LunarLanderContinuous-v2/), install [OpenAI Gym](https://github.com/openai/gym) environment.\n\nTo train [Reacher-v1](https://gym.openai.com/evaluations/eval_6kY02G5DSpekMBmAeRLVyA/), install [MuJoCo](https://github.com/kairproject/kair_algorithms_draft/wiki/MuJoCo-Setup) environment.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9688178488584892
      ],
      "excerpt": "The code is developed using python 2.7, ROS kinetic on Ubuntu 16.04. NVIDIA GPU is needed. The code is developed and tested using 1 NVIDIA GeForce GTX 1080 Ti GPU card. Other platforms or GPU cards are not fully tested. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9714207429223904
      ],
      "excerpt": "cd scripts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9302724796005301
      ],
      "excerpt": "Follow the ROS installation commands in Dockerfile to train. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kairproject/kair_algorithms_draft/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "CMake",
      "Dockerfile",
      "Shell",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Algorithms",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "kair_algorithms_draft",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "kairproject",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kairproject/kair_algorithms_draft/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 20,
      "date": "Thu, 23 Dec 2021 07:27:50 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "python",
      "reinforcement-learning",
      "robotics"
    ],
    "technique": "GitHub API"
  }
}
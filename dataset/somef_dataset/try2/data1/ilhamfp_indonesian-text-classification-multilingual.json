{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2009.05713",
      "https://arxiv.org/abs/1810.04805 [cs] (2019). https://arxiv.org/abs/ 1810.04805. URL: http://arxiv.org/abs/1810.04805.  \n[2] A. Conneau et al. \u201cUnsupervised Cross-lingual Representation Learning at Scale\u201d. In: https://arxiv.org/abs/1911.02116 [cs] (2020). https://arxiv.org/abs/ 1911.02116. URL: http://arxiv.org/abs/1911.02116.  \n[3] A. N. Farhan & M. L. Khodra. \u201cSentiment-specific word embedding for Indonesian sentiment analysis\u201d. In: 2017 International Conference on Advanced Informatics, Concepts, Theory, and Applications (ICAICTA). 2017, 1\u20135. DOI: 10.1109/ICAICTA.2017.8090964.  \n[4] I. A.P. A. Crisdayanti & A. Purwarianti. \u201cImproving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector\u201d. In: (2019).  \n[5] M. O. Ibrohim & I. Budi. \u201cMulti-label Hate Speech and Abusive Language Detection in Indonesian Twitter\u201d. In: Proceedings of the Third Workshop on Abusive Language Online. Association for Computational Linguistics, 2019, 46\u201357. DOI: 10 . 18653 / v1 / W19 - 3506. URL: https://www.aclweb.org/anthology/W19-3506.  ",
      "https://arxiv.org/abs/ 1810.04805. URL: http://arxiv.org/abs/1810.04805.  \n[2] A. Conneau et al. \u201cUnsupervised Cross-lingual Representation Learning at Scale\u201d. In: https://arxiv.org/abs/1911.02116 [cs] (2020). https://arxiv.org/abs/ 1911.02116. URL: http://arxiv.org/abs/1911.02116.  \n[3] A. N. Farhan & M. L. Khodra. \u201cSentiment-specific word embedding for Indonesian sentiment analysis\u201d. In: 2017 International Conference on Advanced Informatics, Concepts, Theory, and Applications (ICAICTA). 2017, 1\u20135. DOI: 10.1109/ICAICTA.2017.8090964.  \n[4] I. A.P. A. Crisdayanti & A. Purwarianti. \u201cImproving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector\u201d. In: (2019).  \n[5] M. O. Ibrohim & I. Budi. \u201cMulti-label Hate Speech and Abusive Language Detection in Indonesian Twitter\u201d. In: Proceedings of the Third Workshop on Abusive Language Online. Association for Computational Linguistics, 2019, 46\u201357. DOI: 10 . 18653 / v1 / W19 - 3506. URL: https://www.aclweb.org/anthology/W19-3506.  ",
      "https://arxiv.org/abs/1911.02116 [cs] (2020). https://arxiv.org/abs/ 1911.02116. URL: http://arxiv.org/abs/1911.02116.  \n[3] A. N. Farhan & M. L. Khodra. \u201cSentiment-specific word embedding for Indonesian sentiment analysis\u201d. In: 2017 International Conference on Advanced Informatics, Concepts, Theory, and Applications (ICAICTA). 2017, 1\u20135. DOI: 10.1109/ICAICTA.2017.8090964.  \n[4] I. A.P. A. Crisdayanti & A. Purwarianti. \u201cImproving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector\u201d. In: (2019).  \n[5] M. O. Ibrohim & I. Budi. \u201cMulti-label Hate Speech and Abusive Language Detection in Indonesian Twitter\u201d. In: Proceedings of the Third Workshop on Abusive Language Online. Association for Computational Linguistics, 2019, 46\u201357. DOI: 10 . 18653 / v1 / W19 - 3506. URL: https://www.aclweb.org/anthology/W19-3506.  ",
      "https://arxiv.org/abs/ 1911.02116. URL: http://arxiv.org/abs/1911.02116.  \n[3] A. N. Farhan & M. L. Khodra. \u201cSentiment-specific word embedding for Indonesian sentiment analysis\u201d. In: 2017 International Conference on Advanced Informatics, Concepts, Theory, and Applications (ICAICTA). 2017, 1\u20135. DOI: 10.1109/ICAICTA.2017.8090964.  \n[4] I. A.P. A. Crisdayanti & A. Purwarianti. \u201cImproving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector\u201d. In: (2019).  \n[5] M. O. Ibrohim & I. Budi. \u201cMulti-label Hate Speech and Abusive Language Detection in Indonesian Twitter\u201d. In: Proceedings of the Third Workshop on Abusive Language Online. Association for Computational Linguistics, 2019, 46\u201357. DOI: 10 . 18653 / v1 / W19 - 3506. URL: https://www.aclweb.org/anthology/W19-3506.  "
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Research mentioned in this README:  \n[1] J. Devlin et al. \u201cBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\u201d. In: arXiv:1810.04805 [cs] (2019). arXiv: 1810.04805. URL: http://arxiv.org/abs/1810.04805.  \n[2] A. Conneau et al. \u201cUnsupervised Cross-lingual Representation Learning at Scale\u201d. In: arXiv:1911.02116 [cs] (2020). arXiv: 1911.02116. URL: http://arxiv.org/abs/1911.02116.  \n[3] A. N. Farhan & M. L. Khodra. \u201cSentiment-specific word embedding for Indonesian sentiment analysis\u201d. In: 2017 International Conference on Advanced Informatics, Concepts, Theory, and Applications (ICAICTA). 2017, 1\u20135. DOI: 10.1109/ICAICTA.2017.8090964.  \n[4] I. A.P. A. Crisdayanti & A. Purwarianti. \u201cImproving Bi-LSTM Performance for Indonesian Sentiment Analysis Using Paragraph Vector\u201d. In: (2019).  \n[5] M. O. Ibrohim & I. Budi. \u201cMulti-label Hate Speech and Abusive Language Detection in Indonesian Twitter\u201d. In: Proceedings of the Third Workshop on Abusive Language Online. Association for Computational Linguistics, 2019, 46\u201357. DOI: 10 . 18653 / v1 / W19 - 3506. URL: https://www.aclweb.org/anthology/W19-3506.  \n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9813161029725735
      ],
      "excerpt": "Book title: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9994600429748258
      ],
      "excerpt": "Paper title (Arxiv): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8728827109464992
      ],
      "excerpt": "|    \u2514\u2500\u2500 paper              &lt;- Microsoft word source for the paper \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9574756557312617,
        0.9574756557312617,
        0.9516706517766257
      ],
      "excerpt": "    * Sentiment Analysis 1: (Farhan & Khodra, 2017) [3] \n    * Sentiment Analysis 2: (Crisdayanti & Purwarianti, 2019) [4] \n    * Hate-speech and Abusive: (Ibrohim & Budi, 2019) [5] \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ilhamfp/indonesian-text-classification-multilingual",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-04-26T07:27:39Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-15T15:33:14Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9451326689331576
      ],
      "excerpt": "This repository is my final year undergraduate project on Institut Teknologi Bandung, supervised by Dr. Eng. Ayu Purwarianti, ST.,MT. It contains the unpolished source codes (.py on /src and .ipynb on /notebooks), book (Indonesian), and paper (English). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9106050150634234
      ],
      "excerpt": "Klasifikasi Teks Berbahasa Indonesia Menggunakan Multilingual Language Model (Studi Kasus: Klasifikasi Ujaran Kebencian dan Analisis Sentimen) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8588025593361271
      ],
      "excerpt": "Improving Indonesian Text Classification Using Multilingual Language Model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9943618027209472
      ],
      "excerpt": "Compared to English, the amount of labeled data for Indonesian text classification tasks is very small. Recently developed multilingual language models have shown its ability to create multilingual representations effectively. This paper investigates the effect of combining English and Indonesian data on building Indonesian text classification (e.g., sentiment analysis and hate speech) using multilingual language models. Using the feature-based approach, we observe its performance on various data sizes and total added English data. The experiment showed that the addition of English data, especially if the amount of Indonesian data is small, improves performance. Using the fine-tuning approach, we further showed its effectiveness in utilizing the English language to build Indonesian text classification models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9826922989550758,
        0.9933742997446422,
        0.9802672918874125,
        0.9907939899961586,
        0.8685274207528186
      ],
      "excerpt": "We investigate the model performance in three different scenarios. Each differs by the combination of the language used in its training data: monolingual, zero-shot, and multilingual. In the monolingual scenario, we use the Indonesian language text to train and validate the model. In the zero-shot scenario, we use the English language text to train the model while being validated on Indonesian text. Lastly, we use a combination of Indonesian and English text to train the model while being validated on Indonesian text in the multilingual scenario. Using these scenarios, we observe the improvement of the added English text. \nThere are two approaches on applying large pre-trained language representation to downstream tasks: feature-based and fine-tuning [1]. On the feature-based approach, we extract fixed features from the pre-trained model. In this experiment, we use the last hidden state, which is 768 for mBERT and 1024 for XLM-R Large, as the feature. This extracted feature is then fed into a single dense layer, the only layer we trained on the feature-based approach, connected with dropout before finally ending on a sigmoid function. In contrast, the finetuning approach trains all the language model parameters, 110M for mBERT and 550M for XLM-R Large, including the last dense layer, on the training data binary cross-entropy loss.   \nUsing the feature-based scenario, we run many experiments as the expensive and multilingual representation have been precomputed on all the data. In all training data scenarios, we vary the total data used. More specifically, we train the model using [500, 1000, 2500, 5000, 7500, Max] text data. Specific to multilingual training data scenario, we vary the amount of added English data by [0.25, 0.5, 0.75, 1, 1.5, 2, 3, 4, 5, 6, 7, 8, 9, 10] times the amount of Indonesian text data. We refer to a multilingual experiment with added English data N times the amount of Indonesian text data as multilingual(N).   \nIn contrast to the feature-based scenarios, fine-tuning the full language model is expensive and resource-intensive. However, as shown in [1], fully fine-tuning the full language model will result in a better text classifier. We fine-tuned the best performing model on the feature-based scenarios. The experiment was reduced to only using the maximum total data and an added English data multiplier up to 3. \nMore details on the book and paper. Quick summary: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8234567673473785,
        0.9461399746809109
      ],
      "excerpt": "Each experiment will train the model using the training set and validate it to the validation set on each epoch. After each epoch, we will evaluate whether we will continue, reduce the learning rate, or stop the training process based on validation set performance and the hyperparameter set on each condition. In the end, we use the model from the best performing epoch based on its validation performance to predict the test set.    \nOn the feature-based experiment, we set the final layer dropout probability to 0.2, the learning rate reducer patience to 5, and the early stopping patience to 12. On full fine-tune experiment, we set the final layer dropout probability to 0.2, the learning rate reducer patience to 0, and the early stopping patience to 4. Every validation and prediction use 0.5 as its label threshold.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9860253282548767
      ],
      "excerpt": "The result of feature-based experiments with XLM-R model on all datasets can be seen in Fig 1. Through this result, we can see that adding English data can help the performance of the model. On [3] & [4] dataset, adding English data consistently improves the performance. But on [5] dataset, there's a point where the added English data results in worse performance. We hypothesize this is due to the large difference in what constitutes hate-speech (or toxic by Jigsaw dataset) between the datasets used.    \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9902588804554174,
        0.9935017171375479
      ],
      "excerpt": "The result of feature-based experiments with mBERT model on all datasets can be seen in Fig 2. The same phenomenon is observed on mBERT based experiment, although the performance is substantially lower. This is expected as XLM-R is designed to improve mBERT on various design choices.   \nDefining the gain as the difference between monolingual and its highest multilingual performance, Table I shows the gains averaged on all datasets across total data and model. The highest gain can be seen on the lowest amount of total data used, 500, with F1-score gain of 0.176 using XLM-R model and 0.129 using mBERT model. The results suggest that the lower the amount of data used; the more gains yield by adding English data to the training set. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Improving Indonesian text classification using multilingual language model",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ilhamfp/indonesian-text-classification-multilingual/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 27 Dec 2021 02:19:15 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ilhamfp/indonesian-text-classification-multilingual/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ilhamfp/indonesian-text-classification-multilingual",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/ilhamfp/indonesian-text-classification-multilingual/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/trip_advisor/xlm_r/indoxtc-fine-tune-head-tripadvisor-xlm-r-all.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/trip_advisor/mbert/indoxtc-fine-tune-head-tripadvisor-mbert-all.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/prosa/xlm_r/indoxtc-fine-tune-head-prosa-xlm-r-all.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/prosa/mbert/indoxtc-fine-tune-head-prosa-mbert-all.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/trip_advisor/xlm_r/indoxtc-extracting-tripadvisor-features-xlm-r.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/trip_advisor/mbert/indoxtc-extracting-tripadvisor-features-mbert.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/xlm_r/indoxtc-extracting-yelp-features-xlm-r-9.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/xlm_r/indoxtc-extracting-yelp-features-xlm-r-8.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/xlm_r/indoxtc-extracting-yelp-features-xlm-r-1.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/xlm_r/indoxtc-combining-yelp-features-xlm-r.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/xlm_r/indoxtc-extracting-yelp-features-xlm-r-7.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/xlm_r/indoxtc-extracting-yelp-features-xlm-r-5.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/xlm_r/indoxtc-extracting-yelp-features-xlm-r-3.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/xlm_r/indoxtc-extracting-yelp-features-xlm-r-6.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/xlm_r/indoxtc-extracting-yelp-features-xlm-r-4.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/xlm_r/indoxtc-extracting-yelp-features-xlm-r-2.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/mbert/indoxtc-extracting-yelp-features-mbert-3.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/mbert/indoxtc-combining-yelp-features-mbert.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/mbert/indoxtc-extracting-yelp-features-mbert-9.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/mbert/indoxtc-extracting-yelp-features-mbert-1.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/mbert/indoxtc-extracting-yelp-features-mbert-8.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/mbert/indoxtc-extracting-yelp-features-mbert-5.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/mbert/indoxtc-extracting-yelp-features-mbert-6.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/mbert/indoxtc-extracting-yelp-features-mbert-2.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/mbert/indoxtc-extracting-yelp-features-mbert-4.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/yelp_review/mbert/indoxtc-extracting-yelp-features-mbert-7.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/prosa/xlm_r/indoxtc-extracting-prosa-features-xlm-r.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/prosa/mbert/indoxtc-extracting-prosa-features-mbert.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/jigsaw_toxic/xlm_r/indoxtc-extracting-toxic-en-features-xlm-r-2.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/jigsaw_toxic/xlm_r/indoxtc-extracting-toxic-en-features-xlm-r-1.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/jigsaw_toxic/xlm_r/indoxtc-combining-toxic-en-features-xlm-r.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/jigsaw_toxic/xlm_r/indoxtc-extracting-toxic-en-features-xlm-r-3.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/jigsaw_toxic/mbert/indoxtc-extracting-toxic-en-features-mbert-6.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/jigsaw_toxic/mbert/indoxtc-extracting-toxic-en-features-mbert-4.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/jigsaw_toxic/mbert/indoxtc-extracting-toxic-en-features-mbert-3.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/jigsaw_toxic/mbert/indoxtc-extracting-toxic-en-features-mbert-5.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/jigsaw_toxic/mbert/indoxtc-extracting-toxic-en-features-mbert-2.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/jigsaw_toxic/mbert/indoxtc-extracting-toxic-en-features-mbert-1.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/jigsaw_toxic/mbert/indoxtc-combining-toxic-en-features-mbert.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/toxic/xlm_r/indoxtc-extracting-toxic-features-xlm-r.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/extracting_features/toxic/mbert/indoxtc-extracting-toxic-features-mbert.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/toxic/xlm_r/indoxtc-fine-tune-head-toxic-xlm-r-all.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_head/toxic/mbert/indoxtc-fine-tune-head-toxic-mbert-all.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_full/trip_advisor/xlm_r/indoxtc-fine-tune-full-tripadvisor-xlm-r.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_full/trip_advisor/xlm_r_duplicate_removed/indoxtc-fine-tune-full-tripadvisor-xlm-r-dupli.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_full/prosa/xlm_r/indoxtc-fine-tune-full-prosa-xlm-r.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_full/toxic/xlm_r/indoxtc-fine-tune-full-toxic-xlm-r-simpler.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/fine_tune_full/toxic/xlm_r_comparable/indoxtc-fine-tune-full-toxic-xlm-r-comparable.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_head/Gain%20analysis%20-%20mBERT.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_head/Gain%20analysis.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_head/trip_advisor/xlm_r/Plot%20Result%20Trip%20XLMR.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_head/trip_advisor/mbert/Plot%20Result%20Trip%20mBERT.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_head/prosa/xlm_r/Plot%20Result%20Prosa%20XLMR.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_head/prosa/mbert/Plot%20Result%20Prosa%20mBERT.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_head/toxic/xlm_r/Plot%20Result%20Toxic%20XLMR.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_head/toxic/mbert/Plot%20Result%20Toxic%20mBERT.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_full/trip_advisor/xlm_r/Analyze%20Zero-shot.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_full/trip_advisor/xlm_r/Analyze%20Improvement.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_full/trip_advisor/xlm_r/Result%20Trip.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_full/trip_advisor/xlm_r_duplicate/Result%20Trip%20Dupli.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_full/prosa/xlm_r/Analyze%20Zero-shot.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_full/prosa/xlm_r/Analyze%20Improvement.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_full/prosa/xlm_r/Result%20Prosa.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_full/toxic/xlm_r/Analyze%20Zero-shot.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_full/toxic/xlm_r/Analyze%20Improvement.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_full/toxic/xlm_r/Result%20Toxic.ipynb",
      "https://raw.githubusercontent.com/ilhamfp/indonesian-text-classification-multilingual/master/notebooks/result_analysis/fine_tune_full/toxic/xlm_r_comparable/Result%20Toxic%20Comparable.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8234112951766007
      ],
      "excerpt": "Using the feature-based scenario, we run many experiments as the expensive and multilingual representation have been precomputed on all the data. In all training data scenarios, we vary the total data used. More specifically, we train the model using [500, 1000, 2500, 5000, 7500, Max] text data. Specific to multilingual training data scenario, we vary the amount of added English data by [0.25, 0.5, 0.75, 1, 1.5, 2, 3, 4, 5, 6, 7, 8, 9, 10] times the amount of Indonesian text data. We refer to a multilingual experiment with added English data N times the amount of Indonesian text data as multilingual(N).   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8101964126250897
      ],
      "excerpt": "We split the training data into training and validation set with a 90:10 ratio. The split was done in a stratified fashion, conserving the distribution of labels between the training & validation set. The result is a dataset separated into training, validation, and test sets.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8862859961672565
      ],
      "excerpt": "<p align=\"center\"> <img src=\".\\notebooks\\result_analysis\\fine_tune_head\\compilation\\plot-trip-xlmr-english.png\" alt=\"xlm-r-1-result\" width=\"250\"/> <img src=\".\\notebooks\\result_analysis\\fine_tune_head\\compilation\\plot-prosa-xlmr-english.png\" alt=\"xlm-r-1-result\" width=\"250\"/> <img src=\".\\notebooks\\result_analysis\\fine_tune_head\\compilation\\plot-toxic-xlmr-english.png\" alt=\"xlm-r-1-result\" width=\"250\"/> </p> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8862859961672565
      ],
      "excerpt": "<p align=\"center\"> <img src=\".\\notebooks\\result_analysis\\fine_tune_head\\compilation\\plot-trip-mbert-english.png\" alt=\"xlm-r-1-result\" width=\"250\"/> <img src=\".\\notebooks\\result_analysis\\fine_tune_head\\compilation\\plot-prosa-mbert-english.png\" alt=\"xlm-r-1-result\" width=\"250\"/> <img src=\".\\notebooks\\result_analysis\\fine_tune_head\\compilation\\plot-toxic-mbert-english.png\" alt=\"xlm-r-1-result\" width=\"250\"/> </p> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8015119899346859
      ],
      "excerpt": "<p align=\"center\"> <img src=\".\\notebooks\\result_analysis\\fine_tune_head\\compilation\\average-f1-score-gains.png\" alt=\"xlm-r-1-result\" width=\"320\"/> </p> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ilhamfp/indonesian-text-classification-multilingual/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Indonesian Text Classification Multilingual",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "indonesian-text-classification-multilingual",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ilhamfp",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ilhamfp/indonesian-text-classification-multilingual/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 11,
      "date": "Mon, 27 Dec 2021 02:19:15 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "multilingual-language-model",
      "text-classification",
      "indonesian-language",
      "indonesian-text-classification",
      "sentiment-analysis",
      "hate-speech-detection",
      "language-model",
      "multilingual",
      "zero-shot",
      "monolingual",
      "cross-lingual-transfer",
      "multilingual-language-models",
      "indonesian-data",
      "english-language"
    ],
    "technique": "GitHub API"
  }
}
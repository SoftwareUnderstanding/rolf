{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1801.01290",
      "https://arxiv.org/abs/1802.09477",
      "https://arxiv.org/abs/1801.01290",
      "https://arxiv.org/abs/1802.09477"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ccolas/rl_stats",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-04T17:55:27Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-20T18:14:38Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9258103088647407
      ],
      "excerpt": "To obtain plots of the false positive rates as a function of the sample size for various tests, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9257449492891339,
        0.9652848466966747,
        0.9722013702969563
      ],
      "excerpt": "The data we used are:  \n* 192 runs of Soft-Actor Critic for 2M timesteps on Half-Cheetah-v2, using the Spinning Up implementation. \n* 192 runs of Twin-Delayed Deep Deterministic Policy Gradient for 2M timesteps on Half-Cheetah-v2, using the Spinning Up implementation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8455497814364272,
        0.9908515160185586
      ],
      "excerpt": "The central tendency, the type of error, the test used, the confidence level and the sample size are tunable parameters. \nThis repository also provides text files with learning curves for 192 runs of Soft-Actor Critic and 192 runs of Twin-Delayed Deep Deterministic Policy Gradient \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ccolas/rl_stats/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 23:29:39 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ccolas/rl_stats/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ccolas/rl_stats",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ccolas/rl_stats/master/run_expe.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This is the repository associated to the paper:\n\n**A Hitchhiker's Guide to Statistical Comparisons of Reinforcement Learning Algorithms.**\n\nThis code serves two purposes: reproducing the experiments from the paper and showing an example \nof rigorous testing and visualization of algorithm performances.\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8308072052322508,
        0.8870055437053419
      ],
      "excerpt": "To obtain plots of the false positive rates as a function of the sample size for various tests, \njust run the plot_false_positive.py script: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "python3 example_test_and_plot.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8846056604440784
      ],
      "excerpt": "This example samples one sample of a given size from each, compares them using a statistical test and plot the learning curves,  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ccolas/rl_stats/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "A Hitchhiker's Guide to Statistical Comparisons of Reinforcement Learning Algorithms",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "rl_stats",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ccolas",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ccolas/rl_stats/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "`python3 run_experiment.py --study equal_dist_equal_var`\n\nPossible studies:\n\n* equal_dist_equal_var\n* equal_dist_unequal_var\n* unequal_dist_equal_var\n* unequal_dist_unequal_var_1: here the first distribution is the one that has the smallest std\n* unequal_dist_unequal_var_2: here the first distribution has the largest std\n\nThis creates a pickle file in ./data/equal_dist_equal_var/ for each pair of distributions.\nA bash file is made available to launch the experiment on a slurm cluster.\n\nIt is advised to run the experiment with fewer iterations first, to make sure everything works.\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Wed, 29 Dec 2021 23:29:39 GMT"
    },
    "technique": "GitHub API"
  }
}
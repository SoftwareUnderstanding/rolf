{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Our code is based on [fairseq-0.8.0](https://github.com/pytorch/fairseq). Thanks for their contribution to the open-source commuity.\r\n\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2004.09297"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this toolkit useful in your work, you can cite the corresponding papers listed below:\r\n\r\n    @article{song2020mpnet,\r\n        title={MPNet: Masked and Permuted Pre-training for Language Understanding},\r\n        author={Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},\r\n        journal={arXiv preprint arXiv:2004.09297},\r\n        year={2020}\r\n    }\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{song2020mpnet,\n    title={MPNet: Masked and Permuted Pre-training for Language Understanding},\n    author={Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},\n    journal={arXiv preprint arXiv:2004.09297},\n    year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8471736354311271
      ],
      "excerpt": "wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/michael-wzhu/mpnet_zh/master/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/michael-wzhu/mpnet_zh",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to Facebook AI Research Sequence-to-Sequence Toolkit (fairseq)\nWe want to make contributing to this project as easy and transparent as\npossible.\nPull Requests\nWe actively welcome your pull requests.\n\nFork the repo and create your branch from master.\nIf you've added code that should be tested, add tests.\nIf you've changed APIs, update the documentation.\nEnsure the test suite passes.\nMake sure your code lints.\nIf you haven't already, complete the Contributor License Agreement (\"CLA\").\n\nContributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\nComplete your CLA here: https://code.facebook.com/cla\nIssues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\nLicense\nBy contributing to Facebook AI Research Sequence-to-Sequence Toolkit (fairseq),\nyou agree that your contributions will be licensed under the LICENSE file in\nthe root directory of this source tree.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-09T12:44:08Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-18T02:21:55Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9647519402238267
      ],
      "excerpt": "MPNet: Masked and Permuted Pre-training for Language Understanding, is a novel pre-training method for language understanding tasks. It solves the problems of MLM (masked language modeling) in BERT and PLM (permuted language modeling) in XLNet and achieves better accuracy. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9305679254697297
      ],
      "excerpt": "Code for pre-training and fine-tuning for a variety of language understanding (GLUE, SQuAD, RACE, etc) tasks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9392850526432036
      ],
      "excerpt": "Then, we need to binarize data. The command of binarizing data is following: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.893167341058
      ],
      "excerpt": "We provide a pre-trained MPNet model in BERT-base setting for you to have a try (which is only pre-trained for 125K steps). We will provide the final model with 500K training steps once the pre-training is finished. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A chinese version MPNet (https://arxiv.org/pdf/1905.02450.pdf)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/michael-wzhu/mpnet_zh/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 14:25:31 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/michael-wzhu/mpnet_zh/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "michael-wzhu/mpnet_zh",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/michael-wzhu/mpnet_zh/tree/master/pretraining/docs"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/michael-wzhu/mpnet_zh/master/MPNet/preprocess_GLUE_tasks.sh",
      "https://raw.githubusercontent.com/michael-wzhu/mpnet_zh/master/src/scripts/pretrain_on_wiki/run_pretrain.sh",
      "https://raw.githubusercontent.com/michael-wzhu/mpnet_zh/master/pretraining/scripts/compound_split_bleu.sh",
      "https://raw.githubusercontent.com/michael-wzhu/mpnet_zh/master/pretraining/scripts/sacrebleu_pregen.sh",
      "https://raw.githubusercontent.com/michael-wzhu/mpnet_zh/master/pretraining/examples/language_model/prepare-wikitext-103.sh",
      "https://raw.githubusercontent.com/michael-wzhu/mpnet_zh/master/pretraining/examples/speech_recognition/datasets/prepare-librispeech.sh",
      "https://raw.githubusercontent.com/michael-wzhu/mpnet_zh/master/pretraining/examples/roberta/preprocess_GLUE_tasks.sh",
      "https://raw.githubusercontent.com/michael-wzhu/mpnet_zh/master/pretraining/examples/roberta/preprocess_RACE.sh",
      "https://raw.githubusercontent.com/michael-wzhu/mpnet_zh/master/pretraining/examples/roberta/commonsense_qa/download_cqa_data.sh",
      "https://raw.githubusercontent.com/michael-wzhu/mpnet_zh/master/pretraining/examples/translation/prepare-wmt14en2fr.sh",
      "https://raw.githubusercontent.com/michael-wzhu/mpnet_zh/master/pretraining/examples/translation/prepare-iwslt14.sh",
      "https://raw.githubusercontent.com/michael-wzhu/mpnet_zh/master/pretraining/examples/translation/prepare-iwslt17-multilingual.sh",
      "https://raw.githubusercontent.com/michael-wzhu/mpnet_zh/master/pretraining/examples/translation/prepare-wmt14en2de.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nWe implement MPNet and this pre-training toolkit based on the codebase of [fairseq](https://github.com/pytorch/fairseq). The installation is as follow:\r\n\r\n```\r\npip install --editable pretraining/\r\npip install pytorch_transformers==1.0.0 transformers scipy sklearn\r\n```\r\n\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "    python MPNet/encode.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.817841589412698
      ],
      "excerpt": "    --trainpref wikitext-103-raw/wiki.train.bpe \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8202500180531594
      ],
      "excerpt": "    --testpref wikitext-103-raw/wiki.test.bpe \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "fairseq-train $DATA_DIR \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8424760504462719
      ],
      "excerpt": "    --tokens-per-sample $TOKENS_PER_SAMPLE \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8559432665962853
      ],
      "excerpt": "    --total-num-update $TOTAL_UPDATES \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8828665034782968
      ],
      "excerpt": "    --weight-decay 0.01 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "    --train-subset=train \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8900486270063179
      ],
      "excerpt": "from fairseq.models.masked_permutation_net import MPNet \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/michael-wzhu/mpnet_zh/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "Cuda",
      "C++",
      "Lua",
      "Batchfile",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) Facebook, Inc. and its affiliates.\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "MPNet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "mpnet_zh",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "michael-wzhu",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/michael-wzhu/mpnet_zh/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Mon, 27 Dec 2021 14:25:31 GMT"
    },
    "technique": "GitHub API"
  }
}
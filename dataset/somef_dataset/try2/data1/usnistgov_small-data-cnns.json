{
  "citation": [
    {
      "confidence": [
        0.9944484218006108
      ],
      "excerpt": "- UNet: https://arxiv.org/pdf/1505.04597.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "totalMemory: 10.92GiB freeMemory: 7.76GiB \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/usnistgov/small-data-cnns",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-10T15:55:43Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-20T13:18:49Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.944798453311724,
        0.9916923794033667
      ],
      "excerpt": "Explore mechanisms for overcoming small datasets when training Convolutional Neural Networks with Deep Learning. \nAll data used for this project is available at: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8009371785030491
      ],
      "excerpt": "- mask type: grayscale image with one of these pixel types: uint8, uint16, int32 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955840416664728,
        0.9536441138363216
      ],
      "excerpt": "This training code uses lmdb databases to store the image and mask data to enable parallel memory-mapped file reader to keep the GPUs fed.  \nThe input folder of images and masks needs to be split into train and test. Train to update the model parameters, and test to estimate the generalization accuracy of the resulting model. By default 80% of the data is used for training, 20% for test. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8952104988397119
      ],
      "excerpt": "Script which converts two folders of images and masks into a pair of lmdb \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8639319651305816
      ],
      "excerpt": "With the lmdb build there are two methods for training a model.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9103736220163398
      ],
      "excerpt": "Whether you launch the training locally or on Enki, the training script will query the system and determine how many GPUs are available. It will then build the network for training using data-parallelism. So when you define your batch size, it will actually be multiplied by the number of GPUs you are using to train the network. So a batch size of 8 training on 4 gpus, results in an actual batch size of 32. Each GPU computes its own forward pass on its own data, computes the gradient, and then all N gradients are averaged. The gradient averaging can either happen on the CPU, or on any of the GPUs.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8395206691891185,
        0.9183694671991841
      ],
      "excerpt": "If the fully connected GPU topology exists, perform gradient averaging on one of the GPUs (gpu:0 by default). Otherwise, it is faster to transfer the gradient information to the CPU and perform the gradient averaging on cpu:0. The training script controls where the gradient averaging happens with the option: gradient_update_location. \nThe full help for the training script is: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9003470782670253
      ],
      "excerpt": "                        image tile size the network is expecting \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8069591731273206
      ],
      "excerpt": "                        Where to perform gradient averaging and update. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9177911624435448,
        0.9184650248926527
      ],
      "excerpt": "number_classes: you need to specify the number of classes being segmented so the network knows how to format the output. The input labels are integers indicating the classes. However, under the hood tensorflow needs a one-hot encoding of the class, so this tells the model how to expand the input label into a one-hot encoding of the class id. \ntest_every_n_steps: typically, you run test/validation every epoch. However, I am often building models with very small amounts of data (e.g. 500 images). With an actual batch size of 32, that allows me 15 gradient updates per epoch. The model does not change that fast, so I impose a fixed global step count between test so that I don't spend all of my GPU time running the test data. A good value for this is typically 1000. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8011769127785652,
        0.8375500661394152,
        0.9537254010326064
      ],
      "excerpt": "gradient_update_location: whether to perform gradient averaging on the CPU or GPU. See the above discussion about GPU connection topology. \nrestore_checkpoint_filepath: if you provide a filepath to a previous training of the same model, the training script will load the model weights, restoring that checkpoint before continuing to train. The filepath to the checkpoint should be like \"~/Semantic-Segmentation/UNet/model/checkpoint/model.ckpt-6\" do not include the \".index\", \".meta\", or \".data\" component of the checkpoint filepath. \nOne of the defining features of this codebase is the parallel (python multiprocess) image reading from lightning memory mapped databases.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8971901197191089,
        0.9596506358555309,
        0.9691816872609298,
        0.9945212280430878
      ],
      "excerpt": "- applies the augmentation transformation to the image and mask pair \n- add the augmented image to the batch that reader is building \n- once a batch is constructed, the imagereader adds it to the output queue shared among all of the imagereaders \nThe training script setups of python generators which just get a reference to the output batch queue data and pass it into tensorflow. One of the largest bottlenecks in deep learning is keeping the GPUs fed. By performing the image reading and data augmentation asynchronously all the main python training thread has to do is get a reference to the next batch (which is waiting in memory) and pass it to tensorflow to be copied to the GPUs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9233283637261012
      ],
      "excerpt": "You will know whether the image readers are keeping up with the GPUs. When the imagereader output queue is getting empty a warning is printed to the log: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9095989214785583
      ],
      "excerpt": "| jitter (x, y)  | Percent of Image Size  | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216071058889584
      ],
      "excerpt": "| blur  | Uniform Selection of Kernel Size | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8358985203126529,
        0.9502012260702014
      ],
      "excerpt": "These augmentation transformations are generally configured based on domain expertise and stay fixed per dataset. \nCurrently the only method for modifying them is to open the imagereader.py file and edit the augmentation parameters contained within the code block within the imagereader __init__: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8698949587553885,
        0.8387836596614869
      ],
      "excerpt": "self._jitter_augmentation_severity = 0.1  #: x% of a FOV \nself._noise_augmentation_severity = 0.02  #: vary noise by x% of the dynamic range present in the image \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "An exploration of the best mechanisms to overcome small datasets when training Convolutional Neural Networks with Deep Learning.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/usnistgov/small-data-cnns/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 23:09:06 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/usnistgov/small-data-cnns/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "usnistgov/small-data-cnns",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/build_tl_models/PythonAPI/pycocoDemo.ipynb",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/build_tl_models/PythonAPI/pycocoEvalDemo.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/meta.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/gan/generate_gan/launch_sbatch.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/UNet-Gan/launch_train_sbatch_rpe.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/UNet-Gan/launch_train_sbatch_concrete.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/UNet-Gan/create_gan_databases.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/UNet-Gan/launch_train_sbatch_hes.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/build_tl_models/PythonAPI/launch_segnet_sbatch.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/build_tl_models/PythonAPI/launch_unet_sbatch.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/SegNet/launch_train_sbatch_aug.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/SegNet/launch_inference_sbatch.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/SegNet/launch_train_sbatch_noaug.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/UNet/launch_inference_desktop.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/UNet/launch_train_sbatch_rpe.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/UNet/launch_inference_sbatch.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/UNet/launch_train_sbatch_hes.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/UNet/create_databases.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/UNet-ED/launch_train_sbatch.sh",
      "https://raw.githubusercontent.com/usnistgov/small-data-cnns/cvmi-2019/src/UNet-ED/create_databases.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8382036121572355
      ],
      "excerpt": "the include shell script launch_train_sbatch.sh is setup to all training on the Enki Cluster. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9065154659820163
      ],
      "excerpt": "2019-02-27 13:05:03.068185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1, 2, 3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8643450863507176,
        0.8643450863507176,
        0.8643450863507176,
        0.8643450863507176,
        0.8643450863507176
      ],
      "excerpt": "2019-02-27 13:05:04.527345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 2 3  \n2019-02-27 13:05:04.528317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y Y Y  \n2019-02-27 13:05:04.529605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N Y Y  \n2019-02-27 13:05:04.530902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 2:   Y Y N Y  \n2019-02-27 13:05:04.532257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 3:   Y Y Y N \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9252602573900718
      ],
      "excerpt": "2019-02-27 13:45:03.442171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0, 1, 2, 3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8728877089607683,
        0.8728877089607683,
        0.8728877089607683,
        0.8728877089607683,
        0.8728877089607683
      ],
      "excerpt": "2019-02-27 13:45:05.405293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 1 2 3  \n2019-02-27 13:45:05.405302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N Y N N  \n2019-02-27 13:45:05.405307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   Y N N N  \n2019-02-27 13:45:05.405311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 2:   N N N Y  \n2019-02-27 13:45:05.405315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 3:   N N Y N \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8232123894060793
      ],
      "excerpt": "2019-02-27 13:40:43.708536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9308458761135345
      ],
      "excerpt": "2019-02-27 13:40:43.708571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9160938194204037,
        0.9160938194204037,
        0.8991357220436823
      ],
      "excerpt": "2019-02-27 13:40:44.094585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0  \n2019-02-27 13:40:44.094608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N  \n2019-02-27 13:40:44.094840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/device:GPU:0 with 7490 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:d8:00.0, compute capability: 6.1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8980582709505841
      ],
      "excerpt": "                        lmdb database to use for (Required) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8043492247211779
      ],
      "excerpt": "                        lmdb database to use for testing (Required) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9704634633688808
      ],
      "excerpt": "                        Options: ['cpu', 'gpu:#:']. Use the GPU if you have a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8798192264371019
      ],
      "excerpt": "gradient_update_location: whether to perform gradient averaging on the CPU or GPU. See the above discussion about GPU connection topology. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8660851044974243
      ],
      "excerpt": "- mask pixel value 0 indicates background/no-class \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8579411795380598
      ],
      "excerpt": "The input folder of images and masks needs to be split into train and test. Train to update the model parameters, and test to estimate the generalization accuracy of the resulting model. By default 80% of the data is used for training, 20% for test. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091,
        0.8587476985249702
      ],
      "excerpt": "python build_lmdb.py -h \nusage: build_lmdb [-h] [--image_folder IMAGE_FOLDER] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8465274270824036
      ],
      "excerpt": "If you want to train the model on local hardware, avoid using launch_train_sbatch.sh, use python and directly launch train_unet.py or train_segnet.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python train_unet.py -h \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8223276235493272
      ],
      "excerpt": "usage: train_unet [-h] [--batch_size BATCH_SIZE] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.843422915301725
      ],
      "excerpt": "                        training batch size \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8069077871255258
      ],
      "excerpt": "restore_checkpoint_filepath: if you provide a filepath to a previous training of the same model, the training script will load the model weights, restoring that checkpoint before continuing to train. The filepath to the checkpoint should be like \"~/Semantic-Segmentation/UNet/model/checkpoint/model.ckpt-6\" do not include the \".index\", \".meta\", or \".data\" component of the checkpoint filepath. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/usnistgov/small-data-cnns/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Shell",
      "C++",
      "C",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Small Data CNNs",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "small-data-cnns",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "usnistgov",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/usnistgov/small-data-cnns/blob/cvmi-2019/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Mon, 27 Dec 2021 23:09:06 GMT"
    },
    "technique": "GitHub API"
  }
}
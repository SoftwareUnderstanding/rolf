{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] Sandler et al. \"MobileNetV2: Inverted Residuals and Linear Bottlenecks\". (https://arxiv.org/pdf/1801.04381.pdf) <br> \n[2] Hu et al. \"Squeeze-and-Excitation Networks\". (https://arxiv.org/pdf/1709.01507.pdf) <br>\n[3] He et al. \"Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks\". (https://arxiv.org/pdf/1808.06866.pdf) <br>\n[4] Liu et al. \"Computation-Performance Optimization of Convolutional Neural Networks with Redundant Kernel Removal\". (https://arxiv.org/pdf/1705.10748.pdf) <br>\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9948264970068836
      ],
      "excerpt": "<td >\u3000<img alt=\"\" title=\"Visit Computer Hope\" src=\"https://raw.githubusercontent.com/Gideon0805/Tensorflow_Model_Pruning/main/pic/Inverted_residual_block_nonpruned.png\" />Non pruned\u3000</td> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9948264970068836
      ],
      "excerpt": "<td >\u3000<img alt=\"\" title=\"Visit Computer Hope\" src=\"https://raw.githubusercontent.com/Gideon0805/Tensorflow_Model_Pruning/main/pic/SEblock_nonpruned.png\" />Non pruned\u3000</td> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Gideon0805/Tensorflow1.15-Model-Pruning",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-09T15:03:46Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-14T03:06:51Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This method now is just support for Inverted-Residual block[[1]](#ref) and Squeeze-and-Excitation block[[2]](#ref). Here use the characteristics of these two blocks, the internal channels of the block are pruned without affecting the output channel size, as shown below.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9697277849629848,
        0.9543717535090858,
        0.9415849511391633
      ],
      "excerpt": "This project was motivated for pruning on Depthwise Separable Convolution. Although the series model of MobileNet has been widely used in edge computing, the models could be through quantization and pruning to achieve a higher speed of inference. \nWe use structural pruning on the model in TF1.15 to reduce inference time practically. \nMethod introduction \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9842663011575801,
        0.9030195619041299
      ],
      "excerpt": "In our codes, we define pruning represent soft-pruning and strip as a real prune. \nThe pruning library allows for specification of the following hyper parameters: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.823964698611162
      ],
      "excerpt": "| scope_names | list of strings | [\"\"] | The scope name is from tf.name_scope or tf.variable_scope, and the scope should be include inverted residual block or SE block. | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8805742144201711
      ],
      "excerpt": "| pruning_filters_dict | dictionary | {} | The decay factor to use for exponential decay of the thresholds | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8948527551389118
      ],
      "excerpt": "| output_nodes | string | 'output' | The output nodes of the model, if there is more than one node, using a comma to separate. For example: 'output1,output2,output3' | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9569956779255129
      ],
      "excerpt": "First, applying soft-pruning[3] on pretrained-model and retraining until the convolution filters are convergence to zero. (Here, we use the definition of redundancy from Liu et al.[4] to determine the pruning filter.) Then remove the zeros-filter and export it to pb file for inference. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9539009174154022
      ],
      "excerpt": "Using the ckpt that return from get_pruning_ckpt() to retrain \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8561305090723833
      ],
      "excerpt": "Repeat step2. to step8. until soft-pruning is converged to your requirements. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Pruning for TF1.5",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Gideon0805/Tensorflow_Model_Pruning/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 27 Dec 2021 07:31:42 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Gideon0805/Tensorflow1.15-Model-Pruning/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Gideon0805/Tensorflow1.15-Model-Pruning",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8417025385423222
      ],
      "excerpt": "| output_dir | string | None | Output directory. | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8804429173905101
      ],
      "excerpt": "Repeat step2. to step8. until soft-pruning is converged to your requirements. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.819179860643615
      ],
      "excerpt": "| input_ckpt_path | string | None | The pretrained model checkpoint path for soft-pruning.| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8192770146687103
      ],
      "excerpt": "| input_tensors_map |dictionary | {} | It will be provided for tf.train.import_meta_graph() to rebuild the model graph. | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8571597939428117
      ],
      "excerpt": "| output_dir | string | None | Output directory. | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8505392339870486
      ],
      "excerpt": "| export_ckpt_path | string | '' | Checkpoint file path. | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8062729676803029
      ],
      "excerpt": "get_pruning_summary() calculate the failure rate to set retrain to be true or false. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Gideon0805/Tensorflow1.15-Model-Pruning/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "HTML"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Tensorflow model pruning:",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Tensorflow1.15-Model-Pruning",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Gideon0805",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Gideon0805/Tensorflow1.15-Model-Pruning/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 27 Dec 2021 07:31:42 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" style=\"width: 400;\">\n<tbody><tr>\n<td>\u3000<img alt=\"\" src=\"https://raw.githubusercontent.com/Gideon0805/Tensorflow_Model_Pruning/main/pic/Inverted_residual_block_soft-pruning.png\" />Inverted Residual block\u3000</td>\n<td>\u3000<img alt=\"\" src=\"https://raw.githubusercontent.com/Gideon0805/Tensorflow_Model_Pruning/main/pic/SEblock_soft-pruning.png\" />SE block\u3000</td>\n</tr></tbody></table>\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" style=\"width: 400;\">\n<tbody><tr>\n<td >\u3000<img alt=\"\" src=\"https://raw.githubusercontent.com/Gideon0805/Tensorflow_Model_Pruning/main/pic/Inverted_residual_block_strip.png\" />Inverted Residual block\u3000</td>\n<td>\u3000<img alt=\"\" src=\"https://raw.githubusercontent.com/Gideon0805/Tensorflow_Model_Pruning/main/pic/SEblock_strip.png\" />SE block\u3000</td>\n</tr></tbody></table>\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "*   [train_pruning_class.py](https://github.com/Gideon0805/Tensorflow_Model_Pruning/tree/main/src/train_pruning_class.py)\n\n\n```python\n#: Make a scope_names list\npruning_scopes = ['SE1', 'SE2', 'SE3']\nfor i in range(1,17):\n    name = 'MobilenetV2/expanded_conv_' + str(i) + '/'\n    pruning_scopes.append(name)\n    pass\n\noutput_dir = '/workspace/model_pruning/Testing/Pruning_Class_Test'\n#: Crate Pruning class\nfrom tf1pruning import Pruning\ntf_pruning = Pruning(\n    input_ckpt_path=FLAGS.pretrained_model_path,\n    scope_names=pruning_scopes,\n    output_dir=output_dir\n    )\n\n#: In training function\n#: create your own threshold list for soft-pruning\n#: and use for loop to retrain soft-pruning until convergence\nth_steps = [0.8, 0.7, 0.6, 0.55, 0.5]\nfor th in th_steps:\n    try_count = 0\n    failed_rate = 1.0\n    #: Set the soft-pruning threshold.\n    tf_pruning.set_threshold(th)\n    #: Through failed_rate and try_count to determine if the checkpoint needs to retrain again.\n    while failed_rate>0.1:\n        if try_count == 0:\n            pruning_output_dir = os.path.join(output_dir, 'TH'+str(th))\n            tf_pruning.set_output_dir(pruning_output_dir)\n            ckpt_to_retrain = tf_pruning.pruning_process(retrain=False)\n        else:\n            pruning_output_dir = os.path.join(output_dir, 'TH'+str(th)+'_Repruned'+str(try_count))\n            tf_pruning.set_output_dir(pruning_output_dir)\n            ckpt_to_retrain = tf_pruning.pruning_process(retrain=True)\n        try_count = try_count + 1\n\n        #: We use model_params to specify the checkpoint that need to be retrained.\n        model_params['pretrained_model_path'] = ckpt_to_retrain\n        #: Training with ckpt_to_retrain\n        task_graph = tf.Graph()\n        with task_graph.as_default():\n            global_step = tf.Variable(0, name='global_step', trainable=False)\n\n            session_config = tf.ConfigProto()\n            session_config.gpu_options.allow_growth = True\n            #:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:\n            #: Your own training script\n            config = ( tf.estimator.RunConfig().replace(...) ) \n\n            model = tf.estimator.Estimator(model_fn=model_fn,\n                                           model_dir=pruning_output_dir,\n                                           config=config,\n                                           params=model_params)\n\n            print(\n                ('\\n validation data number: {} \\n').format(\n                    len(list(tf.python_io.tf_record_iterator(FLAGS.validationset_path)))\n                )\n            )\n\n            pip = Pipeline()\n            model.train(\n                input_fn=lambda: pip.data_pipeline(\n                    datasets,\n                    params=pipeline_param,\n                    batch_size=FLAGS.batch_size\n                ),\n                steps=FLAGS.training_steps,\n                saving_listeners=[\n                    EvalCheckpointSaverListener(\n                        model,\n                        lambda: pip.eval_data_pipeline(\n                            FLAGS.validationset_path,\n                            params=pipeline_param,\n                            batch_size=FLAGS.validation_batch_size\n                        )\n                    )\n                ]\n            )\n            print('Training Process Finished.')\n            #:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:\n        #:==== Training End ====\n        #: get retrained ckpt\n        retrained_ckpt_path = tf_pruning.get_retrained_ckpt(pruning_output_dir)\n        #: Analyze how many filters don't converge to zero.\n        #: If the failed rate is higher than you expect, \n        #: do soft-pruning on retrained_ckpt_path and retrain.\n        failed_rate = tf_pruning.get_pruning_summary()\n        pass\n\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
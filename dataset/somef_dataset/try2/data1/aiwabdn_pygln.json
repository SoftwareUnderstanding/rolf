{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@misc{pygln2020,\n  author       = {Basu, Anindya and Kuhnle, Alexander},\n  title        = {{PyGLN}: {G}ated {L}inear {N}etwork implementations for {NumPy}, {PyTorch}, {TensorFlow} and {JAX}},\n  year         = {2020},\n  url          = {https://github.com/aiwabdn/pygln}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{pygln2020,\n  author       = {Basu, Anindya and Kuhnle, Alexander},\n  title        = {{PyGLN}: {G}ated {L}inear {N}etwork implementations for {NumPy}, {PyTorch}, {TensorFlow} and {JAX}},\n  year         = {2020},\n  url          = {https://github.com/aiwabdn/pygln}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8511535834563826
      ],
      "excerpt": "Published under GNU GPLv3 license. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9270442643068253
      ],
      "excerpt": "Cite PyGLN \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/aiwabdn/pygln",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-01T15:13:59Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-22T16:21:53Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9488049520451444
      ],
      "excerpt": "Implementations of Gated Linear Networks (GLNs), a new family of neural networks introduced by DeepMind in a recent paper, using various frameworks: NumPy, PyTorch, TensorFlow and JAX. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9369523664457149
      ],
      "excerpt": "    corresponding K-dim vector of base predictions (could be a constant prior), instead of \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955441313315927
      ],
      "excerpt": "PyTorch implementation takes torch.Tensors (on the same device as the model) as parameters. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Python implementation of GLN in different frameworks",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/aiwabdn/pygln/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 10,
      "date": "Wed, 29 Dec 2021 14:04:08 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/aiwabdn/pygln/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "aiwabdn/pygln",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To use `pygln`, simply clone the repository and install the package:\n\n```bash\ngit clone git@github.com:aiwabdn/pygln.git\ncd pygln\npip install -e .\n```\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8018566057409832
      ],
      "excerpt": "    base_predictor: Optional[Callable] = None, \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8594142235991984,
        0.8594142235991984
      ],
      "excerpt": "    bias: bool = True, \n    context_bias: bool = True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8289669050403863
      ],
      "excerpt": "    output. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8724192637627809
      ],
      "excerpt": "base_predictor (np.array[N] -> np.array[K]): If given, maps the N-dim input vector to a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9223763706198296,
        0.8481141692098436,
        0.8212095437786386
      ],
      "excerpt": "GLN.predict(input: np.ndarray, \n            target: np.ndarray = None, \n            return_probs: bool = False) -&gt; np.ndarray \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8606665408519905
      ],
      "excerpt": "input (np.array[B, N]): Batch of B N-dim float input vectors. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/aiwabdn/pygln/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "PyGLN: Gated Linear Network implementations for NumPy, PyTorch, TensorFlow and JAX",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pygln",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "aiwabdn",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/aiwabdn/pygln/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 81,
      "date": "Wed, 29 Dec 2021 14:04:08 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To get started, we provide some utility functions in `pygln.utils`, for instance, to obtain the MNIST dataset:\n\n```python\nfrom pygln import utils\n\nX_train, y_train, X_test, y_test = utils.get_mnist()\n```\n\nSince Gated Linear Networks are binary classifiers by default, let's first train a classifier for the target digit 3:\n\n```python\ny_train_3 = (y_train == 3)\ny_test_3 = (y_test == 3)\n```\n\nWe provide a generic wrapper around all four backend implementations. Here, we use the NumPy version ([see below](#gln-interface) for full list of arguments):\n\n```python\nfrom pygln import GLN\n\nmodel_3 = GLN(backend='numpy', layer_sizes=[4, 4, 1], input_size=X_train.shape[1])\n```\n\nAlternatively, the various implementations can be imported directly via their respective submodule:\n\n```python\nfrom pygln.numpy import GLN\n\nmodel_3 = GLN(layer_sizes=[4, 4, 1], input_size=X_train.shape[1])\n```\n\nNext we train the model for one epoch on the dataset:\n\n```python\nfor n in range(X_train.shape[0]):\n    pred = model_3.predict(X_train[n:n+1], target=y_train_3[n:n+1])\n```\n\nNote that GLNs are updated in an online unbatched fashion, so simply by passing each instance and corresponding binary target to `model.predict()`. To speed up training, it can make sense to use small batch sizes (~10).\n\nFinally, to use the model for prediction on unknown instances, we just omit the `target` parameter -- this time the batched version:\n\n```python\nimport numpy as np\n\npreds = []\nbatch_size = 100\nfor n in range(np.ceil(X_test.shape[0] / batch_size).astype(int)):\n    batch = X_test[n * batch_size: (n + 1) * batch_size]\n    pred = model_3.predict(batch)\n    preds.append(pred)\n```\n\nAs accuracy for the trained model we get:\n\n```python\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(y_test_3, np.concatenate(preds, axis=0))\n```\n\n    0.9861\n\nAs can be seen, the accuracy is already quite high, despite the fact that we only did one pass through the data.\n\nTo train a classifier for the entire MNIST dataset, we create a `GLN` model with 10 classes. If `num_classes` provided is greater than `2`, our implementations implicitly create the same number of separate binary GLNs and train them simultaneously in a one-vs-all fashion:\n\n```python\nmodel = GLN(backend='numpy', layer_sizes=[4, 4, 1], input_size=X_train.shape[1],\n            num_classes=10)\n\nfor n in range(X_train.shape[0]):\n    model.predict(X_train[n:n+1], target=y_train[n:n+1])\n\npreds = []\nfor n in range(X_test.shape[0]):\n    preds.append(model.predict(X_test[n]))\n\naccuracy_score(y_test, np.vstack(preds))\n```\n\n    0.9409\n\nWe provide `utils.evaluate_mnist` to run experiments on the MNIST dataset. For instance, to train a GLN as a binary classifier for a particular digit with batches of 4:\n\n```python\nfrom pygln import utils\n\nmodel_3 = GLN(backend='numpy', layer_sizes=[4, 4, 1], input_size=784)\n\nprint(utils.evaluate_mnist(model_3, mnist_class=3, batch_size=4))\n```\n\n    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15000/15000 [00:10<00:00, 1366.94it/s]\n    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:01<00:00, 2195.59it/s]\n\n    98.69\n\nAnd to train on all classes:\n\n```python\nmodel = GLN(backend='numpy', layer_sizes=[4, 4, 1], input_size=784,\n            num_classes=10)\n\nprint(utils.evaluate_mnist(model, batch_size=4))\n```\n\n    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15000/15000 [00:35<00:00, 418.21it/s]\n    100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:03<00:00, 764.10it/s]\n\n    94.69\n\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
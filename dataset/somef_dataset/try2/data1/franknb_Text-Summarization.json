{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1503.02531",
      "https://arxiv.org/abs/1910.01108\n\n- **Model name**: sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6#"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9935274469414742
      ],
      "excerpt": "Original paper: Victor Sanh, Lysandre Debut, Julien Chaumond, Thomas Wolf: \"DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter\", 2020. https://arxiv.org/abs/1910.01108 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/franknb/Text-Summarization",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-10-18T04:42:17Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-22T11:56:49Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8751904993344594,
        0.9582231444884028,
        0.8266123877857758,
        0.9416385369193959,
        0.9145592669645611
      ],
      "excerpt": "What is this? \nAs described, a testing place for different text summarization tools. \nWhat is the background? \nHere's a workflow I created for the complete task. Put it simple, we were asked to complete the task of generating automated summarzations from the Credera weekly updates videos. The videos are on Microsoft Stream, and ultimately we need to generate summarized texts for each video. \nFor now, we will be focusing on the 3rd part of the workflow, namely, the text summarization. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9116738129187356
      ],
      "excerpt": "They includes different approaches for text summarization. In the following part, I will give simple introductions of each methods. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8656499619292638,
        0.9173983790851992,
        0.9905141176765901
      ],
      "excerpt": "What is DistilBERT?:  \nDistil here means (Knowledge) Distillation, just as the literal means, is a compression technique in which a small model is trained to reproduce the behavior of a larger model (or an ensemble of models). It was first introduced in (https://www.cs.cornell.edu/~caruana/compression.kdd06.pdf), then generalized in (https://arxiv.org/abs/1503.02531) \nBERT here stands for Bidirectional Encoder Representations from Transformers, is applying the bidirectional training of Transformer (https://arxiv.org/pdf/1706.03762.pdf), a popular attention model, to language modelling. This is in contrast to previous efforts which looked at a text sequence either from left to right or combined left-to-right and right-to-left training. The paper\u2019s results show that a language model which is bidirectionally trained can have a deeper sense of language context and flow than single-direction language models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "An experimental repo for testing effective text summarization tools.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/franknb/Text-Summarization/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 11:21:08 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/franknb/Text-Summarization/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "franknb/Text-Summarization",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/franknb/Text-Summarization/main/Text_Summarize.ipynb",
      "https://raw.githubusercontent.com/franknb/Text-Summarization/main/PyTorch%20Extractive%20%26%20Abstractive%20Summarization.ipynb",
      "https://raw.githubusercontent.com/franknb/Text-Summarization/main/Text%20Summarization%20Approach%20Comparisons.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/franknb/Text-Summarization/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Text-Summarization",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Text-Summarization",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "franknb",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/franknb/Text-Summarization/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sat, 25 Dec 2021 11:21:08 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "nlp",
      "text-summarization",
      "deep-learning",
      "neural-network",
      "artificial-intelligence"
    ],
    "technique": "GitHub API"
  }
}
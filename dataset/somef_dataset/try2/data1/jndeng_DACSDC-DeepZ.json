{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1612.03144v2",
      "https://arxiv.org/abs/1708.02002"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jndeng/DACSDC-DeepZ",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-06-23T13:42:12Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-23T09:57:14Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Due to the speed limitation of 20 FPS, we started with [YOLOv2-Tiny detector](https://pjreddie.com/darknet/yolov2/), which consists of a backbone network for feature extraction and a detection network for candidate bounding box generation. Considering that there is no need to classify in our task, we reduced the detection network to a location network, in which a candidate bounding box is only represented by a confidence socre and a position.\n\nHowever, with such a simple model, we were soon faced with the challenges of tiny objects, occlusions and distractions from the provided data set. In order to tackle to the aforementioned challenges, we investigated various network architectures for both training and inference. \n\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/jndeng/DACSDC-DeepZ/master/Train/cfg/architecture.png\" alt=\"network architecture\" width=\"380px\" height=\"400px\">\n</p>\n\nWe later combined [Feature Pyramid Network](https://arxiv.org/abs/1612.03144v2) to fuse fine-grained features with strong semantic features to enhance the ability in detecting small objects. Meanwhile, we utilized [Focal Loss](https://arxiv.org/abs/1708.02002) function to mitigate the imbalance between the single ground truth box and the candidate boxes at training phase, thereby partially resolving occlusions and distractions. With the combined techniques, we achieved the inference network as shown in the figure with an accuracy improvement of ~ 0.042. \n\nMoreover, we used multithreading to accelerate the process of prediction by loading images and infering in parallel, which improved about 7 FPS on NVIDIA Jetson TX2.\n\n\nThe performance of our model is as follow:\n\n| Self-Test Accuracy (mean IoU) | Organizer-Test Accuracy (mean IoU) | Speed (FPS on Jetson TX2)\n|:-----:|:-----:|:-----:|\n| 0.866 | 0.691 | ~25 |\n\n**Note:**  \n\nWe develop two projects for different purposes in this repository. Project `Train` is mainly used for model training and accuracy evaluation on powerful GPU(NVIDIA Titan X Pascal in our experiments). While project `Inference` is dedicated to inference on embedded GPU(NVIDIA Jetson TX2) with better optimization in speed and energy consumption.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9480267937753725,
        0.8741381687362596,
        0.9874458181551561
      ],
      "excerpt": "This repository contains the proposed solution of team DeepZ(GPU Platform) for 2018 System Design Contest. \nUPD: Official dataset is available in this repo. \nAnd we just learn that the dataset has been updated and reduced from 98 classes to 95 classes. Unfortunately, we did not notice the update during the contest, which means all of our experiments were based on the former 98 classes dataset. This should not have a big impact on our model, but the division of train/valid set will be different with the new dataset, breaking some of the scripts. For now, we do not have time to review and update those scripts, so feel free to ask here if you encounter any problems. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8685357629207082,
        0.8503123904378396
      ],
      "excerpt": "We provide a python interface for inference on Jetson TX2. Assume that all the images to be detected are stored in $INFERENCE_ROOT/data/images.  \n1. Copy the trained weights of the model from  $TRAIN_ROOT/model/yolo_tiny_dacsdc_best.weights to $INFERENCE_ROOT/model/yolo_tiny_dacsdc_best.weights \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Proposed solution of team DeepZ for 2018 DAC System Design Contest",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jndeng/DACSDC-DeepZ/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 14,
      "date": "Mon, 20 Dec 2021 17:50:16 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/jndeng/DACSDC-DeepZ/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "jndeng/DACSDC-DeepZ",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/jndeng/DACSDC-DeepZ/master/Train/script/train_model.sh",
      "https://raw.githubusercontent.com/jndeng/DACSDC-DeepZ/master/Train/script/valid_model.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "~~1. Download the raw dataset [dac_origin.tar (6.3GB)]() (about 100,000 images and the corresponding labels) and unzip it to `$TRAIN_ROOT/data/raw_dataset`.~~\n1. Download the official dataset, unzip it, rename and move the folder contains all subclass folders to `$TRAIN_ROOT/data/raw_dataset`.\n2. Use the raw dataset `$TRAIN_ROOT/data/raw_dataset` to generate the proper dataset `$TRAIN_ROOT/data/train_dataset` for training. The entire process of dataset generation takes about 14GB of hard disk space, and the raw dataset will no longer be needed once we obtain `$TRAIN_ROOT/data/train_dataset`.\n```Shell\ncd $TRAIN_ROOT/data/script\npython generate_dataset.py\n```\n3. Randomly divide the entire dataset into two disjoint parts: training set and validation set according to 8:2 ratio. The result of division will be stored in `$TRAIN_ROOT/data/dataset` as the meta files. You can make a new division by yourself, or just apply the pre-divided dataset used in our experiments.\n```Shell\n#: Make a new division\ncd $TRAIN_ROOT/data/script\npython divide_dataset_randomly.py\n```\n```Shell\n#: Use a pre-divided dataset\ncd $TRAIN_ROOT/data/script\npython divide_dataset.py\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "*Prerequisites:*\n * OpenCV\n * CUDA/cuDNN\n * Python2/Python2-Numpy\n\n*Project download and installation:*\n1. Download the source code on the appropriate devices respectively. Project `Train` is recommended using on device with powerful GPU. While project `Inference` should be used on NVIDIA Jetson TX2 in order to make a fair evaluation of speed.\n```Shell\n#: You may use this command twice to download the source code on different devices\ngit clone https://github.com/jndeng/DACSDC-DeepZ.git\n```\n2. Build the source code of two projects separately on the corresponding device. We will use `$TRAIN_ROOT` and `$INFERENCE_ROOT` to call the directory of project `Train` and project `Inference` respectively.\n```Shell\n#: For project 'Train'\ncd $TRAIN_ROOT\nmake -j8\n```\n```Shell\n#: For project 'Inference'\ncd $INFERENCE_ROOT\nmake -j8\n```\n\n**Note:**\n1. Our implementation is based on [Darknet framework](https://pjreddie.com/darknet/). You can also refer to the [installation guide](https://pjreddie.com/darknet/install/) of the original Darknet framework.\n2. For convenience, we only implement the code for **single GPU mode**, which means **CPU mode** and **multiple GPUs mode** are not supported in both of our projects.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9668357587463683,
        0.9465718491881494
      ],
      "excerpt": "cd $TRAIN_ROOT/script \nbash train_model.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9668357587463683,
        0.9465718491881494
      ],
      "excerpt": "cd $TRAIN_ROOT/script \nbash valid_model.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9668357587463683
      ],
      "excerpt": "cd $INFERENCE_ROOT/script \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8407651001510851
      ],
      "excerpt": "3. Start training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8262570752280579
      ],
      "excerpt": "By default, training log will be written to file $TRAIN_ROOT/log/yolo_tiny_dacsdc.out, and validation will be performed on validation set every 20000 batch automatically. The accuracy of each validation will be stored in file $TRAIN_ROOT/log/yolo_tiny_dacsdc.log. Besides, weights of the best model among all validated models will be saved as $TRAIN_ROOT/model/yolo_tiny_dacsdc_best.weights. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9333384803827206
      ],
      "excerpt": "python main.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/jndeng/DACSDC-DeepZ/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "C",
      "Cuda",
      "Python",
      "C++",
      "Makefile",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Solution of Team DeepZ for 2018 DACSDC",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DACSDC-DeepZ",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "jndeng",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jndeng/DACSDC-DeepZ/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 24,
      "date": "Mon, 20 Dec 2021 17:50:16 GMT"
    },
    "technique": "GitHub API"
  }
}
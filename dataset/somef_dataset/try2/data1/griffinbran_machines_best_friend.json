{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "External Resources:\n* [`High quality images of dogs`] (Unsplash): ([*source*](https://unsplash.com/s/photos/dogs))\n* [`VQA labeled images of dogs`] (Visual Genome): ([*source*](https://visualgenome.org/VGViz/explore?query=dogs))\n* [`Google Open Source: Dog Detection`] (Open Images): ([*source*](https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=detection&c=%2Fm%2F0bt9lr))\n* [`Google Open Source: Dog Segmentation`] (Open Images): ([*source*](https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=segmentation&c=%2Fm%2F0bt9lr&r=false))\n* [`VGG-19`] (Keras API): ([*source*](https://keras.io/api/applications/vgg/))\n* [`ImageNet ILSVRC Competition`] (Machine Learning Mastery): ([*source*](https://machinelearningmastery.com/introduction-to-the-imagenet-large-scale-visual-recognition-challenge-ilsvrc/))\n\n    \n<span>Photo by <a href=\"https://unsplash.com/@jessedo81?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">jesse orrico</a> on <a href=\"https://unsplash.com/s/photos/dogs?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></span>\n    \n    \n    <span>Photo by <a href=\"https://unsplash.com/@wildmooncreative?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Kasey McCoy</a> on <a href=\"https://unsplash.com/s/photos/dogs?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></span>\n    \n    \nPapers:\n* `VisualBackProp: efficient visualization of CNNs` (arXiv): ([*source*](https://arxiv.org/pdf/1611.05418.pdf))\n* `Very Deep Convolutional Networks For Large-Scale Image Recognition` (arXiv): ([*source*](https://arxiv.org/pdf/1409.1556.pdf))\n* `Transfer Learning in Keras with Computer Vision Models` (Machine Learning Mastery): ([*source*](https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/))\n\n    \n",
      "technique": "Header extraction"
    }
  ],
  "citation": [
    {
      "confidence": [
        0.9919741163226976,
        0.9858255518275743
      ],
      "excerpt": "Computer Vision ( RGB image processing, image formation, feature detection, computational photography) \nConvolutional Neural Networks(CNN)- regularization, automated pattern recognition, ... \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.842790493796475
      ],
      "excerpt": "Automatic photo captioning, Visual Question Answering (VQA) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9979037080891701
      ],
      "excerpt": "|<span style=\"color:yellow\">03-Block 01</span>|<span style=\"color:yellow\">pool1 (MaxPooling2D)</span>|<span style=\"color:yellow\">( 2 x 2 )</span>|<span style=\"color:yellow\">None</span>|<span style=\"color:yellow\">0</span>|<span style=\"color:yellow\">( 2 x 2 )</span>|<span style=\"color:yellow\">( Batch, 112, 112, 64 )| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9973482595969089
      ],
      "excerpt": "|<span style=\"color:yellow\">06-Block 02</span>|<span style=\"color:yellow\">pool2 (MaxPooling2D)</span>|<span style=\"color:yellow\">( 2 x 2 )</span>|<span style=\"color:yellow\">None</span>|<span style=\"color:yellow\">0</span>|<span style=\"color:yellow\">( 2 x 2 )</span>|<span style=\"color:yellow\">( Batch, 56, 56, 128 )| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9996182011747523
      ],
      "excerpt": "|<span style=\"color:yellow\">10-Block 03</span>|<span style=\"color:yellow\">pool3 (MaxPooling2D)</span>|<span style=\"color:yellow\">( 2 x 2 )</span>|<span style=\"color:yellow\">None</span>|<span style=\"color:yellow\">0</span>|<span style=\"color:yellow\">( 2 x 2 )</span>|<span style=\"color:yellow\">( Batch, 28, 28, 256 )| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.975737027764834
      ],
      "excerpt": "|<span style=\"color:yellow\">14-Block 04</span>|<span style=\"color:yellow\">pool4 (MaxPooling2D)</span>|<span style=\"color:yellow\">( 2 x 2 )</span>|<span style=\"color:yellow\">None</span>|<span style=\"color:yellow\">0</span>|<span style=\"color:yellow\">( 2 x 2 )</span>|<span style=\"color:yellow\">( Batch, 14, 14, 512 )| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9989507542819337
      ],
      "excerpt": "|<span style=\"color:yellow\">18-Block 05</span>|<span style=\"color:yellow\">pool5 (MaxPooling2D)</span>|<span style=\"color:yellow\">( 2 x 2 )</span>|<span style=\"color:yellow\">None</span>|<span style=\"color:yellow\">0</span>|<span style=\"color:yellow\">( 2 x 2 )</span>|<span style=\"color:yellow\">( Batch, 7, 7, 512 )| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9846624645716213
      ],
      "excerpt": "ImageNet Large Scale Visual Recognition Challenge (ILSVRC) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/griffinbran/Object-Detection-of-Canines-with-Transfer-Learning",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "External Resources:\n* [`High quality images of dogs`] (Unsplash): ([*source*](https://unsplash.com/s/photos/dogs))\n* [`VQA labeled images of dogs`] (Visual Genome): ([*source*](https://visualgenome.org/VGViz/explore?query=dogs))\n* [`Google Open Source: Dog Detection`] (Open Images): ([*source*](https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=detection&c=%2Fm%2F0bt9lr))\n* [`Google Open Source: Dog Segmentation`] (Open Images): ([*source*](https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=segmentation&c=%2Fm%2F0bt9lr&r=false))\n* [`VGG-19`] (Keras API): ([*source*](https://keras.io/api/applications/vgg/))\n* [`ImageNet ILSVRC Competition`] (Machine Learning Mastery): ([*source*](https://machinelearningmastery.com/introduction-to-the-imagenet-large-scale-visual-recognition-challenge-ilsvrc/))\n\n    \n<span>Photo by <a href=\"https://unsplash.com/@jessedo81?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">jesse orrico</a> on <a href=\"https://unsplash.com/s/photos/dogs?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></span>\n    \n    \n    <span>Photo by <a href=\"https://unsplash.com/@wildmooncreative?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Kasey McCoy</a> on <a href=\"https://unsplash.com/s/photos/dogs?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></span>\n    \n    \nPapers:\n* `VisualBackProp: efficient visualization of CNNs` (arXiv): ([*source*](https://arxiv.org/pdf/1611.05418.pdf))\n* `Very Deep Convolutional Networks For Large-Scale Image Recognition` (arXiv): ([*source*](https://arxiv.org/pdf/1409.1556.pdf))\n* `Transfer Learning in Keras with Computer Vision Models` (Machine Learning Mastery): ([*source*](https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/))\n\n    \n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "> * Brandon Griffin ([GitHub](https://github.com/griffinbran) | [LinkedIn](https://www.linkedin.com/in/griffinbran/))\n\nProject Link: ([*source*](https://github.com/griffinbran/machines_best_friend.git))\n\n---\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-10T19:22:45Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-02-01T20:02:12Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9629962971611608
      ],
      "excerpt": "Capstone Project \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9093897459595239
      ],
      "excerpt": "Machine Learning for Deep Neural Networks (TensorFlow, Keras API) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.823625064861641
      ],
      "excerpt": "Transfer Learning with a pre-trained deep learning image classifier (VGG-16 CNN from Visual Geometry Group in 2014) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "Data Aquisition & Cleaning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "Findings and Recommendations \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8165534105616751,
        0.8877816409497344,
        0.928595003289642
      ],
      "excerpt": "Here is some background info: \nTransfer learning: pre-existing model, trained on millions of images over the period of several weeks. \nEliminates the need to afford cost of training deep learning models from scratch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8194755486494228,
        0.9636658881767498
      ],
      "excerpt": "Weight initialization: weights in re-used layers used as starting point in training and adapted in response to new problem \nUse model as-is to classify new photographs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246384799718741
      ],
      "excerpt": "Tasks more similar to the original training might rely on output from layers deep in the model such as the 2nd to last fully connected layer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9078280112511847,
        0.857436659695181,
        0.8853350995274905,
        0.9452388708483914
      ],
      "excerpt": "Layers closer to the input layer of the model: \n    Learn low-level features such as lines, etc. \nLayers in the middle of the network of layers: \n    Learn complex abstract features that combine the extracted lower-level features from the input \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9407572755809321
      ],
      "excerpt": "    Interpret the extracted features in the context of a classification task \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8314418671647253,
        0.9126448207215906
      ],
      "excerpt": "NOTE: Make sure you cross-reference your data with your data sources to eliminate any data collection or data entry issues.<br> \nSee Acknowledgements and Contact section for starter code resources<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9681061282046677,
        0.9681061282046677
      ],
      "excerpt": "|variable1|dtype|Origin of Data|Category|Description| \n|variable2|dtype|Origin of Data|Category|Description| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9681061282046677,
        0.9681061282046677
      ],
      "excerpt": "|variable2|dtype|Origin of Data|Category|Description| \n|variable1|dtype|Origin of Data|Category|Description| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8577302739126875
      ],
      "excerpt": "DENSE : \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.935649809993839
      ],
      "excerpt": "|CNN Model|Split|Epoch|Loss|Accuracy| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9615571399803653
      ],
      "excerpt": "Google CoLab Pro High-RAM(27.4 GB RAM available in runtime memory) plus GPU had to be used to fit the transfer model without a batch generator(cost $10 for the month). Even with the High-RAM I had to be very careful with order of loading variables into memory. Colab Kernels crashed many times and everytime had to start over from scratch with data loading. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9707125460802843
      ],
      "excerpt": "Hot dogs, I saw like anywhere between 6-10 in the images that were supposed to be dogs. This is a problem, because they are randomly labeled improperly. It makes me have to ask the question, what other common words are introducing bias in the AI due to language? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9974832998895711,
        0.963538639162979,
        0.8508342656672404,
        0.892547197437305,
        0.9928542954171586
      ],
      "excerpt": "YES, with an accuracy of 97.5% the model can identify a dog in an image it has never seen before. With an accuracy about half a percentage point above the baseline score of 97% which would result if the model predicted every single image had no dog, we can say that the model is better than no model lol. Important to consider, moving forward, would be a batch generator to reduce memory demands by moving old batches of data out of memory and new batches of data into RAM iteratively as the model is training. This  allows for a number of benefits such as: \nA.) Data Augmentation, I actually have written a batch generator to perform image augmentation which will act as a regularization technique by preventing overfitting. By augmenting training data the model never sees the exact same image twice and this is ok because a dog is still a dog even if it flipped, reduced in size, enlarged, rotated, etc. \nB.) Batch size is given more freedom to choose larger BASE-2 values, because we no longer need load the entire image dataset into memory. \nConsider the similarity of images, specifically ImageNet images vs Visual Genome data. Visual Genome images are very random with dog objects as the minor object in many. Images have on average up to 35 objects identified, but I did not look at any ImageNet data. Maybe I could have extracted features from a layer lower in the network near the input and obtained less error. \nPredicting breeds would be pretty cool. All I would need to do is ID the breed of dog in over 3K images lol. Ideally an app hosted on Heroku that allows users to upload a dog pic and in return they get the top 5 breed predictions from the model. Top 5 because if someone wants to know the breed of their dog it probably isn't a purebreed. It probably is a mut and multiple breed labels are more apropriate. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8577302739126875
      ],
      "excerpt": "DENSE : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Deep learning for binary classification in Google Colaboratory with >97.5% accuracy on over 108,000 RGB images, including 3,000+ with dogs.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/griffinbran/machines_best_friend/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "***Can an image be used to accurately describe itself?***\n* Visual Question Answering (VQA)\n* Audience:  Computer vision enthusiasts, dog lovers, security services, and the visually impaired\n* Image data is a rich source of information. This project will aims to  automate the task of extracting  image descriptions.\n\n\n  Questions to be explored:\n> 1. Is the dog inside or outside?\n> 2. Does it have a friend?\n> 3. What breed is it?\n> 2. What layers need to be pre-trained?\n> 3. What is a reasonable 'optical cue'?\n<br>\n---\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 00:50:41 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/griffinbran/Object-Detection-of-Canines-with-Transfer-Learning/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "griffinbran/Object-Detection-of-Canines-with-Transfer-Learning",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/griffinbran/machines_best_friend/main/code/Notebook_03_Feature_Extraction_colab.ipynb",
      "https://raw.githubusercontent.com/griffinbran/machines_best_friend/main/code/Notebook-01-Data-Collection.ipynb",
      "https://raw.githubusercontent.com/griffinbran/machines_best_friend/main/code/Notebook-02-EDA.ipynb",
      "https://raw.githubusercontent.com/griffinbran/machines_best_friend/main/code/Machines_Best_FriendCoLab.ipynb",
      "https://raw.githubusercontent.com/griffinbran/machines_best_friend/main/code/Notebook-03-Feature-Extraction.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9032837796845528
      ],
      "excerpt": "Inception modules (GoogLeNet) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8244453191770256
      ],
      "excerpt": "NOTE : <br> \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.804133720883667
      ],
      "excerpt": "Here is some background info: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8195654606248104
      ],
      "excerpt": "Use as feature extraction model, output of pre-trained from a layer prior to output layer used as input to new classifier model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9231429691585326
      ],
      "excerpt": "|VGG-16 Block|Name (Type)|Kernel Size|Nodes|Params #|Stride/Pool|Output ( h x w x depth )| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8494031846314989
      ],
      "excerpt": "|01-Block 01|conv1 (Conv2D)|( 3 x 3 )|64|1,792|( 1 x 1 )|( Batch, 224, 224, 64 )| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8934745846565956
      ],
      "excerpt": "Total params: 138,357,544<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9163989562276041,
        0.871288725219656,
        0.8174540907975313
      ],
      "excerpt": "|Bseline MSE|Training|01|0.0316|0.3251| \n|Bseline MSE|Validation|01|0.0191|0.8220| \n|Bseline MSE|Training|02|0.0266|0.3248| \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/griffinbran/Object-Detection-of-Canines-with-Transfer-Learning/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Machines Best Friend",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Object-Detection-of-Canines-with-Transfer-Learning",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "griffinbran",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/griffinbran/Object-Detection-of-Canines-with-Transfer-Learning/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "https://www.quora.com/What-is-the-VGG-neural-network\n\n---\n<a id='acknowledgements_and_contact'></a>\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 00:50:41 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "transfer-learning",
      "cnn-classification",
      "object-detection",
      "deep-learning",
      "google-colab",
      "visual-genome",
      "imagenet",
      "keras-tensorflow",
      "gpu-computing",
      "dogs"
    ],
    "technique": "GitHub API"
  }
}
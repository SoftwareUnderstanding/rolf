{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find DenseNet useful in your research, please consider citing:\n\n\t@article{huang2019convolutional,\n\t title={Convolutional Networks with Dense Connectivity},\n\t author={Huang, Gao and Liu, Zhuang and Pleiss, Geoff and Van Der Maaten, Laurens and Weinberger, Kilian},\n\t journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},\n\t year={2019}\n\t }\n\t \n\t@inproceedings{huang2017densely,\n\t  title={Densely Connected Convolutional Networks},\n\t  author={Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q },\n\t  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n\t  year={2017}\n\t}\n\t\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{huang2019convolutional,\n title={Convolutional Networks with Dense Connectivity},\n author={Huang, Gao and Liu, Zhuang and Pleiss, Geoff and Van Der Maaten, Laurens and Weinberger, Kilian},\n journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},\n year={2019}\n }\n\n@inproceedings{huang2017densely,\n  title={Densely Connected Convolutional Networks},\n  author={Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q },\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  year={2017}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.996125637913194,
        0.9996526593394545,
        0.9070946534037115
      ],
      "excerpt": "Densely Connected Convolutional Networks (CVPR 2017, Best Paper Award)  \nGao Huang*, Zhuang Liu*, Laurens van der Maaten and Kilian Weinberger (* Authors contributed equally). \nand its journal version \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9997801623518242
      ],
      "excerpt": "Gao Huang, Zhuang Liu, Geoff Pleiss, Laurens van der Maaten and Kilian Weinberger. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8951975427913812
      ],
      "excerpt": "Multi-Scale Dense Convolutional Networks for Efficient Prediction \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8738569545862249
      ],
      "excerpt": "Model | Parameters| CIFAR-10 | CIFAR-10+ | CIFAR-100 | CIFAR-100+  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9725140271112827
      ],
      "excerpt": "DenseNet (L=100, k=12)|7.0M |5.77 |4.10 | 23.79|20.20 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "DenseNet-BC (L=100, k=12)|0.8M |4.51 |22.27 | 0.156s | 5452MB \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9907558046136287
      ],
      "excerpt": "Journal version (accepted by IEEE TPAMI) released. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/liuzhuang13/DenseNet",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "liuzhuangthu at gmail.com  \ngaohuang at tsinghua.edu.cn   \nAny discussions, suggestions and questions are welcome!\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-08-24T21:32:52Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T22:40:10Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "DenseNet is a network architecture where each layer is directly connected to every other layer in a feed-forward fashion (within each *dense block*). For each layer, the feature maps of all preceding layers are treated as separate inputs whereas its own feature maps are passed on as inputs to all subsequent layers. This connectivity pattern yields state-of-the-art accuracies on CIFAR10/100 (with or without data augmentation) and SVHN. On the large scale ILSVRC 2012 (ImageNet) dataset, DenseNet achieves a similar accuracy as ResNet, but using less than half the amount of parameters and roughly half the number of FLOPs.\n\n<img src=\"https://cloud.githubusercontent.com/assets/8370623/17981494/f838717a-6ad1-11e6-9391-f0906c80bc1d.jpg\" width=\"480\">\n\nFigure 1: A dense block with 5 layers and growth rate 4. \n\n\n![densenet](https://cloud.githubusercontent.com/assets/8370623/17981496/fa648b32-6ad1-11e6-9625-02fdd72fdcd3.jpg)\nFigure 2: A deep DenseNet with three dense blocks. \n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9726561364565403
      ],
      "excerpt": "This repository contains the code for DenseNet introduced in the following paper  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865,
        0.9527626853201414,
        0.9329394854207327,
        0.890132448856665
      ],
      "excerpt": "Gao Huang, Zhuang Liu, Geoff Pleiss, Laurens van der Maaten and Kilian Weinberger. \nNow with memory-efficient implementation! Please check the technical report and code for more infomation. \nThe code is built on fb.resnet.torch. \nOur [Caffe], Our memory-efficient [Caffe], Our memory-efficient [PyTorch],  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8029815523772748
      ],
      "excerpt": "[Torch 3D-DenseNet] by Barry Kui, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8192505441185383
      ],
      "excerpt": "[Tensorflow2] by Gaston Rios and Ulises Jeremias Cornejo Fandos. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9169983312139359
      ],
      "excerpt": "CondenseNet: An Efficient DenseNet using Learned Group Convolutions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8105755666870592,
        0.8534899903026898
      ],
      "excerpt": "Results on CIFAR \nResults on ImageNet and Pretrained Models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9642562434954941,
        0.9325023425502947,
        0.8992881635090565
      ],
      "excerpt": "There is an option -optMemory which is very useful for reducing GPU memory footprint when training a DenseNet. By default, the value is set to 2, which activates the shareGradInput function (with small modifications from here). There are two extreme memory efficient modes (-optMemory 3 or -optMemory 4) which use a customized densely connected layer. With -optMemory 4, the largest 190-layer DenseNet-BC on CIFAR can be trained on a single NVIDIA TitanX GPU (uses 8.3G of 12G) instead of fully using four GPUs with the standard (recursive concatenation) implementation .  \nMore details about the memory efficient implementation are discussed here. \nThe table below shows the results of DenseNets on CIFAR datasets. The \"+\" mark at the end denotes for standard data augmentation (random crop after zero-padding, and horizontal flip). For a DenseNet model, L denotes its depth and k denotes its growth rate. On CIFAR-10 and CIFAR-100 without data augmentation, a Dropout layer with drop rate 0.2 is introduced after each convolutional layer except the very first one. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9697266029163526
      ],
      "excerpt": "PyTorch documentation on models. We would like to thank @gpleiss for this nice work in PyTorch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9112708011363171,
        0.9788197493812814
      ],
      "excerpt": "If you use DenseNet as a model in your learning task, to reduce the memory and time consumption, we recommend use a wide and shallow DenseNet, following the strategy of wide residual networks. To obtain a wide DenseNet we set the depth to be smaller (e.g., L=40) and the growthRate to be larger (e.g., k=48). \nWe test a set of Wide-DenseNet-BCs and compared the memory and time with the DenseNet-BC (L=100, k=12) shown above. We obtained the statistics using a single TITAN X card, with batch size 64, and without any memory optimization. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8950035734488655
      ],
      "excerpt": "Wide-DenseNet-BC (L=40, k=48) uses about the same memory/time as DenseNet-BC (L=100, k=12), while is much more accurate. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8101283871837766
      ],
      "excerpt": "Add keras, tf, theano link for pretrained models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9298815437012857
      ],
      "excerpt": "Add usage of models in PyTorch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Densely Connected Convolutional Networks, In CVPR 2017 (Best Paper Award).",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/liuzhuang13/DenseNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1036,
      "date": "Fri, 24 Dec 2021 03:42:40 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/liuzhuang13/DenseNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "liuzhuang13/DenseNet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8862790344135699,
        0.8448833724829546
      ],
      "excerpt": "[PyTorch] by Andreas Veit, [PyTorch] by Brandon Amos, [PyTorch] by Federico Baldassarre, \n[MXNet] by Nicatio,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8448833724829546
      ],
      "excerpt": "[MXNet] by miraclewkf, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9601262557895638
      ],
      "excerpt": "Add supporting code, so one can simply git clone and run. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8255884843855917,
        0.8428544309968485,
        0.8245513258119578
      ],
      "excerpt": "DenseNet (L=100, k=12)|7.0M |5.77 |4.10 | 23.79|20.20 \nDenseNet (L=100, k=24)|27.2M |5.83 |3.74 | 23.42|19.25 \nDenseNet-BC (L=100, k=12)|0.8M |5.92 |4.51 | 24.15|22.27 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8221846523644377
      ],
      "excerpt": "Add Imagenet results and pretrained models. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/liuzhuang13/DenseNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Lua"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright (c) 2016, Zhuang Liu. \\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without modification,\\nare permitted provided that the following conditions are met:\\n\\n * Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n * Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n * Neither the name DenseNet nor the names of its contributors may be used to\\n   endorse or promote products derived from this software without specific\\n   prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Densely Connected Convolutional Networks (DenseNets)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DenseNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "liuzhuang13",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/liuzhuang13/DenseNet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4399,
      "date": "Fri, 24 Dec 2021 03:42:40 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "More accurate models trained with the memory efficient implementation in the [technical report](https://arxiv.org/pdf/1707.06990.pdf). \n\n\n| Network       |  Top-1 error | Torch Model |\n| ------------- | ----------- | ------------ |\n| DenseNet-264 (k=32)  |  22.1 |    [Download (256MB)](https://drive.google.com/file/d/0By1NwtA2JPGzdVRqOEotMUZrbTA/view?usp=sharing)\n| DenseNet-232 (k=48)  | 21.2 | [Download (426MB)](https://drive.google.com/open?id=0By1NwtA2JPGzdkRDaWQ5M3VHTDg)\n| DenseNet-cosine-264 (k=32) | 21.6  |  [Download (256MB)](https://drive.google.com/file/d/0By1NwtA2JPGzRDhxWGo2a3pOTjA/view?usp=sharing)\n| DenseNet-cosine-264 (k=48) | 20.4   | [Download (557MB)](https://drive.google.com/file/d/0By1NwtA2JPGzcnFDSE1HQVh4c0k/view?usp=sharing)\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "0. Install Torch and required dependencies like cuDNN. See the instructions [here](https://github.com/facebook/fb.resnet.torch/blob/master/INSTALL.md) for a step-by-step guide.\n1. Clone this repo: ```git clone https://github.com/liuzhuang13/DenseNet.git```\n\nAs an example, the following command trains a DenseNet-BC with depth L=100 and growth rate k=12 on CIFAR-10:\n```\nth main.lua -netType densenet -dataset cifar10 -batchSize 64 -nEpochs 300 -depth 100 -growthRate 12\n``` \nAs another example, the following command trains a DenseNet-BC with depth L=121 and growth rate k=32 on ImageNet:\n```\nth main.lua -netType densenet -dataset imagenet -data [dataFolder] -batchSize 256 -nEpochs 90 -depth 121 -growthRate 32 -nGPU 4 -nThreads 16 -optMemory 3\n``` \nPlease refer to [fb.resnet.torch](https://github.com/facebook/fb.resnet.torch) for data preparation.\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2010.12321](https://arxiv.org/abs/2010.12321",
      "https://arxiv.org/abs/2010.12321",
      "https://arxiv.org/abs/2105.01990](https://arxiv.org/abs/2105.01990",
      "https://arxiv.org/abs/2105.01990",
      "https://arxiv.org/abs/2109.10234](https://arxiv.org/abs/2109.10234",
      "https://arxiv.org/abs/2109.10234"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9502570162300228
      ],
      "excerpt": "BARThez: a Skilled Pretrained French Sequence-to-Sequence Model: https://arxiv.org/abs/2010.12321<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9688455774172909,
        0.9878817550225492
      ],
      "excerpt": "BERTweetFR : Domain Adaptation of Pre-Trained Language Models for French Tweets: https://arxiv.org/abs/2109.10234<br> \nBARThez github link: https://github.com/moussaKam/BARThez  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hadi-abdine/FrenchWordEmbeddingsDemo",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-20T13:17:23Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-05T20:40:07Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9955214424901193
      ],
      "excerpt": "In this portal we present and make available to the research and industrial community French linguistic resources of high scale and quality for different tasks result of training on very large quantities of online text collected (by our group as well) from the Web. Soon we will integrate similar resources for other languages. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8647699860059543,
        0.9118187973221418,
        0.9538305696241621,
        0.915449257082002
      ],
      "excerpt": "1-BARThez, the first french sequence to sequence pretrained model pretrained on 66GB of french raw text for roughly 60 hours on 128 Nvidia V100 GPUs.<br> \n2-French Word2vec vectors of dimension 300 that were trained using CBOW on a huge 33GB French raw text that we crawled and pre-processed from the French web.<br> \n3-BERTweetFR, the first pre-trained large scale language model adapted to French tweets. It is initialized with CamemBERT, the state-of-art general-domain language model for French based on the RoBERTa architecture. We perform domain-adaptive pre-training on 182M deduplicated tweets. The training runs for roughly 20 hours on 8 Nvidia V100 GPUs.<br> \n4-JuriBERT, set of different size BERT models pre-trained from scratch on 6.3GB of French legal-domain corpora.<br> \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hadi-abdine/FrenchWordEmbeddingsDemo/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 07:17:23 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hadi-abdine/FrenchWordEmbeddingsDemo/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "hadi-abdine/FrenchWordEmbeddingsDemo",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To install NPM dependencies:\n```\nnpm install\n```\nTo install all python dependencies:\n```\npip3 install -r requirements.txt\n```\nTo run the web app:\n```\npython3 explore.py\n```\nMake sure to download the [word vectors](http://master2-bigdata.polytechnique.fr/FrenchLinguisticResources/resources) you're interseting in testing under '../word2vec/dascim2.bin'\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8871212757021654
      ],
      "excerpt": "We introduce the following resources:<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8564053107084612
      ],
      "excerpt": "BARThez github link: https://github.com/moussaKam/BARThez  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8319974222213121
      ],
      "excerpt": "1-BARThez, the first french sequence to sequence pretrained model pretrained on 66GB of french raw text for roughly 60 hours on 128 Nvidia V100 GPUs.<br> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hadi-abdine/FrenchWordEmbeddingsDemo/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "JavaScript",
      "HTML",
      "Python",
      "CSS"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Linguistic Resources Portal <a href=\"http://master2-bigdata.polytechnique.fr/\"><img width=\"10%\" src='https://am3pap003files.storage.live.com/y4mFVNG1WQmoiw3YiiK_IWBvzUoZVh7xJjiXqOItjdfNTBtp2YM95S9dyInXCe-xJGtphyPC53jVtRZygWkmTdqFLiBNy6OffELaIHiM4380S6PaqFcE4k5W6liugAmEERHx5lBQy3nlP8fqf6GiutNudT_HjyBpzLs9wPpIp9-8-RzGcTSgUcEb2E_5ZWhG270?width=1600&height=230&cropmode=none'></a>",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "FrenchWordEmbeddingsDemo",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "hadi-abdine",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hadi-abdine/FrenchWordEmbeddingsDemo/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Tue, 21 Dec 2021 07:17:23 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "french-nlp",
      "word2vec",
      "transformers",
      "bart",
      "summarization",
      "linguistic-corpora"
    ],
    "technique": "GitHub API"
  }
}
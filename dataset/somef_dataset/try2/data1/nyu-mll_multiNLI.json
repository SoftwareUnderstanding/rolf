{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nyu-mll/multiNLI",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-02-03T00:56:59Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-09T07:49:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9675991923231742
      ],
      "excerpt": "This is the code we used to establish baselines for the MultiNLI corpus introduced in A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9756973143404002,
        0.9893347836486102,
        0.9481653470749817,
        0.9937528317624574,
        0.9546551478687013,
        0.9913426472645591,
        0.8588106866801182
      ],
      "excerpt": "We present three baseline neural network models. These range from a bare-bones model (CBOW), to an elaborate model which has achieved state-of-the-art performance on the SNLI corpus (ESIM), \nContinuous Bag of Words (CBOW):  in this model, each sentence is represented as the sum of the embedding representations of its \nwords. This representation is passed to a deep, 3-layers, MLP. Main code for this model is in cbow.py \nBi-directional LSTM: in this model, the average of the states of \na bidirectional LSTM RNN is used as the sentence representation. Main code for this model is in bilstm.py \nEnhanced Sequential Inference Model (ESIM): this is our implementation of the Chen et al.'s (2017) ESIM, without ensembling with a TreeLSTM. Main code for this model is in esim.py \nWe use dropout for regularization in all three models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.913352774298172
      ],
      "excerpt": "To train a model only on SNLI data,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8838290899691837,
        0.9882735733207355
      ],
      "excerpt": "Accuracy on SNLI's dev-set is used to do early stopping.  \nTo train a model on only MultiNLI or on a mixture of MultiNLI and SNLI data,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9580577004787447,
        0.9281360359988815,
        0.8687559842570672,
        0.8838290899691837
      ],
      "excerpt": "The optional alpha flag determines what percentage of SNLI data is used in training. The default value for alpha is 0.0, which means the model will be only trained on MultiNLI data.  \nIf alpha is a set to a value greater than 0 (and less than 1), an alpha percentage of SNLI training data is randomly sampled at the beginning of each epoch.  \nWhen using SNLI training data in this setting, we set alpha = 0.15. \nAccuracy on MultiNLI's matched dev-set is used to do early stopping. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9578920473949725
      ],
      "excerpt": "Accuracy on the dev-set for the chosen genre is used to do early stopping.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8739141009701604
      ],
      "excerpt": "To start training with any of the training scripts, there are a couple of required command-line flags and an array of optional flags. The code concerning all flags can be found in parameters.py. All the parameters set in parameters.py are printed to the log file everytime the training script is launched.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8285028653392815
      ],
      "excerpt": "model_type: there are three model types in this repository, cbow, bilstm, and cbow. You must state which model you want to use. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8231030093380628
      ],
      "excerpt": "datapath: path to your directory with MultiNLI, and SNLI data. Default is set to \"../data\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8862353249842575
      ],
      "excerpt": "seq_length: the maximum sequence length you wish to use. Default value is set to 50. Sentences shorter than seq_length are padded to the right. Sentences longer than seq-length are truncated.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9256956643587674
      ],
      "excerpt": "alpha: only used during train_mnli scheme. Determines what percentage of SNLI training data to use in each epoch of training. Default value set to 0.0 (which makes the model train on MultiNLI only). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9433510263457788
      ],
      "excerpt": "Remaining parameters like the size of hidden layers, word embeddings, and minibatch can be changed directly in parameters.py. The default hidden embedding and word embedding size is set to 300, the minibatch size (batch_size in the code) is set to 32. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9504892632331491
      ],
      "excerpt": "where the model_type flag is set to cbow and can be swapped for bilstm or esim, and the model_name flag is set to petModel-0 and can be changed to whatever you please. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9712287741890574
      ],
      "excerpt": "where 15% of SNLI training data is randomly sampled at the beginning of each epoch.  \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nyu-mll/multiNLI/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 62,
      "date": "Fri, 24 Dec 2021 15:22:08 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/nyu-mll/multiNLI/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "nyu-mll/multiNLI",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To get a CSV of predicted results for unlabeled test sets use `predictions.py`. This script requires the same flags as the training scripts. You must enter the `model_type` and `model_name`, and the path to the saved checkpoint and log files if they are different from the default (the default is set to `../logs` for both paths). \n\nHere is a sample command,\n\n`PYTHONPATH=$PYTHONPATH:. python predictions.py esim petModel-1 --alpha 0.15 --emb_train --logpath ../logs_keep --ckptpath ../logs_keep `\n\nThis script will create a CSV with two columns: pairID and gold_label.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "To test a trained model, simply add the `test` flag to the command used for training. The best checkpoint will be loaded and used to evaluate the model's performance on the MultiNLI dev-sets, SNLI test-set, and the dev-set for each genre in MultiNLI.\n\nFor example,\n\n`PYTHONPATH=$PYTHONPATH:. python train_genre.py esim petModel-2 --genre travel --emb_train --test`\n\n\nWith the `test` flag, the `train_mnli.py` script will also generate a CSV of predictions for the unlabaled matched and mismatched test-sets.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.847138085181828
      ],
      "excerpt": "Required flags, \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8126084607799592,
        0.8087708831513125
      ],
      "excerpt": "To train a model only on SNLI data,  \nUse train_snli.py.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8087708831513125
      ],
      "excerpt": "Use train_mnli.py.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8087708831513125
      ],
      "excerpt": "Use train_genre.py.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8333212748409294
      ],
      "excerpt": "To start training with any of the training scripts, there are a couple of required command-line flags and an array of optional flags. The code concerning all flags can be found in parameters.py. All the parameters set in parameters.py are printed to the log file everytime the training script is launched.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8547784833993508
      ],
      "excerpt": "To train on SNLI data only, here is a sample command, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8165939085729829
      ],
      "excerpt": "Similarly, to train on a mixture MultiNLI and SNLI data, here is a sample command, \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/nyu-mll/multiNLI/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Baseline Models for MultiNLI Corpus",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "multiNLI",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "nyu-mll",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nyu-mll/multiNLI/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 197,
      "date": "Fri, 24 Dec 2021 15:22:08 GMT"
    },
    "technique": "GitHub API"
  }
}
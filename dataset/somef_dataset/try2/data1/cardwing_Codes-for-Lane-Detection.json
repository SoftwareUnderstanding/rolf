{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This repo is built upon [SCNN](https://github.com/XingangPan/SCNN) and [LaneNet](https://github.com/MaybeShewill-CV/lanenet-lane-detection).\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1908.00821",
      "https://arxiv.org/abs/1712.06080",
      "https://arxiv.org/abs/1606.02147",
      "https://arxiv.org/abs/1908.00821"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use the codes, please cite the following publications:\n\n``` \n@article{hou2019learning,\n  title={Learning Lightweight Lane Detection CNNs by Self Attention Distillation},\n  author={Hou, Yuenan and Ma, Zheng and Liu, Chunxiao and Loy, Chen Change},\n  journal={arXiv preprint arXiv:1908.00821},\n  year={2019}\n}\n\n@inproceedings{pan2018SCNN,  \n  author = {Xingang Pan, Jianping Shi, Ping Luo, Xiaogang Wang, and Xiaoou Tang},  \n  title = {Spatial As Deep: Spatial CNN for Traffic Scene Understanding},  \n  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},  \n  month = {February},  \n  year = {2018}  \n}\n\n@misc{hou2019agnostic,\n    title={Agnostic Lane Detection},\n    author={Yuenan Hou},\n    year={2019},\n    eprint={1905.03704},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{hou2019agnostic,\n    title={Agnostic Lane Detection},\n    author={Yuenan Hou},\n    year={2019},\n    eprint={1905.03704},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{pan2018SCNN,\n  author = {Xingang Pan, Jianping Shi, Ping Luo, Xiaogang Wang, and Xiaoou Tang},\n  title = {Spatial As Deep: Spatial CNN for Traffic Scene Understanding},\n  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},\n  month = {February},\n  year = {2018}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{hou2019learning,\n  title={Learning Lightweight Lane Detection CNNs by Self Attention Distillation},\n  author={Hou, Yuenan and Ma, Zheng and Liu, Chunxiao and Loy, Chen Change},\n  journal={arXiv preprint arXiv:1908.00821},\n  year={2019}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cardwing/Codes-for-Lane-Detection",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you have any problems in reproducing the results, just raise an issue in this repo.\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-10-12T05:53:41Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-25T08:05:24Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8930901044020226,
        0.9783622166086532,
        0.9197569164344044,
        0.8848356177521974,
        0.9413133392927907
      ],
      "excerpt": "Key features: \n(1) ENet-label is a light-weight lane detection model based on ENet and adopts self attention distillation (more details can be found in our paper).  \n(2) It has 20 \u00d7 fewer parameters and runs 10 \u00d7 faster compared to the state-of-the-art SCNN, and achieves 72.0 (F1-measure) on CULane testing set (better than SCNN which achieves 71.6). It also achieves 96.64% accuracy in TuSimple testing set (better than SCNN which achieves 96.53%) and 36.56% accuracy in BDD100K testing set (better than SCNN which achieves 35.79%).  \n(3) Applying ENet-SAD to LLAMAS dataset yields 0.635 mAP in the multi-class lane marker segmentation task, which is much better than the baseline algorithm which achieves 0.500 mAP. Details can be found in this repo. \n(Do not hesitate to try our model!!!) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9037616770245492,
        0.8008047662929508,
        0.8008047662929508
      ],
      "excerpt": "The ground-truth labels of TuSimple testing set is now available at TuSimple. The annotated training (#frame = 3268) and validation labels (#frame = 358) can be found here, please use them (list-name.txt) to replace the train_gt.txt and val_gt.txt in train_lanenet.py. Moreover, you need to resize the image to 256 x 512 instead of 288 x 800 in TuSimple. Remember to change the maximum index of rows and columns, and detailed explanations can be seen here. Please evaluate your pred.json using the labels and this script. Besides, to generate pred.json, you can refer to this issue. \nThe whole dataset is available at CULane. \nThe whole dataset is available at BDD100K. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8897396208423749,
        0.8493288373457725
      ],
      "excerpt": "Note that path/to/image_name_list should be like test_img.txt. Now, you get the probability maps from our model. To get the final performance, you need to follow SCNN to get curve lines from probability maps as well as calculate precision, recall and F1-measure. \nReminder: you should check lanenet_data_processor.py and lanenet_data_processor_test.py to ensure that the processing of image path is right. You are recommended to use the absolute path in your image path list. Besides, this code needs batch size used in training and testing to be consistent. To enable arbitrary batch size in the testing phase, please refer to this issue. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9809955495125597
      ],
      "excerpt": "The pre-trained model for testing is here. (coming soon!) Note that in TuSimple, SCNN-Torch is based on ResNet-101 while SCNN-Tensorflow is based on VGG-16. In CULane and BDD100K, both SCNN-Torch and SCNN-Tensorflow are based on VGG-16. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8699654124153463
      ],
      "excerpt": "The pre-trained model for testing is here. Note that you need to exchange the order of VGG-MEAN in test_lanenet.py and change the order of input images from RGB to BGR since the pre-trained model uses opencv to read images. You can further boost the performance by referring to this issue. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.953792399724634
      ],
      "excerpt": "The accuracy and IoU of lane pixels are computed. The pre-trained model for testing is here. (coming soon!) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Learning Lightweight Lane Detection CNNs by Self Attention Distillation (ICCV 2019)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cardwing/Codes-for-Lane-Detection/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 325,
      "date": "Sun, 26 Dec 2021 11:52:19 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/cardwing/Codes-for-Lane-Detection/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "cardwing/Codes-for-Lane-Detection",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/cardwing/Codes-for-Lane-Detection/master/ENet-TuSimple-Torch/laneExp/ENet-model/test.sh",
      "https://raw.githubusercontent.com/cardwing/Codes-for-Lane-Detection/master/ENet-TuSimple-Torch/laneExp/ENet-model/train.sh",
      "https://raw.githubusercontent.com/cardwing/Codes-for-Lane-Detection/master/ENet-Label-Torch/experiments/test.sh",
      "https://raw.githubusercontent.com/cardwing/Codes-for-Lane-Detection/master/ENet-Label-Torch/experiments/train.sh",
      "https://raw.githubusercontent.com/cardwing/Codes-for-Lane-Detection/master/ENet-Label-Torch/tools/lane_evaluation/Run.sh",
      "https://raw.githubusercontent.com/cardwing/Codes-for-Lane-Detection/master/ENet-Label-Torch/tools/lane_evaluation/run.sh",
      "https://raw.githubusercontent.com/cardwing/Codes-for-Lane-Detection/master/ENet-BDD100K-Torch/experiments/test_ENet.sh",
      "https://raw.githubusercontent.com/cardwing/Codes-for-Lane-Detection/master/ENet-BDD100K-Torch/experiments/train_ENet.sh",
      "https://raw.githubusercontent.com/cardwing/Codes-for-Lane-Detection/master/ERFNet-CULane-PyTorch/test_erfnet.sh",
      "https://raw.githubusercontent.com/cardwing/Codes-for-Lane-Detection/master/ERFNet-CULane-PyTorch/train_erfnet.sh",
      "https://raw.githubusercontent.com/cardwing/Codes-for-Lane-Detection/master/ERFNet-CULane-PyTorch/tools/lane_evaluation/Run.sh",
      "https://raw.githubusercontent.com/cardwing/Codes-for-Lane-Detection/master/ERFNet-CULane-PyTorch/tools/lane_evaluation/run.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Install necessary packages:\n```\n    conda create -n tensorflow_gpu pip python=3.5\n    source activate tensorflow_gpu\n    pip install --upgrade tensorflow-gpu==1.3.0\n    pip3 install -r SCNN-Tensorflow/lane-detection-model/requirements.txt\n```\n\n2. Download VGG-16:\n\nDownload the vgg.npy [here](https://github.com/machrisaa/tensorflow-vgg) and put it in SCNN-Tensorflow/lane-detection-model/data.\n\n3. Pre-trained model for testing:\n\nDownload the pre-trained model [here](https://drive.google.com/open?id=1-E0Bws7-v35vOVfqEXDTJdfovUTQ2sf5).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8825984537480721
      ],
      "excerpt": "Note that path/to/image_name_list should be like test_img.txt. Now, you get the probability maps from our model. To get the final performance, you need to follow SCNN to get curve lines from probability maps as well as calculate precision, recall and F1-measure. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8641347892477529
      ],
      "excerpt": "Note that path/to/CULane-dataset/ should contain files like train_gt.txt and val_gt.txt. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8133164511699812
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=\"0\" python tools/train_lanenet.py --net vgg --dataset_dir path/to/CULane-dataset/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8969826685933437
      ],
      "excerpt": "|No line|43.4|45.8|44.7|45.1| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8005181838670592
      ],
      "excerpt": "[ ] Test SCNN-Tensorflow in TuSimple and BDD100K \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/cardwing/Codes-for-Lane-Detection/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Lua",
      "Python",
      "C++",
      "Shell",
      "MATLAB",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD License\\n\\nFor fb.resnet.torch software\\n\\nCopyright (c) 2016, Facebook, Inc. All rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without modification,\\nare permitted provided that the following conditions are met:\\n\\n * Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n * Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n * Neither the name Facebook nor the names of its contributors may be used to\\n   endorse or promote products derived from this software without specific\\n   prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "News",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Codes-for-Lane-Detection",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "cardwing",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cardwing/Codes-for-Lane-Detection/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 893,
      "date": "Sun, 26 Dec 2021 11:52:19 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "lane-detection",
      "deep-learning",
      "lua",
      "tensorflow",
      "cnn",
      "pytorch"
    ],
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1705.02315  Wang, Xiaosong, Peng, Yifan, Lu, Le, Lu, Zhiyong, Bagheri, Mohammadhadi, and Summers, Ronald M. Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. arXiv preprint arXiv:1705.02315, 2017.\n\n\n#### Input:\n224x224 image, convert to RGB, normalized based on the mean and standard deviation of training dataset of ImageNet\n\n\n#### CNN Model:\ndensenet121 https://arxiv.org/abs/1608.06993\ninitialize parameters from the model pre-trained on ImageNet:\nhttp://www.image-net.org/papers/imagenet_cvpr09.pdf \n\nBottleneck Features:  1x1024 \n\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n#### 3-Class Output:\ndense layer: 14x3,  {p_0, p_1, p_2} on each label,  without Softmax(",
      "https://arxiv.org/abs/1608.06993\ninitialize parameters from the model pre-trained on ImageNet:\nhttp://www.image-net.org/papers/imagenet_cvpr09.pdf \n\nBottleneck Features:  1x1024 \n\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n#### 3-Class Output:\ndense layer: 14x3,  {p_0, p_1, p_2} on each label,  without Softmax(",
      "https://arxiv.org/abs/1705.02315, 2017.\n\n\n#### Input:\n224x224 image, convert to RGB, normalized based on the mean and standard deviation of training dataset of ImageNet\n\n\n#### CNN Model:\ndensenet121 https://arxiv.org/abs/1608.06993\ninitialize parameters from the model pre-trained on ImageNet:\nhttp://www.image-net.org/papers/imagenet_cvpr09.pdf \n\nBottleneck Features:  1x1024 \n\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n#### 3-Class Output:\ndense layer: 14x3,  {p_0, p_1, p_2"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9999999981041583
      ],
      "excerpt": "https://arxiv.org/abs/1705.02315  Wang, Xiaosong, Peng, Yifan, Lu, Le, Lu, Zhiyong, Bagheri, Mohammadhadi, and Summers, Ronald M. Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. arXiv preprint arXiv:1705.02315, 2017. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944484218006108
      ],
      "excerpt": "densenet121 https://arxiv.org/abs/1608.06993 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9201869887197545
      ],
      "excerpt": "http://www.image-net.org/papers/imagenet_cvpr09.pdf  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "Decayed Factor: 10 / 2 epoch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156566588472104
      ],
      "excerpt": "| Lung Lesion                   | 0.32      | 0.64      | 0.83      | 0.18      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9904682582335301,
        0.9507374082549614
      ],
      "excerpt": "| Pneumonia                     |           | 0.09      | 0.09      | 0.13      | 0.10      | 0.09      | 0.11      | 0.10          | 0.14          | \n| Pneumothorax                  |           | 0.19      | 0.30      | 0.19      | 0.39      | 0.46      | 0.36      | 0.33          | 0.37          | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yichigo/Chest-X-Ray",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-04T10:05:38Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-02-23T07:43:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8931771366280703,
        0.8574792420589314
      ],
      "excerpt": "U-Zeros model (0: negative, 1: positive, merge uncertain into negative for training): \nU-Ones model (0: negative, 1: positive, merge uncertain into positive for training): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9482304582834107
      ],
      "excerpt": "224x224 image, convert to RGB, normalized based on the mean and standard deviation of training dataset of ImageNet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8930901044020226
      ],
      "excerpt": "Bottleneck Features:  1x1024  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9235174224835886
      ],
      "excerpt": "Batch Size (based on the size of memory) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016,
        0.9394449182630016,
        0.9846351853158721
      ],
      "excerpt": "for 224x224: ~0.6 hour / epoch \nfor 320x320: ~1.3 hour / epoch \nwhile Xception is some kind of slower than Densenet121, and Fractalnet is much slower. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8610917914535873,
        0.9410007103099214,
        0.9839102285997581
      ],
      "excerpt": "We tried to use random crop and random horizontal flip in the data preprocessing, however the performance was worse than do nothing. \nSince random cropping might drop some important part of the images, and views from the front or from the back are actually different. While center cropping, padding zeros, and resizing to square got the similar performances, here we simply resized to square \nTo reproduce the paper, we supposed to use 320x320 resolution in the begining. However, the limitation of computing resource made us decrease the resolution to 224x224 first. We spend most of the time on raising the performance under 224x224. After that, we modified our input to 320x320. One of the reason why we must use 320x320 is because the input size of Xception model must be larger than 299x299 (if we hard code the input size to 224x224 in Xception, then the pretrained model performs bad since it is pre-trained on ImageNet by 299x299 ) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9643236773664147,
        0.9815888096459154
      ],
      "excerpt": "In the valid dataset, there is only 0 or 1 positive case in Lung Lesion, Pleural Other, and Fracture. The uncertain choices we made on these 3 types are based on the models trained on a re-split dataset. The re-split process should split the dateset by patients, not studies \nWe did not tune the Fractalnet too much, since it is very deep and costs a long time for training. But the results we got show that Xception and Densenet1212 perform much better than Fractalnet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9390973377243342
      ],
      "excerpt": "in ./data/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.915024984204633
      ],
      "excerpt": "To check the performance of the trained model, we only need: valid/ and valid.csv \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Chest X-Ray Diagnose",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yichigo/Chest-X-Ray/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Thu, 23 Dec 2021 23:25:13 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yichigo/Chest-X-Ray/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "yichigo/Chest-X-Ray",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9632347459754548,
        0.9770335174395833
      ],
      "excerpt": "conda env create environment.yml \nconda activate chexpert \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8103597713366086
      ],
      "excerpt": "U-Zeros model (0: negative, 1: positive, merge uncertain into negative for training): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8533045700692429
      ],
      "excerpt": "Decayed Factor: 10 / 2 epoch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8361349576714179
      ],
      "excerpt": "| Lung Lesion                   |           | 0.00      | 0.01      | 0.01      | 0.00      | 0.01      | 0.00      | 0.00          | 0.01          | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.894036606553709
      ],
      "excerpt": "./data/ train/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8897107595245954
      ],
      "excerpt": "    train.csv \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.899160403219227
      ],
      "excerpt": "modify the data path in datasplit.py, train.py if you need \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8289669050403863,
        0.9255372870017364,
        0.8632422980364927
      ],
      "excerpt": "empty output/ \nin ./code2class/, run train.py, model will be saved in ../output/ \nif ./output/ is empty, move a model file ?.pth into output/.  Currently, the MyCNN.pth in ./output/ is a 320x320 2 class Xception model. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yichigo/Chest-X-Ray/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Model Details",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Chest-X-Ray",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "yichigo",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yichigo/Chest-X-Ray/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Thu, 23 Dec 2021 23:25:13 GMT"
    },
    "technique": "GitHub API"
  }
}
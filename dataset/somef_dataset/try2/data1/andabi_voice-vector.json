{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.10135"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Nagrani, A., Chung, J. S., & Zisserman, A. (2017, June 27). [VoxCeleb: a large-scale speaker identification dataset](http://arxiv.org/abs/1706.08612v1). arXiv.org.\n* Zhang, C., & Koishida, K. (2017). [End-to-End Text-Independent Speaker Verification with Triplet Loss on Short Utterances](http://www.isca-speech.org/archive/Interspeech_2017/abstracts/1608.html) (pp. 1487\u20131491). Presented at the Interspeech 2017, ISCA: ISCA. http://doi.org/10.21437/Interspeech.2017-1608\n* Li, C., Ma, X., Jiang, B., Li, X., Zhang, X., Liu, X., et al. (2017, May 6). [Deep Speaker: an End-to-End Neural Speaker Embedding System](http://arxiv.org/abs/1705.02304v1). arXiv.org.\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8953453614647129
      ],
      "excerpt": "Authors: Dabi Ahn(andabi412@gmail.com), Noah Jung, Jujin Lee and Kyubyong Park \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9446879745058808
      ],
      "excerpt": "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/andabi/voice-vector/master/materials/title.png\" width=\"60%\"></p> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/andabi/voice-vector",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-02-14T06:55:34Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-09T21:42:27Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8821494049458893
      ],
      "excerpt": "Demo: Check out who your voice is like! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8535839878379928
      ],
      "excerpt": "This project aims to find individual voice vectors using VoxCeleb dataset, which contains 1,251 Hollywood stars' 145,379 utterances. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9685815760613896
      ],
      "excerpt": "Also the closer the vector distance is, the more voices are similar. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9356341283932249,
        0.9743208325455499
      ],
      "excerpt": "The architecture is based on a classification model. \nThe utterance inputted is classified as one of the Hollywood stars. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8282155791344022
      ],
      "excerpt": "The model architecture is structured as follows. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8649146769220373
      ],
      "excerpt": "    * memory cell's last output is projected by the size of embedding vector. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8316093273714164
      ],
      "excerpt": "    * embedding is logits for each classes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865,
        0.8646569777688613
      ],
      "excerpt": "gender dist.: 690 males and 561 females \nage dist.: 136, 351, 318, 210, and 236 for 20s, 30s, 40s, 50s, and over 60s respectively. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9506360751902564
      ],
      "excerpt": "for each speaker, the utterance inputted is randomly selected and cropped so that it does not matter to text. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8441474631809883
      ],
      "excerpt": "hundreds of thousands of English utterances from numerous voice contributors in the world. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.957878286414324
      ],
      "excerpt": "remote mode: utilizing more cores of remote server to load data and enqueue more quickly. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Deep neural networks for getting text-independent speaker embedding written in TensorFlow",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/andabi/voice-vector/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 79,
      "date": "Tue, 28 Dec 2021 18:52:11 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/andabi/voice-vector/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "andabi/voice-vector",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.9436319954197327,
        0.958402584740488
      ],
      "excerpt": "train.py for training.  \nrun python train.py some_case_name \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.81409573871092,
        0.9191732169562344
      ],
      "excerpt": "eval.py for evaluation. \nrun python eval.py some_case_name \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8516058409355712
      ],
      "excerpt": "run python embedding.py some_case_name \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8749822103111317
      ],
      "excerpt": "Text tab: prediction texts with the following form: 'input-speaker-name (meta) -> predicted-speaker-name (meta)' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9038076866404997
      ],
      "excerpt": "t-SNE output file \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/andabi/voice-vector/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License (MIT) Copyright (c) 2018 Dabi Ahn\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of\\nthis software and associated documentation files (the \"Software\"), to deal in\\nthe Software without restriction, including without limitation the rights to\\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\\nof the Software, and to permit persons to whom the Software is furnished to do\\nso, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Text-independent voice vectors",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "voice-vector",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "andabi",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/andabi/voice-vector/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "  * python 2.7\n  * tensorflow >= 1.1\n  * numpy >= 1.11.1\n  * librosa == 0.5.1\n  * tensorpack == 0.8.0\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 291,
      "date": "Tue, 28 Dec 2021 18:52:11 GMT"
    },
    "technique": "GitHub API"
  }
}
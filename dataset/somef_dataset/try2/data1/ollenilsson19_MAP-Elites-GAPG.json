{
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{Mouret2015,\narchivePrefix = {arXiv},\narxivId = {1504.04909},\nauthor = {Mouret, Jean-Baptiste and Clune, Jeff},\neprint = {1504.04909},\nmonth = {apr},\ntitle = {{Illuminating search spaces by mapping elites}},\nurl = {http://arxiv.org/abs/1504.04909},\nyear = {2015}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{VassiliadesCM16,\n  author    = {Vassilis Vassiliades and\n               Konstantinos I. Chatzilygeroudis and\n               Jean{-}Baptiste Mouret},\n  title     = {Scaling Up MAP-Elites Using Centroidal Voronoi Tessellations},\n  journal   = {CoRR},\n  volume    = {abs/1610.05729},\n  year      = {2016},\n  url       = {http://arxiv.org/abs/1610.05729},\n  archivePrefix = {arXiv},\n  eprint    = {1610.05729},\n  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},\n  biburl    = {https://dblp.org/rec/journals/corr/VassiliadesCM16.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{fujimoto2018addressing,\n  title={Addressing Function Approximation Error in Actor-Critic Methods},\n  author={Fujimoto, Scott and Hoof, Herke and Meger, David},\n  booktitle={International Conference on Machine Learning},\n  pages={1582--1591},\n  year={2018}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{nilsson2021_PGA-MAP-Elites,\n  TITLE = {{Policy Gradient Assisted MAP-Elites}},\n  AUTHOR = {Nilsson, Olle and Cully, Antoine},\n  URL = {https://hal.archives-ouvertes.fr/hal-03135723},\n  BOOKTITLE = {{The Genetic and Evolutionary Computation Conference}},\n  ADDRESS = {Lille, France},\n  YEAR = {2021},\n  MONTH = Jul,\n  DOI = {10.1145/3449639.3459304},\n  PDF = {https://hal.archives-ouvertes.fr/hal-03135723v2/file/PGA_MAP_Elites_GECCO.pdf},\n  HAL_ID = {hal-03135723},\n  HAL_VERSION = {v2},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8739914556468947
      ],
      "excerpt": "if [ ! -d ./results ]; then \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ollenilsson19/PGA-MAP-Elites",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-09-29T15:54:28Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-16T13:10:51Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The output of the code will be saved in the location specified by the `--save_path` argument. The output is three main files. The progress file, the actors file, and archive files. The log file is saved under `args.save_path/progress_{file_name}.dat` with `file_name = PGA-MAP-Elites_{args.env}_{args.seed}_{args.dim_map}`. After each batch the progress file will log in each column:\n\n- Nr of Evaluations\n- Coverage \n- Max Fitness\n- Mean Fitness\n- Median Fitness\n- 5th Percentile Fitness\n- 95th Percentile Fitness\n- Averaged Max Fitness (10 Evaluations)\n- Averaged Max Fitness Behaviour Descriptor (10 Evaluations)\n\nThe actors file takes the form `args.save_path/actors_{file_name}.dat` and saves information about each actor added to the main archive.\n\n\n- Nr of Evaluations\n- id\n- Fitness\n- Behaviour Descriptor\n- Associated CVT centroid\n- Parent 1 id\n- Parent 2 id\n- type (evo/gradient)\n- novel (bool)\n- delta fitness (compared to the previous solution in that cell)\n\nEach `--save_period` evaluations the state of the archive is saved under `args.save_path/archive_{file_name}_{nr_of_evaluations}.dat`. The saves info about each actor currently in the archive:\n\n\n- Fitness\n- Assosiated CVT centroid\n- Behaviour Descriptor \n- id\n\nThe PyTorch network models are saved for all actors in the final archive under `args.save_path/models/{file_name}_actor_id`.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8835914403970678,
        0.8389168367733859
      ],
      "excerpt": "This is the code for the PGA-MAP-Elites algorithm as published at the Genetic and Evolutionary Computation Conference (GECCO) in 2021 where it recived a Best Paper award (https://gecco-2021.sigevo.org/Best-Paper-Awards). The paper can be found here. \nPGA-MAP-Elites combines MAP-Elites and Actor-Critic DRL by training a critic network off-policy based on experience collected when evaluating solutions. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9419839535779648
      ],
      "excerpt": "This addresses some limitations of MAP-Elites by: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9747286514422963,
        0.9346921716493064,
        0.9464590287992033
      ],
      "excerpt": "Using an Action-Value function approximation that smooths the target policy and acts as an implicit averaging or smoothing of behaviours, leading to learning behaviours that don\u2019t converge to narrow peaks in the fitness landscape and therefore are less sensitive to noise/stochasticity. \nBased on the TD3 paper and the CVT-MAP-Elites implemetation from here \nEvaluated on four stochastic tasks from QDgym where the task is to discover ways to walk. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8354549392469336
      ],
      "excerpt": "Controller: NN with ~ 20000 parameters.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9708310894153623
      ],
      "excerpt": "QD-Score: The progression of the sum of fitness in the archive. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.871327920209427,
        0.9788230789910671,
        0.8316056751695641
      ],
      "excerpt": "Max Fitness: The progression of the overall highest fitness solution in the archive. \nThe bottom plots show the progression of the max fitness averaged over 10 evaluations. This is used as a statistic for assessing the robustness of the single evaluation used to add solutions to the archive. Only a single evaluation is used to add solutions to the archive in the algorithm. \nEach experiment is repeated 20 times with different random seeds and the solid line displays the median and the shaded area is bounded by the first and third quartiles. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9420305072471669
      ],
      "excerpt": "Cumulative fitness density plots. These represent the likely number of solutions found in a fitness range for a given run of the algorithm. Calculated as the average over 20 seeds: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8809120293208524
      ],
      "excerpt": "If the CVT centroids that are required by the specified configuration do not exist then they will be automatically generated before the algorithm is launched. A range of pre-computed CVTs is available in the CVT folder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Repository for the PGA-MAP-Elites algorithm.  PGA-MAP-Elites was developed to efficiently scale MAP-Elites to large genotypes and noisy domains. It uses Neuroevolution driven by a Genetic Algorithm (GA)  coupled with Policy Gradients (PG) derived from an off-policy Deep Reinforcement Learning method.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ollenilsson19/MAP-Elites-GAPG/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 03:37:00 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ollenilsson19/PGA-MAP-Elites/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ollenilsson19/PGA-MAP-Elites",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "--normalise           |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--neurons_list        |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--mutation_rate       |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--max_genotype        |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--min_genotype        |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--crossover_op        |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--max_evals           |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "    name = f\"config_{i+1 + 0}\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9371634203359391
      ],
      "excerpt": "The different versions of the algorithm used in the paper can run be via the supplied singularity containers. To run these first install singularity (https://github.com/sylabs/singularity/blob/master/INSTALL.md). \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.873660725677503
      ],
      "excerpt": "If any argument is not specified in the config.txt file the default will be used. The default values of all arguments can be found by inspecting the main.py file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8458751354831934
      ],
      "excerpt": "if name == \"main\": \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8168416486596227
      ],
      "excerpt": "ranges_1 = [[\"QDAntBulletEnv-v0\"], range(20), [4], [1296], [1000000], [\"128 128\"]] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8168416486596227
      ],
      "excerpt": "ranges_2 = [[\"QDWalker2DBulletEnv-v0\"], range(20), [2], [1024], [1000000], [\"128 128\"]] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8168416486596227
      ],
      "excerpt": "ranges_3 = [[\"QDHalfCheetahBulletEnv-v0\"], range(20), [2], [1024], [1000000], [\"128 128\"]] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8168416486596227
      ],
      "excerpt": "ranges_4 = [[\"QDHopperBulletEnv-v0\"], range(20), [1], [1000], [1000000], [\"128 128\"]] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "    name = f\"config_{i+1 + 0}\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8253824670592544
      ],
      "excerpt": "will generate config files enumerated from config_1.txt to config_80.txt using QDAnt_config.txt as a base when running: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "python3 generate_configs.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.825084642020709,
        0.918972007965224
      ],
      "excerpt": "cp configure_experiment/config$PBS_ARRAY_INDEX.txt $CURPATH/results/$PATHNAME/ #: Copy config file of experiment to results               \npython3 main.py --save_path $CURPATH/results/$PATHNAME/ \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ollenilsson19/PGA-MAP-Elites/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Olle Nilsson\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Intro",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "PGA-MAP-Elites",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ollenilsson19",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ollenilsson19/PGA-MAP-Elites/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```shell script\ngit clone https://github.com/ollenilsson19/PGA-MAP-Elites.git\ncd PGA-MAP-Elites/\n```\n\nPGA-MAP-Elites requires to install:\n\n+ Python=3.6\n+ torch==1.7.1\n+ numpy==1.19.5\n+ gym==0.15.4\n+ pybullet==3.0.8\n+ Cython==0.29.21\n+ scikit-learn==0.21.3\n+ [QDgym](https://github.com/ollenilsson19/QDgym)\n\nthese can be installed via the requirements file:\n```shell script\npip3 install -r requirements.txt\n```\n\nIf the installation fails, it will likely be due to your pip version being too old for the requirements of opencv (gym dependency). See https://pypi.org/project/opencv-python/. The solution is likely to upgrade pip.\n\n```\npip install --upgrade pip\n```\n\nWith the correct dependencies installed the code can be run by:\n\n```shell script\npython3 main.py\n```\n`main.py` takes a range of arguments which is easiest to pass as a .txt by using the `--config_file` argument:\n\n\n```shell script\npython3 main.py --config_file path/to/config_file/config_file.txt\n```\nA range of config files is included in the `configure_experiment` folder.\n\n- local_config.txt\n- QDHalfCheetah_config.txt\n- QDWalker_config.txt\n- QDAnt_config.txt\n- QDHopper_config.txt\n\n\nThe QDHalfCheetah_config.txt, QDWalker_config.txt, QDAnt_config.txt, QDHopper_config.txt are the configs used to run the experiments that produced the results presented above and in the GECCO paper. Although these configs are unlikely to run on your local computer as they are setup to run on resources available on an HPC system. The local_config.txt is set up to run the code locally for debugging/testing so I recommend you use the below for testing the code locally:\n\n```shell script\npython3 main.py --config_file configure_experiment/local_config.txt\n```\n\nIf you get \"Too many open files\" errors, this has to do with limitations imposed by your os and is not an error related to the code. Depending on your system, this may be solved by:\n\n```shell script\nulimit -n 4000\n```\n\nThe config file passed can be used to pass the following arguments:\n\n\nArgument              |Comment\n----------------------|----------\n--config_file         |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--seed                |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "We recommend using the following setting for the code to run optimally:\n\n```shell script\nKMP_SETTING=\"KMP_AFFINITY=granularity=fine,compact,1,0\"\nKMP_BLOCKTIME=1\n\nexport $KMP_SETTING\nexport KMP_BLOCKTIME=$KMP_BLOCKTIME\nexport OMP_NUM_THREADS=1\nexport MKL_NUM_THREADS=1\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 11,
      "date": "Mon, 27 Dec 2021 03:37:00 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "--crossover_op        |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--min_genotype        |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--eval_batch_size     |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--num_cpu_var         |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--use_cached_cvt      |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--not_discard_dead    |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--normalise           |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--affine              |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--gradient_op         |",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "--lr                  |",
      "technique": "Header extraction"
    }
  ]
}
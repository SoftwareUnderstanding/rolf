{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The [paper](https://www.aclweb.org/anthology/W19-1905.pdf) was accepted to the ClinicalNLP Workshop at NAACL 2019\n\nOren Melamud, and Chaitanya Shivade. __Towards Automatic Generation of Shareable Synthetic Clinical Notes Using Neural Language Models.__ Proceedings of the 2nd Clinical Natural Language Processing Workshop. 2019.\n\n```\n@inproceedings{melamud2019towards,\n  title={Towards Automatic Generation of Shareable Synthetic Clinical Notes Using Neural Language Models},\n  author={Melamud, Oren and Shivade, Chaitanya},\n  booktitle={Proceedings of the 2nd Clinical Natural Language Processing Workshop at NAACL},\n  url={https://www.aclweb.org/anthology/W19-1905.pdf},\n  pages={35--45},\n  year={2019}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{melamud2019towards,\n  title={Towards Automatic Generation of Shareable Synthetic Clinical Notes Using Neural Language Models},\n  author={Melamud, Oren and Shivade, Chaitanya},\n  booktitle={Proceedings of the 2nd Clinical Natural Language Processing Workshop at NAACL},\n  url={https://www.aclweb.org/anthology/W19-1905.pdf},\n  pages={35--45},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9706387173480345
      ],
      "excerpt": "Oren Melamud and Chaitanya Shivade. The Clinical NLP Workshop at NAACL (2019). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8365719028279359
      ],
      "excerpt": "* Obtain MIMIC-III version v1.4 from https://mimic.physionet.org/ (contact MIMIC for authorization) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/orenmel/synth-clinical-notes",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-02T18:11:35Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-14T16:22:58Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9706155880601408
      ],
      "excerpt": "This repository contains the code used in the paper: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8715460000041393
      ],
      "excerpt": "Follow these steps to generate MedText-2 (small) and MedText-103 (large): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9710248914405203
      ],
      "excerpt": "Note that 80 epochs of size 2860000 tokens (including artificial EOS tokens) is equivalent to doing 2 full epochs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8614166958694849
      ],
      "excerpt": "SIZE stands for either 'small' or 'large' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8486565247603135
      ],
      "excerpt": "Generate notes using unigram model:   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8248805257002191
      ],
      "excerpt": "Compute predictions diff per every word in the heldout note and dump it to \"diff_result.debug\" files: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8381765181488307
      ],
      "excerpt": "Aggregate results from the 30 different runs into the \"privacy.debug\" file (we chose the mean-max metric) \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/orenmel/synth-clinical-notes/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sat, 25 Dec 2021 04:47:13 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/orenmel/synth-clinical-notes/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "orenmel/synth-clinical-notes",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/preprocessing/generate_lm_benchmark.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/ExtrinsicEva.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/intrinsicEva.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/create_shf_low_text.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/createModel.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/pre-process.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/keras/data/ner/JNLPBA/tools/combine-and-eval.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/keras/ner/convall.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/keras/ner/batch-ner.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/geniass/run_geniass.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/word2vec/demo-phrase-accuracy.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/word2vec/demo-classes.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/word2vec/demo-word-accuracy.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/word2vec/demo-phrases.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/word2vec/demo-train-big-model-v1.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/word2vec/demo-analogy.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/word2vec/demo-word.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/wvlib/eval-all-ranks.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/wvlib/eval-all-classes.sh",
      "https://raw.githubusercontent.com/orenmel/synth-clinical-notes/master/BioNLP-2016-master/wvlib/tools/convert-senna-embeddings.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can use the environment.yml file to ensure that your environment is compatible with the one used in the paper. Run the following commands: \n\n```\nconda env create -f environment.yml\nsource activate medlm\npython -m spacy download en\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9239258865062174,
        0.9208784407883127
      ],
      "excerpt": "Run the command below to generate the train/valid/test splits. Note that this might take a day to run. \n* cd /PATH-TO-CODE/preprocessing/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8992330417977755
      ],
      "excerpt": "cd /PATH-TO-CODE/BioNLP-2016-master/ \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8241186935521486
      ],
      "excerpt": "Run the command below to generate the train/valid/test splits. Note that this might take a day to run. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8632781019801884
      ],
      "excerpt": "* ./generate_lm_benchmark.sh /PATH-TO-DATA/NOTEEVENTS.csv /PATH-TO-DATA/MED-TEXT-DIR/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8987171268897557,
        0.919831004954583,
        0.9102106165052879
      ],
      "excerpt": "python /PATH-TO-CODE/word_language_model/main.py --epochs 20 --cuda --dropout DROP --emsize 650 --nhid 650 --vocab /PATH-TO-DATA/MED-TEXT-DIR/Discharge_summary.small.all.txt.vocab --lr 20.0 --log-interval 2000 --data /PATH-TO-DATA/MED-TEXT-DIR/small/  --save /PATH-TO-MODELS/MODEL_NAME.pt \npython /PATH-TO-CODE/word_language_model/main.py --epochs 80 --epoch_size 2860000 --cuda --dropout DROP --emsize 650 --nhid 650 --vocab /PATH-TO-DATA/MED-TEXT-DIR/Discharge_summary.large.all.txt.vocab --lr 20.0 --lr_backoff 1.2 --batch_size 20 --log-interval 2000 --data /PATH-TO-DATA/MED-TEXT-DIR/large --save /PATH-TO-MODELS/OUTPUT-MODEL_NAME.pt \n(e.g. OUTPUT-MODEL-NAME.pt = rnn_model.e20.d650.drop0.0.pt) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9273176554454824
      ],
      "excerpt": "python /PATH-TO-CODE/word_language_model/main.py --cuda --data /PATH-TO-DATA/MED-TEXT-DIR/SIZE/ --load /PATH-TO-MODELS/MODEL-NAME.pt --test \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9241593903763331
      ],
      "excerpt": "python /PATH-TO-CODE/experiments/unigram_perplexity.py /PATH-TO-DATA/MED-TEXT-DIR/Discharge_summary.SIZE.TYPE.txt /PATH-TO-DATA/MED-TEXT-DIR/Discharge_summary.SIZE.train.txt.eo.vocab 1.0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9101173751712346
      ],
      "excerpt": "python /PATH-TO-CODE/word_language_model/generate.py --data /PATH-TO-DATA/MED-TEXT-DIR/SIZE/ --checkpoint /PATH-TO-MODELS/MODEL_NAME.pt --outf /PATH-TO-DATA/MED-TEXT-M-DIR/SIZE/SYNTH-NOTES-FILENAME.txt --words NUMBER-OF-WORDS-TO-GENERATE --cuda \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9348804525587757
      ],
      "excerpt": "python /PATH-TO-CODE/experiments/generate_notes_from_unigram.py /PATH-TO-DATA/MED-TEXT-M-DIR/SIZE/SYNTH-NOTES-FILENAME.txt /PATH-TO-DATA/MED-TEXT-DIR/Discharge_summary.SIZE.train.txt.eo.vocab NUMBER-OF-WORDS-TO-GENERATE \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8961566409362959,
        0.869248625815457,
        0.8610428594464282,
        0.9412394329607613
      ],
      "excerpt": "python /PATH-TO-CODE/experiments/clinical_notes_hold_out.py /PATH-TO-DATA/MED-TEXT-DIR/SIZE/ /PATH-TO-DATA/MED-TEXT-DIR/heldout/SIZE/ 30 \nTrain heldout lm models: \ncd /PATH-TO-DATA/MED-TEXT-DIR/heldout/SIZE/ \nls -d heldout.* | python /PATH-TO-CODE/word_language_model/train_script.py \"python /PATH-TO-CODE/word_language_model/main.py --epochs EPOCHS_NUM --epoch_size EPOCH_SIZE --cuda --dropout DROP --emsize 650 --nhid 650 --vocab /PATH-TO-DATA/MED-TEXT-DIR/Discharge_summary.SIZE.all.txt.vocab --lr 20.0 --lr_backoff 1.2 --batch_size 20 --log-interval 2000\" /PATH-TO-DATA/MED-TEXT-DIR/heldout/SIZE/ OUTPUT-MODEL-NAME.pt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9102106165052879
      ],
      "excerpt": "(e.g. OUTPUT-MODEL-NAME.pt = rnn_model.e20.d650.drop0.0.pt) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9061462000041248,
        0.8931827705911175
      ],
      "excerpt": "ls -d /PATH-TO-DATA/MED-TEXT-DIR/heldout/SIZE/* | python /PATH-TO-CODE/word_language_model/experiments/diff_script.py \"python /PATH-TO-CODE/word_language_model/model_predictions_diff.py --cuda --corpus_vocab /PATH-TO-DATA/MED-TEXT-DIR/Discharge_summary.SIZE.all.txt.vocab\"  /PATH-TO-DATA/MED-TEXT-DIR/SIZE/ INPUT-MODEL-NAME.pt \n(INPUT-MODEL-NAME corresponds to previously learned models e.g. MODEL-NAME.pt = rnn_model.e20.d650.drop0.0.pt) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9216002380512988
      ],
      "excerpt": "cat `find /PATH-TO-DATA/MED-TEXT-DIR/heldout/SIZE/ -name \"INPUT-MODEL-NAME.pt.diff_result.debug\"` | grep \"mean diff metric\" | python /PATH-TO-CODE/experiments/max_diff_script.py &gt; /PATH-TO-DATA/MED-TEXT-DIR/heldout/SIZE/INPUT-MODEL-NAME.privacy \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9163747780801083,
        0.9122005861468186
      ],
      "excerpt": "ls -d /PATH-TO-DATA/MED-TEXT-DIR/heldout/SIZE/heldout* | python /PATH-TO-CODE/experiments/diff_script_unigram.py \"python /PATH-TO-CODE/experiments/unigram_diff_privacy.py\" /PATH-TO-DATA/MED-TEXT-DIR/Discharge_summary.SIZE.train.txt.count.vocab \ncat `find /PATH-TO-DATA/MED-TEXT-DIR/heldout/SIZE/ -name \"unigram*diff_result\"` | awk '{ total += $0; count++ } END { print total/count }' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9314507352136435
      ],
      "excerpt": "python ./evaluate.py -w /PATH-TO-DATA/MED-TEXT-DIR/Discharge_summary.large.train.txt.count.vocab  -i  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936116217556167
      ],
      "excerpt": "python ./evaluate.py -w /PATH-TO-DATA/MED-TEXT-DIR/Discharge_summary.small.train.txt.count.vocab  -i  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/orenmel/synth-clinical-notes/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C",
      "C++",
      "Roff",
      "Shell",
      "Perl",
      "Ruby",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Apache License 2.0",
      "url": "https://api.github.com/licenses/apache-2.0"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright (c) 2013, spyysalo\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without modification,\\nare permitted provided that the following conditions are met:\\n\\n Redistributions of source code must retain the above copyright notice, this\\n  list of conditions and the following disclaimer.\\n\\n Redistributions in binary form must reproduce the above copyright notice, this\\n  list of conditions and the following disclaimer in the documentation and/or\\n  other materials provided with the distribution.\\n\\n* Neither the name of the {organization} nor the names of its\\n  contributors may be used to endorse or promote products derived from\\n  this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Synthetic Clinical Notes",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "synth-clinical-notes",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "orenmel",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/orenmel/synth-clinical-notes/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Python 3.6\n* Pytorch 0.3.1\n* Spacy 2.0.7\n* `python -m spacy download en`\n\nIt is recommended to run the neural training code on a GPU-enabled platform.   \nIf running on CPU, remove param --cuda where relevant.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 11,
      "date": "Sat, 25 Dec 2021 04:47:13 GMT"
    },
    "technique": "GitHub API"
  }
}
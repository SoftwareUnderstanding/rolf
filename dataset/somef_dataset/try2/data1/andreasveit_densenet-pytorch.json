{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1608.06993",
      "https://arxiv.org/abs/1603.09382",
      "https://arxiv.org/abs/1605.06431",
      "https://arxiv.org/abs/1512.03385",
      "https://arxiv.org/abs/1608.06993",
      "https://arxiv.org/abs/1608.06993.\n\n[2] Huang, G., Sun, Y., Liu, Z., Sedra, D., & Weinberger, K. Q. (2016). Deep networks with stochastic depth. In European Conference on Computer Vision (ECCV '16)\n\n[3] Veit, A., Wilber, M. J., & Belongie, S. (2016). Residual networks behave like ensembles of relatively shallow networks. In Advances in Neural Information Processing Systems (NIPS '16)\n\n[4] He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Conference on Computer Vision and Pattern Recognition (CVPR '16)"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] Huang, G., Liu, Z., Weinberger, K. Q., & van der Maaten, L. (2016). Densely connected convolutional networks. arXiv preprint arXiv:1608.06993.\n\n[2] Huang, G., Sun, Y., Liu, Z., Sedra, D., & Weinberger, K. Q. (2016). Deep networks with stochastic depth. In European Conference on Computer Vision (ECCV '16)\n\n[3] Veit, A., Wilber, M. J., & Belongie, S. (2016). Residual networks behave like ensembles of relatively shallow networks. In Advances in Neural Information Processing Systems (NIPS '16)\n\n[4] He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Conference on Computer Vision and Pattern Recognition (CVPR '16)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use DenseNets in your work, please cite the original paper as:\n```\n@article{Huang2016Densely,\n  author  = {Huang, Gao and Liu, Zhuang and Weinberger, Kilian Q.},\n  title   = {Densely Connected Convolutional Networks},\n  journal = {arXiv preprint arXiv:1608.06993},\n  year    = {2016}\n}\n```\n\nIf this implementation is useful to you and your project, please also consider to cite or acknowledge this code repository.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{Huang2016Densely,\n  author  = {Huang, Gao and Liu, Zhuang and Weinberger, Kilian Q.},\n  title   = {Densely Connected Convolutional Networks},\n  journal = {arXiv preprint arXiv:1608.06993},\n  year    = {2016}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/andreasveit/densenet-pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-02-17T16:58:13Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T04:44:15Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9891547040588392,
        0.8864106196356734,
        0.923531128385128
      ],
      "excerpt": "This repository contains a PyTorch implementation of the paper Densely Connected Convolutional Networks. The code is based on the excellent PyTorch example for training ResNet on Imagenet. \nThe detault setting for this repo is a DenseNet-BC (with bottleneck layers and channel reduction), 100 layers, a growth rate of 12 and batch size 64.  \nThe Official torch implementaion contains further links to implementations in other frameworks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9591104928252417
      ],
      "excerpt": "DenseNets [1] were introduced in late 2016 after to the discoveries by [2] and [3] that residual networks [4] exhibit extreme parameter redundancy. DenseNets address this shortcoming by reducing the size of the modules and by introducing more connections between layers. In fact, the output of each layer flows directly as input to all subsequent layers of the same feature dimension as illustrated in their Figure 1 (below). This increases the dependency between the layers and thus reduces redundancy. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.869822896412962
      ],
      "excerpt": "The improvements in accuracy per parameter are illustrated in their results on ImageNet (Figure 3).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8524965449271159,
        0.9441144174311767,
        0.9903392906709856,
        0.9699910933084024,
        0.951762661089535
      ],
      "excerpt": "The training code in train.py trains a DenseNet on CIFAR 10 or 100. To train on ImageNet, densenet.py can be copied into the PyTorch example for training ResNets on Imagenet, upon which this repo is based. Note that for ImageNet the model contains four dense blocks. \nThis implementation is quite memory efficient requiring between 10% and 20% less memory compared to the original torch implementation. We optain a final test error of 4.76 % with DenseNet-BC-100-12 (paper reports 4.51 %) and 5.35 % with DenseNet-40-12 (paper reports 5.24 %). \nThis implementation allows for all model variants in the DenseNet paper, i.e., with and without bottleneck, channel reduction, data augmentation and dropout.  \nFor simple configuration of the model, this repo uses argparse so that key hyperparameters can be easily changed. \nFurther, this implementation supports easy checkpointing, keeping track of the best model and resuming training from previous checkpoints. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A PyTorch Implementation for Densely Connected Convolutional Networks (DenseNets)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/andreasveit/densenet-pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 128,
      "date": "Sun, 26 Dec 2021 08:35:35 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/andreasveit/densenet-pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "andreasveit/densenet-pytorch",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.999746712887969
      ],
      "excerpt": "pip install tensorboard_logger \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8119141767769946
      ],
      "excerpt": "Example usage with optional arguments for different hyperparameters (e.g., DenseNet-40-12): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8083403226106063
      ],
      "excerpt": "$ python train.py --layers 40 --growth 12 --no-bottleneck --reduce 1.0 --name DenseNet-40-12 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/andreasveit/densenet-pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\n\\nCopyright (c) 2017, Andreas Veit\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n Redistributions of source code must retain the above copyright notice, this\\n  list of conditions and the following disclaimer.\\n\\n Redistributions in binary form must reproduce the above copyright notice,\\n  this list of conditions and the following disclaimer in the documentation\\n  and/or other materials provided with the distribution.\\n\\n* Neither the name of the copyright holder nor the names of its\\n  contributors may be used to endorse or promote products derived from\\n  this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "A PyTorch Implementation for Densely Connected Convolutional Networks (DenseNets)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "densenet-pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "andreasveit",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/andreasveit/densenet-pytorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* [PyTorch](http://pytorch.org/)\n\noptional:\n* [tensorboard_logger](https://github.com/TeamHG-Memex/tensorboard_logger)\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 377,
      "date": "Sun, 26 Dec 2021 08:35:35 GMT"
    },
    "technique": "GitHub API"
  }
}
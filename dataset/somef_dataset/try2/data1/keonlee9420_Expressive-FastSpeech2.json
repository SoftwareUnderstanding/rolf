{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1803.09017",
      "https://arxiv.org/abs/1812.04342",
      "https://arxiv.org/abs/2103.09474",
      "https://arxiv.org/abs/2006.04558",
      "https://arxiv.org/abs/2005.10438"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [ming024's FastSpeech2](https://github.com/ming024/FastSpeech2) (Later than 2021.02.26 ver.)\n- [HGU-DLLAB's Korean-FastSpeech2-Pytorch](https://github.com/HGU-DLLAB/Korean-FastSpeech2-Pytorch)\n- [hccho2's Tacotron2-Wavenet-Korean-TTS](https://github.com/hccho2/Tacotron2-Wavenet-Korean-TTS)\n- [carpedm20' multi-speaker-tacotron-tensorflow](https://github.com/carpedm20/multi-speaker-tacotron-tensorflow)",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "If you would like to use or refer to this implementation, please cite the repo.\n\n```bash\n@misc{lee2021expressive_fastspeech2,\n  author = {Lee, Keon},\n  title = {Expressive-FastSpeech2},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/keonlee9420/Expressive-FastSpeech2}}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{lee2021expressive_fastspeech2,\n  author = {Lee, Keon},\n  title = {Expressive-FastSpeech2},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/keonlee9420/Expressive-FastSpeech2}}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/keonlee9420/Expressive-FastSpeech2",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-26T08:35:09Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-12T03:09:44Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9791865347213357
      ],
      "excerpt": "Non-autoregressive Expressive TTS: This project aims to provide a cornerstone for future research and application on a non-autoregressive expressive TTS including Emotional TTS and Conversational TTS. For datasets, AIHub Multimodal Video AI datasets and IEMOCAP database are picked for Korean and English, respectively. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9953035574229441,
        0.992013014346068,
        0.9689254656108345,
        0.9556464020344739
      ],
      "excerpt": "Annotated Data Processing: This project shed light on how to handle the new dataset, even with a different language, for the successful training of non-autoregressive emotional TTS. \nEnglish and Korean TTS: In addition to English, this project gives a broad view of treating Korean for the non-autoregressive TTS where the additional data processing must be considered under the language-specific features (e.g., training Montreal Forced Aligner with your own language and dataset). Please closely look into text/.  \nAdopting Own Language: For those who are interested in adapting other languages, please refer to the \"Training with your own dataset (own language)\" section of the categorical branch. \nIn this project, FastSpeech2 is adapted as a base non-autoregressive multi-speaker TTS framework, so it would be helpful to read the paper and code first (Also see FastSpeech2 branch). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9430655966433814
      ],
      "excerpt": "Emotional TTS: Following branches contain implementations of the basic paradigm intorduced by Emotional End-to-End Neural Speech synthesizer. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8144279990500278,
        0.87289503965055,
        0.9822715840297577
      ],
      "excerpt": "categorical branch: only conditioning categorical emotional descriptors (such as happy, sad, etc.) \ncontinuous branch: conditioning continuous emotional descriptors (such as arousal, valence, etc.) in addition to categorical emotional descriptors \nConversational TTS: Following branch contains implementation of Conversational End-to-End TTS for Voice Agent \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "PyTorch Implementation of Non-autoregressive Expressive (emotional, conversational) TTS based on FastSpeech2, supporting English, Korean, and your own languages.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/keonlee9420/Expressive-FastSpeech2/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 20,
      "date": "Sun, 26 Dec 2021 10:36:33 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/keonlee9420/Expressive-FastSpeech2/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "keonlee9420/Expressive-FastSpeech2",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.882394915165871
      ],
      "excerpt": "    <img src=\"img/model.png\" width=\"80%\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8673805446708356
      ],
      "excerpt": "    <img src=\"img/model_emotional_tts.png\" width=\"80%\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8673805446708356
      ],
      "excerpt": "    <img src=\"img/model_conversational_tts.png\" width=\"80%\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/keonlee9420/Expressive-FastSpeech2/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/keonlee9420/Expressive-FastSpeech2/main/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Jungil Kong\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Expressive-FastSpeech2 - PyTorch Implementation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Expressive-FastSpeech2",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "keonlee9420",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/keonlee9420/Expressive-FastSpeech2/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "keonlee9420",
        "body": "",
        "dateCreated": "2021-05-14T08:50:29Z",
        "datePublished": "2021-05-15T13:31:32Z",
        "html_url": "https://github.com/keonlee9420/Expressive-FastSpeech2/releases/tag/v0.1.0",
        "name": "First Release",
        "tag_name": "v0.1.0",
        "tarball_url": "https://api.github.com/repos/keonlee9420/Expressive-FastSpeech2/tarball/v0.1.0",
        "url": "https://api.github.com/repos/keonlee9420/Expressive-FastSpeech2/releases/42996868",
        "zipball_url": "https://api.github.com/repos/keonlee9420/Expressive-FastSpeech2/zipball/v0.1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 64,
      "date": "Sun, 26 Dec 2021 10:36:33 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "text-to-speech",
      "tts",
      "speech-synthesis",
      "non-autoregressive",
      "emotional-tts",
      "emotional-speech-synthesis",
      "expressive-tts",
      "expressive-speech-synthesis",
      "korean-speech-synthesis",
      "korean-tts",
      "conversational-tts",
      "conversational-speech-synthesis"
    ],
    "technique": "GitHub API"
  }
}
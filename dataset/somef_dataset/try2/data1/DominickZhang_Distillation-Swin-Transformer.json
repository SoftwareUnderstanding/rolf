{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2106.13230",
      "https://arxiv.org/abs/2103.14030",
      "https://arxiv.org/abs/2105.03404",
      "https://arxiv.org/abs/2105.03404",
      "https://arxiv.org/abs/2103.14030"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@article{liu2021Swin,\n  title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},\n  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},\n  journal={arXiv preprint arXiv:2103.14030},\n  year={2021}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{liu2021Swin,\n  title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},\n  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},\n  journal={arXiv preprint arXiv:2103.14030},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9999988430092245
      ],
      "excerpt": "By Ze Liu*, Yutong Lin*, Yue Cao*, Han Hu*, Yixuan Wei, Zheng Zhang, Stephen Lin and Baining Guo. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9805538058415082
      ],
      "excerpt": "Object Detection and Instance Segmentation: See Swin Transformer for Object Detection. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9991245600483735,
        0.8715509475085587
      ],
      "excerpt": "Video Action Recognition: See Video Swin Transformer. \nSemi-Supervised Object Detection: See Soft Teacher. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9210623956343095,
        0.9506781818271818
      ],
      "excerpt": "1. Video Swin Transformer is released at Video-Swin-Transformer. \nVideo Swin Transformer achieves state-of-the-art accuracy on a broad range of video recognition benchmarks, including action recognition (84.9 top-1 accuracy on Kinetics-400 and 86.1 top-1 accuracy on Kinetics-600 with ~20x less pre-training data and ~3x smaller model size) and temporal modeling (69.6 top-1 accuracy on Something-Something v2). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8191321963994659,
        0.8191321963994659
      ],
      "excerpt": "| Swin-B | ImageNet-22K | 224x224 | 85.2 | 97.5 | 88M | 15.4G | 278 | github/baidu | github/baidu/test-config | \n| Swin-B | ImageNet-22K | 384x384 | 86.4 | 98.0 | 88M | 47.1G | 85 | github/baidu | github/baidu/test-config | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8191321963994659
      ],
      "excerpt": "| Swin-L | ImageNet-22K | 384x384 | 87.3 | 98.2 | 197M | 103.9G | 42 | github/baidu | github/baidu/test-config | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9593768481638728
      ],
      "excerpt": "| SwinMLP-B | ImageNet-1K | 224x224 | 81.3 | 95.3 | 61M | 10.4G | 409 | github/baidu/config | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9836373349407552
      ],
      "excerpt": "COCO Object Detection (2017 val) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DominickZhang/Distillation-Swin-Transformer",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-07T11:40:33Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-27T07:39:03Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "**Swin Transformer** (the name `Swin` stands for **S**hifted **win**dow) is initially described in [arxiv](https://arxiv.org/abs/2103.14030), which capably serves as a\ngeneral-purpose backbone for computer vision. It is basically a hierarchical Transformer whose representation is\ncomputed with shifted windows. The shifted windowing scheme brings greater efficiency by limiting self-attention\ncomputation to non-overlapping local windows while also allowing for cross-window connection.\n\nSwin Transformer achieves strong performance on COCO object detection (`58.7 box AP` and `51.1 mask AP` on test-dev) and\nADE20K semantic segmentation (`53.5 mIoU` on val), surpassing previous models by a large margin.\n\n![teaser](figures/teaser.png)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9751352246707092
      ],
      "excerpt": "This repo is the official implementation of \"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\". It currently includes code and models for the following tasks: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9949899336796264
      ],
      "excerpt": "1. Add Swin MLP, which is an adaption of Swin Transformer by replacing all multi-head self-attention (MHSA) blocks by MLP layers (more precisely it is a group linear layer). The shifted window configuration can also significantly improve the performance of vanilla MLP architectures.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9318533616559062
      ],
      "excerpt": "Video Swin Transformer achieves state-of-the-art accuracy on a broad range of video recognition benchmarks, including action recognition (84.9 top-1 accuracy on Kinetics-400 and 86.1 top-1 accuracy on Kinetics-600 with ~20x less pre-training data and ~3x smaller model size) and temporal modeling (69.6 top-1 accuracy on Something-Something v2). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8204523772550929,
        0.9749096958831
      ],
      "excerpt": "1. Used as a backbone for Self-Supervised Learning: Transformer-SSL \nUsing Swin-Transformer as the backbone for self-supervised learning enables us to evaluate the transferring performance of the learnt representations on down-stream tasks, which is missing in previous works due to the use of ViT/DeiT, which has not been well tamed for down-stream tasks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8691783522107942
      ],
      "excerpt": "The cuda kernel implementation for the local relation layer is provided in branch LR-Net. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8520102959534915,
        0.8520102959534915,
        0.890581112160451,
        0.8520102959534915,
        0.8520102959534915
      ],
      "excerpt": "| Swin-T | Mask R-CNN | ImageNet-1K | 3x | 46.0 | 41.6 | 48M | 267G | \n| Swin-S | Mask R-CNN | ImageNet-1K | 3x | 48.5 | 43.3 | 69M | 359G | \n| Swin-T | Cascade Mask R-CNN | ImageNet-1K | 3x | 50.4 | 43.7 | 86M | 745G | \n| Swin-S | Cascade Mask R-CNN | ImageNet-1K |  3x | 51.9 | 45.0 | 107M | 838G | \n| Swin-B | Cascade Mask R-CNN | ImageNet-1K |  3x | 51.9 | 45.0 | 145M | 982G | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8086333707823806
      ],
      "excerpt": "| Backbone | Method | pretrain | Crop Size | Lr Schd | mIoU | mIoU (ms+flip) | #params | FLOPs | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8199837720617734
      ],
      "excerpt": "a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8073737513954784,
        0.9783267603835809
      ],
      "excerpt": "This project has adopted the Microsoft Open Source Code of Conduct. \nFor more information see the Code of Conduct FAQ or \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8411378894176985,
        0.9214339495776546
      ],
      "excerpt": "This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft  \ntrademarks or logos is subject to and must follow  \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DominickZhang/Distillation-Swin-Transformer/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 13:29:58 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/DominickZhang/Distillation-Swin-Transformer/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "DominickZhang/Distillation-Swin-Transformer",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/apex/examples/docker/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/DominickZhang/Distillation-Swin-Transformer/tree/main/apex/docs"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/run_intermediate_distill_32G.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/run_command_collections.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/run_relation_dist.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/run_joint_distill.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/run_intermediate_distill.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/sync_codes.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/apex/tests/docker_extension_builds/run.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/apex/tests/L1/common/run_test.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/apex/tests/L1/cross_product/run.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/apex/tests/L1/cross_product_distributed/run.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/apex/tests/distributed/synced_batchnorm/unit_test.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/apex/tests/distributed/DDP/run_race_test.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/apex/tests/distributed/amp_master_params/run.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/apex/examples/simple/distributed/run.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/apex/apex/pyprof/examples/jit/test.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/apex/apex/pyprof/examples/imagenet/test.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/apex/apex/pyprof/examples/user_annotation/test.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/apex/apex/pyprof/examples/apex/test.sh",
      "https://raw.githubusercontent.com/DominickZhang/Distillation-Swin-Transformer/main/apex/apex/pyprof/examples/custom_func_module/test.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8003352366805131
      ],
      "excerpt": "a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8317381494643538
      ],
      "excerpt": "| name | pretrain | resolution |acc@1 | acc@5 | #params | FLOPs | FPS| 22K model | 1K model | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8156961074856751,
        0.8212129646907822
      ],
      "excerpt": "ImageNet-1K Pretrained Swin MLP Models \n| name | pretrain | resolution |acc@1 | acc@5 | #params | FLOPs | FPS |  1K model | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8091546380572749,
        0.8091546380572749
      ],
      "excerpt": "| Swin-S | Cascade Mask R-CNN | ImageNet-1K |  3x | 51.9 | 45.0 | 107M | 838G | \n| Swin-B | Cascade Mask R-CNN | ImageNet-1K |  3x | 51.9 | 45.0 | 145M | 982G | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8412130156637656
      ],
      "excerpt": "| Swin-T | UPerNet | ImageNet-1K | 512x512 | 160K | 44.51 | 45.81 | 60M | 945G | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/DominickZhang/Distillation-Swin-Transformer/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C++",
      "Cuda",
      "Shell",
      "C",
      "CSS",
      "HTML",
      "Makefile",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'All rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\\n\\n3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Swin Transformer",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Distillation-Swin-Transformer",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "DominickZhang",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DominickZhang/Distillation-Swin-Transformer/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 13:29:58 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- For **Image Classification**, please see [get_started.md](get_started.md) for detailed instructions.\n- For **Object Detection and Instance Segmentation**, please see [Swin Transformer for Object Detection](https://github.com/SwinTransformer/Swin-Transformer-Object-Detection).\n- For **Semantic Segmentation**, please see [Swin Transformer for Semantic Segmentation](https://github.com/SwinTransformer/Swin-Transformer-Semantic-Segmentation).\n- For **Self-Supervised Learning**, please see [Transformer-SSL](https://github.com/SwinTransformer/Transformer-SSL).\n- For **Video Recognition**, please see [Video Swin Transformer](https://github.com/SwinTransformer/Video-Swin-Transformer).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "***In this pargraph, we cross link third-party repositories which use Swin and report results. You can let us know by raising an issue*** \n\n(`Note please report accuracy numbers and provide trained models in your new repository to facilitate others to get sense of correctness and model behavior`)\n\n[08/29/2021] Swin Transformer for Image Restoration: [SwinIR](https://github.com/JingyunLiang/SwinIR)\n\n[08/12/2021] Swin Transformer for person reID: [https://github.com/layumi/Person_reID_baseline_pytorch](https://github.com/layumi/Person_reID_baseline_pytorch)\n\n[06/29/2021] Swin-Transformer in PaddleClas and inference based on whl package: [https://github.com/PaddlePaddle/PaddleClas](https://github.com/PaddlePaddle/PaddleClas)\n\n[04/14/2021] Swin for RetinaNet in Detectron: https://github.com/xiaohu2015/SwinT_detectron2.\n\n[04/16/2021] Included in a famous model zoo: https://github.com/rwightman/pytorch-image-models.\n\n[04/20/2021] Swin-Transformer classifier inference using TorchServe: https://github.com/kamalkraj/Swin-Transformer-Serve\n\n",
      "technique": "Header extraction"
    }
  ]
}
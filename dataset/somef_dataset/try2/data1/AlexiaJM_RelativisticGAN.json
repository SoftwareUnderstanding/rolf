{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1807.00734",
      "https://arxiv.org/abs/1807.00734",
      "https://arxiv.org/abs/1901.02474"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this code useful please cite us in your work.\n\nPaper introducing Relativistic GANs (https://github.com/AlexiaJM/RelativisticGAN):\n```\n@article{jolicoeur2018relativistic,\n  title={The relativistic discriminator: a key element missing from standard GAN},\n  author={Jolicoeur-Martineau, Alexia},\n  journal={arXiv preprint arXiv:1807.00734},\n  year={2018}\n}\n```\nPaper providing the mathematical foundations for Relativistic GANs (https://github.com/AlexiaJM/relativistic-f-divergences)\n```\n@article{jolicoeur2018rfdiv,\n  title={On Relativistic f-Divergences},\n  author={Jolicoeur-Martineau, Alexia},\n  journal={arXiv preprint arXiv:1901.02474},\n  year={2019}\n}\n```\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{jolicoeur2018rfdiv,\n  title={On Relativistic f-Divergences},\n  author={Jolicoeur-Martineau, Alexia},\n  journal={arXiv preprint arXiv:1901.02474},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{jolicoeur2018relativistic,\n  title={The relativistic discriminator: a key element missing from standard GAN},\n  author={Jolicoeur-Martineau, Alexia},\n  journal={arXiv preprint arXiv:1807.00734},\n  year={2018}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9870273950387941
      ],
      "excerpt": "Now accepted at ICLR 2019: https://openreview.net/forum?id=S1erHoR5t7&noteId=S1erHoR5t7 \ud83d\ude38 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8357664768244879
      ],
      "excerpt": "Discussion at https://ajolicoeur.wordpress.com/RelativisticGAN. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AlexiaJM/RelativisticGAN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-07-03T10:19:16Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-15T06:29:37Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8128215010195804
      ],
      "excerpt": "Code to replicate all analyses from the paper The relativistic discriminator: a key element missing from standard GAN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633644850036301
      ],
      "excerpt": "Note: Newer version of pretty much the same code, with extra features is on here: https://github.com/AlexiaJM/relativistic-f-divergences \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "* To Replicate \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9869893821327808,
        0.9567588029116127,
        0.9567588029116127
      ],
      "excerpt": "Although I always used the same seed (seed = 1), keep in mind that your results may be sightly different. Neural networks are notoriously difficult to perfectly replicate. CUDNN introduce some randomness and slight changes in the code have been made over time. Tensorflow FIDs values may vary a little, but they should still be very stable since the sample size used for the calculations is large. Also, the original code to construct RaSGAN and RaLSGAN used \"torch.mean(y_pred_fake) - y_pred\" instead of \"y_pred_fake - torch.mean(y_pred)\" in the second terms of the equation with the expectation over fake data; results are comparable. \n64x64 cats with RaLSGAN (FID = 11.97) \n128x128 cats with RaLSGAN (FID = 15.85) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127,
        0.9567588029116127,
        0.9567588029116127
      ],
      "excerpt": "256x256 cats with RaSGAN (FID = 32.11) \n256x256 cats with RaLSGAN (FID = 35.21) \n256x256 cats with SpectralSGAN (FID = 54.73) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code for replication of the paper \"The relativistic discriminator: a key element missing from standard GAN\"",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AlexiaJM/RelativisticGAN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 105,
      "date": "Tue, 28 Dec 2021 03:44:03 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/AlexiaJM/RelativisticGAN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "AlexiaJM/RelativisticGAN",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/AlexiaJM/RelativisticGAN/master/code/setting_up_script.sh",
      "https://raw.githubusercontent.com/AlexiaJM/RelativisticGAN/master/code/unstable.sh",
      "https://raw.githubusercontent.com/AlexiaJM/RelativisticGAN/master/code/stable.sh",
      "https://raw.githubusercontent.com/AlexiaJM/RelativisticGAN/master/code/fid_script.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8519939412804439
      ],
      "excerpt": "Note: Newer version of pretty much the same code, with extra features is on here: https://github.com/AlexiaJM/relativistic-f-divergences \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365,
        0.9664992112464309,
        0.9562541131018253
      ],
      "excerpt": "Python 3.6 \nPytorch (Latest from source) \nTensorflow (Latest from source, needed to get FID) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8928290112741657
      ],
      "excerpt": "Run setting_up_script.sh in same folder as preprocess_cat_dataset.py and your CAT dataset (open and run manually) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8126010326570124
      ],
      "excerpt": "* To run models \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/AlexiaJM/RelativisticGAN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Relativistic GAN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "RelativisticGAN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "AlexiaJM",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AlexiaJM/RelativisticGAN/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 678,
      "date": "Tue, 28 Dec 2021 03:44:03 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\n#:#:#: Assuming this gets you real and fake data\n\n#: Real data\nx.data.resize_as_(images).copy_(images)\ny_pred = D(x)\ny.data.resize_(current_batch_size).fill_(1)\n\n#: Fake data\nz.data.resize_(current_batch_size, param.z_size, 1, 1).normal_(0, 1)\nfake = G(z)\nx_fake.data.resize_(fake.data.size()).copy_(fake.data)\ny_pred_fake = D(x_fake.detach()) #: For generator step do not detach\ny2.data.resize_(current_batch_size).fill_(0)\n\n\n#:#:#: Standard GAN (non-saturating)\n\n#: Use torch.nn.Sigmoid() as last layer in discriminator\n\ncriterion = torch.nn.BCELoss()\n\n#: Real data Discriminator loss\nerrD_real = criterion(y_pred, y)\nerrD_real.backward()\n\n#: Fake data Discriminator loss\nerrD_fake = criterion(y_pred_fake, y2)\nerrD_fake.backward()\n\n#: Generator loss\nerrG = criterion(y_pred_fake, y)\nerrG.backward()\n\n\n#:#:#: Relativistic Standard GAN\n\n#: No sigmoid activation in last layer of discriminator because BCEWithLogitsLoss() already adds it\n\nBCE_stable = torch.nn.BCEWithLogitsLoss()\n\n#: Discriminator loss\nerrD = BCE_stable(y_pred - y_pred_fake, y)\nerrD.backward()\n\n#: Generator loss (You may want to resample again from real and fake data)\nerrG = BCE_stable(y_pred_fake - y_pred, y)\nerrG.backward()\n\n\n#:#:#: Relativistic average Standard GAN\n\n#: No sigmoid activation in last layer of discriminator because BCEWithLogitsLoss() already adds it\n\nBCE_stable = torch.nn.BCEWithLogitsLoss()\n\n#: Discriminator loss\nerrD = ((BCE_stable(y_pred - torch.mean(y_pred_fake), y) + BCE_stable(y_pred_fake - torch.mean(y_pred), y2))/2\nerrD.backward()\n\n#: Generator loss (You may want to resample again from real and fake data)\nerrG = ((BCE_stable(y_pred - torch.mean(y_pred_fake), y2) + BCE_stable(y_pred_fake - torch.mean(y_pred), y))/2\nerrG.backward()\n\n\n#:#:#: Relativistic average LSGAN\n\n#: No activation in discriminator\n\n#: Discriminator loss\nerrD = (torch.mean((y_pred - torch.mean(y_pred_fake) - y) ** 2) + torch.mean((y_pred_fake - torch.mean(y_pred) + y) ** 2))/2\nerrD.backward()\n\n#: Generator loss (You may want to resample again from real and fake data)\nerrG = (torch.mean((y_pred - torch.mean(y_pred_fake) + y) ** 2) + torch.mean((y_pred_fake - torch.mean(y_pred) - y) ** 2))/2\nerrG.backward()\n\n\n#:#:#: Relativistic average HingeGAN\n\n#: No activation in discriminator\n\n#: Discriminator loss\nerrD = (torch.mean(torch.nn.ReLU()(1.0 - (y_pred - torch.mean(y_pred_fake)))) + torch.mean(torch.nn.ReLU()(1.0 + (y_pred_fake - torch.mean(y_pred)))))/2\nerrD.backward()\n \n#: Generator loss  (You may want to resample again from real and fake data)\nerrG = (torch.mean(torch.nn.ReLU()(1.0 + (y_pred - torch.mean(y_pred_fake)))) + torch.mean(torch.nn.ReLU()(1.0 - (y_pred_fake - torch.mean(y_pred)))))/2\nerrG.backward()\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
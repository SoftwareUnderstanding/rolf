{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MatteoBrentegani/PPO",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-04-13T12:57:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-05T22:06:22Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The project implement the clipped version of Proximal Policy Optimization Algorithms described here https://arxiv.org/pdf/1707.06347.pdf\n\nInto the config.yaml file are defined some of the hyper parameter used into the various implementation. Those parameters are initilized with the values proposed in the article.\n\n\nHere the key point:\n* Loss function parameters:\n  * epsilon = 0.2\n  * gamma = 0.99\n  * entropy loss = 1e-3\n  \n* Network size:\n  * state_size = 27 (25 laser scan + target heading + target distance)\n  * action_size (angular velocity) = 5\n  * action_size2 (linear velocity) = 3\n  * batch_size = 64\n  * output layer = 8 into 2 streams (5 nodes for angular and 3 for linear velocity)\n  * lossWeights for the output layer: \n    * 0,5\n    * 0.5\n    \nThe values for the loss weights are the result of some test. With an equal weight the success rate is lower. \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9822211359435128,
        0.8345218333810733
      ],
      "excerpt": "This is an implementation of the PPO algorithm. The agent to move in the environment uses both angular and linear speed. \nThis feature is also used in the Multi-agent version. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MatteoBrentegani/PPO/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 18:41:50 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/MatteoBrentegani/PPO/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "MatteoBrentegani/PPO",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8401213851383328
      ],
      "excerpt": "activate tensorflow \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8610380712239168
      ],
      "excerpt": "For start the training run the main.py file into anaconda environment: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8410994372961152
      ],
      "excerpt": "python main.c \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/MatteoBrentegani/PPO/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "ASP",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Proximal Policy Optimization - with Keras",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "PPO",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "MatteoBrentegani",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MatteoBrentegani/PPO/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": " * Python 3\n * Tensorflow\n * NumPy, matplotlib, scipy\n * [Keras](https://keras.io/)\n * [Unity](https://unity3d.com/get-unity/download)\n\n```\n#: create conda environment named \"tensorflow\"\nconda create -n tensorflow pip python=3.6\n\n#: activate conda environment\nactivate tensorflow\n\n#: Tensorflow\npip install tensorflow\n\n#: Keras\npip install keras\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 18:41:50 GMT"
    },
    "technique": "GitHub API"
  }
}
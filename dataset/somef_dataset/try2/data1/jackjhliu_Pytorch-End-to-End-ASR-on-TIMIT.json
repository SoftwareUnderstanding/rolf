{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] W. Chan _et al._, \"Listen, Attend and Spell\",\nhttps://arxiv.org/pdf/1508.01211.pdf\n\n[2] J. Chorowski _et al._, \"Attention-Based Models for Speech Recognition\",\nhttps://arxiv.org/pdf/1506.07503.pdf\n\n[3] M. Luong _et al._, \"Effective Approaches to Attention-based Neural Machine Translation\",\nhttps://arxiv.org/pdf/1508.04025.pdf\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/biyoml/PyTorch-End-to-End-ASR-on-TIMIT",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-17T03:24:32Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-10T01:25:12Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8111255935756151,
        0.9621247163317062,
        0.8461193414644087
      ],
      "excerpt": "BiGRU encoder + Attention decoder, based on \"Listen, Attend and Spell\"<sup>1</sup>. \nThe acoustic features are 80-dimensional filter banks. They are stacked every 3 consecutive frames, so the time resolution is reduced. \nFollowing the standard recipe, we use 462-speaker training set with all SA records removed. Outputs are mapped to 39 phonemes when evalauting. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Attention-based end-to-end ASR on TIMIT in PyTorch",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jackjhliu/Pytorch-End-to-End-ASR-on-TIMIT/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Tue, 21 Dec 2021 16:13:32 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/biyoml/PyTorch-End-to-End-ASR-on-TIMIT/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "biyoml/PyTorch-End-to-End-ASR-on-TIMIT",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This will create lists (*.csv) of audio file paths along with their transcripts:\n```bash\n$ python prepare_data.py --root ${DIRECTORY_OF_TIMIT}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\n$ pip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9503189345333785
      ],
      "excerpt": "$ python train.py -h \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9383004500983586
      ],
      "excerpt": "$ python train.py exp/default.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503189345333785
      ],
      "excerpt": "$ python train.py ${PATH_TO_YOUR_CONFIG} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8157944488586287,
        0.8490728136895299
      ],
      "excerpt": "The checkpoint with the lowest error rate will be saved in the logging directory (by default exp/default/best.pth). \nTo evalutate the checkpoint on test set, run: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8901532013527039
      ],
      "excerpt": "$ python eval.py exp/default/best.pth \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8402526537601729
      ],
      "excerpt": "$ python inference.py exp/default/best.pth \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/biyoml/PyTorch-End-to-End-ASR-on-TIMIT/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Pytorch-End-to-End-ASR-on-TIMIT",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "PyTorch-End-to-End-ASR-on-TIMIT",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "biyoml",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/biyoml/PyTorch-End-to-End-ASR-on-TIMIT/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\n$ pip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Tue, 21 Dec 2021 16:13:32 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "end-to-end",
      "asr",
      "timit",
      "pytorch",
      "attention-seq2seq"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "With the default configuration, the training logs are stored in `exp/default/history.csv`.\nSpecify your training logs accordingly.\n```bash\n$ python show_history.py exp/default/history.csv\n```\n![](./img/Figure_1.png)\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2005.03295",
      "https://arxiv.org/abs/2009.04323",
      "https://arxiv.org/abs/1810.04826"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9572487334023723
      ],
      "excerpt": "| after VoiceFilter      | 12.6  | 10.2 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837129573709209
      ],
      "excerpt": "VoiceFilter utilizes speaker recognition system (d-vector embeddings). \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mindslab-ai/voicefilter",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-22T07:37:59Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-25T02:00:11Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9794621146010439,
        0.9273048970920478,
        0.9489924069911636
      ],
      "excerpt": "and I didn't expect this repository to grab such a great amount of attention for a long time. \nI would like to thank everyone for giving such attention, and also Mr. Quan Wang (the first author of the VoiceFilter paper) for referring this project in his paper. \nActually, this project was done by me when it was only 3 months after I started studying deep learning & speech separation without a supervisor in the relevant field. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9286793552566106
      ],
      "excerpt": "Now that I've spent more time on deep learning & speech since then (I also wrote a paper published at Interspeech 2020 \ud83d\ude0a), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8433845933334295,
        0.8919563883026465
      ],
      "excerpt": "Those issues were kindly raised by GitHub users; please refer to the \nIssues and Pull Requests for that. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8320738461129493,
        0.873394580852955,
        0.9083200617101097,
        0.9796149429427421,
        0.900898018465766,
        0.9311298520878682,
        0.9301411136434481
      ],
      "excerpt": "and I would like to remind everyone to use this code at their own risk (as specified in LICENSE). \nUnfortunately, I can't afford extra time on revising this project or reviewing the Issues / Pull Requests. \nInstead, I would like to offer some pointers to newer, more reliable resources: \nThis is a newer version of VoiceFilter presented at Interspeech 2020, which is also written by Mr. Quan Wang (and his colleagues at Google). \nI highly recommend checking this paper, since it focused on a more realistic situation where VoiceFilter is needed. \nList of VoiceFilter implementation available on GitHub: \nIn March 2019, this repository was the only available open-source implementation of VoiceFilter. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8747940307996581,
        0.9412211299689959,
        0.9610165585514522
      ],
      "excerpt": "Back in 2019, I could not find a great deep-learning project template for myself, \nso I and my colleagues had used this project as a template for other new projects. \nFor people who are searching for such project template, I would like to strongly recommend PyTorch Lightning. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8061760269507503,
        0.8948858268832939
      ],
      "excerpt": "I found PyTorch Lightning much better than my own template. \nThanks for reading, and I wish everyone good health during the global pandemic situation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9552344807012123
      ],
      "excerpt": "Unofficial PyTorch implementation of Google AI's: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8710586445186391
      ],
      "excerpt": "Here, we provide pretrained model for obtaining d-vector embeddings. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8207503123523057,
        0.8333620906213259
      ],
      "excerpt": "where utterances are randomly fit to time length [70, 90] frames. \nTests are done with window 80 / hop 40 and have shown equal error rate about 1%. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8194492390658668
      ],
      "excerpt": "Try power-law compressed reconstruction error as loss function, instead of MSE. (See #14) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Unofficial PyTorch implementation of Google AI's VoiceFilter system",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mindslab-ai/voicefilter/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 185,
      "date": "Sat, 25 Dec 2021 22:02:14 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mindslab-ai/voicefilter/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "mindslab-ai/voicefilter",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/mindslab-ai/voicefilter/master/utils/normalize-resample.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Download LibriSpeech dataset\n\n    To replicate VoiceFilter paper, get LibriSpeech dataset at http://www.openslr.org/12/.\n    `train-clear-100.tar.gz`(6.3G) contains speech of 252 speakers, and `train-clear-360.tar.gz`(23G) contains 922 speakers.\n    You may use either, but the more speakers you have in dataset, the more better VoiceFilter will be.\n\n1. Resample & Normalize wav files\n\n    First, unzip `tar.gz` file to desired folder:\n    ```bash\n    tar -xvzf train-clear-360.tar.gz\n    ```\n\n    Next, copy `utils/normalize-resample.sh` to root directory of unzipped data folder. Then:\n    ```bash\n    vim normalize-resample.sh #: set \"N\" as your CPU core number.\n    chmod a+x normalize-resample.sh\n    ./normalize-resample.sh #: this may take long\n    ```\n\n1. Edit `config.yaml`\n\n    ```bash\n    cd config\n    cp default.yaml config.yaml\n    vim config.yaml\n    ```\n\n1. Preprocess wav files\n\n    In order to boost training speed, perform STFT for each files before training by:\n    ```bash\n    python generator.py -c [config yaml] -d [data directory] -o [output directory] -p [processes to run]\n    ```\n    This will create 100,000(train) + 1000(test) data. (About 160G)\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9322609392449874
      ],
      "excerpt": "PyTorch Lightning: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8610958605835308
      ],
      "excerpt": "Data used for test were selected from first 8 speakers of VoxCeleb1 test dataset, where 10 utterances per each speakers are randomly selected. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9302779952906605,
        0.8444229056784623
      ],
      "excerpt": "python trainer.py -c [config yaml] -e [path of embedder pt file] -m [name] \nThis will create chkpt/name and logs/name at base directory(-b option, . in default) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9158549549636356
      ],
      "excerpt": "python trainer.py -c [config yaml] --checkpoint_path [chkpt/name/chkpt_{step}.pt] -e [path of embedder pt file] -m name \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8794959923786672
      ],
      "excerpt": "python inference.py -c [config yaml] -e [path of embedder pt file] --checkpoint_path [path of chkpt pt file] -m [path of mixed wav file] -r [path of reference wav file] -o [output directory] \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mindslab-ai/voicefilter/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "VoiceFilter",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "voicefilter",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "mindslab-ai",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mindslab-ai/voicefilter/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Python and packages\n\n    This code was tested on Python 3.6 with PyTorch 1.0.1.\n    Other packages can be installed by:\n\n    ```bash\n    pip install -r requirements.txt\n    ```\n\n1. Miscellaneous \n\n    [ffmpeg-normalize](https://github.com/slhck/ffmpeg-normalize) is used for resampling and normalizing wav files.\n    See README.md of [ffmpeg-normalize](https://github.com/slhck/ffmpeg-normalize/blob/master/README.md) for installation.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 780,
      "date": "Sat, 25 Dec 2021 22:02:14 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "source-separation",
      "audio-separation",
      "speech-separation",
      "pytorch",
      "voicefilter"
    ],
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556",
      "https://arxiv.org/abs/1409.1556"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "VGGNet\u5728\u8bad\u7ec3\u65f6\u6709\u4e00\u4e2a\u5c0f\u6280\u5de7\uff0c\u5148\u8bad\u7ec3\u7ea7\u522bA\u7684\u7b80\u5355\u7f51\u7edc\uff0c\u518d\u590d\u7528A\u7f51\u7edc\u7684\u6743\u91cd\u6765\u521d\u59cb\u5316\u540e\u9762\u7684\u51e0\u4e2a\u590d\u6742\u6a21\u578b\uff0c\u8fd9\u6837\u8bad\u7ec3\u6536\u655b\u7684\u901f\u5ea6\u66f4\u5feb\u3002\u5728\u9884\u6d4b\u65f6\uff0cVGG\u91c7\u7528Multi-Scale\u7684\u65b9\u6cd5\uff0c\u5c06\u56fe\u50cfscale\u5230\u4e00\u4e2a\u5c3a\u5bf8Q\uff0c\u5e76\u5c06\u56fe\u7247\u8f93\u5165\u5377\u79ef\u7f51\u7edc\u8ba1\u7b97\u3002\u7136\u540e\u5728\u6700\u540e\u4e00\u4e2a\u5377\u79ef\u5c42\u4f7f\u7528\u6ed1\u7a97\u7684\u65b9\u5f0f\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b\uff0c\u5c06\u4e0d\u540c\u7a97\u53e3\u7684\u5206\u7c7b\u7ed3\u679c\u5e73\u5747\uff0c\u518d\u5c06\u4e0d\u540c\u5c3a\u5bf8Q\u7684\u7ed3\u679c\u5e73\u5747\u5f97\u5230\u6700\u540e\u7ed3\u679c\uff0c\u8fd9\u6837\u53ef\u63d0\u9ad8\u56fe\u7247\u6570\u636e\u7684\u5229\u7528\u7387\u5e76\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u7387\u3002\u5728\u8bad\u7ec3\u4e2d\uff0cVGGNet\u8fd8\u4f7f\u7528\u4e86Multi-Scale\u7684\u65b9\u6cd5\u505a\u6570\u636e\u589e\u5f3a\uff0c\u5c06\u539f\u59cb\u56fe\u50cf\u7f29\u653e\u5230\u4e0d\u540c\u5c3a\u5bf8S\uff0c\u7136\u540e\u518d\u968f\u673a\u88c1\u5207224\u00b4224\u7684\u56fe\u7247\uff0c\u8fd9\u6837\u80fd\u589e\u52a0\u5f88\u591a\u6570\u636e\u91cf\uff0c\u5bf9\u4e8e\u9632\u6b62\u6a21\u578b\u8fc7\u62df\u5408\u6709\u5f88\u4e0d\u9519\u7684\u6548\u679c\u3002\u5b9e\u8df5\u4e2d\uff0c\u4f5c\u8005\u4ee4S\u5728[256,512]\u8fd9\u4e2a\u533a\u95f4\u5185\u53d6\u503c\uff0c\u4f7f\u7528Multi-Scale\u83b7\u5f97\u591a\u4e2a\u7248\u672c\u7684\u6570\u636e\uff0c\u5e76\u5c06\u591a\u4e2a\u7248\u672c\u7684\u6570\u636e\u5408\u5728\u4e00\u8d77\u8fdb\u884c\u8bad\u7ec3\u3002\u56fe4\u6240\u793a\u4e3aVGGNet\u4f7f\u7528Multi-Scale\u8bad\u7ec3\u65f6\u5f97\u5230\u7684\u7ed3\u679c\uff0c\u53ef\u4ee5\u770b\u5230D\u548cE\u90fd\u53ef\u4ee5\u8fbe\u52307.5%\u7684\u9519\u8bef\u7387\u3002\u6700\u7ec8\u63d0\u4ea4\u5230ILSVRC 2014\u7684\u7248\u672c\u662f\u4ec5\u4f7f\u7528Single-Scale\u76846\u4e2a\u4e0d\u540c\u7b49\u7ea7\u7684\u7f51\u7edc\u4e0eMulti-Scale\u7684D\u7f51\u7edc\u7684\u878d\u5408\uff0c\u8fbe\u5230\u4e867.3%\u7684\u9519\u8bef\u7387\u3002\u4e0d\u8fc7\u6bd4\u8d5b\u7ed3\u675f\u540e\u4f5c\u8005\u53d1\u73b0\u53ea\u878d\u5408Multi-Scale\u7684D\u548cE\u53ef\u4ee5\u8fbe\u5230\u66f4\u597d\u7684\u6548\u679c\uff0c\u9519\u8bef\u7387\u8fbe\u52307.0%\uff0c\u518d\u4f7f\u7528\u5176\u4ed6\u4f18\u5316\u7b56\u7565\u6700\u7ec8\u9519\u8bef\u7387\u53ef\u8fbe\u52306.8%\u5de6\u53f3\uff0c\u975e\u5e38\u63a5\u8fd1\u540c\u5e74\u7684\u51a0\u519bGoogle Inceptin Net\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u5728\u5bf9\u6bd4\u5404\u7ea7\u7f51\u7edc\u65f6\u603b\u7ed3\u51fa\u4e86\u4ee5\u4e0b\u51e0\u4e2a\u89c2\u70b9\uff1a\uff081\uff09LRN\u5c42\u4f5c\u7528\u4e0d\u5927\uff08VGGNet\u4e0d\u4f7f\u7528\u5c40\u90e8\u54cd\u5e94\u6807\u51c6\u5316(LRN)\uff0c\u8fd9\u79cd\u6807\u51c6\u5316\u5e76\u4e0d\u80fd\u5728ILSVRC\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u6027\u80fd\uff0c\u5374\u5bfc\u81f4\u66f4\u591a\u7684\u5185\u5b58\u6d88\u8017\u548c\u8ba1\u7b97\u65f6\u95f4\u3002\uff09\uff1b\uff082\uff09\u8d8a\u6df1\u7684\u7f51\u7edc\u6548\u679c\u8d8a\u597d\uff1b\uff083\uff0911\u7684\u5377\u79ef\u4e5f\u662f\u5f88\u6709\u6548\u7684\uff0c\u4f46\u662f\u6ca1\u670933\u7684\u5377\u79ef\u597d\uff0c\u5927\u4e00\u4e9b\u7684\u5377\u79ef\u6838\u53ef\u4ee5\u5b66\u4e60\u66f4\u5927\u7684\u7a7a\u95f4\u7279\u5f81\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "\u50cf\u7d20\uff1a \uff08224-3+12\uff09/1+1=224 22422464  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "10.pool2: kernel size:2 stride:2 pad:0  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8834756699654108,
        0.8955886365383559
      ],
      "excerpt": "            img = Image.open(img_path) \n            img = img.resize((32, 32)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": "classes = 10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9783599346414921
      ],
      "excerpt": "        if i % 10 == 0: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "        if (i + 1) == max_steps: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Lornatang/tensorflow-vgg",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-08T03:06:09Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-19T05:34:29Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9915925020191079
      ],
      "excerpt": "VGGNet\u662f\u725b\u6d25\u5927\u5b66\u8ba1\u7b97\u673a\u89c6\u89c9\u7ec4\uff08VisualGeometry Group\uff09\u548cGoogleDeepMind\u516c\u53f8\u7684\u7814\u7a76\u5458\u4e00\u8d77\u7814\u53d1\u7684\u7684\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3002VGGNet\u63a2\u7d22\u4e86\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6df1\u5ea6\u4e0e\u5176\u6027\u80fd\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u901a\u8fc7\u53cd\u590d\u5806\u53e033\u7684\u5c0f\u578b\u5377\u79ef\u6838\u548c22\u7684\u6700\u5927\u6c60\u5316\u5c42\uff0cVGGNet\u6210\u529f\u5730\u6784\u7b51\u4e8616~19\u5c42\u6df1\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3002VGGNet\u76f8\u6bd4\u4e4b\u524dstate-of-the-art\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u9519\u8bef\u7387\u5927\u5e45\u4e0b\u964d\uff0c\u5e76\u53d6\u5f97\u4e86ILSVRC 2014\u6bd4\u8d5b\u5206\u7c7b\u9879\u76ee\u7684\u7b2c2\u540d\u548c\u5b9a\u4f4d\u9879\u76ee\u7684\u7b2c1\u540d\u3002\u540c\u65f6VGGNet\u7684\u62d3\u5c55\u6027\u5f88\u5f3a\uff0c\u8fc1\u79fb\u5230\u5176\u4ed6\u56fe\u7247\u6570\u636e\u4e0a\u7684\u6cdb\u5316\u6027\u975e\u5e38\u597d\u3002VGGNet\u7684\u7ed3\u6784\u975e\u5e38\u7b80\u6d01\uff0c\u6574\u4e2a\u7f51\u7edc\u90fd\u4f7f\u7528\u4e86\u540c\u6837\u5927\u5c0f\u7684\u5377\u79ef\u6838\u5c3a\u5bf8\uff0833\uff09\u548c\u6700\u5927\u6c60\u5316\u5c3a\u5bf8\uff0822\uff09\u3002\u5230\u76ee\u524d\u4e3a\u6b62\uff0cVGGNet\u4f9d\u7136\u7ecf\u5e38\u88ab\u7528\u6765\u63d0\u53d6\u56fe\u50cf\u7279\u5f81\u3002VGGNet\u8bad\u7ec3\u540e\u7684\u6a21\u578b\u53c2\u6570\u5728\u5176\u5b98\u65b9\u7f51\u7ad9\u4e0a\u5f00\u6e90\u4e86\uff0c\u53ef\u7528\u6765\u5728\u7279\u5b9a\u7684\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fdb\u884c\u518d\u8bad\u7ec3\uff08\u76f8\u5f53\u4e8e\u63d0\u4f9b\u4e86\u975e\u5e38\u597d\u7684\u521d\u59cb\u5316\u6743\u91cd\uff09\uff0c\u56e0\u6b64\u88ab\u7528\u5728\u4e86\u5f88\u591a\u5730\u65b9\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "        for img_name in os.listdir(class_path): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8930901044020226,
        0.8930901044020226
      ],
      "excerpt": "features = tf.parse_single_example(serialized_example, \n                                   features={ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "                                       'data': tf.FixedLenFeature([], tf.string), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "#: trans float32 and norm \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9319708861235405
      ],
      "excerpt": "with tf.Session() as sess: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8291041892580366
      ],
      "excerpt": "            saver.save(sess, './model/model.ckpt', global_step=i) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation of VGG based on tensorflow",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Lornatang/tensorflow-vgg/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Sat, 25 Dec 2021 03:26:09 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Lornatang/tensorflow-vgg/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Lornatang/tensorflow-vgg",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8057675898656085
      ],
      "excerpt": "def create_record(path): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9272439022450627
      ],
      "excerpt": "    class_path = cwd + path + name + \"/\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "def MaxPool2D(input_op, kernel_size, stride, name): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "                      name=name) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "pool1 = MaxPool2D(conv1_2, kernel_size=2, stride=2, name='max_pool1') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "pool2 = MaxPool2D(conv2_2, kernel_size=2, stride=2, name='max_pool2') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521,
        0.8661176197453521,
        0.8661176197453521,
        0.8661176197453521,
        0.8661176197453521,
        0.8661176197453521,
        0.8661176197453521,
        0.8661176197453521,
        0.8661176197453521,
        0.8661176197453521,
        0.8661176197453521
      ],
      "excerpt": "#: pool3 = MaxPool2D(conv3_4, kernel_size=2, stride=2, name='max_pool3') \nconv4_1 = Conv2D(conv3_4, 512, kernel_size=3, stride=1, name='conv3_1') \nconv4_2 = Conv2D(conv4_1, 512, kernel_size=3, stride=1, name='conv3_2') \nconv4_3 = Conv2D(conv4_2, 512, kernel_size=3, stride=1, name='conv3_3') \nconv4_4 = Conv2D(conv4_3, 512, kernel_size=3, stride=1, name='conv3_4') \n#: pool4 = MaxPool2D(conv4_4, kernel_size=2, stride=2, name='max_pool3') \nconv5_1 = Conv2D(conv4_4, 512, kernel_size=3, stride=1, name='conv3_1') \nconv5_2 = Conv2D(conv5_1, 512, kernel_size=3, stride=1, name='conv3_2') \nconv5_3 = Conv2D(conv5_2, 512, kernel_size=3, stride=1, name='conv3_3') \nconv5_4 = Conv2D(conv5_3, 512, kernel_size=3, stride=1, name='conv3_4') \npool5 = MaxPool2D(conv5_4, kernel_size=2, stride=2, name='max_pool3') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "fc6 = FullyConnected(flatten, 4096, name='fc6') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "fc7 = FullyConnected(dropout1, 4096, name='fc7') \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8061062927729137
      ],
      "excerpt": "4.conv3-128:kernel size:3 stride:1 pad:1  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8061062927729137
      ],
      "excerpt": "5.conv3-128:kernel size:3 stride:1 pad:1  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8031434402907102
      ],
      "excerpt": "10.pool2: kernel size:2 stride:2 pad:0  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401558704798054,
        0.8044146895679722,
        0.925671696398174
      ],
      "excerpt": "import os \nfrom PIL import Image \nimport tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8936954105699045
      ],
      "excerpt": "writer = tf.python_io.TFRecordWriter(\"train.tfrecords\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8160238286645072,
        0.936606094659785
      ],
      "excerpt": "    class_path = cwd + path + name + \"/\" \n    print(class_path) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8719120920365895,
        0.9189064088189233,
        0.8963725031673749
      ],
      "excerpt": "            example = tf.train.Example(features=tf.train.Features(feature={ \n                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[int(name)])), \n                'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9115099417499427
      ],
      "excerpt": "            writer.write(example.SerializeToString()) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8555603441068306,
        0.9409509849657737,
        0.8778487586960795
      ],
      "excerpt": "    for serialized_example in tf.python_io.tf_record_iterator(\"train.tfrecords\"): \n        example = tf.train.Example() \n        example.ParseFromString(serialized_example) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8675354848368307
      ],
      "excerpt": "    print(label) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174,
        0.9457175861910134,
        0.8430069903536603
      ],
      "excerpt": "import tensorflow as tf \nimport numpy as np \n: print layer information \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.950820698882835
      ],
      "excerpt": "    print(f\"{t.op.name} {t.get_shape().as_list()} \\n\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8164541271960205
      ],
      "excerpt": ":param out: output tensor. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8666454900520489
      ],
      "excerpt": ":param name: layer name. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731562459058029,
        0.8834355619556028,
        0.8123763140827432
      ],
      "excerpt": "input_x = x.get_shape()[-1].value \nwith tf.name_scope(name) as scope: \n    kernel = tf.get_variable(scope + \"w\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8186790943648705
      ],
      "excerpt": "                             dtype=tf.float32, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8170396574231907,
        0.8693971791180761
      ],
      "excerpt": "    conv = tf.nn.conv2d(x, kernel, (1, stride, stride, 1), padding='SAME') \n    bias_init_val = tf.constant(0.0, shape=[out], dtype=tf.float32) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8174762616299084
      ],
      "excerpt": "    z = tf.nn.bias_add(conv, biases) \n    activation = tf.nn.relu(z, name=scope) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8164541271960205,
        0.8666454900520489
      ],
      "excerpt": ":param out: output tensor. \n:param name: layer name. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731562459058029,
        0.8834355619556028,
        0.8123763140827432
      ],
      "excerpt": "input_x = x.get_shape()[-1].value \nwith tf.name_scope(name) as scope: \n    kernel = tf.get_variable(scope + \"w\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8186790943648705
      ],
      "excerpt": "                             dtype=tf.float32, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8680267136974066,
        0.8174762616299084
      ],
      "excerpt": "    biases = tf.Variable(tf.constant(0.1, shape=[out], dtype=tf.float32, name='b')) \n    activation = tf.nn.relu_layer(x, kernel, biases, name=scope) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8666454900520489
      ],
      "excerpt": ":param name: layer name \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8069275751695314
      ],
      "excerpt": ":return: tf.nn.max_pool. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8069275751695314
      ],
      "excerpt": "return tf.nn.max_pool(input_op, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "                      name=name) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8470994933049683,
        0.8137115985783987,
        0.8421074476017179,
        0.8633321019506591,
        0.8633321019506591,
        0.8421074476017179
      ],
      "excerpt": "conv1_1 = Conv2D(images, 64, kernel_size=3, stride=1, name='conv1_1') \nconv1_2 = Conv2D(conv1_1, 64, kernel_size=3, stride=1, name='conv1_2') \npool1 = MaxPool2D(conv1_2, kernel_size=2, stride=2, name='max_pool1') \nconv2_1 = Conv2D(pool1, 128, kernel_size=3, stride=1, name='conv2_1') \nconv2_2 = Conv2D(conv2_1, 128, kernel_size=3, stride=1, name='conv2_2') \npool2 = MaxPool2D(conv2_2, kernel_size=2, stride=2, name='max_pool2') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179,
        0.8421074476017179,
        0.8421074476017179,
        0.8421074476017179,
        0.8421074476017179,
        0.8421074476017179,
        0.8421074476017179,
        0.8421074476017179,
        0.8421074476017179,
        0.8421074476017179,
        0.8421074476017179
      ],
      "excerpt": "#: pool3 = MaxPool2D(conv3_4, kernel_size=2, stride=2, name='max_pool3') \nconv4_1 = Conv2D(conv3_4, 512, kernel_size=3, stride=1, name='conv3_1') \nconv4_2 = Conv2D(conv4_1, 512, kernel_size=3, stride=1, name='conv3_2') \nconv4_3 = Conv2D(conv4_2, 512, kernel_size=3, stride=1, name='conv3_3') \nconv4_4 = Conv2D(conv4_3, 512, kernel_size=3, stride=1, name='conv3_4') \n#: pool4 = MaxPool2D(conv4_4, kernel_size=2, stride=2, name='max_pool3') \nconv5_1 = Conv2D(conv4_4, 512, kernel_size=3, stride=1, name='conv3_1') \nconv5_2 = Conv2D(conv5_1, 512, kernel_size=3, stride=1, name='conv3_2') \nconv5_3 = Conv2D(conv5_2, 512, kernel_size=3, stride=1, name='conv3_3') \nconv5_4 = Conv2D(conv5_3, 512, kernel_size=3, stride=1, name='conv3_4') \npool5 = MaxPool2D(conv5_4, kernel_size=2, stride=2, name='max_pool3') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "fc6 = FullyConnected(flatten, 4096, name='fc6') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "fc7 = FullyConnected(dropout1, 4096, name='fc7') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516,
        0.8801854956928516
      ],
      "excerpt": "from datetime import datetime \nfrom vgg19 import * \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9482048995985969
      ],
      "excerpt": ":param filename: tf records file name. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9348028583514716
      ],
      "excerpt": "filename_queue = tf.train.string_input_producer([filename]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8058938626604182,
        0.8528521672778586
      ],
      "excerpt": "                                       'label': tf.FixedLenFeature([], tf.int64), \n                                       'data': tf.FixedLenFeature([], tf.string), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8485302730953036
      ],
      "excerpt": "img = tf.decode_raw(features['data'], tf.uint8) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.877893571109221,
        0.8894428403789731,
        0.8128131768734507
      ],
      "excerpt": "    X = tf.placeholder(dtype=tf.float32, shape=[None, 32, 32, 3], name='input') \n    y = tf.placeholder(dtype=tf.float32, shape=[None, classes], name='label') \n    keep_prob = tf.placeholder(tf.float32) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8235222976674484,
        0.8496959304986199
      ],
      "excerpt": "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=y)) \ntrain_step = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8557289028830757
      ],
      "excerpt": "img_batch, label_batch = tf.train.shuffle_batch([images, labels], \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8936954105699045,
        0.8135654125968134
      ],
      "excerpt": "saver = tf.train.Saver() \nwith tf.Session() as sess: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8936954105699045,
        0.8611778100090014
      ],
      "excerpt": "    coord = tf.train.Coordinator() \n    threads = tf.train.start_queue_runners(sess=sess, coord=coord) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008331685760428
      ],
      "excerpt": "        batch_x, batch_y = sess.run([img_batch, label_batch]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8209198148545674
      ],
      "excerpt": "            print(f\"{datetime.now()}: Step [%d/{max_steps}]  Loss : {i:.8f}, training accuracy :  {train_arr:.4g}\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8458751354831934,
        0.8589534893990137
      ],
      "excerpt": "if name == 'main': \n    train() \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Lornatang/tensorflow-vgg/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Lornatang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "\u8bba\u6587\u5730\u5740\uff1a[https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "tensorflow-vgg",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Lornatang",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Lornatang/tensorflow-vgg/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Sat, 25 Dec 2021 03:26:09 GMT"
    },
    "technique": "GitHub API"
  }
}
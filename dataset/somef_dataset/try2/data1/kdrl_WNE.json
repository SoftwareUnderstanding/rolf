{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Mikolov, T., Corrado, G., Chen, K., & Dean, J. (2013). **Efficient Estimation of Word Representations in Vector Space**. In Proceedings of ICLR2013. [[pdf](https://arxiv.org/pdf/1301.3781.pdf), [code](https://code.google.com/archive/p/word2vec/)]\n2. Oshikiri, T. (2017). **Segmentation-Free Word Embedding for Unsegmented Languages**. In Proceedings of EMNLP2017. [[pdf](http://aclweb.org/anthology/D17-1080)]\n3. Kudo, T., Yamamoto, K., & Matsumoto, Y. (2004). **Applying Conditional Random Fields to Japanese Morphological Analysis**. In Proceedings of EMNLP2004. [[pdf](http://www.aclweb.org/anthology/W04-3230)]\n4. **MeCab: Yet Another Part-of-Speech and Morphological Analyzer**. [[code](http://taku910.github.io/mecab/)]\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kdrl/WNE",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-09-01T00:53:20Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-08T17:26:30Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9391281237046774,
        0.8418274835416472
      ],
      "excerpt": "1_preprocess/ : Pre-processing corpus. Sentences are concatenated and white spaces are replaces with another character for visualization. \n2_count_ngram_frequency/ : Count n-grams frequency. In this implementation, we use lossy counting algorithm. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9529535830854885,
        0.9339551859748927
      ],
      "excerpt": "4_count_expected_word_frequenct/ : Count expected word frequency (ewf) of word-like n-grams. \n5_SGNS_WNE/ : Compute distributed representations of word-like n-grams via skip-gram model with negative sampling. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "C++ implementation of the paper \"Word-like n-gram embedding\". EMNLP 2018 Workshop on Noisy User-generated Text.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kdrl/WNE/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 00:45:40 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kdrl/WNE/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "kdrl/WNE",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/kdrl/WNE/master/5_SGNS_WNE/run.sh",
      "https://raw.githubusercontent.com/kdrl/WNE/master/4_count_expected_word_frequency/run.sh",
      "https://raw.githubusercontent.com/kdrl/WNE/master/2_count_ngram_frequency/run.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9349326232967055
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u2514\u2500\u2500 run.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9349326232967055
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u2514\u2500\u2500 run.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9349326232967055
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 run.sh \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9285065137266004
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u2514\u2500\u2500 main.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9285065137266004
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u2514\u2500\u2500 main.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kdrl/WNE/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "C++",
      "Python",
      "Makefile",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Geewook Kim\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SGNS-WNE : The word-like n-gram embedding version of skip-gram model with negative sampling",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "WNE",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "kdrl",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kdrl/WNE/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "kdrl",
        "body": "",
        "dateCreated": "2018-11-01T12:23:03Z",
        "datePublished": "2018-11-01T12:24:34Z",
        "html_url": "https://github.com/kdrl/WNE/releases/tag/v0.1",
        "name": "v0.1",
        "tag_name": "v0.1",
        "tarball_url": "https://api.github.com/repos/kdrl/WNE/tarball/v0.1",
        "url": "https://api.github.com/repos/kdrl/WNE/releases/13775600",
        "zipball_url": "https://api.github.com/repos/kdrl/WNE/zipball/v0.1"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Linux(Tested with CentOS Linux release 7.4.1708)\n- gcc(>=5)\n- hdf5\n- Python 3\n- NumPy\n- Pandas\n- h5py\n- scikit-learn\n- tqdm\n- [cmdline](https://github.com/tanakh/cmdline/blob/master/cmdline.h) : Download `cmdline.h` and place it in `2_count_ngram_frequency/`, `4_count_expected_word_frequenct/` and `5_SGNS_WNE/`\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "* [word2vec - Google Codes](https://code.google.com/archive/p/word2vec/)\n* [oshikiri/w2v-sembei - GitHub](https://github.com/oshikiri/w2v-sembei)\n* [tanakh/cmdline - GitHub](https://github.com/tanakh/cmdline)\n\nThe majority of C++ code which is used for computing representations for n-grams with SGNS is taken from **[word2vec - Google Codes](https://code.google.com/archive/p/word2vec/)**[1] and **[w2v-sembei](https://github.com/oshikiri/w2v-sembei)**[2].\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 00:45:40 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "word-embedding",
      "machine-learning",
      "word-segmentation",
      "representation-learning"
    ],
    "technique": "GitHub API"
  }
}
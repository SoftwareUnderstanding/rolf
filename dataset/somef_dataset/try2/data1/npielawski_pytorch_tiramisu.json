{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Many thanks to [@RaphaelaHeil](https://github.com/RaphaelaHeil) for her much\nappreciated advices on best practices.\n\nAcknowledging this repository and citing it is appreciated. The static record is\navailable on Zenodo: [https://zenodo.org/record/3685491](https://zenodo.org/record/3685491)\n\nCite as:\n\n```MLA\nNicolas Pielawski. (2020, February 24). npielawski/pytorch_tiramisu: Better Tiramisu 1.0 (Version 1.0). Zenodo. http://doi.org/10.5281/zenodo.3685491\n```\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/npielawski/pytorch_tiramisu",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-24T07:03:11Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-03T16:30:45Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9958854591478008
      ],
      "excerpt": "Implementation of the Tiramisu Neural network for PyTorch with new features such as: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9558504179898416
      ],
      "excerpt": "\ud83d\uddbc Works with any input size (not only powers of 2 anymore). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9480476866306908
      ],
      "excerpt": "\ud83c\udfd7 The depth and width of the Tiramisu is fully configurable. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8778818048284776,
        0.8585933747086054
      ],
      "excerpt": "\ud83d\udc78\ud83c\udffc The activation functions of all layers can be modified to something trendier. \n\ud83c\udf89 Won a competition (Adipocyte Cell Imaging Challenge)! Preprint of the winners is here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9708317785210444
      ],
      "excerpt": "to different types of layers. This was introduced to wrap many arguments of the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.915970678359447
      ],
      "excerpt": "CONV: Convolution operations in the full model. Change with care. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9106286957787902
      ],
      "excerpt": "BATCHNORM: Batch normalization in the full model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8725178222529983
      ],
      "excerpt": "  size is odd, round up to the closest integer. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8326018129604819
      ],
      "excerpt": "For upsampling, there are some presets: UPSAMPLE_NEAREST (default), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.933668714021753
      ],
      "excerpt": "The partial function can prefill some of the arguments to be used in the model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9071945914439182
      ],
      "excerpt": "are hard to manage and may create a lot of gridding artefacts. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8162311346141213,
        0.9785059037755481,
        0.8558470971112295,
        0.8700062640218997
      ],
      "excerpt": "The model creates border artifacts at the edge, which can be mitigated by changing \nthe padding_mode argument of the Conv2d in the module bank. For instance, using \n\"reflect\" instead of \"zeros\" will create a smooth continuation in the boundaries \ninstead of an edge. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A regular Tiramisu network for PyTorch with a LOT of extra features!",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The parameters of the constructor are explained as following:\n\n* in_channels: The number of channels of the input image (e.g. 1 for grayscale, 3 for\n  RGB).\n* out_channels: The number of output channels (e.g. C for C classes).\n* init_conv_filters: The number of filters in the very first convolution.\n* structure: Divided in three parts (down blocks, bottleneck and up blocks) which\n  describe the depth of the neural network (how many levels there are) and how many\n  DenseLayers each of those levels have.\n* growth_rate: Describes the size of each convolution in the DenseLayers. At each conv.\n  the DenseLayer grows by this many channels.\n* compression: The compression of the DenseLayers to reduce the memory footprint and\n  computational complexity of the model.\n* early_transition: Optimization where the input is downscaled by a factor of two after\n  the first layer by using a down-transition (without skip-connection) early on.\n* include_top: Including the top layer, with the last convolution and activation (True)\n  or returns the embeddings for each pixel.\n* checkpoint: Activates memory checkpointing, a memory efficient version of the\n  Tiramisu. See: [https://arxiv.org/pdf/1707.06990.pdf](https://arxiv.org/pdf/1707.06990.pdf)\n* module_bank: The bank of layers the Tiramisu uses to build itself. See next subsection\n  for details.\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/npielawski/pytorch_tiramisu/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Thu, 23 Dec 2021 03:11:37 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/npielawski/pytorch_tiramisu/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "npielawski/pytorch_tiramisu",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/npielawski/pytorch_tiramisu/master/test/download_mockdata.sh"
    ],
    "technique": "File Exploration"
  },
  "identifier": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://zenodo.org/badge/latestdoi/242668685",
      "technique": "Regular expression"
    }
  ],
  "installation": [
    {
      "confidence": [
        0.8759961735293489
      ],
      "excerpt": "The layers that can be redefined are: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9635274672371793
      ],
      "excerpt": "Pytorch - Version >=1.4.0 (for memory efficient version) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/npielawski/pytorch_tiramisu/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020-2021 Nicolas Pielawski\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "DEPRECATED! Please use [OctoPyTorch](https://github.com/npielawski/octopytorch) instead",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pytorch_tiramisu",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "npielawski",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/npielawski/pytorch_tiramisu/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "npielawski",
        "body": "First version with the following features:\r\n- Memory-efficient version (trade-off between memory and speed).\r\n- Different types of upsampling (deconvolution, upsampling and pixel shuffle).\r\n- Different types of pooling (max-pooling, avg-pooling, blur-pooling).\r\n- The depth and width of the Tiramisu is fully configurable.\r\n- Early-transition can be enabled when the input images are big.\r\n- The activation function of the last layer can be disabled or modified.",
        "dateCreated": "2020-02-24T08:29:44Z",
        "datePublished": "2020-02-24T08:34:32Z",
        "html_url": "https://github.com/npielawski/pytorch_tiramisu/releases/tag/1.0",
        "name": "Better Tiramisu 1.0",
        "tag_name": "1.0",
        "tarball_url": "https://api.github.com/repos/npielawski/pytorch_tiramisu/tarball/1.0",
        "url": "https://api.github.com/repos/npielawski/pytorch_tiramisu/releases/23921156",
        "zipball_url": "https://api.github.com/repos/npielawski/pytorch_tiramisu/zipball/1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 40,
      "date": "Thu, 23 Dec 2021 03:11:37 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The package can be installed from the repository with:\n\n```console\n> pip3 install git+https://github.com/npielawski/pytorch_tiramisu\n```\n\nYou can try the model in Python with:\n\n```py\nfrom functools import partial\nimport torch\nfrom torch import nn\nfrom tiramisu import DenseUNet, DEFAULT_MODULE_BANK, ModuleName\n\nmodule_bank = DEFAULT_MODULE_BANK.copy()\n#: Dropout\nmodule_bank[ModuleName.DROPOUT] = partial(nn.Dropout2d, p=0.2, inplace=True)\n#: Every activation in the model is going to be a GELU (Gaussian Error Linear \n#: Units function). GELU(x) = x * \u03a6(x)\n#: See: https://pytorch.org/docs/stable/generated/torch.nn.GELU.html\nmodule_bank[ModuleName.ACTIVATION] = nn.GELU\n#: Example for segmentation:\nmodule_bank[ModuleName.ACTIVATION_FINAL] = partial(nn.LogSoftmax, dim=1)\n#: Example for regression (default):\n#:module_bank[ModuleName.ACTIVATION_FINAL] = nn.Identity\n\nmodel = DenseUNet(\n    in_channels = 3,          #: RGB images\n    out_channels = 5,         #: 5-channel output (5 classes)\n    init_conv_filters = 48,   #: Number of channels outputted by the 1st convolution\n    structure = (\n        [4, 4, 4, 4, 4],      #: Down blocks\n        4,                    #: bottleneck layers\n        [4, 4, 4, 4, 4],      #: Up blocks\n    ),\n    growth_rate = 12,         #: Growth rate of the DenseLayers\n    compression = 1.0,        #: No compression\n    early_transition = False, #: No early transition\n    include_top = True,       #: Includes last layer and activation\n    checkpoint = False,       #: No memory checkpointing\n    module_bank = module_bank #: Modules to use\n)\n\n#: Initializes all the convolutional kernel weights.\nmodel.initialize_kernels(nn.init.kaiming_uniform_, conv=True)\n#: Shows some information about the model.\nmodel.summary()\n```\n\nThis example tiramisu network has a depth of len(down_blocks) = 5, meaning that the\ninput images should be at least 32x32 pixels (i.e. 2^5=32).\n\n",
      "technique": "Header extraction"
    }
  ]
}
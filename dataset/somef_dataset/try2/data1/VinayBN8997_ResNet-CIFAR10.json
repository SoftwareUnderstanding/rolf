{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1512.03385\n\nIt is observed that as the networks goes deeper and deeper, during the convergence, the degradation of weights is an inevitable problem. The weights get too small which leads to saturated accuracy.\nTo avoid this problem, skip connections are introduced into the architecture so that instead of just stacking up of layers, the prior reidual mapping is also concatenated with the current mapping so that the architecture is explicitly let to fit a residual mapping.\nBelow is a Residual block used in the ResNet architecture. Here the identity mapping of input X is also added to the output of the convolution block. On doing this in all the convolution blocks, the degradation problem is tackled.\n\n![image](https://user-images.githubusercontent.com/33830482/61840489-f89b9880-aeae-11e9-809d-8eaa7befdf9a.png",
      "https://arxiv.org/abs/ https://arxiv.org/abs/1512.03385\n\nIt is observed that as the networks goes deeper and deeper, during the convergence, the degradation of weights is an inevitable problem. The weights get too small which leads to saturated accuracy.\nTo avoid this problem, skip connections are introduced into the architecture so that instead of just stacking up of layers, the prior reidual mapping is also concatenated with the current mapping so that the architecture is explicitly let to fit a residual mapping.\nBelow is a Residual block used in the ResNet architecture. Here the identity mapping of input X is also added to the output of the convolution block. On doing this in all the convolution blocks, the degradation problem is tackled.\n\n![image](https://user-images.githubusercontent.com/33830482/61840489-f89b9880-aeae-11e9-809d-8eaa7befdf9a.png)\n\nTo get the model configured from ImageNet to CIFAR10 configuration, we need to add anothe layer at the end.\n\n```python\nbase_model = ResNet18(input_shape=(32,32,3), weights='imagenet', include_top=False)\nx = keras.layers.GlobalAveragePooling2D()(base_model.output)\noutput = keras.layers.Dense(n_classes, activation='softmax')(x)\nmodel = keras.models.Model(inputs=[base_model.input], outputs=[output])\n```\n\n## Next, we are working on Gradcam which helps in understanding what the model is looking at\n\nReference: http://www.hackevolve.com/where-cnn-is-looking-grad-cam/\n\nGradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say logits for \u2018dog\u2019 or even a caption), flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept.\nProcess:\n\n1. Compute the gradient of the class output value with respect to the feature map\n2. Pool the gradients over all the axes leaving out the channel dimension\n3. Weigh the output feature map with the computed gradient values\n4. Average the weighed feature map along the channel dimension resulting in a heat map of size same as the input image\n5. Finally normalize the heat map to make the values in between 0 and 1\n\n### 3 funtions are written which returns the activation map from thier respective layers as below:\n\n1. stage1_unit1_relu2 : Initial stage of the network\n2. stage1_unit2_relu2 : Layer approximately in the middle of the architecture\n3. stage4_unit1_relu1: Deeper stage of the network\n\n\n\n\n\n"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9626356225854676
      ],
      "excerpt": "Link: https://github.com/qubvel \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9314443980314455
      ],
      "excerpt": "2. Classification_models : Github: https://github.com/qubvel/classification_models.git \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9945167849443287,
        0.9995991827938789
      ],
      "excerpt": "Source: https://en.wikipedia.org/wiki/CIFAR-10 \narXiv: https://arxiv.org/abs/1512.03385 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8729393277090676
      ],
      "excerpt": "base_model = ResNet18(input_shape=(32,32,3), weights='imagenet', include_top=False) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/VinayBN8997/ResNet-CIFAR10",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-07-25T01:54:10Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-07-25T02:19:42Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8874182418490745,
        0.9362518883454206
      ],
      "excerpt": "A notebook referenct to model ResNet on CIFAR 10 \nTo import the pretarined model, we are using another GitHub repository from Pavel Yakubovskiy. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9587729360458289
      ],
      "excerpt": "The model is trained on Google Colab which provides 12 hours of free GPU instance per session. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9786056241947013,
        0.977547013483383,
        0.9848030531631232,
        0.9646206397339598
      ],
      "excerpt": "It is observed that as the networks goes deeper and deeper, during the convergence, the degradation of weights is an inevitable problem. The weights get too small which leads to saturated accuracy. \nTo avoid this problem, skip connections are introduced into the architecture so that instead of just stacking up of layers, the prior reidual mapping is also concatenated with the current mapping so that the architecture is explicitly let to fit a residual mapping. \nBelow is a Residual block used in the ResNet architecture. Here the identity mapping of input X is also added to the output of the convolution block. On doing this in all the convolution blocks, the degradation problem is tackled. \nTo get the model configured from ImageNet to CIFAR10 configuration, we need to add anothe layer at the end. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A notebook reference to model ResNet on CIFAR 10. Gradcam is applied on it.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/VinayBN8997/ResNet-CIFAR10/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 04:55:41 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/VinayBN8997/ResNet-CIFAR10/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "VinayBN8997/ResNet-CIFAR10",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/VinayBN8997/ResNet-CIFAR10/master/ResNet_on_CIFAR10.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8918974083095406
      ],
      "excerpt": "Link: https://github.com/qubvel \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9984079357284334
      ],
      "excerpt": "!pip install git+https://github.com/qubvel/classification_models.git \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9452345072558894,
        0.8233588558014837,
        0.8966655221085083
      ],
      "excerpt": "2. Classification_models : Github: https://github.com/qubvel/classification_models.git \n3. Numpy \n4. Matplotlib \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8129929742847939
      ],
      "excerpt": "A notebook referenct to model ResNet on CIFAR 10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8048646326257287
      ],
      "excerpt": "model = keras.models.Model(inputs=[base_model.input], outputs=[output]) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/VinayBN8997/ResNet-CIFAR10/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "ResNet-CIFAR10",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ResNet-CIFAR10",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "VinayBN8997",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/VinayBN8997/ResNet-CIFAR10/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 04:55:41 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Reference: http://www.hackevolve.com/where-cnn-is-looking-grad-cam/\n\nGradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say logits for \u2018dog\u2019 or even a caption), flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept.\nProcess:\n\n1. Compute the gradient of the class output value with respect to the feature map\n2. Pool the gradients over all the axes leaving out the channel dimension\n3. Weigh the output feature map with the computed gradient values\n4. Average the weighed feature map along the channel dimension resulting in a heat map of size same as the input image\n5. Finally normalize the heat map to make the values in between 0 and 1\n\n",
      "technique": "Header extraction"
    }
  ]
}
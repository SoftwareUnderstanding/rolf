{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.10593 paper, and eriklindernoren project https://github.com/eriklindernoren/Keras-GAN  \nIn this project I implemented a Cycle Generative Adversarial Network, or short-  a \"Cycle Gan\". The Cycle Gan network receives two datasets and can produce an integrated picture of the two input images from the datasets. The datasets that I built for this task is printed sentences dataset and handwriting sentences dataset.\n\n## The network\nIn order to get the best result, I tried several different architectures and compared them. All the models contain two parts: Generator and Discriminator.\nThe generator architecture is U-net. The U-net is convolutional network architecture for fast and precise segmentation of images. The network consists of Down sampling and Up sampling, when the number of filters increase in the first layers and decrease in the last layers.\n\n## Datasets:\n### Printed Dataset\nThe first dataset is printed sentences that I built from a pdf online book \"Education and Philosophical Ideal By Horatio W Dresser\". I converted the pdf into jpeg format, and I cut the lines. For be sure the lines will crop well, I cropped the printed frame area.\nThen I resized the cropped image to the nearest integer that can divided by the rows number, and then, to achieve automatic line separator, it run with loop and cut the lines.\nIn order to avoid a blank line, the program throws lines whose number of bytes is less than a certain threshold.\nfor building the train/test datasets, I padded the images and resize them to the optimal size that I found the network working best- 512x48 \nThis dataset contain 614 grey scale 512x48 images for training, and 112 images for test.\n\n### Handwriting Dataset\nThe second dataset is a handwriting sentences. This dataset has taken from \"IAM Handwriting Database\". The database contains forms of unconstrained handwritten text, which were scanned at a resolution of 300dpi and saved as PNG images with 256 gray levels.\nIn this project I used the lines of the forms data. In the data preparation I used several image processing method for cleaning the data and feet the size to 512x48 with the best quality\nThe method for cleaning the images was to remove high frequency contents from the images for inverse Fourier transform and threshold dropping. First I used Fourier Transform and inverse Fourier transform for removing low frequency components. Then the image with low frequencies removed from the original image. \nThis dataset contain 578 grey scale 512x48 images for training, and 60 images for test.\n\n## Network architectures\n### Architecture 1:\n#### Generator\nThe generator architecture is U-net with those layers:\n\nDown sampling\n\n+ Convolution 4x4 with 32 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\t+ Instance Normalization\n+ Convolution 4x4 with 64 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\t+ Instance Normalization\n+ Convolution 4x4 with 128 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\t+ Instance Normalization\n+ Convolution 4x4 with 256 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\t+ Instance Normalization\n\t\nUp sampling\n\n+ Convolution 4x4 with 128 filters\n\t+ ReLu Activation function\n\t+ Instance normalization \n\t+ Concat with the down sample output\n+ Convolution 4x4 with 64 filters\n\t+ ReLu Activation function\n\t+ Instance normalization \n\t+ Concat with the down sample output\n+ Convolution 4x4 with 32 filters\n\t+ ReLu Activation function\n\t+ Instance normalization \n\t+ Concat with the down sample output\n\n#### Discriminator\n+ Convolution 4x4 with 32 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n+ Convolution  4x4 with 64 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n+ Convolution  4x4 with 128 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n+ Convolution  4x4 with 256 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\n### Architecture 2:\n#### Generator\nThe generator architecture is U-net with those layers:\n\nDown sampling\n\n+ Convolution 3x3 with 32 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\t+ Instance Normalization\n+ Convolution 3x3 with 64 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\t+ Instance Normalization\n+ Convolution 3x3 with 128 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\t+ Instance Normalization\n+ Convolution 3x3 with 256 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\t+ Instance Normalization\n\nUp sampling\n\n+ Convolution 3x3 with 128 filters, strides=1\n+ Convolution 3x3 with 128 filters, strides=1\n\t+ ReLu Activation function\n\t+ Instance normalization \n\t+ Concatenate with the down sample output\n+ Convolution 3x3 with 64 filters, strides=1\n+ Convolution 3x3 with 64 filters, strides=1\n\t+ ReLu Activation function\n\t+ Instance normalization \n\t+ Concatenate with the down sample output\n+ Convolution 3x3 with 32 filters, strides=1\n+ Convolution 3x3 with 32 filters, strides=1\n\t+ ReLu Activation function\n\t+ Instance normalization \n\t+ Concatenate with the down sample output\n\n#### Discriminator\n\n+ Convolution 3x3 with 32 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n+ Convolution  3x3 with 64 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n+ Convolution  3x3 with 128 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n+ Convolution  3x3 with 256 filters, strides=2\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\n### Architecture 3:\n#### Generator\nThe generator architecture is U-net with those layers:\nDown sampling\n+ Convolution 3x3 with 32 filters, strides=2\n+ Convolution 3x3 with 32 filters\n+ Convolution 3x3 with 32 filters\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\t+ Instance Normalization\n+ Convolution 3x3 with 64 filters, strides=2\n+ Convolution 3x3 with 64 filters\n+ Convolution 3x3 with 64 filters\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\t+ Instance Normalization\n+ Convolution 3x3 with 128 filters, strides=2\n+ Convolution 3x3 with 128 filters\n+ Convolution 3x3 with 128 filters\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\t+ Instance Normalization\n+ Convolution 3x3 with 256 filters, strides=2\n+ Convolution 3x3 with 256 filters\n+ Convolution 3x3 with 256 filters\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\t+ Instance Normalization\n\nUp sampling\n\n+ Convolution 3x3 with 128 filters, strides=1\n+ Convolution 3x3 with 128 filters\n+ Convolution 3x3 with 128 filters\n\t+ ReLu Activation function\n\t+ Dropout 0.2 \n\t+ Instance normalization\n\t+ Concatenate with the down sample output\n+ Convolution 3x3 with 64 filters, strides=1\n+ Convolution 3x3 with 64 filters\n+ Convolution 3x3 with 64 filters\n\t+ ReLu Activation function\n\t+ Dropout 0.2 \n\t+ Instance normalization \n\t+ Concatenate with the down sample output\n+ Convolution 3x3 with 32 filters, strides=1\n+ Convolution 3x3 with 32 filters\n+ Convolution 3x3 with 32 filters\n\t+ ReLu Activation function\n\t+ Dropout 0.2 \n\t+ Instance normalization \n\t+ Concatenate with the down sample output\n\n#### Discriminator\n+ Convolution 3x3 with 32 filters, strides=2\n+ Convolution 3x3 with 32 filters\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n+ Convolution  3x3 with 64 filters, strides=2\n+ Convolution  3x3 with 64 filters\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n+ Convolution  3x3 with 128 filters, strides=2\n+ Convolution  3x3 with 128 filters\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n+ Convolution  3x3 with 256 filters, strides=2\n+ Convolution  3x3 with 256 filters\n\t+ Leaky-ReLu Activation function with 0.2 Alpha\n\n### Results\nAs we can see in the samples, the best results were of Architecture 2. It is noticeable that the results of Architecture 3 were over fitting.\n\n#### Architecture 1\n![Image description](https://github.com/RanBezen/cycleGan/blob/master/tmp/arch1.png"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8520335179207914
      ],
      "excerpt": "This project is a generative adversarial networks implementation for generate handwriting sentences. The project based on https://arxiv.org/abs/1703.10593 paper, and eriklindernoren project https://github.com/eriklindernoren/Keras-GAN \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RanBezen/cycleGan_handwriting",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-06-24T16:34:21Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-24T07:51:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9492968445592587,
        0.967001439877181,
        0.900952808131403,
        0.931532153857495,
        0.8804738590180636
      ],
      "excerpt": "This project is a generative adversarial networks implementation for generate handwriting sentences. The project based on https://arxiv.org/abs/1703.10593 paper, and eriklindernoren project https://github.com/eriklindernoren/Keras-GAN \nIn this project I implemented a Cycle Generative Adversarial Network, or short-  a \"Cycle Gan\". The Cycle Gan network receives two datasets and can produce an integrated picture of the two input images from the datasets. The datasets that I built for this task is printed sentences dataset and handwriting sentences dataset. \nIn order to get the best result, I tried several different architectures and compared them. All the models contain two parts: Generator and Discriminator. \nThe generator architecture is U-net. The U-net is convolutional network architecture for fast and precise segmentation of images. The network consists of Down sampling and Up sampling, when the number of filters increase in the first layers and decrease in the last layers. \nThe first dataset is printed sentences that I built from a pdf online book \"Education and Philosophical Ideal By Horatio W Dresser\". I converted the pdf into jpeg format, and I cut the lines. For be sure the lines will crop well, I cropped the printed frame area. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9236948679754134,
        0.9956990656412726,
        0.889915276497861
      ],
      "excerpt": "The second dataset is a handwriting sentences. This dataset has taken from \"IAM Handwriting Database\". The database contains forms of unconstrained handwritten text, which were scanned at a resolution of 300dpi and saved as PNG images with 256 gray levels. \nIn this project I used the lines of the forms data. In the data preparation I used several image processing method for cleaning the data and feet the size to 512x48 with the best quality \nThe method for cleaning the images was to remove high frequency contents from the images for inverse Fourier transform and threshold dropping. First I used Fourier Transform and inverse Fourier transform for removing low frequency components. Then the image with low frequencies removed from the original image.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.829204004926076
      ],
      "excerpt": "The generator architecture is U-net with those layers: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution 4x4 with 32 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution 4x4 with 64 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution 4x4 with 128 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution 4x4 with 256 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution 4x4 with 128 filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution 4x4 with 64 filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution 4x4 with 32 filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution 4x4 with 32 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution  4x4 with 64 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution  4x4 with 128 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution  4x4 with 256 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.829204004926076
      ],
      "excerpt": "The generator architecture is U-net with those layers: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution 3x3 with 32 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution 3x3 with 64 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution 3x3 with 128 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution 3x3 with 256 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921,
        0.856287150284921
      ],
      "excerpt": "Convolution 3x3 with 128 filters, strides=1 \nConvolution 3x3 with 128 filters, strides=1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921,
        0.856287150284921
      ],
      "excerpt": "Convolution 3x3 with 64 filters, strides=1 \nConvolution 3x3 with 64 filters, strides=1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921,
        0.856287150284921
      ],
      "excerpt": "Convolution 3x3 with 32 filters, strides=1 \nConvolution 3x3 with 32 filters, strides=1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution 3x3 with 32 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution  3x3 with 64 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution  3x3 with 128 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921
      ],
      "excerpt": "Convolution  3x3 with 256 filters, strides=2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.829204004926076
      ],
      "excerpt": "The generator architecture is U-net with those layers: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921,
        0.856287150284921,
        0.856287150284921
      ],
      "excerpt": "+ Convolution 3x3 with 32 filters, strides=2 \n+ Convolution 3x3 with 32 filters \n+ Convolution 3x3 with 32 filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921,
        0.856287150284921,
        0.856287150284921
      ],
      "excerpt": "+ Convolution 3x3 with 64 filters, strides=2 \n+ Convolution 3x3 with 64 filters \n+ Convolution 3x3 with 64 filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921,
        0.856287150284921,
        0.856287150284921
      ],
      "excerpt": "+ Convolution 3x3 with 128 filters, strides=2 \n+ Convolution 3x3 with 128 filters \n+ Convolution 3x3 with 128 filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921,
        0.856287150284921,
        0.856287150284921
      ],
      "excerpt": "+ Convolution 3x3 with 256 filters, strides=2 \n+ Convolution 3x3 with 256 filters \n+ Convolution 3x3 with 256 filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921,
        0.856287150284921,
        0.856287150284921
      ],
      "excerpt": "Convolution 3x3 with 128 filters, strides=1 \nConvolution 3x3 with 128 filters \nConvolution 3x3 with 128 filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921,
        0.856287150284921,
        0.856287150284921
      ],
      "excerpt": "Convolution 3x3 with 64 filters, strides=1 \nConvolution 3x3 with 64 filters \nConvolution 3x3 with 64 filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921,
        0.856287150284921,
        0.856287150284921
      ],
      "excerpt": "Convolution 3x3 with 32 filters, strides=1 \nConvolution 3x3 with 32 filters \nConvolution 3x3 with 32 filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921,
        0.856287150284921
      ],
      "excerpt": "Convolution 3x3 with 32 filters, strides=2 \nConvolution 3x3 with 32 filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921,
        0.856287150284921
      ],
      "excerpt": "Convolution  3x3 with 64 filters, strides=2 \nConvolution  3x3 with 64 filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921,
        0.856287150284921
      ],
      "excerpt": "Convolution  3x3 with 128 filters, strides=2 \nConvolution  3x3 with 128 filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856287150284921,
        0.856287150284921
      ],
      "excerpt": "Convolution  3x3 with 256 filters, strides=2 \nConvolution  3x3 with 256 filters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.954896347528262,
        0.9445672487121901,
        0.8270419216705797
      ],
      "excerpt": "As we can see in the samples, the best results were of Architecture 2. It is noticeable that the results of Architecture 3 were over fitting. \nThe system, with its three different architectures, is ready for use. I trained the three networks and kept the weights of each. I developed a test system that receives input from the user. The output is an image of the printed text, and a handwriting translation \nInput: Network testing, Rans project. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Generate handwriting sentences using Deep learning",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RanBezen/cycleGan_handwriting/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Wed, 22 Dec 2021 15:15:29 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/RanBezen/cycleGan_handwriting/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "RanBezen/cycleGan_handwriting",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8125251441580196
      ],
      "excerpt": "This dataset contain 614 grey scale 512x48 images for training, and 112 images for test. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8125251441580196
      ],
      "excerpt": "This dataset contain 578 grey scale 512x48 images for training, and 60 images for test. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/RanBezen/cycleGan_handwriting/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Generate handwriting using Deep learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "cycleGan_handwriting",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "RanBezen",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RanBezen/cycleGan_handwriting/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 20,
      "date": "Wed, 22 Dec 2021 15:15:29 GMT"
    },
    "technique": "GitHub API"
  }
}
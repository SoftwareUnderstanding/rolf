{
  "citation": [
    {
      "confidence": [
        0.8001118323515268
      ],
      "excerpt": "--epoch - number of epochs, default =10 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kirillermolov/ChatBot",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-10-19T11:46:32Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-10-19T15:50:57Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8712514717570689
      ],
      "excerpt": "This is chatbot model build using Seq2Seq model (https://arxiv.org/pdf/1409.3215.pdf) and memory block described in https://www.csie.ntu.edu.tw/~yvchen/doc/IS16_ContextualSLU.pdf. Model is trained on Cornell Movie-Dialogs Corpus, so that 2 first lines of dialog are used to train basic Seq2Seq model, then if dialog have more lines it is divided into memory, input and output parts. E.g. if dialog has 4 lines (1, 2, 3 and 4), following data is used in training: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8240553706228557
      ],
      "excerpt": "Representation vectors produced by Seq2Seq encoder and memory block are summed and fed into Seq2Seq decoder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9337609428192192
      ],
      "excerpt": "--maxvocab - maximum size of vocabulary, vocabulary is formed from training data, default 50000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9524386776436623
      ],
      "excerpt": "--decrate - training is done with step decay of learning rate, factor of decay, default = 0.5 \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kirillermolov/ChatBot/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Fri, 24 Dec 2021 09:12:14 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kirillermolov/ChatBot/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "kirillermolov/ChatBot",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8289669050403863
      ],
      "excerpt": "Output: 3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8289669050403863
      ],
      "excerpt": "Output: 4 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8289669050403863
      ],
      "excerpt": "Output: 4 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8915271233486645
      ],
      "excerpt": "Download and unzip Cornell Movie-Dialogs Corpus (https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html) into data folder, then run train.py. In the end of training model will be saved into saved_model folder. Following command-line options can be used in training: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8179210363321612
      ],
      "excerpt": "--maxvocab - maximum size of vocabulary, vocabulary is formed from training data, default 50000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8208868584298378,
        0.8099352149925214,
        0.8122051251449373
      ],
      "excerpt": "--epoch - number of epochs, default =10 \n--batch - size of batch, default = 128  \n--maxlen - maximum length of sentence in training batch, default = 16 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kirillermolov/ChatBot/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "ChatBot with memory",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ChatBot",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "kirillermolov",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kirillermolov/ChatBot/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Python 3\n\nTensorflow (tested with version 1.8.0)\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Pretrained model is available from https://drive.google.com/open?id=1axMZ1UlkW80N1ZeSAOqu0R1C3yVnTxg1. Unzip and save it in folder saved_model, then run chatbot.py. It accepts following command-line option:\n\n* --tf cpu - default, if run with tensorflow\n* --tf gpu - if run with tensorflow-gpu \n \n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 09:12:14 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Environment based on mobile game [Puzzle & Dragons](https://www.puzzleanddragons.us/)\n\nImplementation of DQN algorithms were with reference to the original papers:\n* [Playing Atari with Deep Reinforcement Learning (2013)](https://arxiv.org/pdf/1312.5602.pdf)\n* [Dueling Network Architectures for Deep Reinforcement Learning (2016)](https://arxiv.org/pdf/1511.06581.pdf)\n\nVery much credit to the series of blogposts and Jupyter notebooks by `awjuliani` on reinforement learning:\n* [github](https://github.com/awjuliani/DeepRL-Agents)\n* [gists](https://gist.github.com/awjuliani?page=1)\n* [medium](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0)\n\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nathanin/pad",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-09-10T21:33:40Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-29T03:48:25Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Puzzle RLE (Reinforcement Learning Environment) is an environment for learning the puzzle gameplay from the mobile game [Puzzle and Dragons](https://youtu.be/tLku-s20EBE) (Gungho Online Entertainment, Tokyo, Japan).\nThe environment is a re-implemntation based on orb-matching and clearing mechanics encountered during normal gameplay.\n\nThe environment supports the following:\n* pygame environment visualization engine\n* 5 Actions: select-orb, move left, up, right, down\n* Baseline random agent\n* OpenAI Baselines agents\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8535925621188934
      ],
      "excerpt": "Implement Deep Q Network learning agent (:heavy_check_mark: Sep 9 '17 ) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8998177345710395
      ],
      "excerpt": "Update environment to work with openai gym style with spaces, step(), ... etc. (:heavy_check_mark: Sep '18) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9734563080816941
      ],
      "excerpt": "Move timer to work \"real - time\" : reset clock when orb is selected. End episode after timer. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "RL environment",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nathanin/pad/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Sun, 26 Dec 2021 20:46:49 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/nathanin/pad/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "nathanin/pad",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8721361590733816,
        0.8681222472473001
      ],
      "excerpt": "Update environment to work with openai gym style with spaces, step(), ... etc. (:heavy_check_mark: Sep '18) \nUpdate render-able environment via pygame (:heavy_check_mark: Oct '18) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8380287568101925
      ],
      "excerpt": "Represent environment timer on-screen \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8015802640310951
      ],
      "excerpt": "Implement a random agent and run experiments to generate baseline statistics ( :heavy_check_mark: Sep 2, '17) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/nathanin/pad/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Puzzle RLE",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pad",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "nathanin",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nathanin/pad/blob/master/ReadMe.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Sun, 26 Dec 2021 20:46:49 GMT"
    },
    "technique": "GitHub API"
  }
}
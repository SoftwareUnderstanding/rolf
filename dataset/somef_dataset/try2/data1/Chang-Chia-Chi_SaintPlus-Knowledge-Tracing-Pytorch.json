{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2010.12042 - SAINT+: Integrating Temporal Features for EdNet Correctness Prediction   \nhttps://arxiv.org/abs/1706.03762 - Attention Is All You Need",
      "https://arxiv.org/abs/1706.03762 - Attention Is All You Need"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "https://arxiv.org/abs/2010.12042 - SAINT+: Integrating Temporal Features for EdNet Correctness Prediction   \nhttps://arxiv.org/abs/1706.03762 - Attention Is All You Need\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Chang-Chia-Chi/SaintPlus-Knowledge-Tracing-Pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-04T13:46:02Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T13:35:02Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Thanks to Kaggle and a lot of amazing data enthusiasm people sharing their notebooks so I had a chance to learn Transformer and really use it to a real-world task!   \n    \nSaint+ is a **Transformer** based knowledge-tracing model which takes students' exercise history information to predict future performance. As classical Transformer, it has an Encoder-Decoder structure that Encoder applied self-attention to a stream of exercise embeddings; Decoder applied self-attention to responses embeddings and encoder-decoder attention to encoder output.\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8797014890103602,
        0.9303132369643357,
        0.9642394462913244,
        0.8901817545960657,
        0.9650090606590437,
        0.9656832169690648,
        0.8852059743937662
      ],
      "excerpt": "The basic idea is that we fed current question and stream of past exerices into encoder, it will find which parts of exercises experience should be noticed. Then fed the weighted sum of encoder value vector as key and value to encoder-decoder attention layer.     \nHow students performed in past is used as decoder input. The first layer of decoder will learn relationship between responses, how long they took for a question task and time gap between different task user answered. The output sequence from first decoder layer is forward to second layer as query. The intuitive explanation is right now we have past experince of knowledge (query), how will a student perform (weighted value vector) for a sequence of questions (key, value).    \nBesides, Causal Mask as shown below is applied to all of encoder & decoder layers to prevent future data leakage. \nAdd prior_question_had_explanation to encoder, provide information whether a user watched answer or explanation of last quecstion.     \nAdd prior_user_answer to decoder, provide information of answer stream. Like if a student picked same choice of answer (A,A,A,A for instance) for a sequence of questions, he/she is probably be wrong for next question.    \nBoth time features are scaled by nature log to help model converge more quickly and easily.     \nUse concatenate instead of plus to combine information from different embeddings and add position embedding with a learnable weighting factor.     \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8820082957548422,
        0.8971579653313819,
        0.8894959908395049
      ],
      "excerpt": "Data is derived from kaggler: tito's strategy notebook. \nBecause this is a time series competition, training and validation dataset should be split by time. If we only use last several rows for each user as validation, we'll probably focusing too much on heavy user. But timestamp feature in original data only specified time the question be finished since the user's first event. We have no idea what's actual time in real world!   \ntito used a strategy that it first finds maximum timestamp over all users and uses it as upper bound. Then for each user's own maximum timestamp, Max_TimeStamp subtracts this timestamp to get a interval that when user might start his/her first event. Finally, random select a time within this interval to get \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.940566054896292
      ],
      "excerpt": "Training/Validation/Inference group data notebook \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Saint+: A time series transformer model to predict users' performance of future questions.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Chang-Chia-Chi/SaintPlus-Knowledge-Tracing-Pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 22 Dec 2021 11:18:57 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Chang-Chia-Chi/SaintPlus-Knowledge-Tracing-Pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Chang-Chia-Chi/SaintPlus-Knowledge-Tracing-Pytorch",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.989971822083262,
        0.969098174444013
      ],
      "excerpt": "git clone https://github.com/Chang-Chia-Chi/SaintPlus-Knowledge-Tracing-Pytorch.git     \ncd SaintPlus-Knowledge-Tracing-Pytorch    \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8627029614094055,
        0.8880636280088927,
        0.958402584740488
      ],
      "excerpt": "(P.S. You could also run pre_process.py but you have to concatenate train/validation dataframe from tito first and download it. Besides, question csv from competition is also required. Then set correct file path in pre_process.py and run. \nAdjust hyperparameter in parser.py \nRun python train.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8475868586397524
      ],
      "excerpt": "kaggle training notebook  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Chang-Chia-Chi/SaintPlus-Knowledge-Tracing-Pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SaintPlus-Knowledge-Tracing-Transformer",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SaintPlus-Knowledge-Tracing-Pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Chang-Chia-Chi",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Chang-Chia-Chi/SaintPlus-Knowledge-Tracing-Pytorch/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Wed, 22 Dec 2021 11:18:57 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "python",
      "kaggle-competition",
      "transformer",
      "pytorch",
      "time-series-forecasting"
    ],
    "technique": "GitHub API"
  }
}
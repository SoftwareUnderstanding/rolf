{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1911.00792",
      "https://arxiv.org/abs/1810.04805",
      "https://arxiv.org/abs/1911.00792"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If our work is helpful to your research, please cite it:\n\n```\n@misc{heinsen2019algorithm,\n    title={An Algorithm for Routing Capsules in All Domains},\n    author={Franz A. Heinsen},\n    year={2019},\n    eprint={1911.00792},\n    archivePrefix={arXiv},\n    primaryClass={cs.LG}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{heinsen2019algorithm,\n    title={An Algorithm for Routing Capsules in All Domains},\n    author={Franz A. Heinsen},\n    year={2019},\n    eprint={1911.00792},\n    archivePrefix={arXiv},\n    primaryClass={cs.LG}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/glassroom/heinsen_routing",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-14T15:52:45Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-08T07:21:53Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.98378252072726,
        0.8565708089349054,
        0.9028416250097643,
        0.9933278093045601,
        0.9856425068534892,
        0.9937634071380811,
        0.9895982713696028,
        0.9169454656865111
      ],
      "excerpt": "Official implementation of \"An Algorithm for Routing Capsules in All Domains\" (Heinsen, 2019) in PyTorch. This learning algorithm, without change, achieves state-of-the-art results in two domains, vision and language. \nFor example, a capsule network using this algorithm outperforms Hinton et al. (2018)'s capsule network on a visual task using fewer parameters and requiring an order of magnitude less training. A capsule network using the same algorithm outperforms BERT on a language task. In both of these examples, the same training regime was used to train the model (same hyperparameters, learning rate schedule, regularization, etc.). \nYou can easily add the algorithm as a new layer to any model to improve its performance. Try it! \nInitial evaluations show that our learning algorithm, without change, achieves state-of-the-art results in two domains, vision and language. In our experience, this is unusual, and therefore worthy of attention and further research: \nMoreover, we find evidence that our learning algorithm, when we apply it to a visual recognition task, learns to perform a form of \"reverse graphics.\" The following visualization, from our paper, shows a two-dimensional approximation of the trajectories of the pose vectors of an activated class capsule as we change viewpoint elevation of the same object from one image to the next: \nOur algorithm is a new, general-purpose form of \"routing by agreement\" (Hinton et al., 2018) which uses expectation-maximization (EM) to cluster similar votes from input capsules to output capsules in a layer of a neural network. A capsule is a group of neurons whose outputs represent different properties of the same entity in different contexts. Routing by agreement is an iterative form of clustering in which each output capsule detects an entity by looking for agreement among votes from input capsules that have already detected parts of the entity in a previous layer. \nIf you wish to replicate our results, we recommend recreating our setup in a virtual Python environment, with the same versions of all libraries and dependencies. Runing the code requires at least one Nvidia GPU with 11GB+ RAM, along with a working installation of CUDA 10 or newer. The code is meant to be easily modifiable to work with greater numbers of GPUs, or with TPUs. It is also meant to be easily modifiable to work with frameworks other than PyTorch (as long as they support Einsten summation notation for describing multilinear operations), such as TensorFlow. \nTo replicate our environment and results, follow these steps: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9888256616137182,
        0.8724590738672514
      ],
      "excerpt": "The results shown in the paper were obtained by training each model 10 times and using the end-of-training snapshot with the lowest validation error for testing. Some variability in training is normal, because each output capsule must learn to execute an expectation-maximization (EM) loop, which is known to be sensitive to initialization. As we mention in the paper, you may be able to obtain better performance with more careful tweaking of layer sizes and training regime. \nWe have made pretrained weights available for the smallNORB and SST models: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "model = SmallNORBClassifier(n_objs=5, n_parts=64, d_chns=64) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Official implementation of \"An Algorithm for Routing Capsules in All Domains\" (Heinsen, 2019) in PyTorch.",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://nbconvert.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/glassroom/heinsen_routing/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 10,
      "date": "Mon, 27 Dec 2021 12:53:33 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/glassroom/heinsen_routing/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "glassroom/heinsen_routing",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/glassroom/heinsen_routing/master/SST_training.ipynb",
      "https://raw.githubusercontent.com/glassroom/heinsen_routing/master/smallNORB_training.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Download one file: [heinsen_routing.py](heinsen_routing.py).\n2. Import the module: `from heinsen_routing import Routing`.\n3. Use it as shown above.\n\nNote: requires a working installation of [PyTorch](https://pytorch.org).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8761364140681921
      ],
      "excerpt": "If you wish to replicate our results, we recommend recreating our setup in a virtual Python environment, with the same versions of all libraries and dependencies. Runing the code requires at least one Nvidia GPU with 11GB+ RAM, along with a working installation of CUDA 10 or newer. The code is meant to be easily modifiable to work with greater numbers of GPUs, or with TPUs. It is also meant to be easily modifiable to work with frameworks other than PyTorch (as long as they support Einsten summation notation for describing multilinear operations), such as TensorFlow. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9142708131943249,
        0.9252554586938889,
        0.9748314483585809,
        0.92592487629568,
        0.9973888716298099,
        0.9958776959782978,
        0.9959187824361477,
        0.9754272386554153
      ],
      "excerpt": "Create a new Python 3 virtual environment: \nvirtualenv --python=python3 python \nActivate the virtual environment: \nsource ./python/bin/activate \nInstall required Python libraries in environment: \npip install --upgrade pip \npip install --upgrade -r requirements.txt \nInstall other dependencies: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9809116195345331,
        0.9809116195345331
      ],
      "excerpt": "git clone https://github.com/glassroom/torch_train_test_loop.git deps/torch_train_test_loop \ngit clone https://github.com/ndrplz/small_norb.git deps/small_norb \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8080002376980483
      ],
      "excerpt": "cd .data/smallnorb \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd ../.. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.977422141434073
      ],
      "excerpt": "Make sure the virtual environment is activated beforehand. Also, you may want to modify the code to use more than one GPU device (recommended). You can run the notebooks non-interactively or interactively: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8929909901774887
      ],
      "excerpt": "We have tested our code only on Ubuntu Linux 18.04 with Python 3.6+. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8900486270063179,
        0.8313987326114234
      ],
      "excerpt": "from models import SmallNORBClassifier, SSTClassifier \n: Load pretrained smallNORM model. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/glassroom/heinsen_routing/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 GlassRoom Software LLC\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "heinsen_routing",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "heinsen_routing",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "glassroom",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/glassroom/heinsen_routing/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 40,
      "date": "Mon, 27 Dec 2021 12:53:33 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "em-routing",
      "heinsen-routing",
      "capsule-network",
      "routing-algorithm",
      "capsules",
      "paper",
      "pytorch"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Detect objects from their component parts in images:\n\n```python\nfrom heinsen_routing import Routing\n\npart_scores = torch.randn(100)       #: 100 scores, one per detected part\npart_poses = torch.randn(100, 4, 4)  #: 100 capsules, each a 4 x 4 pose matrix\n\ndetect_objs = Routing(d_cov=4, d_inp=4, d_out=4, n_inp=100, n_out=10)\nobj_scores, obj_poses, obj_poses_sig2 = detect_objs(part_scores, part_poses)\n\nprint(obj_scores)                    #: 10 scores, one per detected object\nprint(obj_poses)                     #: 10 capsules, each a 4 x 4 pose matrix\n```\n\nClassify sequences of token embeddings:\n\n```python\nfrom heinsen_routing import Routing\n\ntok_scores = torch.randn(n)          #: token scores, n is variable\ntok_embs = torch.randn(n, 1024)      #: token embeddings, n is variable\ntok_embs = tok_embs.unsqueeze(1)     #: reshape to n x 1 x 1024 (n matrices)\n\nclassify = Routing(d_cov=1, d_inp=1024, d_out=8, n_out=2)  #: variable n_inp\nclass_scores, class_embs, class_embs_sig2 = classify(tok_scores, tok_embs)\n\nprint(class_scores)                  #: 2 scores, one per class\nprint(class_embs)                    #: 2 capsules, each a 1 x 8 matrix\n```\n\nPredict variable numbers of targets:\n\n```python\nfrom heinsen_routing import Routing\n\nattr_scores = torch.randn(10)        #: 10 scores\nattr_caps = torch.randn(10, 1, 256)  #: 10 capsules with 1 x 256 features\n\npredict = Routing(d_cov=1, d_inp=256, d_out=64, n_inp=10)  #: variable n_out\npred_scores, pred_caps, pred_caps_sig2 = predict(attr_scores, attr_caps, n_out=n)\n\nprint(pred_scores)                   #: n scores, one per prediction\nprint(pred_caps)                     #: n capsules with 1 x 64 features\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
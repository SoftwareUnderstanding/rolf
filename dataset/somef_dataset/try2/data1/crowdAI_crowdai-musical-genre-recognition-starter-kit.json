{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1612.01840\n[challenge_paper]: https://arxiv.org/abs/1803.05337\n[challenge_slides]: https://doi.org/10.5281/zenodo.1243501\n\n## Results\n\n| Team              | Round 1 <br> leaderboard <br> 35k clips <br> log loss | Round 1 <br> subset <br> 3k clips <br> log loss | Round 2 <br> secret <br> 3k clips <br> log loss | Rank | Round 1 <br> leaderboard <br> 35k clips <br> F1 score | Round 1 <br> subset <br> 3k clips <br> F1 score | Round 2 <br> secret <br> 3k clips <br> F1 score |\n|-------------------|:----:|:----:|:--------:|:---:|:---:|:---:|:---:|\n| minzwon & jaehun  | 0.55 | 0.67 | **1.31** |  1  | 85% | 80% | 63% |\n| hglim             | 0.33 | 0.34 | **1.34** |  2  | 92% | 92% | 64% |\n| benjamin_murauer  | 0.82 | 0.86 | **1.44** |  3  | 74% | 74% | 60% |\n| gg12 & check      | 0.66 | 0.49 | **1.50** |  4  | 80% | 86% | 61% |\n| viper & algohunt  | 0.66 | 0.65 | **1.52** |  5  | 80% | 81% | 60% |\n| mimbres           | 0.41 | 0.43 | **2.08** |  6  | 90% | 90% | 60% |\n\nThe three columns per metric references:\n1. the best scores obtained on the public leaderboard during the first round,\n1. the scores obtained by the submitted systems on a subset of the public test set,\n1. the scores obtained by the submitted systems on a private test set collected for the second round.\n\nFind more details in the [slides used to announce the\nresults][challenge_slides] and in the [overview paper][challenge_paper].\n\nIn the interest of reproducibility and transparency for interested\nresearchers, you'll find below links to the source code repositories of all\nsystems submitted by the participants for the second round of the challenge.\nThanks to all the participants for making this happen!\n\n1. Transfer Learning of Artist Group Factors to Musical Genre Classification\n\t* Jaehun Kim ([@jaehun]",
      "https://arxiv.org/abs/1803.05337\n[challenge_slides]: https://doi.org/10.5281/zenodo.1243501\n\n## Results\n\n| Team              | Round 1 <br> leaderboard <br> 35k clips <br> log loss | Round 1 <br> subset <br> 3k clips <br> log loss | Round 2 <br> secret <br> 3k clips <br> log loss | Rank | Round 1 <br> leaderboard <br> 35k clips <br> F1 score | Round 1 <br> subset <br> 3k clips <br> F1 score | Round 2 <br> secret <br> 3k clips <br> F1 score |\n|-------------------|:----:|:----:|:--------:|:---:|:---:|:---:|:---:|\n| minzwon & jaehun  | 0.55 | 0.67 | **1.31** |  1  | 85% | 80% | 63% |\n| hglim             | 0.33 | 0.34 | **1.34** |  2  | 92% | 92% | 64% |\n| benjamin_murauer  | 0.82 | 0.86 | **1.44** |  3  | 74% | 74% | 60% |\n| gg12 & check      | 0.66 | 0.49 | **1.50** |  4  | 80% | 86% | 61% |\n| viper & algohunt  | 0.66 | 0.65 | **1.52** |  5  | 80% | 81% | 60% |\n| mimbres           | 0.41 | 0.43 | **2.08** |  6  | 90% | 90% | 60% |\n\nThe three columns per metric references:\n1. the best scores obtained on the public leaderboard during the first round,\n1. the scores obtained by the submitted systems on a subset of the public test set,\n1. the scores obtained by the submitted systems on a private test set collected for the second round.\n\nFind more details in the [slides used to announce the\nresults][challenge_slides] and in the [overview paper][challenge_paper].\n\nIn the interest of reproducibility and transparency for interested\nresearchers, you'll find below links to the source code repositories of all\nsystems submitted by the participants for the second round of the challenge.\nThanks to all the participants for making this happen!\n\n1. Transfer Learning of Artist Group Factors to Musical Genre Classification\n\t* Jaehun Kim ([@jaehun]",
      "https://arxiv.org/abs/1610.02357",
      "https://arxiv.org/abs/1707.01629",
      "https://arxiv.org/abs/1803.05337},\n}\n```"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{fma_crowdai_challenge,\n  title = {Learning to Recognize Musical Genre from Audio},\n  author = {Defferrard, Micha\\\"el and Mohanty, Sharada P. and Carroll, Sean F. and Salath\\'e, Marcel},\n  booktitle = {WWW '18 Companion: The 2018 Web Conference Companion},\n  year = {2018},\n  url = {https://arxiv.org/abs/1803.05337},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9343900839872272,
        0.9268240064709804,
        0.9997950470568385
      ],
      "excerpt": "Jaehun Kim (@jaehun), TU Delft and Minz Won (@minzwon), Universitat Pompeu Fabra \nCode: https://gitlab.crowdai.org/minzwon/WWWMusicalGenreRecognitionChallenge \nPaper: https://doi.org/10.1145/3184558.3191823 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9268240064709804
      ],
      "excerpt": "Code: https://gitlab.crowdai.org/hglim/WWWMusicalGenreRecognitionChallenge \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9268240064709804,
        0.9997950470568385
      ],
      "excerpt": "Code: https://gitlab.crowdai.org/Benjamin_Murauer/WWWMusicalGenreRecognitionChallenge \nPaper: https://doi.org/10.1145/3184558.3191822 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9268240064709804
      ],
      "excerpt": "Code: https://gitlab.crowdai.org/gg12/WWWMusicalGenreRecognitionChallenge \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9268240064709804
      ],
      "excerpt": "Code: https://gitlab.crowdai.org/viper/crowdai-viper \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9104388306336967,
        0.9268240064709804
      ],
      "excerpt": "Sungkyun Chang (@mimbres), Seoul National University \nCode: https://gitlab.crowdai.org/mimbres/WWWMusicalGenreRecognitionChallenge \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8400251224554877
      ],
      "excerpt": "and a timeout of 10 hours. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/crowdAI/crowdai-musical-genre-recognition-starter-kit",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-12-01T22:26:00Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-01T10:13:39Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9362552484337541,
        0.9694667870764393
      ],
      "excerpt": "Starter kit for the WWW2018 challenge \"Learning to Recognize Musical Genre\" hosted on CrowdAI. \nThe following overview paper summarizes our experience running a challenge with open data for musical genre recognition. Those notes motivate the task and the challenge design, show some statistics about the submissions, and present the results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9402792052215719
      ],
      "excerpt": "are encouraged to check out that repository for Jupyter notebooks showing how \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9425769449769514,
        0.9258083908169606
      ],
      "excerpt": "uses the rc1 version of the data, make sure to checkout that version of the \ncode. The associated paper describes the data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9203343436183412,
        0.900220302361386,
        0.9855811766186036
      ],
      "excerpt": "Find more details in the slides used to announce the \nresults and in the overview paper. \nIn the interest of reproducibility and transparency for interested \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.877019049925074,
        0.9816382977355476,
        0.9804045890539343,
        0.908925214220865
      ],
      "excerpt": "systems submitted by the participants for the second round of the challenge. \nThanks to all the participants for making this happen! \nTransfer Learning of Artist Group Factors to Musical Genre Classification \nJaehun Kim (@jaehun), TU Delft and Minz Won (@minzwon), Universitat Pompeu Fabra \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9617625404225586
      ],
      "excerpt": "Ensemble of CNN-based Models using various Short-Term Input \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8372396012058242,
        0.9225765337981583
      ],
      "excerpt": "ConvNet on STFT spectrograms \nDaniyar Chumbalov (@check), EPFL and Philipp Pushnyakov (@gg12), Moscow Institute of Physics and Technologies (MIPT) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8372396012058242,
        0.908925214220865
      ],
      "excerpt": "Xception on mel-scaled spectrograms \n@viper and @algohunt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.867305063073487
      ],
      "excerpt": "execute any of the systems on your own mp3s by following those steps: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8681962494522271,
        0.9042156508941868
      ],
      "excerpt": "It will be used by our grading orchestrator to predict the genres for all the files in a secret test set. \nThe systems have to be submitted as binder compatible repositories. You'll find all the details to package and submit your code in the following documents: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8229110481741653
      ],
      "excerpt": "During the execution of the container, all the mp3 files will be mounted at /crowdai-payload. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359001709648448
      ],
      "excerpt": "During the runtime, the container will not have access to the external Internet, and will have access to: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9832382048878661,
        0.9968029537584643,
        0.8106422009563552
      ],
      "excerpt": "5 cores of an Intel Xeon E5-2650 v4 (2.20-2.90 GHz), \n60 GB of RAM, \n100 GB of disk, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8895342617013974,
        0.911124445306531,
        0.9607760708602763
      ],
      "excerpt": "At the end of the process, your model will simply be an \"executable\" git \nrepository. Please provide an open-source license and a README with an \nexecutive summary of how your system works. At the end of the challenge, we'll \n",
      "technique": "Supervised classification"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://mybinder.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/crowdAI/crowdai-musical-genre-recognition-starter-kit/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 21,
      "date": "Mon, 27 Dec 2021 11:37:37 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/crowdAI/crowdai-musical-genre-recognition-starter-kit/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "crowdAI/crowdai-musical-genre-recognition-starter-kit",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/crowdAI/crowdai-musical-genre-recognition-starter-kit/master/run.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[datasets]: https://www.crowdai.org/challenges/www-2018-challenge-learning-to-recognize-musical-genre/dataset_files\n\nDownload and extract [datasets] such as:\n* Training metadata `csv` files from `fma_metadata.zip` are accessible at `data/fma_metadata/*.csv`.\n* Training `mp3` files from `fma_medium.zip` are accessible at `data/fma_medium/*/*.mp3`.\n* Test `mp3` files from `fma_crowdai_www2018_test.tar.gz` are accessible at `data/crowdai_fma_test/*.mp3`.\n\n```sh\ngit clone https://github.com/crowdAI/crowdai-musical-genre-recognition-starter-kit\ncd crowdai-musical-genre-recognition-starter-kit\npip install -r requirements.txt\n```\n\n**NOTE**: This challenge requires `crowdai` version 1.0.14 at least.\nThe code in this repository and the [FMA repository][fma_repo] has been tested with Python 3.6 only.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8978185981163689,
        0.930798662702776
      ],
      "excerpt": "execute any of the systems on your own mp3s by following those steps: \n1. Clone the git repository. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8153719825575283
      ],
      "excerpt": "Execution of your container will be initiated by executing /home/run.sh. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8083906070468602
      ],
      "excerpt": "1 Nvidia GTX GeForce 1080 Ti (11 GB GDDR5X), \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/crowdAI/crowdai-musical-genre-recognition-starter-kit/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "crowdai-musical-genre-recognition-starter-kit",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "crowdai-musical-genre-recognition-starter-kit",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "crowdAI",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/crowdAI/crowdai-musical-genre-recognition-starter-kit/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 57,
      "date": "Mon, 27 Dec 2021 11:37:37 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Run `python convert.py` to convert `data/fma_metadata/tracks.csv` to a simpler\n`data/train_labels.csv` file where the first column is the `track_id` and the\nsecond column is the target musical genre.\n\nYou can now load the training labels with:\n```python\nimport pandas as pd\nlabels = pd.read_csv('data/train_labels.csv', index_col=0)\n```\n\nThe path to the training mp3 with a `track_id` of 2 is given by:\n```python\nimport fma\npath = fma.get_audio_path(2)\n```\nand can be loaded as a numpy array with:\n```python\nimport librosa\nx, sr = librosa.load(path, sr=None, mono=False)\n```\n\nThe list of testing file IDs can be obtained with:\n```python\nimport glob\ntest_ids = sorted(glob.glob('data/crowdai_fma_test/*.mp3'))\ntest_ids = [path.split('/')[-1][:-4] for path in test_ids]\n```\nand the path to a testing mp3 is given by:\n```python\npath = 'data/crowdai_fma_test/{}.mp3'.format(test_ids[0])\n```\n\nThe submission file can be created with:\n```python\nCLASSES = ['Blues', 'Classical', 'Country', 'Easy Listening', 'Electronic',\n           'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International',\n           'Jazz', 'Old-Time / Historic', 'Pop', 'Rock', 'Soul-RnB', 'Spoken']\n\nsubmission = pd.DataFrame(1/16, pd.Index(test_ids, name='file_id'), CLASSES)\nsubmission.to_csv('data/submission.csv', header=True)\n```\nand then submitted with:\n```python\nimport crowdai\nAPI_KEY = '<your_crowdai_api_key_here>'\nchallenge = crowdai.Challenge('WWWMusicalGenreRecognitionChallenge', API_KEY)\nresponse = challenge.submit('data/submission.csv')\nprint(response['message'])\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "The [random_submission.py](random_submission.py) script submits random\npredictions, to be run as:\n```sh\npython random_submission.py --round=1 --api_key=<YOUR CROWDAI API KEY>\n```\n\nThe [features.py](features.py) script extracts many audio features (with the\nhelp of [librosa]) from all training and testing mp3s. Extracted features are\nstored in `data/features.csv`. Script to be run as:\n```sh\npython features.py\n```\nNote that this script can take many hours to complete on the whole 60k tracks.\nFor you to play with the data right away, you'll find those features\npre-computed on the [challenge's dataset page][datasets].\n\nThe [baseline_svm.py](baseline_svm.py) script trains a [support vector\nclassifier (SVC)][svc] with `data/train_labels.csv` as target and\n`data/features.csv` as features. The predictions are stored in\n`data/submission_svm.csv`. Script to be run as:\n```sh\npython baseline_svm.py\n```\n\nFinally, a prediction can be submitted with the [submit.py](submit.py) script:\n```sh\npython submit.py --api_key=<YOUR CROWDAI API KEY> data/submission.csv\n```\n\n[librosa]: https://github.com/librosa/librosa\n[svc]: http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1611.01576",
      "https://arxiv.org/abs/1611.01576"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{bradbury2016quasi,\n  title={{Quasi-Recurrent Neural Networks}},\n  author={Bradbury, James and Merity, Stephen and Xiong, Caiming and Socher, Richard},\n  journal={International Conference on Learning Representations (ICLR 2017)},\n  year={2017}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9995457175598671
      ],
      "excerpt": "If you use this code or our results in your research, please cite: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8579561142376856
      ],
      "excerpt": "    - cuda: If True, use the fast element-wise CUDA kernel for recurrence. If False, uses naive for loop. Default: True. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/salesforce/pytorch-qrnn",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-09-27T20:16:39Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-19T09:50:12Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.976870172783056,
        0.8505442587181736
      ],
      "excerpt": "This repository contains a PyTorch implementation of Salesforce Research's Quasi-Recurrent Neural Networks paper. \nThe QRNN provides similar accuracy to the LSTM but can be betwen 2 and 17 times faster than the highly optimized NVIDIA cuDNN LSTM implementation depending on the use case. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8362475644423449,
        0.8920693744557241,
        0.9397965245787145,
        0.8365063701733141,
        0.9033260746167227,
        0.9193496940296467
      ],
      "excerpt": "Speeds are between 2 and 17 times faster than NVIDIA's cuDNN LSTM, with the difference as a result of varying batch size and sequence length. \nThe largest gains are for small batch sizes or long sequence lengths, both highlighting the LSTMs parallelization difficulty due to forced sequentiality. \nFor full information, refer to the Quasi-Recurrent Neural Networks paper. \nPictured above is Figure 4 from the QRNN paper: \nLeft: Training speed for two-layer 640-unit PTB LM on a batch of 20 examples of 105 timesteps. \u201cRNN\u201d and \u201csoftmax\u201d include the forward and backward times, while \u201coptimization overhead\u201d includes gradient clipping, L2 regularization, and SGD computations. \nRight: Inference speed advantage of a 320-unit QRNN layer alone over an equal-sized cuDNN LSTM layer for data with the given batch size and sequence length. Training results are similar. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8664249775976256,
        0.9189051419044971,
        0.8019961753658447
      ],
      "excerpt": "The ForgetMult takes two arguments - the candidate input x and forget gates f - and computes h = f * x + (1 - f) * hm1 where hm1 is the previous hidden state output. \nThe QRNN class is a thin wrapper around this that performs the large matrix multiplications for the candidate x, the forget gates f, and the output gates o. \nAny other operation which requires recurrence and can have precomputed values for the candidate x and forget gates f can use this fast form of recurrence. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8133501934266081
      ],
      "excerpt": "This equation is equivalent to dynamic weighted averaging. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.94094552664047
      ],
      "excerpt": "    - X (seq_len, batch, input_size): tensor containing the features of the input sequence. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8301456881605556
      ],
      "excerpt": "    - hidden_init (batch, input_size): tensor containing the initial hidden state for the recurrence (h_{t-1}). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "PyTorch implementation of the Quasi-Recurrent Neural Network - up to 16 times faster than NVIDIA's cuDNN LSTM",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/salesforce/pytorch-qrnn/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 193,
      "date": "Sun, 26 Dec 2021 07:24:44 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/salesforce/pytorch-qrnn/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "salesforce/pytorch-qrnn",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9741498677201467,
        0.999436300804454
      ],
      "excerpt": "To install, simply run: \npip install cupy pynvrtc git+https://github.com/salesforce/pytorch-qrnn \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8854588189844136
      ],
      "excerpt": "Example usage of the ForgetMult module: output = ForgetMult()(f, x, hidden). \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/salesforce/pytorch-qrnn/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\n\\nCopyright (c) 2017, \\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n Redistributions of source code must retain the above copyright notice, this\\n  list of conditions and the following disclaimer.\\n\\n Redistributions in binary form must reproduce the above copyright notice,\\n  this list of conditions and the following disclaimer in the documentation\\n  and/or other materials provided with the distribution.\\n\\n* Neither the name of the copyright holder nor the names of its\\n  contributors may be used to endorse or promote products derived from\\n  this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Quasi-Recurrent Neural Network (QRNN) for PyTorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pytorch-qrnn",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "salesforce",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/salesforce/pytorch-qrnn/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This codebase requires Python 3, [PyTorch](http://pytorch.org/), [pynvrtc](https://github.com/NVIDIA/pynvrtc) (NVIDIA's Python Bindings to NVRTC), and [CuPy](https://cupy.chainer.org/).\nWhile the codebase contains a CPU implementation of the QRNN, the GPU QRNN implementation is used by default if possible.\nRequirements are provided in `requirements.txt`.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1232,
      "date": "Sun, 26 Dec 2021 07:24:44 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "First, thanks! :)\n\nOpen tasks that are interesting:\n\n+ Modify the `ForgetMult` CUDA kernel to produce a `BackwardForgetMult`. This will enable a bidirectional QRNN. The input should be the same - `f` and `x` - but the kernel should walk backwards through the inputs.\n+ Bidirectional QRNN support (requires the modification above)\n+ Support PyTorch's `PackedSequence` such that variable length sequences are correctly masked\n+ Show how to use the underlying fast recurrence operator `ForgetMult` in other generic ways\n",
      "technique": "Header extraction"
    }
  ],
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We've updated the previously released Salesforce Research [AWD-LSTM language modeling](https://github.com/salesforce/awd-lstm-lm) codebase to support use of the `AWD-QRNN`.\nWith the same number of parameters as the LSTM and less well tuned hyper parameters, the QRNN model trains over twice as quickly and achieves nearly equivalent state-of-the-art language modeling results.\nFor full details, refer to the [AWD-LSTM-LM repository](https://github.com/salesforce/awd-lstm-lm).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "The QRNN API is meant to be drop-in compatible with the [LSTM](http://pytorch.org/docs/master/_modules/torch/nn/modules/rnn.html#LSTM) for many standard use cases.\nAs such, the easiest thing to do is replace any `GRU` or `LSTM` module with the `QRNN`.\n\nNote: bidirectional QRNN is not yet supported though will be in the near future.\n\n```python\nimport torch\nfrom torchqrnn import QRNN\n\nseq_len, batch_size, hidden_size = 7, 20, 256\nsize = (seq_len, batch_size, hidden_size)\nX = torch.autograd.Variable(torch.rand(size), requires_grad=True).cuda()\n\nqrnn = QRNN(hidden_size, hidden_size, num_layers=2, dropout=0.4)\nqrnn.cuda()\noutput, hidden = qrnn(X)\n\nprint(output.size(), hidden.size())\n```\n\nThe full documentation for the `QRNN` is listed below:\n\n```\nQRNN(input_size, hidden_size, num_layers, dropout=0):\n    Applies a multiple layer Quasi-Recurrent Neural Network (QRNN) to an input sequence.\n\n    Args:\n        input_size: The number of expected features in the input x.\n        hidden_size: The number of features in the hidden state h. If not specified, the input size is used.\n        num_layers: The number of QRNN layers to produce.\n        layers: List of preconstructed QRNN layers to use for the QRNN module (optional).\n        save_prev_x: Whether to store previous inputs for use in future convolutional windows (i.e. for a continuing sequence such as in language modeling). If true, you must call reset to remove cached previous values of x. Default: False.\n        window: Defines the size of the convolutional window (how many previous tokens to look when computing the QRNN values). Supports 1 and 2. Default: 1.\n        zoneout: Whether to apply zoneout (i.e. failing to update elements in the hidden state) to the hidden state updates. Default: 0.\n        output_gate: If True, performs QRNN-fo (applying an output gate to the output). If False, performs QRNN-f. Default: True.\n        use_cuda: If True, uses fast custom CUDA kernel. If False, uses naive for loop. Default: True.\n\n    Inputs: X, hidden\n        - X (seq_len, batch, input_size): tensor containing the features of the input sequence.\n        - hidden (layers, batch, hidden_size): tensor containing the initial hidden state for the QRNN.\n\n    Outputs: output, h_n\n        - output (seq_len, batch, hidden_size): tensor containing the output of the QRNN for each timestep.\n        - h_n (layers, batch, hidden_size): tensor containing the hidden state for t=seq_len\n```\n\nThe included QRNN layer supports convolutional windows of size 1 or 2 but will be extended in the future to support arbitrary convolutions.\n\nIf you are using convolutional windows of size 2 (i.e. looking at the inputs from two previous timesteps to compute the input) and want to run over a long sequence in batches, such as when using BPTT, you can set `save_prev_x=True` and call `reset` when you wish to reset the cached previous inputs.\n \nIf you want flexibility in the definition of each QRNN layer, you can construct individual `QRNNLayer` modules and pass them to the `QRNN` module using the `layer` argument.\n\n",
      "technique": "Header extraction"
    }
  ]
}
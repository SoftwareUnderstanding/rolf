{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2105.08127",
      "https://arxiv.org/abs/1907.02544",
      "https://arxiv.org/abs/2006.10728",
      "https://arxiv.org/abs/1912.04958"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bibtex\n@inproceedings{melaskyriazi2021finding,\n  author    = {Melas-Kyriazi, Luke and Rupprecht, Christian and Laina, Iro and Vedaldi, Andrea},\n  title     = {Finding an Unsupervised Image Segmenter in each of your Deep Generative Models},\n  booktitle = arxiv,\n  year      = {2021}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{melaskyriazi2021finding,\n  author    = {Melas-Kyriazi, Luke and Rupprecht, Christian and Laina, Iro and Vedaldi, Andrea},\n  title     = {Finding an Unsupervised Image Segmenter in each of your Deep Generative Models},\n  booktitle = arxiv,\n  year      = {2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9999752349464645
      ],
      "excerpt": "<!-- [![Conference](http://img.shields.io/badge/CVPR-2021-4b44ce.svg)](https://papers.nips.cc/book/advances-in-neural-information-processing-systems-31-2018) --> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lukemelas/unsupervised-image-segmentation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-05T22:11:54Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T14:48:44Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Recent research has shown that numerous human-interpretable directions exist in the latent space of GANs. In this paper, we develop an automatic procedure for finding directions that lead to foreground-background image separation, and we use these directions to train an image segmentation model without human supervision. Our method is generator-agnostic, producing strong segmentation results with a wide range of different GAN architectures. Furthermore, by leveraging GANs pretrained on large datasets such as ImageNet, we are able to segment images from a range of domains without further training or finetuning. Evaluating our method on image segmentation benchmarks, we compare favorably to prior work while using neither human supervision nor access to the training data. Broadly, our results demonstrate that automatically extracting foreground-background structure from pretrained deep generative models can serve as a remarkably effective substitute for human supervision. \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9294851143310638
      ],
      "excerpt": "Our unsupervised segmentation approach has two steps: (1) finding a good direction in latent space, and (2) training a segmentation model from data and masks that are generated using this direction.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9300007485017056
      ],
      "excerpt": " 1. We use optimization/main.py finds a salient direction (or two salient directions) in the latent space of a given pretrained GAN that leads to foreground-background image separation.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8997254394395016
      ],
      "excerpt": "The structure of the configs is as follows:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8556679073270878,
        0.863688043943891,
        0.9193946620997714
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 generated.yaml  #: &lt;- for generating data with 1 latent direction \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 generated-dual.yaml   #: &lt;- for generating data with 2 latent directions \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 generator  #: &lt;- different types of GANs for generating data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8629549961461492
      ],
      "excerpt": "The code is structured as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Finding an Unsupervised Image Segmenter in each of your Deep Generative Models",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lukemelas/unsupervised-image-segmentation/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Sat, 25 Dec 2021 11:25:35 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lukemelas/unsupervised-image-segmentation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "lukemelas/unsupervised-image-segmentation",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8631447719377787
      ],
      "excerpt": "We use Hydra for configuration and Weights and Biases for logging. With Hydra, you can specify a config file (found in configs/) with --config-name=myconfig.yaml. You can also override the config from the command line by specifying the overriding arguments (without --). For example, you can enable Weights and Biases with wandb=True and you can name the run with name=myname.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8823102435441175
      ],
      "excerpt": "The datasets should have the following structure. You can easily add you own datasets or use only a subset of these datasets by modifying config/segment.yaml. You should specify your directory by modifying root in that file on line 19, or by passing data_seg.root=MY_DIR using the command line whenever you call python segmentation/main.py.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8157536551057836
      ],
      "excerpt": "The datasets can be downloaded from: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8728510858857873
      ],
      "excerpt": "Note: All commands are called from within the src directory.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "name=NAME \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8816006402268479
      ],
      "excerpt": "This will generate 1 million image-label pairs and save them to YOUR_OUTPUT_DIR/images. Note that YOUR_OUTPUT_DIR should be an absolute path, not a relative one, because Hydra changes the working directory. You may also want to tune the generation_batch_size to maximize GPU utilization on your machine. It takes around 3-4 hours to generate 1 million images on a single V100 GPU. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "name=NAME \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8796394427874537
      ],
      "excerpt": "It takes around 3 hours on 1 GPU to complete 18000 iterations, by which point the model has converged (in fact you can probably get away with fewer steps, I would guess around ~5000).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "name=NAME \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8882978001404158
      ],
      "excerpt": "It should be possible to use any GAN from pytorch-pretrained-gans, including: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "\u2502   \u251c\u2500\u2500 __init__.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "\u2502   \u2514\u2500\u2500 unet_parts.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "\u2502   \u251c\u2500\u2500 __init__.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8331837595649851
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 main.py  #: &lt;- main script \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8343455104261642
      ],
      "excerpt": "PYTHONPATH=. python optimization/main.py data_gen/generator=bigbigan name=NAME \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "name=NAME \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8483057884181817,
        0.8421074476017179
      ],
      "excerpt": "PYTHONPATH=. python segmentation/main.py \\ \nname=NAME \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8204443626462709
      ],
      "excerpt": "Alternatively, you can generate data while training the segmentation model. An example script would be:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8483057884181817,
        0.8421074476017179
      ],
      "excerpt": "PYTHONPATH=. python segmentation/main.py \\ \nname=NAME \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8747347895075824
      ],
      "excerpt": "To evaluate, set the train argument to False. For example: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503189345333785,
        0.8373329412761656,
        0.870541837016169
      ],
      "excerpt": "python train.py \\ \nname=\"eval\" \\ \ntrain=False \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lukemelas/unsupervised-image-segmentation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Finding an Unsupervised Image Segmenter in each of your Deep Generative Models",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "unsupervised-image-segmentation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "lukemelas",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lukemelas/unsupervised-image-segmentation/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "lukemelas",
        "body": "",
        "dateCreated": "2021-04-12T03:54:41Z",
        "datePublished": "2021-04-26T17:19:43Z",
        "html_url": "https://github.com/lukemelas/unsupervised-image-segmentation/releases/tag/v0.0.1",
        "name": "Initial release with checkpoint",
        "tag_name": "v0.0.1",
        "tarball_url": "https://api.github.com/repos/lukemelas/unsupervised-image-segmentation/tarball/v0.0.1",
        "url": "https://api.github.com/repos/lukemelas/unsupervised-image-segmentation/releases/42022466",
        "zipball_url": "https://api.github.com/repos/lukemelas/unsupervised-image-segmentation/zipball/v0.0.1"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This code depends on [pytorch-pretrained-gans](https://github.com/lukemelas/pytorch-pretrained-gans), a repository I developed that exposes a standard interface for a variety of pretrained GANs. Install it with:\n```bash\npip install git+https://github.com/lukemelas/pytorch-pretrained-gans\n```\nThe pretrained weights for most GANs are downloaded automatically. For those that are not, I have provided scripts in that repository. \n\nThere are also some standard dependencies:\n - PyTorch (tested on version 1.7.1, but should work on any version)\n - [PyTorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning)\n - [Hydra](https://github.com/facebookresearch/hydra) 1.1\n - [Albumentations](https://github.com/albumentations-team/albumentations)\n - [Kornia](https://github.com/kornia/kornia)\n - [Retry](https://github.com/invl/retry)\n - [Optional] [Weights and Biases](https://wandb.ai/)\n \n Install them with:\n ```bash\npip install hydra-core==1.1.0dev5 pytorch_lightning albumentations tqdm retry kornia\n ```\n \n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 43,
      "date": "Sat, 25 Dec 2021 11:25:35 GMT"
    },
    "technique": "GitHub API"
  }
}
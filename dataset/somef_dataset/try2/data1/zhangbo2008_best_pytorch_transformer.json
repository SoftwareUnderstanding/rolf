{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- The project structure, some scripts and the dataset preprocessing steps are heavily borrowed from [OpenNMT/OpenNMT-py](https://github.com/OpenNMT/OpenNMT-py).\r\n- Thanks for the suggestions from @srush, @iamalbert and @ZiJianZhao.\r\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1706.03762",
      "https://arxiv.org/abs/1703.03130"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8374695145293155
      ],
      "excerpt": "wget https://raw.githubusercontent.com/moses-smt/mosesdecoder/master/scripts/share/nonbreaking_prefixes/nonbreaking_prefix.de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8729393277090676
      ],
      "excerpt": "wget https://raw.githubusercontent.com/moses-smt/mosesdecoder/master/scripts/generic/multi-bleu.perl \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zhangbo2008/best_pytorch_transformer",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-03T11:42:51Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-03T11:44:32Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9488735678091932,
        0.9397222580254985,
        0.8065455373225795
      ],
      "excerpt": "This is a PyTorch implementation of the Transformer model in \"Attention is All You Need\" (Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin, arxiv, 2017).  \nA novel sequence to sequence framework utilizes the self-attention mechanism, instead of Convolution operation or Recurrent structure, and achieve the state-of-the-art performance on WMT 2014 English-to-German translation task. (2017/06/12) \nThe official Tensorflow Implementation can be found in: tensorflow/tensor2tensor. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8797084746543432,
        0.9411896382383477,
        0.8966494816205388,
        0.8452356395237308
      ],
      "excerpt": "The project support training and translation with trained model now. \nNote that this project is still a work in progress. \nIf there is any suggestion or error, feel free to fire an issue to let me know. :) \nThe example below uses the Moses tokenizer (http://www.statmt.org/moses/) to prepare the data and the moses BLEU script for evaluation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "just run tran.py",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n```bash\r\nmkdir -p data/multi30k\r\nwget http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/training.tar.gz &&  tar -xf training.tar.gz -C data/multi30k && rm training.tar.gz\r\nwget http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/validation.tar.gz && tar -xf validation.tar.gz -C data/multi30k && rm validation.tar.gz\r\nwget http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/mmt16_task1_test.tar.gz && tar -xf mmt16_task1_test.tar.gz -C data/multi30k && rm mmt16_task1_test.tar.gz\r\n```\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zhangbo2008/best_pytorch_transformer/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 01:01:26 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/zhangbo2008/best_pytorch_transformer/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "zhangbo2008/best_pytorch_transformer",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8188069223799144
      ],
      "excerpt": "<img src=\"http://imgur.com/1krF2R6.png\" width=\"250\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8404410114723558
      ],
      "excerpt": "python preprocess.py -train_src data/multi30k/train.en.atok -train_tgt data/multi30k/train.de.atok -valid_src data/multi30k/val.en.atok -valid_tgt data/multi30k/val.de.atok -save_data data/multi30k.atok.low.pt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8813355769487233
      ],
      "excerpt": "python train.py -data data/multi30k.atok.low.pt -save_model trained -save_mode best -proj_share_weight -label_smoothing \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9350161006416731
      ],
      "excerpt": "python translate.py -model trained.chkpt -vocab data/multi30k.atok.low.pt -src data/multi30k/test.en.atok -no_cuda \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/zhangbo2008/best_pytorch_transformer/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\r\\n\\r\\nCopyright (c) 2017 Victor Huang\\r\\n\\r\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\r\\nof this software and associated documentation files (the \"Software\"), to deal\\r\\nin the Software without restriction, including without limitation the rights\\r\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\r\\ncopies of the Software, and to permit persons to whom the Software is\\r\\nfurnished to do so, subject to the following conditions:\\r\\n\\r\\nThe above copyright notice and this permission notice shall be included in all\\r\\ncopies or substantial portions of the Software.\\r\\n\\r\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\r\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\r\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\r\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\r\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\r\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\r\\nSOFTWARE.\\r\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Attention is all you need: A Pytorch Implementation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "best_pytorch_transformer",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "zhangbo2008",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zhangbo2008/best_pytorch_transformer/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- python 3.4+\r\n- pytorch 0.4.1+\r\n- tqdm\r\n- numpy\r\n\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 01:01:26 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n",
      "technique": "Header extraction"
    }
  ]
}
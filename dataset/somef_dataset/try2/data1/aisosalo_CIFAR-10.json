{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[Aleksei Tiulpin](https://github.com/lext/) is acknowledged for kindly providing access to his pipeline scripts and giving his permission to reproduce and modify his pipeline for this task.\n\n[Research Unit of Medical Imaging, Physics and Technology](https://www.oulu.fi/mipt/) is acknowledged for making it possible to run the experiments.\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1605.07146",
      "https://arxiv.org/abs/1806.00451",
      "https://arxiv.org/abs/1806.00451, 2018."
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "      (10): ReLU(inplace) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "      (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "      (30): ReLU(inplace) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9867211080294279
      ],
      "excerpt": "  <img src=\"https://github.com/aisosalo/CIFAR-10/blob/master/plots/Loss_fold_0_2019_02_25_06_20.png\" title=\"Loss over time\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9867211080294279
      ],
      "excerpt": "  <img src=\"https://github.com/aisosalo/CIFAR-10/blob/master/plots/Accuracy_fold_0_2019_02_25_06_20.png\" title=\"Validation accuracy over time\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9978754116146212
      ],
      "excerpt": "  <img src=\"https://github.com/aisosalo/CIFAR-10/blob/master/plots/CM_fold_0_epoch_39_2019_02_24_19_54.png\" title=\"Confusion Matrix, Validation, Epoch 40\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9978754116146212
      ],
      "excerpt": "  <img src=\"https://github.com/aisosalo/CIFAR-10/blob/master/plots/CM_fold_0_epoch_79_2019_02_24_20_51.png\" title=\"Confusion Matrix, Validation, Epoch 80\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9978754116146212
      ],
      "excerpt": "  <img src=\"https://github.com/aisosalo/CIFAR-10/blob/master/plots/CM_fold_0_epoch_119_2019_02_24_22_02.png\" title=\"Confusion Matrix, Validation, Epoch 120\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9978754116146212
      ],
      "excerpt": "  <img src=\"https://github.com/aisosalo/CIFAR-10/blob/master/plots/CM_fold_0_epoch_159_2019_02_24_23_27.png\" title=\"Confusion Matrix, Validation, Epoch 160\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9966468827460175
      ],
      "excerpt": "  <img src=\"https://github.com/aisosalo/CIFAR-10/blob/master/plots/CM_evaluation_2019_02_25.png\" title=\"Confusion Matrix, Evaluation\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9787239807048498,
        0.9999957963156979,
        0.9295539164898299,
        0.9740122860573481
      ],
      "excerpt": "Antti Isosalo, University of Oulu, 2018- \nZagoruyko, Sergey, and Nikos Komodakis. \"Wide Residual Networks.\" Proceedings of the British Machine Vision Conference (BMVC), 2016. \nZagoruyko, Sergey. \"92.45% on CIFAR-10.\" 2015 \nTiulpin, Aleksei, \"Streaming Over Lightweight Data Transformations.\" Research Unit of Medical Imaging, Physics and Technology, University of Oulu, Finalnd, 2018. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/aisosalo/CIFAR-10",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-11T16:25:12Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-03T12:05:45Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.982713103549065
      ],
      "excerpt": "We present here our solution to the famous machine learning problem of image classification with CIFAR-10 dataset with 60000 labeled images. The aim is to learn and assign a category for these 32x32 pixel images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9628299719129854,
        0.9870389178886364
      ],
      "excerpt": "Here we have used for training and validation purposes only the 50000 images originally meant for training. Stratified K-Folds cross-validation is used to split the data so that the percentage of samples for each class is preserved. Several other reported implementations use the data as it is given and use the given 10000 sample testing set straight for validation. Instead we use the 10000 sample test set for evaluating our trained model. \nWe have made a PyTorch implementation of Sergey Zagoruyko VGG like network with BatchNormalization and Dropout for the task. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8930901044020226
      ],
      "excerpt": "    (features): Sequential( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9618776244855022,
        0.8990956339303704,
        0.8791262769876086,
        0.8682558711327841
      ],
      "excerpt": "In this implementation we only use horizontal flips. We pad the images into size 34x34 using reflective padding and then crop the images back into size 32x32. Random cropping is used as an augmentation in the training and then center cropping in the validation phase. Moreover, solt is used for the data augmentations. \nIn their experiments, Sergey Zagoruyko and Nikos Komodakis seem to have used whitened data. We use here the original data. \nYUV color space was proposed to be used by Sergey Zagoruyko. We have run our experimets without the RGB to YUV conversion. \nData is normalized in the usual way with mean and standard deviation calculated across the 50000 images, as it can, e.g., speed up the training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9682135113068411,
        0.8654102692713175
      ],
      "excerpt": "Here we provide the results related to the VGGBNDrop model proposed by Sergey Zagoruyko using SGD as optimizer. \nAs can be seen from the curves representing loss over time, the model starts to overfit around epoch 164. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9139125418391746
      ],
      "excerpt": "From the confusion matrices below related to the validation accuracy curve, we can see how the learning progresses. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.832614667016565
      ],
      "excerpt": "Evaluation has been run using the model for which the validation loss was the best (see session for details). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8988321069300755
      ],
      "excerpt": "Krizhevsky, Alex, and Geoffrey Hinton. \"Learning multiple layers of features from tiny images.\" Vol. 1. No. 4. Technical Report, University of Toronto, 2009. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "PyTorch Implementation of CIFAR-10 Image Classification Pipeline Using VGG Like Network",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/aisosalo/CIFAR-10/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Wed, 29 Dec 2021 09:19:22 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/aisosalo/CIFAR-10/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "aisosalo/CIFAR-10",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "From PyCharm Terminal\n\n```\n$ python build_dataset.py --dataset CIFAR10\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9508209762345723
      ],
      "excerpt": "From PyCharm Terminal \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8217897149790029,
        0.8421770442769498
      ],
      "excerpt": "The CIFAR-10 dataset, as it is provided, consists of 5 batches of training images which sum up to 50000 and a batch of 10000 test images. \nEach test batch consists of exactly 1000 randomly-selected images from each class. The training batches contain images in random order, some training batches having more images from one class than another. Together, the training batches contain exactly 5000 images from each class. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8453821665518155
      ],
      "excerpt": "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8453821665518155
      ],
      "excerpt": "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8669123635012759
      ],
      "excerpt": "      (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8209673127278408
      ],
      "excerpt": "      (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8983680110713115
      ],
      "excerpt": "      (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8338233508567103
      ],
      "excerpt": "      (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8338233508567103
      ],
      "excerpt": "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8559510486687592
      ],
      "excerpt": "      (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8022890911370598
      ],
      "excerpt": "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8492437425643694
      ],
      "excerpt": "      (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8382423390025753
      ],
      "excerpt": "      (33): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8084471102754522
      ],
      "excerpt": "      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8261848803893383
      ],
      "excerpt": "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8917086031636282
      ],
      "excerpt": "      (45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8362463055199162
      ],
      "excerpt": "      (49): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8338968463748341
      ],
      "excerpt": "      (51): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8382423390025753
      ],
      "excerpt": "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9302104883613522
      ],
      "excerpt": "$ python run_training.py --dataset_name CIFAR10 --num_classes 10 --experiment vggbndrop --bs 128 --optimizer sgd --lr 0.1 --lr_drop \"[160, 260]\" --n_epochs 300 --wd 5e-4 --learning_rate_decay 0.2 --n_threads 12 --color_space rgb --set_nesterov True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8331847014794241
      ],
      "excerpt": "Zagoruyko, Sergey. \"92.45% on CIFAR-10.\" 2015 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/aisosalo/CIFAR-10/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Antti Isosalo\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "PyTorch Implementation of CIFAR-10 Image Classification Pipeline Using VGG Like Network",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "CIFAR-10",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "aisosalo",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/aisosalo/CIFAR-10/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Wed, 29 Dec 2021 09:19:22 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "cifar-10",
      "pytorch",
      "vgg",
      "image-classification",
      "deep-learning"
    ],
    "technique": "GitHub API"
  }
}
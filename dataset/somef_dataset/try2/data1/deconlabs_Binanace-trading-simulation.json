{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1707.06347\n## Rainbow\nhttps://arxiv.org/abs/1710.02298\n## Attention\nhttp://nlp.seas.harvard.edu/2018/04/03/attention.html\n\n# Performance at trading gym\n![Performance](figs/TradingAgentPerformance.png",
      "https://arxiv.org/abs/1710.02298\n## Attention\nhttp://nlp.seas.harvard.edu/2018/04/03/attention.html\n\n# Performance at trading gym\n![Performance](figs/TradingAgentPerformance.png"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/deconlabs/TradingZoo-Dynamic-fee-simulation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-27T08:52:00Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-25T09:10:36Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9108709797376926
      ],
      "excerpt": "This project is to about finding the optimal Fee mechanism in the Exchange. RL agents acts as people under certain Fee policies. We observe how RL agents's behavior changes with Fee mechanism changes. Fee mechanism would change total trade volume and total fee. This project is maintained as Binance Fellowship. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9436382790752157
      ],
      "excerpt": "Our project environment is based on https://github.com/Yvictor/TradingGym/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9142056003448007,
        0.8935474731178125
      ],
      "excerpt": "Transfer agents to different environments where different fee mechanism is applied.  \n Agents will trained again for 500 episodes more to adapt to each environment. Also, differentiate agents by varying risk_aversion ratio so that some agents prefer risk while others not. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9087701986749421,
        0.9698478303881264
      ],
      "excerpt": "Using integrated_gradient, we can interpret how agents observe the data. \nX axis represents actions and Y axis represents the feature of data. The graph shows how the feature of data affects the action decision of trading agent. You can see that the weight distribution of feature is different depending on the training algorithms. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Simulate binance fee mechanism by RL agents",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/deconlabs/Binanace-trading-simulation/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Thu, 30 Dec 2021 00:05:23 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/deconlabs/TradingZoo-Dynamic-fee-simulation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "deconlabs/TradingZoo-Dynamic-fee-simulation",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/ScorePlot-PPO%2C%20RAINBOW%2C%20Attention%20together.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/dataset/Crawl_binance_data.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/PPO.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/Transformer%28Attention%29/ScorePlot.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/Transformer%28Attention%29/LSTM.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/Transformer%28Attention%29/%5BTransformer%5DIntegratedGradients-everyaction_together_no%20diff.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/Transformer%28Attention%29/%5BTransformer%5DIntegratedGradients-everyaction_together-diff%20%EA%B3%B1%ED%95%9C%EA%B1%B0%20normalized.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/PPO/%5BPPO%5DAllActionIntegratedGradient.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/PPO/ScorePlot-PPO-Copy1.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/PPO/PPOagent.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/PPO/ScorePlot-PPO.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/PPO/PPOTradingAgent/PPO%20Model.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/utils/%5BTOTAL0.003%5DAnalysis%20of%20transfer_learned%20Agent.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/utils/%5BBifee_total_0.0005%5DAnalysis%20of%20transfer_learned%20Agent.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/utils/IntegratedGradients.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/utils/%5BBifee_total_0-Copy1.0001%5DAnalysis%20of%20transfer_learned%20Agent.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/utils/%5BBifee_total_0.0015%5DAnalysis%20of%20transfer_learned%20Agent.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/utils/%5BTOTAL_0.005%5DAnalysis%20of%20transfer_learned%20Agent.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/utils/Analysis%20of%20transfer_learned%20Agent.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/DQN/ScorePlot.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/DQN/Observation%20of%20fee%20and%20volume.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/DQN/%5BDQN%5DIntegratedGradients-everyaction_together_no%20diff.ipynb",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/DQN/saves/ScorePlot.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/Transformer%28Attention%29/transfer_learn.sh",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/Transformer%28Attention%29/kill_session.sh",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/Transformer%28Attention%29/run.sh",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/utils/transfer_learn.sh",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/utils/kill_session.sh",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/utils/run.sh",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/DQN/transfer_learn.sh",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/DQN/kill_session.sh",
      "https://raw.githubusercontent.com/deconlabs/Binanace-trading-simulation/master/agent/DQN/run.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8257839262082767
      ],
      "excerpt": "Train RL agents using trading gym.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9625196775343342,
        0.9625196775343342
      ],
      "excerpt": "RSI bound Environment \nMACD bound Environment \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8273939354707942
      ],
      "excerpt": "    Stores the historical data to train the agents \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8043052275524087
      ],
      "excerpt": "Train RL agents using trading gym.  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/deconlabs/TradingZoo-Dynamic-fee-simulation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Decon\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Binanace_trading_simulation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "TradingZoo-Dynamic-fee-simulation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "deconlabs",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/deconlabs/TradingZoo-Dynamic-fee-simulation/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 26,
      "date": "Thu, 30 Dec 2021 00:05:23 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```shell\npip install -r requirements.txt\n```\n1. Train original agent\n```python3\ncd agent/PPO\npython ppo_start.py\n```\n```python3\ncd agent/Attention\npython attention_start.py\n```\n```python3\ncd agent/DQN\npython dqn_start.py\n```\nif you want to train multiple agents,\n```shell\ncd agent/DQN\nbash run.sh\n```\n2. Transfer Learning\n```python3\ncd agent/DQN\npython transfer_learning.py --environment=[environment]\n```\nif you want to transfer learn multiple agents,\n```shell\ncd agent/DQN\nbash transfer.sh\n```\n3. Observation\n```shell\ncd agent/DQN\n```\nOpen Observation notebook and run all cell\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{tang2015line,\n  title={LINE: Large-scale Information Network Embedding.},\n  author={Tang, Jian and Qu, Meng and Wang, Mingzhe and Zhang, Ming and Yan, Jun and Mei, Qiaozhu},\n  booktitle={WWW},\n  year={2015},\n  organization={ACM}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9392395551057171
      ],
      "excerpt": "Contact: Jian Tang, tangjianpku@gmail.com \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8334383858677847
      ],
      "excerpt": "This work was done when the author was working at Microsoft Research \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/tangjianpku/LINE",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2015-03-06T03:33:04Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-28T08:00:02Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9929724526200995
      ],
      "excerpt": "This is the LINE toolkit developed for embedding very large-scale information networks. It is suitable to a variety of networks including directed, undirected, binary or weighted edges. The LINE model is quite efficient, which is able to embed a network with millions of vertices and billions of edges on a single machine within a few hours. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.917310371514103
      ],
      "excerpt": "We provide both the Windows and LINUX versions. To compile the souce codes, some external packages are required, which are used to generate random numbers for the edge-sampling algorithm in the LINE model. For Windows version, the BOOST package is used and can be downloaded at http://www.boost.org/; for LINUX, the GSL package is used and can be downloaded at http://www.gnu.org/software/gsl/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9124885978996079,
        0.8490037945672047,
        0.8490037945672047
      ],
      "excerpt": "The input of a network consists of the edges in the network. Each line of the input file represents a DIRECTED edge in the network, which is specified as the format \"source_node target_node weight\" (can be either separated by blank or tab). For each undirected edge, users must use TWO DIRECTED edges to represent it. Here is an input example of a word co-occurrence network: \ngood the 3 \nthe good 3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9968029537584643,
        0.9968029537584643
      ],
      "excerpt": "bad of 4 \nof bad 4 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9216356251160066
      ],
      "excerpt": "- -size, the dimension of the embedding; the default is 100; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9483003284858925
      ],
      "excerpt": "- -negative, the number of negative samples used in negative sampling; the deault is 5; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9203272932600117
      ],
      "excerpt": "- -rho, the starting value of the learning rate; the default is 0.025; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.986328185046861,
        0.8599822210184436,
        0.9067251783885987
      ],
      "excerpt": "- reconstruct.cpp, the code used for reconstructing the sparse networks into dense ones, which is described in Section 4.3; \n- normalize.cpp, the code for normalizing the embeddings (l2 normalization); \n- concatenate.cpp, the code for concatenating the embeddings with 1st-order and 2nd-order; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "LINE: Large-scale information network embedding",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/tangjianpku/LINE/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 387,
      "date": "Thu, 30 Dec 2021 10:59:01 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/tangjianpku/LINE/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "tangjianpku/LINE",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/tangjianpku/LINE/master/linux/train_youtube.sh",
      "https://raw.githubusercontent.com/tangjianpku/LINE/master/linux/evaluate/make.sh",
      "https://raw.githubusercontent.com/tangjianpku/LINE/master/linux/evaluate/run.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8507558737570006
      ],
      "excerpt": "We provide both the Windows and LINUX versions. To compile the souce codes, some external packages are required, which are used to generate random numbers for the edge-sampling algorithm in the LINE model. For Windows version, the BOOST package is used and can be downloaded at http://www.boost.org/; for LINUX, the GSL package is used and can be downloaded at http://www.gnu.org/software/gsl/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8751403247584032
      ],
      "excerpt": "To run the script, users first need to compile the evaluation codes by running make.sh in the folder \"evaluate\". Afterwards, we can run train_youtube.bat or train_youtube.sh to run the whole pipeline. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9245340428822578,
        0.808640899986295,
        0.8074844351252953
      ],
      "excerpt": "./line -train network_file -output embedding_file -binary 1 -size 200 -order 2 -negative 5 -samples 100 -rho 0.025 -threads 20 \n- -train, the input file of a network; \n- -output, the output file of the embedding; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8723475980280084
      ],
      "excerpt": "- -samples, the total number of training samples (*Million); \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/tangjianpku/LINE/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "C++",
      "C",
      "Python",
      "Makefile",
      "Shell",
      "MATLAB",
      "Batchfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "LINE: Large-scale information network embedding",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "LINE",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "tangjianpku",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/tangjianpku/LINE/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 970,
      "date": "Thu, 30 Dec 2021 10:59:01 GMT"
    },
    "technique": "GitHub API"
  }
}
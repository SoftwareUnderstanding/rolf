{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2002.08679"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@article{kozlov2020neural,\n    title =   {Neural network compression framework for fast model inference},\n    author =  {Kozlov, Alexander and Lazarevich, Ivan and Shamporov, Vasily and Lyalyushkin, Nikolay and Gorbachev, Yury},\n    journal = {arXiv preprint arXiv:2002.08679},\n    year =    {2020}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{kozlov2020neural,\n    title =   {Neural network compression framework for fast model inference},\n    author =  {Kozlov, Alexander and Lazarevich, Ivan and Shamporov, Vasily and Lyalyushkin, Nikolay and Gorbachev, Yury},\n    journal = {arXiv preprint arXiv:2002.08679},\n    year =    {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9146894306581498
      ],
      "excerpt": "Object Detection sample \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9146894306581498
      ],
      "excerpt": "Object Detection sample \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9146894306581498
      ],
      "excerpt": "  * Object detection \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9146894306581498
      ],
      "excerpt": "  * Object detection \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "|MobileNet V2|INT8|ImageNet|71.35 (0.58)| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "|MobileNet V2|INT8 + Sparsity 52% (RB)|ImageNet|71.11 (0.82)| \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/openvinotoolkit/nncf",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to NNCF\nContributions are accepted in the form of:\n* Submitting issues against the current code to report bugs or request features\n* Extending NNCF functionality with important features (e.g. to address community requests, improve usability, implement a recently published compression algorithm, etc.)\n* Adding example scripts to showcase NNCF usage in real training pipelines and provide the means to reproduce the reported compression results\n* Providing recipes (specific NNCF configurations and training hyperparameters) to obtain state-of-the-art compression using NNCF for existing models\n* Adding well-defined patches that integrate NNCF into third-party repositories\n* Reducing performance overhead of NNCF compression by writing specialized CUDA kernels for compression operations or improving existing ones. \nThe latter forms are accepted as pull requests from your own forks of the NNCF repository.\nAny contributions must not violate the repository's LICENSE requirements.\nTesting\nAfter your pull request is submitted, the maintainer will launch a scope of CI tests against it.\nThe scope will depend on the impact of the commit, but will at least be equal to pre-commit scope checks.\nThe pre-commit scope may be run locally by executing the pytest command (without any additional arguments) in the root repository folder.\nPlease run the pre-commit testing scope locally before submitting your PR and ensure that it passes to conserve your own time and that of the reviewing maintainer.\nNew feature pull requests should include all the necessary testing code.\nTesting is done using the pytest framework. \nThe test files should be located inside the tests directory and start with test_ so that the pytest is able to discover them.\nAny additional data that is required for tests (configuration files, mock datasets, etc.) must be stored within the tests/data folder.\nThe test files themselves may be grouped in arbitrary directories according to their testing purpose and common sense.\nAny additional tests in the tests directory will be automatically added into the pre-commit CI scope. \nIf your testing code is more extensive than unit tests (in terms of test execution time), or would be more suited to be executed on a nightly/weekly basis instead of for each future commit, please inform the maintainers in your PR discussion thread so that our internal testing pipelines could be adjusted accordingly.\nCode style\nChanges to NNCF Python code should conform to Python Style Guide\nPylint is used throughout the project to ensure code cleanliness and quality. \nA Pylint run is also done as part of the pre-commit scope - the pre-commit pytest scope will not be run if your code fails the Pylint checks.\nThe Pylint rules and exceptions for this repository are described in the standard .pylintrc format - make sure your local linter uses these.\nBinary files\nPlease refrain from adding huge binary files into the repository. If binary files have to be added, mark these to use Git LFS via the .gitattributes file.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-13T16:41:05Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-26T12:30:32Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9703272864337801,
        0.9918944184115708,
        0.9349805496375072
      ],
      "excerpt": "NNCF provides a suite of advanced algorithms for Neural Networks inference optimization in OpenVINO&trade; with minimal accuracy drop. \nNNCF is designed to work with models from PyTorch and TensorFlow. \nNNCF provides samples that demonstrate the usage of compression algorithms for three different use cases on public PyTorch and  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8826212008462975,
        0.9781758465447881,
        0.8437907674633781,
        0.9652178209727403
      ],
      "excerpt": "Compression results achievable with the NNCF-powered samples can be found in a table at  \nthe end of this document. \nThe framework is organized as a Python* package that can be built and used in a standalone mode. The framework  \narchitecture is unified to make it easy to add different compression algorithms for both PyTorch and TensorFlow deep  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9261886421537832
      ],
      "excerpt": "Support of various compression algorithms, applied during a model fine-tuning process to achieve a better performance-accuracy trade-off: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9315609956779631,
        0.9303355691764538
      ],
      "excerpt": "Automatic, configurable model graph transformation to obtain the compressed model. \nNOTE: Limited support for TensorFlow models. The models created using Sequential or Keras Functional API are only supported. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.831490992210562,
        0.9351329156118114
      ],
      "excerpt": "Git patches for prominent third-party repositories (huggingface-transformers) demonstrating the process of integrating NNCF into custom training pipelines \nExporting PyTorch compressed models to ONNX* checkpoints and TensorFlow compressed models to SavedModel or Frozen Graph format, ready to use with OpenVINO&trade; toolkit. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9819901386899641,
        0.9451087020399257,
        0.9328467940528676,
        0.9663651672826277
      ],
      "excerpt": "to optimize models for inference with the OpenVINO Toolkit. \n- Optimizing PyTorch models with NNCF of OpenVINO by 8-bit quantization \n- Optimizing TensorFlow models with NNCF of OpenVINO by 8-bit quantization \n- Post-Training Quantization of Pytorch model with NNCF \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9117535088816697,
        0.9213378483312697
      ],
      "excerpt": "NNCF is integrated into OpenVINO Training Extensions as model optimization backend. So you can train, optimize and export new models based on the available model templates as well as run exported models with OpenVINO. \nSee third_party_integration for examples of code modifications (Git patches and base commit IDs are provided) that are necessary to integrate NNCF into the following repositories: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9493789696363587
      ],
      "excerpt": "NB: For launching example scripts in this repository, we recommend replacing the install option above with develop and setting the PYTHONPATH variable to the root of the checked-out repository. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9686726155201998
      ],
      "excerpt": "Refer to the CONTRIBUTING.md file for guidelines on contributions to the NNCF repository. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8800010342297744
      ],
      "excerpt": "with this repository. See README.md files for sample scripts and example patches  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8497377662904809,
        0.9061412096231481,
        0.8918714504612804,
        0.8497377662904809
      ],
      "excerpt": "|RetinaNet|INT8 (per-tensor for weights)|COCO2017|33.22 (0.22)| \n|RetinaNet|Sparsity 50% (Magnitude)|COCO2017|33.13 (0.31)| \n|RetinaNet|Filter Pruning 40%, geometric_median criterion|COCO2017|32.7 (0.74)| \n|RetinaNet|Filter Pruning 40%, geometric_median criterion + INT8 (per-tensor for weights)|COCO2017|32.53 (0.91)| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Neural Network Compression Framework for enhanced OpenVINO\u2122 inference",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/openvinotoolkit/nncf_pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 97,
      "date": "Mon, 27 Dec 2021 19:50:09 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/openvinotoolkit/nncf/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "openvinotoolkit/nncf",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/openvinotoolkit/nncf_pytorch/develop/docker/torch/gpu/Dockerfile",
      "https://raw.githubusercontent.com/openvinotoolkit/nncf_pytorch/develop/docker/torch/cpu/Dockerfile",
      "https://raw.githubusercontent.com/openvinotoolkit/nncf_pytorch/develop/docker/tensorflow/gpu/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/openvinotoolkit/nncf_pytorch/tree/develop/docs"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We suggest to install or use the package in the [Python virtual environment](https://docs.python.org/3/tutorial/venv.html).\n\nIf you want to optimize a model from PyTorch, install PyTorch by following [PyTorch installation guide](https://pytorch.org/get-started/locally/#start-locally). \nIf you want to optimize a model from TensorFlow, install TensorFlow by following [TensorFlow installation guide](https://www.tensorflow.org/install/).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9068851962386303,
        0.9820226428242687,
        0.9892878093429132,
        0.9468262408825022,
        0.8478147624679555,
        0.9590189658225119
      ],
      "excerpt": "Install the package and its dependencies by running the following in the repository root directory: \npython setup.py install \nAlternatively, If you don't install any backend you can install NNCF and PyTorch in one line with: \npython setup.py install --torch \nInstall NNCF and TensorFlow in one line: \npython setup.py install --tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9813984719589414,
        0.999746712887969,
        0.9892878093429132,
        0.9853723880054749,
        0.8478147624679555,
        0.9897411650844645,
        0.8498520410880369,
        0.996714160028586,
        0.9957139898138555,
        0.9670795751751088
      ],
      "excerpt": "NNCF can be installed as a regular PyPI package via pip: \npip install nncf \nAlternatively, If you don't install any backend you can install NNCF and PyTorch in one line with: \npip install nncf[torch] \nInstall NNCF and TensorFlow in one line: \npip install nncf[tf] \nNNCF is also available via conda: \nconda install -c conda-forge nncf \npip install git+https://github.com/openvinotoolkit/nncf@bd189e2#:egg=nncf \nNote that in order for this to work for pip versions >= 21.3, your Git version must be at least 2.22. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9119797940507073
      ],
      "excerpt": "- PyTorch models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "<a name=\"pytorch_classification\"></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "<a name=\"pytorch_object_detection\"></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "<a name=\"pytorch_semantic_segmentation\"></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "<a name=\"pytorch_nlp\"></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "<a name=\"tensorflow_classification\"></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "<a name=\"tensorflow_object_detection\"></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "<a name=\"tensorflow_instance_segmentation\"></a> \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8040932355777498
      ],
      "excerpt": "Instance Segmentation sample \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "<a name=\"pytorch_classification\"></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8084339548435566
      ],
      "excerpt": "|SqueezeNet V1.1|Mixed, 54.7% INT8 / 45.3% INT4|ImageNet|58.9 (-0.66)| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "<a name=\"pytorch_object_detection\"></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8002152438082484,
        0.8421074476017179
      ],
      "excerpt": "|SSD512-VGG-BN|INT8 + Sparsity 70% (Magnitude)|VOC12+07 train, VOC07 eval|79.67 (0.59)| \n<a name=\"pytorch_semantic_segmentation\"></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.811854372964597
      ],
      "excerpt": "|UNet|INT8|CamVid|71.8 (0.15)| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "<a name=\"pytorch_nlp\"></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "<a name=\"tensorflow_classification\"></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "<a name=\"tensorflow_object_detection\"></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "<a name=\"tensorflow_instance_segmentation\"></a> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/openvinotoolkit/nncf/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cuda",
      "C++",
      "PureBasic",
      "Dockerfile",
      "C"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Apache License 2.0",
      "url": "https://api.github.com/licenses/apache-2.0"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'                                 Apache License\\n                           Version 2.0, January 2004\\n                        http://www.apache.org/licenses/\\n\\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\\n\\n   1. Definitions.\\n\\n      \"License\" shall mean the terms and conditions for use, reproduction,\\n      and distribution as defined by Sections 1 through 9 of this document.\\n\\n      \"Licensor\" shall mean the copyright owner or entity authorized by\\n      the copyright owner that is granting the License.\\n\\n      \"Legal Entity\" shall mean the union of the acting entity and all\\n      other entities that control, are controlled by, or are under common\\n      control with that entity. For the purposes of this definition,\\n      \"control\" means (i) the power, direct or indirect, to cause the\\n      direction or management of such entity, whether by contract or\\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\\n      outstanding shares, or (iii) beneficial ownership of such entity.\\n\\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\\n      exercising permissions granted by this License.\\n\\n      \"Source\" form shall mean the preferred form for making modifications,\\n      including but not limited to software source code, documentation\\n      source, and configuration files.\\n\\n      \"Object\" form shall mean any form resulting from mechanical\\n      transformation or translation of a Source form, including but\\n      not limited to compiled object code, generated documentation,\\n      and conversions to other media types.\\n\\n      \"Work\" shall mean the work of authorship, whether in Source or\\n      Object form, made available under the License, as indicated by a\\n      copyright notice that is included in or attached to the work\\n      (an example is provided in the Appendix below).\\n\\n      \"Derivative Works\" shall mean any work, whether in Source or Object\\n      form, that is based on (or derived from) the Work and for which the\\n      editorial revisions, annotations, elaborations, or other modifications\\n      represent, as a whole, an original work of authorship. For the purposes\\n      of this License, Derivative Works shall not include works that remain\\n      separable from, or merely link (or bind by name) to the interfaces of,\\n      the Work and Derivative Works thereof.\\n\\n      \"Contribution\" shall mean any work of authorship, including\\n      the original version of the Work and any modifications or additions\\n      to that Work or Derivative Works thereof, that is intentionally\\n      submitted to Licensor for inclusion in the Work by the copyright owner\\n      or by an individual or Legal Entity authorized to submit on behalf of\\n      the copyright owner. For the purposes of this definition, \"submitted\"\\n      means any form of electronic, verbal, or written communication sent\\n      to the Licensor or its representatives, including but not limited to\\n      communication on electronic mailing lists, source code control systems,\\n      and issue tracking systems that are managed by, or on behalf of, the\\n      Licensor for the purpose of discussing and improving the Work, but\\n      excluding communication that is conspicuously marked or otherwise\\n      designated in writing by the copyright owner as \"Not a Contribution.\"\\n\\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\\n      on behalf of whom a Contribution has been received by Licensor and\\n      subsequently incorporated within the Work.\\n\\n   2. Grant of Copyright License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      copyright license to reproduce, prepare Derivative Works of,\\n      publicly display, publicly perform, sublicense, and distribute the\\n      Work and such Derivative Works in Source or Object form.\\n\\n   3. Grant of Patent License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      (except as stated in this section) patent license to make, have made,\\n      use, offer to sell, sell, import, and otherwise transfer the Work,\\n      where such license applies only to those patent claims licensable\\n      by such Contributor that are necessarily infringed by their\\n      Contribution(s) alone or by combination of their Contribution(s)\\n      with the Work to which such Contribution(s) was submitted. If You\\n      institute patent litigation against any entity (including a\\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\\n      or a Contribution incorporated within the Work constitutes direct\\n      or contributory patent infringement, then any patent licenses\\n      granted to You under this License for that Work shall terminate\\n      as of the date such litigation is filed.\\n\\n   4. Redistribution. You may reproduce and distribute copies of the\\n      Work or Derivative Works thereof in any medium, with or without\\n      modifications, and in Source or Object form, provided that You\\n      meet the following conditions:\\n\\n      (a) You must give any other recipients of the Work or\\n          Derivative Works a copy of this License; and\\n\\n      (b) You must cause any modified files to carry prominent notices\\n          stating that You changed the files; and\\n\\n      (c) You must retain, in the Source form of any Derivative Works\\n          that You distribute, all copyright, patent, trademark, and\\n          attribution notices from the Source form of the Work,\\n          excluding those notices that do not pertain to any part of\\n          the Derivative Works; and\\n\\n      (d) If the Work includes a \"NOTICE\" text file as part of its\\n          distribution, then any Derivative Works that You distribute must\\n          include a readable copy of the attribution notices contained\\n          within such NOTICE file, excluding those notices that do not\\n          pertain to any part of the Derivative Works, in at least one\\n          of the following places: within a NOTICE text file distributed\\n          as part of the Derivative Works; within the Source form or\\n          documentation, if provided along with the Derivative Works; or,\\n          within a display generated by the Derivative Works, if and\\n          wherever such third-party notices normally appear. The contents\\n          of the NOTICE file are for informational purposes only and\\n          do not modify the License. You may add Your own attribution\\n          notices within Derivative Works that You distribute, alongside\\n          or as an addendum to the NOTICE text from the Work, provided\\n          that such additional attribution notices cannot be construed\\n          as modifying the License.\\n\\n      You may add Your own copyright statement to Your modifications and\\n      may provide additional or different license terms and conditions\\n      for use, reproduction, or distribution of Your modifications, or\\n      for any such Derivative Works as a whole, provided Your use,\\n      reproduction, and distribution of the Work otherwise complies with\\n      the conditions stated in this License.\\n\\n   5. Submission of Contributions. Unless You explicitly state otherwise,\\n      any Contribution intentionally submitted for inclusion in the Work\\n      by You to the Licensor shall be under the terms and conditions of\\n      this License, without any additional terms or conditions.\\n      Notwithstanding the above, nothing herein shall supersede or modify\\n      the terms of any separate license agreement you may have executed\\n      with Licensor regarding such Contributions.\\n\\n   6. Trademarks. This License does not grant permission to use the trade\\n      names, trademarks, service marks, or product names of the Licensor,\\n      except as required for reasonable and customary use in describing the\\n      origin of the Work and reproducing the content of the NOTICE file.\\n\\n   7. Disclaimer of Warranty. Unless required by applicable law or\\n      agreed to in writing, Licensor provides the Work (and each\\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\\n      implied, including, without limitation, any warranties or conditions\\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\\n      PARTICULAR PURPOSE. You are solely responsible for determining the\\n      appropriateness of using or redistributing the Work and assume any\\n      risks associated with Your exercise of permissions under this License.\\n\\n   8. Limitation of Liability. In no event and under no legal theory,\\n      whether in tort (including negligence), contract, or otherwise,\\n      unless required by applicable law (such as deliberate and grossly\\n      negligent acts) or agreed to in writing, shall any Contributor be\\n      liable to You for damages, including any direct, indirect, special,\\n      incidental, or consequential damages of any character arising as a\\n      result of this License or out of the use or inability to use the\\n      Work (including but not limited to damages for loss of goodwill,\\n      work stoppage, computer failure or malfunction, or any and all\\n      other commercial damages or losses), even if such Contributor\\n      has been advised of the possibility of such damages.\\n\\n   9. Accepting Warranty or Additional Liability. While redistributing\\n      the Work or Derivative Works thereof, You may choose to offer,\\n      and charge a fee for, acceptance of support, warranty, indemnity,\\n      or other liability obligations and/or rights consistent with this\\n      License. However, in accepting such obligations, You may act only\\n      on Your own behalf and on Your sole responsibility, not on behalf\\n      of any other Contributor, and only if You agree to indemnify,\\n      defend, and hold each Contributor harmless for any liability\\n      incurred by, or claims asserted against, such Contributor by reason\\n      of your accepting any such warranty or additional liability.\\n\\n   END OF TERMS AND CONDITIONS\\n\\n   APPENDIX: How to apply the Apache License to your work.\\n\\n      To apply the Apache License to your work, attach the following\\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\\n      replaced with your own identifying information. (Don\\'t include\\n      the brackets!)  The text should be enclosed in the appropriate\\n      comment syntax for the file format. We also recommend that a\\n      file or class name and description of purpose be included on the\\n      same \"printed page\" as the copyright notice for easier\\n      identification within third-party archives.\\n\\n   Copyright [yyyy] [name of copyright owner]\\n\\n   Licensed under the Apache License, Version 2.0 (the \"License\");\\n   you may not use this file except in compliance with the License.\\n   You may obtain a copy of the License at\\n\\n       http://www.apache.org/licenses/LICENSE-2.0\\n\\n   Unless required by applicable law or agreed to in writing, software\\n   distributed under the License is distributed on an \"AS IS\" BASIS,\\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n   See the License for the specific language governing permissions and\\n   limitations under the License.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Neural Network Compression Framework (NNCF)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "nncf",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "openvinotoolkit",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/openvinotoolkit/nncf/blob/develop/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "vshampor",
        "body": "## Target version updates:\r\n- Relax TensorFlow version requirements to 2.4.x",
        "dateCreated": "2021-11-30T10:50:41Z",
        "datePublished": "2021-12-01T08:15:03Z",
        "html_url": "https://github.com/openvinotoolkit/nncf/releases/tag/v2.0.2",
        "name": "v2.0.2",
        "tag_name": "v2.0.2",
        "tarball_url": "https://api.github.com/repos/openvinotoolkit/nncf/tarball/v2.0.2",
        "url": "https://api.github.com/repos/openvinotoolkit/nncf/releases/54387449",
        "zipball_url": "https://api.github.com/repos/openvinotoolkit/nncf/zipball/v2.0.2"
      },
      {
        "authorType": "User",
        "author_name": "vshampor",
        "body": "## Target version updates:\r\n- Bump target framework versions to PyTorch 1.9.1 and TensorFlow 2.4.3\r\n- Increased target HuggingFace transformers version for the integration patch to 4.9.1\r\n\r\n## Bugfixes:\r\n- Fixed statistic collection for the algo mixing scenario\r\n- Increased pruning algorithm robustness in cases of a disconnected NNCF graph\r\n- Fixed the fatality of NNCF graph PNG rendering failures\r\n- Fixed README command lines\r\n- (PyTorch) Fixed a bug with quantizing shared weights multiple times\r\n- (PyTorch) Fixed knowledge distillation failures in CPU-only and DataParallel scenarios\r\n- (PyTorch) Fixed sparsity application for torch.nn.Embedding and EmbeddingBag modules\r\n- (PyTorch) Added GroupNorm + ReLU as a fusable pattern\r\n- (TensorFlow) Fixed gamma fusion handling for pruning TF BatchNorm\r\n- (PyTorch) Fixed pruning for models where operations have multiple convolution predecessors\r\n- (PyTorch) Fixed NNCFNetwork wrapper so that `self` in the calls to the wrapped model refer to the wrapper NNCFNetwork object and not to the wrapped model\r\n- (PyTorch) Fixed tracing of `view` operations to handle shape arguments with the `torch.Tensor` type \r\n- (PyTorch) Added matmul ops to be considered for fusing\r\n- (PyTorch, TensorFlow) Fixed tensorboard logging for accuracy-aware scenarios\r\n- (PyTorch, TensorFlow) Fixed FLOPS calculation for grouped convolutions\r\n- (PyTorch) Fixed knowledge distillation failures for tensors of unsupported shapes - will ignore output tensors with unsupported shapes now instead of crashing.",
        "dateCreated": "2021-10-25T09:36:13Z",
        "datePublished": "2021-10-26T09:18:29Z",
        "html_url": "https://github.com/openvinotoolkit/nncf/releases/tag/v2.0.1",
        "name": "",
        "tag_name": "v2.0.1",
        "tarball_url": "https://api.github.com/repos/openvinotoolkit/nncf/tarball/v2.0.1",
        "url": "https://api.github.com/repos/openvinotoolkit/nncf/releases/52039414",
        "zipball_url": "https://api.github.com/repos/openvinotoolkit/nncf/zipball/v2.0.1"
      },
      {
        "authorType": "User",
        "author_name": "vshampor",
        "body": "## New features:\r\n- Added TensorFlow 2.4.2 support - NNCF can now be used to apply the compression algorithms to models originally trained in TensorFlow.\r\nNNCF with TensorFlow backend supports the following features:\r\n  - Compression algorithms:\r\n    - Quantization (with HW-specific targeting aligned with PyTorch)\r\n    - Sparsity:\r\n      - Magnitude Sparsity \r\n      - RB Sparsity\r\n    - Filter pruning\r\n  - Support for only Keras models consisting of standard Keras layers and created by:\r\n    - Keras Sequential API\r\n    - Keras Functional API\r\n  - Automatic, configurable model graph transformation to obtain the compressed model.\r\n  - Distributed training on multiple GPUs on one machine is supported using `tf.distribute.MirroredStrategy`.\r\n  - Exporting compressed models to SavedModel or Frozen Graph format, ready to use with OpenVINO\u2122 toolkit.\r\n  \r\n- Added model compression samples for NNCF with TensorFlow backend:\r\n  - Classification\r\n    - Keras training loop.\r\n    - Models form the tf.keras.applications module (ResNets, MobileNets, Inception and etc.) are supported.\r\n    - TensorFlow Datasets (TFDS) and TFRecords (ImageNet2012, Cifar100, Cifar10) are supported.\r\n    - Compression results are claimed for MobileNet V2, MobileNet V3 small, MobileNet V3 large, ResNet50, Inception V3.\r\n  - Object Detection (Compression results are claimed for RetinaNet, YOLOv4)\r\n    - Custom training loop.\r\n    - TensorFlow Datasets (TFDS) and TFRecords for COCO2017 are supported.\r\n    - Compression results for are claimed for RetinaNet, YOLOv4.\r\n  - Instance Segmentation\r\n    - Custom training loop\r\n    - TFRecords for COCO2017 is supported.\r\n    - Compression results are claimed for MaskRCNN\r\n\r\n- Accuracy-aware training available for filter pruning and sparsity in order to achieve best compression results within a given accuracy drop threshold in a fully automated fashion.\r\n- Framework-specific checkpoints produced with NNCF now have NNCF-specific compression state information included, so that the exact compressed model state can be restored/loaded without having to provide the same NNCF config file that was used during the creation of the NNCF-compressed checkpoint \r\n- Common interface for compression methods for both PyTorch and TensorFlow backends (https://github.com/openvinotoolkit/nncf/tree/develop/nncf/api).\r\n- (PyTorch) Added an option to specify an effective learning rate multiplier for the trainable parameters of the compression algorithms via NNCF config, for finer control over which should tune faster - the underlying FP32 model weights or the compression parameters.\r\n- (PyTorch) Unified scales for concat operations - the per-tensor quantizers that affect the concat operations will now have identical scales so that the resulting concatenated tensor can be represented without loss of accuracy w.r.t. the concatenated subcomponents.\r\n- (TensorFlow) Algo-mixing: Added configuration files and reference checkpoints for filter-pruned + qunatized models: ResNet50@ImageNet2012(40% of filters pruned + INT8), RetinaNet@COCO2017(40% of filters pruned + INT8).\r\n- (Experimental, PyTorch) [Learned Global Ranking]((https://arxiv.org/abs/1904.12368)) filter pruning mechanism for better pruning ratios with less accuracy drop for a broad range of models has been implemented.\r\n- (Experimental, PyTorch) Knowledge distillation supported, ready to be used with any compression algorithm to produce an additional loss source of the compressed model against the uncompressed version\r\n\r\n### Breaking changes:\r\n- `CompressionLevel` has been renamed to `CompressionStage`\r\n- `\"ignored_scopes\"` and \"target_scopes\" no longer allow prefix matching - use full-fledged regular expression approach via {re} if anything more than an exact match is desired.\r\n- (PyTorch) Removed version-agnostic name mapping for ReLU operations, i.e. the NNCF configs that referenced \"RELU\" (all caps) as an operation name will now have to reference an exact ReLU PyTorch function name such as \"relu\" or \"relu_\"\r\n- (PyTorch) Removed the example of code modifications (Git patches and base commit IDs are provided) for [mmdetection](https://github.com/open-mmlab/mmdetection) repository.\r\n- Batchnorm adaptation \"forgetting\" step has been removed since it has been observed to introduce accuracy degradation; the \"num_bn_forget_steps\" parameter in the corresponding NNCF config section has been removed.\r\n- Framework-specific requirements no longer installed during `pip install nncf` or `python setup.py install` and are assumed to be present in the user's environment; the pip's \"extras\" syntax must be used to install the BKC requirements, e.g. by executing `pip install nncf[tf]`, `pip install nncf[torch]` or `pip install nncf[tf,torch]`\r\n- `\"quantizable_subgraph_patterns\"` option removed from the NNCF config\r\n\r\n### Bugfixes:\r\n- (PyTorch) Fixed a hang with batchnorm adaptation being applied in DDP mode\r\n- (PyTorch) Fixed tracing of the operations that return NotImplemented",
        "dateCreated": "2021-07-19T18:04:20Z",
        "datePublished": "2021-07-20T08:49:25Z",
        "html_url": "https://github.com/openvinotoolkit/nncf/releases/tag/v2.0.0",
        "name": "v2.0.0",
        "tag_name": "v2.0.0",
        "tarball_url": "https://api.github.com/repos/openvinotoolkit/nncf/tarball/v2.0.0",
        "url": "https://api.github.com/repos/openvinotoolkit/nncf/releases/46459757",
        "zipball_url": "https://api.github.com/repos/openvinotoolkit/nncf/zipball/v2.0.0"
      },
      {
        "authorType": "User",
        "author_name": "vshampor",
        "body": "- Fixed a bug with where compressed models that were supposed to return named tuples actually returned regular tuples\r\n- Fixed an issue with batch norm adaptation-enabled compression runs hanging in the DDP scenario",
        "dateCreated": "2021-05-06T08:18:59Z",
        "datePublished": "2021-05-06T11:02:31Z",
        "html_url": "https://github.com/openvinotoolkit/nncf/releases/tag/v1.7.1",
        "name": "",
        "tag_name": "v1.7.1",
        "tarball_url": "https://api.github.com/repos/openvinotoolkit/nncf/tarball/v1.7.1",
        "url": "https://api.github.com/repos/openvinotoolkit/nncf/releases/42532975",
        "zipball_url": "https://api.github.com/repos/openvinotoolkit/nncf/zipball/v1.7.1"
      },
      {
        "authorType": "User",
        "author_name": "vshampor",
        "body": "### New features:\r\n- Adjust Padding feature to support accurate execution of U4 on VPU - when setting \"target_device\" to \"VPU\", the training-time padding values for quantized convolutions will be adjusted to better reflect VPU inference process.\r\n- Weighted layers that are \"frozen\" (i.e. have requires_grad set to False at compressed model creation time) are no longer considered for compression, to better handle transfer learning cases.\r\n- Quantization algorithm now sets up quantizers without giving an option for requantization, which guarantees best performance, although at some cost to quantizer configuration flexibility.\r\n- Pruning models with FCOS detection heads and instance normalization operations now supported\r\n- Added a mean percentile initializer for the quantization algorithm\r\n- Now possible to additionally quantize model outputs (separate control for each output quantization is supported)\r\n- Models quantized for CPU now use effective 7-bit quantization for weights - the ONNX-exported model is still configured to use 8 bits for quantization, but only the middle 128 quanta of the total possible 256 are actually used, which allows for better OpenVINO inference accuracy alignment with PyTorch on non-VNNI CPUs\r\n- Bumped target PyTorch version to 1.8.1 and relaxed package requirements constraints to allow installation into environments with PyTorch >=1.5.0\r\n\r\n### Notable bugfixes:\r\n- Fixed bias pruning in depthwise convolution\r\n- Made per-tensor quantization available for all operations that support per-channel quantization \r\n- Fixed progressive training performance degradation when an output tensor of an NNCF-compressed model is reused as its input.\r\n- `pip install .` path of installing NNCF from a checked-out repository is now supported.\r\n- Nested `with no_nncf_trace()` blocks now function as expected.\r\n- NNCF compression API now formally abstract to guard against virtual function calls\r\n- Now possible to load AutoQ and HAWQ-produced checkpoints to evaluate them or export to ONNX\r\n\r\n### Removed features:\r\n- Pattern-based quantizer setup mode for quantization algorithm - due to its logic, it did not guarantee that all required operation inputs are ultimately quantized.",
        "dateCreated": "2021-04-19T08:32:25Z",
        "datePublished": "2021-04-19T12:29:44Z",
        "html_url": "https://github.com/openvinotoolkit/nncf/releases/tag/v1.7.0",
        "name": "",
        "tag_name": "v1.7.0",
        "tarball_url": "https://api.github.com/repos/openvinotoolkit/nncf/tarball/v1.7.0",
        "url": "https://api.github.com/repos/openvinotoolkit/nncf/releases/41641826",
        "zipball_url": "https://api.github.com/repos/openvinotoolkit/nncf/zipball/v1.7.0"
      },
      {
        "authorType": "User",
        "author_name": "vshampor",
        "body": "- Added AutoQ - an AutoML-based mixed-precision initialization mode for quantization, which utilizes the power of reinforcement learning to select the best quantizer configuration for any model in terms of quality metric for a given HW architecture type.\r\n- NNCF now supports inserting compression operations as pre-hooks to PyTorch operations, instead of abusing the post-hooking; the flexibility of quantization setups has been improved as a result of this change.\r\n- Improved the pruning algorithm to group together dependent filters from different layers in the network and prune these together\r\n- Extended the ONNX compressed model exporting interface with an option to explicitly name input and output tensors\r\n- Changed the compression scheduler so that the correspondingepoch_step  and step methods should now be called in the beginning of the epoch and before the optimizer step (previously these were called in the end of the epoch and after the optimizer step respectively)\r\n- Data-dependent compression algorithm initialization is now specified in terms of dataset samples instead of training batches, e.g. `\"num_init_samples\"` should be used in place of \"num_init_steps\" in NNCF config files.\r\n- Custom user modules to be registered for compression can now be specified to be ignored for certain compression algorithms\r\n- Batch norm adaptation now being applied by default for all compression algorithms\r\n- Bumped target PyTorch version to 1.7.0\r\n- Custom OpenVINO operations such as \"FakeQuantize\" that appear in NNCF-exported ONNX models now have their ONNX `domain` set to org.openvinotoolkit\r\n- The quantization algorithm will now quantize nn.Embedding and nn.EmbeddingBag weights when targeting CPU\r\n- Added an option to optimize logarithms of quantizer scales instead of scales themselves directly, a technique which improves convergence in certain cases\r\n- Added reference checkpoints for filter-pruned models: UNet@Mapillary (25% of filters pruned), SSD300@VOC (40% of filters pruned)\r\n",
        "dateCreated": "2021-01-29T13:30:04Z",
        "datePublished": "2021-01-29T14:25:36Z",
        "html_url": "https://github.com/openvinotoolkit/nncf/releases/tag/v1.6.0",
        "name": "v1.6.0",
        "tag_name": "v1.6.0",
        "tarball_url": "https://api.github.com/repos/openvinotoolkit/nncf/tarball/v1.6.0",
        "url": "https://api.github.com/repos/openvinotoolkit/nncf/releases/37086835",
        "zipball_url": "https://api.github.com/repos/openvinotoolkit/nncf/zipball/v1.6.0"
      },
      {
        "authorType": "User",
        "author_name": "vshampor",
        "body": "",
        "dateCreated": "2020-11-06T14:37:22Z",
        "datePublished": "2020-11-06T14:39:08Z",
        "html_url": "https://github.com/openvinotoolkit/nncf/releases/tag/v1.5.0",
        "name": "",
        "tag_name": "v1.5.0",
        "tarball_url": "https://api.github.com/repos/openvinotoolkit/nncf/tarball/v1.5.0",
        "url": "https://api.github.com/repos/openvinotoolkit/nncf/releases/33567445",
        "zipball_url": "https://api.github.com/repos/openvinotoolkit/nncf/zipball/v1.5.0"
      },
      {
        "authorType": "User",
        "author_name": "vshampor",
        "body": "Fixed packaging",
        "dateCreated": "2020-07-28T17:08:26Z",
        "datePublished": "2020-07-28T17:11:28Z",
        "html_url": "https://github.com/openvinotoolkit/nncf/releases/tag/v1.4.1",
        "name": "v1.4.1",
        "tag_name": "v1.4.1",
        "tarball_url": "https://api.github.com/repos/openvinotoolkit/nncf/tarball/v1.4.1",
        "url": "https://api.github.com/repos/openvinotoolkit/nncf/releases/29039315",
        "zipball_url": "https://api.github.com/repos/openvinotoolkit/nncf/zipball/v1.4.1"
      },
      {
        "authorType": "User",
        "author_name": "vshampor",
        "body": "",
        "dateCreated": "2020-07-28T14:02:49Z",
        "datePublished": "2020-07-28T14:03:59Z",
        "html_url": "https://github.com/openvinotoolkit/nncf/releases/tag/v1.4",
        "name": "v1.4",
        "tag_name": "v1.4",
        "tarball_url": "https://api.github.com/repos/openvinotoolkit/nncf/tarball/v1.4",
        "url": "https://api.github.com/repos/openvinotoolkit/nncf/releases/29031228",
        "zipball_url": "https://api.github.com/repos/openvinotoolkit/nncf/zipball/v1.4"
      },
      {
        "authorType": "User",
        "author_name": "vshampor",
        "body": "Documentation updates",
        "dateCreated": "2020-06-08T11:34:30Z",
        "datePublished": "2020-06-08T11:43:15Z",
        "html_url": "https://github.com/openvinotoolkit/nncf/releases/tag/v1.3.2",
        "name": "",
        "tag_name": "v1.3.2",
        "tarball_url": "https://api.github.com/repos/openvinotoolkit/nncf/tarball/v1.3.2",
        "url": "https://api.github.com/repos/openvinotoolkit/nncf/releases/27322120",
        "zipball_url": "https://api.github.com/repos/openvinotoolkit/nncf/zipball/v1.3.2"
      },
      {
        "authorType": "User",
        "author_name": "vshampor",
        "body": "",
        "dateCreated": "2020-06-03T14:28:58Z",
        "datePublished": "2020-06-03T14:32:47Z",
        "html_url": "https://github.com/openvinotoolkit/nncf/releases/tag/v1.3.1",
        "name": "",
        "tag_name": "v1.3.1",
        "tarball_url": "https://api.github.com/repos/openvinotoolkit/nncf/tarball/v1.3.1",
        "url": "https://api.github.com/repos/openvinotoolkit/nncf/releases/27181927",
        "zipball_url": "https://api.github.com/repos/openvinotoolkit/nncf/zipball/v1.3.1"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Ubuntu\\* 18.04 or later (64-bit)\n- Python\\* 3.6.2 or later\n- Supported frameworks:\n  - PyTorch\\* >=1.5.0, <=1.9.1 (1.8.0 not supported)\n  - TensorFlow\\* 2.4.3\n\nThis repository is tested on Python* 3.6.2+, PyTorch* 1.9.1 (NVidia CUDA\\* Toolkit 10.2) and TensorFlow* 2.4.3 (NVidia CUDA\\* Toolkit 11.0).\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 378,
      "date": "Mon, 27 Dec 2021 19:50:09 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "quantization",
      "pruning",
      "sparsity",
      "quantization-aware-training",
      "mixed-precision-training",
      "compression",
      "semantic-segmentation",
      "object-detection",
      "classification",
      "nlp",
      "bert",
      "mmdetection",
      "transformers",
      "hawq",
      "pytorch",
      "tensorflow"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The NNCF is organized as a regular Python package that can be imported in your target training pipeline script.\nThe basic workflow is loading a JSON configuration script containing NNCF-specific parameters determining the compression to be applied to your model, and then passing your model along with the configuration script to the `create_compressed_model` function.\nThis function returns a model with additional modifications necessary to enable algorithm-specific compression during fine-tuning and handle to the object allowing you to control the compression during the training process:\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\nimport torch\nimport nncf  #: Important - should be imported directly after torch\n\nfrom nncf import NNCFConfig\nfrom nncf.torch import create_compressed_model, register_default_init_args\n\n#: Instantiate your uncompressed model\nfrom torchvision.models.resnet import resnet50\nmodel = resnet50()\n\n#: Load a configuration file to specify compression\nnncf_config = NNCFConfig.from_json(\"resnet50_int8.json\")\n\n#: Provide data loaders for compression algorithm initialization, if necessary\nimport torchvision.datasets as datasets\nrepresentative_dataset = datasets.ImageFolder(\"/path\")\ninit_loader = torch.utils.data.DataLoader(representative_dataset)\nnncf_config = register_default_init_args(nncf_config, init_loader)\n\n#: Apply the specified compression algorithms to the model\ncompression_ctrl, compressed_model = create_compressed_model(model, nncf_config)\n\n#: Now use compressed_model as a usual torch.nn.Module \n#: to fine-tune compression parameters along with the model weights\n\n#: ... the rest of the usual PyTorch-powered training pipeline\n\n#: Export to ONNX or .pth when done fine-tuning\ncompression_ctrl.export_model(\"compressed_model.onnx\")\ntorch.save(compressed_model.state_dict(), \"compressed_model.pth\")\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\nimport tensorflow as tf\n\nfrom nncf import NNCFConfig\nfrom nncf.tensorflow import create_compressed_model, register_default_init_args\n\n#: Instantiate your uncompressed model\nfrom tensorflow.keras.applications import ResNet50\nmodel = ResNet50()\n\n#: Load a configuration file to specify compression\nnncf_config = NNCFConfig.from_json(\"resnet50_int8.json\")\n\n#: Provide dataset for compression algorithm initialization\nrepresentative_dataset = tf.data.Dataset.list_files(\"/path/*.jpeg\")\nnncf_config = register_default_init_args(nncf_config, representative_dataset, batch_size=1)\n\n#: Apply the specified compression algorithms to the model\ncompression_ctrl, compressed_model = create_compressed_model(model, nncf_config)\n\n#: Now use compressed_model as a usual Keras model\n#: to fine-tune compression parameters along with the model weights\n\n#: ... the rest of the usual TensorFlow-powered training pipeline\n\n#: Export to Frozen Graph, TensorFlow SavedModel or .h5  when done fine-tuning \ncompression_ctrl.export_model(\"compressed_model.pb\", save_format='frozen_graph')\n```\n\nFor a more detailed description of NNCF usage in your training code, see [this tutorial](docs/Usage.md). \nFor in-depth examples of NNCF integration, browse the [sample scripts](#model-compression-samples) code, or the [example patches](#third-party-repository-integration) to third-party repositories.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "|TensorFlow Model|<img width=\"110\" height=\"1\">Compression algorithm<img width=\"110\" height=\"1\">|Dataset|mAP (drop) %|\n| :---: | :---: | :---: | :---: |\n|MaskRCNN|INT8 (per-tensor for weights)|COCO2017|bbox: 37.14 (0.19)<br/>segm: 33.53 (0.03)|\n|MaskRCNN|Sparsity 50% (Magnitude)|COCO2017|bbox: 36.93 (0.40)<br/>segm: 33.23 (0.33)|\n\n",
      "technique": "Header extraction"
    }
  ]
}
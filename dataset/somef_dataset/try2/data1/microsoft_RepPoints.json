{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1904.11490",
      "https://arxiv.org/abs/1904.11490"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@inproceedings{yang2019reppoints,\n  title={RepPoints: Point Set Representation for Object Detection},\n  author={Yang, Ze and Liu, Shaohui and Hu, Han and Wang, Liwei and Lin, Stephen},\n  booktitle={The IEEE International Conference on Computer Vision (ICCV)},\n  month={Oct},\n  year={2019}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{yang2019reppoints,\n  title={RepPoints: Point Set Representation for Object Detection},\n  author={Yang, Ze and Liu, Shaohui and Hu, Han and Wang, Liwei and Lin, Stephen},\n  booktitle={The IEEE International Conference on Computer Vision (ICCV)},\n  month={Oct},\n  year={2019}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/microsoft/RepPoints",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-12T14:00:37Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-18T08:41:44Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "**RepPoints**, initially described in [arXiv](https://arxiv.org/abs/1904.11490), is a new representation method for visual objects, on which visual understanding tasks are typically centered. Visual object representation, aiming at both geometric description and appearance feature extraction, is conventionally achieved by `bounding box + RoIPool (RoIAlign)`. The bounding box representation is convenient to use; however, it provides only a rectangular localization of objects that lacks geometric precision and may consequently degrade feature quality. Our new representation, RepPoints, models objects by a `point set` instead of a `bounding box`, which learns to adaptively position themselves over an object in a manner that circumscribes the object\u2019s `spatial extent` and enables `semantically aligned feature extraction`. This richer and more flexible representation maintains the convenience of bounding boxes while facilitating various visual understanding applications. This repo demonstrated the effectiveness of RepPoints for COCO object detection.\n\nAnother feature of this repo is the demonstration of an `anchor-free detector`, which can be as effective as state-of-the-art anchor-based detection methods. The anchor-free detector can utilize either `bounding box` or `RepPoints` as the basic object representation.\n\n<div align=\"center\">\n  <img src=\"demo/reppoints.png\" width=\"400px\" />\n  <p>Learning RepPoints in Object Detection.</p>\n</div>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8472802707617643
      ],
      "excerpt": "The results on COCO 2017val are shown in the table below. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8933973267180738
      ],
      "excerpt": "| BBox | R-50-FPN | single | -    | 1x      | 36.3|model | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8606018550295674,
        0.8606018550295674,
        0.8606018550295674
      ],
      "excerpt": "| RepPoints | R-50-FPN | none     | MinMax | 1x      | 38.2| model  | \n| RepPoints | R-50-FPN | none     | moment | 1x      | 38.2| model | \n| RepPoints | R-50-FPN | none     | moment | 2x      | 38.6| model | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8606018550295674
      ],
      "excerpt": "| RepPoints | R-101-FPN | none   | moment | 2x   | 40.3| model | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8606018550295674
      ],
      "excerpt": "| RepPoints | R-101-FPN-DCN | none   | moment | 2x   | 43.0| model | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8606018550295674
      ],
      "excerpt": "| RepPoints | X-101-FPN-DCN | none   | moment | 2x   | 44.5| model | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.905032022634004,
        0.9811478250858504,
        0.934817737526953
      ],
      "excerpt": "R-xx, X-xx denote the ResNet and ResNeXt architectures, respectively.  \nDCN denotes replacing 3x3 conv with the 3x3 deformable convolution in c3-c5 stages of backbone. \nnone in the anchor column means 2-d center point (x,y) is used to represent the initial object hypothesis. single denotes one 4-d anchor box (x,y,w,h) with IoU based label assign criterion is adopted.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9764453648381836,
        0.8110399745830099
      ],
      "excerpt": "Note the results here are slightly different from those reported in the paper, due to framework change. While the original paper uses an MXNet implementation, we re-implement the method in PyTorch based on mmdetection. \nThis project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Represent Visual Objects by Point Sets",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/microsoft/RepPoints/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 70,
      "date": "Sun, 26 Dec 2021 12:13:29 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/microsoft/RepPoints/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "microsoft/RepPoints",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/microsoft/RepPoints/master/init.sh",
      "https://raw.githubusercontent.com/microsoft/RepPoints/master/download_coco2017.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "By [Ze Yang](https://yangze.tech/), [Shaohui Liu](http://b1ueber2y.me/), and [Han Hu](https://ancientmooner.github.io/).\n\nWe provide code support and configuration files to reproduce the results in the paper for\n[\"RepPoints: Point Set Representation for Object Detection\"](https://arxiv.org/abs/1904.11490) on COCO object detection. Our code is based on [mmdetection](https://github.com/open-mmlab/mmdetection), which is a clean open-sourced project for benchmarking object detection methods. \n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8704945377090106,
        0.8931911897301548
      ],
      "excerpt": "| RepPoints | R-50-FPN | none     | moment | 2x (ms train)   | 40.8| model | \n| RepPoints | R-50-FPN | none     | moment | 2x (ms train&ms test)   | 42.2|          | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8765398148546782,
        0.8972758128962326
      ],
      "excerpt": "| RepPoints | R-101-FPN | none   | moment | 2x (ms train)   | 42.3| model | \n| RepPoints | R-101-FPN | none   | moment | 2x (ms train&ms test)   | 44.1|          | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8765398148546782,
        0.8972758128962326
      ],
      "excerpt": "| RepPoints | R-101-FPN-DCN | none   | moment | 2x (ms train)   | 44.8| model | \n| RepPoints | R-101-FPN-DCN | none   | moment | 2x (ms train&ms test)   | 46.4|          | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9201114203626014,
        0.8972758128962326
      ],
      "excerpt": "| RepPoints | X-101-FPN-DCN | none   | moment | 2x (ms train)   | 45.6| model | \n| RepPoints | X-101-FPN-DCN | none   | moment | 2x (ms train&ms test)   | 46.8|          | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/microsoft/RepPoints/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'    MIT License\\r\\n\\r\\n    Copyright (c) Microsoft Corporation. All rights reserved.\\r\\n\\r\\n    Permission is hereby granted, free of charge, to any person obtaining a copy\\r\\n    of this software and associated documentation files (the \"Software\"), to deal\\r\\n    in the Software without restriction, including without limitation the rights\\r\\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\r\\n    copies of the Software, and to permit persons to whom the Software is\\r\\n    furnished to do so, subject to the following conditions:\\r\\n\\r\\n    The above copyright notice and this permission notice shall be included in all\\r\\n    copies or substantial portions of the Software.\\r\\n\\r\\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\r\\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\r\\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\r\\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\r\\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\r\\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\r\\n    SOFTWARE\\r\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "RepPoints: Point Set Representation for Object Detection",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "RepPoints",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "microsoft",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/microsoft/RepPoints/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 552,
      "date": "Sun, 26 Dec 2021 12:13:29 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "a. Clone the repo:\n```\ngit clone --recursive https://github.com/microsoft/RepPoints\n```\nb. Download the COCO detection dataset, copy RepPoints src into mmdetection and install mmdetection. \n```\nsh ./init.sh\n```\nc. Run experiments with a speicific configuration file:\n```\n./mmdetection/tools/dist_train.sh ${path-to-cfg-file} ${num_gpu} --validate\n```\nWe give one example here:\n```\n./mmdetection/tools/dist_train.sh ./configs/reppoints_moment_r101_fpn_2x_mt.py 8 --validate\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
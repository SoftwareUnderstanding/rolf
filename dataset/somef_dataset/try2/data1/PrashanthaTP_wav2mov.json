{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1406.2661\">[1] Generative Adversarial Nets</a>\n```bibtex\n@article{goodfellow2014generative,\n  title={Generative adversarial networks},\n  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},\n  journal={arXiv preprint arXiv:1406.2661},\n  year={2014}\n}\n```\n\n<a id=\"2\" href=\"http://spandh.dcs.shef.ac.uk/avlombard/\">[2] The Audio-Visual Lombard Grid Speech Corpus</a>\n\n[![Github stars](https://img.shields.io/badge/Dataset-LombardGrid-<COLOR>.svg",
      "https://arxiv.org/abs/1805.09313\">[4] End to End Facial Animation using Temporal GANs</a>\n```bibtex\n@article{vougioukas2018end,\n  title={End-to-end speech-driven facial animation with temporal gans},\n  author={Vougioukas, Konstantinos and Petridis, Stavros and Pantic, Maja},\n  journal={arXiv preprint arXiv:1805.09313},\n  year={2018}\n}\n```\n\n<a id=\"#5\" href=\"https://arxiv.org/abs/2008.10010\">[5] A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild</a>\n\n\n[![Github stars](https://img.shields.io/badge/Github-wav2Lip-<COLOR>.svg",
      "https://arxiv.org/abs/2008.10010\">[5] A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild</a>\n\n\n[![Github stars](https://img.shields.io/badge/Github-wav2Lip-<COLOR>.svg",
      "https://arxiv.org/abs/1406.2661",
      "https://arxiv.org/abs/1805.09313"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<a id=\"1\" href=\"https://arxiv.org/abs/1406.2661\">[1] Generative Adversarial Nets</a>\n```bibtex\n@article{goodfellow2014generative,\n  title={Generative adversarial networks},\n  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},\n  journal={arXiv preprint arXiv:1406.2661},\n  year={2014}\n}\n```\n\n<a id=\"2\" href=\"http://spandh.dcs.shef.ac.uk/avlombard/\">[2] The Audio-Visual Lombard Grid Speech Corpus</a>\n\n[![Github stars](https://img.shields.io/badge/Dataset-LombardGrid-<COLOR>.svg)](http://spandh.dcs.shef.ac.uk/avlombard/)\n\n```bibtex\n@article{Alghamdi_2018,\n\tdoi = {10.1121/1.5042758},\n\turl = {https://doi.org/10.1121%2F1.5042758},\n\tyear = 2018,\n\tmonth = {jun},\n\tpublisher = {Acoustical Society of America ({ASA})},\n\tvolume = {143},\n\tnumber = {6},\n\tpages = {EL523--EL529},\n\tauthor = {Najwa Alghamdi and Steve Maddock and Ricard Marxer and Jon Barker and Guy J. Brown},\n\ttitle = {A corpus of audio-visual Lombard speech with frontal and profile views},\n\tjournal = {The Journal of the Acoustical Society of America}\n}\n```\n\n<a id=\"#3\" href=\"https://link.springer.com/article/10.1007/s11263-019-01251-8\">[3] Realistic Facial Animation using GANs</a>\n\n[![Github stars](https://img.shields.io/badge/Github-sda-<COLOR>.svg)](https://github.com/DinoMan/speech-driven-animation)\n\n```bibtex\n@article{Vougioukas_2019,\n\tdoi = {10.1007/s11263-019-01251-8},\n\turl = {https://doi.org/10.1007%2Fs11263-019-01251-8},\n\tyear = 2019,\n\tmonth = {oct},\n\tpublisher = {Springer Science and Business Media {LLC}},\n\tvolume = {128},\n\tnumber = {5},\n\tpages = {1398--1413},\n\tauthor = {Konstantinos Vougioukas and Stavros Petridis and Maja Pantic},\n\ttitle = {Realistic Speech-Driven Facial Animation with {GANs}},\n\tjournal = {International Journal of Computer Vision}\n}\n```\n\n<a id=\"#4\" href=\"https://arxiv.org/abs/1805.09313\">[4] End to End Facial Animation using Temporal GANs</a>\n```bibtex\n@article{vougioukas2018end,\n  title={End-to-end speech-driven facial animation with temporal gans},\n  author={Vougioukas, Konstantinos and Petridis, Stavros and Pantic, Maja},\n  journal={arXiv preprint arXiv:1805.09313},\n  year={2018}\n}\n```\n\n<a id=\"#5\" href=\"https://arxiv.org/abs/2008.10010\">[5] A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild</a>\n\n\n[![Github stars](https://img.shields.io/badge/Github-wav2Lip-<COLOR>.svg)](https://github.com/Rudrabha/Wav2Lip)\n```bibtex\n@inproceedings{10.1145/3394171.3413532,\nauthor = {Prajwal, K R and Mukhopadhyay, Rudrabha and Namboodiri, Vinay P. and Jawahar, C.V.},\ntitle = {A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild},\nyear = {2020},\nisbn = {9781450379885},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3394171.3413532},\ndoi = {10.1145/3394171.3413532},\nbooktitle = {Proceedings of the 28th ACM International Conference on Multimedia},\npages = {484\u2013492},\nnumpages = {9},\nkeywords = {lip sync, talking face generation, video generation},\nlocation = {Seattle, WA, USA},\nseries = {MM '20}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{10.1145/3394171.3413532,\nauthor = {Prajwal, K R and Mukhopadhyay, Rudrabha and Namboodiri, Vinay P. and Jawahar, C.V.},\ntitle = {A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild},\nyear = {2020},\nisbn = {9781450379885},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3394171.3413532},\ndoi = {10.1145/3394171.3413532},\nbooktitle = {Proceedings of the 28th ACM International Conference on Multimedia},\npages = {484\u2013492},\nnumpages = {9},\nkeywords = {lip sync, talking face generation, video generation},\nlocation = {Seattle, WA, USA},\nseries = {MM '20}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{vougioukas2018end,\n  title={End-to-end speech-driven facial animation with temporal gans},\n  author={Vougioukas, Konstantinos and Petridis, Stavros and Pantic, Maja},\n  journal={arXiv preprint arXiv:1805.09313},\n  year={2018}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{Vougioukas_2019,\n    doi = {10.1007/s11263-019-01251-8},\n    url = {https://doi.org/10.1007%2Fs11263-019-01251-8},\n    year = 2019,\n    month = {oct},\n    publisher = {Springer Science and Business Media {LLC}},\n    volume = {128},\n    number = {5},\n    pages = {1398--1413},\n    author = {Konstantinos Vougioukas and Stavros Petridis and Maja Pantic},\n    title = {Realistic Speech-Driven Facial Animation with {GANs}},\n    journal = {International Journal of Computer Vision}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{Alghamdi_2018,\n    doi = {10.1121/1.5042758},\n    url = {https://doi.org/10.1121%2F1.5042758},\n    year = 2018,\n    month = {jun},\n    publisher = {Acoustical Society of America ({ASA})},\n    volume = {143},\n    number = {6},\n    pages = {EL523--EL529},\n    author = {Najwa Alghamdi and Steve Maddock and Ricard Marxer and Jon Barker and Guy J. Brown},\n    title = {A corpus of audio-visual Lombard speech with frontal and profile views},\n    journal = {The Journal of the Acoustical Society of America}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{goodfellow2014generative,\n  title={Generative adversarial networks},\n  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},\n  journal={arXiv preprint arXiv:1406.2661},\n  year={2014}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/PrashanthaTP/wav2mov",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-25T10:00:26Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-06T00:17:41Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Speech to Facial Animation using GANs",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/PrashanthaTP/wav2mov/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 19:23:41 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/PrashanthaTP/wav2mov/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "PrashanthaTP/wav2mov",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/PrashanthaTP/wav2mov/master/wav2mov/test.sh",
      "https://raw.githubusercontent.com/PrashanthaTP/wav2mov/master/wav2mov/run_sync_expert.sh",
      "https://raw.githubusercontent.com/PrashanthaTP/wav2mov/master/wav2mov/preprocess.sh",
      "https://raw.githubusercontent.com/PrashanthaTP/wav2mov/master/wav2mov/run.sh",
      "https://raw.githubusercontent.com/PrashanthaTP/wav2mov/master/wav2mov/inference/generate.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "![gan_setup](/wav2mov-docs/gan_setup.PNG)\n![generator_architecture](/wav2mov-docs/gen_arch.PNG)\n",
      "technique": "Header extraction"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/PrashanthaTP/wav2mov/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "Batchfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "wav2mov",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "PrashanthaTP",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/PrashanthaTP/wav2mov/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Thu, 23 Dec 2021 19:23:41 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deeplearning",
      "pytorch",
      "gans",
      "face-animation",
      "facial-animation",
      "lip-animation",
      "generative-adversarial-networks",
      "generative-adversarial-network",
      "deep-learning",
      "gan"
    ],
    "technique": "GitHub API"
  }
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- This work was supported in part through computational resources of HPC facilities at NRU HSE\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2002.05709"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "|----------|------------|-----------|---------------|---------------|-----------------------------------|------------|\n| CIFAR-10 | 1024       | 1000      | 2v100         | 13h           | 93\\.44                             | 93.95      |\n| ImageNet | 512        | 100       | 4v100         | 85h           | 60\\.14                            | 60.62      |\n| ImageNet | 2048       | 200       | 16v100        | 55h           | 65\\.58                            | 65.83      |\n| ImageNet | 2048       | 600       | 16v100        | 170h          | 67\\.84                            | 68.71       |\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8024003536718776
      ],
      "excerpt": "The implementation closely reproduces the original ResNet50 results on ImageNet and CIFAR-10. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AndrewAtanov/simclr-pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-12-10T13:52:17Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-28T15:48:36Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9944948286528857,
        0.8262936124116357
      ],
      "excerpt": "This is an unofficial repository reproducing results of the paper A Simple Framework for Contrastive Learning of Visual Representations. The implementation supports multi-GPU distributed training on several nodes with PyTorch DistributedDataParallel. \nThe implementation closely reproduces the original ResNet50 results on ImageNet and CIFAR-10. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8879220434085132
      ],
      "excerpt": "The configs imagenet_params_epochs*_bs*.yaml contain the parameters to reproduce results for ImageNet dataset. It requires at 4v100-16v100 GPUs depending on a batch size. The single-node (4 v100 GPUs) pretraining command is: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9852687170516103
      ],
      "excerpt": "See how to work with logs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8322003712283986
      ],
      "excerpt": "The above model with batch size 1024 gives 93.5 linear eval test accuracy. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9114116198974221
      ],
      "excerpt": "- --node_rank: 0 for the main node and 1,... for the others. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8710939573605313
      ],
      "excerpt": "and on the second node: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9039845765025022
      ],
      "excerpt": "The ImageNet the pretaining on 4 nodes all with 4 GPUs looks as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9640721900940192
      ],
      "excerpt": "Parts of this code are based on the following repositories:v \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9905904048362612
      ],
      "excerpt": "- SimCLR - A Simple Framework for Contrastive Learning of Visual Representations for more details on the original implementation  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "PyTorch implementation of SimCLR: supports multi-GPU training and closely reproduces results",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AndrewAtanov/simclr-pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 19,
      "date": "Wed, 29 Dec 2021 23:30:39 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/AndrewAtanov/simclr-pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "AndrewAtanov/simclr-pytorch",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/AndrewAtanov/simclr-pytorch/master/colabs/model_apply.ipynb",
      "https://raw.githubusercontent.com/AndrewAtanov/simclr-pytorch/master/colabs/read_logs.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Create a python enviroment with the provided config file and [miniconda](https://docs.conda.io/en/latest/miniconda.html):\n\n```(bash)\nconda env create -f environment.yml\nconda activate simclr_pytorch\n\nexport IMAGENET_PATH=... #: If you have enough RAM using /dev/shm usually accelerates data loading time\nexport EXMAN_PATH=... #: A path to logs\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8161024107650553,
        0.9173764645360128
      ],
      "excerpt": "Pre-trained weights can be downloaded with a command line interface as following: \npip3 install wldhx.yadisk-direct \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9258639431137687
      ],
      "excerpt": "For example, to train with two nodes you need to run the following command on the main node: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8057372273445166
      ],
      "excerpt": "- PyTorch, PyTorch Examples, PyTorch Lightning for standard backbones, training loops, etc. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8149590771599664,
        0.8030471171616834
      ],
      "excerpt": "| Dataset  | Batch Size | \\ \nTry out a pre-trained models   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8082022887640018
      ],
      "excerpt": "unzip pretrained_models.zip \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8824999796377215
      ],
      "excerpt": "python train.py --problem eval --eval_only true --iters 1 --arch linear \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8991908121294769
      ],
      "excerpt": "python train.py --problem eval --eval_only true --iters 1 --arch linear --data imagenet \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9185617089492827
      ],
      "excerpt": "python train.py --config configs/cifar_train_epochs1000_bs1024.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9185617089492827,
        0.8856531907489882
      ],
      "excerpt": "python train.py --config configs/imagenet_train_epochs100_bs512.yaml \nThe logs and the model will be stored at ./logs/exman-train.py/runs/&lt;experiment-id&gt;/. You can access all the experiments from python with exman.Index('./logs/exman-train.py').info(). \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/AndrewAtanov/simclr-pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Andrei Atanov*, Arsenii Ashukha; Bayesian Methods Research Group, Samsung AI Center Moscow, Samsung-HSE Laboratory, EPFL\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SimCLR PyTorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "simclr-pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "AndrewAtanov",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AndrewAtanov/simclr-pytorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 73,
      "date": "Wed, 29 Dec 2021 23:30:39 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "self-supervised-learning",
      "contrastive-learning",
      "pytorch-implementation",
      "deep-learning",
      "representation-learning"
    ],
    "technique": "GitHub API"
  }
}
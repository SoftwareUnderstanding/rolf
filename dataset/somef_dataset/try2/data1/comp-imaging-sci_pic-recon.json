{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2102.12525\n\nVarun A. Kelkar, Mark A. Anastasio <br />\nUniversity of Illinois at Urbana-Champaign, Urbana, IL - 61801, USA\n\n**Contact:** vak2@illinois.edu, maa@illinois.edu\n\n**Abstract:** Obtaining a useful estimate of an object from highly incomplete imaging measurements remains a holy grail of imaging science. Deep learning methods have shown promise in learning object priors or constraints to improve the conditioning of an ill-posed imaging inverse problem. In this study, a framework for estimating an object of interest that is semantically related to a known prior image, is proposed. An optimization problem is formulated in the disentangled latent space of a style-based generative model, and semantically meaningful constraints are imposed using the disentangled latent representation of the prior image. Stable recovery from incomplete measurements with the help of a prior image is theoretically analyzed. Numerical experiments demonstrating the superior performance of our approach as compared to related methods are presented\n\n<p align=\"center\">\n<img src=\"./pic_recon/docs/face_recons_paper.png\" alt=\"Face image reconstruction\" width=\"500\"/>\n<img src=\"./pic_recon/docs/brain_recon_images_paper.png\" alt=\"MRI image reconstruction\" width=\"1000\"/>\n</p>\n\n## System Requirements\n- Linux/Unix-based systems recommended. The code hasn't been tested on Windows.\n- 64 bit Python 3.6+. The code has been tested with Python 3.7.4 installed via Anaconda\n- Tensorflow 1.14/1.15. The code has been tested with Tensorflow 1.14. Tensorflow 2+ is not supported.\n- [imageio](https://imageio.readthedocs.io/en/stable/",
      "https://arxiv.org/abs/1812.04948, https://github.com/NVlabs/ffhq-dataset\n\n\n\n\n\n\n\n",
      "https://arxiv.org/abs/2102.12525",
      "https://arxiv.org/abs/1811.08839 (2018).\n2. **The Cancer Imaging Archive** Clark, K., Vendt, B., Smith, K., Freymann, J., Kirby, J., Koppel, P., Moore, S., Phillips, S., Maffitt, D., Pringle, M., Tarbox, L., & Prior, F. (2013). The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository. Journal of Digital Imaging, 26(6), 1045\u20131057. https://doi.org/10.1007/s10278-013-9622-7\n3. **TCIA Brain-Tumor-Progression** Schmainda KM, Prah M (2018). Data from Brain-Tumor-Progression. The Cancer Imaging Archive. https://doi.org/10.7937/K9/TCIA.2018.15quzvnb \n4. **FFHQ dataset** A Style-Based Generator Architecture for Generative Adversarial Networks\nTero Karras (NVIDIA), Samuli Laine (NVIDIA), Timo Aila (NVIDIA)\nhttps://arxiv.org/abs/1812.04948, https://github.com/NVlabs/ffhq-dataset\n\n\n\n\n\n\n\n"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. **FastMRI initiative database:** Zbontar, Jure, et al. \"fastMRI: An open dataset and benchmarks for accelerated MRI.\" arXiv preprint arXiv:1811.08839 (2018).\n2. **The Cancer Imaging Archive** Clark, K., Vendt, B., Smith, K., Freymann, J., Kirby, J., Koppel, P., Moore, S., Phillips, S., Maffitt, D., Pringle, M., Tarbox, L., & Prior, F. (2013). The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository. Journal of Digital Imaging, 26(6), 1045\u20131057. https://doi.org/10.1007/s10278-013-9622-7\n3. **TCIA Brain-Tumor-Progression** Schmainda KM, Prah M (2018). Data from Brain-Tumor-Progression. The Cancer Imaging Archive. https://doi.org/10.7937/K9/TCIA.2018.15quzvnb \n4. **FFHQ dataset** A Style-Based Generator Architecture for Generative Adversarial Networks\nTero Karras (NVIDIA), Samuli Laine (NVIDIA), Timo Aila (NVIDIA)\nhttps://arxiv.org/abs/1812.04948, https://github.com/NVlabs/ffhq-dataset\n\n\n\n\n\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@article{kelkar2021prior,\n  title={Prior Image-Constrained Reconstruction using Style-Based Generative Models},\n  author={Kelkar, Varun A and Anastasio, Mark A},\n  journal={arXiv preprint arXiv:2102.12525},\n  year={2021}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{kelkar2021prior,\n  title={Prior Image-Constrained Reconstruction using Style-Based Generative Models},\n  author={Kelkar, Varun A and Anastasio, Mark A},\n  journal={arXiv preprint arXiv:2102.12525},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9562045845684718,
        0.8592871015078041
      ],
      "excerpt": "University of Illinois at Urbana-Champaign, Urbana, IL - 61801, USA \nContact: vak2@illinois.edu, maa@illinois.edu \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/comp-imaging-sci/pic-recon/main/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/comp-imaging-sci/pic-recon",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to fastMRI\nWe want to make contributing to this project as easy and transparent as\npossible.\nPull Requests\nWe actively welcome your pull requests.\n\nFork the repo and create your branch from master.\nIf you've added code that should be tested, add tests.\nIf you've changed APIs, update the documentation.\nEnsure the test suite passes.\nMake sure your code lints.\nIf you haven't already, complete the Contributor License Agreement (\"CLA\").\n\nContributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\nComplete your CLA here: https://code.facebook.com/cla\nIssues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\nFacebook has a bounty program for the safe\ndisclosure of security bugs. In those cases, please go through the process\noutlined on that page and do not file a public issue.\nCoding Style\n\n4 spaces for indentation rather than tabs\n100 character line length\nPEP8 formatting\n\nLicense\nBy contributing to fastMRI, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-10T20:39:06Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-17T18:57:37Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9539707002181486
      ],
      "excerpt": "University of Illinois at Urbana-Champaign, Urbana, IL - 61801, USA \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9990811332945893
      ],
      "excerpt": "Abstract: Obtaining a useful estimate of an object from highly incomplete imaging measurements remains a holy grail of imaging science. Deep learning methods have shown promise in learning object priors or constraints to improve the conditioning of an ill-posed imaging inverse problem. In this study, a framework for estimating an object of interest that is semantically related to a known prior image, is proposed. An optimization problem is formulated in the disentangled latent space of a style-based generative model, and semantically meaningful constraints are imposed using the disentangled latent representation of the prior image. Stable recovery from incomplete measurements with the help of a prior image is theoretically analyzed. Numerical experiments demonstrating the superior performance of our approach as compared to related methods are presented \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9853423682918057
      ],
      "excerpt": "- Addition of regularization based on Gaussianized disentangled latent-space for projecting images onto the range of the StyleGAN2 (contained in stylegan2/projector.py with regularization and optimization parameters controlled in stylegan2/run_projector.py).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9526869385645197
      ],
      "excerpt": "- Various scripts for related to the theoretical results presented in our paper.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9402836963950757
      ],
      "excerpt": "- src Stores all python codes for image reconstruction. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9502135104598364
      ],
      "excerpt": "- results - stores the results of the reconstruction. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9463506474047977
      ],
      "excerpt": "The simplest way to get a recon algorithm alg is as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9635575967395913,
        0.8240227823099705,
        0.9466900231922762
      ],
      "excerpt": "The Shutterstock Collection containing the GT-PI pairs for the face images can be found here: https://www.shutterstock.com/collections/298591136-e81133c6. A Shutterstock license is needed to use these images. The preprocessing steps used  are described in our paper, and include manual cropping and resizing to 128x128x3. You may also use the automatic face alignment procedure developed by V. Kazemi and J. Sullivan for preprocessing, similar to the original FFHQ dataset. This is likely to improve the reconstruction performance of CSGM and PICGM further. \nAll the recon scripts contain the following common arguments: \n- process : This is the index of the image to be reconstructed. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9749090499581273
      ],
      "excerpt": "- mask_type : More generally refers to the forward model. For random Gaussian sensing, this argument takes the form gaussian_${m_by_n}. For simulated MRI with random cartesian undersampling, this argument takes the form mask_rand_${n_by_m}x. The Gaussian sensing matrices are generated in the code using a fixed seed. The undersampling masks for MRI are located inside pic_recon/masks_mri/.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.840710015194916
      ],
      "excerpt": "- pi_filename: (only for PICCS and PICGM) Path to the prior image. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code associated with the paper \"Prior Image-Constrained Reconstruction using Style-Based Generative Models\" accepted to ICML 2021.",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://imageio.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/comp-imaging-sci/pic-recon/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Tue, 21 Dec 2021 21:48:07 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/comp-imaging-sci/pic-recon/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "comp-imaging-sci/pic-recon",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/comp-imaging-sci/pic-recon/main/stylegan2/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/comp-imaging-sci/pic-recon/tree/main/stylegan2/docs",
      "https://github.com/comp-imaging-sci/pic-recon/tree/main/pic_recon/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/comp-imaging-sci/pic-recon/main/pic_recon/fastMRI/fastMRI_tutorial.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/comp-imaging-sci/pic-recon/main/scripts/get_network_weights.sh",
      "https://raw.githubusercontent.com/comp-imaging-sci/pic-recon/main/scripts/recon_plstv.sh",
      "https://raw.githubusercontent.com/comp-imaging-sci/pic-recon/main/scripts/recon_picgm.sh",
      "https://raw.githubusercontent.com/comp-imaging-sci/pic-recon/main/scripts/recon_csgm.sh",
      "https://raw.githubusercontent.com/comp-imaging-sci/pic-recon/main/scripts/run_projector.sh",
      "https://raw.githubusercontent.com/comp-imaging-sci/pic-recon/main/scripts/recon_piccs.sh",
      "https://raw.githubusercontent.com/comp-imaging-sci/pic-recon/main/stylegan2/run_lin_limit.sh",
      "https://raw.githubusercontent.com/comp-imaging-sci/pic-recon/main/stylegan2/run_projector.sh",
      "https://raw.githubusercontent.com/comp-imaging-sci/pic-recon/main/pic_recon/fastMRI/models/unet/train_unet.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.947138960103509
      ],
      "excerpt": "  Can be installed via pip install prox_tv. In our experience, this works on Linux and Mac, but not on Windows. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.870149475610027
      ],
      "excerpt": "GCC 7.2+. The code has been tested with GCC 7.2.0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8268038596521629
      ],
      "excerpt": "The directory pic_recon contains the following sub-directories: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9539676618431917
      ],
      "excerpt": "Download StyleGAN2 weights, for example <br /> bash scripts/get_network_weights.sh FastMRIT1T2. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8114970667684512
      ],
      "excerpt": "1. Download the appropriate StyleGAN2 weights. For brain images, use <br /> bash scripts/get_network_weights.sh CompMRIT1T2.<br /> For face images, use <br /> bash scripts/get_network_weights.sh FFHQ. <br /> The weights are stored in stylegan2/nets/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.848887445900219
      ],
      "excerpt": "4. Run <br />bash scripts/recon_${alg}.sh <br> for an algorithm alg, where alg can be plstv, csgm, piccs or picgm. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8576912166899607,
        0.8394743203509698
      ],
      "excerpt": "<img src=\"./pic_recon/docs/face_recons_paper.png\" alt=\"Face image reconstruction\" width=\"500\"/> \n<img src=\"./pic_recon/docs/brain_recon_images_paper.png\" alt=\"MRI image reconstruction\" width=\"1000\"/> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/comp-imaging-sci/pic-recon/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook",
      "Cuda",
      "Shell",
      "HTML",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Kristian Monsen Haug and Mathias Lohne\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Prior image-constrained reconstruction using style-based generative models - Tensorflow implementation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pic-recon",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "comp-imaging-sci",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/comp-imaging-sci/pic-recon/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Linux/Unix-based systems recommended. The code hasn't been tested on Windows.\n- 64 bit Python 3.6+. The code has been tested with Python 3.7.4 installed via Anaconda\n- Tensorflow 1.14/1.15. The code has been tested with Tensorflow 1.14. Tensorflow 2+ is not supported.\n- [imageio](https://imageio.readthedocs.io/en/stable/) - Install via `pip` or `conda`.\n- [scikit-image](https://scikit-image.org/)\n\nAdditional dependencies that are required for the various reconstruction methods are as follows:\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Tue, 21 Dec 2021 21:48:07 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "stylegan2",
      "image-reconstruction",
      "latent-representations",
      "tensorflow"
    ],
    "technique": "GitHub API"
  }
}
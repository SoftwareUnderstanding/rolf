{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1412.6980"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "EPOCH 10 : Validation Accuracy = 92.766% \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "EPOCH 12 : Validation Accuracy = 93.469% \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "EPOCH 30 : Validation Accuracy = 94.853% \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "EPOCH 10 : Validation Accuracy = 98.322% \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "EPOCH 12 : Validation Accuracy = 98.730% \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "EPOCH 30 : Validation Accuracy = 99.161% \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mohamedameen93/German-Traffic-Sign-Classification-Using-TensorFlow",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-11-22T09:40:49Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-20T12:57:32Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The pickled data is a dictionary with 4 key/value pairs:\n\n- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n- `'sizes'` is a list containing tuples, (width, height) representing the original width and height the image.\n- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image.\n\n**First, we will use `numpy` provide the number of images in each subset, in addition to the image size, and the number of unique classes.**\nNumber of training examples:  34799\nNumber of testing examples:  12630\nNumber of validation examples:  4410\nImage data shape = (32, 32, 3)\nNumber of classes = 43\n\n**Then, we used `matplotlib` plot sample images from each subset.**\n\n\n<figure>\n <img src=\"./traffic-signs-data/Screenshots/Train.png\" width=\"1072\" alt=\"Combined Image\" />\n <figcaption>\n <p></p> \n </figcaption>\n</figure>\n\n\n<figure>\n <img src=\"./traffic-signs-data/Screenshots/Test.png\" width=\"1072\" alt=\"Combined Image\" />\n <figcaption>\n <p></p> \n </figcaption>\n</figure>\n\n<figure>\n <img src=\"./traffic-signs-data/Screenshots/Valid.png\" width=\"1072\" alt=\"Combined Image\" />\n <figcaption>\n <p></p> \n </figcaption>\n</figure>\n\n\n**And finally, we will use `numpy` to plot a histogram of the count of images in each unique class.**\n\n\n<figure>\n <img src=\"./traffic-signs-data/Screenshots/TrainHist.png\" width=\"1072\" alt=\"Combined Image\" />\n <figcaption>\n <p></p> \n </figcaption>\n</figure>\n\n<figure>\n <img src=\"./traffic-signs-data/Screenshots/TestHist.png\" width=\"1072\" alt=\"Combined Image\" />\n <figcaption>\n <p></p> \n </figcaption>\n</figure>\n\n<figure>\n <img src=\"./traffic-signs-data/Screenshots/ValidHist.png\" width=\"1072\" alt=\"Combined Image\" />\n <figcaption>\n <p></p> \n </figcaption>\n</figure>\n\n---\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9498990895036631
      ],
      "excerpt": "In this project, I used Python and TensorFlow to classify traffic signs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "Data Preprocessing. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8107043347610092
      ],
      "excerpt": "Testing the Model on New Images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9781807745486125
      ],
      "excerpt": "Shuffling: In general, we shuffle the training data to increase randomness and variety in training dataset, in order for the model to be more stable. We will use sklearn to shuffle our data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.849572889903056
      ],
      "excerpt": "Local Histogram Equalization: This technique simply spreads out the most frequent intensity values in an image, resulting in enhancing images with low contrast. Applying this technique will be very helpfull in our case since the dataset in hand has real world images, and many of them has low contrast. We will use skimage to apply local histogram equalization to the training images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9232055865259485
      ],
      "excerpt": "Normalization: Normalization is a process that changes the range of pixel intensity values. Usually the image data should be normalized so that the data has mean zero and equal variance. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9420667703355896,
        0.9584426525183638,
        0.9909711825659511
      ],
      "excerpt": "In this step, we will design and implement a deep learning model that learns to recognize traffic signs from our dataset German Traffic Sign Dataset. \nWe'll use Convolutional Neural Networks to classify the images in this dataset. The reason behind choosing ConvNets is that they are designed to recognize visual patterns directly from pixel images with minimal preprocessing. They automatically learn hierarchies of invariant features at every level from data. \nWe will implement two of the most famous ConvNets. Our goal is to reach an accuracy of +95% on the validation set. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9364689523694089,
        0.989436035675302
      ],
      "excerpt": "1. We specify the learning rate of 0.001, which tells the network how quickly to update the weights. \n2. We minimize the loss function using the Adaptive Moment Estimation (Adam) Algorithm. Adam is an optimization algorithm introduced by D. Kingma and J. Lei Ba in a 2015 paper named Adam: A Method for Stochastic Optimization. Adam algorithm computes adaptive learning rates for each parameter. In addition to storing an exponentially decaying average of past squared gradients like Adadelta and RMSprop algorithms, Adam also keeps an exponentially decaying average of past gradients mtmt, similar to momentum algorithm, which in turn produce better results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9916505948561295
      ],
      "excerpt": "LeNet-5 is a convolutional network designed for handwritten and machine-printed character recognition. It was introduced by the famous Yann LeCun in his paper Gradient-Based Learning Applied to Document Recognition in 1998. Although this ConvNet is intended to classify hand-written digits, we're confident it have a very high accuracy when dealing with traffic signs, given that both hand-written digits and traffic signs are given to the computer in the form of pixel images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.943210249074901
      ],
      "excerpt": "Flattening: Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9569537772732503
      ],
      "excerpt": "VGGNet was first introduced in 2014 by K. Simonyan and A. Zisserman from the University of Oxford in a paper called Very Deep Convolutional Networks for Large-Scale Image Recognition. They were investigating the convolutional network depth on its accuracy in the large-scale image recognition setting. Their main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.870911150119204
      ],
      "excerpt": "The original VGGNet architecture has 16-19 layers, but I've excluded some of them and implemented a modified version of only 12 layers to save computational resources. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.943210249074901
      ],
      "excerpt": "Flattening: Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9047056669907038,
        0.8076052252369922,
        0.9448006312586568,
        0.982757259505159
      ],
      "excerpt": "In this step, we will train our model using normalized_images, then we'll compute softmax cross entropy between logits and labels to measure the model's error probability. \nThe keep_prob and keep_prob_conv variables will be used to control the dropout rate when training the neural network. \nOverfitting is a serious problem in deep nural networks. Dropout is a technique for addressing this problem. \nThe key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \u201cthinned\u201d networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. This technique was introduced by N. Srivastava, G. Hinton, A. Krizhevsky I. Sutskever, and R. Salakhutdinov in their paper Dropout: A Simple Way to Prevent Neural Networks from Overfitting. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8686964461801
      ],
      "excerpt": "- After each epoch, we measure the loss and accuracy of the validation set. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8452159730485066
      ],
      "excerpt": "- A low accuracy on the training and validation sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9712453603567189
      ],
      "excerpt": "We've been able to reach a maximum accuracy of 95.3% on the validation set over 30 epochs, using a learning rate of 0.001. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8535878319308826,
        0.8232698245179662,
        0.969212787514232
      ],
      "excerpt": "Using VGGNet, we've been able to reach a maximum validation accuracy of 99.3%. As you can observe, the model has nearly saturated after only 10 epochs, so we can reduce the epochs to 10 and save computational resources. \nWe'll use this model to predict the labels of the test set. \nIn this step, we will use the model to predict traffic signs type of 5 random images of German traffic signs from the web our model's performance on these images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8976161990377376,
        0.974302514673866,
        0.9572197376954628
      ],
      "excerpt": "These test images include some easy to predict signs, and other signs are considered hard for the model to predict. \nFor instance, we have easy to predict signs like the \"Stop\" and the \"No entry\". The two signs are clear and belong to classes where the model can predict with  high accuracy. \nOn the other hand, we have signs belong to classes where has poor accuracy, like the \"Speed limit\" sign, because as stated above it turns out that the various speed limits are sometimes misclassified among themselves, and the \"Pedestrians\" sign, because traffic signs with traingular shape are misclassified among themselves. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9524048651562499,
        0.9860053164848792,
        0.8542484200029774
      ],
      "excerpt": "As we can notice from the top 5 softmax probabilities, the model has very high confidence (100%) when it comes to predict simple signs, like the \"Stop\" and the \"No entry\" sign, and even high confidence when predicting simple triangular signs in a very clear image, like the \"Yield\" sign. \nOn the other hand, the model's confidence slightly reduces with more complex triangular sign in a \"pretty noisy\" image, in the \"Pedestrian\" sign image, we have a triangular sign with a shape inside it, and the images copyrights adds some noise to the image, the model was able to predict the true class, but with 80% confidence. \nAnd in the \"Speed limit\" sign, we can observe that the model accurately predicted that it's a \"Speed limit\" sign, but was somehow confused between the different speed limits. However, it predicted the true class at the end. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "In this project, I used Python and TensorFlow to classify traffic signs. Dataset used: German Traffic Sign Dataset. This dataset has more than 50,000 images of 43 classes. I was able to reach a +99% validation accuracy, and a 97.3% testing accuracy.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mohamedameen93/German-Traffic-Sign-Classification-Using-TensorFlow/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 42,
      "date": "Tue, 28 Dec 2021 00:45:07 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mohamedameen93/German-Traffic-Sign-Classification-Using-TensorFlow/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "mohamedameen93/German-Traffic-Sign-Classification-Using-TensorFlow",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/mohamedameen93/German-Traffic-Sign-Classification-Using-TensorFlow/master/Traffic_Sign_Classifier.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Now, we'll use the testing set to measure the accuracy of the model over unknown examples.\nWe've been able to reach a **Test accuracy of 97.6%**. A remarkable performance.\n\nNow we'll plot the confusion matrix to see where the model actually fails.\n\n<figure>\n <img src=\"./traffic-signs-data/Screenshots/cm.png\" width=\"1072\" alt=\"Combined Image\" />\n <figcaption>\n <p></p> \n </figcaption>\n</figure>\n\nWe observe some clusters in the confusion matrix above. It turns out that the various speed limits are sometimes misclassified among themselves. Similarly, traffic signs with traingular shape are misclassified among themselves. We can further improve on the model using hierarchical CNNs to first identify broader groups (like speed signs) and then have CNNs to classify finer features (such as the actual speed limit).\n\n---\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8837680365796365,
        0.8866078757857799
      ],
      "excerpt": "Python 3.6.2 \nTensorFlow 0.12.1 (GPU support) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8480563993068025
      ],
      "excerpt": "Testing the Model Using the Test Set. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8663824494083123,
        0.8512913607783593
      ],
      "excerpt": "- train.p: The training set. \n- test.p: The testing set. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8556998077171949
      ],
      "excerpt": " <img src=\"./traffic-signs-data/Screenshots/Gray.png\" width=\"1072\" alt=\"Combined Image\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8556998077171949
      ],
      "excerpt": " <img src=\"./traffic-signs-data/Screenshots/Equalized.png\" width=\"1072\" alt=\"Combined Image\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.818019158363948
      ],
      "excerpt": " <img src=\"./traffic-signs-data/Screenshots/Normalized.png\" width=\"1072\" alt=\"Combined Image\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8304235499165605
      ],
      "excerpt": " <img src=\"LeNet.png\" width=\"1072\" alt=\"Combined Image\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8304235499165605
      ],
      "excerpt": " <img src=\"VGGNet.png\" width=\"1072\" alt=\"Combined Image\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8249603404358024
      ],
      "excerpt": "Layer 3 (Pooling) The output shape should be 16x16x32. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8249603404358024
      ],
      "excerpt": "Layer 6 (Pooling) The output shape should be 8x8x64. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8249603404358024
      ],
      "excerpt": "Layer 9 (Pooling) The output shape should be 4x4x128. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8388687112509768
      ],
      "excerpt": "Now, we'll run the training data through the training pipeline to train the model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.844799537643701
      ],
      "excerpt": "Number of new testing examples:  5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8556998077171949
      ],
      "excerpt": " <img src=\"./traffic-signs-data/Screenshots/NewImg.png\" width=\"1072\" alt=\"Combined Image\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8556998077171949
      ],
      "excerpt": " <img src=\"./traffic-signs-data/Screenshots/TopSoft.png\" width=\"1072\" alt=\"Combined Image\" /> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mohamedameen93/German-Traffic-Sign-Classification-Using-TensorFlow/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "HTML",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2017 Mohamed Ameen\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "German Traffic Sign Classification Using TensorFlow",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "German-Traffic-Sign-Classification-Using-TensorFlow",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "mohamedameen93",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mohamedameen93/German-Traffic-Sign-Classification-Using-TensorFlow/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 54,
      "date": "Tue, 28 Dec 2021 00:45:07 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "python",
      "tensorflow",
      "machine-learning",
      "deep-learning",
      "deep-neural-networks",
      "image-classification",
      "german-traffic-sign-classifier",
      "autonomous-vehicles",
      "autonomous-driving"
    ],
    "technique": "GitHub API"
  }
}
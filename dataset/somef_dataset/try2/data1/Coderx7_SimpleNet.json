{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1608.06037       \n(Check the successor of this architecture at [Towards Principled Design of Deep Convolutional Networks: Introducing SimpNet](https://github.com/Coderx7/SimpNet",
      "https://arxiv.org/abs/1608.06037"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find SimpleNet useful in your research, please consider citing:\n\n    @article{hasanpour2016lets,\n      title={Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures},\n      author={Hasanpour, Seyyed Hossein and Rouhani, Mohammad and Fayyaz, Mohsen and Sabokrou, Mohammad},\n      journal={arXiv preprint arXiv:1608.06037},\n      year={2016}\n    }\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{hasanpour2016lets,\n  title={Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures},\n  author={Hasanpour, Seyyed Hossein and Rouhani, Mohammad and Fayyaz, Mohsen and Sabokrou, Mohammad},\n  journal={arXiv preprint arXiv:1608.06037},\n  year={2016}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "| CIFAR100  | 78.37*| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.881848456479086,
        0.8550101043698384,
        0.9618188552511033
      ],
      "excerpt": "| ResNet-110L / 1202L  *      |  1.7/10.2m   | 93.57 / 92.07 | 74.84/72.18  | \n| SD-110L / 1202L              |  1.7/10.2m   | 94.77 / 95.09 |  75.42 / -   | \n| WRN-(16/8)/(28/10)           |    11/36m    | 95.19 / 95.83 |  77.11/79.5  | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "| SimpleNet-Arch 2 (\u06e9) |    5.48M     |   95.51   |  78.37   | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856138460984869
      ],
      "excerpt": "| Multi-column DNN for Image Classi\ufb01cation** |     0.23%      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "| Deeply Supervised Net        |      1.92      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9763154040476395
      ],
      "excerpt": "| CIFAR100 | 64.68|66.82|65.46|65.43|66.29|66.22|67.37|69.11|- | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.946498592459726,
        0.9156566588472104,
        0.9156566588472104
      ],
      "excerpt": "| Stochastic depth-1202L                  |    95.09     |    10.2m     | \n| Wide Residual Net                       |    95.19     |     11m      | \n| Wide Residual Net                       |    95.83     |     36m      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9465077790545373
      ],
      "excerpt": "| Recurrent CNN for Object Recognition    |    92.91     |      -      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "| SqueezeNet     | 861.34M  |  9.67M   |  226K   |  1.51M  |     12.58M      |   1.25M    |     4.7      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "| NIN            |  11.06G  |  28.93M  |  380K   |   20K   |     38.79M      |    7.6M    |      29      | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Coderx7/SimpleNet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-03-18T09:31:08Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-12T12:45:24Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9770273120627807
      ],
      "excerpt": "This repository contains the architectures, Models, logs, etc pertaining to the SimpleNet Paper  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9322413587455244,
        0.9217014656839554,
        0.973902750394607,
        0.9731743415502748
      ],
      "excerpt": "(Check the successor of this architecture at Towards Principled Design of Deep Convolutional Networks: Introducing SimpNet) \nSimpleNet-V1 outperforms deeper and heavier architectures such as AlexNet, VGGNet,ResNet,GoogleNet,etc in a series of benchmark datasets, such as CIFAR10/100, MNIST, SVHN.  \nIt also achievs a higher accuracy (currently 67.17/87.44) in imagenet, more than AlexNet, NIN, Squeezenet, etc with only 5.7M parameters. \nSlimer versions of the architecture work very decently against more complex architectures such as ResNet and WRN as well. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9011410150317631,
        0.9101084174134649
      ],
      "excerpt": "For using Pytorch implemnetation click Pytorch implementation \nImageNet result was achieved using simple SGD without hyper parameter tuning for 100 epochs(single crop). no multicrop techniques were used. no dense evaluation or combinations of such techniques were used unlike all other architectures. the models will be uploaded when the training is finished.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8150771532802734
      ],
      "excerpt": "| Method                   | #Params |  CIFAR10  | CIFAR100 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9813535820779772
      ],
      "excerpt": "*Note that the Fractional max pooling[13] uses deeper architectures and also uses extreme data augmentation.\u06de  means No zero-padding or normalization with dropout and \u06e9 means Standard data-augmentation- with dropout. To our knowledge, our architecture has the state of the art result, without aforementioned data-augmentations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.855992331020293
      ],
      "excerpt": "| Generalizing Pooling Functions in CNN**    |     0.29%      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.923612902535385,
        0.9405032531363477,
        0.8806542485216926,
        0.9541760115733873,
        0.8952699772008637
      ],
      "excerpt": "*Note that we didn\u2019t intend on achieving the state of the art \nperformance here as we are using a single optimization policy without \nfine-tuning hyper parameters or data-augmentation for a specific task, \nand still we nearly achieved state-of-the-art on MNIST. **Results \nachieved using an ensemble or extreme data-augmentation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8295854924284407
      ],
      "excerpt": "| Model | Ours | Maxout | DSN | ALLCNN | dasNet | ResNet(32) | WRN | NIN | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8091716024595429
      ],
      "excerpt": "*Since we presented their results in their respective sections, we avoided mentioning the results here again. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.855992331020293
      ],
      "excerpt": "| Generalizing Pooling Functions in CNN   |    93.95     |      -      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9261113223473905
      ],
      "excerpt": "| SimpleNet-Arch1 using data augmentation |    95.32     |     5.4m     | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8577819544049452
      ],
      "excerpt": "Flops and Parameter Comparison: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.811944990496964
      ],
      "excerpt": "| Model      | MACC | COMP | ADD | DIV | Activations | Params | SIZE(MB) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8924212690395703,
        0.9088111381320131,
        0.8161315490882625
      ],
      "excerpt": "| VGG16          |  154.7G  | 196.85M  |   10K   |   10K   |     288.03M     |  138.36M   |    512.2     | \nFlops and Parameter Comparison of Models trained on ImageNet \n*Inception v3, v4 did not have any Caffe model, so we reported their \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8757032548390677,
        0.8815207159807193
      ],
      "excerpt": "Inception-ResNet-V2 would take 60 days of training with 2 Titan X to \nachieve the reported accuracy. Statistics are obtained using \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This repository contains the architectures, Models, logs, etc pertaining to the SimpleNet Paper (Lets keep it simple: Using simple architectures to outperform deeper architectures ) ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Coderx7/SimpleNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 23,
      "date": "Thu, 23 Dec 2021 04:37:26 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Coderx7/SimpleNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Coderx7/SimpleNet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9322609392449874,
        0.877635197703164
      ],
      "excerpt": "Pytorch : \nFor using Pytorch implemnetation click Pytorch implementation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8214076149741596
      ],
      "excerpt": "| All you need is a good init (LSUV)      |    94.16     |      -      | \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8765911425545474
      ],
      "excerpt": "| Model      | MACC | COMP | ADD | DIV | Activations | Params | SIZE(MB) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8151369362694735
      ],
      "excerpt": "| ResNet-50      |  3.87G   |  10.89M  | 16.21M  | 10.59M  |     46.72M      |   25.56M   |    97.70     | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Coderx7/SimpleNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2017 Seyyed Hossein Hasan Pour\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Lets Keep it simple, Using simple architectures to outperform deeper and more complex architectures (2016).",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SimpleNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Coderx7",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Coderx7/SimpleNet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 77,
      "date": "Thu, 23 Dec 2021 04:37:26 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        0.877118600674591
      ],
      "excerpt": "How to improve object detection \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9969562844724977
      ],
      "excerpt": "A Yolo cross-platform Windows and Linux version (for object detection). Contributtors: https://github.com/pjreddie/darknet/graphs/contributors \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dwaithe/yolov2",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-03-29T12:25:31Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-09T10:49:24Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8991542656349587,
        0.991067225592752,
        0.948132169075817,
        0.9160677209119603
      ],
      "excerpt": "This network is used in unison with the Automated Microscopy Control Algorithm (AMCA) located in the following repository: https://github.com/dwaithe/amca. This repository is forked from Linux-version: https://github.com/pjreddie/darknet \nLargely the code is as in the original by PJ Reddie. Here there are some specific modifications for using on microscopy data by Dominic Waithe. \n- I changed the data augmentation to flip image vertically as well as horizontally. \n- Rather than using and evaluating on ImageNet I do so on my own microscopy data. This data is available here https://zenodo.org/record/2548493. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.866841361811332
      ],
      "excerpt": "How to compile on Linux \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9189854242214757
      ],
      "excerpt": "How to calculate mAP on PascalVOC 2007 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8556303529516746
      ],
      "excerpt": "How to mark bounded boxes of objects and create annotation files \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9633452392874654
      ],
      "excerpt": "This repository supports: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8299166424698432
      ],
      "excerpt": "Replace the address below, on shown in the phone application (Smart WebCam) and launch: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8105296482968791
      ],
      "excerpt": "* OPENMP=1 to build with OpenMP support to accelerate Yolo by using multi-core CPU \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8669661932453169
      ],
      "excerpt": "open \\darknet.sln -> (right click on project) -> properties  -> C/C++ -> Preprocessor -> Preprocessor Definitions, and add at the beginning of line: CUDNN; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8988889521982104
      ],
      "excerpt": "Then add to your created project: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9141212236067242
      ],
      "excerpt": "- add to project all .c & .cu files from \\src \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9034970316319945
      ],
      "excerpt": "-  (right click on project) -> properties  -> Linker -> Input -> Additional dependecies, put here:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9588146532828058
      ],
      "excerpt": "- (right click on project) -> properties -> C/C++ -> Preprocessor -> Preprocessor Definitions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9766161927973006
      ],
      "excerpt": "(Generally filters depends on the classes, num and coords, i.e. equal to (classes + coords + 1)*num, where num is number of anchors) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8979411005071259
      ],
      "excerpt": "  data/obj/img2.jpg \n  data/obj/img3.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.988266287233394
      ],
      "excerpt": "Do all the same steps as for the full yolo model as described above. With the exception of: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030738807590973
      ],
      "excerpt": "Choose weights-file with the highest IoU (intersect of union) and mAP (mean average precision) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.992002893611231,
        0.8997185071233157,
        0.9462966168653406
      ],
      "excerpt": "IoU (intersect of union) - average instersect of union of objects and detections for a certain threshold = 0.24 \nmAP (mean average precision) - mean value of average precisions for each class, where average precision is average value of 11 points on PR-curve for each possible threshold (each probability of detection) for the same class (Precision-Recall in terms of PascalVOC, where Precision=TP/(TP+FP) and Recall=TP/(TP+FN) ), page-11: http://homepages.inf.ed.ac.uk/ckiw/postscript/ijcv_voc09.pdf \nIn terms of Wiki, indicators Precision and Recall have a slightly different meaning than in the PascalVOC competition, but IoU always has the same meaning. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8089589788437591
      ],
      "excerpt": "Then there are 2 ways to get mAP: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9086147222393187
      ],
      "excerpt": "(The article specifies the value of mAP = 76.8% for YOLOv2 416\u00d7416, page-4 table-3: https://arxiv.org/pdf/1612.08242v1.pdf. We get values lower - perhaps due to the fact that the model was trained on a slightly different source code than the code on which the detection is was done) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8677692569661041,
        0.8280344704046255
      ],
      "excerpt": "for training with a large number of objects in each image, add the parameter max=200 or higher value in the last layer [region] in your cfg-file \nto speedup training (with decreasing detection accuracy) do Fine-Tuning instead of Transfer-Learning, set param stopbackward=1 in one of the penultimate convolutional layers, for example here: https://github.com/AlexeyAB/darknet/blob/cad4d1618fee74471d335314cb77070fee951a42/cfg/yolo-voc.2.0.cfg#L202 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9053512929171167
      ],
      "excerpt": "Increase network-resolution by set in your .cfg-file (height=608 and width=608) or (height=832 and width=832) or (any value multiple of 32) - this increases the precision and makes it possible to detect small objects: link \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8215478943909726
      ],
      "excerpt": "Here you can find repository with GUI-software for marking bounded boxes of objects and generating annotation files for Yolo v2: https://github.com/AlexeyAB/Yolo_mark \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8704697882761409
      ],
      "excerpt": "Simultaneous detection and classification of 9000 objects: \n",
      "technique": "Supervised classification"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* `yolo.cfg` (194 MB COCO-model) - require 4 GB GPU-RAM: http://pjreddie.com/media/files/yolo.weights\n* `yolo-voc.cfg` (194 MB VOC-model) - require 4 GB GPU-RAM: http://pjreddie.com/media/files/yolo-voc.weights\n* `tiny-yolo.cfg` (60 MB COCO-model) - require 1 GB GPU-RAM: http://pjreddie.com/media/files/tiny-yolo.weights\n* `tiny-yolo-voc.cfg` (60 MB VOC-model) - require 1 GB GPU-RAM: http://pjreddie.com/media/files/tiny-yolo-voc.weights\n* `yolo9000.cfg` (186 MB Yolo9000-model) - require 4 GB GPU-RAM: http://pjreddie.com/media/files/yolo9000.weights\n\nPut it near compiled: darknet.exe\n\nYou can get cfg-files by path: `darknet/cfg/`\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dwaithe/yolov2/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Mon, 27 Dec 2021 11:23:03 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dwaithe/yolov2/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "dwaithe/yolov2",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/dwaithe/yolov2/master/image_voc.sh",
      "https://raw.githubusercontent.com/dwaithe/yolov2/master/mjpeg_stream.sh",
      "https://raw.githubusercontent.com/dwaithe/yolov2/master/video_voc.sh",
      "https://raw.githubusercontent.com/dwaithe/yolov2/master/net_cam_voc.sh",
      "https://raw.githubusercontent.com/dwaithe/yolov2/master/scripts/dice_label.sh",
      "https://raw.githubusercontent.com/dwaithe/yolov2/master/scripts/gen_tactic.sh",
      "https://raw.githubusercontent.com/dwaithe/yolov2/master/scripts/imagenet_label.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8861518504264562,
        0.9230526238937559
      ],
      "excerpt": "How to compile on Linux \nHow to compile on Windows \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8290700962917505
      ],
      "excerpt": "A Yolo cross-platform Windows and Linux version (for object detection). Contributtors: https://github.com/pjreddie/darknet/graphs/contributors \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9271281673501826
      ],
      "excerpt": "both Windows and Linux \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8444225293496384,
        0.8411004553040458
      ],
      "excerpt": "both cuDNN v5-v7 \nCUDA >= 7.5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9451957319250918,
        0.9390280262067607,
        0.8797838877753553,
        0.9292919430580964
      ],
      "excerpt": "Linux GCC>=4.9 or Windows MS Visual Studio 2015 (v140): https://go.microsoft.com/fwlink/?LinkId=532606&clcid=0x409  (or offline ISO image) \nCUDA 9.1: https://developer.nvidia.com/cuda-downloads \nOpenCV 3.4.0: https://sourceforge.net/projects/opencvlibrary/files/opencv-win/3.4.0/opencv-3.4.0-vc14_vc15.exe/download \nor OpenCV 2.4.13: https://sourceforge.net/projects/opencvlibrary/files/opencv-win/2.4.13/opencv-2.4.13.2-vc14.exe/download \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9875395931933965
      ],
      "excerpt": "GPU with CC >= 2.0 if you use CUDA, or GPU CC >= 3.0 if you use cuDNN + CUDA: https://en.wikipedia.org/wiki/CUDA#GPUs_supported \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.811319624300472
      ],
      "excerpt": "Start Smart WebCam on your phone \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8044083335257789
      ],
      "excerpt": "Just do make in the darknet directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.976885133954891,
        0.8752615859580927
      ],
      "excerpt": "* GPU=1 to build with CUDA to accelerate by using GPU (CUDA should be in /usr/local/cuda) \n* CUDNN=1 to build with cuDNN v5-v7 to accelerate training by using GPU (cuDNN should be in /usr/local/cudnn) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9631039082873826
      ],
      "excerpt": "If you have MSVS 2015, CUDA 9.1 and OpenCV 3.0 (with paths: C:\\opencv_3.0\\opencv\\build\\include & C:\\opencv_3.0\\opencv\\build\\x64\\vc14\\lib), then start MSVS, open build\\darknet\\darknet.sln, set x64 and Release, and do the: Build -> Build darknet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9591987711399047,
        0.962596104775014
      ],
      "excerpt": "If you have other version of CUDA (not 9.1) then open build\\darknet\\darknet.vcxproj by using Notepad, find 2 places with \"CUDA 9.1\" and change it to your CUDA-version, then do step 1 \nIf you don't have GPU, but have MSVS 2015 and OpenCV 3.0 (with paths: C:\\opencv_3.0\\opencv\\build\\include & C:\\opencv_3.0\\opencv\\build\\x64\\vc14\\lib), then start MSVS, open build\\darknet\\darknet_no_gpu.sln, set x64 and Release, and do the: Build -> Build darknet_no_gpu \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8379021737860485,
        0.9806485596022798,
        0.9309039827099643
      ],
      "excerpt": "If you want to build with CUDNN to speed up then: \ndownload and install cuDNN 7.0 for CUDA 9.1: https://developer.nvidia.com/cudnn \nadd Windows system variable cudnn with path to CUDNN: https://hsto.org/files/a49/3dc/fc4/a493dcfc4bd34a1295fd15e0e2e01f26.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8847562642029537
      ],
      "excerpt": "Also, you can to create your own darknet.sln & darknet.vcxproj, this example for CUDA 9.1 and OpenCV 3.0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.875650876183317
      ],
      "excerpt": "- (right click on project) -> Build dependecies -> Build Customizations -> set check on CUDA 9.1 or what version you have - for example as here: http://devblogs.nvidia.com/parallelforall/wp-content/uploads/2015/01/VS2013-R-5.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9296625389598782
      ],
      "excerpt": "cusolver64_91.dll, curand64_91.dll, cudart64_91.dll, cublas64_91.dll - 91 for CUDA 9.1 or your version, from C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.1\\bin \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8466183741406523
      ],
      "excerpt": "For OpenCV 2.4.13: opencv_core2413.dll, opencv_highgui2413.dll and opencv_ffmpeg2413_64.dll from  C:\\opencv_2.4.13\\opencv\\build\\x64\\vc14\\bin \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9837438037624533
      ],
      "excerpt": "Download and install Python for Windows: https://www.python.org/ftp/python/3.5.2/python-3.5.2-amd64.exe \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.829704442551866
      ],
      "excerpt": "Also you can get result earlier than all 45000 iterations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8324839727464387
      ],
      "excerpt": "Download PascalVOC dataset, install Python 3.x and get file 2007_test.txt as described here: https://github.com/AlexeyAB/darknet#how-to-train-pascal-voc-data \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8377090365529959
      ],
      "excerpt": "How to train (Pascal VOC Data) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8688523306653981
      ],
      "excerpt": "- add to project all .c & .cu files from \\src \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401588059931042
      ],
      "excerpt": "Download The Pascal VOC Data and unpack it to directory build\\darknet\\x64\\data\\voc will be created dir build\\darknet\\x64\\data\\voc\\VOCdevkit\\: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9020260040251167
      ],
      "excerpt": "2.1 Download file voc_label.py to dir build\\darknet\\x64\\data\\voc: http://pjreddie.com/media/files/voc_label.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8645231307703959
      ],
      "excerpt": "Run command: python build\\darknet\\x64\\data\\voc\\voc_label.py (to generate files: 2007_test.txt, 2007_train.txt, 2007_val.txt, 2012_train.txt, 2012_val.txt) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8683439956015095
      ],
      "excerpt": "Start training by using train_voc.cmd or by using the command line: darknet.exe detector train data/voc.data yolo-voc.2.0.cfg darknet19_448.conv.23 (Note: To disable Loss-Window use flag -dont_show. If you are using CPU, try darknet_no_gpu.exe instead of darknet.exe.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8839048520372936,
        0.8607408777988208
      ],
      "excerpt": "Train it first on 1 GPU for like 1000 iterations: darknet.exe detector train data/voc.data yolo-voc.2.0.cfg darknet19_448.conv.23 \nThen stop and by using partially-trained model /backup/yolo-voc_1000.weights run training with multigpu (up to 4 GPUs): darknet.exe detector train data/voc.data yolo-voc.2.0.cfg /backup/yolo-voc_1000.weights -gpus 0,1,2,3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.877731550916042,
        0.8202257195562564
      ],
      "excerpt": "Create file obj.names in the directory build\\darknet\\x64\\data\\, with objects names - each in new line \nCreate file obj.data in the directory build\\darknet\\x64\\data\\, containing (where classes = number of objects): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8933741375046061,
        0.8428497312187538
      ],
      "excerpt": "  train  = data/train.txt \n  valid  = data/test.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8237249625365071
      ],
      "excerpt": "Put image-files (.jpg) of your objects in the directory build\\darknet\\x64\\data\\obj\\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8544845343256366
      ],
      "excerpt": "For example for img1.jpg you should create img1.txt containing: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9410048613256292
      ],
      "excerpt": "Create file train.txt in directory build\\darknet\\x64\\data\\, with filenames of your images, each filename in new line, with path relative to darknet.exe, for example containing: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8860031283138505
      ],
      "excerpt": "Start training by using the command line: darknet.exe detector train data/obj.data yolo-obj.cfg darknet19_448.conv.23 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8458885468892599
      ],
      "excerpt": "After each 1000 iterations you can stop and later start training from this point. For example, after 2000 iterations you can stop training, and later just copy yolo-obj_2000.weights from build\\darknet\\x64\\backup\\ to build\\darknet\\x64\\ and start training using: darknet.exe detector train data/obj.data yolo-obj.cfg yolo-obj_2000.weights \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8719351761670333
      ],
      "excerpt": "2.1. At first, in your file obj.data you must specify the path to the validation dataset valid = valid.txt (format of valid.txt as in train.txt), and if you haven't validation images, just copy data\\train.txt to data\\valid.txt. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8547348386270781
      ],
      "excerpt": "Then download file https://raw.githubusercontent.com/AlexeyAB/darknet/master/scripts/voc_label_difficult.py to the dir build\\darknet\\x64\\data\\voc then run voc_label_difficult.py to get the file difficult_2007_test.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8014014222502843
      ],
      "excerpt": "Using Darknet + Python: run the file build/darknet/x64/calc_mAP_voc_py.cmd - you will get mAP for yolo-voc.cfg model, mAP = 75.9% \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8122973964631659
      ],
      "excerpt": "With example of: train.txt, obj.names, obj.data, yolo-obj.cfg, air1-6.txt, bird1-4.txt for 2 classes of objects (air, bird) and train_obj.cmd with example how to train this image-set with Yolo v2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.809547384061538
      ],
      "excerpt": "9k.names - \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dwaithe/yolov2/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "C",
      "Cuda",
      "Python",
      "C++",
      "Batchfile",
      "Makefile",
      "Shell",
      "Objective-C"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/dwaithe/yolov2/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'                                  YOLO LICENSE\\n                             Version 2, July 29 2016\\n\\nTHIS SOFTWARE LICENSE IS PROVIDED \"ALL CAPS\" SO THAT YOU KNOW IT IS SUPER\\nSERIOUS AND YOU DON\\'T MESS AROUND WITH COPYRIGHT LAW BECAUSE YOU WILL GET IN\\nTROUBLE HERE ARE SOME OTHER BUZZWORDS COMMONLY IN THESE THINGS WARRANTIES\\nLIABILITY CONTRACT TORT LIABLE CLAIMS RESTRICTION MERCHANTABILITY. NOW HERE\\'S\\nTHE REAL LICENSE:\\n\\n0. Darknet is public domain.\\n1. Do whatever you want with it.\\n2. Stop emailing me about it!\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Yolo-v2 modified for microscopy (Windows and Linux version).",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "yolov2",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "dwaithe",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dwaithe/yolov2/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "dwaithe",
        "body": "Release used upon publication of AMCA\r\n\r\nhttps://www.biorxiv.org/content/10.1101/544833v1",
        "dateCreated": "2019-02-01T11:28:28Z",
        "datePublished": "2019-03-15T09:38:25Z",
        "html_url": "https://github.com/dwaithe/yolov2/releases/tag/v0.3",
        "name": "YOLOv2 for AMCA publication release",
        "tag_name": "v0.3",
        "tarball_url": "https://api.github.com/repos/dwaithe/yolov2/tarball/v0.3",
        "url": "https://api.github.com/repos/dwaithe/yolov2/releases/16135549",
        "zipball_url": "https://api.github.com/repos/dwaithe/yolov2/zipball/v0.3"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 12,
      "date": "Mon, 27 Dec 2021 11:23:03 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* `darknet_voc.cmd` - initialization with 194 MB VOC-model yolo-voc.weights & yolo-voc.cfg and waiting for entering the name of the image file\n* `darknet_demo_voc.cmd` - initialization with 194 MB VOC-model yolo-voc.weights & yolo-voc.cfg and play your video file which you must rename to: test.mp4\n* `darknet_demo_store.cmd` - initialization with 194 MB VOC-model yolo-voc.weights & yolo-voc.cfg and play your video file which you must rename to: test.mp4, and store result to: res.avi\n* `darknet_net_cam_voc.cmd` - initialization with 194 MB VOC-model, play video from network video-camera mjpeg-stream (also from you phone)\n* `darknet_web_cam_voc.cmd` - initialization with 194 MB VOC-model, play video from Web-Camera number #0\n* `darknet_coco_9000.cmd` - initialization with 186 MB Yolo9000 COCO-model, and show detection on the image: dog.jpg\n* `darknet_coco_9000_demo.cmd` - initialization with 186 MB Yolo9000 COCO-model, and show detection on the video (if it is present): street4k.mp4, and store result to: res.avi\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "On Linux use `./darknet` instead of `darknet.exe`, like this:`./darknet detector test ./cfg/coco.data ./cfg/yolo.cfg ./yolo.weights`\n\n* 194 MB COCO-model - image: `darknet.exe detector test data/coco.data yolo.cfg yolo.weights -i 0 -thresh 0.2`\n* Alternative method 194 MB COCO-model - image: `darknet.exe detect yolo.cfg yolo.weights -i 0 -thresh 0.2`\n* 194 MB VOC-model - image: `darknet.exe detector test data/voc.data yolo-voc.cfg yolo-voc.weights -i 0`\n* 194 MB COCO-model - video: `darknet.exe detector demo data/coco.data yolo.cfg yolo.weights test.mp4 -i 0`\n* 194 MB VOC-model - video: `darknet.exe detector demo data/voc.data yolo-voc.cfg yolo-voc.weights test.mp4 -i 0`\n* 194 MB COCO-model - **save result to the file res.avi**: `darknet.exe detector demo data/coco.data yolo.cfg yolo.weights test.mp4 -i 0 -out_filename res.avi`\n* 194 MB VOC-model - **save result to the file res.avi**: `darknet.exe detector demo data/voc.data yolo-voc.cfg yolo-voc.weights test.mp4 -i 0 -out_filename res.avi`\n* Alternative method 194 MB VOC-model - video: `darknet.exe yolo demo yolo-voc.cfg yolo-voc.weights test.mp4 -i 0`\n* 60 MB VOC-model for video: `darknet.exe detector demo data/voc.data tiny-yolo-voc.cfg tiny-yolo-voc.weights test.mp4 -i 0`\n* 194 MB COCO-model for net-videocam - Smart WebCam: `darknet.exe detector demo data/coco.data yolo.cfg yolo.weights http://192.168.0.80:8080/video?dummy=param.mjpg -i 0`\n* 194 MB VOC-model for net-videocam - Smart WebCam: `darknet.exe detector demo data/voc.data yolo-voc.cfg yolo-voc.weights http://192.168.0.80:8080/video?dummy=param.mjpg -i 0`\n* 194 MB VOC-model - WebCamera #0: `darknet.exe detector demo data/voc.data yolo-voc.cfg yolo-voc.weights -c 0`\n* 186 MB Yolo9000 - image: `darknet.exe detector test cfg/combine9k.data yolo9000.cfg yolo9000.weights`\n* 186 MB Yolo9000 - video: `darknet.exe detector demo cfg/combine9k.data yolo9000.cfg yolo9000.weights test.mp4`\n* Remeber to put data/9k.tree and data/coco9k.map under the same folder of your app if you use the cpp api to build an app\n* To process a list of images `data/train.txt` and save results of detection to `result.txt` use:                             \n    `darknet.exe detector test data/voc.data yolo-voc.cfg yolo-voc.weights -dont_show < data/train.txt > result.txt`\n    You can comment this line so that each image does not require pressing the button ESC: https://github.com/AlexeyAB/darknet/blob/6ccb41808caf753feea58ca9df79d6367dedc434/src/detector.c#L509\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. To compile Yolo as C++ DLL-file `yolo_cpp_dll.dll` - open in MSVS2015 file `build\\darknet\\yolo_cpp_dll.sln`, set **x64** and **Release**, and do the: Build -> Build yolo_cpp_dll\n    * You should have installed **CUDA 9.1**\n    * To use cuDNN do: (right click on project) -> properties -> C/C++ -> Preprocessor -> Preprocessor Definitions, and add at the beginning of line: `CUDNN;`\n\n2. To use Yolo as DLL-file in your C++ console application - open in MSVS2015 file `build\\darknet\\yolo_console_dll.sln`, set **x64** and **Release**, and do the: Build -> Build yolo_console_dll\n\n    * you can run your console application from Windows Explorer `build\\darknet\\x64\\yolo_console_dll.exe`\n    * or you can run from MSVS2015 (before this - you should copy 2 files `yolo-voc.cfg` and `yolo-voc.weights` to the directory `build\\darknet\\` )\n    * after launching your console application and entering the image file name - you will see info for each object: \n    `<obj_id> <left_x> <top_y> <width> <height> <probability>`\n    * to use simple OpenCV-GUI you should uncomment line `//#define OPENCV` in `yolo_console_dll.cpp`-file: [link](https://github.com/AlexeyAB/darknet/blob/a6cbaeecde40f91ddc3ea09aa26a03ab5bbf8ba8/src/yolo_console_dll.cpp#L5)\n    * you can see source code of simple example for detection on the video file: [link](https://github.com/AlexeyAB/darknet/blob/ab1c5f9e57b4175f29a6ef39e7e68987d3e98704/src/yolo_console_dll.cpp#L75)\n   \n`yolo_cpp_dll.dll`-API: [link](https://github.com/AlexeyAB/darknet/blob/master/src/yolo_v2_class.hpp#L42)\n```\nclass Detector {\npublic:\n\tDetector(std::string cfg_filename, std::string weight_filename, int gpu_id = 0);\n\t~Detector();\n\n\tstd::vector<bbox_t> detect(std::string image_filename, float thresh = 0.2, bool use_mean = false);\n\tstd::vector<bbox_t> detect(image_t img, float thresh = 0.2, bool use_mean = false);\n\tstatic image_t load_image(std::string image_filename);\n\tstatic void free_image(image_t m);\n\n#:ifdef OPENCV\n\tstd::vector<bbox_t> detect(cv::Mat mat, float thresh = 0.2, bool use_mean = false);\n#:endif\n};\n```\n",
      "technique": "Header extraction"
    }
  ]
}
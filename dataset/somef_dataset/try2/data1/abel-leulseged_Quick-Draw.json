{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Baseline RNN model forked from Kevin Mader [here](https://www.kaggle.com/kmader/quickdraw-baseline-lstm-reading-and-submission)  \nCNN model forked from JohnM [here](https://www.kaggle.com/jpmiller/image-based-cnn)  \nhttp://cs230.stanford.edu/files_winter_2018/projects/6921313.pdf  \nhttps://uu.diva-portal.org/smash/get/diva2:1218490/FULLTEXT01.pdf  \nhttps://arxiv.org/pdf/1704.03477.pdf  \nhttps://www.theverge.com/2017/6/26/15877020/google-ai-experiment-sketch-rnn-doodles-quick-draw  \nhttps://github.com/KKeishiro/Sketch-RNN/blob/master/sketch_rnn_model.py  \nhttps://www.kaggle.com/c/quickdraw-doodle-recognition/discussion/70558  \n\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/abel-leulseged/Quick-Draw",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-11-26T06:20:37Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-13T22:55:19Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Quick, Draw! game was originally an experimental game released by Google to teach the general population about artificial intelligence. The game asks the user to draw a picture of an object or idea and uses a neural network artificial intelligence to guess what the sketch represents. Moreover, the network continues to guess as the user draws, even though the sketch is incomplete. The network uses such drawings to learn and increase its accuracy in the future.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8206005161679423
      ],
      "excerpt": "We are given two datasets from Kaggle. The raw data (65.87 GB) is the exact input recorded from user drawing. The simplified data (7.37 GB) removes unnecessary information from the vector. Kaggle provides such an example. Imagine a straight line was recorded with 8 points. Then the simplified version removes 6 points to create a line with 2 points. Each csv file represents one \"label\" representing the drawing. Each row in the csv file represents a drawing or sketch with multiple strokes. Each stroke is represented by x,y, and t coordinates where t stands for time. Moreover, these are represented by nested arrays.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9848926241646926,
        0.8979411005071259,
        0.9936753100216138,
        0.9481160372267499,
        0.9865035461832682,
        0.8705036638742941,
        0.9721841242801389
      ],
      "excerpt": "Since our dataset was so big (~70 GB total), it was hard to get it onto our google compute instance. We looked into and tried out a few approaches but the one we ended up using, which in our opinion was the simplest solution was to mount the file system of our GCE instance into our local machine and treat our entire GCE directory as a local subdirectory. We were then able to just copy the dataset as you would any file from one subdirectory to another. This was also helpful when we later wanted to actually open and look at some of the csv files in our dataset since using vim while we were SSHed to look at a csv with thousands of lines was rather messy. The instructions we found and followed on how to mount filesystems can be found here.  \nCleaning Data \nFor our CNN model, we tried converting the stroke of the drawings into images and saving them into subdirectories for later training. Even though we tried different variations improving the efficiency of our code, it would take incredibly long to run. We later found an online implementation that used a few tricks to expedite the cleaning code (i.e. not writing out the images into actual files, using matplotlib instead of PIL or openCV.  \nLoading and Cleaning the Data repeatedly for different runs \nSince we were working with such a huge dataset, we would have to load and clean the data for every session. Even with the subset of the smaller dataset, this takes incredibly long. As such, we looked into ways we could save the loaded and cleaned panda dataframes for easier and faster reloading. We chose to use the HDF5 file format. However, even though we tried different ways of storing dataframes onto HDF5 files, we kept running into errors related to our version of python and or pandas. And since it did not seem reasonable to downgrade an already working part of our virtual environment, we chose to abandon this avenue. \nTime and Resource Exhaustion during hyperparameter tuning  \nWe repeatedly ran into Resource exhaustion errors. We would often not know how to fix this error so we would switch temporarily to a Kaggle kernel (considerably slower than our GCE instance). And since Kaggle has a 6 hour time limit and we also ran into the same error there, we concluded the error was not specific to our GCE instance. Upon further investigation, we found that our GPU memory was full. We fixed this by clearing our GPU memory using the %reset -f command. Note that clearing and restarting the kernel does not fix this.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9454423042420895,
        0.9980806275714843,
        0.8990776130021082,
        0.8191350048502996,
        0.9574379528143425,
        0.9993438756540112
      ],
      "excerpt": "The two most common type of neural network structures used were RNN and CNN. Our first choice was to implement an RNN. Consequently, we took a baseline model from Kevin Mader and decided to first see how well it performed. We discovered that there were many issues with the baseline model(523,002 trainable params). First, the training took too long, the accuracy was too low, and the model was too complicated for its subpar performance. \nWe referred to various research articles and kaggle discussions on how we could improve the baseline RNN model. To begin with, we chose to simplify the model. The first thing we did was remove all dropout layers. Since the model was not doing well enough to even overfit, it did not make sense to have regularization yet. Removing all the dropout layers increased our initial accuracy of 4.6% and top 3 accuracy of 10.8% to an accuracy of 8.3 and top 3 accuracy of 15% (both for just 10 epochs on the whole data). This seemed to indicate we were on the right path so we proceeded to simplify the model even further. We removed all the 1D convolutions and instead used only one Global Average Pooling layer, which according to some experts in the kaggle discussion and a research paper found here is actually better in that it can also be used to regularize. Through various combinations of parameters and after numerous test runs, we eventually chose to have the architecture shown below. However, there are various architectures that we came across during the course of this project that we came up with on our own or read about in publications. \nFor instance, one of our simpler architectures with no dropout and just one LSTM (totally 44,396 trainable params) had accuracy: 13.0%, Top 3 Accuracy:25.3%. \nWhen we made the LSTM bidirectional we got Accuracy: 18.5%, Top 3 Accuracy 33.9%. \nTo put these values in context, the baseline model took 16.443 mins to train for 10 epochs on the whole dataset and got Accuracy: 4.6%, Top 3 Accuracy 10.8% whereas our model took 251 sec ~4.2 mins to train and had Accuracy: 18.5%, Top 3 Accuracy 33.9%. Also, please keep in mind that these accuracies are low because we are only doing 10 epochs and this was done to expedite hyperparameter tuning and training since having to run for hundreds of epochs everytime we change some parameter would take a few hours for a single model. \nAnother interesting and effective thing we learned about over the course of this project is the keras callback method. Apparently, keras lets us specify a set of callbacks to keep in mind during training. These callbacks include but are not limited to reducing learning rate on a plateau, saving the model the second it does better (checkpoint),   and early stopping. In our case, reducing learning rate on plateau was particularly useful since our training plots from the baseline model show that there were lots of plateaus and we wanted to avoid these plateaus so that our model trains more efficiently. And so, we tinkered with the parameters of the ReduceLROnPlateau to avoid these plateaus and were pleased with the results. As is apparent from the explanations above and the graphs below, we avoided the plateaus, which resulted in a significantly shorter training time and even better accuracy. More detailed documentation of the keras' callbacks can be found here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8620109807112113
      ],
      "excerpt": "The Architecture of the modified RNN:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9980005648559243
      ],
      "excerpt": "We next attempted to compare the performance of our modified RNN to a CNN model since the model that won first place was a CNN model. As a result, we similarly took a baseline model from JohnM and after some minor tweaks. For the architecture of the model, we found that it was best to start with a 2D convolutional layer instead of a fully connected layer because it would otherwise lose spatial information. We also kept some of the original structure such as the implementation of max pooling to downsample the features and flatten to transform a tensor of any shape to a one-dimensional tensor. Finally, we incorporated dropouts in between each dense layer that we added. The reason we added it after a dense layer instead of a convolutional layer was that a convolutional layer has fewer parameters than a dense layer. As a result, a convolutional layer has less of a need for regularization to prevent overfitting compared to a fully connected dense layer. When ran on the Kaggle kernel, the final result of our implementation came out to be a validation accuracy of 65.63%, validation loss of 1.2015, and a top 3 validation accuracy of 85.17%. The results of the loss and accuracy are shown in the graph below. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Using Deep Learning to classify doodles as they are being drawn",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/abel-leulseged/Quick-Draw/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To begin, the training data comes from the actual Google game itself. Consequently, they may be incomplete or may not even represent the label. As a result, the task is to build a better classifier using the noisy dataset. \n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Wed, 29 Dec 2021 22:03:33 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/abel-leulseged/Quick-Draw/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "abel-leulseged/Quick-Draw",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/abel-leulseged/Quick-Draw/master/Baseline%20RNN.ipynb",
      "https://raw.githubusercontent.com/abel-leulseged/Quick-Draw/master/CNN.ipynb",
      "https://raw.githubusercontent.com/abel-leulseged/Quick-Draw/master/Modified%20RNN.ipynb",
      "https://raw.githubusercontent.com/abel-leulseged/Quick-Draw/master/.ipynb_checkpoints/CNN%20MobileNet-checkpoint.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8268980526118367
      ],
      "excerpt": "45 mins to an hour per model depending on the batch size and model (CNN or RNN). \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/abel-leulseged/Quick-Draw/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Quick-Draw",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Quick-Draw",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "abel-leulseged",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/abel-leulseged/Quick-Draw/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 22:03:33 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "RNN baseline submission  \n![rnn_baseline_submission](https://user-images.githubusercontent.com/35898484/50037183-9d720100-ffc3-11e8-8ea4-1b15060b480c.png)  \nRNN Modified submission    \n![rnn_modified_submission](https://user-images.githubusercontent.com/35898484/50037193-ba0e3900-ffc3-11e8-9a5c-1f3e646ca195.png)  \n\n",
      "technique": "Header extraction"
    }
  ]
}
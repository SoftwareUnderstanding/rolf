{
  "citation": [
    {
      "confidence": [
        0.9331059471198938
      ],
      "excerpt": "allennlp evaluate --cuda-device -0 -o '{\"iterator\": {\"base_iterator\": {\"maximum_samples_per_batch\": [\"num_tokens\", 500], \"max_instances_in_memory\": 8192, \"batch_size\": 128 }}}' ../transformer-elmo-2019.01.10.tar.gz ../MP-Tweets/filtered_split_test.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9331059471198938
      ],
      "excerpt": "allennlp evaluate --cuda-device -0 -o '{\"iterator\": {\"base_iterator\": {\"maximum_samples_per_batch\": [\"num_tokens\", 300], \"max_instances_in_memory\": 16384, \"batch_size\": 512 }}}' ../transformer-elmo-2019.01.10.tar.gz ../amazon/filtered_split_test.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9331059471198938
      ],
      "excerpt": "allennlp evaluate --cuda-device -0 -o '{\"iterator\": {\"base_iterator\": {\"maximum_samples_per_batch\": [\"num_tokens\", 300], \"max_instances_in_memory\": 16384, \"batch_size\": 512 }}}' ../transformer-elmo-2019.01.10.tar.gz ../yelp/splits/filtered_split_test.txt \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/apmoore1/language-model",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-03T16:49:29Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-21T19:38:22Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9316763808391705
      ],
      "excerpt": "The Transformer ELMo model that came from the following paper was trained on the 1 Billion word corpus that can be downloaded from here and a good tutorial about the model can be found here. As the downloaded 1 billion corpus has already been tokenised and the Transformer ELMo model that has been downloaded comes with a fixed output vocabulary, we show that the vocabularly comes from only the training corpus and from words that have a frequency of at least 3 in the training corpus. We also find that not all the words in the test corpus are in the training corpus of the 1 billion word corpus. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8765189266741319,
        0.9248898753111897,
        0.9695741123146733
      ],
      "excerpt": "NOTE: It is required to un-tar the transformer-elmo-2019.01.10.tar.gz as the vocabulary is required and the weights therefore we assume you have un-tared it into the following folder ../transformer_unpacked \nTo see how we discovered how the Transformer ELMo model output vocabularly was discovered and how this vocabularly MORE IMPORTANTLY overlaps with the TDSA data and the TDSA target words look at the following mark down file \nThe Yelp dataset was accessed on the week starting the 1st of April 2019, this is important as Yelp releases a new dataset every year. We only used reviews that review businesses from the following categories restaurants restaurant restaurants, this was to ensure that the domain of the reviews were similar to the restaurant review domain (some reviews are about hospitals etc). To filter the reviews we ran the following command: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9964982232495331
      ],
      "excerpt": "Once we have the filtered data we are only interested in the text of the data as we want to fine tune the Transformer ELMo model from the news corpus data it was original trained on to restaurant reviews. This is because restaurant reviews use a slightly different vocabularly (for examples see this) and more than likely a different language style to news data.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9532085363916102
      ],
      "excerpt": "Based on the data statistics we are going to further filter the Yelp sentences dataset so that it only includes sentences that are at least 3 tokens long. We will also restrict the maximum sentence length to 40 as there are so few review sentences greater than this (2.48%). To do this run the following command: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8777303043127905
      ],
      "excerpt": "This will create three more files within the ../yelp/splits directory; filtered_split_train.txt, filtered_split_val.txt, and filtered_split_test.txt. These train, validation, and test splits are the final dataset that we will use to fine tune the Transformer ELMo model on for the restaurant review domain. Now we can re-run the data statistics to see the proportions and distribution of token and sentence length frequencies of the new filtered yelp training, validation, and test data: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8623462614283427,
        0.8863486596456278,
        0.8164206993972365,
        0.8959106297091026,
        0.979837783506846
      ],
      "excerpt": "1. Training set has a mean sentence length of 14.78 (8.02) with 27,286,698 sentences and 218,903 tokens that occur at least 3 times. Distribution of the sentence lengths can be found here. \n2. Validation set has a mean sentence length of 14.78 (8.01) with 2,606,292 sentences and 69,106 tokens that occur at least 3 times. Distribution of the sentence lengths can be found here. \n3. Test set has a mean sentence length of 14.77 (8.01) with 2,602,337 sentences and 68,588 tokens that occur at least 3 times. Distribution of the sentence lengths can be found here. \nAs we can see the sentence lengths and standard devations are very similar across the splits. \nWe want to compare the words that are in the Yelp Training data to those TDSA restaurant dataset. Therefore we are going to follow similar steps to those used in analysising the vocabulary of the Transformer ELMo and the TDSA data which can be found here. First we need to create a vocabulary for the Yelp Training data: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8470751860381753
      ],
      "excerpt": "Now the vocabulary is created and assuming you have done the steps in here we want to compare the restaurant TDSA \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9029352330228876
      ],
      "excerpt": "We find that there are 16 target words not in the Yelp training data and that these 16 target words affect only 16 samples out of the 4722 samples in the whole of the restaurant TDSA (train, validation, and test sets). Examples of these words: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9661152262809016
      ],
      "excerpt": "We find that there are 156 words that are not in the Yelp training vocabulary but are in the TDSA dataset of which 25 of these are target words that affect 26 targets and 26 samples of he 4722 samples across training, validation, and test sets. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.960770111199991
      ],
      "excerpt": "Based on the data statistics we are going to further filter the Amazon sentences dataset so that it only includes sentences that are at least 3 tokens long. We will also restrict the maximum sentence length to 50 as there are so few review sentences greater than this (2.48%). To do this run the following command: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8667361593825902,
        0.8900105608075725,
        0.8222337127068776,
        0.8959106297091026,
        0.9836520024116403
      ],
      "excerpt": "1. Training set has a mean sentence length of 18.06 (9.81) with 9,580,995 sentences and 182,900 tokens that occur at least 3 times. Distribution of the sentence lengths can be found here. \n2. Validation set has a mean sentence length of 18.03 (9.81) with 907,343 sentences and 47,255 tokens that occur at least 3 times. Distribution of the sentence lengths can be found here. \n3. Test set has a mean sentence length of 18.07 (9.83) with 905,555 sentences and 47,178 tokens that occur at least 3 times. Distribution of the sentence lengths can be found here. \nAs we can see the sentence lengths and standard devations are very similar across the splits. \nThe MP Twitter data is created using the following GitHub Repositroy. The data contains 2,464,909 Tweets, these Tweets are found on this computer here ../MP-Tweets/all_mp_data.json. The Tweets were collected from June the 7th 2019 to July the 10th 2019, these tweets are all tweets that mention 1 of the 399 verified MP Twitter handles. These 399 MPs were chosen as they were the top 399 MP on Twitter based on the number of followers (this was found through the following website). We now need to create Train, Validation, and Test datasets for the Language Model to be trained on. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9532085363916102
      ],
      "excerpt": "Based on the data statistics we are going to further filter the MP tweets dataset so that it only includes sentences that are at least 3 tokens long. We will also restrict the maximum sentence length to 60 as there are so few review sentences greater than this (3.98%). To do this run the following command: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8715505303755262,
        0.889232617374545,
        0.8259797510369887,
        0.8959106297091026
      ],
      "excerpt": "1. Training set has a mean sentence length of 25.28 (15.52) with 1,980,600 sentences and 180,501 tokens that occur at least 3 times. Distribution of the sentence lengths can be found here. \n2. Validation set has a mean sentence length of 25.24 (15.53) with 188,552 sentences and 46,707 tokens that occur at least 3 times. Distribution of the sentence lengths can be found here. \n3. Test set has a mean sentence length of 25.22 (15.51) with 188,417 sentences and 46,769 tokens that occur at least 3 times. Distribution of the sentence lengths can be found here. \nAs we can see the sentence lengths and standard devations are very similar across the splits. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9929075960151175
      ],
      "excerpt": "Loss of 4.28(4.281530955097563)  which is a perplexity of 72.35 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9929075960151175,
        0.9522563267600949
      ],
      "excerpt": "Loss of 5.32(5.322864265508469)  which is a perplexity of 204.97 \nIn this section we show how you can fine tune the Transformer ELMo model to other domains and mediums. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.825770035156944
      ],
      "excerpt": "Where ../amazon_lm_vocab is a new directory that stores only the vocabulary files, of which the vocabulary that will be used can be found here ../amazon_lm_vocab/tokens.txt. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8885988345086872,
        0.9864098343523268,
        0.8608269022082391
      ],
      "excerpt": "Where ../amazon_language_model_save_large is the directory that will save the language model to. \nWe got a perplexity score of 24.78 perplexity which is a loss of 3.21. \nWe did not do any quick test to see the difference of using a pre-trained model and not. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9773008988920213
      ],
      "excerpt": "We achieved a perplexity of 29.15 which is a loss of 3.37 (3.3725986638315453) which is close to the training loss. We now compare that to the non-fine tuned model which was trained on the 1 billion word corpus which came from news data, to do this run the following command: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8990151168351264,
        0.9728035336701888
      ],
      "excerpt": "This will take longer to run (4 hours 30 minutes on a 1060 6GB GPU) as it has a much larger vocabulary therefore a much large softmax layer to compute within the neural network. We got a loss of 4.70 (4.7040290288591615) which is a perplexity score of 110.39.  \nAs we can see fine tunning to the dataset has made large difference with respect to the language model score. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.825770035156944
      ],
      "excerpt": "Where ../yelp_lm_vocab is a new directory that stores only the vocabulary files, of which the vocabulary that will be used can be found here ../yelp_lm_vocab/tokens.txt. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8885988345086872,
        0.9864098343523268,
        0.9086470347271549
      ],
      "excerpt": "Where ../yelp_language_model_save_large is the directory that will save the language model to. \nWe got a perplexity score of 24.78 perplexity which is a loss of 3.21. \nWe currently find that using the pre-trained model does not help at first but within 1 hour of training the perplexity decreases quicker suggesting that model finds it easier to learn more quickily through pre-training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9814819759921194
      ],
      "excerpt": "We achieved a perplexity of 24.53 which is a loss of 3.20 (3.207513492262822) which is almost identical to the training loss. We now compare that to the non-fine tuned model which was trained on the 1 billion word corpus which came from news data, to do this run the following command: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8542141661412646,
        0.9728035336701888,
        0.9952811890181464,
        0.8916227522211361,
        0.9089638579073367,
        0.9183095894691079,
        0.8808606845599417,
        0.9710790134665193
      ],
      "excerpt": "This will take longer to run (10 hours 45 minutes on a 1060 6GB GPU) as it has a much larger vocabulary therefore a much large softmax layer to compute within the neural network. We got a loss of 4.61 (4.612278219667751) which is a perplexity score of 100.71.  \nAs we can see fine tunning to the dataset has made large difference with respect to the language model score. \nOther suggestion for training better with a pre-trained model would be to use something like the ULMFit model as currently we are using a learning rate schduler that is similar in warm up and decreasing but it does not care about the different layers i.e. does not freeze any of the layers at different epochs nor does it have a different learning rate for different layers all of this could be important for us. We have also not looked at the best learning rate which we could do through fine learning rate which is based on the training data and batches. To find the number of parameter groups for the ULMFit model see this \nAll of the CWR models can be found at the following URL https://ucrel-web.lancs.ac.uk/moorea/research/phd_thesis/resources/CWR/. To summaries:  \nThe MP Twitter CWR (called election_model.tar.gz at the URL address) has been completely fine tuned from scratch on the MP Twitter data. MP Twiiter fine tuning dataset has a mean sentence length of 25.28 (15.52) with 1,980,600 sentences. The model was trained for five epochs, thus fine tuned on 9,903,000 sentences. \nThe Amazon CWR (called laptop_model.tar.gz at the URL address) has first been intitalised with the pre-trained weights from the 1 Billion word corpus Transformer ELMo language model and then fine-tuned on the Amazon electronics data. Amazon fine tuning dataset has a mean sentence length of 18.06 (9.81) with 9,580,995 sentences. The model was trained for three epochs, thus fine tuned on 28,742,985 sentences.    \nThe Yelp CWR (called restaurant_model.tar.gz at the URL address) has first been intitalised with the pre-trained weights from the 1 Billion word corpus Transformer ELMo language model and then fine-tuned on the 2019 Yelp data. Yelp fine tuning dataset has a mean sentence length of 14.78 (8.02) with 27,286,698 sentences. The model was trained for one epoch, thus fine tuned on 27,286,698 sentences. \nTo compare to the language models we are going to create domain sepcific word embeddings. First of all we are going to create two types: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9416044602556721,
        0.9855017939302255,
        0.9346004613222231
      ],
      "excerpt": "The reason for the two types is so that the first can be used to compare fairly against a domain sepcific Contextualised Word Embedding (CWE) that has been created using the ELMo language model described here using the same data. \nWe are going to train both of these embeddings using the same training data that is used to train the language models. The second word embedding will use MWE up to length 3 as fewer than 5% of the targets in the training data are longer than 3 words see this notebook for those details. \nAll of the word vectors are 300 dimension Word2Vec Skip Gram vectors that have been trained for 5 epochs with 5 negative samples as per the default configurations in the Gensim package. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.907578719081174
      ],
      "excerpt": "Now that we have a training set for both Restaurants and Laptops we are going to sub-sample these into datasets that contain only 1 million sentences each, these randomly sub-sampled datasets can be create using the following script: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8694169285470592
      ],
      "excerpt": "We shall also use the Domain Specific language models that we have created here as well as the Glove 300D general word embedding as the word representations for the Bi-LSTM with CRF decoding. First before training the models we need to split them into train, validation and test splits using the following script: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9563677102547935
      ],
      "excerpt": "Before we predict the targets for the large filtered un-labelled training data we are going to sub-sample to save computational costs. We are only going to use a 1,000,000 sentences: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Fine Tuning Language models",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/apmoore1/language-model/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 30 Dec 2021 06:52:13 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/apmoore1/language-model/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "apmoore1/language-model",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/apmoore1/language-model/master/word_embeddings/create_embeddings.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Download the following datasets:\n\n1. SemEval Restaurant and Laptop 2014 [1] [train](http://metashare.ilsp.gr:8080/repository/browse/semeval-2014-absa-train-data-v20-annotation-guidelines/683b709298b811e3a0e2842b2b6a04d7c7a19307f18a4940beef6a6143f937f0/) and [test] and put the `Laptop_Train_v2.xml` and `Restaurants_Train_v2.xml` training files into the following directory `./tdsa_data` and do the same for the test files (`Laptops_Test_Gold.xml` and `Restaurants_Test_Gold.xml`)\n2. Election dataset [2] from the following [link](https://ndownloader.figshare.com/articles/4479563/versions/1) and extract all of the data into the following folder `./tdsa_data/election`, the `election` folder should now contain the following files `annotations.tar.gz`, `test_id.txt`, `train_id.txt`, and `tweets.tar.gz`. Extract both the `annotations.tar.gz` and the `tweets.tar.gz` files.\n\nThen run the following command to create the relevant and determinstic train, validaion, and test splits of which these will be stored in the following directory `./tdsa_data/splits`:\n\n``` bash\npython ./tdsa_data/generate_datasets.py ./tdsa_data ./tdsa_data/splits\n```\n\nThis should create all of the splits that we will use throughout the normal experiments that are the baseline values for all of our augmentation experiments. This will also print out some statistics for each of the splits to ensure that they are relatively similar.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9073358513327268
      ],
      "excerpt": "NOTE: It is required to un-tar the transformer-elmo-2019.01.10.tar.gz as the vocabulary is required and the weights therefore we assume you have un-tared it into the following folder ../transformer_unpacked \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8738538998608946
      ],
      "excerpt": "To evaluare using the language model trained on the one billion word corpus use the following command takes around 2 hours on a 1060 6GB GPU. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772058376805153
      ],
      "excerpt": "To train the model run the following command (This will take a long time around 63 hours on a 1060 6GB GPU): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633314133946884
      ],
      "excerpt": "To evaluate the model we shall use the Amazon filterted test split which you should be able to find here if you followed the previous steps ../amazon/filtered_split_test.txt and to evaluate you run the following command (This again will take around 1 hours 15 minutes on a 1060 6GB GPU): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8466088837007109
      ],
      "excerpt": "To train the model run the following command (This will take a long time around 49 hours on a 1060 6GB GPU): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.892855641214947
      ],
      "excerpt": "To evaluate the model we shall use the Yelp filterted test split which you should be able to find here if you followed the previous steps ../yelp/splits/filtered_split_test.txt and to evaluate you run the following command (This again will take around 3 hours 25 minutes on a 1060 6GB GPU): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9511670622860063,
        0.8192751249735446,
        0.8192751249735446,
        0.8192751249735446
      ],
      "excerpt": "Then to train the models run the following: \nallennlp train TDSA_configs/ELMO_Laptop.jsonnet -s TDSA_Models/Laptop --include-package target_extraction \nallennlp train TDSA_configs/ELMO_Restaurant.jsonnet -s TDSA_Models/Restaurant --include-package target_extraction \nallennlp train TDSA_configs/ELMO_MP.jsonnet -s TDSA_Models/MP --include-package target_extraction \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8361321685650418
      ],
      "excerpt": "Now we are going to predict targets on these sub-sampled 1,000,000 sentence files, by running the following command: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8967713307829016
      ],
      "excerpt": "python dataset_analysis/filter_businesses_by_category.py YELP_REVIEW_DIR/business.json business_filter_ids.json 'restaurants restaurant restaurants,' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python dataset_analysis/to_sentences_tokens.py ../yelp/splits yelp \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python dataset_analysis/filter_by_sentence_length.py ../yelp/splits yelp_sentences 3 40 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9189661247488412,
        0.9189661247488412,
        0.9189661247488412
      ],
      "excerpt": "python dataset_analysis/data_stats.py ../yelp/splits/filtered_split_train.txt yelp_sentences --sentence_length_distribution ./images/sentence_distributions/yelp_filtered_training.png \npython dataset_analysis/data_stats.py ../yelp/splits/filtered_split_val.txt yelp_sentences --sentence_length_distribution ./images/sentence_distributions/yelp_filtered_validation.png \npython dataset_analysis/data_stats.py ../yelp/splits/filtered_split_test.txt yelp_sentences --sentence_length_distribution ./images/sentence_distributions/yelp_filtered_test.png \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9215693103233217
      ],
      "excerpt": "python vocab_comparison/create_vocab.py ../yelp/splits/filtered_split_train.txt ../vocab_test_files/yelp_filtered_train.json whitespace \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9042975904425897
      ],
      "excerpt": "python vocab_comparison/comapre_vocabs.py ../vocab_test_files/restaurant_tdsa.json ../vocab_test_files/yelp_filtered_train.json ../vocab_test_files/tdsa_diff_between_yelp_train_and_restaurant.txt --not_symmetric \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9042975904425897,
        0.8993956902664898,
        0.8537634654537919
      ],
      "excerpt": "python vocab_comparison/comapre_vocabs.py ../vocab_test_files/restaurant_target_tdsa.json ../vocab_test_files/yelp_filtered_train.json ../vocab_test_files/tdsa_diff_between_yelp_train_and_restaurant_targets.txt --not_symmetric \npython vocab_comparison/targets_affected.py restaurant ../vocab_test_files/tdsa_diff_between_yelp_train_and_restaurant_targets.txt spacy tdsa_data/splits/ \npython vocab_comparison/targets_affected.py restaurant ../vocab_test_files/tdsa_diff_between_yelp_train_and_restaurant_targets.txt spacy tdsa_data/splits/ --unique \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9215693103233217,
        0.9042975904425897,
        0.9042975904425897,
        0.8993956902664898,
        0.8537634654537919
      ],
      "excerpt": "python vocab_comparison/txt_to_json.py ../yelp_lm_vocab/tokens.txt ../vocab_test_files/yelp_train_model.json  \npython vocab_comparison/comapre_vocabs.py ../vocab_test_files/restaurant_tdsa.json ../vocab_test_files/yelp_train_model.json ../vocab_test_files/tdsa_diff_between_yelp_train_model_and_restaurant.txt --not_symmetric \npython vocab_comparison/comapre_vocabs.py ../vocab_test_files/restaurant_target_tdsa.json ../vocab_test_files/yelp_train_model.json ../vocab_test_files/tdsa_diff_between_yelp_train_model_and_restaurant_targets.txt --not_symmetric \npython vocab_comparison/targets_affected.py restaurant ../vocab_test_files/tdsa_diff_between_yelp_train_model_and_restaurant_targets.txt spacy tdsa_data/splits/ \npython vocab_comparison/targets_affected.py restaurant ../vocab_test_files/tdsa_diff_between_yelp_train_model_and_restaurant_targets.txt spacy tdsa_data/splits/ --unique \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8237734343256989
      ],
      "excerpt": "Number of test reviews 135136(0.0800005683204001%) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8079593916293212,
        0.8783731980550076,
        0.8783731980550076,
        0.8783731980550076
      ],
      "excerpt": "python dataset_analysis/filter_by_sentence_length.py ../amazon yelp_sentences 3 50 \npython dataset_analysis/data_stats.py ../amazon/filtered_split_train.txt yelp_sentences --sentence_length_distribution ./images/sentence_distributions/amazon_filtered_training.png \npython dataset_analysis/data_stats.py ../amazon/filtered_split_val.txt yelp_sentences --sentence_length_distribution ./images/sentence_distributions/amazon_filtered_validation.png \npython dataset_analysis/data_stats.py ../amazon/filtered_split_test.txt yelp_sentences --sentence_length_distribution ./images/sentence_distributions/amazon_filtered_test.png \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9280857673571561
      ],
      "excerpt": "python dataset_analysis/create_train_val_test.py ../MP-Tweets/all_mp_data.json ../MP-Tweets/ mp \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8237734343256989
      ],
      "excerpt": "Number of test reviews 197193(0.08000011359445725%) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python dataset_analysis/to_sentences_tokens.py ../MP-Tweets/ mp \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091,
        0.9189661247488412,
        0.9189661247488412,
        0.9189661247488412
      ],
      "excerpt": "python dataset_analysis/filter_by_sentence_length.py ../MP-Tweets yelp_sentences 3 60 \npython dataset_analysis/data_stats.py ../MP-Tweets/filtered_split_train.txt yelp_sentences --sentence_length_distribution ./images/sentence_distributions/mp_filtered_training.png \npython dataset_analysis/data_stats.py ../MP-Tweets/filtered_split_val.txt yelp_sentences --sentence_length_distribution ./images/sentence_distributions/mp_filtered_validation.png \npython dataset_analysis/data_stats.py ../MP-Tweets/filtered_split_test.txt yelp_sentences --sentence_length_distribution ./images/sentence_distributions/mp_filtered_test.png \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9280857673571561
      ],
      "excerpt": "python fine_tune_lm/create_lm_vocab.py fine_tune_lm/training_configs/mp_lm_vocab_create_config.json ../mp_lm_vocab \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8890390350607155
      ],
      "excerpt": "allennlp train fine_tune_lm/training_configs/mp_lm_config.json -s ../mp_language_model_save_large \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9280857673571561
      ],
      "excerpt": "python fine_tune_lm/create_lm_vocab.py fine_tune_lm/training_configs/amazon_lm_vocab_create_config.json ../amazon_lm_vocab \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8890390350607155
      ],
      "excerpt": "allennlp train fine_tune_lm/training_configs/amazon_lm_config.json -s ../amazon_language_model_save_large \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9280857673571561
      ],
      "excerpt": "python fine_tune_lm/create_lm_vocab.py fine_tune_lm/training_configs/yelp_lm_vocab_create_config.json ../yelp_lm_vocab \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8890390350607155
      ],
      "excerpt": "allennlp train fine_tune_lm/training_configs/yelp_lm_config.json -s ../yelp_language_model_save_large \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8479436032831332
      ],
      "excerpt": "python dataset_analysis/subsample_sentence.py ../yelp/splits/filtered_split_train.txt ../yelp/splits/sub_filtered_split_train.txt 1000000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8725507946180425,
        0.8725507946180425,
        0.9284565975362779,
        0.8232109315993728
      ],
      "excerpt": "python dataset_analysis/TDSA_create_splits.py ../original_target_datasets/semeval_2014/SemEval\\'14-ABSA-TrainData_v2\\ \\&amp;\\ AnnotationGuidelines/Laptop_Train_v2.xml ../original_target_datasets/semeval_2014/ABSA_Gold_TestData/Laptops_Test_Gold.xml semeval_2014 ../original_target_datasets/semeval_2014/laptop_json/train.json ../original_target_datasets/semeval_2014/laptop_json/val.json ../original_target_datasets/semeval_2014/laptop_json/test.json \npython dataset_analysis/TDSA_create_splits.py ../original_target_datasets/semeval_2014/SemEval\\'14-ABSA-TrainData_v2\\ \\&amp;\\ AnnotationGuidelines/Restaurants_Train_v2.xml ../original_target_datasets/semeval_2014/ABSA_Gold_TestData/Restaurants_Test_Gold.xml semeval_2014 ../original_target_datasets/semeval_2014/restaurant_json/train.json ../original_target_datasets/semeval_2014/restaurant_json/val.json ../original_target_datasets/semeval_2014/restaurant_json/test.json \npython dataset_analysis/TDSA_create_splits.py --remove_errors not_valid.txt not_valid.txt election_twitter ../original_target_datasets/election/train.json ../original_target_datasets/election/val.json ../original_target_datasets/election/test.json \nThen to train the models run the following: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8479436032831332,
        0.8479436032831332
      ],
      "excerpt": "python dataset_analysis/subsample_sentence.py ../yelp/splits/filtered_split_train.txt ../yelp/splits/sub_filtered_split_train.txt 1000000 \npython dataset_analysis/subsample_sentence.py ../MP-Tweets/filtered_split_train.txt ../MP-Tweets/sub_filtered_split_train.txt 1000000 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/apmoore1/language-model/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jsonnet",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Getting the data and models",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "language-model",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "apmoore1",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/apmoore1/language-model/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "command:\n\n\n``` bash\nallennlp evaluate --cuda-device -0 -o '{\"iterator\": {\"base_iterator\": {\"maximum_samples_per_batch\": [\"num_tokens\", 500], \"max_instances_in_memory\": 512, \"batch_size\": 128 }}}' transformer-elmo-2019.01.10.tar.gz 1-billion-word-language-modeling-benchmark-r13output/heldout-monolingual.tokenized.shuffled/news.en-00000-of-00100\n```\nDid not find it any quicker to have more of the data in memory nor did the perplexity measure change.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 30 Dec 2021 06:52:13 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "ALL DATA HERE IS TOKENIZED USING SPACY!\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Download the following datasets:\n\n1. SemEval Restaurant and Laptop 2014 [1] [train](http://metashare.ilsp.gr:8080/repository/browse/semeval-2014-absa-train-data-v20-annotation-guidelines/683b709298b811e3a0e2842b2b6a04d7c7a19307f18a4940beef6a6143f937f0/) and [test] and put the `Laptop_Train_v2.xml` and `Restaurants_Train_v2.xml` training files into the following directory `./tdsa_data` and do the same for the test files (`Laptops_Test_Gold.xml` and `Restaurants_Test_Gold.xml`)\n2. Election dataset [2] from the following [link](https://ndownloader.figshare.com/articles/4479563/versions/1) and extract all of the data into the following folder `./tdsa_data/election`, the `election` folder should now contain the following files `annotations.tar.gz`, `test_id.txt`, `train_id.txt`, and `tweets.tar.gz`. Extract both the `annotations.tar.gz` and the `tweets.tar.gz` files.\n\nThen run the following command to create the relevant and determinstic train, validaion, and test splits of which these will be stored in the following directory `./tdsa_data/splits`:\n\n``` bash\npython ./tdsa_data/generate_datasets.py ./tdsa_data ./tdsa_data/splits\n```\n\nThis should create all of the splits that we will use throughout the normal experiments that are the baseline values for all of our augmentation experiments. This will also print out some statistics for each of the splits to ensure that they are relatively similar.\n\n",
      "technique": "Header extraction"
    }
  ]
}
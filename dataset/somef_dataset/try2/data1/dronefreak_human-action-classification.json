{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1701.00295\n\n[2] https://github.com/DenisTome/Lifting-from-the-Deep-release\n\n### Mobilenet\n\n[1] Original Paper : https://arxiv.org/abs/1704.04861\n\n[2] Pretrained model (Pose estimation",
      "https://arxiv.org/abs/1704.04861\n\n[2] Pretrained model (Pose estimation"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "BATCH_SIZE = 10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9998416198938155
      ],
      "excerpt": "[1] Arxiv Paper : https://arxiv.org/abs/1701.00295 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.994799811898885
      ],
      "excerpt": "[1] Original Paper : https://arxiv.org/abs/1704.04861 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8471736354311271,
        0.9105368110547479
      ],
      "excerpt": "[1] Stanford 40 : http://vision.stanford.edu/Datasets/40actions.html \n[1] Tensorpack : https://github.com/ppwwyyxx/tensorpack \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dronefreak/human-action-classification",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-22T13:35:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T02:22:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8736945385379873
      ],
      "excerpt": "Pose estimation & detection has been minimally implemented using the OpenPose implementation https://github.com/ildoonet/tf-pose-estimation with Tensorflow. For binary classification of poses, (sitting or upright), MobileNet (a CNN originally trained on the ImageNet Large Visual Recognition Challenge dataset), was retrained (final layer) on a dataset of ~1500 images of poses. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9720364661209462
      ],
      "excerpt": "Also, please do not forget to change the address variable in the code according to your local machine. This is a TODO, in the sense that the viewer can use os.getcwd() for an improved generic performance. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.983416252407147
      ],
      "excerpt": "Please note that the inference time for a single image is 1.423 seconds on an average (once the GPU is instantiated), when tested on a system with Ubuntu 18.04, 8GB DDR4 RAM, i5-8240 Intel Processor and NVIDIA GTX 1050Ti (768 Cores with 4GB VRAM). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9663214697361268
      ],
      "excerpt": "The Action-(n) folders would contain your different poses/scenes that you want to classify. This structure is recommended on tensorflow.org as well. It is advised to use smaller CNNs for pose classification (as there are lesser number of classes), like maybe MobileNet-v1 and a relatively larger CNN for scene classification, like Inception-v3 maybe. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076,
        0.860059181823877
      ],
      "excerpt": "Y = [i[2] for i in train_data] \nmodel.fit(X,Y,20, batch_size = 5) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This repository allows you to classify 40 different human actions. Pose detection, estimation and classification is also performed. Poses are classified into sitting, upright and lying down.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dronefreak/human-action-classification/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 35,
      "date": "Wed, 29 Dec 2021 10:41:43 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dronefreak/human-action-classification/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "dronefreak/human-action-classification",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/tf_pose/slim/slim_walkthrough.ipynb",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/tf_pose/slim/nets/mobilenet/mobilenet_example.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/tf_pose/slim/scripts/export_mobilenet.sh",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/tf_pose/slim/scripts/finetune_inception_v1_on_flowers.sh",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/tf_pose/slim/scripts/finetune_inception_resnet_v2_on_flowers.sh",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/tf_pose/slim/scripts/train_lenet_on_mnist.sh",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/tf_pose/slim/scripts/finetune_resnet_v1_50_on_flowers.sh",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/tf_pose/slim/scripts/train_cifarnet_on_cifar10.sh",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/tf_pose/slim/scripts/finetune_inception_v3_on_flowers.sh",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/tf_pose/slim/datasets/download_and_convert_imagenet.sh",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/tf_pose/slim/datasets/download_imagenet.sh",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/models/graph/cmu/download.sh",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/models/pretrained/mobilenet_v1_1.0_224_2017_06_14/download.sh",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/models/pretrained/mobilenet_v1_0.50_224_2017_06_14/download.sh",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/models/pretrained/resnet_v2_101/download.sh",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/models/pretrained/mobilenet_v1_0.75_224_2017_06_14/download.sh",
      "https://raw.githubusercontent.com/dronefreak/human-action-classification/master/models/numpy/download.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9695750782889518,
        0.8464675350223967,
        0.9718780720507743
      ],
      "excerpt": "$ git clone https://github.com/dronefreak/human-action-classification.git \n$ cd human-action-classification \nPlease check the dependency tree before executing the pip install command. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466,
        0.8837680365796365
      ],
      "excerpt": "$ cd tf_pose/pafprocess/ \n$ swig -python -c++ pafprocess.i  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8948368986645309
      ],
      "excerpt": "[2] https://github.com/DenisTome/Lifting-from-the-Deep-release \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8918974083095406
      ],
      "excerpt": "[1] Tensorpack : https://github.com/ppwwyyxx/tensorpack \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9065562463582615
      ],
      "excerpt": "$ python3 run_image.py --image=1.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "$ python3 run_webcam.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8639986685036579,
        0.8639986685036579
      ],
      "excerpt": "\u2502   \u2502   file011.jpg \n\u2502   \u2502   file012.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8639986685036579,
        0.8639986685036579
      ],
      "excerpt": "    \u2502   file021.jpg \n    \u2502   file022.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8581846667002003
      ],
      "excerpt": "python3 scripts/retrain.py --model_dir=tf_files/retrained_graph.pb --output_labels=tf_files/retrained_labels.txt --image_dir=training/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8796325398080971
      ],
      "excerpt": "from inception_from_scratch import inceptionv3 as incp \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8152416518617106
      ],
      "excerpt": "HEIGHT = 100 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8409031262936775
      ],
      "excerpt": "model = incp(WIDTH, HEIGHT, 3, LR, output=40, model_name=MODEL_NAME) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8956252725836699
      ],
      "excerpt": "X = np.array([i[1] for i in train_data]).reshape(-1,WIDTH,HEIGHT,3) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dronefreak/human-action-classification/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Saumya Kumaar Saksena\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Human Action Classification",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "human-action-classification",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "dronefreak",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dronefreak/human-action-classification/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The following are required :\n\n- Python3\n- tensorflow-gpu 1.13.0 (works with CPU version as well but with a much higher inference time)\n- opencv3\n- slim\n- slidingwindow - (https://github.com/adamrehn/slidingwindow)\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 109,
      "date": "Wed, 29 Dec 2021 10:41:43 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pose-estimation",
      "pose-classification",
      "human-action-recognition",
      "convolutional-neural-networks",
      "computer-vision"
    ],
    "technique": "GitHub API"
  }
}
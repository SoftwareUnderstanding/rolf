{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1809.08895",
      "https://arxiv.org/abs/1905.09263",
      "https://arxiv.org/abs/2006.04558"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "Francesco Cardinale, github: cfrancesco \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/as-ideas/TransformerTTS",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-26T14:21:36Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-20T21:19:33Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9089932591369674,
        0.8367225462112312,
        0.9098600032299495,
        0.9779540130088887
      ],
      "excerpt": "Being non-autoregressive, this Transformer model is: \n- Robust: No repeats and failed attention modes for challenging sentences. \n- Fast: With no autoregression, predictions take a fraction of the time. \n- Controllable: It is possible to control the speed and pitch of the generated utterance. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8259227446164804,
        0.9748881639535582
      ],
      "excerpt": "06/20: Added normalisation and pre-trained models compatible with the faster MelGAN vocoder. \n11/20: Added pitch prediction. Autoregressive model is now specialized as an Aligner and Forward is now the only TTS model. Changed models architectures. Discontinued WaveRNN support. Improved duration extraction with Dijkstra algorithm. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "model = tts_ljspeech() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9917159896299618
      ],
      "excerpt": ": Convert spectrogram to wav (with griffin lim) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8936852082265567
      ],
      "excerpt": "Steps from 60000 to 100000 are available at a frequency of 5K steps (60000, 65000, ..., 95000, 100000). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8136810850899752
      ],
      "excerpt": "Currently 493be6345341af0df3ae829de79c2793c9afd0ec \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.883843380963944
      ],
      "excerpt": "swap the content of data_config_wavernn.yaml in config/training_config.yaml to create models compatible with WaveRNN  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9310571892052111
      ],
      "excerpt": "Change the --config argument based on the configuration of your choice. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8061830765023555
      ],
      "excerpt": "To restart training, delete the weights and/or the logs from the logs folder with the training flag --reset_dir (both) or --reset_logs, --reset_weights \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9917159896299618
      ],
      "excerpt": ": Convert spectrogram to wav (with griffin lim) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "| Model URL | Commit | Vocoder Commit| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "\ud83e\udd16\ud83d\udcac Transformer TTS: Implementation of a non-autoregressive Transformer based neural network for text to speech.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/as-ideas/TransformerTTS/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 169,
      "date": "Fri, 24 Dec 2021 07:49:17 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/as-ideas/TransformerTTS/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "as-ideas/TransformerTTS",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/as-ideas/TransformerTTS/tree/main/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/as-ideas/TransformerTTS/main/notebooks/synthesize_forward_melgan.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Make sure you have:\n\n* Python >= 3.6\n\nInstall espeak as phonemizer backend (for macOS use brew):\n```\nsudo apt-get install espeak\n```\n\nThen install the rest with pip:\n```\npip install -r requirements.txt\n```\n\nRead the individual scripts for more command line arguments.\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9079185768576028,
        0.8934477375241742
      ],
      "excerpt": "from data.audio import Audio \nfrom model.factory import tts_ljspeech \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8228908620340866
      ],
      "excerpt": "EDIT PATHS: in config/training_config.yaml edit the paths to point at your dataset and log folders \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8328222087808682
      ],
      "excerpt": "you can use the ljspeech preprocessor in data/metadata_readers.py, otherwise add your own under the same file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8002124840713474
      ],
      "excerpt": " -  the metadata reader function name is the same as data_name field in training_config.yaml. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8640490495203853,
        0.8652631132455295
      ],
      "excerpt": "python create_training_data.py --config config/training_config.yaml \nThis will populate the training data directory (default transformer_tts_data.ljspeech). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8640490495203853,
        0.805496658703798
      ],
      "excerpt": "python train_aligner.py --config config/training_config.yaml \nFirst use the aligner model to create the durations dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8640490495203853,
        0.8214756757944689
      ],
      "excerpt": "python extract_durations.py --config config/training_config.yaml \nthis will add the durations.&lt;session name&gt; as well as the char-wise pitch folders to the training data directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8640490495203853,
        0.8369105479817186
      ],
      "excerpt": "python train_tts.py --config config/training_config.yaml \nTraining and model settings can be configured in training_config.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8068431761286978,
        0.8040493270787691
      ],
      "excerpt": "tensorboard --logdir /logs/directory/ \nFrom command line with \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9040368155137037,
        0.9079185768576028
      ],
      "excerpt": "from model.models import ForwardTransformer \nfrom data.audio import Audio \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/as-ideas/TransformerTTS/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/as-ideas/TransformerTTS/main/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'COPYRIGHT\\n\\nCopyright (c) 2020 Axel Springer AI. All rights reserved.\\n\\nLICENSE\\n\\nThe MIT License (MIT)\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "### Non-Autoregressive",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "TransformerTTS",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "as-ideas",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/as-ideas/TransformerTTS/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "cfrancesco",
        "body": "Adding a downloadable HiFiGan artefact.\r\nHiFiGan credit: https://github.com/jik876/hifi-gan",
        "dateCreated": "2021-06-03T11:19:11Z",
        "datePublished": "2021-06-03T12:36:31Z",
        "html_url": "https://github.com/as-ideas/TransformerTTS/releases/tag/v1.5",
        "name": "Change model loading, add HiFigan model.",
        "tag_name": "v1.5",
        "tarball_url": "https://api.github.com/repos/as-ideas/TransformerTTS/tarball/v1.5",
        "url": "https://api.github.com/repos/as-ideas/TransformerTTS/releases/44038242",
        "zipball_url": "https://api.github.com/repos/as-ideas/TransformerTTS/zipball/v1.5"
      },
      {
        "authorType": "User",
        "author_name": "cfrancesco",
        "body": "Added Forward Model based on FastSpeech, with scripted training on LJSpeech.\r\nFixes to previous model and improvements to layers structure.\r\nSamples, colab notebooks and pre-trained models are available.",
        "dateCreated": "2020-05-29T16:27:41Z",
        "datePublished": "2020-05-29T16:39:10Z",
        "html_url": "https://github.com/as-ideas/TransformerTTS/releases/tag/v2.0",
        "name": "Forward Model",
        "tag_name": "v2.0",
        "tarball_url": "https://api.github.com/repos/as-ideas/TransformerTTS/tarball/v2.0",
        "url": "https://api.github.com/repos/as-ideas/TransformerTTS/releases/27039895",
        "zipball_url": "https://api.github.com/repos/as-ideas/TransformerTTS/zipball/v2.0"
      },
      {
        "authorType": "User",
        "author_name": "cfrancesco",
        "body": "Implementation of a Transformer phonemes to spectrograms model.\r\nScripted training on LJSpeech.\r\nWorking pre-trained model.",
        "dateCreated": "2020-05-19T19:13:08Z",
        "datePublished": "2020-05-26T22:16:55Z",
        "html_url": "https://github.com/as-ideas/TransformerTTS/releases/tag/1.0",
        "name": "Autoregressive Transformer",
        "tag_name": "1.0",
        "tarball_url": "https://api.github.com/repos/as-ideas/TransformerTTS/tarball/1.0",
        "url": "https://api.github.com/repos/as-ideas/TransformerTTS/releases/26920827",
        "zipball_url": "https://api.github.com/repos/as-ideas/TransformerTTS/zipball/1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 819,
      "date": "Fri, 24 Dec 2021 07:49:17 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "axelspringerai",
      "text-to-speech",
      "python",
      "tensorflow",
      "tts"
    ],
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        0.8334710283794773,
        0.8753150968738145
      ],
      "excerpt": "For business inquiries, please contact researchinquiries@nvidia.com \nFor press and other inquiries, please contact Hector Marinez at hmarinez@nvidia.com \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9022277929869588,
        0.9792428879788975
      ],
      "excerpt": "Paper (NVIDIA research) \nPaper (arXiv) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9186665153711271,
        0.9186665153711271
      ],
      "excerpt": "ICLR 2018 poster (karras2018iclr-poster.pdf) \nICLR 2018 slides (karras2018iclr-slides.pptx) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9744690116628929
      ],
      "excerpt": "High-quality video clips (videos/high-quality-video-clips) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9086892148066392
      ],
      "excerpt": "| Repro CIFAR-10 results            | No                                            | Yes \u2013 identical           | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/civilman628/pgan",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-08-14T22:35:27Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-10-29T20:33:25Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9909102390816775
      ],
      "excerpt": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024\u00b2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9536039723150844,
        0.9935871540535333
      ],
      "excerpt": "All the material, including source code, is made freely available for non-commercial use under the Creative Commons CC BY-NC 4.0 license. Feel free to use any of the material in your own work, as long as you give us appropriate credit by mentioning the title and author list of our paper. \nThere are two different versions of the source code. The TensorFlow version is newer and more polished, and we generally recommend it as a starting point if you are looking to experiment with our technique, build upon it, or apply it to novel datasets. The original Theano version, on the other hand, is what we used to produce all the results shown in our paper. We recommend using it if \u2013 and only if \u2013 you are looking to reproduce our exact results for benchmark datasets like CIFAR-10, MNIST-RGB, and CelebA. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8775776390329579
      ],
      "excerpt": "    #: Gs = Long-term average of the generator, yielding higher-quality results than the instantaneous snapshot. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8895603476781382
      ],
      "excerpt": "It is also possible to import networks that were produced using the Theano implementation, as long as they do not employ any features that are not natively supported by the TensorFlow version (minibatch discrimination, batch normalization, etc.). To enable Theano network import, however, you must use misc.load_pkl() in place of pickle.load(): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8484203000065101,
        0.8848460376500837
      ],
      "excerpt": "Once you have imported the networks, you can call Gs.run() to produce a set of images for given latent vectors, or Gs.get_output_for() to include the generator network in a larger TensorFlow expression. For further details, please consult the example script found on Google Drive. Instructions: \nPull the Progressive GAN code repository and add it to your PYTHONPATH environment variable. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8002024688558572,
        0.921752638540966,
        0.9820685239805219,
        0.8839708168942676
      ],
      "excerpt": "The results are written into a newly created subdirectory under config.result_dir \nWait several days (or weeks) for the training to converge, and analyze the results. \nBy default, config.py is configured to train a 1024x1024 network for CelebA-HQ using a single-GPU. This is expected to take about two weeks even on the highest-end NVIDIA GPUs. The key to enabling faster training is to employ multiple GPUs and/or go for a lower-resolution dataset. To this end, config.py contains several examples for commonly used datasets, as well as a set of \"configuration presets\" for multi-GPU training. All of the presets are expected to yield roughly the same image quality for CelebA-HQ, but their total training time can vary considerably: \npreset-v1-1gpu: Original config that was used to produce the CelebA-HQ and LSUN results shown in the paper. Expected to take about 1 month on NVIDIA Tesla V100. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8712682735240527
      ],
      "excerpt": "For reference, the expected output of each configuration preset for CelebA-HQ can be found in networks/tensorflow-version/example_training_runs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8486053481850085,
        0.818678582486339
      ],
      "excerpt": "VERBOSE: Save image and network snapshots very frequently to facilitate debugging. \nGRAPH and HIST: Include additional data in the TensorBoard report. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/civilman628/pgan/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 00:50:40 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/civilman628/pgan/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "civilman628/pgan",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The Progressive GAN code repository contains a command-line tool for recreating bit-exact replicas of the datasets that we used in the paper. The tool also provides various utilities for operating on the datasets:\n\n```\nusage: dataset_tool.py [-h] <command> ...\n\n    display             Display images in dataset.\n    extract             Extract images from dataset.\n    compare             Compare two datasets.\n    create_mnist        Create dataset for MNIST.\n    create_mnistrgb     Create dataset for MNIST-RGB.\n    create_cifar10      Create dataset for CIFAR-10.\n    create_cifar100     Create dataset for CIFAR-100.\n    create_svhn         Create dataset for SVHN.\n    create_lsun         Create dataset for single LSUN category.\n    create_celeba       Create dataset for CelebA.\n    create_celebahq     Create dataset for CelebA-HQ.\n    create_from_images  Create dataset from a directory full of images.\n    create_from_hdf5    Create dataset from legacy HDF5 archive.\n\nType \"dataset_tool.py <command> -h\" for more information.\n```\n\nThe datasets are represented by directories containing the same image data in several resolutions to enable efficient streaming. There is a separate `*.tfrecords` file for each resolution, and if the dataset contains labels, they are stored in a separate file as well:\n\n```\n> python dataset_tool.py create_cifar10 datasets/cifar10 ~/downloads/cifar10\n> ls -la datasets/cifar10\ndrwxr-xr-x  2 user user         7 Feb 21 10:07 .\ndrwxrwxr-x 10 user user        62 Apr  3 15:10 ..\n-rw-r--r--  1 user user   4900000 Feb 19 13:17 cifar10-r02.tfrecords\n-rw-r--r--  1 user user  12350000 Feb 19 13:17 cifar10-r03.tfrecords\n-rw-r--r--  1 user user  41150000 Feb 19 13:17 cifar10-r04.tfrecords\n-rw-r--r--  1 user user 156350000 Feb 19 13:17 cifar10-r05.tfrecords\n-rw-r--r--  1 user user   2000080 Feb 19 13:17 cifar10-rxx.labels\n```\n\nThe ```create_*``` commands take the standard version of a given dataset as input and produce the corresponding `*.tfrecords` files as output. Additionally, the ```create_celebahq``` command requires a set of data files representing deltas with respect to the original CelebA dataset. These deltas (27.6GB) can be downloaded from [`datasets/celeba-hq-deltas`](https://drive.google.com/open?id=0B4qLcYyJmiz0TXY1NG02bzZVRGs).\n\n**Note about module versions**: Some of the dataset commands require specific versions of Python modules and system libraries (e.g. pillow, libjpeg), and they will give an error if the versions do not match. Please heed the error messages \u2013 there is **no way** to get the commands to work other than installing these specific versions.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8925713586182477
      ],
      "excerpt": "| Feature                           | TensorFlow version                            | Original Theano version   | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8326040649804013,
        0.9998754988878206
      ],
      "excerpt": "Pull the Progressive GAN code repository and add it to your PYTHONPATH environment variable. \nInstall the required Python packages with pip install -r requirements-pip.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8054334000543399
      ],
      "excerpt": "Download karras2018iclr-celebahq-1024x1024.pkl from networks/tensorflow-version and place it in the same directory as the script. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8293455251007239
      ],
      "excerpt": "with open('karras2018iclr-celebahq-1024x1024.pkl', 'rb') as file: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import misc \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9037260382419103
      ],
      "excerpt": "Run the script with python import_example.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9523651689170409
      ],
      "excerpt": "Run the training script with python train.py. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.946823558979354
      ],
      "excerpt": "Uncomment the generate_interpolation_video line in config.py, replace run_id=10, and run python train.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/civilman628/pgan/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Progressive Growing of GANs for Improved Quality, Stability, and Variation<br><i>\u2013 Official TensorFlow implementation of the ICLR 2018 paper</i>",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pgan",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "civilman628",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/civilman628/pgan/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Both Linux and Windows are supported, but we strongly recommend Linux for performance and compatibility reasons.\n* 64-bit Python 3.6 installation with numpy 1.13.3 or newer. We recommend Anaconda3.\n* One or more high-end NVIDIA Pascal or Volta GPUs with 16GB of DRAM. We recommend NVIDIA DGX-1 with 8 Tesla V100 GPUs.\n* NVIDIA driver 391.25 or newer, CUDA toolkit 9.0 or newer, cuDNN 7.1.2 or newer.\n* Additional Python packages listed in `requirements-pip.txt`\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 00:50:40 GMT"
    },
    "technique": "GitHub API"
  }
}
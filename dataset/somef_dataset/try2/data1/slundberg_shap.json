{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1704.02685",
      "https://arxiv.org/abs/1703.01365",
      "https://arxiv.org/abs/1706.03825",
      "https://arxiv.org/abs/1704.02685 (2017).\n\n4. *QII:* Datta, Anupam, Shayak Sen, and Yair Zick. \"Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems.\" Security and Privacy (SP), 2016 IEEE Symposium on. IEEE, 2016.\n\n5. *Layer-wise relevance propagation:* Bach, Sebastian, et al. \"On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation.\" PloS one 10.7 (2015): e0130140.\n\n6. *Shapley regression values:* Lipovetsky, Stan, and Michael Conklin. \"Analysis of regression in game theory approach.\" Applied Stochastic Models in Business and Industry 17.4 (2001): 319-330.\n\n7. *Tree interpreter:* Saabas, Ando. Interpreting random forests. http://blog.datadive.net/interpreting-random-forests/\n\n## Citations\n\nThe algorithms and visualizations used in this package came primarily out of research in [Su-In Lee's lab](https://suinlee.cs.washington.edu) at the University of Washington, and Microsoft Research. If you use SHAP in your research we would appreciate a citation to the appropriate paper(s):\n\n- For general use of SHAP you can read/cite our [NeurIPS paper](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions) ([bibtex](https://raw.githubusercontent.com/slundberg/shap/master/docs/references/shap_nips.bib)). \n- For TreeExplainer you can read/cite our [Nature Machine Intelligence paper](https://www.nature.com/articles/s42256-019-0138-9) ([bibtex](https://raw.githubusercontent.com/slundberg/shap/master/docs/references/tree_explainer.bib); [free access](https://rdcu.be/b0z70)).\n- For `force_plot` visualizations and medical applications you can read/cite our [Nature Biomedical Engineering paper](https://www.nature.com/articles/s41551-018-0304-0) ([bibtex](https://raw.githubusercontent.com/slundberg/shap/master/docs/references/nature_bme.bib); [free access](https://rdcu.be/baVbR)).\n\n<img height=\"1\" width=\"1\" style=\"display:none\" src=\"https://www.facebook.com/tr?id=189147091855991&ev=PageView&noscript=1\" />"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The algorithms and visualizations used in this package came primarily out of research in [Su-In Lee's lab](https://suinlee.cs.washington.edu) at the University of Washington, and Microsoft Research. If you use SHAP in your research we would appreciate a citation to the appropriate paper(s):\n\n- For general use of SHAP you can read/cite our [NeurIPS paper](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions) ([bibtex](https://raw.githubusercontent.com/slundberg/shap/master/docs/references/shap_nips.bib)). \n- For TreeExplainer you can read/cite our [Nature Machine Intelligence paper](https://www.nature.com/articles/s42256-019-0138-9) ([bibtex](https://raw.githubusercontent.com/slundberg/shap/master/docs/references/tree_explainer.bib); [free access](https://rdcu.be/b0z70)).\n- For `force_plot` visualizations and medical applications you can read/cite our [Nature Biomedical Engineering paper](https://www.nature.com/articles/s41551-018-0304-0) ([bibtex](https://raw.githubusercontent.com/slundberg/shap/master/docs/references/nature_bme.bib); [free access](https://rdcu.be/baVbR)).\n\n<img height=\"1\" width=\"1\" style=\"display:none\" src=\"https://www.facebook.com/tr?id=189147091855991&ev=PageView&noscript=1\" />\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9997626875156186
      ],
      "excerpt": "LIME: Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. \"Why should i trust you?: Explaining the predictions of any classifier.\" Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2016. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9997580599793784,
        0.9998956826332083,
        0.836194381413665,
        0.9953824643700333
      ],
      "excerpt": "DeepLIFT: Shrikumar, Avanti, Peyton Greenside, and Anshul Kundaje. \"Learning important features through propagating activation differences.\" arXiv preprint arXiv:1704.02685 (2017). \nQII: Datta, Anupam, Shayak Sen, and Yair Zick. \"Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems.\" Security and Privacy (SP), 2016 IEEE Symposium on. IEEE, 2016. \nLayer-wise relevance propagation: Bach, Sebastian, et al. \"On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation.\" PloS one 10.7 (2015): e0130140. \nShapley regression values: Lipovetsky, Stan, and Michael Conklin. \"Analysis of regression in game theory approach.\" Applied Stochastic Models in Business and Industry 17.4 (2001): 319-330. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/slundberg/shap",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-11-22T19:17:08Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-28T17:29:22Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9935683293981542
      ],
      "excerpt": "SHAP interaction values are a generalization of SHAP values to higher order interactions. Fast exact computation of pairwise interactions are implemented for tree models with shap.TreeExplainer(model).shap_interaction_values(X). This returns a matrix for every prediction, where the main effects are on the diagonal and the interaction effects are off-diagonal. These values often reveal interesting hidden relationships, such as how the increased risk of death peaks for men at age 60 (see the NHANES notebook for details): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9800118790150407,
        0.9796299554029462,
        0.9175613830691406,
        0.9257725825707774,
        0.9948714190988202,
        0.8692710975699615,
        0.9566375848007344,
        0.9932105654663833,
        0.9522923405392526,
        0.9756845251319001,
        0.9444934926144986,
        0.9915930992546405,
        0.9542848056134862,
        0.9875510733237219,
        0.9299618119560062,
        0.808394831977469
      ],
      "excerpt": "An implementation of Tree SHAP, a fast and exact algorithm to compute SHAP values for trees and ensembles of trees. \nNHANES survival model with XGBoost and SHAP interaction values - Using mortality data from 20 years of followup this notebook demonstrates how to use XGBoost and shap to uncover complex risk factor relationships. \nCensus income classification with LightGBM - Using the standard adult census income dataset, this notebook trains a gradient boosting tree model with LightGBM and then explains predictions using shap. \nLeague of Legends Win Prediction with XGBoost - Using a Kaggle dataset of 180,000 ranked matches from League of Legends we train and explain a gradient boosting tree model with XGBoost to predict if a player will win their match. \nAn implementation of Deep SHAP, a faster (but only approximate) algorithm to compute SHAP values for deep learning models that is based on connections between SHAP and the DeepLIFT algorithm. \nMNIST Digit classification with Keras - Using the MNIST handwriting recognition dataset, this notebook trains a neural network with Keras and then explains predictions using shap. \nKeras LSTM for IMDB Sentiment Classification - This notebook trains an LSTM with Keras on the IMDB text sentiment analysis dataset and then explains predictions using shap. \nAn implementation of expected gradients to approximate SHAP values for deep learning models. It is based on connections between SHAP and the Integrated Gradients algorithm. GradientExplainer is slower than DeepExplainer and makes different approximation assumptions. \nExplain an Intermediate Layer of VGG16 on ImageNet - This notebook demonstrates how to explain the output of a pre-trained VGG16 ImageNet model using an internal convolutional layer. \nFor a linear model with independent features we can analytically compute the exact SHAP values. We can also account for feature correlation if we are willing to estimate the feature covaraince matrix. LinearExplainer supports both of these options. \nSentiment Analysis with Logistic Regression - This notebook demonstrates how to explain a linear logistic regression sentiment analysis model. \nAn implementation of Kernel SHAP, a model agnostic method to estimate SHAP values for any model. Because it makes not assumptions about the model type, KernelExplainer is slower than the other model type specific algorithms. \nCensus income classification with scikit-learn - Using the standard adult census income dataset, this notebook trains a k-nearest neighbors classifier using scikit-learn and then explains predictions using shap. \nImageNet VGG16 Model with Keras - Explain the classic VGG16 convolutional nerual network's predictions for an image. This works by applying the model agnostic Kernel SHAP method to a super-pixel segmented image. \nIris classification - A basic demonstration using the popular iris species dataset. It explains predictions from six different models in scikit-learn using shap. \nLIME: Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. \"Why should i trust you?: Explaining the predictions of any classifier.\" Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2016. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8863990887123901
      ],
      "excerpt": "Shapley regression values: Lipovetsky, Stan, and Michael Conklin. \"Analysis of regression in game theory approach.\" Applied Stochastic Models in Business and Industry 17.4 (2001): 319-330. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A game theoretic approach to explain the output of any machine learning model.",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "These notebooks comprehensively demonstrate how to use specific functions and objects. \n\n- [`shap.decision_plot` and `shap.multioutput_decision_plot`](https://slundberg.github.io/shap/notebooks/plots/decision_plot.html)\n\n- [`shap.dependence_plot`](https://slundberg.github.io/shap/notebooks/plots/dependence_plot.html)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://shap.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/slundberg/shap/releases",
    "technique": "GitHub API"
  },
  "executable_example": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://mybinder.org/v2/gh/slundberg/shap/master",
      "technique": "Regular expression"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2253,
      "date": "Tue, 28 Dec 2021 20:21:50 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/slundberg/shap/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "slundberg/shap",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/slundberg/shap/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/image_examples/image_captioning/Image%20Captioning%20using%20Azure%20Cognitive%20Services.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/image_examples/image_captioning/Image%20Captioning%20using%20Open%20Source.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/image_examples/image_classification/Explain%20an%20Intermediate%20Layer%20of%20VGG16%20on%20ImageNet.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/image_examples/image_classification/Explain%20an%20Intermediate%20Layer%20of%20VGG16%20on%20ImageNet%20%28PyTorch%29.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/image_examples/image_classification/Explain%20ResNet50%20using%20the%20Partition%20explainer.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/image_examples/image_classification/Multi-input%20Gradient%20Explainer%20MNIST%20Example.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/image_examples/image_classification/Multi-class%20ResNet50%20on%20ImageNet%20%28TensorFlow%29-checkpoint.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/image_examples/image_classification/Image%20Multi%20Class.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/image_examples/image_classification/PyTorch%20Deep%20Explainer%20MNIST%20example.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/image_examples/image_classification/Front%20Page%20DeepExplainer%20MNIST%20Example.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/image_examples/image_classification/Multi-class%20ResNet50%20on%20ImageNet%20%28TensorFlow%29.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/api_examples/maskers/custom.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/api_examples/plots/heatmap.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/api_examples/plots/text.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/api_examples/plots/image.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/api_examples/plots/bar.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/api_examples/plots/waterfall.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/api_examples/plots/scatter.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/api_examples/plots/beeswarm.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/api_examples/plots/decision_plot.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/api_examples/explainers/GPUTree.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/api_examples/explainers/Exact.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/api_examples/explainers/Permutation.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/text_examples/summarization/Abstractive%20Summarization%20Explanation%20Demo.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/text_examples/sentiment_analysis/Keras%20LSTM%20for%20IMDB%20Sentiment%20Classification.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/text_examples/sentiment_analysis/Positive%20vs.%20Negative%20Sentiment%20Classification.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/text_examples/sentiment_analysis/Emotion%20classification%20multiclass%20example.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/text_examples/sentiment_analysis/Using%20custom%20functions%20and%20tokenizers.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/text_examples/language_modelling/Language%20Modeling%20Explanation%20Demo.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/text_examples/question_answering/Explaining%20a%20Question%20Answering%20Transformers%20Model.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/text_examples/text_generation/Open%20Ended%20GPT2%20Text%20Generation%20Explanations.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/text_examples/translation/Machine%20Translation%20Explanations.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/text_examples/text_entailment/Textual%20Entailment%20Explanation%20Demo.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/benchmarks/tabular/Benchmark%20XGBoost%20explanations.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/overviews/Be%20careful%20when%20interpreting%20predictive%20models%20in%20search%20of%20causal%C2%A0insights.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/overviews/Explaining%20quantitative%20measures%20of%20fairness.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/benchmark/tabular/Tabular%20Prediction%20Benchmark%20Demo.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/benchmark/image/Image%20Multiclass%20Classification%20Benchmark%20Demo.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/benchmark/text/Text%20Emotion%20Multiclass%20Classification%20Benchmark%20Demo.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/benchmark/text/Abstractive%20Summarization%20Benchmark%20Demo.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/benchmark/text/Machine%20Translation%20Benchmark%20Demo.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/benchmark/others/Benchmark%20Debug%20Mode.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/model_agnostic/Simple%20Kernel%20SHAP.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/model_agnostic/Multioutput%20Regression%20SHAP.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/model_agnostic/Diabetes%20regression.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/model_agnostic/Iris%20classification%20with%20scikit-learn.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/model_agnostic/Census%20income%20classification%20with%20scikit-learn.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/model_agnostic/Squashing%20Effect.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/model_agnostic/Simple%20Boston%20Demo.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/Census%20income%20classification%20with%20XGBoost.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/Scatter%20Density%20vs.%20Violin%20Plot%20Comparison.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/Basic%20SHAP%20Interaction%20Value%20Example%20in%20XGBoost.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/Example%20of%20loading%20a%20custom%20tree%20model%20into%20SHAP.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/Explaining%20the%20Loss%20of%20a%20Model.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/League%20of%20Legends%20Win%20Prediction%20with%20XGBoost.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/Census%20income%20classification%20with%20LightGBM.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/Perfomance%20Comparison.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/Python%20Version%20of%20Tree%20SHAP.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/Catboost%20tutorial.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/Force%20Plot%20Colors.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/Front%20page%20example%20%28XGBoost%29.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/Understanding%20Tree%20SHAP%20for%20Simple%20Models.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/NHANES%20I%20Survival%20Model.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/Explaining%20a%20simple%20OR%20function.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/Fitting%20a%20Linear%20Simulation%20with%20XGBoost.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/tree_shap_paper/Performance%20comparison.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/tree_shap_paper/Figure%206%20-%20Supervised%20Clustering%20R-squared.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/tree_shap_paper/Figures%208-11%20NHANES%20I%20Survival%20Model.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/tree_shap_paper/Figure%201%20-%20Simple%20Inconsistency%20Example.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/tree_shap_paper/Performance%20comparison%20copy.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/tree_shap_paper/Tree%20SHAP%20in%20Python.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/tree_shap_paper/Figure%204%20-%20Supervised%20Clustering%20Adult%20Census%20Data.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/tree_shap_paper/Figure%207%20-%20Airline%20Tweet%20Sentiment%20Analysis.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/tree_shap_paper/Figure%203%20-%20User%20Study.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/tree_shap_paper/Figure%205%20-%20Runtime.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/tree_based_models/tree_shap_paper/Figures%208-11%20NHANES%20I%20Survival%20Model-Copy1.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/linear_models/Math%20behind%20LinearExplainer%20with%20correlation%20feature%20perturbation.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/linear_models/Sentiment%20Analysis%20with%20Logistic%20Regression.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/tabular_examples/neural_networks/Census%20income%20classification%20with%20Keras.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/notebooks/genomic_examples/DeepExplainer%20Genomics%20Example.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/docs/notebooks/plots/bar.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/docs/user_studies/sickness_scores/Analyse%20Results.ipynb",
      "https://raw.githubusercontent.com/slundberg/shap/master/docs/user_studies/sickness_scores/Approve%20Hits.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "SHAP can be installed from either [PyPI](https://pypi.org/project/shap) or [conda-forge](https://anaconda.org/conda-forge/shap):\n\n<pre>\npip install shap\n<i>or</i>\nconda install -c conda-forge shap\n</pre>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8147063921061061
      ],
      "excerpt": "Census income classification with scikit-learn - Using the standard adult census income dataset, this notebook trains a k-nearest neighbors classifier using scikit-learn and then explains predictions using shap. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/slundberg/shap/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "C++",
      "JavaScript",
      "Cuda",
      "PowerShell",
      "Batchfile",
      "HTML"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License (MIT)\\n\\nCopyright (c) 2018 Scott Lundberg\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "citations) for details and citations).",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "shap",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "slundberg",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/slundberg/shap/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "This release contains many bugs fixes and lots of new functionality, specifically for transformer based NLP models. Some highlights include:\r\n- New plots, bug fixes, docs, and features for NLP model explanations (see docs for details).\r\n- important permutation explainer performance fix by @sander-sn \r\n- New joint scatter plots to plot many at once on the same y-scale\r\n- better tree model memory usage by @morriskurz \r\n- new docs by @coryroyce \r\n- new wheel building by @PrimozGodec \r\n- dark mode improvements for the docs by @gialmisi \r\n- api tweaks by @c56pony @nsorros @jebarb ",
        "dateCreated": "2021-10-20T18:24:29Z",
        "datePublished": "2021-10-20T18:36:57Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/v0.40.0",
        "name": "v0.40.0",
        "tag_name": "v0.40.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/v0.40.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/51730201",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/v0.40.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "Lots of new text explainer work courtesy of @ryserrao and serialization courtesy of @vivekchettiar! (will note all the other changes later)",
        "dateCreated": "2021-03-03T18:36:49Z",
        "datePublished": "2021-03-03T18:38:33Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/v0.39.0",
        "name": "v0.39.0",
        "tag_name": "v0.39.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/v0.39.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/39205263",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/v0.39.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "Fixes a version mismatch with the v0.38.0 release and serialization updates.",
        "dateCreated": "2021-01-15T17:47:40Z",
        "datePublished": "2021-01-15T18:02:54Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/v0.38.1",
        "name": "v0.38.1",
        "tag_name": "v0.38.1",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/v0.38.1",
        "url": "https://api.github.com/repos/slundberg/shap/releases/36463279",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/v0.38.1"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "This release contains improved support for explanations of transformer text models and support for the new Explanation object based API. Specific improvements include:\r\n\r\n- Transformer model support in the Text explainer courtesy of @ryserrao\r\n- Interventional Tree explainer GPU support courtesy of @RAMitchell\r\n- Image captioning model support courtesy of @anusham1990 \r\n- Benchmarking improvements courtesy of @maggiewu19 \r\n- New text and image visualizations courtesy of @vivekchettiar \r\n- New explainer serialization support courtesy of @vivekchettiar\r\n- Bug fixes for Linear explainer and the new API courtesy of @heimengqi \r\n- Fix for categorical plots courtesy of @jeffreyftang\r\n- CUDA support improvements courtesy of @JohnZed \r\n- Support for econML model courtesy of @vasilismsr\r\n- Many other bug fixes and API improvements.\r\n",
        "dateCreated": "2021-01-14T17:17:44Z",
        "datePublished": "2021-01-14T17:33:16Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/v0.38.0",
        "name": "v0.38.0",
        "tag_name": "v0.38.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/v0.38.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/36402992",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/v0.38.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "This release contains more support for the new API, many bug fixes, and preliminary model agnostic text/image explainer support (still beta). Specific contributions include:\r\n\r\n- Fix Sampling explainer sample counting issue courtesy of @tcbegley \r\n- Add multi-bar plotting support.\r\n- Preliminary support for cohorts.\r\n- Fixed an import error courtesy of @suragnair \r\n- Fix Tree explainer issues with isolation forests with max_features < 1 courtesy of @zhanjiezhu\r\n- Huge documentation cleanup and update courtesy of @lrjball \r\n- Typo fix courtesy of @anusham1990\r\n- Added a documentation notebook for the Exact explainer.\r\n- Text and Image explainers courtesy of @anusham1990 and Ryan Serrao\r\n- Bug fix for shap.utils.hclust\r\n- Initial support for InterpretML EBM models.\r\n- Added column grouping functionality to Explainer objects.\r\n- Fix for loop index bug in Deep explainer for PyTorch courtesy of @quentinRaq \r\n- Initial text to text visualization concepts courtesy of @vivekchettiar\r\n- Color conversion warning fix courtesy of @wangjoshuah \r\n- Fix invertibility issues in Kernel explainer with the pseudoinverse courtesy of @PrimozGodec \r\n- New benchmark code courtesy of @maggiewu19 and @vivekchettiar\r\n- Other small bug fixes and enhancements.",
        "dateCreated": "2020-11-04T19:06:03Z",
        "datePublished": "2020-11-04T21:26:02Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/v0.37.0",
        "name": "v0.37.0",
        "tag_name": "v0.37.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/v0.37.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/33474518",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/v0.37.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "This version contains a significant refactoring of the SHAP code base into a new (cleaner) API. Full backwards compatibility should be retained, but most things are now available in locations with the new API. Note that this API is still in a beta form, so refrain from depending on it for production code until the next release. Highlights include:\r\n- A new shap.Explainer object that auto-chooses the explainer based on the given model and masking dataset.\r\n- A new shap.Explanation object that allows for parallel slicing of data, SHAP values, base values (expected values), and other explanation-specific elements.\r\n- A new shap.maskers.* module that separates the various ways to mask (i.e. perturb/hide) features from the algorithms themselves.\r\n- A new shap.explainers.Partition explainer that can explain any text or image models very quickly.\r\n- A new shap.maskers.Partition masker that ensures tightly grouped features are perturbed in unison, so preventing \"unrealistic\" model inputs from inappropriately influencing the model prediction. It also allows for the exact quadratic time computation of SHAP values for the 'structured games' (with coalitions structured according to a hierarchical clustering).\r\n- A new shap.plots.* module with revamped plot types that all support the new API. Plots are now named more directly, so `summary_plot` (default) becomes `beeswarm`, and `dependent_plot` becomes `scatter`. Not all the plots have been ported over to the new API, but most have.\r\n- A new notebooks/plots/* directory given examples of how to use the new plotting functions.\r\n- A new shap.plots.bar function to directly create bar plots and also display hierarchical clustering structures to group redundant features together, and show the structure used by a Partition explainer (that relied on Owen values, which are an extension of Shapley values).\r\n- Equally check fixes courtesy of @jameslamb\r\n- Sparse kmeans support courtesy of @PrimozGodec\r\n- Pytorch bug fixes courtesy of @rightx2\r\n- NPM JS code clean up courtesy of @SachinVarghese\r\n- Fix logit force plot bug courtesy of @ehuijzer\r\n- Decision plot documentation updates courtesy of @floidgilbert\r\n- sklearn GBM fix courtesy of @ChemEngDataSci\r\n- XGBoost 1.1 fix courtesy of @lrjball\r\n- Make SHAP spark serializable courtesy of @QuentinAmbard\r\n- Custom summary plot color maps courtesy of @nasir-bhanpuri\r\n- Support string inputs for KernelSHAP courtesy of @YotamElor\r\n- Doc fixes courtesy of @imatiach-msft\r\n- Support for GPBoost courtesy of @fabsig\r\n- Import bug fix courtesy of @gracecarrillo and @aokeson \r\n\r\n",
        "dateCreated": "2020-08-27T23:13:20Z",
        "datePublished": "2020-08-27T23:15:10Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/v0.36.0",
        "name": "v0.36.0",
        "tag_name": "v0.36.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/v0.36.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/30293992",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/v0.36.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "This release includes:\r\n\r\n- Better support for TensorFlow 2 (thanks @imatiach-msft)\r\n- Support for NGBoost models in TreeExplainer (thanks @zhiruiwang)\r\n- TreeExplainer support for the new sklearn.ensemble.HistGradientBoosting model.\r\n- New improved versions of PartitionExplainer for images and text.\r\n- IBM zOS compatibility courtesy of @DorianCzichotzki.\r\n- Support for XGBoost 1.0\r\n- Many bug fixes courtesy of Ivan, Christian Paul, @RandallJEllis, and @ibuda.",
        "dateCreated": "2020-02-27T19:27:29Z",
        "datePublished": "2020-02-27T19:35:49Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.35.0",
        "name": "0.35.0",
        "tag_name": "0.35.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.35.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/24051602",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.35.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "This release includes:\r\n- Many small bug fixes.\r\n- Better matplotlib text alignment during rotation courtesy of @koomie\r\n- Cleaned up the C++ transformer code to allow easier PRs.\r\n- Fixed a too tight check_additivity tolerance in TreeExplainer #950\r\n- Updated the LinearExplainer API to match TreeExplainer\r\n- Allow custom class ordering in a summary_plot courtesy of @SimonStreicher",
        "dateCreated": "2019-12-27T17:46:10Z",
        "datePublished": "2019-12-27T17:51:57Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.34.0",
        "name": "0.34.0",
        "tag_name": "0.34.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.34.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/22488244",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.34.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "This release contains various bug fixes and new features including:\r\n\r\n- Added PySpark support for TreeExplainer courtesy of @QuentinAmbard\r\n- A new type of plot that is an alternative to the force_plot, a `waterfall_plot`\r\n- A new PermutationExplainer that is an alternative to KernelExplainer and SamplingExplainer.\r\n- Added `return_variances` to GradientExplainer for PyTorch courtesy of @s6juncheng \r\n- Now we use exceptions rather than assertions in TreeExplainer courtesy of @ssaamm\r\n- Fixed image_plot transpose issue courtesy of @Jimbotsai\r\n- Fix color bar axis attachment issue courtesy of Lasse Valentini Jensen\r\n- Fix tensor attachment issue in PyTorch courtesy of @gabrieltseng \r\n- Fix color clipping ranges in summary_pot courtesy of @joelostblom\r\n- Address sklearn 0.22 API changes courtesy of @lemon-yellow\r\n- Ensure matplotlib is optional courtesy of @imatiach-msft ",
        "dateCreated": "2019-12-11T21:27:08Z",
        "datePublished": "2019-12-11T21:39:57Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.33.0",
        "name": "0.33.0",
        "tag_name": "0.33.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.33.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/22159812",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.33.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "This release is just intended to push better auto-deploy bundles out of travis and appveyor.",
        "dateCreated": "2019-11-06T19:10:37Z",
        "datePublished": "2019-11-06T19:23:14Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.32.1",
        "name": "0.32.1",
        "tag_name": "0.32.1",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.32.1",
        "url": "https://api.github.com/repos/slundberg/shap/releases/21266552",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.32.1"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "This release includes:\r\n- Support for sklearn isolation forest courtesy of @JiechengZhao \r\n- New check_additivity tests to ensure no errors in DeepExplainer and TreeExplainer\r\n- Fix #861, #860 \r\n- Fix missing readme example html file\r\n- Support for spark decision tree regressor courtesy of @QuentinAmbard \r\n- Better safe isinstance checking courtesy of @parsatorb\r\n- Fix eager execution in TF < 2 courtesy of @bottydim",
        "dateCreated": "2019-11-06T16:57:50Z",
        "datePublished": "2019-11-06T17:04:08Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.32.0",
        "name": "0.32.0",
        "tag_name": "0.32.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.32.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/21262524",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.32.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "This release contains several new features and bug fixes:\r\n- GradientExplainer now supports TensorFlow 2.0.\r\n- We now do a lazy load of the plotting dependencies, which means a pip install no longer needs to also pull in matplotlib, skimage, and ipython. This should make installs much lighter, especially those that don't need plotting :)\r\n- Added a new BruteForceExplainer for easy testing and comparison on small problems.\r\n- Added a new partial_dependence_plot function. This function will be used to illustrate the close connections between partial dependence plots and SHAP values in future example notebooks.\r\n- Handle the multiclass case with no intercept in LinearExplainer courtesy of @gabrieltseng \r\n- Some extras_require options during the pip install courtesy of @AbdealiJK \r\n- Other small bug fixes and updates\r\n",
        "dateCreated": "2019-10-17T04:20:32Z",
        "datePublished": "2019-10-21T02:42:31Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.31.0",
        "name": "0.31.0",
        "tag_name": "0.31.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.31.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/20839011",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.31.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "This release is primarily to remove a dependency on dill that was not in setup.py. It also includes:\r\n\r\n- A typo fix in force.py courtesy of @jonlwowski012\r\n- Test code cleanup courtesy of @jorgecarleitao ",
        "dateCreated": "2019-10-08T20:25:09Z",
        "datePublished": "2019-10-09T17:54:34Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.30.2",
        "name": "0.30.2",
        "tag_name": "0.30.2",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.30.2",
        "url": "https://api.github.com/repos/slundberg/shap/releases/20587820",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.30.2"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "- Fix floating point rounding mismatches in recent sklearn versions of tree models\r\n- An update to allow easier loading of custom tree ensemble models by TreeExplainer.\r\n- `decision_plot` documentation updates courtesy of @floidgilbert ",
        "dateCreated": "2019-09-09T22:04:05Z",
        "datePublished": "2019-09-09T22:17:07Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.30.1",
        "name": "0.30.1",
        "tag_name": "0.30.1",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.30.1",
        "url": "https://api.github.com/repos/slundberg/shap/releases/19865534",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.30.1"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "- New decision_plot function courtesy of @floidgilbert \r\n- Add alpha version of the new model agnostic PartitionExplainer\r\n- ensure data is all on the same device for pytorch in DeepExplainer courtesy of @gabrieltseng \r\n- fix lightgbm edge case issue courtesy of @imatiach-msft\r\n- create binder setup for shap courtesy of @jamesmyatt \r\n- Allow for multiple inputs in the gradient explainer courtesy of @gabrieltseng\r\n- New KernelExplainer unit tests courtesy of @jorgecarleitao\r\n- Add python 2/3 trove classifiers courtesy of @proinsias\r\n- support for pyspark trees courtesy of @QuentinAmbard\r\n- many other bug fixes courtesy of @Rygu, @Kylecrif, @trams, @imatiach-msft, @yunchuankong, @invokermain, @lupusomniator, @satyarta, @jotsif, @parkerzf, @jaller94, @gabrieltseng, and others\r\n",
        "dateCreated": "2019-08-31T22:57:09Z",
        "datePublished": "2019-08-31T23:10:38Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.30.0",
        "name": "0.30.0",
        "tag_name": "0.30.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.30.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/19675586",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.30.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "- Fixes an issue in DeepExplainer caused by a change in TensorFlow 1.14.",
        "dateCreated": "2019-06-19T20:30:42Z",
        "datePublished": "2019-06-19T20:48:02Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.29.3",
        "name": "0.29.3",
        "tag_name": "0.29.3",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.29.3",
        "url": "https://api.github.com/repos/slundberg/shap/releases/18104197",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.29.3"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "Various bug fixes and improvements including:\r\n\r\n- adding SHAP values for binary classification to CatBoost courtesy of @dvpolyakov\r\n- Integer division fix for plots courtesy of @pmeier-tiplu\r\n- Support passing in an Axes object to dependence_plot courtesy of @mqk \r\n- Add adaptive average pooling and conv transpose layers courtesy of of @gabrieltseng \r\n- fix import errors on a missing matplotlib backend courtesy of @hchandola \r\n- fix TreeExplainer GradientBoostingClassifier bug courtesy of @prempiyush\r\n- make tqdm play nicer with notebooks courtesy of @KOLANICH\r\n- Allow deep_pytorch to use cuda models courtesy of @juliusbierk \r\n- Fix sklearn GradientBoostingRegressor bug courtesy of @nasir-bhanpuri \r\n- adding sparse support to shap linear explainer courtesy of @imatiach-msft ",
        "dateCreated": "2019-06-19T00:24:02Z",
        "datePublished": "2019-06-19T15:46:47Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.29.2",
        "name": "0.29.2",
        "tag_name": "0.29.2",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.29.2",
        "url": "https://api.github.com/repos/slundberg/shap/releases/18096933",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.29.2"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "Fixes to support changes in the most recent version of sklearn",
        "dateCreated": "2019-05-15T01:19:29Z",
        "datePublished": "2019-05-15T10:10:04Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.29.1",
        "name": "0.29.1",
        "tag_name": "0.29.1",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.29.1",
        "url": "https://api.github.com/repos/slundberg/shap/releases/17363758",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.29.1"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "A few contribution highlights of this release (in chronological order)\r\n- Better testing courtesy of @jorgecarleitao\r\n- Image plot customizations courtesy of @verdimrc\r\n- Batch norm support for PyTorch in DeepExplainer courtesy of @JiechengZhao\r\n- Leaky ReLU and other conv layer support for pytorch deep explainer courtesy of @gabrieltseng \r\n- Fixed keras multi input in gradient explainer and improved random seeds courtesy of @moritzaugustin\r\n- Support for catBoost ranker courtesy of @doramir\r\n- Added XGBRanker and LGBMRanker to TreeExplainer courtesy of @imatiach-msft\r\n- Fix embedding lookup with tf.keras in DeepExplainer courtesy of @andriy-nikolov \r\n- Custom dependence_plot colors maps courtesy of @rcarneva \r\n- Fix divide by zero issues possible with CatBoost models courtesy of @dvpolyakov\r\n- Lots of other bug fixes/improvements!",
        "dateCreated": "2019-05-03T16:18:55Z",
        "datePublished": "2019-05-14T23:45:07Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.29.0",
        "name": "0.29.0",
        "tag_name": "0.29.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.29.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/17355332",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.29.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "This release is just to refresh the Windows builds on AppVeyor that didn't complete for 0.28.4",
        "dateCreated": "2019-02-16T17:57:58Z",
        "datePublished": "2019-02-16T17:59:43Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.28.5",
        "name": "0.28.5",
        "tag_name": "0.28.5",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.28.5",
        "url": "https://api.github.com/repos/slundberg/shap/releases/15600896",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.28.5"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "- Fixes memory corruption error from TreeExplainer (courtesy of @imatiach-msft)\r\n- Adds support for skopt Random Forest and ExtraTrees Regressors (courtesy of @Bacoknight)\r\n- Adds support for matplotlib forceplot with text rotation (courtesy of @vatsan)\r\n- Adds a save_html function",
        "dateCreated": "2019-02-16T01:29:55Z",
        "datePublished": "2019-02-16T02:00:34Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.28.4",
        "name": "0.28.4",
        "tag_name": "0.28.4",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.28.4",
        "url": "https://api.github.com/repos/slundberg/shap/releases/15596389",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.28.4"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "- Fix some plot coloring issues introduced by 0.28 (such as #406)",
        "dateCreated": "2019-01-24T17:16:29Z",
        "datePublished": "2019-01-24T17:30:11Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.28.3",
        "name": "0.28.3",
        "tag_name": "0.28.3",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.28.3",
        "url": "https://api.github.com/repos/slundberg/shap/releases/15164831",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.28.3"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "- Downgrade numpy API usage to support older versions.",
        "dateCreated": "2019-01-23T22:08:07Z",
        "datePublished": "2019-01-23T22:35:40Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.28.2",
        "name": "0.28.2",
        "tag_name": "0.28.2",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.28.2",
        "url": "https://api.github.com/repos/slundberg/shap/releases/15146325",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.28.2"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "- Fixes a byte-alignment issue on Windows when loading XGBoost models.\r\n- Now matches tree_limit use in XGBoost models courtesy of @HughChen \r\n- Fix an issue with the expected_value of transformed model outputs in TreeExplainer",
        "dateCreated": "2019-01-23T20:57:45Z",
        "datePublished": "2019-01-23T21:36:13Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.28.1",
        "name": "0.28.1",
        "tag_name": "0.28.1",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.28.1",
        "url": "https://api.github.com/repos/slundberg/shap/releases/15145421",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.28.1"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "- Add support for rank-based feature selection in `KernelExplainer`.\r\n- Depreciate `l1_reg=\"auto\"` in `KernelExplainer` in favor of eventually defaulting to `l1_reg=\"num_features(10)\"` \r\n- New color scales based on the Lch color space.\r\n- Better auto-color choices for multi-class summary plots.\r\n- Better plotting of NaN values in dependence_plots\r\n- Updates for Pytorch 1.0 courtesy of @gabrieltseng \r\n- Fix the sklearn DecisionTreeClassifier handling to correctly normalize to a probability output\r\n- Enable multi-output model support for `TreeExplainer` when `feature_dependence=\"independent\"`\r\n- Correctly load the objective of LightGBM models for use in explaining the model loss.\r\n- Fix numerical precision mismatch with sklearn models.\r\n- Fix numerical precision mismatch with XGBoost models by now directly loading from memory instead of JSON.",
        "dateCreated": "2019-01-21T18:52:12Z",
        "datePublished": "2019-01-21T19:11:47Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.28.0",
        "name": "0.28.0",
        "tag_name": "0.28.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.28.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/15095700",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.28.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "- Better hierarchal clustering orderings that now rotate subtrees to give more continuity.\r\n- Work around XGBoost JSON issue.\r\n- Account for NaNs when doing auto interaction detection.\r\n- PyTorch fixes.\r\n- Updated LinearExplainer.",
        "dateCreated": "2019-01-01T17:41:38Z",
        "datePublished": "2019-01-01T17:46:01Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.27.0",
        "name": "0.27.0",
        "tag_name": "0.27.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.27.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/14758196",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.27.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "- Complete refactor of TreeExplainer to support deeper C++ integration\r\n- The ability to explain transformed outputs of tree models in TreeExplainer, including the loss. In collaboration with @HughChen \r\n- Allow for a dynamic reference value in DeepExplainer courtesy of @AvantiShri \r\n- Add `x_jitter` option for categorical dependence plots courtesy of @ihopethiswillfi \r\n- Added support for GradientBoostingRegressor with quantile loss courtesy of @dmilad\r\n- Better plotting support for NaN values\r\n- Fixes several bugs.\r\n\r\n",
        "dateCreated": "2018-12-12T21:15:54Z",
        "datePublished": "2018-12-12T21:35:42Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.26.0",
        "name": "0.26.0",
        "tag_name": "0.26.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.26.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/14502432",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.26.0"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "- Allows ordering_keys to be given to force_plot courtesy of @JasonTam \r\n- Fixes sparse nonzero background issue with KernelExplainer courtesy of @imatiach-msft \r\n- Fix to support tf.concat in DeepExplainer.",
        "dateCreated": "2018-11-09T19:49:13Z",
        "datePublished": "2018-11-09T19:57:06Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.25.2",
        "name": "0.25.2",
        "tag_name": "0.25.2",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.25.2",
        "url": "https://api.github.com/repos/slundberg/shap/releases/13928290",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.25.2"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "Fixes a problem where tree_shap.h was not included in the pip bundle.",
        "dateCreated": "2018-11-08T00:27:35Z",
        "datePublished": "2018-11-08T00:30:23Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.25.1",
        "name": "0.25.1",
        "tag_name": "0.25.1",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.25.1",
        "url": "https://api.github.com/repos/slundberg/shap/releases/13888281",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.25.1"
      },
      {
        "authorType": "User",
        "author_name": "slundberg",
        "body": "- Support for PyTorch in GradientExplainer and preliminary support for PyTorch in DeepExplainer courtesy of @gabrieltseng.\r\n- A matplotlib version of the single sample force_plot courtesy of @jverre.\r\n- Support functional Keras models in GradientExplainer.\r\n- KernelExplainer speed improvements.\r\n- Various performance improvements and bug fixes.",
        "dateCreated": "2018-11-02T22:02:31Z",
        "datePublished": "2018-11-07T16:25:53Z",
        "html_url": "https://github.com/slundberg/shap/releases/tag/0.25.0",
        "name": "0.25.0",
        "tag_name": "0.25.0",
        "tarball_url": "https://api.github.com/repos/slundberg/shap/tarball/0.25.0",
        "url": "https://api.github.com/repos/slundberg/shap/releases/13879728",
        "zipball_url": "https://api.github.com/repos/slundberg/shap/zipball/0.25.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 14972,
      "date": "Tue, 28 Dec 2021 20:21:50 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "interpretability",
      "machine-learning",
      "deep-learning",
      "gradient-boosting",
      "shap",
      "shapley",
      "explainability"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "While SHAP can explain the output of any machine learning model, we have developed a high-speed exact algorithm for tree ensemble methods (see our [Nature MI paper](https://rdcu.be/b0z70)). Fast C++ implementations are supported for *XGBoost*, *LightGBM*, *CatBoost*, *scikit-learn* and *pyspark* tree models:\n\n```python\nimport xgboost\nimport shap\n\n#: train an XGBoost model\nX, y = shap.datasets.boston()\nmodel = xgboost.XGBRegressor().fit(X, y)\n\n#: explain the model's predictions using SHAP\n#: (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\nexplainer = shap.Explainer(model)\nshap_values = explainer(X)\n\n#: visualize the first prediction's explanation\nshap.plots.waterfall(shap_values[0])\n```\n\n<p align=\"center\">\n  <img width=\"616\" src=\"https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_waterfall.png\" />\n</p>\n\nThe above explanation shows features each contributing to push the model output from the base value (the average model output over the training dataset we passed) to the model output. Features pushing the prediction higher are shown in red, those pushing the prediction lower are in blue. Another way to visualize the same explanation is to use a force plot (these are introduced in our [Nature BME paper](https://rdcu.be/baVbR)):\n\n```python\n#: visualize the first prediction's explanation with a force plot\nshap.plots.force(shap_values[0])\n```\n\n<p align=\"center\">\n  <img width=\"811\" src=\"https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_instance.png\" />\n</p>\n\nIf we take many force plot explanations such as the one shown above, rotate them 90 degrees, and then stack them horizontally, we can see explanations for an entire dataset (in the notebook this plot is interactive):\n\n```python\n#: visualize all the training set predictions\nshap.plots.force(shap_values)\n```\n\n<p align=\"center\">\n  <img width=\"811\" src=\"https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_dataset.png\" />\n</p>\n\nTo understand how a single feature effects the output of the model we can plot the SHAP value of that feature vs. the value of the feature for all the examples in a dataset. Since SHAP values represent a feature's responsibility for a change in the model output, the plot below represents the change in predicted house price as RM (the average number of rooms per house in an area) changes. Vertical dispersion at a single value of RM represents interaction effects with other features. To help reveal these interactions we can color by another feature. If we pass the whole explanation tensor to the `color` argument the scatter plot will pick the best feature to color by. In this case it picks RAD (index of accessibility to radial highways) since that highlights that the average number of rooms per house has less impact on home price for areas with a high RAD value.\n\n```python\n#: create a dependence scatter plot to show the effect of a single feature across the whole dataset\nshap.plots.scatter(shap_values[:,\"RM\"], color=shap_values)\n```\n\n<p align=\"center\">\n  <img width=\"544\" src=\"https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_scatter.png\" />\n</p>\n\n\nTo get an overview of which features are most important for a model we can plot the SHAP values of every feature for every sample. The plot below sorts features by the sum of SHAP value magnitudes over all samples, and uses SHAP values to show the distribution of the impacts each feature has on the model output. The color represents the feature value (red high, blue low). This reveals for example that a high LSTAT (% lower status of the population) lowers the predicted home price.\n\n```python\n#: summarize the effects of all the features\nshap.plots.beeswarm(shap_values)\n```\n\n<p align=\"center\">\n  <img width=\"583\" src=\"https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_beeswarm.png\" />\n</p>\n\nWe can also just take the mean absolute value of the SHAP values for each feature to get a standard bar plot (produces stacked bars for multi-class outputs):\n\n```python\nshap.plots.bar(shap_values)\n```\n\n<p align=\"center\">\n  <img width=\"570\" src=\"https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/boston_global_bar.png\" />\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "SHAP has specific support for natural language models like those in the Hugging Face transformers library. By adding coalitional rules to traditional Shapley values we can form games that explain large modern NLP model using very few function evaluations. Using this functionality is as simple as passing a supported transformers pipeline to SHAP:\n\n```python\nimport transformers\nimport shap\n\n#: load a transformers pipeline model\nmodel = transformers.pipeline('sentiment-analysis', return_all_scores=True)\n\n#: explain the model on two sample inputs\nexplainer = shap.Explainer(model) \nshap_values = explainer([\"What a great movie! ...if you have no taste.\"])\n\n#: visualize the first prediction's explanation for the POSITIVE output class\nshap.plots.text(shap_values[0, :, \"POSITIVE\"])\n```\n\n<p align=\"center\">\n  <img width=\"811\" src=\"https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/sentiment_analysis_plot.png\" />\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Deep SHAP is a high-speed approximation algorithm for SHAP values in deep learning models that builds on a connection with [DeepLIFT](https://arxiv.org/abs/1704.02685) described in the SHAP NIPS paper. The implementation here differs from the original DeepLIFT by using a distribution of background samples instead of a single reference value, and using Shapley equations to linearize components such as max, softmax, products, divisions, etc. Note that some of these enhancements have also been since integrated into DeepLIFT. TensorFlow models and Keras models using the TensorFlow backend are supported (there is also preliminary support for PyTorch):\n\n```python\n#: ...include code from https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n\nimport shap\nimport numpy as np\n\n#: select a set of background examples to take an expectation over\nbackground = x_train[np.random.choice(x_train.shape[0], 100, replace=False)]\n\n#: explain predictions of the model on four images\ne = shap.DeepExplainer(model, background)\n#: ...or pass tensors directly\n#: e = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)\nshap_values = e.shap_values(x_test[1:5])\n\n#: plot the feature attributions\nshap.image_plot(shap_values, -x_test[1:5])\n```\n\n<p align=\"center\">\n  <img width=\"820\" src=\"https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/mnist_image_plot.png\" />\n</p>\n\nThe plot above explains ten outputs (digits 0-9) for four different images. Red pixels increase the model's output while blue pixels decrease the output. The input images are shown on the left, and as nearly transparent grayscale backings behind each of the explanations. The sum of the SHAP values equals the difference between the expected model output (averaged over the background dataset) and the current model output. Note that for the 'zero' image the blank middle is important, while for the 'four' image the lack of a connection on top makes it a four instead of a nine.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Expected gradients combines ideas from [Integrated Gradients](https://arxiv.org/abs/1703.01365), SHAP, and [SmoothGrad](https://arxiv.org/abs/1706.03825) into a single expected value equation. This allows an entire dataset to be used as the background distribution (as opposed to a single reference value) and allows local smoothing. If we approximate the model with a linear function between each background data sample and the current input to be explained, and we assume the input features are independent then expected gradients will compute approximate SHAP values. In the example below we have explained how the 7th intermediate layer of the VGG16 ImageNet model impacts the output probabilities.\n\n```python\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nimport keras.backend as K\nimport numpy as np\nimport json\nimport shap\n\n#: load pre-trained model and choose two images to explain\nmodel = VGG16(weights='imagenet', include_top=True)\nX,y = shap.datasets.imagenet50()\nto_explain = X[[39,41]]\n\n#: load the ImageNet class names\nurl = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\nfname = shap.datasets.cache(url)\nwith open(fname) as f:\n    class_names = json.load(f)\n\n#: explain how the input to the 7th layer of the model explains the top two classes\ndef map2layer(x, layer):\n    feed_dict = dict(zip([model.layers[0].input], [preprocess_input(x.copy())]))\n    return K.get_session().run(model.layers[layer].input, feed_dict)\ne = shap.GradientExplainer(\n    (model.layers[7].input, model.layers[-1].output),\n    map2layer(X, 7),\n    local_smoothing=0 #: std dev of smoothing noise\n)\nshap_values,indexes = e.shap_values(map2layer(to_explain, 7), ranked_outputs=2)\n\n#: get the names for the classes\nindex_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)\n\n#: plot the explanations\nshap.image_plot(shap_values, to_explain, index_names)\n```\n\n<p align=\"center\">\n  <img width=\"500\" src=\"https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/gradient_imagenet_plot.png\" />\n</p>\n\nPredictions for two input images are explained in the plot above. Red pixels represent positive SHAP values that increase the probability of the class, while blue pixels represent negative SHAP values the reduce the probability of the class. By using `ranked_outputs=2` we explain only the two most likely classes for each input (this spares us from explaining all 1,000 classes).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Kernel SHAP uses a specially-weighted local linear regression to estimate SHAP values for any model. Below is a simple example for explaining a multi-class SVM on the classic iris dataset.\n\n```python\nimport sklearn\nimport shap\nfrom sklearn.model_selection import train_test_split\n\n#: print the JS visualization code to the notebook\nshap.initjs()\n\n#: train a SVM classifier\nX_train,X_test,Y_train,Y_test = train_test_split(*shap.datasets.iris(), test_size=0.2, random_state=0)\nsvm = sklearn.svm.SVC(kernel='rbf', probability=True)\nsvm.fit(X_train, Y_train)\n\n#: use Kernel SHAP to explain test set predictions\nexplainer = shap.KernelExplainer(svm.predict_proba, X_train, link=\"logit\")\nshap_values = explainer.shap_values(X_test, nsamples=100)\n\n#: plot the SHAP values for the Setosa output of the first instance\nshap.force_plot(explainer.expected_value[0], shap_values[0][0,:], X_test.iloc[0,:], link=\"logit\")\n```\n<p align=\"center\">\n  <img width=\"810\" src=\"https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/iris_instance.png\" />\n</p>\n\nThe above explanation shows four features each contributing to push the model output from the base value (the average model output over the training dataset we passed) towards zero. If there were any features pushing the class label higher they would be shown in red.\n\nIf we take many explanations such as the one shown above, rotate them 90 degrees, and then stack them horizontally, we can see explanations for an entire dataset. This is exactly what we do below for all the examples in the iris test set:\n\n```python\n#: plot the SHAP values for the Setosa output of all instances\nshap.force_plot(explainer.expected_value[0], shap_values[0], X_test, link=\"logit\")\n```\n<p align=\"center\">\n  <img width=\"813\" src=\"https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/iris_dataset.png\" />\n</p>\n\n",
      "technique": "Header extraction"
    }
  ]
}
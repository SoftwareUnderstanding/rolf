{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2106.09660",
      "https://arxiv.org/abs/2106.09660",
      "https://arxiv.org/abs/2106.09660",
      "https://arxiv.org/abs/2009.00713",
      "https://arxiv.org/abs/2006.11239",
      "https://arxiv.org/abs/2010.04301"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Chen *et al.*, [WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis](https://arxiv.org/abs/2106.09660)\n- Chen *et al.*, [WaveGrad: Estimating Gradients for Waveform Generation](https://arxiv.org/abs/2009.00713)\n- Ho *et al.*, [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)\n- Shen *et al.*, [Non-Attentive Tacotron: Robust and Controllable Neural TTS Synthesis Including Unsupervised Duration Modeling](https://arxiv.org/abs/2010.04301)\n\nThis implementation uses code from following repositories:\n- [J.Ho's Official DDPM Implementation](https://github.com/hojonathanho/diffusion)\n- [lucidrains' DDPM Pytorch Implementation](https://github.com/lucidrains/denoising-diffusion-pytorch)\n- [ivanvovk's WaveGrad Pytorch Implementation](https://github.com/ivanvovk/WaveGrad)\n- [lmnt-com's DiffWave Pytorch Implementation](https://github.com/lmnt-com/diffwave)\n- [ming024's FastSpeech2 Pytorch Implementation](https://github.com/ming024/FastSpeech2)\n- [yanggeng1995's EATS Pytorch Implementation](https://github.com/yanggeng1995/EATS)\n- [Kyubyoung's g2p\\_en](https://github.com/Kyubyong/g2p)\n- [mindslab's NU-Wave](https://github.com/mindslab-ai/nuwave)\n- [Keith Ito's Tacotron implementation](https://github.com/keithito/tacotron)\n- [NVIDIA's Tacotron2 implementation](https://github.com/NVIDIA/tacotron2)\n\nThe webpage for the audio samples uses a template from:\n- [WaveGrad2 Official Github.io](https://wavegrad.github.io/v2/)\n\nThe audio samples on our webpage are partially derived from:\n- [LJSpeech](https://keithito.com/LJ-Speech-Dataset/): a single-speaker English dataset consists of 13100 short audio clips of a female speaker reading passages from 7 non-fiction books, approximately 24 hours in total.\n- [WaveGrad2 Official Github.io](https://wavegrad.github.io/v2/)\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "./montreal-forced-aligner/bin/mfa_align raw_data/LJSpeech/ lexicon/librispeech-lexicon.txt english preprocessed_data/LJSpeech \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "./montreal-forced-aligner/bin/mfa_train_and_align raw_data/LJSpeech/ lexicon/librispeech-lexicon.txt preprocessed_data/LJSpeech \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    end: 100000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "  is_large: True #:if False, Base \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8029948720864918
      ],
      "excerpt": "  - e.g. https://github.com/ivanvovk/WaveGrad/issues/24#issue-943985027 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8957010020063867,
        0.8957010020063867
      ],
      "excerpt": "- Seungu Han at MINDs Lab hansw0326@mindslab.ai \n- Junhyeok Lee at MINDs Lab jun3518@mindslab.ai \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mindslab-ai/wavegrad2",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-09T09:28:57Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-17T11:33:51Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9187024160395943
      ],
      "excerpt": "Unofficial PyTorch+Lightning Implementation of Chen et al.(JHU, Google Brain), WaveGrad2.<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9370667008254513
      ],
      "excerpt": "Update: Enjoy our pre-trained model with Google Colab notebook! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8252770895694371
      ],
      "excerpt": "[x] Checkpoint release for Base \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8484748298040976
      ],
      "excerpt": "[x] Checkpoint release for Large \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8605590358331859
      ],
      "excerpt": "The supported datasets are \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9615477898664626
      ],
      "excerpt": "Montreal Forced Aligner (MFA) is used to obtain the alignments between the utterances and the phoneme sequences. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9481451303309563
      ],
      "excerpt": "We provide a Jupyter Notebook script to provide the code for inference and show some visualizations with resulting audio. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9502304824743231
      ],
      "excerpt": "Note: it could be different with google's implementation since number of parameters are different with paper's value.<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8551695483358855,
        0.9394449182630016
      ],
      "excerpt": "  dilations: [[1,2,4,8],[1,2,4,8],[1,2,4,8],[1,2,4,8],[1,2,4,8]] #:dilations for Large \n  #:dilations: [[1,2,4,8],[1,2,4,8],[1,2,4,8],[1,2,1,2],[1,2,1,2]] dilations for Base \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9012634672677422
      ],
      "excerpt": "Since this repo is unofficial implementation and WaveGrad2 paper do not provide several details, a slight differences between paper could exist. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8983225551179064,
        0.9821516868978656,
        0.8493577158582656
      ],
      "excerpt": "- Normal LSTM without ZoneOut is applied for encoder.  \n- g2p_en is applied instead of Google's unknown G2P. \n- Trained with LJSpeech datasdet instead of Google's proprietary dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8564395326704102
      ],
      "excerpt": "- WaveGrad-Large decoder's architecture could be different with Google's implementation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "\u251c\u2500\u2500 model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9139286346403551
      ],
      "excerpt": "This code is implemented by \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "Special thanks to  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Unofficial Pytorch Implementation of WaveGrad2",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mindslab-ai/wavegrad2/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Wed, 29 Dec 2021 04:42:36 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mindslab-ai/wavegrad2/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "mindslab-ai/wavegrad2",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/mindslab-ai/wavegrad2/main/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/mindslab-ai/wavegrad2/tree/main/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/mindslab-ai/wavegrad2/main/inference.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8057675898656085
      ],
      "excerpt": "  corpus_path: '/DATA1/LJSpeech-1.1' #: LJSpeech corpus path \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9039733694903622
      ],
      "excerpt": "Alternately, you can align the corpus by yourself.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8048244288410975
      ],
      "excerpt": "  batch_size: 12 #: Dependent on GPU memory size \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8190745789339001
      ],
      "excerpt": "  num_workers: 16 #: Dependent on CPU cores \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8689064836387151
      ],
      "excerpt": "    required = False, help = \"Start from ema checkpoint\") \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8136055429559771
      ],
      "excerpt": "- AISHELL-3: a Mandarin TTS dataset with 218 male and female speakers, roughly 85 hours in total. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8545689925263742
      ],
      "excerpt": "run prepare_align.py for some preparations.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9144740148503889
      ],
      "excerpt": "python prepare_align.py -c preprocess.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9144740148503889
      ],
      "excerpt": "python preprocess.py -c preprocess.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8947796391075787
      ],
      "excerpt": "And then run preprocess.py. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9144740148503889,
        0.8560023500220517
      ],
      "excerpt": "python preprocess.py -c preprocess.yaml \nAdjust hparameter.yaml, especially train section. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8478776640842458
      ],
      "excerpt": "If you want to train with other dataset, adjust data section in hparameter.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8089667694908923
      ],
      "excerpt": "  train_meta: 'train.txt'  #: relative path of metadata file from train_dir \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8736670543853119
      ],
      "excerpt": "run trainer.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8510822795984749
      ],
      "excerpt": "python trainer.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8299951442553173
      ],
      "excerpt": "    required = False, help = \"Resume Checkpoint epoch number\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8038134290621377
      ],
      "excerpt": "    required = False, help = \"Start from ema checkpoint\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8252092804337223
      ],
      "excerpt": "run inference.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8246932800011934
      ],
      "excerpt": "  - train.adam.lr: 3e-4 and train.adam.weight_decay: 1e-6 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8555976728427789
      ],
      "excerpt": "  - train.loss_rate: 1 as total_loss = 1 * L1_loss + 1 * duration_loss \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "\u251c\u2500\u2500 dataloader.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "\u251c\u2500\u2500 lightning_model.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 downsampling.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 gaussian_upsampling.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8509882522201616,
        0.9336801098518991,
        0.9336801098518991,
        0.9336801098518991,
        0.8033161956936304,
        0.845584264996502,
        0.9336801098518991,
        0.9336801098518991
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 layers.py \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 linear_modulation.py \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 nn.py \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 resampling.py \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 upsampling.py \n\u2502\u00a0\u00a0 \u2514\u2500\u2500 window.py \n\u251c\u2500\u2500 prepare_align.py \n\u251c\u2500\u2500 preprocess.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9336801098518991,
        0.8359299706379749,
        0.9336801098518991,
        0.9336801098518991,
        0.9336801098518991,
        0.9156243655062436,
        0.8280243174265178,
        0.828520898273279,
        0.8924976426181745,
        0.9336801098518991,
        0.9336801098518991,
        0.9336801098518991,
        0.9586232994076559
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 ljspeech.py \n\u2502\u00a0\u00a0 \u2514\u2500\u2500 preprocessor.py \n\u251c\u2500\u2500 text \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cleaners.py \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cmudict.py \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 numbers.py \n\u2502\u00a0\u00a0 \u2514\u2500\u2500 symbols.py \n\u251c\u2500\u2500 trainer.py \n\u251c\u2500\u2500 utils \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 mel.py \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 stft.py \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 tblogger.py \n\u2502\u00a0\u00a0 \u2514\u2500\u2500 utils.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mindslab-ai/wavegrad2/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\n\\nCopyright (c) 2021, MINDs Lab\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n3. Neither the name of the copyright holder nor the names of its\\n   contributors may be used to endorse or promote products derived from\\n   this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "WaveGrad 2 &mdash; Unofficial PyTorch Implementation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "wavegrad2",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "mindslab-ai",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mindslab-ai/wavegrad2/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [Pytorch](https://pytorch.org/) \n- [Pytorch-Lightning](https://github.com/PyTorchLightning/pytorch-lightning)==1.2.10\n- The requirements are highlighted in [requirements.txt](./requirements.txt).<br>\n- We also provide docker setup [Dockerfile](./Dockerfile).<br>\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 83,
      "date": "Wed, 29 Dec 2021 04:42:36 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "text-to-speech",
      "tts",
      "speech-synthesis",
      "deep-generative-model",
      "end-to-end"
    ],
    "technique": "GitHub API"
  }
}
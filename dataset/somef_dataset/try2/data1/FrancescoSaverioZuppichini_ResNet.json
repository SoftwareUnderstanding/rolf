{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1512.03385"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "conv = conv3x3(in_channels=32, out_channels=64) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8187756947909643,
        0.8977365023903343
      ],
      "excerpt": "    residual = x \n    if self.should_apply_shortcut: residual = self.shortcut(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8187756947909643
      ],
      "excerpt": "    x += residual \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "ResidualBlock(32, 64) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8043073075947367
      ],
      "excerpt": "    })) if self.should_apply_shortcut else None \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "ResNetResidualBlock(32, 64) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "    (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "      (conv): Conv2dAuto(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "    (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9904682582335301
      ],
      "excerpt": "dummy = torch.ones((1, 32, 10, 10)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "      (conv): Conv2dAuto(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "        downsampling = 2 if in_channels != out_channels else 1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9218387569487573,
        0.8109194328925066,
        0.8654671031158477
      ],
      "excerpt": "       Conv2dAuto-10           [-1, 64, 56, 56]          36,864 \n      BatchNorm2d-11           [-1, 64, 56, 56]             128 \n             ReLU-12           [-1, 64, 56, 56]               0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "             ReLU-18           [-1, 64, 56, 56]               0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066,
        0.8654671031158477
      ],
      "excerpt": "      BatchNorm2d-29           [-1, 64, 56, 56]             128 \n             ReLU-30           [-1, 64, 56, 56]               0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278824608274014
      ],
      "excerpt": "       Conv2dAuto-37          [-1, 128, 56, 56]          32,768 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9218387569487573
      ],
      "excerpt": "             ReLU-10           [-1, 64, 56, 56]               0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "      BatchNorm2d-12          [-1, 256, 56, 56]             512 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "      BatchNorm2d-18           [-1, 64, 56, 56]             128 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066,
        0.8654671031158477
      ],
      "excerpt": "             ReLU-29           [-1, 64, 56, 56]               0 \n           Conv2d-30           [-1, 64, 56, 56]          36,864 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "             ReLU-32           [-1, 64, 56, 56]               0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278824608274014
      ],
      "excerpt": "           Conv2d-37          [-1, 128, 56, 56]          32,768 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/FrancescoSaverioZuppichini/ResNet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-02-22T13:21:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-12T21:04:35Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8086038638659914,
        0.859513051376032,
        0.9612600904397792,
        0.8174267440838617,
        0.9605112184059422,
        0.9082935207186706
      ],
      "excerpt": "Today we are going to implement the famous ResNet from Kaiming He et al. (Microsoft Research). It won the 1st place on the ILSVRC 2015 classification task. \nThe original paper can be read from here  and it is very easy to follow, additional material can be found in this quora answer \nDeeper neural networks are more difficult to train. Why? One big problem of deeper network is the vanishing gradient. Basically, the model is not able to learn anymore. \nTo solve this problem, the Authors proposed to use a reference to the previous layer to compute the output at a given layer. In ResNet, the output form the previous layer, called residual, is added to the output of the current layer. The following picture visualizes this operation \nWe are going to make our implementation as scalable as possible using one think think unknown to mostly of the data scientiest: object orienting programming \nOkay, the first thing is to think about what we need. Well, first of all we need a convolution layer and since PyTorch does not have the 'auto' padding in Conv2d, so we have to code ourself! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9926683827430285
      ],
      "excerpt": "To make clean code is mandatory to think about the main building block of each application, or of the network in our case. The residual block takes an input with in_channels, applies some blocks of convolutional layers to reduce it to out_channels and sum it up to the original input. If their sizes mismatch, then the input goes into an identity. We can abstract this process and create a interface that can be extedend. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9346754219347561
      ],
      "excerpt": "In ResNet each block has a expansion parameter in order to increase the out_channels. Also, the identity is defined as a Convolution followed by an Activation layer, this is referred as shortcut. Then, we can just extend ResidualBlock and defined the shortcut function. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.874247550953166
      ],
      "excerpt": "A basic ResNet block is composed by two layers of 3x3 convs/batchnorm/relu. In the picture, the lines represnet the residual operation. The dotted line means that the shortcut was applied to match the input and the output dimension. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9736857265029789
      ],
      "excerpt": "To increase the network deepths but to decrese the number of parameters, the Authors defined a BottleNeck block that  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.853228538483409
      ],
      "excerpt": "We can easily defined it by just stuck n blocks one after the other, just remember that the first convolution block has a stide of two since \"We perform downsampling directly by convolutional layers that have a stride of 2\". \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8034906623085181
      ],
      "excerpt": "        #: 'We perform downsampling directly by convolutional layers that have a stride of 2.' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8614406946258639
      ],
      "excerpt": "Similarly, the encoder is composed by multiple layer at increasing features size. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8051419082246902
      ],
      "excerpt": "          for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]        \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9860436972181008
      ],
      "excerpt": "The decoder is the last piece we need to create the full network. It is a fully connected layer that maps the features learned by the network to their respective classes. Easily, we can defined it as: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8647594346051957
      ],
      "excerpt": "    This class represents the tail of ResNet. It performs a global pooling and maps the output to the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8503430564653977
      ],
      "excerpt": "Final, we can put all the pieces together and create the final model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8525257567016801
      ],
      "excerpt": "We can now defined the five models proposed by the Authors, resnet18,34,50,101,152 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "model = resnet101(3, 1000) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Clean, scalable and easy to use ResNet implementation in Pytorch",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/FrancescoSaverioZuppichini/ResNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 40,
      "date": "Mon, 27 Dec 2021 10:01:36 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/FrancescoSaverioZuppichini/ResNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "FrancescoSaverioZuppichini/ResNet",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/FrancescoSaverioZuppichini/ResNet/master/ResNet.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8851567038949967
      ],
      "excerpt": "Let's test it with a dummy vector with one one, we should get a vector with two \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8791175621392118
      ],
      "excerpt": "from collections import OrderedDict \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8453821665518155
      ],
      "excerpt": "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8495868209909367
      ],
      "excerpt": "Let's first create an handy function to stack one conv and batchnorm layer. Using OrderedDict to properly name each sublayer. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8791175621392118
      ],
      "excerpt": "from collections import OrderedDict \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8382423390025753
      ],
      "excerpt": "  (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8453821665518155
      ],
      "excerpt": "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8453821665518155
      ],
      "excerpt": "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8453821665518155
      ],
      "excerpt": "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8453821665518155
      ],
      "excerpt": "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8453821665518155
      ],
      "excerpt": "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8338233508567103
      ],
      "excerpt": "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8338233508567103
      ],
      "excerpt": "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8185966757630769
      ],
      "excerpt": ": layer(dummy).shape \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8253039443647691,
        0.8669123635012759
      ],
      "excerpt": "          (conv): Conv2dAuto(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) \n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8144853130267888,
        0.8669123635012759
      ],
      "excerpt": "          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8253039443647691,
        0.8669123635012759
      ],
      "excerpt": "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) \n        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8144853130267888,
        0.8669123635012759
      ],
      "excerpt": "          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8144853130267888,
        0.8669123635012759
      ],
      "excerpt": "          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8144853130267888,
        0.8669123635012759
      ],
      "excerpt": "          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8144853130267888,
        0.8669123635012759
      ],
      "excerpt": "          (conv): Conv2dAuto(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from torchsummary import summary \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.906614234580968
      ],
      "excerpt": "        Layer (type)               Output Shape         Param # \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8934745846565956
      ],
      "excerpt": "Total params: 44,549,160 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8337602022600056
      ],
      "excerpt": "Params size (MB): 169.94 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8762729030460817
      ],
      "excerpt": "import torchvision.models as models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.906614234580968
      ],
      "excerpt": "        Layer (type)               Output Shape         Param # \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8934745846565956
      ],
      "excerpt": "Total params: 44,549,160 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8337602022600056,
        0.8253198209235613
      ],
      "excerpt": "Params size (MB): 169.94 \nEstimated Total Size (MB): 600.25 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/FrancescoSaverioZuppichini/ResNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 FrancescoSaverioZuppichini\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Implementing ResNet in PyTorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ResNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "FrancescoSaverioZuppichini",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/FrancescoSaverioZuppichini/ResNet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 116,
      "date": "Mon, 27 Dec 2021 10:01:36 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "python3",
      "deep-learning",
      "neural-networks",
      "convolutional-neural-networks",
      "pytorch"
    ],
    "technique": "GitHub API"
  }
}
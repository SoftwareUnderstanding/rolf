{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2011.06294",
      "https://arxiv.org/abs/2011.06294"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Optical Flow:\n[ARFlow](https://github.com/lliuz/ARFlow)  [pytorch-liteflownet](https://github.com/sniklaus/pytorch-liteflownet)  [RAFT](https://github.com/princeton-vl/RAFT)  [pytorch-PWCNet](https://github.com/sniklaus/pytorch-pwc)\n\nVideo Interpolation: \n[DVF](https://github.com/lxx1991/pytorch-voxel-flow)  [TOflow](https://github.com/Coldog2333/pytoflow)  [SepConv](https://github.com/sniklaus/sepconv-slomo)  [DAIN](https://github.com/baowenbo/DAIN)  [CAIN](https://github.com/myungsub/CAIN)  [MEMC-Net](https://github.com/baowenbo/MEMC-Net)   [SoftSplat](https://github.com/sniklaus/softmax-splatting)  [BMBC](https://github.com/JunHeum/BMBC)  [EDSC](https://github.com/Xianhang/EDSC-pytorch)  [EQVI](https://github.com/lyh-18/EQVI)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@article{huang2020rife,\n  title={RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation},\n  author={Huang, Zhewei and Zhang, Tianyuan and Heng, Wen and Shi, Boxin and Zhou, Shuchang},\n  journal={arXiv preprint arXiv:2011.06294},\n  year={2020}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{huang2020rife,\n  title={RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation},\n  author={Huang, Zhewei and Zhang, Tianyuan and Heng, Wen and Shi, Boxin and Zhou, Shuchang},\n  journal={arXiv preprint arXiv:2011.06294},\n  year={2020}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hzwer/arXiv2020-RIFE",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-12T05:46:23Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-28T05:46:11Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This project is the implement of [RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation](https://arxiv.org/abs/2011.06294). Currently, our model can run 30+FPS for 2X 720p interpolation on a 2080Ti GPU. It supports arbitrary-timestep interpolation between a pair of images. \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9936127588759495
      ],
      "excerpt": "We are not responsible for and participating in the development of above software. According to the open source license, we respect the commercial behavior of other developers. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.952590717072778
      ],
      "excerpt": "If you are a developer, welcome to follow Practical-RIFE, which aims to make RIFE more practical for users by adding various features and design new models with faster speed. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8390671765035873
      ],
      "excerpt": "Many thanks to Grisk. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hzwer/Arxiv2020-RIFE/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 233,
      "date": "Tue, 28 Dec 2021 11:33:29 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hzwer/arXiv2020-RIFE/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "hzwer/arXiv2020-RIFE",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/hzwer/Arxiv2020-RIFE/main/docker/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/hzwer/Arxiv2020-RIFE/main/Colab_demo.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\ngit clone git@github.com:hzwer/arXiv2020-RIFE.git\ncd arXiv2020-RIFE\npip3 install -r requirements.txt\n```\n\n* Download the pretrained **HD** models from [here](https://drive.google.com/file/d/1APIzVeI-4ZZCEuIRE1m6WYfSCaOsi_7_/view?usp=sharing). (\u767e\u5ea6\u7f51\u76d8\u94fe\u63a5:https://pan.baidu.com/share/init?surl=u6Q7-i4Hu4Vx9_5BJibPPA \u5bc6\u7801:hfk3\uff0c\u628a\u538b\u7f29\u5305\u89e3\u5f00\u540e\u653e\u5728 train_log/\\*)\n\n* Unzip and move the pretrained parameters to train_log/\\*\n\n* This model is not reported by our paper, for our paper model please refer to [evaluation](https://github.com/hzwer/arXiv2020-RIFE#evaluation).\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.807731226678929
      ],
      "excerpt": "Vimeo90K: Download Vimeo90K dataset at ./vimeo_interp_test \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8111595454892884
      ],
      "excerpt": "python3 benchmark/UCF101.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8313694566114332
      ],
      "excerpt": "python3 benchmark/Vimeo90K.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8313694566114332
      ],
      "excerpt": "python3 benchmark/MiddleBury_Other.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8313694566114332
      ],
      "excerpt": "python3 benchmark/HD.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8313694566114332,
        0.8463371876059486
      ],
      "excerpt": "python3 benchmark/HD_multi_4X.py \n: \"PSNR: 22.96(544*1280), 31.87(720p), 34.25(1080p)\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8447634792014815
      ],
      "excerpt": "Download Vimeo90K dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8000624046546174
      ],
      "excerpt": "python3 -m torch.distributed.launch --nproc_per_node=4 train.py --world_size=4 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hzwer/arXiv2020-RIFE/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook",
      "Dockerfile",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 hzwer\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "RIFE - Real-Time Intermediate Flow Estimation for Video Frame Interpolation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "arXiv2020-RIFE",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "hzwer",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hzwer/arXiv2020-RIFE/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "hzwer",
        "body": "https://arxiv.org/abs/2011.06294v5",
        "dateCreated": "2021-06-28T07:33:21Z",
        "datePublished": "2021-08-13T03:31:01Z",
        "html_url": "https://github.com/hzwer/arXiv2020-RIFE/releases/tag/arxiv_v5_code",
        "name": "Archive the code for v5 and earlier arXiv preprints",
        "tag_name": "arxiv_v5_code",
        "tarball_url": "https://api.github.com/repos/hzwer/arXiv2020-RIFE/tarball/arxiv_v5_code",
        "url": "https://api.github.com/repos/hzwer/arXiv2020-RIFE/releases/47786617",
        "zipball_url": "https://api.github.com/repos/hzwer/arXiv2020-RIFE/zipball/arxiv_v5_code"
      }
    ],
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "**Video Frame Interpolation**\n\nYou can use our [demo video](https://drive.google.com/file/d/1i3xlKb7ax7Y70khcTcuePi6E7crO_dFc/view?usp=sharing) or your own video. \n```\npython3 inference_video.py --exp=1 --video=video.mp4 \n```\n(generate video_2X_xxfps.mp4)\n```\npython3 inference_video.py --exp=2 --video=video.mp4\n```\n(for 4X interpolation)\n```\npython3 inference_video.py --exp=1 --video=video.mp4 --scale=0.5\n```\n(If your video has very high resolution such as 4K, we recommend set --scale=0.5 (default 1.0). If you generate disordered pattern on your videos, try set --scale=2.0. This parameter control the process resolution for optical flow model.)\n```\npython3 inference_video.py --exp=2 --img=input/\n```\n(to read video from pngs, like input/0.png ... input/612.png, ensure that the png names are numbers)\n```\npython3 inference_video.py --exp=2 --video=video.mp4 --fps=60\n```\n(add slomo effect, the audio will be removed)\n```\npython3 inference_video.py --video=video.mp4 --montage --png\n```\n(if you want to montage the origin video and save the png format output)\n\n**Image Interpolation**\n\n```\npython3 inference_img.py --img img0.png img1.png --exp=4\n```\n(2^4=16X interpolation results)\nAfter that, you can use pngs to generate mp4:\n```\nffmpeg -r 10 -f image2 -i output/img%d.png -s 448x256 -c:v libx264 -pix_fmt yuv420p output/slomo.mp4 -q:v 0 -q:a 0\n```\nYou can also use pngs to generate gif:\n```\nffmpeg -r 10 -f image2 -i output/img%d.png -s 448x256 -vf \"split[s0][s1];[s0]palettegen=stats_mode=single[p];[s1][p]paletteuse=new=1\" output/slomo.gif\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Place the pre-trained models in `train_log/\\*.pkl` (as above)\n\nBuilding the container:\n```\ndocker build -t rife -f docker/Dockerfile .\n```\n\nRunning the container:\n```\ndocker run --rm -it -v $PWD:/host rife:latest inference_video --exp=1 --video=untitled.mp4 --output=untitled_rife.mp4\n```\n```\ndocker run --rm -it -v $PWD:/host rife:latest inference_img --img img0.png img1.png --exp=4\n```\n\nUsing gpu acceleration (requires proper gpu drivers for docker):\n```\ndocker run --rm -it --gpus all -v /dev/dri:/dev/dri -v $PWD:/host rife:latest inference_video --exp=1 --video=untitled.mp4 --output=untitled_rife.mp4\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2188,
      "date": "Tue, 28 Dec 2021 11:33:29 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "video-interpolation",
      "computer-vision",
      "slomo-filter",
      "deep-learning"
    ],
    "technique": "GitHub API"
  }
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Let your divine entity of choice bless:\n    - [Spijkervet](https://github.com/Spijkervet)\n        - [PyTorch Lightning Bolts](https://github.com/PyTorchLightning/pytorch-lightning-bolts)\n\nConsider citing the original paper if you found this useful:\n```\n@inproceedings{chen2020simple,\n  title={A simple framework for contrastive learning of visual representations},\n  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},\n  booktitle={International conference on machine learning},\n  pages={1597--1607},\n  year={2020},\n  organization={PMLR}\n}\n```\n",
      "technique": "Header extraction"
    }
  ],
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{chen2020simple,\n  title={A simple framework for contrastive learning of visual representations},\n  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},\n  booktitle={International conference on machine learning},\n  pages={1597--1607},\n  year={2020},\n  organization={PMLR}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rdbch/not_a_simclr",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-02-05T14:26:14Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-15T10:12:21Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "SimCLR is a framework of contrastive learning that was introduced by Ting Chen et. al. in [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/pdf/2002.05709v3.pdf) at ICML 2020(\ud83d\ude2e), that allows one to learn good representations form data without any express supervision. What does this mean? Think of fitting a CNN model on a completly new dataset, instead of training it from scratch, it is a very common practice to start with the weights trained on a learge and generalistic dataset, such as ImageNet (1000 classes with 1000 images/class). This speeds up the training process and helps one achieve better results, because the used encoder learned very good representations from data. However, when we don't have access to such a model, or when we want to train our model on a new dataset that has very few labeled samples we can use this method to obtain a similar effect.  In the image below, one can see that by using this method, one can acieve performances similar with supervised approaches. \n\n<p align=\"center\">\n    <img src=\"./assets/images/performance.png\" width=\"400\" height=\"400\" />\n</p>\n\nLong story short, this SimCLR is a \ud83c\udfc3\u200d\u2642\ufe0ftraining method\ud83c\udfc3\u200d\u2642\ufe0f that can be used to create a pretrained model for your custom dataset and not requiring any labels. It does this by maximizing the agreement between differently augmented views of the same image via a *contrastive loss* in the latent space. The produced network, can be further used to solve tasks, but keeping it would require some sorth of supervision. \n\n During training, this framework is composed of 4 main components (for each component, more information will be presented in the **Task** section below): \n\n<p align=\"center\">\n    <img src=\"./assets/images/architecture.png\" width=\"400\" height=\"450\" />\n</p>\n\n\n1. **Image augmentation :** Module responsible with generating two correlated views of the same example. \n2. **Encoder:** An image encoder (CNN) that is used to extract latent representation vectors from the augmented samples . \n3. **Projection Head:** A small neural network, with a few linear units, that is used to map the latent space of the encoder output to another latent space where contrastive loss can be applied. \n4. **Contrastive Loss Function:** Given a set of examples including a positive(simialr) pair of examples, the contrastive prediction task has to identify them.\n5. **The training itself**\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9359104226342994
      ],
      "excerpt": "A simplified tutorial for A Simple Framework for Contrastive Learning of Visual Representations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9303722453061269
      ],
      "excerpt": "For this tutorial, a starter project was developed, such that it will allow one to only focus on important aspects. Besides this, if everything is done correctly, one will be able to see the latent space representation in Tensorboard. Because we do not have access to a vaste amount of computing resources, we will use the CIFAR10 dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8619843389870402
      ],
      "excerpt": "The module should be a callable object that takes as parameter an image and returns 2 augmented versions of it. The Resize, ToTensor and Normalize operations are common for both augmentations transforms. One can use the transformations provided by Torchvision or Abumentations \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567555490201691,
        0.8202166450755758,
        0.8144374624860599
      ],
      "excerpt": "Check page 12 of the original paper for more details - arxiv \nOfficial implementation (Tensorflow) - GitHub  \nUn-official implementation (PyTorch) - GitHub - do not cheat \ud83d\ude11 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9700862451565253,
        0.9707322282581051
      ],
      "excerpt": "For this part, because it would be beyond the purpose of this tutorial to implement from scratch an encoder such as ResNet, one will only have to configure such a network to produce the desired outputs. For this, one will have to modify the core/nn/networks/simclr.py, where the SimCLR class is deffinied.  \nFor this task, one will have to work in the .build() method, where a Resnet model should be defined. This model should take as input a color image [B, C, H, W] and output a latent representation h extracted from this [B, H_LATENT] (where H_LATENT is the size of the latent representation).  The output of this model wil be fed to the project funciton.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9757515559149634
      ],
      "excerpt": "This is the high level view of the model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8686640735790999
      ],
      "excerpt": "    self.project = [...] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8686640735790999
      ],
      "excerpt": "    z = self.project(h) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.860059181823877
      ],
      "excerpt": "h1, _ = model(firstAugImage) \nh2, _ = model(secondAugImage) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8658420792470849
      ],
      "excerpt": "This is encoder definition in the .build() method. By answering to this question, it will be way easier.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9418527797873709,
        0.8885829420574095
      ],
      "excerpt": "    outChNo     = self.latentChNo,     #: int       : Check and see the paper for latent size \ud83d\ude09 \n    norm        = self.norm,           #: str *     : We all know that BatchNorm helps, but what about GroupNorm?\ud83d\ude1d \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9643092528653179
      ],
      "excerpt": "    activ       = self.activ,          #: str *     : Well, which is our favourite nonlinearity? \ud83e\udd14 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8141863803033241,
        0.8454227305532347
      ],
      "excerpt": "    strides     = self.encoderStrides, #: list[int] : A list of 6 ints, where an element represents the stride at each step in ResNet \n    downType    = 'maxpool',           #: str       : Ho do we reduce spatial dims? ['maxpool', 'avgpool' or 'conv']  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8202166450755758,
        0.8763156397809418,
        0.8448910005040771,
        0.8984686034810202,
        0.9188856777366139
      ],
      "excerpt": "Official Tensorflow implementation GitHub \nUn-official Pytorch implementation  1 GitHub[model],  GitHub[init],  \nUn-official Pytorch implementation  2 GitHub \nFor this part, one will define a projection function by using the the MLP class and add it to the same SimCLR class. For this, one will have to modify the same core/nn/networks/simclr.py. The projection module should take as input a latent reprezentation h [B, H_LATENT] and project to a smaller latent space z  [B, Z] where the contrastive loss will be applied. \nThe initialization process is similar with the one described at the previous module. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.860059181823877
      ],
      "excerpt": ", z2 = model(firstAugImage) \n, z2 = model(secondAugImage) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.880672894902933
      ],
      "excerpt": "This is projection function definition in the .build() method. By answering to this question, it will be way easier to configure it.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9776618694844216
      ],
      "excerpt": "    outChNo         = self.outChNo,      #: int       : Check and see the paper for latent size [rule of thumb dim(Z)<dim(H)] \ud83d\ude09 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8241528640555276
      ],
      "excerpt": "    norm            = None,              #: str *     : We all know that BatchNorm helps, but not here, so no normalization\ud83d\ude1d \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9643092528653179
      ],
      "excerpt": "    activ           = self.activ,        #: str *     : Well, which is our favourite nonlinearity? \ud83e\udd14 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8163305539783035
      ],
      "excerpt": "    dropLayers      = dropLayers,        #: int       : Apply dropout on this last no of layers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8202166450755758,
        0.9161603257810326,
        0.8448910005040771,
        0.972647914891159
      ],
      "excerpt": "Official Tensorflow implementation GitHub \nUn-official Pytorch implementation 1 GitHub[model] \nUn-official PyTorch implementation 2 GitHub \nFor this task, one should implement the contrastive loss function described in the paper. Firstly please look at the subsection 2.1 Method of the paper. Below it is cited the most relevant portion of it. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8509966938535497
      ],
      "excerpt": "Let $\\mathrm{sim}(u,v) = u^\\top v / \\lVert u\\rVert \\lVert v\\rVert$ denote the dot product between $\\ell_2$ normalized $u$ and $v$ (i.e. cosine similarity). Then the loss function for a positive pair of examples $(i, j)$ is defined as \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9391310397224133
      ],
      "excerpt": "where ${k \\neq i} \\in { 0,  1}$ is an indicator function evaluating to $1$ iff $k \\neq i$ and $\\tau$ denotes a temperature parameter. The final loss is computed across all positive pairs, both $(i, j)$ and $(j, i)$, in a mini-batch. [...] We term it NT-Xent (the normalized temperature-scaled cross entropy loss). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "hB, zB = model(augImageB) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8202166450755758,
        0.8448910005040771
      ],
      "excerpt": "Official Tensorflow implementation      GitHub \nUn-official PyTorch implementation 1  GitHub \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8728057489583144
      ],
      "excerpt": "train/trainer.py - where all the modules required for training are initialized such as data, networks, losses, etc, and where the training logic is implemented optimiz_ parameters() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8720274184860525
      ],
      "excerpt": "The results will also be visible in Tensorboard. For this, the common logDir is assets/logs  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.974728659727783
      ],
      "excerpt": "The dataset of choice is CIFAR10. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9669395401589798
      ],
      "excerpt": "And these are some intermediary results obtained with t-SNE: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A simple PyTorch tutorial for helping one implement the SimCLR framework.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rdbch/tutorial_simclr/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 02:47:00 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/rdbch/not_a_simclr/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "rdbch/not_a_simclr",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.890662556153636
      ],
      "excerpt": "If CUDA 10.2 is compatible with your device, you can simply create your environment with  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9952708442871605
      ],
      "excerpt": "If one does not use Conda, you can manually install PyTorch from this link and get your other requirements by running: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9954427483597357
      ],
      "excerpt": "$ pip install -r req_pip.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9096104964140866,
        0.960949091439427
      ],
      "excerpt": "    ).build() \n: * Name taken from PyTorch (ex: BatchNorm2d, GroupNorm2d, ReLU, Tanh, etc) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9096104964140866,
        0.960949091439427
      ],
      "excerpt": "    ).build() \n: * Name taken from PyTorch (ex: BatchNorm2d, GroupNorm2d, ReLU, Tanh, etc) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8934347377147135
      ],
      "excerpt": "Sample usage: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8934347377147135
      ],
      "excerpt": "Sample usage: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8016038000533272
      ],
      "excerpt": "model = SimCLR(cfg) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8627015506845328
      ],
      "excerpt": "    archType    = self.archType,       #: str       : ResNet architecture ['18','34']. For ResNet18, 1 epoch ~ 1 min (total 100 epochs) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8934347377147135
      ],
      "excerpt": "Sample usage: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8016038000533272
      ],
      "excerpt": "model = SimCLR(cfg) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8934347377147135
      ],
      "excerpt": "Sample usage \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9239527797730154
      ],
      "excerpt": "train/main.py - script that starts the training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8168423292174,
        0.8407651001510851
      ],
      "excerpt": "train/config.py - where a skeleton for allowed configurations is. This is file only provides some default, and usually, for each experiment, one will have to merge it with an .yaml file \nStart training: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.951055635172533
      ],
      "excerpt": "$ python train/main.py -l assets/experiments/base_simclr.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9194372255344301
      ],
      "excerpt": "    <img src=\"./assets/images/results.png\" width=\"700\" height=\"450\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9227741113294464
      ],
      "excerpt": "    <img src=\"./assets/images/tsne.png\" width=\"700\" height=\"400\" /> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/rdbch/not_a_simclr/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Radu Beche\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SimCLR",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "not_a_simclr",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "rdbch",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rdbch/not_a_simclr/blob/solution/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Wed, 29 Dec 2021 02:47:00 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "contrastive-learning",
      "neural-network",
      "tutorial",
      "exercise",
      "loss"
    ],
    "technique": "GitHub API"
  }
}
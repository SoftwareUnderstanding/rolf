{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2010.15327",
      "https://arxiv.org/abs/2103.14030",
      "https://arxiv.org/abs/2108.08810"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use this repo in your project or research, please cite as  -\n\n```\n@software{subramanian2021torch_cka,\n    author={Anand Subramanian},\n    title={torch_cka},\n    url={https://github.com/AntixK/PyTorch-Model-Compare},\n    year={2021}\n}\n```\n\n\n\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@software{subramanian2021torch_cka,\n    author={Anand Subramanian},\n    title={torch_cka},\n    url={https://github.com/AntixK/PyTorch-Model-Compare},\n    year={2021}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AntixK/PyTorch-Model-Compare",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-11T14:14:42Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T13:40:12Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9873756251574501,
        0.987797101001249
      ],
      "excerpt": "A tiny package to compare two neural networks in PyTorch. There are many ways to compare two neural networks, but one robust and scalable way is using the Centered Kernel Alignment (CKA) metric, where the features of the networks are compared. \nCentered Kernel Alignment (CKA) is a representation similarity metric that is widely used for understanding the representations learned by neural networks. Specifically, CKA takes two feature maps / representations X and Y as input and computes their normalized similarity (in terms of the Hilbert-Schmidt Independence Criterion (HSIC)) as \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9081055450882364,
        0.9650509706603974,
        0.9673321270553327,
        0.9914352477935575,
        0.9883809189319944,
        0.9660799504366078,
        0.8468157915389095,
        0.9343504042310808,
        0.9464320983567546,
        0.9776760684136674,
        0.9942393062674634,
        0.9577651675265136
      ],
      "excerpt": "Where K and L are similarity matrices of X and Y respectively. \nHowever, the above formula is not scalable against deep architectures and large datasets. Therefore, a minibatch version can be constructed that uses an unbiased estimator of the HSIC as \nThe above form of CKA is from the 2021 ICLR paper by Nguyen T., Raghu M, Kornblith S. \nA simple experiment is to analyse the features learned by two architectures of the same family - ResNets but of different depths. Taking two ResNets - ResNet18 and ResNet34 - pre-trained on the Imagenet dataset, we can analyse how they produce their features on, say CIFAR10 for simplicity. This comparison is shown as a heatmap below.  \nWe see high degree of similarity between the two models in lower layers as they both learn similar representations from the data. However at higher layers, the similarity reduces as the deeper model (ResNet34) learn higher order features which the is elusive to the shallower model (ResNet18). Yet, they do indeed have certain similarity in their last fc layer which acts as the feature classifier. \nAnother way of using CKA is in ablation studies. We can go further than those ablation studies that only focus on resultant performance and employ CKA to study the internal representations. Case in point - ResNet50 and WideResNet50 (k=2). WideResNet50 has the same architecture as ResNet50 except having wider residual bottleneck layers (by a factor of 2 in this case). \nWe clearly notice that the learned features are indeed different after the first few layers. The width has a more pronounced effect in deeper layers as compared to the earlier layers as both networks seem to learn similar features in the initial layers.  \nAs a bonus, here is a comparison between ViT and the latest SOTA model Swin Transformer pretrained on ImageNet22k. \nCNNs have been analysed a lot over the past decade since AlexNet. We somewhat know what sort of features they learn across their layers (through visualizations) and we have put them to good use. One interesting approach is to compare these understandable features with newer models that don't permit easy visualizations (like recent vision transformer architectures) and study them. This has indeed been a hot research topic (see Raghu et.al 2021). \nYet another application is to compare two datasets - preferably two versions of the data. This is especially useful in production where data drift is a known issue. If you have an updated version of a dataset, you can study how your model will perform on it by comparing the representations of the datasets. This can be more telling about actual performance than simply comparing the datasets directly.  \nThis can also be quite useful in studying the performance of a model on downstream tasks and fine-tuning. For instance, if the CKA score is high for some features on different datasets, then those can be frozen during fine-tuning. As an example, the following figure compares the features of a pretrained Resnet50 on the Imagenet test data and the VOC dataset. Clearly, the pretrained features have little correlation with the VOC dataset. Therefore, we have to resort to fine-tuning to get at least satisfactory results. \nIf your model is large (lots of layers or large feature maps), try to extract from select layers. This is to avoid out of memory issues.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9422439417352346,
        0.9736812845327365
      ],
      "excerpt": "Give proper model names to avoid confusion when interpreting the results. The code automatically extracts the model name for you by default, but it is good practice to label the models according to your use case. \nWhen providing your dataloader(s) to the compare() function, it is important that they are seeded properly for reproducibility.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Compare neural networks by their feature similarity",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AntixK/PyTorch-Model-Compare/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Thu, 23 Dec 2021 19:19:35 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/AntixK/PyTorch-Model-Compare/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "AntixK/PyTorch-Model-Compare",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npip install torch_cka\n```\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8312291907017765
      ],
      "excerpt": "<img src=\"assets/cka.png\" alt=\"CKA original version\" width=\"60%\" style=\"display: block; margin-left: auto; margin-right: auto;\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/AntixK/PyTorch-Model-Compare/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'\\nThe MIT License (MIT)\\n\\nCopyright (c) 2021 Anand\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "PyTorch Model Compare",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "PyTorch-Model-Compare",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "AntixK",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AntixK/PyTorch-Model-Compare/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 80,
      "date": "Thu, 23 Dec 2021 19:19:35 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "deep-learning",
      "neural-networks",
      "cka",
      "transformers",
      "imagenet",
      "feature-extraction",
      "pip",
      "torch-cka"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\nfrom torch_cka import CKA\nmodel1 = resnet18(pretrained=True)  #: Or any neural network of your choice\nmodel2 = resnet34(pretrained=True)\n\ndataloader = DataLoader(your_dataset, \n                        batch_size=batch_size, #: according to your device memory\n                        shuffle=False)  #: Don't forget to seed your dataloader\n\ncka = CKA(model1, model2,\n          model1_name=\"ResNet18\",   #: good idea to provide names to avoid confusion\n          model2_name=\"ResNet34\",   \n          model1_layers=layer_names_resnet18, #: List of layers to extract features from\n          model2_layers=layer_names_resnet34, #: extracts all layer features by default\n          device='cuda')\n\ncka.compare(dataloader) #: secondary dataloader is optional\n\nresults = cka.export()  #: returns a dict that contains model names, layer names\n                        #: and the CKA matrix\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "`torch_cka` can be used with any pytorch model (subclass of `nn.Module`) and can be used with pretrained models available from popular sources like torchHub, timm, huggingface etc. Some examples of where this package can come in handy are illustrated below.\n\n",
      "technique": "Header extraction"
    }
  ]
}
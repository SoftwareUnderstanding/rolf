{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1409.0473, September 2014](https://arxiv.org/pdf/1409.0473.pdf)\n\n2.\u7b2c\u4e00\u7bc7\u5c06attention\u7528\u4e8e\u8bed\u97f3\u8bc6\u522b\u7684\u6587\u7ae0(\u63d0\u51fahybird attention\u673a\u5236\uff0c\u89e3\u51b3attention\u7684\u4f4d\u7f6e\u4fe1\u606f\u95ee\u9898\uff0c\u63d0\u51fa`attention\u52a0\u7a97\u673a\u5236`\uff0c\u6570\u636e\u96c6\uff1a`TIMIT`)\uff1a<br>\n[J.Chorowski, D.Bahdanau, D.Serdyuk, K.Cho, and Y.Bengio.\"Attention-based models for speech recognition\"](http://papers.nips.cc/paper/5847-attention-based-models-for-speech-recognition.pdf)<br>\n\n3.attention\u52a0\u7a97\u6539\u8fdb\uff0cRNN\u66f4\u6362\u4e3aGRU\u5728LVCSR\u4efb\u52a1\u4e0a\u7684\u5e94\u7528\uff08\u6570\u636e\u96c6\uff1a`(WSJ) corpus (available as LDC93S6B and LDC94S13B)`\uff09\uff1a<br>\n[D. Bahdanau, J. Chorowski, D. Serdyuk, P. Brakel, and Y. Bengio,\u201cEnd-to-end attention- based large vocabulary speech recognition,\u201d](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7472618)<br>\n\n4.\u6700\u7ecf\u5178\u7684attention\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\uff1a<br>\n[W. Chan, N. Jaitly, Q. Le, and O. Vinyals, \u201cListen, attend and spell: Aneural network for large vocabulary conversational speech recognition\u201d](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7472621)<br>\n\n5.CTC+Attention(CTC\u5f3a\u5316\u4e86\u5bf9\u9f50\u7684\u5355\u8c03\u6027\uff0c\u4e14CTC\u52a0\u5feb\u7f51\u7edc\u8bad\u7ec3\u901f\u5ea6\uff0c\u6570\u636e\u96c6\uff1a`WSJ1 (81 hours)` ,`WSJ0 (15 hours) `, `CHiME-4 (18 hours)`):<br>\n[S. Kim, T. Hori, and S. Watanabe, \u201cJoint CTC-attention based end-to-end speech recognition using multi-task learning\u201d](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7953075)<br>\n\n6.transformer:<br>\n[N. Shazeer, Niki Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, \u0141. Kaiser, I. Polosukhin \"Attention Is All You Need\"](http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)<br>\n\n7.CNN\u673a\u5668\u7ffb\u8bd1\uff1a<br>\n[J. Gehring, M. Auli, D. Grangier, D. Carats, Y. N. Dauphin \"Convolutional Sequence to Sequence Learning\"](http://delivery.acm.org/10.1145/3310000/3305510/p1243-gehring.pdf?ip=61.150.43.51&id=3305510&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2E1DE562CDF7C9BB11%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1576586699_b9d77762bc10a1c4d4c4da49c7d10881)<br> \n\n8.CNN+RNN\u7684E2E ASR\uff1a<br>\n[VERY DEEP CONVOLUTIONAL NETWORKS FOR END-TO-END SPEECH RECOGNITION](https://arxiv.org/pdf/1610.03022.pdf)\n\n9.CNN+RNN attention+CTC\uff08Encoder\u5728RNN\u524d\u52a0\u5165VGGnet\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u6570\u636e\u96c6\uff1a`WSJ0`,`CHIME-4`\uff09:<br>\n[Kim S, Hori T, Watanabe S. Joint CTC-attention based end-to-end speech recognition using multi-task learning](https://arxiv.org/pdf/1609.06773.pdf)<br>\n\n10.self-attention+CTC:<br>\n[SELF-ATTENTION NETWORKS FOR CONNECTIONIST TEMPORAL CLASSIFICATION IN SPEECH RECOGNITION](https://arxiv.org/pdf/1901.10055.pdf)\n\n## \u4ee3\u7801\n1.[tensorflow E2EASR\u4ee3\u7801](https://github.com/hirofumi0810/tensorflow_end2end_speech_recognition)<br>\n\n2.[pytorch E2EASR\u4ee3\u7801](https://github.com/Alexander-H-Liu/End-to-end-ASR-Pytorch)<br>\n\u9700\u8981\u89e3\u51b3\u7684\u95ee\u9898\uff1a\u5982\u4f55\u591aGPU\u8fd0\u884c"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9222383658450612
      ],
      "excerpt": "GMIS 2017 | \u817e\u8bafAI Lab\u526f\u4e3b\u4efb\u4fde\u680b\uff1a\u8bed\u97f3\u8bc6\u522b\u7814\u7a76\u7684\u56db\u5927\u524d\u6cbf\u65b9\u5411<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9763035580664422
      ],
      "excerpt": "to align and translate. arXiv:1409.0473, September 2014 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.96763909597593
      ],
      "excerpt": "D. Bahdanau, J. Chorowski, D. Serdyuk, P. Brakel, and Y. Bengio,\u201cEnd-to-end attention- based large vocabulary speech recognition,\u201d<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9473273781904477
      ],
      "excerpt": "W. Chan, N. Jaitly, Q. Le, and O. Vinyals, \u201cListen, attend and spell: Aneural network for large vocabulary conversational speech recognition\u201d<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9993729326244424
      ],
      "excerpt": "S. Kim, T. Hori, and S. Watanabe, \u201cJoint CTC-attention based end-to-end speech recognition using multi-task learning\u201d<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8792053771618258
      ],
      "excerpt": "VERY DEEP CONVOLUTIONAL NETWORKS FOR END-TO-END SPEECH RECOGNITION \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9989592837336272,
        0.9646569785501992
      ],
      "excerpt": "Kim S, Hori T, Watanabe S. Joint CTC-attention based end-to-end speech recognition using multi-task learning<br> \nSELF-ATTENTION NETWORKS FOR CONNECTIONIST TEMPORAL CLASSIFICATION IN SPEECH RECOGNITION \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/aaaceo890/Attention",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-12-17T11:59:47Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-31T00:39:21Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8384366016714759
      ],
      "excerpt": "J.Chorowski, D.Bahdanau, D.Serdyuk, K.Cho, and Y.Bengio.\"Attention-based models for speech recognition\"<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8922847830653179
      ],
      "excerpt": "D. Bahdanau, J. Chorowski, D. Serdyuk, P. Brakel, and Y. Bengio,\u201cEnd-to-end attention- based large vocabulary speech recognition,\u201d<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8028443459841162
      ],
      "excerpt": "W. Chan, N. Jaitly, Q. Le, and O. Vinyals, \u201cListen, attend and spell: Aneural network for large vocabulary conversational speech recognition\u201d<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9007000043600076
      ],
      "excerpt": "S. Kim, T. Hori, and S. Watanabe, \u201cJoint CTC-attention based end-to-end speech recognition using multi-task learning\u201d<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112,
        0.8923382656887265,
        0.9627487715650112,
        0.8680037584977036
      ],
      "excerpt": "8.CNN+RNN\u7684E2E ASR\uff1a<br> \nVERY DEEP CONVOLUTIONAL NETWORKS FOR END-TO-END SPEECH RECOGNITION \n9.CNN+RNN attention+CTC\uff08Encoder\u5728RNN\u524d\u52a0\u5165VGGnet\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u6570\u636e\u96c6\uff1aWSJ0,CHIME-4\uff09:<br> \nKim S, Hori T, Watanabe S. Joint CTC-attention based end-to-end speech recognition using multi-task learning<br> \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/aaaceo890/Attention/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 30 Dec 2021 02:53:34 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/aaaceo890/Attention/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "aaaceo890/Attention",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9322609392449874
      ],
      "excerpt": "2.pytorch E2EASR\u4ee3\u7801<br> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/aaaceo890/Attention/issues{/number}",
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Attention",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Attention",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "aaaceo890",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/aaaceo890/Attention/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Thu, 30 Dec 2021 02:53:34 GMT"
    },
    "technique": "GitHub API"
  }
}
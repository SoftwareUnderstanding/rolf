{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1608.04644",
      "https://arxiv.org/abs/1706.06083",
      "https://arxiv.org/abs/1811.09600",
      "https://arxiv.org/abs/1812.06371",
      "https://arxiv.org/abs/1907.02044",
      "https://arxiv.org/abs/1911.02466",
      "https://arxiv.org/abs/2003.01690",
      "https://arxiv.org/abs/2103.01208",
      "https://arxiv.org/abs/2011.11857",
      "https://arxiv.org/abs/2011.12423",
      "https://arxiv.org/abs/2102.12827",
      "https://arxiv.org/abs/2106.01538",
      "https://arxiv.org/abs/1801.03924\n\n## Contributions\n\nSuggestions and contributions are welcome :"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If this library has been useful for your research, you can cite it as follows:\n\n```bibtex\n@misc{rony2020adversarial,\n   title={Adversarial Library},\n   author={Rony, J{\\'e}r{\\^o}me and {Ben Ayed}, Ismail},\n   year={2020},\n   url={https://github.com/jeromerony/adversarial-library}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{rony2020adversarial,\n   title={Adversarial Library},\n   author={Rony, J{\\'e}r{\\^o}me and {Ben Ayed}, Ismail},\n   year={2020},\n   url={https://github.com/jeromerony/adversarial-library}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9695895711447347
      ],
      "excerpt": "| Name                                                   | Knowledge | Type    | Distance(s)                                               | ArXiv Link                       | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9358223674441953
      ],
      "excerpt": "- SSIM https://ece.uwaterloo.ca/~z70wang/research/ssim/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944484218006108
      ],
      "excerpt": "- LPIPS https://arxiv.org/abs/1801.03924 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jeromerony/adversarial-library",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-24T03:07:47Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-17T15:36:42Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.992451229231862,
        0.9380326969677236,
        0.906765418728176,
        0.8972396717653683
      ],
      "excerpt": "This library contains various resources related to adversarial attacks implemented in PyTorch. It is aimed towards researchers looking for implementations of state-of-the-art attacks. \nThe code was written to maximize efficiency (e.g. by preferring low level functions from PyTorch) while retaining simplicity (e.g. by avoiding abstractions). As a consequence, most of the library, and especially the attacks, is implemented using pure functions (whenever possible). \nWhile focused on attacks, this library also provides several utilities related to adversarial attacks: distances (SSIM, CIEDE2000, LPIPS), visdom callback, projections, losses and helper functions. Most notably the function run_attack from utils/attack_utils.py performs an attack on a model given the inputs and labels, with fixed batch size, and reports complexity related metrics (run-time and forward/backward propagations). \nCurrently the following attacks are implemented in the adv_lib.attacks module: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9703415559788554,
        0.9455579295060029
      ],
      "excerpt": "Bold means that this repository contains the official implementation. \nType refers to the goal of the attack: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Library containing PyTorch implementations of various adversarial attacks and resources",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jeromerony/adversarial-library/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Tue, 28 Dec 2021 15:47:37 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/jeromerony/adversarial-library/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "jeromerony/adversarial-library",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can either install using:\n\n```pip install git+https://github.com/jeromerony/adversarial-library```\n\nOr you can clone the repo and run:\n\n```python setup.py install```\n\nAlternatively, you can install (after cloning) the library in editable mode:\n\n```pip install -e .```\n\n",
      "technique": "Header extraction"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/jeromerony/adversarial-library/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\n\\nCopyright (c) 2020, J\\xc3\\xa9r\\xc3\\xb4me Rony\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n3. Neither the name of the copyright holder nor the names of its\\n   contributors may be used to endorse or promote products derived from\\n   this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "adversarial-library",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "adversarial-library",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "jeromerony",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jeromerony/adversarial-library/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The goal of this library is to be up-to-date with newer versions of PyTorch so the dependencies are expected to be updated regularly (possibly resulting in breaking changes).\n\n- pytorch>=1.7.0\n- torchvision>=0.8.0\n- tqdm>=4.48.0\n- visdom>=0.1.8\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 46,
      "date": "Tue, 28 Dec 2021 15:47:37 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "machine-learning",
      "adversarial-attacks",
      "adversarial-examples",
      "pytorch"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": " For an example on how to use this library, you can look at this repo: https://github.com/jeromerony/augmented_lagrangian_adversarial_attacks\n\n",
      "technique": "Header extraction"
    }
  ]
}
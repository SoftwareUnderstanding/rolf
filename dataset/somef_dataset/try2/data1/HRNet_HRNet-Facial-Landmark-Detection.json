{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] Deep High-Resolution Representation Learning for Visual Recognition. Jingdong Wang, Ke Sun, Tianheng Cheng, \n    Borui Jiang, Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, Wenyu Liu, Bin Xiao. Accepted by TPAMI.  [download](https://arxiv.org/pdf/1908.07919.pdf)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this work or code is helpful in your research, please cite:\n````\n@inproceedings{SunXLW19,\n  title={Deep High-Resolution Representation Learning for Human Pose Estimation},\n  author={Ke Sun and Bin Xiao and Dong Liu and Jingdong Wang},\n  booktitle={CVPR},\n  year={2019}\n}\n\n@article{WangSCJDZLMTWLX19,\n  title={Deep High-Resolution Representation Learning for Visual Recognition},\n  author={Jingdong Wang and Ke Sun and Tianheng Cheng and \n          Borui Jiang and Chaorui Deng and Yang Zhao and Dong Liu and Yadong Mu and \n          Mingkui Tan and Xinggang Wang and Wenyu Liu and Bin Xiao},\n  journal   = {TPAMI}\n  year={2019}\n}\n````\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{WangSCJDZLMTWLX19,\n  title={Deep High-Resolution Representation Learning for Visual Recognition},\n  author={Jingdong Wang and Ke Sun and Tianheng Cheng and \n          Borui Jiang and Chaorui Deng and Yang Zhao and Dong Liu and Yadong Mu and \n          Mingkui Tan and Xinggang Wang and Wenyu Liu and Bin Xiao},\n  journal   = {TPAMI}\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{SunXLW19,\n  title={Deep High-Resolution Representation Learning for Human Pose Estimation},\n  author={Ke Sun and Bin Xiao and Dong Liu and Jingdong Wang},\n  booktitle={CVPR},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9353051976633957
      ],
      "excerpt": "[2020/03/13] Our paper is accepted by TPAMI: Deep High-Resolution Representation Learning for Visual Recognition. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9015781078351486
      ],
      "excerpt": "cd HRNet-Facial-Landmark-Detection \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9606712260438129
      ],
      "excerpt": "Human pose estimation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9146894306581498
      ],
      "excerpt": "Object detection \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/HRNet/HRNet-Facial-Landmark-Detection",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-09T13:25:44Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-24T10:57:07Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This is the official code of [High-Resolution Representations for Facial Landmark Detection](https://arxiv.org/pdf/1904.04514.pdf). \nWe extend the high-resolution representation (HRNet) [1] by augmenting the high-resolution representation by aggregating the (upsampled) \nrepresentations from all the parallel convolutions, leading to stronger representations. The output representations are fed into\nclassifier. We evaluate our methods on four datasets, COFW, AFLW, WFLW and 300W.\n\n<div align=center>\n\n![](images/hrnet.jpg)\n\n</div>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9570636454608743,
        0.9167601970792938,
        0.9235525221601059
      ],
      "excerpt": "[2020/03/13] Our paper is accepted by TPAMI: Deep High-Resolution Representation Learning for Visual Recognition. \nHRNetV2 ImageNet pretrained models are now available! Codes and pretrained models are in HRNets for Image Classification \nWe adopt HRNetV2-W18(#Params=9.3M, GFLOPs=4.3G) for facial landmark detection on COFW, AFLW, WFLW and 300W. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "| Model | NME | FR<sub>0.1</sub>|pretrained model|model| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9004583576180396,
        0.9101315571655881
      ],
      "excerpt": "The model is trained on AFLW train and evaluated on AFLW full and frontal. \n| Model | NME<sub>full</sub> | NME<sub>frontal</sub> | pretrained model|model| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8928039114635801
      ],
      "excerpt": "This code is developed using on Python 3.6 and PyTorch 1.0.0 on Ubuntu 16.04 with NVIDIA GPUs. Training and testing are  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.923948005372906,
        0.8979411005071259
      ],
      "excerpt": "-- tools \n-- data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8186001324146379
      ],
      "excerpt": "Please specify the configuration file in experiments (learning rate should be adjusted when the number of GPUs is changed). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This is an official implementation of facial landmark detection for our TPAMI paper \"Deep High-Resolution Representation Learning for Visual Recognition\". https://arxiv.org/abs/1908.07919",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/HRNet/HRNet-Facial-Landmark-Detection/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 209,
      "date": "Sun, 26 Dec 2021 09:59:11 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/HRNet/HRNet-Facial-Landmark-Detection/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "HRNet/HRNet-Facial-Landmark-Detection",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Install PyTorch 1.0 following the [official instructions](https://pytorch.org/)\n2. Install dependencies\n````bash\n\npip install -r requirements.txt\n````\n3. Clone the project\n````bash \ngit clone https://github.com/HRNet/HRNet-Facial-Landmark-Detection.git\n````\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9009610898459604
      ],
      "excerpt": "performed using 1 NVIDIA P40 GPU with CUDA 9.0 and cuDNN 7.0. Other platforms or GPUs are not fully tested. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8902627162932362
      ],
      "excerpt": "mkdir hrnetv2_pretrained \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8075926379592141
      ],
      "excerpt": "| Model | NME | FR<sub>0.1</sub>|pretrained model|model| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8924076742478699
      ],
      "excerpt": "|HRNetV2-W18  | 3.45 | 0.20 | HRNetV2-W18 | HR18-COFW.pth| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8025549570784234
      ],
      "excerpt": "| Model | NME<sub>full</sub> | NME<sub>frontal</sub> | pretrained model|model| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8616391788095444
      ],
      "excerpt": ": Download pretrained models into this folder \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8084956211712775
      ],
      "excerpt": "You need to download images (300W, AFLW, WFLW) from official websites and then put them into images folder for each dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.934512547732543,
        0.8778487586960795,
        0.9197138544944952
      ],
      "excerpt": "python tools/train.py --cfg <CONFIG-FILE> \n: example: \npython tools/train.py --cfg experiments/wflw/face_alignment_wflw_hrnet_w18.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9453455289786712,
        0.8778487586960795,
        0.9577382108722359
      ],
      "excerpt": "python tools/test.py --cfg <CONFIG-FILE> --model-file <MODEL WEIGHT>  \n: example: \npython tools/test.py --cfg experiments/wflw/face_alignment_wflw_hrnet_w18.yaml --model-file HR18-WFLW.pth \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/HRNet/HRNet-Facial-Landmark-Detection/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "High-resolution networks (HRNets) for facial landmark detection",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "HRNet-Facial-Landmark-Detection",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "HRNet",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/HRNet/HRNet-Facial-Landmark-Detection/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 765,
      "date": "Sun, 26 Dec 2021 09:59:11 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "hrnets",
      "facial-landmarks",
      "deep-high-resolution-net",
      "face-alignment",
      "facealignment"
    ],
    "technique": "GitHub API"
  }
}
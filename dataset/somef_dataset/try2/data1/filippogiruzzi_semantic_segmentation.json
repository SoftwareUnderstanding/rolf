{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1505.04597",
      "https://arxiv.org/abs/1711.03938"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9792428879788975
      ],
      "excerpt": "2015,  Arxiv  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.993980143105462
      ],
      "excerpt": "2017,  Arxiv  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/filippogiruzzi/semantic_segmentation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-05T14:50:16Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-06T07:31:00Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8906128909950556
      ],
      "excerpt": " Introduction  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.853134726109167
      ],
      "excerpt": " Project structure  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8559607020725433
      ],
      "excerpt": " Project usage  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8076344345050138
      ],
      "excerpt": "    5.3  Visualize predictions with trained model  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9968354213019989,
        0.8952195608702915,
        0.9328571122324776,
        0.8941017575383292,
        0.9366366196546311
      ],
      "excerpt": "The purpose of this project is to design and implement  \na real-time Semantic Segmentation algorithm based on Deep Learning. \nThe designed solution is based on a UNet model implemented in TensorFlow. I use a Focal loss  \nto solve the unbalanced data problem among the classes. \nThe model was trained  on Google Colab for approximately 200 epochs with the  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8728592049761854
      ],
      "excerpt": "* semseg/data_processing/: data processing,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9512367523787568
      ],
      "excerpt": "on Kaggle, which is based from the  Lyft Udacity challenge  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801827024013563
      ],
      "excerpt": "[x] Full training on Google Colab & update results \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8370886967043416
      ],
      "excerpt": "[ ] Add data augmentation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8119541910778083
      ],
      "excerpt": " Website  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Semantic Segmentation project for Autonomous Driving based on a TensorFlow implementation of UNet",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/filippogiruzzi/semantic_segmentation/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Mon, 20 Dec 2021 22:50:30 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/filippogiruzzi/semantic_segmentation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "filippogiruzzi/semantic_segmentation",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This project was designed for:\n* Python 3.6\n* TensorFlow 1.12.0\n\nPlease install requirements & project:\n```\n$ cd /path/to/project/\n$ git clone https://github.com/filippogiruzzi/semantic_segmentation.git\n$ cd semantic_segmentation/\n$ pip3 install -r requirements.txt\n$ pip3 install -e . --user --upgrade\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9769420979004304
      ],
      "excerpt": "Installation  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.819118553941283
      ],
      "excerpt": "The project semantic_segmentation/ has the following structure: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.81046520052504,
        0.8333607518942004
      ],
      "excerpt": " Project usage  \n    5.1  Record raw data to .tfrecord format  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8340377062807277
      ],
      "excerpt": "* semseg/training/: data input pipeline, model  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.857990829675769
      ],
      "excerpt": "$ python3 data_processing/data_to_tfrecords.py --data_dir /path/to/carla_semseg_data/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9381325104459932,
        0.9381325104459932,
        0.8265757464612293
      ],
      "excerpt": "$ python3 training/train.py --data-dir /path/to/carla_semseg_data/tfrecords/ \n$ python3 training/train.py --data-dir /path/to/carla_semseg_data/tfrecords/ \n                            --mode predict \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/filippogiruzzi/semantic_segmentation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Semantic Segmentation project",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "semantic_segmentation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "filippogiruzzi",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/filippogiruzzi/semantic_segmentation/blob/master/ReadMe.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Mon, 20 Dec 2021 22:50:30 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "semantic-segmentation",
      "unet",
      "unet-image-segmentation",
      "unet-tensorflow",
      "tensorflow",
      "python",
      "unet-segmentation",
      "unet-model",
      "autonomous-driving",
      "self-driving-car",
      "deep-learning",
      "carla-simulator",
      "carla-driving-simulator",
      "carla",
      "self-driving-cars",
      "autonomous-vehicles",
      "artificial-intelligence",
      "deep-neural-networks",
      "deeplearning",
      "lyft-udacity-challenge"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd /path/to/project/semantic_segmentation/semseg/\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
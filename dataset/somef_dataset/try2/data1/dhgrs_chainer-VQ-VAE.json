{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1711.00937 "
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9896978521113555
      ],
      "excerpt": "A Chainer implementation of VQ-VAE( https://arxiv.org/abs/1711.00937 ). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "If True apply dropout. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dhgrs/chainer-VQ-VAE",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-11-08T01:20:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-28T15:42:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9684915575131307
      ],
      "excerpt": "The threshold db for triming silence. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9893341749641272
      ],
      "excerpt": "The input channels of wave. If it is 1, mu-law is not applied. Else mu-law is applied. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9225163961106264
      ],
      "excerpt": "The parameter d in the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9225163961106264
      ],
      "excerpt": "The parameter k in the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9228180564522516
      ],
      "excerpt": "The number of output channels of causal dilated convolution layers. This is splited into tanh and sigmoid so the number of hidden units is half of this number. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.885665649949491
      ],
      "excerpt": "The number of channels of skip connections and last projection layer. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9121816197442519
      ],
      "excerpt": "The number of logistic distribution. It is used only use_logistic is True. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9006001924861713
      ],
      "excerpt": "The number for stability. It is used only use_logistic is True. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8996618171942135
      ],
      "excerpt": "The dimension of speaker embeded-vector. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8939815515275101
      ],
      "excerpt": "The dimension of local contioning vectors. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8938425562509802
      ],
      "excerpt": "The parameter beta in the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9390803920346439
      ],
      "excerpt": "Other arguments -f and -p are parameters for multiprocess in preprocessing. -f means the number of prefetch and -p means the number of processes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9968029537584643
      ],
      "excerpt": "[x] descritized mixture of logistics \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A Chainer implementation of VQ-VAE.",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can download VCTK-Corpus(en) from [here](http://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html). And you can download CMU-ARCTIC(en)/voice-statistics-corpus(ja) very easily via [my repository](https://github.com/dhgrs/download_dataset).\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dhgrs/chainer-VQ-VAE/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 18,
      "date": "Tue, 21 Dec 2021 11:51:01 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dhgrs/chainer-VQ-VAE/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "dhgrs/chainer-VQ-VAE",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/dhgrs/chainer-VQ-VAE/audio/Colaboratory/generate.ipynb",
      "https://raw.githubusercontent.com/dhgrs/chainer-VQ-VAE/audio/Colaboratory/train.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8768220937576192
      ],
      "excerpt": "The interval that you save snapshot. You can set this parameter like as trigger. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8842009198251607
      ],
      "excerpt": "(without GPU) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9692562918933139
      ],
      "excerpt": "(with GPU #:n) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8838041791449868
      ],
      "excerpt": "[x] using GPU fot generating \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9503189345333785
      ],
      "excerpt": "python train.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503189345333785
      ],
      "excerpt": "python train.py -g n \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503189345333785
      ],
      "excerpt": "python train.py -g 0 1 2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503189345333785
      ],
      "excerpt": "python train.py -r snapshot_iter_100000 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dhgrs/chainer-VQ-VAE/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "chainer-VQ-VAE",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "chainer-VQ-VAE",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "dhgrs",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dhgrs/chainer-VQ-VAE/blob/audio/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "I trained and generated with\n\n- python(3.5.2)\n- chainer(4.0.0b3)\n- librosa(0.5.1)\n\nAnd now you can try it on Google Colaboratory. You don't need install chainer/librosa in your local or buy GPUs. Check [this](Colaboratory/README.md).\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 78,
      "date": "Tue, 21 Dec 2021 11:51:01 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "vq-vae",
      "chainer",
      "wavenet",
      "voice-conversion"
    ],
    "technique": "GitHub API"
  }
}
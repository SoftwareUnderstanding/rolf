{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1912.04488",
      "https://arxiv.org/abs/2003.10152",
      "https://arxiv.org/abs/1911.07451",
      "https://arxiv.org/abs/1904.01355",
      "https://arxiv.org/abs/2001.00309",
      "https://arxiv.org/abs/2003.11712",
      "https://arxiv.org/abs/2002.10200",
      "https://arxiv.org/abs/2003.05664",
      "https://arxiv.org/abs/2003.10152",
      "https://arxiv.org/abs/1911.07451"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use this toolbox in your research or wish to refer to the baseline results, please use the following BibTeX entries.\n\n```BibTeX\n@inproceedings{tian2019fcos,\n  title     =  {{FCOS}: Fully Convolutional One-Stage Object Detection},\n  author    =  {Tian, Zhi and Shen, Chunhua and Chen, Hao and He, Tong},\n  booktitle =  {Proc. Int. Conf. Computer Vision (ICCV)},\n  year      =  {2019}\n}\n\n@inproceedings{chen2020blendmask,\n  title     =  {{BlendMask}: Top-Down Meets Bottom-Up for Instance Segmentation},\n  author    =  {Chen, Hao and Sun, Kunyang and Tian, Zhi and Shen, Chunhua and Huang, Yongming and Yan, Youliang},\n  booktitle =  {Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR)},\n  year      =  {2020}\n}\n\n@inproceedings{zhang2020MEInst,\n  title     =  {Mask Encoding for Single Shot Instance Segmentation},\n  author    =  {Zhang, Rufeng and Tian, Zhi and Shen, Chunhua and You, Mingyu and Yan, Youliang},\n  booktitle =  {Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR)},\n  year      =  {2020}\n}\n\n@inproceedings{liu2020abcnet,\n  title     =  {{ABCNet}: Real-time Scene Text Spotting with Adaptive Bezier-Curve Network},\n  author    =  {Liu, Yuliang and Chen, Hao and Shen, Chunhua and He, Tong and Jin, Lianwen and Wang, Liangwei},\n  booktitle =  {Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR)},\n  year      =  {2020}\n}\n\n@inproceedings{wang2020solo,\n  title     =  {{SOLO}: Segmenting Objects by Locations},\n  author    =  {Wang, Xinlong and Kong, Tao and Shen, Chunhua and Jiang, Yuning and Li, Lei},\n  booktitle =  {Proc. Eur. Conf. Computer Vision (ECCV)},\n  year      =  {2020}\n}\n\n@article{wang2020solov2,\n  title   =  {{SOLOv2}: Dynamic, Faster and Stronger},\n  author  =  {Wang, Xinlong and Zhang, Rufeng and Kong, Tao and Li, Lei and Shen, Chunhua},\n  journal =  {arXiv preprint arXiv:2003.10152},\n  year    =  {2020}\n}\n\n@article{tian2019directpose,\n  title   =  {{DirectPose}: Direct End-to-End Multi-Person Pose Estimation},\n  author  =  {Tian, Zhi and Chen, Hao and Shen, Chunhua},\n  journal =  {arXiv preprint arXiv:1911.07451},\n  year    =  {2019}\n}\n\n@inproceedings{tian2020conditional,\n  title     =  {Conditional Convolutions for Instance Segmentation},\n  author    =  {Tian, Zhi and Shen, Chunhua and Chen, Hao},\n  booktitle =  {Proc. Eur. Conf. Computer Vision (ECCV)},\n  year      =  {2020}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{tian2020conditional,\n  title     =  {Conditional Convolutions for Instance Segmentation},\n  author    =  {Tian, Zhi and Shen, Chunhua and Chen, Hao},\n  booktitle =  {Proc. Eur. Conf. Computer Vision (ECCV)},\n  year      =  {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{tian2019directpose,\n  title   =  {{DirectPose}: Direct End-to-End Multi-Person Pose Estimation},\n  author  =  {Tian, Zhi and Chen, Hao and Shen, Chunhua},\n  journal =  {arXiv preprint arXiv:1911.07451},\n  year    =  {2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{wang2020solov2,\n  title   =  {{SOLOv2}: Dynamic, Faster and Stronger},\n  author  =  {Wang, Xinlong and Zhang, Rufeng and Kong, Tao and Li, Lei and Shen, Chunhua},\n  journal =  {arXiv preprint arXiv:2003.10152},\n  year    =  {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{wang2020solo,\n  title     =  {{SOLO}: Segmenting Objects by Locations},\n  author    =  {Wang, Xinlong and Kong, Tao and Shen, Chunhua and Jiang, Yuning and Li, Lei},\n  booktitle =  {Proc. Eur. Conf. Computer Vision (ECCV)},\n  year      =  {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{liu2020abcnet,\n  title     =  {{ABCNet}: Real-time Scene Text Spotting with Adaptive Bezier-Curve Network},\n  author    =  {Liu, Yuliang and Chen, Hao and Shen, Chunhua and He, Tong and Jin, Lianwen and Wang, Liangwei},\n  booktitle =  {Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR)},\n  year      =  {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{zhang2020MEInst,\n  title     =  {Mask Encoding for Single Shot Instance Segmentation},\n  author    =  {Zhang, Rufeng and Tian, Zhi and Shen, Chunhua and You, Mingyu and Yan, Youliang},\n  booktitle =  {Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR)},\n  year      =  {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{chen2020blendmask,\n  title     =  {{BlendMask}: Top-Down Meets Bottom-Up for Instance Segmentation},\n  author    =  {Chen, Hao and Sun, Kunyang and Tian, Zhi and Shen, Chunhua and Huang, Yongming and Yan, Youliang},\n  booktitle =  {Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR)},\n  year      =  {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{tian2019fcos,\n  title     =  {{FCOS}: Fully Convolutional One-Stage Object Detection},\n  author    =  {Tian, Zhi and Shen, Chunhua and Chen, Hao and He, Tong},\n  booktitle =  {Proc. Int. Conf. Computer Vision (ICCV)},\n  year      =  {2019}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/quangvy2703/ABCNet-ESRGAN-SRTEXT",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-21T09:38:24Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-12T02:55:03Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.90387120413718,
        0.902078113666546
      ],
      "excerpt": "AdelaiDet is an open source toolbox for multiple instance-level recognition tasks on top of Detectron2. \nAll instance-level recognition works from our group are open-sourced here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9434768973015376
      ],
      "excerpt": "For more models and information, please refer to ABCNet README.md. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8793793675764062
      ],
      "excerpt": "- We set OMP_NUM_THREADS=1 by default, which achieves the best speed on our machines, please change it as needed. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation of using esrgan to super-resolution text image for scene text detection-recognition base on ABCNet",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/quangvy2703/ABCNet-ESRGAN-SRTEXT/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Tue, 28 Dec 2021 06:39:58 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/quangvy2703/ABCNet-ESRGAN-SRTEXT/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "quangvy2703/ABCNet-ESRGAN-SRTEXT",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/quangvy2703/ABCNet-ESRGAN-SRTEXT/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/quangvy2703/ABCNet-ESRGAN-SRTEXT/master/onnx/pytorch-onnx-caffe-ncnn.sh",
      "https://raw.githubusercontent.com/quangvy2703/ABCNet-ESRGAN-SRTEXT/master/onnx/pytorch-onnx-caffe-ncnn-rt.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "First install Detectron2 following the official guide: [INSTALL.md](https://github.com/facebookresearch/detectron2/blob/master/INSTALL.md). Please use Detectron2 with commit id [9eb4831](https://github.com/facebookresearch/detectron2/commit/9eb4831f742ae6a13b8edb61d07b619392fb6543) for now. The incompatibility with the latest one will be fixed soon.\n\nThen build AdelaiDet with:\n\n```\ngit clone https://github.com/aim-uofa/AdelaiDet.git\ncd AdelaiDet\npython setup.py build develop\n```\n\nSome projects may require special setup, please follow their own `README.md` in [configs](configs).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8630298091409239,
        0.8630298091409239
      ],
      "excerpt": "SOLO to be released (mmdet version) \nSOLOv2 to be released (mmdet version) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8431264577996327
      ],
      "excerpt": "Name | inf. time | e2e-hmean | det-hmean | download \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8826220462631758
      ],
      "excerpt": "setup the corresponding datasets following \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8838377520179606
      ],
      "excerpt": "Note that: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8157439033119126
      ],
      "excerpt": "FCOS_R_50_1x | 16 FPS | 38.7 | model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8017778607929922,
        0.8017778607929922,
        0.8017778607929922
      ],
      "excerpt": "FCOS_MS_X_101_32x8d_2x | 6.6 FPS | 43.9 | model \nFCOS_MS_X_101_32x8d_dcnv2_2x | 4.6 FPS | 46.6 | model \nFCOS_RT_MS_DLA_34_4x_shtw | 52 FPS | 39.1 | model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8612558838572962
      ],
      "excerpt": "Name | inf. time | e2e-hmean | det-hmean | download \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9008116137719951
      ],
      "excerpt": "Pick a model and its config file, for example, fcos_R_50_1x.yaml. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421174927206765,
        0.9057698139330033
      ],
      "excerpt": "Run the demo with \npython demo/demo.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.881670876222929
      ],
      "excerpt": "    --input input1.jpg input2.jpg \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9366641523006497
      ],
      "excerpt": "To train a model with \"train_net.py\", first \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8117007451991057,
        0.810477497050042
      ],
      "excerpt": "then run: \nOMP_NUM_THREADS=1 python tools/train_net.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8272690102910759,
        0.810477497050042
      ],
      "excerpt": "To evaluate the model after training, run: \nOMP_NUM_THREADS=1 python tools/train_net.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8183947818984721
      ],
      "excerpt": "- The configs are made for 8-GPU training. To train on another number of GPUs, change the --num-gpus. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/quangvy2703/ABCNet-ESRGAN-SRTEXT/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cuda",
      "C++",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/quangvy2703/ABCNet-ESRGAN-SRTEXT/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'AdelaiDet for non-commercial purposes\\n\\nCopyright (c) 2019 the authors\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n Redistributions of source code must retain the above copyright notice, this\\n  list of conditions and the following disclaimer.\\n\\n Redistributions in binary form must reproduce the above copyright notice,\\n  this list of conditions and the following disclaimer in the documentation\\n  and/or other materials provided with the distribution.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "AdelaiDet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ABCNet-ESRGAN-SRTEXT",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "quangvy2703",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/quangvy2703/ABCNet-ESRGAN-SRTEXT/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Tue, 28 Dec 2021 06:39:58 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Model | Name |inf. time | box AP | mask AP | download\n--- |:---:|:---:|:---:|:---:|:---:\nMask R-CNN | [R_101_3x](https://github.com/facebookresearch/detectron2/blob/master/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml) | 10 FPS | 42.9 | 38.6 |\nBlendMask | [R_101_3x](configs/BlendMask/R_101_3x.yaml) | 11 FPS | 44.8 | 39.5 | [model](https://cloudstor.aarnet.edu.au/plus/s/e4fXrliAcMtyEBy/download)\nBlendMask | [R_101_dcni3_5x](configs/BlendMask/R_101_dcni3_5x.yaml) | 10 FPS | 46.8 | 41.1 | [model](https://cloudstor.aarnet.edu.au/plus/s/vbnKnQtaGlw8TKv/download)\n\nFor more models and information, please refer to BlendMask [README.md](configs/BlendMask/README.md).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Name | inf. time | box AP | mask AP | download\n--- |:---:|:---:|:---:|:---:\n[MEInst_R_50_3x](https://github.com/aim-uofa/AdelaiDet/configs/MEInst-InstanceSegmentation/MEInst_R_50_3x.yaml) | 12 FPS | 43.6 | 34.5 | [model](https://cloudstor.aarnet.edu.au/plus/s/1ID0DeuI9JsFQoG/download)\n\nFor more models and information, please refer to MEInst [README.md](configs/MEInst-InstanceSegmentation/README.md).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Name | inf. time | box AP | mask AP | download\n--- |:---:|:---:|:---:|:---:\n[CondInst_MS_R_50_1x](configs/CondInst/MS_R_50_1x.yaml) | 14 FPS | 39.7 | 35.7 | [model](https://cloudstor.aarnet.edu.au/plus/s/Trx1r4tLJja7sLT/download)\n[CondInst_MS_R_50_BiFPN_3x_sem](configs/CondInst/MS_R_50_BiFPN_3x_sem.yaml) | 13 FPS | 44.7 | 39.4 | [model](https://cloudstor.aarnet.edu.au/plus/s/9cAHjZtdaAGnb2Q/download)\n[CondInst_MS_R_101_3x](configs/CondInst/MS_R_101_3x.yaml) | 11 FPS | 43.3 | 38.6 | [model](https://cloudstor.aarnet.edu.au/plus/s/vWLiYm8OnrTSUD2/download)\n[CondInst_MS_R_101_BiFPN_3x_sem](configs/CondInst/MS_R_101_BiFPN_3x_sem.yaml) | 10 FPS | 45.7 | 40.2 | [model](https://cloudstor.aarnet.edu.au/plus/s/2p1ashxl54Su8vv/download)\n\nFor more models and information, please refer to CondInst [README.md](configs/CondInst/README.md).\n\nNote that:\n- Inference time for all projects is measured on a NVIDIA 1080Ti with batch size 1.\n- APs are evaluated on COCO2017 val split unless specified.\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
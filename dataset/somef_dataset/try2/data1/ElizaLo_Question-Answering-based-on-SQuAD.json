{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1611.01603",
      "https://arxiv.org/abs/1606.05250",
      "https://arxiv.org/abs/1806.03822",
      "https://arxiv.org/abs/1611.01603",
      "https://arxiv.org/abs/1810.04805"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8728059224385537
      ],
      "excerpt": "Source: BiDAF paper \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9995157199955657,
        0.998778219784074,
        0.9977994744046882
      ],
      "excerpt": "SQuAD: 100,000+ Questions for Machine Comprehension of Text, 2016: https://arxiv.org/pdf/1606.05250.pdf \nKnow What You Don\u2019t Know: Unanswerable Questions for SQuAD, 2018: https://arxiv.org/pdf/1806.03822.pdf \nBiDAF: https://arxiv.org/pdf/1611.01603.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9923824385339041
      ],
      "excerpt": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8715509475085587,
        0.8833705422112558
      ],
      "excerpt": "SQuAD 2.0: https://rajpurkar.github.io/SQuAD-explorer/ \nBi-Directional Attention Flow for Machine Comprehension \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8654671031158477
      ],
      "excerpt": "GloVE: https://nlp.stanford.edu/projects/glove/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9822150123617318,
        0.9961784272285156,
        0.9626788402420574
      ],
      "excerpt": "SQuAD: 100,000+ Questions for Machine Comprehension of Text: https://paperswithcode.com/paper/squad-100000-questions-for-machine \nBidirectional Attention Flow for Machine Comprehension : https://paperswithcode.com/paper/bidirectional-attention-flow-for-machine \nUnderstanding LSTM Networks: http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.996646006960799,
        0.9893467189653059
      ],
      "excerpt": "Semantic Word Embeddings: https://www.offconvex.org/2015/12/12/word-embeddings-1/ \nQuestion Answering in Natural Language Processing [Part-I]: https://medium.com/lingvo-masino/question-and-answering-in-natural-language-processing-part-i-168f00291856 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ElizaLo/Question-Answering-based-on-SQuAD",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-25T10:02:30Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-29T14:12:31Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8952931761420792
      ],
      "excerpt": "Implemented a Bidirectional Attention Flow neural network as a baseline, improving Chris Chute's model implementation, adding word-character inputs as described in the original paper and improving GauthierDmns' code. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9605357943542444
      ],
      "excerpt": "Question-answer pairs for a sample passage in the SQuAD dataset. Each of the answers is a segment of text from the passage. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8508830890397249,
        0.8750381207894962
      ],
      "excerpt": "\u251c\u2500\u2500 data_loader.py     &lt;- Define an iterator who collects batches of data to train the model \n\u251c\u2500\u2500 eval.py            &lt;- Evaluate the model on a new pair of (context, question) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8889496577048623,
        0.8018469602317619,
        0.8181704209799999,
        0.9036516078248451
      ],
      "excerpt": "- [ ] set up a variable to choose between training the model with word only VS word + characters \n- [ ] collect the moving average of the weights during training and use them during testing \n- [ ] add the ability to train the model on multiple GPUs, and offer half-precision training to speed-up the training \n- [ ] improve this baseline using pre-training encoding such as BERT, and/or set-up a multi-task learning pipeline to jointly learn to answer questions together with another closely related NLP task. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9312887985999561
      ],
      "excerpt": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.886466809138234
      ],
      "excerpt": "Papers With Code  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Question Answering System using BiDAF Model on SQuAD v2.0",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ElizaLo/Question-Answering-based-on-SQuAD/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [Pytorch Tip: Yielding Image Sizes](https://medium.com/@yvanscher/pytorch-tip-yielding-image-sizes-6a776eb4115b)\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 21,
      "date": "Tue, 28 Dec 2021 07:12:40 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ElizaLo/Question-Answering-based-on-SQuAD/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ElizaLo/Question-Answering-based-on-SQuAD",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Clone the repository\n* Create a directory for your experiments, logs and model weights: `mkdir output`\n* Download GloVE word vectors: https://nlp.stanford.edu/projects/glove/\n* Modify the `config.py` file to set up the paths where your GloVE, SquAD and models will be located\n* Create a Python virtual environment, source to it: `mkvirualenv qa-env ; workon qa-env` if you use virtualenvwrapper\n* Install the dependencies: `pip install -r requirements.txt ; python -m spacy download en`\n* Run `python make_dataset.py` to download SquAD dataset and pre-process the data\n* Run `python train.py` to train the model with hyper-parameters found in `config.py`\n* Run `python test.py` to test the model EM and F1 scores on Dev examples\n* Play with `eval.py` to answer your own questions! :)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9698571289336496
      ],
      "excerpt": "\u251c\u2500\u2500 requirements.txt   &lt;- Required Python libraries to build the project \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9725002728977397
      ],
      "excerpt": "PyTorch pretrained BERT: https://github.com/huggingface/pytorch-pretrained-BERT \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8778942925242261
      ],
      "excerpt": "\u251c\u2500\u2500 config.py          &lt;- Configuration file with data directories and hyperparamters to train the model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8185349105968415
      ],
      "excerpt": "\u251c\u2500\u2500 make_dataset.py    &lt;- Download the SquAD dataset and pre-process the data for training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8072644740710192,
        0.8778569076228988
      ],
      "excerpt": "\u251c\u2500\u2500 test.py            &lt;- Test the performance of a trained model on the DEV dataset \n\u251c\u2500\u2500 train.py           &lt;- Train a model using the TRAIN dataset only \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ElizaLo/Question-Answering-based-on-SQuAD/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Question Answering with SQuAD using BiDAF model",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Question-Answering-based-on-SQuAD",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ElizaLo",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ElizaLo/Question-Answering-based-on-SQuAD/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- `Python 3.6`\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 16,
      "date": "Tue, 28 Dec 2021 07:12:40 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "nlp",
      "nlp-machine-learning",
      "question-answering",
      "squad",
      "bidaf",
      "neural-network",
      "nlp-datasets",
      "machine-learning",
      "python",
      "python-3-6",
      "natural-language-processing",
      "natural-language-understanding"
    ],
    "technique": "GitHub API"
  }
}
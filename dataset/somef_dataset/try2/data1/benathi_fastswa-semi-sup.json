{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.01780",
      "https://arxiv.org/abs/1610.02242",
      "https://arxiv.org/abs/1803.05407"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{athiwaratkun2018improving,\n  title={There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average},\n  author={Athiwaratkun, Ben and Finzi, Marc and Izmailov, Pavel and Wilson, Andrew Gordon},\n  journal={ICLR},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9476270722224395
      ],
      "excerpt": "<img src=\"figs/N-4000_seed-10_exp-cifar10_mt_cnn_short_n4k_date-2018-06-06_01-40-29.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.90097832490285
      ],
      "excerpt": "if epoch &gt;= (args.epochs - args.cycle_interval) and (epoch - args.epochs - args.cycle_interval) % fastswa_freq == 0: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/benathi/fastswa-semi-sup",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-05-20T00:19:15Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-21T01:17:33Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.991354515867569
      ],
      "excerpt": "This repository contains the code for our paper There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average, which achieves the best known performance for semi-supervised learning on CIFAR-10 and CIFAR-100. By analyzing the geometry of training objectives involving consistency regularization, we can significantly improve the Mean Teacher model (Tarvainen and Valpola, NIPS 2017) and the Pi Model (Laine and Aila, ICLR 2017), using stochastic weight averaging (SWA) and our proposed variant fast-SWA which achieves faster reduction in prediction errors. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9211419701079541
      ],
      "excerpt": "We provide training scripts in folder exps. To replicate the results for CIFAR-10 using the Mean Teacher model on 4000 labels with a 13-layer CNN, run the following: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9450648114658176
      ],
      "excerpt": "Figure 1. CIFAR-10 Test Accuracy of the Mean Teacher Model with SWA and fastSWA using a 13-layer CNN and 4000 labels. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9616727018517126
      ],
      "excerpt": "Figure 2. CIFAR-100 Test Accuracy of the Mean Teacher Model with SWA and fastSWA using a 13-layer CNN and 10000 labels. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8679445028702735
      ],
      "excerpt": "fastSWA can be incorporated into training very conveniently with just a few lines of code. First, we initialize a replicate model (which can be set to require no gradients to save memory) and initialize the weight averaging optimization object. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8458325108383015
      ],
      "excerpt": "Then, the fastSWA model can be updated every fastswa_freq epochs. Note that after updating the weights, we need to update Batch Normalization running average variables by passing the training data through the fastSWA model.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8456212659130324
      ],
      "excerpt": "For more details, see main.py. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Improving Consistency-Based Semi-Supervised Learning with Weight Averaging ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/benathi/fastswa-semi-sup/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 32,
      "date": "Thu, 23 Dec 2021 22:02:57 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/benathi/fastswa-semi-sup/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "benathi/fastswa-semi-sup",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/plot_results.sh",
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/data-local/labels/bin/prepare_semisupervised_sets_cifar100_50k.sh",
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/data-local/labels/bin/prepare_semisupervised_sets_cifar10_10_20k.sh",
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/data-local/labels/bin/create_balanced_semisupervised_labels.sh",
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/data-local/labels/bin/prepare_semisupervised_sets_cifar10_50k.sh",
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/data-local/labels/bin/create_balanced_semisupervised_labels_trainval.sh",
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/data-local/labels/bin/prepare_semisupervised_sets_cifar10_2000.sh",
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/data-local/labels/bin/prepare_semisupervised_sets.sh",
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/data-local/labels/bin/prepare_semisupervised_sets_cifar100.sh",
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/data-local/bin/link_cifar10_val.sh",
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/data-local/bin/link_cifar10_train.sh",
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/data-local/bin/link_cifar100_val.sh",
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/data-local/bin/link_cifar100_train.sh",
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/data-local/bin/prepare_cifar10.sh",
      "https://raw.githubusercontent.com/benathi/fastswa-semi-sup/master/data-local/bin/prepare_cifar100.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The code runs on Python 3 with Pytorch 0.3. The following packages are also required.\n```\npip install scipy tqdm matplotlib pandas msgpack\n```\n\nThen prepare CIFAR-10 and CIFAR-100 with the following commands:\n\n```\n./data-local/bin/prepare_cifar10.sh\n./data-local/bin/prepare_cifar100.sh\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8890099980735993
      ],
      "excerpt": "python experiments/cifar10_mt_cnn_short_n4k.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8890099980735993,
        0.8014225302872362
      ],
      "excerpt": "python experiments/cifar100_mt_cnn_short_n10k.py \nThe results are saved to the directories cifar10_mt_cnn_short_n4k and results/cifar100_mt_cnn_short_n10k. The plot the accuracy versus epoch, run \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8242790076618196
      ],
      "excerpt": "<img src=\"figs/N-10000_seed-11_exp-cifar100_mt_cnn_short_n10k_date-2018-06-06_01-45-02.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "fastswa_net = create_model(no_grad=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8081653686879935
      ],
      "excerpt": "For more details, see main.py. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/benathi/fastswa-semi-sup/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Shell",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "fastswa-semi-sup",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "benathi",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/benathi/fastswa-semi-sup/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 166,
      "date": "Thu, 23 Dec 2021 22:02:57 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1905.13727",
      "https://arxiv.org/abs/2102.12092",
      "https://arxiv.org/abs/1905.13727",
      "https://arxiv.org/abs/1905.13727",
      "https://arxiv.org/abs/1905.13727}\n    }"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use this code, please cite the following [paper](https://arxiv.org/abs/1905.13727)\n\n    @inproceedings{vkj2019powerSGD,\n      author = {Vogels, Thijs and Karimireddy, Sai Praneeth and Jaggi, Martin},\n      title = \"{{PowerSGD}: Practical Low-Rank Gradient Compression for Distributed Optimization}\",\n      booktitle = {NeurIPS 2019 - Advances in Neural Information Processing Systems},\n      year = 2019,\n      url = {https://arxiv.org/abs/1905.13727}\n    }\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{vkj2019powerSGD,\n  author = {Vogels, Thijs and Karimireddy, Sai Praneeth and Jaggi, Martin},\n  title = \"{{PowerSGD}: Practical Low-Rank Gradient Compression for Distributed Optimization}\",\n  booktitle = {NeurIPS 2019 - Advances in Neural Information Processing Systems},\n  year = 2019,\n  url = {https://arxiv.org/abs/1905.13727}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/epfml/powersgd",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-31T17:04:01Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-28T16:02:39Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8344612122720377
      ],
      "excerpt": "Practical Low-Rank Gradient Compression for Distributed Optimization \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9947162065899577,
        0.9503242330535924
      ],
      "excerpt": "We study gradient compression methods to alleviate the communication bottleneck in data-parallel distributed optimization. Despite the significant attention received, current compression schemes either do not scale well or fail to achieve the target test accuracy. We propose a new low-rank gradient compressor based on power iteration that can i) compress gradients rapidly, ii) efficiently aggregate the compressed gradients using all-reduce, and iii) achieve test performance on par with SGD. The proposed algorithm is the only method evaluated that achieves consistent wall-clock speedups when benchmarked against regular SGD with an optimized communication backend. We demonstrate reduced training times for convolutional networks as well as LSTMs on common datasets. \nThis repository contains research code for the experiments in the PowerSGD paper. Since version 1.8, PyTorch features a derived implementation of the algorithm as a communucation hook for DistributedDataParallel models. If you intend to use PowerSGD in a production environment, (Ramesh et al., 2021 - DALL-E) share their experiments in scaling PowerSGD to large-scale systems. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9748009799113199
      ],
      "excerpt": "Core of the PowerSGD algorithm \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8815669365430062
      ],
      "excerpt": "Hyperparameters for the experiments in the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490037945672047
      ],
      "excerpt": ": Configure the worker \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Practical low-rank gradient compression for distributed optimization:  https://arxiv.org/abs/1905.13727",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/epfml/powersgd/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 16,
      "date": "Mon, 27 Dec 2021 08:46:26 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/epfml/powersgd/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "epfml/powersgd",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.9043515116353895
      ],
      "excerpt": "train.py is the entrypoint. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9438978350240889
      ],
      "excerpt": "import train \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8307999333604473
      ],
      "excerpt": "train.config[\"n_workers\"] = 4 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8307999333604473,
        0.8307999333604473,
        0.8307999333604473,
        0.9038376386196266,
        0.9038376386196266,
        0.8307999333604473
      ],
      "excerpt": "train.config[\"optimizer_scale_lr_with_factor\"] = 4  #: workers \ntrain.config[\"optimizer_reducer\"] = \"RankKReducer\" \ntrain.config[\"optimizer_reducer_rank\"] = 4 \ntrain.config[\"optimizer_memory\"] = True \ntrain.config[\"optimizer_reducer_reuse_query\"] = True \ntrain.config[\"optimizer_reducer_n_power_iterations\"] = 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137,
        0.8589534893990137,
        0.8589534893990137,
        0.8407651001510851
      ],
      "excerpt": "train.output_dir = \"choose_a_directory\" \ntrain.log_info = your_function_pointer \ntrain.log_metric = your_metric_function_pointer \n: Start training \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/epfml/powersgd/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 EPFL Machine Learning and Optimization\\xc2\\xa0Laboratory\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "PowerSGD",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "powersgd",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "epfml",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/epfml/powersgd/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 69,
      "date": "Mon, 27 Dec 2021 08:46:26 GMT"
    },
    "technique": "GitHub API"
  }
}
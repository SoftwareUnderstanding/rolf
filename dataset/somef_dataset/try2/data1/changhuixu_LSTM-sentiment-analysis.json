{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/changhuixu/LSTM-sentiment-analysis",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-05-15T13:13:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-10-05T07:24:18Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9854373837872893,
        0.873014839267686
      ],
      "excerpt": "Due to computationly intensive of LSTM method, we only use two LSTM layes in our classifcation model. These two LSTM layes are bidirectional, which include a forwads LSTM and a backwards LSTM.  \nFeature extraction was done by reading all training reviews and tokenizing all english words, as well as removing stop words using nltk package. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9314608814058398,
        0.8282229297051305,
        0.9844877490509595
      ],
      "excerpt": "Then, you go backwards computing derivatives. This uses the cell states (what the network knows at a given point in time) to figure out how to change the network's weights. When LSTM updates cell states, we choose to use the default Adam optimizer (http://arxiv.org/abs/1412.6980v8), which is a method for Stochastic Optimization. The optimizer minimizes the loss function, which here is the mean square error between expected output and acutal output. \ninput matrix shape is (number of samples x maxlen) \nnumber_of_samples here is 25000 reviews. All reviews are transform into sequences of word vector. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9580842173248192
      ],
      "excerpt": "max_features is the dictionary size. The dictionary was created before data feed into LSTM RNN. Dictionary keys are purified words, dictionary values are the indicies, which is from 2 to 90000. Such that, the most frequent word has lowest index value. For those rarely occurred words, their indicies is large. We can use max_features to filter out uncommon words. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9784064386841504,
        0.9149615999362476
      ],
      "excerpt": "The length of sentences are right skewed (Q1:67, Median 92, Q3:152). With squence length of 150, about 75% of reviews are covered.  \nSecond, keeping the maxlen = 150, we tested the effect of max_features, which varied from 2500 to 50000. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9740133628264745,
        0.9159137186515945,
        0.9458684975317916
      ],
      "excerpt": "It is interesting to notice that the most frequently appeared 2500 english words could largely determine the sentiment of movie reviews very well. \nBritain\u2019s Guardian newspaper, in 1986, estimated the size of the average person\u2019s vocabulary as developing from roughly 300 words at two years old, through 5,000 words at five years old, to some 12,000 words at the age of 12. \nSomething that could help cut down on extraneous words is pyenchant https://pythonhosted.org/pyenchant/api/enchant.html. Basic idea is to make your input text a list of words, and fix spelling errors (or recorrect words that shouldn't belong). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "LSTM sentiment analysis. Please look at my another repo for SVM and Naive algorithem",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/changhuixu/LSTM-sentiment-analysis/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Mon, 20 Dec 2021 20:19:10 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/changhuixu/LSTM-sentiment-analysis/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "changhuixu/LSTM-sentiment-analysis",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/changhuixu/LSTM-sentiment-analysis/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "LSTM-sentiment-analysis",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "LSTM-sentiment-analysis",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "changhuixu",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/changhuixu/LSTM-sentiment-analysis/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 19,
      "date": "Mon, 20 Dec 2021 20:19:10 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "lstm",
      "review",
      "l1-lstm",
      "dictionary",
      "lstm-layes",
      "sentiment",
      "sentiment-analysis",
      "machine-learning"
    ],
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@inproceedings{XieFGY21,\n  author    = {Wanying Xie and\n               Yang Feng and\n               Shuhao Gu and\n               Dong Yu},\n  title     = {Importance-based Neuron Allocation for Multilingual Neural Machine\n               Translation},\n  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational\n               Linguistics and the 11th International Joint Conference on Natural\n               Language Processing, {ACL/IJCNLP} 2021, (Volume 1: Long Papers), Virtual\n               Event, August 1-6, 2021},\n  pages     = {5725--5737},\n  publisher = {Association for Computational Linguistics},\n  year      = {2021},\n  url       = {https://doi.org/10.18653/v1/2021.acl-long.445},\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{XieFGY21,\n  author    = {Wanying Xie and\n               Yang Feng and\n               Shuhao Gu and\n               Dong Yu},\n  title     = {Importance-based Neuron Allocation for Multilingual Neural Machine\n               Translation},\n  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational\n               Linguistics and the 11th International Joint Conference on Natural\n               Language Processing, {ACL/IJCNLP} 2021, (Volume 1: Long Papers), Virtual\n               Event, August 1-6, 2021},\n  pages     = {5725--5737},\n  publisher = {Association for Computational Linguistics},\n  year      = {2021},\n  url       = {https://doi.org/10.18653/v1/2021.acl-long.445},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.856507423580374
      ],
      "excerpt": "Source code for the ACL 2021 paper Importance-based Neuron Allocation for Multilingual Neural Machine Translation. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ictnlp/NA-MNMT",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-25T01:47:49Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-06T12:30:01Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Source code for \"Importance-based Neuron Allocation for Multilingual Neural Machine Translation\"",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://fairseq.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ictnlp/NA-MNMT/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 27 Dec 2021 02:11:42 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ictnlp/NA-MNMT/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ictnlp/NA-MNMT",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/ictnlp/NA-MNMT/tree/main/docs"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ictnlp/NA-MNMT/main/test.sh",
      "https://raw.githubusercontent.com/ictnlp/NA-MNMT/main/importanceModel.sh",
      "https://raw.githubusercontent.com/ictnlp/NA-MNMT/main/run.sh",
      "https://raw.githubusercontent.com/ictnlp/NA-MNMT/main/scripts/compound_split_bleu.sh",
      "https://raw.githubusercontent.com/ictnlp/NA-MNMT/main/scripts/sacrebleu_pregen.sh"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ictnlp/NA-MNMT/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cuda",
      "C++",
      "Cython",
      "Lua",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) Facebook, Inc. and its affiliates.\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "NA-MNMT",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "NA-MNMT",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ictnlp",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ictnlp/NA-MNMT/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This system has been tested in the following environment.\n+ OS: Ubuntu 16.04.1 LTS 64 bits\n+ Fairseq = v0.9.0 \n+ Python version \\>=3.6\n+ Pytorch version \\>=1.1\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Mon, 27 Dec 2021 02:11:42 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Preprocess the training data. Pretrain the baseline model with your data. Read [here](https://fairseq.readthedocs.io/en/latest/getting_started.html#training-a-new-model) for more instructions.\n\n- Evaluate the importance of the neurons. \n\nRun it for each language pair to calculate the importance.\n\n```\nbash importanceModel.sh\n```\n\nor\n\n```\n#:!/bin/bash \nsave_dir={checkpoints}/model.pt\nlangs=lang1,lang2,lang3,lang4 #: All languages pairs of your model such as \"en-zh,zh-en,en-ar,ar-en\"\nlang=lang1 #: Current language pair, such as \"en-zh\"\n\npython importance.py data-bin/{data} \\\n       --arch multilingual_transformer  --reset-optimizer \\\n       --encoder-langtok \"tgt\" \\\n       --task multilingual_translation --lang-pairs $langs \\\n       --share-encoders --share-decoders \\\n       --share-all-embeddings \\\n       --focus-lang $lang --fp16 \\\n       --max-tokens 2048  --save-dir $save_dir\n```\n\n- Generate mask matrix based on the importance value\n  \n```\npython importance_mask.py\n```\n  \n  \n- Fine-tuning the model with language-specific mask matrix\n\n```\nbash run.sh\n```\n\nor\n\n```\n#: !/bin/bash\nmodel={path_to_ckpt}\n#:model=test\n\npython3 train.py data-bin/{data}} \\\n    --arch multilingual_transformer \\\n    --fp16 \\\n    --encoder-langtok \"tgt\" \\\n    --restore-file /path_to_baseline/model.pt \\\n    --task multilingual_translation --lang-pairs $langs \\\n    --share-encoders --share-decoders \\\n    --share-all-embeddings --share-decoder-input-output-embed \\\n    --reset-lr-scheduler --reset-optimizer \\\n    --optimizer adam --adam-betas '(0.9, 0.98)' \\\n    --lr-scheduler inverse_sqrt --warmup-init-lr 1e-07 --warmup-updates 4000 \\\n    --lr 0.0001 --min-lr 1e-09 --ddp-backend=no_c10d \\\n    --dropout 0.1 \\\n    --weight-decay 0.0 --clip-norm 0.0 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n    --max-tokens 4096  --update-freq 2 \\\n    --no-progress-bar --log-format json --log-interval 20 \\\n    --save-dir checkpoints/$model |tee -a  logs/$model.log\n```\n\n- Generate the language-specific translation \n\n```\n#: !/bin/bash\nt=$src\nf=$tgt\ncat tst.$t-$f.$t \\\npython interactive.py $DATABIN --path $model_path \\\n        --task multilingual_translation --source-lang $t --target-lang $f \\\n        --encoder-langtok \"tgt\" \\\n        --buffer-size 2000 --lang-pairs $langs \\\n        --beam 4 --batch-size 128 --lenpen 0.6 --remove-bpe \\\n        --log-format=none > $OUT_DIR/tst.$t-$f\n```\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
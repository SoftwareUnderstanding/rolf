{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you used this code for your experiments or found it helpful, consider citing the following paper:\n\n<pre>\n@article{lowe2017multi,\n  title={Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},\n  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, Pieter and Mordatch, Igor},\n  journal={Neural Information Processing Systems (NIPS)},\n  year={2017}\n}\n</pre>\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{lowe2017multi,\n  title={Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},\n  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, Pieter and Mordatch, Igor},\n  journal={Neural Information Processing Systems (NIPS)},\n  year={2017}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9055392137394023
      ],
      "excerpt": "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "Multi-Agent Particle Environments (MPE). \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/openai/maddpg",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-02-01T18:59:57Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T01:34:02Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9735328731964357
      ],
      "excerpt": "This is the code for implementing the MADDPG algorithm presented in the paper: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8885757693932431
      ],
      "excerpt": "It is configured to be run in conjunction with environments from the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9510621847804078,
        0.9060126810812599,
        0.8006244667535797
      ],
      "excerpt": "Update: the original implementation for policy ensemble and policy estimation can be found here. The code is provided as-is. \n--scenario: defines which environment in the MPE is to be used (default: \"simple\") \n--max-episode-len maximum length of each episode for the environment (default: 25) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8377727436973745
      ],
      "excerpt": "--good-policy: algorithm used for the 'good' (non adversary) policies in the environment \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.823479930573625
      ],
      "excerpt": "--adv-policy: algorithm used for the adversary policies in the environment \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8485164617957005
      ],
      "excerpt": "--save-rate: model is saved every time this number of episodes has been completed (default: 1000) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8536618068755993
      ],
      "excerpt": "./maddpg/trainer/maddpg.py: core code for the MADDPG algorithm \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code for the MADDPG algorithm from the paper \"Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments\"",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/openai/maddpg/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 348,
      "date": "Sat, 25 Dec 2021 07:17:07 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/openai/maddpg/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "openai/maddpg",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- To install, `cd` into the root directory and type `pip install -e .`\n\n- Known dependencies: Python (3.5.4), OpenAI gym (0.10.5), tensorflow (1.8.0), numpy (1.14.5)\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9125972967524477
      ],
      "excerpt": "--num-episodes total number of training episodes (default: 60000) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8002581981698412
      ],
      "excerpt": "(default: \"maddpg\"; options: {\"maddpg\", \"ddpg\"}) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8002581981698412
      ],
      "excerpt": "(default: \"maddpg\"; options: {\"maddpg\", \"ddpg\"}) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9043228032138015,
        0.8307971650204694
      ],
      "excerpt": "--exp-name: name of the experiment, used as the file name to save all results (default: None) \n--save-dir: directory where intermediate training results and model will be saved (default: \"/tmp/policy/\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8021161629282147
      ],
      "excerpt": "--load-dir: directory where training state and model are loaded from (default: \"\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8119783540648179,
        0.831042181780497
      ],
      "excerpt": "--plots-dir: directory where training curves are saved (default: \"./learning_curves/\") \n./experiments/train.py: contains code for training MADDPG on the MPE \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8161837711272321
      ],
      "excerpt": "./maddpg/trainer/replay_buffer.py: replay buffer code for MADDPG \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/openai/maddpg/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Multi-Agent Deep Deterministic Policy Gradient (MADDPG)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "maddpg",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "openai",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/openai/maddpg/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 942,
      "date": "Sat, 25 Dec 2021 07:17:07 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We demonstrate here how the code can be used in conjunction with the\n[Multi-Agent Particle Environments (MPE)](https://github.com/openai/multiagent-particle-envs).\n\n- Download and install the MPE code [here](https://github.com/openai/multiagent-particle-envs)\nby following the `README`.\n\n- Ensure that `multiagent-particle-envs` has been added to your `PYTHONPATH` (e.g. in `~/.bashrc` or `~/.bash_profile`).\n\n- To run the code, `cd` into the `experiments` directory and run `train.py`:\n\n``python train.py --scenario simple``\n\n- You can replace `simple` with any environment in the MPE you'd like to run.\n\n",
      "technique": "Header extraction"
    }
  ],
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "paper"
    ],
    "technique": "GitHub API"
  }
}
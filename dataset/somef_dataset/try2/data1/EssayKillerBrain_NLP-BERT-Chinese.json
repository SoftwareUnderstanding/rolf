{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1810.04805\n\n\n## \u4e00\u3001\u4ec0\u4e48\u662fBERT\u6a21\u578b\uff1f\n\n\u6700\u8fd1\u8c37\u6b4c\u641e\u4e86\u4e2a\u5927\u65b0\u95fb\uff0c\u516c\u53f8AI\u56e2\u961f\u65b0\u53d1\u5e03\u7684BERT\u6a21\u578b\uff0c\u5728\u673a\u5668\u9605\u8bfb\u7406\u89e3\u9876\u7ea7\u6c34\u5e73\u6d4b\u8bd5SQuAD1.1\u4e2d\u8868\u73b0\u51fa\u60ca\u4eba\u7684\u6210\u7ee9\uff1a\u5168\u90e8\u4e24\u4e2a\u8861\u91cf\u6307\u6807\u4e0a\u5168\u9762\u8d85\u8d8a\u4eba\u7c7b\uff0c\u5e76\u4e14\u8fd8\u572811\u79cd\u4e0d\u540cNLP\u6d4b\u8bd5\u4e2d\u521b\u51fa\u6700\u4f73\u6210\u7ee9\uff0c\u5305\u62ec\u5c06GLUE\u57fa\u51c6\u63a8\u81f380.4\uff05\uff08\u7edd\u5bf9\u6539\u8fdb7.6\uff05\uff09\uff0cMultiNLI\u51c6\u786e\u5ea6\u8fbe\u523086.7% \uff08\u7edd\u5bf9\u6539\u8fdb\u73875.6\uff05\uff09\u7b49\u3002\u53ef\u4ee5\u9884\u89c1\u7684\u662f\uff0cBERT\u5c06\u4e3aNLP\u5e26\u6765\u91cc\u7a0b\u7891\u5f0f\u7684\u6539\u53d8\uff0c\u4e5f\u662fNLP\u9886\u57df\u8fd1\u671f\u6700\u91cd\u8981\u7684\u8fdb\u5c55\u3002  \n<div align=center><img width=\"400\" height=\"450\" src=\"https://img-blog.csdn.net/20181021135223575?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTIxNTU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"/></div>\n\n\u8c37\u6b4c\u56e2\u961f\u7684Thang Luong\u76f4\u63a5\u5b9a\u4e49\uff1aBERT\u6a21\u578b\u5f00\u542f\u4e86NLP\u7684\u65b0\u65f6\u4ee3    \n\n<div align=center><img width=\"450\" height=\"350\" src=\"https://img-blog.csdn.net/20181021135254746?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTIxNTU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"/></div>\n\n\n\u4ece\u73b0\u5728\u7684\u5927\u8d8b\u52bf\u6765\u770b\uff0c\u4f7f\u7528\u67d0\u79cd\u6a21\u578b\u9884\u8bad\u7ec3\u4e00\u4e2a\u8bed\u8a00\u6a21\u578b\u770b\u8d77\u6765\u662f\u4e00\u79cd\u6bd4\u8f83\u9760\u8c31\u7684\u65b9\u6cd5\u3002\u4ece\u4e4b\u524dAI2\u7684 ELMo\uff0c\u5230 OpenAI\u7684fine-tune transformer\uff0c\u518d\u5230Google\u7684\u8fd9\u4e2aBERT\uff0c\u5168\u90fd\u662f\u5bf9\u9884\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\u7684\u5e94\u7528\u3002\n\nBERT\u8fd9\u4e2a\u6a21\u578b\u4e0e\u5176\u5b83\u4e24\u4e2a\u4e0d\u540c\u7684\u662f\uff0c\u5b83\u5728\u8bad\u7ec3\u53cc\u5411\u8bed\u8a00\u6a21\u578b\u65f6\u4ee5\u51cf\u5c0f\u7684\u6982\u7387\u628a\u5c11\u91cf\u7684\u8bcd\u66ff\u6210\u4e86Mask\u6216\u8005\u53e6\u4e00\u4e2a\u968f\u673a\u7684\u8bcd\u3002\u6211\u4e2a\u4eba\u611f\u89c9\u8fd9\u4e2a\u76ee\u7684\u5728\u4e8e\u4f7f\u6a21\u578b\u88ab\u8feb\u589e\u52a0\u5bf9\u4e0a\u4e0b\u6587\u7684\u8bb0\u5fc6\u3002\u81f3\u4e8e\u8fd9\u4e2a\u6982\u7387\uff0c\u6211\u731c\u662fJacob\u62cd\u8111\u888b\u968f\u4fbf\u8bbe\u7684\u3002\u589e\u52a0\u4e86\u4e00\u4e2a\u9884\u6d4b\u4e0b\u4e00\u53e5\u7684loss\u3002\u8fd9\u4e2a\u770b\u8d77\u6765\u5c31\u6bd4\u8f83\u65b0\u5947\u4e86\u3002\n\n### BERT\u6a21\u578b\u5177\u6709\u4ee5\u4e0b\u4e24\u4e2a\u7279\u70b9\uff1a\n\n\u7b2c\u4e00\uff0c\u662f\u8fd9\u4e2a\u6a21\u578b\u975e\u5e38\u7684\u6df1\uff0c12\u5c42\uff0c\u5e76\u4e0d\u5bbd(wide\uff09\uff0c\u4e2d\u95f4\u5c42\u53ea\u67091024\uff0c\u800c\u4e4b\u524d\u7684Transformer\u6a21\u578b\u4e2d\u95f4\u5c42\u67092048\u3002\u8fd9\u4f3c\u4e4e\u53c8\u5370\u8bc1\u4e86\u8ba1\u7b97\u673a\u56fe\u50cf\u5904\u7406\u7684\u4e00\u4e2a\u89c2\u70b9\u2014\u2014\u6df1\u800c\u7a84 \u6bd4 \u6d45\u800c\u5bbd \u7684\u6a21\u578b\u66f4\u597d\u3002\n\n\u7b2c\u4e8c\uff0cMLM\uff08Masked Language Model\uff09\uff0c\u540c\u65f6\u5229\u7528\u5de6\u4fa7\u548c\u53f3\u4fa7\u7684\u8bcd\u8bed\uff0c\u8fd9\u4e2a\u5728ELMo\u4e0a\u5df2\u7ecf\u51fa\u73b0\u4e86\uff0c\u7edd\u5bf9\u4e0d\u662f\u539f\u521b\u3002\u5176\u6b21\uff0c\u5bf9\u4e8eMask\uff08\u906e\u6321\uff09\u5728\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5e94\u7528\uff0c\u5df2\u7ecf\u88abZiang Xie\u63d0\u51fa\u4e86\uff08\u6211\u5f88\u6709\u5e78\u7684\u4e5f\u53c2\u4e0e\u5230\u4e86\u8fd9\u7bc7\u8bba\u6587\u4e2d\uff09\uff1a[1703.02573] Data Noising as Smoothing in Neural Network Language Models\u3002\u8fd9\u4e5f\u662f\u7bc7\u5de8\u661f\u4e91\u96c6\u7684\u8bba\u6587\uff1aSida Wang\uff0cJiwei Li\uff08\u9999\u4fac\u79d1\u6280\u7684\u521b\u59cb\u4eba\u517cCEO\u517c\u53f2\u4e0a\u53d1\u6587\u6700\u591a\u7684NLP\u5b66\u8005\uff09\uff0cAndrew Ng\uff0cDan Jurafsky\u90fd\u662fCoauthor\u3002\u4f46\u5f88\u53ef\u60dc\u7684\u662f\u4ed6\u4eec\u6ca1\u6709\u5173\u6ce8\u5230\u8fd9\u7bc7\u8bba\u6587\u3002\u7528\u8fd9\u7bc7\u8bba\u6587\u7684\u65b9\u6cd5\u53bb\u505aMasking\uff0c\u76f8\u4fe1BRET\u7684\u80fd\u529b\u8bf4\u4e0d\u5b9a\u8fd8\u4f1a\u6709\u63d0\u5347\u3002\n\n\n\u90e8\u5206\u4ee3\u7801\u57fa\u4e8e [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9537267708315463
      ],
      "excerpt": "Junseong Kim, Scatter Lab (codertimo@gmail.com / junseong.kim@scatter.co.kr) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9945713194286558,
        0.9229923602250443
      ],
      "excerpt": "Copyright 2018 Junseong Kim, Scatter Lab, respective BERT contributors \nCopyright (c) 2018 Alexander Rush : The Annotated Trasnformer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9997706017152777
      ],
      "excerpt": "Paper URL : https://arxiv.org/abs/1810.04805 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9964189199332645
      ],
      "excerpt": "\u901a\u5e38\u60c5\u51b5 transformer \u6a21\u578b\u6709\u5f88\u591a\u53c2\u6570\u9700\u8981\u8bad\u7ec3\u3002\u8b6c\u5982 BERT BASE \u6a21\u578b: L=12, H=768, A=12, \u9700\u8981\u8bad\u7ec3\u7684\u6a21\u578b\u53c2\u6570\u603b\u6570\u662f 12 * 768 * 12 = 110M\u3002\u8fd9\u4e48\u591a\u53c2\u6570\u9700\u8981\u8bad\u7ec3\uff0c\u81ea\u7136\u9700\u8981\u6d77\u91cf\u7684\u8bad\u7ec3\u8bed\u6599\u3002\u5982\u679c\u5168\u90e8\u7528\u4eba\u529b\u6807\u6ce8\u7684\u529e\u6cd5\uff0c\u6765\u5236\u4f5c\u8bad\u7ec3\u6570\u636e\uff0c\u4eba\u529b\u6210\u672c\u592a\u5927\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9614442731800593
      ],
      "excerpt": "BERT\u7684\u6a21\u578b\u67b6\u6784\u662f\u57fa\u4e8eVaswani et al. (2017) \u4e2d\u63cf\u8ff0\u7684\u539f\u59cb\u5b9e\u73b0multi-layer bidirectional Transformer\u7f16\u7801\u5668\uff0c\u5e76\u5728tensor2tensor\u5e93\u4e2d\u53d1\u5e03\u3002\u7531\u4e8eTransformer\u7684\u4f7f\u7528\u6700\u8fd1\u53d8\u5f97\u65e0\u5904\u4e0d\u5728\uff0c\u8bba\u6587\u4e2d\u7684\u5b9e\u73b0\u4e0e\u539f\u59cb\u5b9e\u73b0\u5b8c\u5168\u76f8\u540c\uff0c\u56e0\u6b64\u8fd9\u91cc\u5c06\u7701\u7565\u5bf9\u6a21\u578b\u7ed3\u6784\u7684\u8be6\u7ec6\u63cf\u8ff0\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906174419333412
      ],
      "excerpt": "* BERT_{BASE} : L=12, H=768, A=12, Total Parameters=110M \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9988872982591002
      ],
      "excerpt": "\u4f7f\u7528WordPiece\u5d4c\u5165\uff08Wu et al., 2016\uff09\u548c30,000\u4e2atoken\u7684\u8bcd\u6c47\u8868\u3002\u7528##\u8868\u793a\u5206\u8bcd\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9998944008055906
      ],
      "excerpt": "\u4e0ePeters et al. (2018) \u548c Radford et al. (2018)\u4e0d\u540c\uff0c\u8bba\u6587\u4e0d\u4f7f\u7528\u4f20\u7edf\u7684\u4ece\u5de6\u5230\u53f3\u6216\u4ece\u53f3\u5230\u5de6\u7684\u8bed\u8a00\u6a21\u578b\u6765\u9884\u8bad\u7ec3BERT\u3002\u76f8\u53cd\uff0c\u4f7f\u7528\u4e24\u4e2a\u65b0\u7684\u65e0\u76d1\u7763\u9884\u6d4b\u4efb\u52a1\u5bf9BERT\u8fdb\u884c\u9884\u8bad\u7ec3\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9440952840704602
      ],
      "excerpt": "\u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0c\u4e0emasked token\u5bf9\u5e94\u7684\u6700\u7ec8\u9690\u85cf\u5411\u91cf\u88ab\u8f93\u5165\u5230\u8bcd\u6c47\u8868\u4e0a\u7684\u8f93\u51fasoftmax\u4e2d\uff0c\u5c31\u50cf\u5728\u6807\u51c6LM\u4e2d\u4e00\u6837\u3002\u5728\u56e2\u961f\u6240\u6709\u5b9e\u9a8c\u4e2d\uff0c\u968f\u673a\u5730\u5c4f\u853d\u4e86\u6bcf\u4e2a\u5e8f\u5217\u4e2d15%\u7684WordPiece token\u3002\u4e0e\u53bb\u566a\u7684\u81ea\u52a8\u7f16\u7801\u5668\uff08Vincent et al.\uff0c 2008\uff09\u76f8\u53cd\uff0c\u53ea\u9884\u6d4bmasked words\u800c\u4e0d\u662f\u91cd\u5efa\u6574\u4e2a\u8f93\u5165\u3002 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/EssayKillerBrain/NLP-BERT-Chinese",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-28T16:15:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-30T11:06:07Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9330547216830019
      ],
      "excerpt": "Notice: This is only For the convinience of Chineses reader who cannot read English version directly \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8332418943662542
      ],
      "excerpt": "This project following Apache 2.0 License as written in LICENSE file \u672c\u9879\u76ee\u57fa\u4e8eApache2.0\u534f\u8bae \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9380176467946056,
        0.8451720178895493
      ],
      "excerpt": "Pytorch implementation of Google AI's 2018 BERT, with simple annotation \nBERT 2018 BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8933033163409319,
        0.8490037945672047
      ],
      "excerpt": "\u7b2c\u4e8c\uff0cMLM\uff08Masked Language Model\uff09\uff0c\u540c\u65f6\u5229\u7528\u5de6\u4fa7\u548c\u53f3\u4fa7\u7684\u8bcd\u8bed\uff0c\u8fd9\u4e2a\u5728ELMo\u4e0a\u5df2\u7ecf\u51fa\u73b0\u4e86\uff0c\u7edd\u5bf9\u4e0d\u662f\u539f\u521b\u3002\u5176\u6b21\uff0c\u5bf9\u4e8eMask\uff08\u906e\u6321\uff09\u5728\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5e94\u7528\uff0c\u5df2\u7ecf\u88abZiang Xie\u63d0\u51fa\u4e86\uff08\u6211\u5f88\u6709\u5e78\u7684\u4e5f\u53c2\u4e0e\u5230\u4e86\u8fd9\u7bc7\u8bba\u6587\u4e2d\uff09\uff1a[1703.02573] Data Noising as Smoothing in Neural Network Language Models\u3002\u8fd9\u4e5f\u662f\u7bc7\u5de8\u661f\u4e91\u96c6\u7684\u8bba\u6587\uff1aSida Wang\uff0cJiwei Li\uff08\u9999\u4fac\u79d1\u6280\u7684\u521b\u59cb\u4eba\u517cCEO\u517c\u53f2\u4e0a\u53d1\u6587\u6700\u591a\u7684NLP\u5b66\u8005\uff09\uff0cAndrew Ng\uff0cDan Jurafsky\u90fd\u662fCoauthor\u3002\u4f46\u5f88\u53ef\u60dc\u7684\u662f\u4ed6\u4eec\u6ca1\u6709\u5173\u6ce8\u5230\u8fd9\u7bc7\u8bba\u6587\u3002\u7528\u8fd9\u7bc7\u8bba\u6587\u7684\u65b9\u6cd5\u53bb\u505aMasking\uff0c\u76f8\u4fe1BRET\u7684\u80fd\u529b\u8bf4\u4e0d\u5b9a\u8fd8\u4f1a\u6709\u63d0\u5347\u3002 \n\u90e8\u5206\u4ee3\u7801\u57fa\u4e8e The Annotated Transformer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8702593868056067
      ],
      "excerpt": "\u53d7\u300aA Neural Probabilistic Language Model\u300b\u8bba\u6587\u7684\u542f\u53d1\uff0cBERT \u4e5f\u7528 unsupervised \u7684\u529e\u6cd5\uff0c\u6765\u8bad\u7ec3 transformer \u6a21\u578b\u3002\u795e\u7ecf\u6982\u7387\u8bed\u8a00\u6a21\u578b\u8fd9\u7bc7\u8bba\u6587\uff0c\u4e3b\u8981\u8bb2\u4e86\u4e24\u4ef6\u4e8b\u513f\uff0c1. \u80fd\u5426\u7528\u6570\u503c\u5411\u91cf\uff08word vector\uff09\u6765\u8868\u8fbe\u81ea\u7136\u8bed\u8a00\u8bcd\u6c47\u7684\u8bed\u4e49\uff1f2. \u5982\u4f55\u7ed9\u6bcf\u4e2a\u8bcd\u6c47\uff0c\u627e\u5230\u6070\u5f53\u7684\u6570\u503c\u5411\u91cf\uff1f \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8536747530384059
      ],
      "excerpt": "\u6a21\u578b\u53c2\u6570\u6570\u91cf\u8fd9\u4e48\u5927\uff0c\u5fc5\u7136\u9700\u8981\u6d77\u91cf\u7684\u8bad\u7ec3\u8bed\u6599\u3002\u4ece\u54ea\u91cc\u6536\u96c6\u8fd9\u4e9b\u6d77\u91cf\u7684\u8bad\u7ec3\u8bed\u6599\uff1f\u300aA Neural Probabilistic Language Model\u300b\u8fd9\u7bc7\u8bba\u6587\u8bf4\uff0c\u6bcf\u4e00\u7bc7\u6587\u7ae0\uff0c\u5929\u751f\u662f\u8bad\u7ec3\u8bed\u6599\u3002\u96be\u9053\u4e0d\u9700\u8981\u4eba\u5de5\u6807\u6ce8\u5417\uff1f\u56de\u7b54\uff0c\u4e0d\u9700\u8981\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8997136122614414,
        0.9081259796837968,
        0.8108008689666927
      ],
      "excerpt": "\u300aA Neural Probabilistic Language Model\u300b\u8fd9\u7bc7\u8bba\u6587\u8bb2\u7684 Language Model\uff0c\u4e25\u683c\u8bb2\u662f\u8bed\u8a00\u751f\u6210\u6a21\u578b\uff08Language Generative Model\uff09\uff0c\u9884\u6d4b\u8bed\u53e5\u4e2d\u4e0b\u4e00\u4e2a\u5c06\u4f1a\u51fa\u73b0\u7684\u8bcd\u6c47\u3002\u8bed\u8a00\u751f\u6210\u6a21\u578b\u80fd\u4e0d\u80fd\u76f4\u63a5\u79fb\u7528\u5230\u5176\u5b83 NLP \u95ee\u9898\u4e0a\u53bb\uff1f\u8b6c\u5982\uff0c\u6dd8\u5b9d\u4e0a\u6709\u5f88\u591a\u7528\u6237\u8bc4\u8bba\uff0c\u80fd\u5426\u628a\u6bcf\u4e00\u6761\u7528\u6237\u8f6c\u6362\u6210\u8bc4\u5206\uff1f-2\u3001-1\u30010\u30011\u30012\uff0c\u5176\u4e2d -2 \u662f\u6781\u5dee\uff0c+2 \u662f\u6781\u597d\u3002\u5047\u5982\u6709\u8fd9\u6837\u4e00\u6761\u7528\u6237\u8bc4\u8bed\uff0c\u201c\u4e70\u4e86\u4e00\u4ef6\u9e7f\u6657\u540c\u6b3e\u886c\u886b\uff0c\u6ca1\u60f3\u5230\uff0c\u7a7f\u5728\u81ea\u5df1\u8eab\u4e0a\uff0c\u4e0d\u50cf\u5c0f\u9c9c\u8089\uff0c\u5012\u50cf\u662f\u53a8\u5e08\u201d\uff0c\u8bf7\u95ee\u8fd9\u6761\u8bc4\u8bed\uff0c\u7b49\u540c\u4e8e -2\uff0c\u8fd8\u662f\u5176\u5b83\uff1f \n\u8bed\u8a00\u751f\u6210\u6a21\u578b\uff0c\u80fd\u4e0d\u80fd\u5f88\u597d\u5730\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff1f\u8fdb\u4e00\u6b65\u95ee\uff0c\u6709\u6ca1\u6709 \u201c\u901a\u7528\u7684\u201d \u8bed\u8a00\u6a21\u578b\uff0c\u80fd\u591f\u7406\u89e3\u8bed\u8a00\u7684\u8bed\u4e49\uff0c\u9002\u7528\u4e8e\u5404\u79cd NLP \u95ee\u9898\uff1fBERT \u8fd9\u7bc7\u8bba\u6587\u7684\u9898\u76ee\u5f88\u76f4\u767d\uff0c\u300aBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\u300b\uff0c\u4e00\u773c\u770b\u53bb\uff0c\u5c31\u80fd\u731c\u5f97\u5230\u8fd9\u7bc7\u6587\u7ae0\u4f1a\u8bb2\u54ea\u4e9b\u5185\u5bb9\u3002 \n\u8fd9\u4e2a\u9898\u76ee\u6709\u4e94\u4e2a\u5173\u952e\u8bcd\uff0c\u5206\u522b\u662f Pre-training\u3001Deep\u3001Bidirectional\u3001Transformers\u3001\u548c Language Understanding\u3002\u5176\u4e2d pre-training \u7684\u610f\u601d\u662f\uff0c\u4f5c\u8005\u8ba4\u4e3a\uff0c\u786e\u5b9e\u5b58\u5728\u901a\u7528\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u5148\u7528\u6587\u7ae0\u9884\u8bad\u7ec3\u901a\u7528\u6a21\u578b\uff0c\u7136\u540e\u518d\u6839\u636e\u5177\u4f53\u5e94\u7528\uff0c\u7528 supervised \u8bad\u7ec3\u6570\u636e\uff0c\u7cbe\u52a0\u5de5\uff08fine tuning\uff09\u6a21\u578b\uff0c\u4f7f\u4e4b\u9002\u7528\u4e8e\u5177\u4f53\u5e94\u7528\u3002\u4e3a\u4e86\u533a\u522b\u4e8e\u9488\u5bf9\u8bed\u8a00\u751f\u6210\u7684 Language Model\uff0c\u4f5c\u8005\u7ed9\u901a\u7528\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u53d6\u4e86\u4e00\u4e2a\u540d\u5b57\uff0c\u53eb\u8bed\u8a00\u8868\u5f81\u6a21\u578b Language Representation Model\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8847653613616269
      ],
      "excerpt": "BERT \u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u9884\u8bad\u7ec3\u76ee\u6807\uff1a\u906e\u853d\u8bed\u8a00\u6a21\u578b\uff08masked language model\uff0cMLM\uff09\uff0c\u6765\u514b\u670d\u4e0a\u6587\u63d0\u5230\u7684\u5355\u5411\u6027\u5c40\u9650\u3002MLM \u7684\u7075\u611f\u6765\u81ea Cloze \u4efb\u52a1\uff08Taylor, 1953\uff09\u3002MLM \u968f\u673a\u906e\u853d\u6a21\u578b\u8f93\u5165\u4e2d\u7684\u4e00\u4e9b token\uff0c\u76ee\u6807\u5728\u4e8e\u4ec5\u57fa\u4e8e\u906e\u853d\u8bcd\u7684\u8bed\u5883\u6765\u9884\u6d4b\u5176\u539f\u59cb\u8bcd\u6c47 id\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9177542225650669
      ],
      "excerpt": "\u4ece\u76f4\u89c9\u4e0a\u770b\uff0c\u7814\u7a76\u56e2\u961f\u6709\u7406\u7531\u76f8\u4fe1\uff0c\u6df1\u5ea6\u53cc\u5411\u6a21\u578b\u6bd4left-to-right \u6a21\u578b\u6216left-to-right and right-to-left\u6a21\u578b\u7684\u6d45\u5c42\u8fde\u63a5\u66f4\u5f3a\u5927\u3002\u9057\u61be\u7684\u662f\uff0c\u6807\u51c6\u6761\u4ef6\u8bed\u8a00\u6a21\u578b\u53ea\u80fd\u4ece\u5de6\u5230\u53f3\u6216\u4ece\u53f3\u5230\u5de6\u8fdb\u884c\u8bad\u7ec3\uff0c\u56e0\u4e3a\u53cc\u5411\u6761\u4ef6\u4f5c\u7528\u5c06\u5141\u8bb8\u6bcf\u4e2a\u5355\u8bcd\u5728\u591a\u5c42\u4e0a\u4e0b\u6587\u4e2d\u95f4\u63a5\u5730\u201csee itself\u201d\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8709777459247952,
        0.8336901183739936,
        0.8336901183739936
      ],
      "excerpt": "80\uff05\u7684\u65f6\u95f4\uff1a\u7528[MASK]\u6807\u8bb0\u66ff\u6362\u5355\u8bcd\uff0c\u4f8b\u5982\uff0cmy dog is hairy \u2192 my dog is [MASK] \n10\uff05\u7684\u65f6\u95f4\uff1a\u7528\u4e00\u4e2a\u968f\u673a\u7684\u5355\u8bcd\u66ff\u6362\u8be5\u5355\u8bcd\uff0c\u4f8b\u5982\uff0cmy dog is hairy \u2192 my dog is apple \n10\uff05\u7684\u65f6\u95f4\uff1a\u4fdd\u6301\u5355\u8bcd\u4e0d\u53d8\uff0c\u4f8b\u5982\uff0cmy dog is hairy \u2192 my dog is hairy. \u8fd9\u6837\u505a\u7684\u76ee\u7684\u662f\u5c06\u8868\u793a\u504f\u5411\u4e8e\u5b9e\u9645\u89c2\u5bdf\u5230\u7684\u5355\u8bcd\u3002   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9615971488755714,
        0.9270316931984927,
        0.9978285840856607,
        0.9677434464077148,
        0.860059181823877
      ],
      "excerpt": "BERT\u662f\u4e00\u4e2a\u8bed\u8a00\u8868\u5f81\u6a21\u578b\uff08language representation model\uff09\uff0c\u901a\u8fc7\u8d85\u5927\u6570\u636e\u3001\u5de8\u5927\u6a21\u578b\u3001\u548c\u6781\u5927\u7684\u8ba1\u7b97\u5f00\u9500\u8bad\u7ec3\u800c\u6210\uff0c\u572811\u4e2a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6700\u4f18\uff08state-of-the-art, SOTA\uff09\u7ed3\u679c\u3002\u6216\u8bb8\u4f60\u5df2\u7ecf\u731c\u5230\u4e86\u6b64\u6a21\u578b\u51fa\u81ea\u4f55\u65b9\uff0c\u6ca1\u9519\uff0c\u5b83\u4ea7\u81ea\u8c37\u6b4c\u3002\u4f30\u8ba1\u4e0d\u5c11\u4eba\u4f1a\u8c03\u4f83\u8fd9\u79cd\u89c4\u6a21\u7684\u5b9e\u9a8c\u5df2\u7ecf\u57fa\u672c\u8ba9\u4e00\u822c\u7684\u5b9e\u9a8c\u5ba4\u548c\u7814\u7a76\u5458\u671b\u5c18\u83ab\u53ca\u4e86\uff0c\u4f46\u5b83\u786e\u5b9e\u7ed9\u6211\u4eec\u63d0\u4f9b\u4e86\u5f88\u591a\u5b9d\u8d35\u7684\u7ecf\u9a8c\uff1a \n\u6df1\u5ea6\u5b66\u4e60\u5c31\u662f\u8868\u5f81\u5b66\u4e60 \uff08Deep learning is representation learning\uff09\uff1a\"We show that pre-trained representations eliminate the needs of many heavily engineered task-specific architectures\". \u572811\u9879BERT\u5237\u51fa\u65b0\u5883\u754c\u7684\u4efb\u52a1\u4e2d\uff0c\u5927\u591a\u53ea\u5728\u9884\u8bad\u7ec3\u8868\u5f81\uff08pre-trained representation\uff09\u5fae\u8c03\uff08fine-tuning\uff09\u7684\u57fa\u7840\u4e0a\u52a0\u4e00\u4e2a\u7ebf\u6027\u5c42\u4f5c\u4e3a\u8f93\u51fa\uff08linear output layer\uff09\u3002\u5728\u5e8f\u5217\u6807\u6ce8\u7684\u4efb\u52a1\u91cc\uff08e.g. NER\uff09\uff0c\u751a\u81f3\u8fde\u5e8f\u5217\u8f93\u51fa\u7684\u4f9d\u8d56\u5173\u7cfb\u90fd\u5148\u4e0d\u7ba1\uff08i.e. non-autoregressive and no CRF\uff09\uff0c\u7167\u6837\u79d2\u6740\u4e4b\u524d\u7684SOTA\uff0c\u53ef\u89c1\u5176\u8868\u5f81\u5b66\u4e60\u80fd\u529b\u4e4b\u5f3a\u5927\u3002 \n\u89c4\u6a21\u5f88\u91cd\u8981\uff08Scale matters\uff09\uff1a\"One of our core claims is that the deep bidirectionality of BERT, which is enabled by masked LM pre-training, is the single most important improvement of BERT compared to previous work\". \u8fd9\u79cd\u906e\u6321\uff08mask\uff09\u5728\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5e94\u7528\u5bf9\u5f88\u591a\u4eba\u6765\u8bf4\u5df2\u7ecf\u4e0d\u65b0\u9c9c\u4e86\uff0c\u4f46\u786e\u662fBERT\u7684\u4f5c\u8005\u5728\u5982\u6b64\u8d85\u5927\u89c4\u6a21\u7684\u6570\u636e+\u6a21\u578b+\u7b97\u529b\u7684\u57fa\u7840\u4e0a\u9a8c\u8bc1\u4e86\u5176\u5f3a\u5927\u7684\u8868\u5f81\u5b66\u4e60\u80fd\u529b\u3002\u8fd9\u6837\u7684\u6a21\u578b\uff0c\u751a\u81f3\u53ef\u4ee5\u5ef6\u4f38\u5230\u5f88\u591a\u5176\u4ed6\u7684\u6a21\u578b\uff0c\u53ef\u80fd\u4e4b\u524d\u90fd\u88ab\u4e0d\u540c\u7684\u5b9e\u9a8c\u5ba4\u63d0\u51fa\u548c\u8bd5\u9a8c\u8fc7\uff0c\u53ea\u662f\u7531\u4e8e\u89c4\u6a21\u7684\u5c40\u9650\u6ca1\u80fd\u5145\u5206\u6316\u6398\u8fd9\u4e9b\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u800c\u9057\u61be\u5730\u8ba9\u5b83\u4eec\u88ab\u6df9\u6ca1\u5728\u4e86\u6eda\u6eda\u7684paper\u6d2a\u6d41\u4e4b\u4e2d\u3002 \n\u9884\u8bad\u7ec3\u4ef7\u503c\u5f88\u5927\uff08Pre-training is important\uff09\uff1a\"We believe that this is the first work to demonstrate that scaling to extreme model sizes also leads to large improvements on very small-scale tasks, provided that the model has been sufficiently pre-trained\". \u9884\u8bad\u7ec3\u5df2\u7ecf\u88ab\u5e7f\u6cdb\u5e94\u7528\u5728\u5404\u4e2a\u9886\u57df\u4e86\uff08e.g. ImageNet for CV, Word2Vec in NLP\uff09\uff0c\u591a\u662f\u901a\u8fc7\u5927\u6a21\u578b\u5927\u6570\u636e\uff0c\u8fd9\u6837\u7684\u5927\u6a21\u578b\u7ed9\u5c0f\u89c4\u6a21\u4efb\u52a1\u80fd\u5e26\u6765\u7684\u63d0\u5347\u6709\u51e0\u4f55\uff0c\u4f5c\u8005\u4e5f\u7ed9\u51fa\u4e86\u81ea\u5df1\u7684\u7b54\u6848\u3002BERT\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u662f\u7528Transformer\u505a\u7684\uff0c\u4f46\u6211\u60f3\u6362\u505aLSTM\u6216\u8005GRU\u7684\u8bdd\u5e94\u8be5\u4e0d\u4f1a\u6709\u592a\u5927\u6027\u80fd\u4e0a\u7684\u5dee\u522b\uff0c\u5f53\u7136\u8bad\u7ec3\u8ba1\u7b97\u65f6\u7684\u5e76\u884c\u80fd\u529b\u5c31\u53e6\u5f53\u522b\u8bba\u4e86\u3002 \nmodel Tutorial \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8580138204279316
      ],
      "excerpt": "Welcome to the \\t the jungle\\n \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9454074460813625
      ],
      "excerpt": "or tokenized corpus (tokenization is not in package) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.809504647691836
      ],
      "excerpt": "bert-vocab -c data/corpus.small -o data/vocab.small \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9327025247518362,
        0.9385357652340618
      ],
      "excerpt": "In the paper, authors shows the new language model training methods,  \nwhich are \"masked language model\" and \"predict next sentence\". \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9266906915093617
      ],
      "excerpt": "Randomly 15% of input token will be changed into something, based on under sub-rules\uff1a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.924807497248963,
        0.823206699190029
      ],
      "excerpt": "Input : [CLS] the man went to the store [SEP] he bought a gallon of milk [SEP] \nLabel : Is Next \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/EssayKillerBrain/NLP-BERT-Chinese/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Sun, 26 Dec 2021 13:38:48 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/EssayKillerBrain/NLP-BERT-Chinese/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "EssayKillerBrain/NLP-BERT-Chinese",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9029048463607832
      ],
      "excerpt": "Environment require: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233588558014837
      ],
      "excerpt": "               ---numpy  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9822265678149505
      ],
      "excerpt": "This version has based on the version in https://github.com/codertimo/BERT-pytorch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9995486579735738
      ],
      "excerpt": "pip install bert-pytorch \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8607660469287802
      ],
      "excerpt": "<div align=center><img width=\"400\" height=\"450\" src=\"https://img-blog.csdn.net/20181021135223575?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTIxNTU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"/></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8555043679871546
      ],
      "excerpt": "<div align=center><img width=\"450\" height=\"350\" src=\"https://img-blog.csdn.net/20181021135254746?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTIxNTU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"/></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8607660469287802
      ],
      "excerpt": "<div align=center><img width=\"400\" height=\"500\" src=\"https://img-blog.csdn.net/20181021135336856?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTIxNTU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"/></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8555043679871546
      ],
      "excerpt": "<div align=center><img width=\"450\" height=\"450\" src=\"https://img-blog.csdn.net/20181021135434193?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTIxNTU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"/></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8555043679871546
      ],
      "excerpt": "<div align=center><img width=\"450\" height=\"450\" src=\"https://img-blog.csdn.net/2018102114002264?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTIxNTU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"/></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8561042485225449
      ],
      "excerpt": "\u8fd9\u4e2a\u6a21\u578b\u7684\u6838\u5fc3\u662f\u805a\u7126\u673a\u5236\uff0c\u5bf9\u4e8e\u4e00\u4e2a\u8bed\u53e5\uff0c\u53ef\u4ee5\u540c\u65f6\u542f\u7528\u591a\u4e2a\u805a\u7126\u70b9\uff0c\u800c\u4e0d\u5fc5\u5c40\u9650\u4e8e\u4ece\u524d\u5f80\u540e\u7684\uff0c\u6216\u8005\u4ece\u540e\u5f80\u524d\u7684\uff0c\u5e8f\u5217\u4e32\u884c\u5904\u7406\u3002\u4e0d\u4ec5\u8981\u6b63\u786e\u5730\u9009\u62e9\u6a21\u578b\u7684\u7ed3\u6784\uff0c\u800c\u4e14\u8fd8\u8981\u6b63\u786e\u5730\u8bad\u7ec3\u6a21\u578b\u7684\u53c2\u6570\uff0c\u8fd9\u6837\u624d\u80fd\u4fdd\u969c\u6a21\u578b\u80fd\u591f\u51c6\u786e\u5730\u7406\u89e3\u8bed\u53e5\u7684\u8bed\u4e49\u3002BERT \u7528\u4e86\u4e24\u4e2a\u6b65\u9aa4\uff0c\u8bd5\u56fe\u53bb\u6b63\u786e\u5730\u8bad\u7ec3\u6a21\u578b\u7684\u53c2\u6570\u3002\u7b2c\u4e00\u4e2a\u6b65\u9aa4\u662f\u628a\u4e00\u7bc7\u6587\u7ae0\u4e2d\uff0c15% \u7684\u8bcd\u6c47\u906e\u76d6\uff0c\u8ba9\u6a21\u578b\u6839\u636e\u4e0a\u4e0b\u6587\u5168\u5411\u5730\u9884\u6d4b\u88ab\u906e\u76d6\u7684\u8bcd\u3002\u5047\u5982\u6709 1 \u4e07\u7bc7\u6587\u7ae0\uff0c\u6bcf\u7bc7\u6587\u7ae0\u5e73\u5747\u6709 100 \u4e2a\u8bcd\u6c47\uff0c\u968f\u673a\u906e\u76d6 15% \u7684\u8bcd\u6c47\uff0c\u6a21\u578b\u7684\u4efb\u52a1\u662f\u6b63\u786e\u5730\u9884\u6d4b\u8fd9 15 \u4e07\u4e2a\u88ab\u906e\u76d6\u7684\u8bcd\u6c47\u3002\u901a\u8fc7\u5168\u5411\u9884\u6d4b\u88ab\u906e\u76d6\u4f4f\u7684\u8bcd\u6c47\uff0c\u6765\u521d\u6b65\u8bad\u7ec3 Transformer \u6a21\u578b\u7684\u53c2\u6570\u3002\u7136\u540e\uff0c\u7528\u7b2c\u4e8c\u4e2a\u6b65\u9aa4\u7ee7\u7eed\u8bad\u7ec3\u6a21\u578b\u7684\u53c2\u6570\u3002\u8b6c\u5982\u4ece\u4e0a\u8ff0 1 \u4e07\u7bc7\u6587\u7ae0\u4e2d\uff0c\u6311\u9009 20 \u4e07\u5bf9\u8bed\u53e5\uff0c\u603b\u5171 40 \u4e07\u6761\u8bed\u53e5\u3002\u6311\u9009\u8bed\u53e5\u5bf9\u7684\u65f6\u5019\uff0c\u5176\u4e2d 2\u4e5810\u4e07\u5bf9\u8bed\u53e5\uff0c\u662f\u8fde\u7eed\u7684\u4e24\u6761\u4e0a\u4e0b\u6587\u8bed\u53e5\uff0c\u53e6\u5916 2x10 \u4e07\u5bf9\u8bed\u53e5\uff0c\u4e0d\u662f\u8fde\u7eed\u7684\u8bed\u53e5\u3002\u7136\u540e\u8ba9 Transformer \u6a21\u578b\u6765\u8bc6\u522b\u8fd9 20 \u4e07\u5bf9\u8bed\u53e5\uff0c\u54ea\u4e9b\u662f\u8fde\u7eed\u7684\uff0c\u54ea\u4e9b\u4e0d\u8fde\u7eed\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8555043679871546
      ],
      "excerpt": "<div align=center><img width=\"650\" height=\"250\" src=\"https://img-blog.csdn.net/20181021135554835?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTIxNTU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"/></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8555043679871546
      ],
      "excerpt": "<div align=center><img width=\"650\" height=\"250\" src=\"https://img-blog.csdn.net/20181021135717183?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTIxNTU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"/></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8555043679871546
      ],
      "excerpt": "<div align=center><img width=\"550\" height=\"550\" src=\"https://img-blog.csdn.net/20181021135953777?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTIxNTU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"/></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8555043679871546
      ],
      "excerpt": "<div align=center><img width=\"750\" height=\"220\" src=\"https://img-blog.csdn.net/20181021135810611?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTIxNTU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"/></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8555043679871546
      ],
      "excerpt": "<div align=center><img width=\"550\" height=\"550\" src=\"https://img-blog.csdn.net/20181021135826274?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTIxNTU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"/></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8567530716081265
      ],
      "excerpt": "<div align=center><img width=\"450\" height=\"270\" src=\"https://img-blog.csdn.net/20181021135853817?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTIxNTU0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\"/></div> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/EssayKillerBrain/NLP-BERT-Chinese/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "HTML"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "NLP-BERT \u8c37\u6b4c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6a21\u578b\uff1aBERT-\u57fa\u4e8epytorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "NLP-BERT-Chinese",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "EssayKillerBrain",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/EssayKillerBrain/NLP-BERT-Chinese/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Sun, 26 Dec 2021 13:38:48 GMT"
    },
    "technique": "GitHub API"
  }
}
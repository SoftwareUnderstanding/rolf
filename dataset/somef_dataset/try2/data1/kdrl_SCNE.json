{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.05916"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Mikolov, T., Corrado, G., Chen, K., & Dean, J. (2013). **Efficient Estimation of Word Representations in Vector Space**. In Proceedings of ICLR2013. [[pdf](https://arxiv.org/pdf/1301.3781.pdf), [code](https://code.google.com/archive/p/word2vec/)]\n2. Oshikiri, T. (2017). **Segmentation-Free Word Embedding for Unsegmented Languages**. In Proceedings of EMNLP2017. [[pdf](http://aclweb.org/anthology/D17-1081)]\n3. Sakaizawa, Y., & Komachi, M. (2017).  **Construction of a japanese word similarity dataset**. CoRR, abs/1703.05916. [[pdf](https://arxiv.org/abs/1703.05916), [data](https://github.com/tmu-nlp/JapaneseWordSimilarityDataset)]\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{kim-etal-2019-segmentation,\n    title = \"Segmentation-free compositional $n$-gram embedding\",\n    author = \"Kim, Geewook  and\n      Fukui, Kazuki  and\n      Shimodaira, Hidetoshi\",\n    booktitle = \"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\",\n    month = jun,\n    year = \"2019\",\n    address = \"Minneapolis, Minnesota\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/N19-1324\",\n    pages = \"3207--3215\",\n    abstract = \"We propose a new type of representation learning method that models words, phrases and sentences seamlessly. Our method does not depend on word segmentation and any human-annotated resources (e.g., word dictionaries), yet it is very effective for noisy corpora written in unsegmented languages such as Chinese and Japanese. The main idea of our method is to ignore word boundaries completely (i.e., segmentation-free), and construct representations for all character $n$-grams in a raw corpus with embeddings of compositional sub-$n$-grams. Although the idea is simple, our experiments on various benchmarks and real-world datasets show the efficacy of our proposal.\",\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9999987738238175,
        0.9813161029725735,
        0.9956306229412123
      ],
      "excerpt": "If you find this code useful for your research, please cite the following paper in your publication: \n    title = \"Segmentation-free compositional $n$-gram embedding\", \n    author = \"Kim, Geewook  and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.999871345781478,
        0.8955886365383559,
        0.9960965048981569
      ],
      "excerpt": "    booktitle = \"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\", \n    month = jun, \n    year = \"2019\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9686679014285212,
        0.8944178096468923
      ],
      "excerpt": "    url = \"https://www.aclweb.org/anthology/N19-1324\", \n    pages = \"3207--3215\", \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kdrl/SCNE",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-30T02:10:56Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-08T17:26:03Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9224799599590003
      ],
      "excerpt": "SCNE is an open source implementation of the paper \"Segmentation-free compositional n-gram embedding\". NAACL-HLT2019. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "      Fukui, Kazuki  and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.870859878798435
      ],
      "excerpt": "    booktitle = \"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "    publisher = \"Association for Computational Linguistics\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9996665906610759
      ],
      "excerpt": "    abstract = \"We propose a new type of representation learning method that models words, phrases and sentences seamlessly. Our method does not depend on word segmentation and any human-annotated resources (e.g., word dictionaries), yet it is very effective for noisy corpora written in unsegmented languages such as Chinese and Japanese. The main idea of our method is to ignore word boundaries completely (i.e., segmentation-free), and construct representations for all character $n$-grams in a raw corpus with embeddings of compositional sub-$n$-grams. Although the idea is simple, our experiments on various benchmarks and real-world datasets show the efficacy of our proposal.\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "C++ implementation of the paper \"Segmentation-free compositional n-gram embedding\". NAACL-HLT2019.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kdrl/SCNE/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 18:37:48 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kdrl/SCNE/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "kdrl/SCNE",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/kdrl/SCNE/master/train.sh"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kdrl/SCNE/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "C++",
      "Python",
      "Makefile",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Geewook Kim\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SCNE",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SCNE",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "kdrl",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kdrl/SCNE/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Linux (Demo program tested on CentOS Linux release 7.4.1708)\n- gcc (>=5)\n- Python 3\n- NumPy\n- Pandas\n- SciPy\n- scikit-learn\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "The code is based on:\n\n* [word2vec - Google Codes](https://code.google.com/archive/p/word2vec/)\n* [oshikiri/w2v-sembei - GitHub](https://github.com/oshikiri/w2v-sembei)\n* [jarro2783/cxxopts - GitHub](https://github.com/jarro2783/cxxopts)\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 26 Dec 2021 18:37:48 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "representation-learning",
      "machine-learning",
      "word-embedding",
      "sentence-embedding"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Initialize the submodules using\n```\ngit submodule init\ngit submodule update\n```\n2. Compile with `make`\n3. Prepare a training corpus. As a preprocessing, we replaced all whitespaces with '\u2423' (U+2423 Open Box Unicode Character)\n4. Train embeddings (See `train.sh`)\n5. Load the learned compositional n-gram embeddings and Use it (See `scne.py`)\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/seominjoon/qrn",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-04-17T01:05:12Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-14T17:20:35Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9613703555429652,
        0.8778684160273683
      ],
      "excerpt": "[QRN][qrn] is a purely sequential model like LSTM or GRU (but simpler than them) for story-based question answering ([bAbI QA tasks][babi]). \n[QRN][qrn] is implemented using [TensorFlow][tensorflow]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9865101965688982
      ],
      "excerpt": "See model details and more results in [this paper][qrn]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8283313713954261
      ],
      "excerpt": "We can visualize the magnitudes of the update and reset gates using the result file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8098961752173466
      ],
      "excerpt": "Note that the batch size, init_lr, wd, and hidden_size changed. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8825258209193763
      ],
      "excerpt": "To control other parameters and see other options, type: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Query-Reduction Networks (QRN)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/uwnlp/qrn/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 30,
      "date": "Sat, 25 Dec 2021 02:11:06 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/seominjoon/qrn/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "seominjoon/qrn",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/uwnlp/qrn/master/download.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9833775153761817
      ],
      "excerpt": "Note that you need jinja2 (Python package). \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8073717429578583
      ],
      "excerpt": "| 1k avg  | 51.3         | 15.2             | 9.9        | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9111395211117812
      ],
      "excerpt": "After training and testing, the result is stored in evals/babi/en/02-None-00-01/test_0150.json. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8636705646263798
      ],
      "excerpt": "python -m babi.visualize_result --task 2 --open True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8641027535519646
      ],
      "excerpt": "To train the model on 10k dataset, first preprocess the data with large flag: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8465592661508311
      ],
      "excerpt": "Then train the model with large flag as well: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8990022429227705
      ],
      "excerpt": "python -m babi.main --noload --task 2 --large True --batch_size 128 --init_lr 0.1 --wd 0.0005 --hidden_size 200 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8533512095740536
      ],
      "excerpt": "python -m babi.visualize_result --task 2 --open True --large True \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/seominjoon/qrn/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "HTML",
      "Makefile",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2017 Minjoon Seo\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Query-Reduction Networks (QRN)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "qrn",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "seominjoon",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/seominjoon/qrn/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To train the model on bAbI dialog, preprocess the data with bAbI dialog dataset:\n```bash\npython -m prepro-dialog --task 2\n```\n\nThen train the model:\n```bash\npython -m dialog.main --noload --task 2\n```\n\nTo use match, `use_match` flag is required:\n```bash\npython -m dialog.main --noload --task 2 --use_match True\n```\n\nTo use RNN decoder, `use_rnn` flag is required:\n```bash\npython -m dialog.main --noload --task 2 --use_rnn True\n```\n\n[qrn]: http://arxiv.org/abs/1606.04582\n[babi]: http://arxiv.org/abs/1502.05698\n[lstm]: http://arxiv.org/abs/1502.05698 \n[memn2n]: http://arxiv.org/abs/1503.08895\n[tensorflow]: https://www.tensorflow.org/\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 136,
      "date": "Sat, 25 Dec 2021 02:11:06 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "qrn",
      "tensorflow",
      "babi",
      "dialog",
      "qa",
      "rnn",
      "university-of-washington",
      "iclr2017"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We are assuming you are working in a Linux environment. \nMake sure that you have Python (verified on 3.5, issues have been reported with 2.x), and you installed these Python packages: `tensorflow` (>=0.8, <=0.11, issues have been reported with >=0.12) and `progressbar2`.\n\nFirst, download bAbI QA dataset (note that this downloads the dataset to `$HOME/data/babi`):\n\n```bash\nchmod +x download.sh; ./download.sh \n```\n\nThen preprocess the data for a particular task, say Task 2 (this stores the preprocessed data in `data/babi/en/02/`):\n```bash\npython -m prepro --task 2\n```\n\nFinally, you train the model (test is automatically performed at the end):\n```bash\npython -m babi.main --noload --task 2\n```\nIt took ~3 minutes on my laptop using CPU.\n\nYou can run it several times with new weight initialization (e.g. 10) and report the test result with the lowest dev loss:\n```bash\npython -m babi.main --noload --task 2 --num_trials 10\n```\nThis is critical to stably get the reported results; some weight initialization leads to a bad optima.\n\n",
      "technique": "Header extraction"
    }
  ]
}
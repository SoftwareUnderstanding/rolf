{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2008.00820\r\n[audioset]:https://research.google.com/audioset/index.html\r\n[VEGAS_link]:http://bvision11.cs.unc.edu/bigpen/yipin/visual2sound_webpage/VEGAS.zip\r\n[pytorch]:https://github.com/pytorch/pytorch\r\n[wavenet]:https://arxiv.org/abs/1609.03499\r\n[wavenet_repository]:https://github.com/r9y9/wavenet_vocoder\r\n[opencv]:https://github.com/opencv/opencv\r\n[dense_flow]:https://github.com/yjxiong/dense_flow\r\n[VEGAS]: http://bvision11.cs.unc.edu/bigpen/yipin/visual2sound_webpage/visual2sound.html\r\n[visual_to_sound]: https://arxiv.org/abs/1712.01393\r\n[TSN]: https://github.com/yjxiong/temporal-segment-networks\r\n[VAS]: https://drive.google.com/file/d/14birixmH7vwIWKxCHI0MIWCcZyohF59g/view?usp=sharing\r\n[TSN_docker]: https://hub.docker.com/r/bitxiong/tsn/tags\r\n[demo]: https://youtu.be/fI_h5mZG7bg\r",
      "https://arxiv.org/abs/1609.03499\r\n[wavenet_repository]:https://github.com/r9y9/wavenet_vocoder\r\n[opencv]:https://github.com/opencv/opencv\r\n[dense_flow]:https://github.com/yjxiong/dense_flow\r\n[VEGAS]: http://bvision11.cs.unc.edu/bigpen/yipin/visual2sound_webpage/visual2sound.html\r\n[visual_to_sound]: https://arxiv.org/abs/1712.01393\r\n[TSN]: https://github.com/yjxiong/temporal-segment-networks\r\n[VAS]: https://drive.google.com/file/d/14birixmH7vwIWKxCHI0MIWCcZyohF59g/view?usp=sharing\r\n[TSN_docker]: https://hub.docker.com/r/bitxiong/tsn/tags\r\n[demo]: https://youtu.be/fI_h5mZG7bg\r",
      "https://arxiv.org/abs/1712.01393\r\n[TSN]: https://github.com/yjxiong/temporal-segment-networks\r\n[VAS]: https://drive.google.com/file/d/14birixmH7vwIWKxCHI0MIWCcZyohF59g/view?usp=sharing\r\n[TSN_docker]: https://hub.docker.com/r/bitxiong/tsn/tags\r\n[demo]: https://youtu.be/fI_h5mZG7bg\r"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n\r\nPlease cite the following paper if you feel RegNet useful to your research\r\n```\r\n@Article{chen2020regnet,\r\n  author  = {Peihao Chen, Yang Zhang, Mingkui Tan, Hongdong Xiao, Deng Huang and Chuang Gan},\r\n  title   = {Generating Visually Aligned Sound from Videos},\r\n  journal = {TIP},\r\n  year    = {2020},\r\n}\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@Article{chen2020regnet,\n  author  = {Peihao Chen, Yang Zhang, Mingkui Tan, Hongdong Xiao, Deng Huang and Chuang Gan},\n  title   = {Generating Visually Aligned Sound from Videos},\n  journal = {TIP},\n  year    = {2020},\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/PeihaoChen/regnet",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "For any question, please file an issue or contact\r\n```\r\nPeihao Chen: phchencs@gmail.com\r\nHongdong Xiao: xiaohongdonghd@gmail.com\r\n```\r\n\r\n[REGNET]:https://arxiv.org/abs/2008.00820\r\n[audioset]:https://research.google.com/audioset/index.html\r\n[VEGAS_link]:http://bvision11.cs.unc.edu/bigpen/yipin/visual2sound_webpage/VEGAS.zip\r\n[pytorch]:https://github.com/pytorch/pytorch\r\n[wavenet]:https://arxiv.org/abs/1609.03499\r\n[wavenet_repository]:https://github.com/r9y9/wavenet_vocoder\r\n[opencv]:https://github.com/opencv/opencv\r\n[dense_flow]:https://github.com/yjxiong/dense_flow\r\n[VEGAS]: http://bvision11.cs.unc.edu/bigpen/yipin/visual2sound_webpage/visual2sound.html\r\n[visual_to_sound]: https://arxiv.org/abs/1712.01393\r\n[TSN]: https://github.com/yjxiong/temporal-segment-networks\r\n[VAS]: https://drive.google.com/file/d/14birixmH7vwIWKxCHI0MIWCcZyohF59g/view?usp=sharing\r\n[TSN_docker]: https://hub.docker.com/r/bitxiong/tsn/tags\r\n[demo]: https://youtu.be/fI_h5mZG7bg\r\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-24T02:38:27Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-24T04:15:54Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.976748437625916
      ],
      "excerpt": "This is the official pytorch implementation of the TIP paper \"[Generating Visually Aligned Sound from Videos][REGNET]\" and the corresponding Visually Aligned Sound (VAS) dataset.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "Data Preprocessing \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9889855717181288
      ],
      "excerpt": "Notice: The script we provided to calculate optical flow is easy to run but is resource-consuming and will take a long time. We strongly recommend you to refer to [TSN repository][TSN] and their built [docker image][TSN_docker] (our paper also uses this solution)  to speed up optical flow extraction and to restrictly reproduce the results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9599757660356539,
        0.9599757660356539,
        0.9599757660356539
      ],
      "excerpt": "rgb_feature_dir data/features/dog/feature_rgb_bninception_dim1024_21.5fps \\ \nflow_feature_dir data/features/dog/feature_flow_bninception_dim1024_21.5fps \\ \nmel_dir data/features/dog/melspec_10s_22050hz \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Official PyTorch implementation of the TIP paper \"Generating Visually Aligned Sound from Videos\" and the corresponding Visually Aligned Sound (VAS) dataset.",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nIn our paper, we collect 8 sound types (Dog, Fireworks, Drum, Baby form [VEGAS][vegas] and Gun, Sneeze, Cough, Hammer from [AudioSet][audioset]) to build our [Visually Aligned Sound (VAS)][VAS] dataset.\r\nPlease first download VAS dataset and unzip the data to *`$REGNET_ROOT/data/`*  folder.\r\n\r\nFor each sound type in AudioSet, we download all videos from Youtube and clean data on Amazon Mechanical Turk (AMT) using the same way as [VEGAS][visual_to_sound].\r\n\r\n\r\n```bash\r\nunzip ./data/VAS.zip -d ./data\r\n```\r\n\r\n\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/PeihaoChen/regnet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Mon, 27 Dec 2021 00:44:24 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/PeihaoChen/regnet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "PeihaoChen/regnet",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/PeihaoChen/regnet/master/data_preprocess.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nClone this repository into a directory. We refer to that directory as *`REGNET_ROOT`*.\r\n\r\n```bash\r\ngit clone https://github.com/PeihaoChen/regnet\r\ncd regnet\r\n```\r\nCreate a new Conda environment.\r\n```bash\r\nconda create -n regnet python=3.7.1\r\nconda activate regnet\r\n```\r\nInstall [PyTorch][pytorch] and other dependencies.\r\n```bash\r\nconda install pytorch==1.2.0 torchvision==0.4.0 cudatoolkit=10.0\r\nconda install ffmpeg -n regnet -c conda-forge\r\npip install -r requirements.txt\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9654765604684976
      ],
      "excerpt": "source data_preprocess.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9978632248958672,
        0.9206633769338113
      ],
      "excerpt": "git clone https://github.com/r9y9/wavenet_vocoder &amp;&amp; cd wavenet_vocoder \ngit checkout 2092a64 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.964529161286854,
        0.8226900798456268
      ],
      "excerpt": "cd ./ckpt/dog \ntar -xvf ./ckpt/dog/RegNet_dog_checkpoint_041000.tar #: unzip \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8197938582524695
      ],
      "excerpt": "Download Datasets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": "Training RegNet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9078431934650627
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=7 python train.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9078431934650627
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=7 python train.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9089800953215836
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=7 python test.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "aux_zero True \\  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8182128932023278
      ],
      "excerpt": "First, download and unzip the pre-computed features (Dog) to ./data/features/dog folder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8107976107217431
      ],
      "excerpt": "Second, download and unzip our pre-trained RegNet (Dog) to ./ckpt/dog folder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9089800953215836
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0 python test.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "aux_zero True \\  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/PeihaoChen/regnet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Generating Visually Aligned Sound from Videos",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "regnet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "PeihaoChen",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/PeihaoChen/regnet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "PeihaoChen",
        "body": "You can use our pre-trained RegNet and pre-computed features for generating visually aligned sounds.",
        "dateCreated": "2020-11-23T11:41:07Z",
        "datePublished": "2020-11-23T12:49:59Z",
        "html_url": "https://github.com/PeihaoChen/regnet/releases/tag/pretrained_RegNet",
        "name": "Pre-trained RegNet",
        "tag_name": "pretrained_RegNet",
        "tarball_url": "https://api.github.com/repos/PeihaoChen/regnet/tarball/pretrained_RegNet",
        "url": "https://api.github.com/repos/PeihaoChen/regnet/releases/34305594",
        "zipball_url": "https://api.github.com/repos/PeihaoChen/regnet/zipball/pretrained_RegNet"
      },
      {
        "authorType": "User",
        "author_name": "PeihaoChen",
        "body": "We upload our trained WaveNet model for different sound categories for transferring predicted spectrograms to the waveform.",
        "dateCreated": "2020-08-24T02:45:14Z",
        "datePublished": "2020-08-24T07:03:33Z",
        "html_url": "https://github.com/PeihaoChen/regnet/releases/tag/WaveNet_model",
        "name": "WaveNet Model",
        "tag_name": "WaveNet_model",
        "tarball_url": "https://api.github.com/repos/PeihaoChen/regnet/tarball/WaveNet_model",
        "url": "https://api.github.com/repos/PeihaoChen/regnet/releases/30035207",
        "zipball_url": "https://api.github.com/repos/PeihaoChen/regnet/zipball/WaveNet_model"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 17,
      "date": "Mon, 27 Dec 2021 00:44:24 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "[[back to top](#Generating-Visually-Aligned-Sound-from-Videos)]\r\n\r\n",
      "technique": "Header extraction"
    }
  ]
}
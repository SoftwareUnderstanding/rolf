{
  "citation": [
    {
      "confidence": [
        0.877118600674591
      ],
      "excerpt": "How to improve object detection \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9678274005321363
      ],
      "excerpt": "Yolo v3 source chart for the RetinaNet on MS COCO got from Table 1 (e): https://arxiv.org/pdf/1708.02002.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.901083715581408,
        0.9969562844724977
      ],
      "excerpt": "Yolo v2 on Pascal VOC 2012 (comp4): https://hsto.org/files/3a6/fdf/b53/3a6fdfb533f34cee9b52bdd9bb0b19d9.jpg \nA Yolo cross-platform Windows and Linux version (for object detection). Contributtors: https://github.com/AlexeyAB/darknet/graphs/contributors \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8306763126980392
      ],
      "excerpt": "added example of Detection and Tracking objects: https://github.com/AlexeyAB/darknet/blob/master/src/yolo_console_dll.cpp \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ParsonsCorp/darknet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-07T18:01:50Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-02-11T20:16:46Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.865783793959396
      ],
      "excerpt": "Improvements in this repository \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.866841361811332
      ],
      "excerpt": "How to compile on Linux \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9189854242214757
      ],
      "excerpt": "How to calculate mAP on PascalVOC 2007 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8556303529516746
      ],
      "excerpt": "How to mark bounded boxes of objects and create annotation files \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9633452392874654
      ],
      "excerpt": "This repository supports: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8826405011675686
      ],
      "excerpt": "improved performance 3.5 X times of data augmentation for training (using OpenCV SSE/AVX functions instead of hand-written functions) - removes bottleneck for training on multi-GPU or GPU Volta \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.803202738940659
      ],
      "excerpt": "optimized initialization GPU for detection - we use batch=1 initially instead of re-init with batch=1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8742383245854864,
        0.8914828933850917
      ],
      "excerpt": "added drawing of chart of average loss during training \nadded calculation of anchors for training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9252512406965311
      ],
      "excerpt": "many other fixes of code... \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8198950586035019
      ],
      "excerpt": "Also, you might be interested in using a simplified repository where is implemented INT8-quantization (+30% speedup and -1% mAP reduced): https://github.com/AlexeyAB/yolo2_light \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8299166424698432
      ],
      "excerpt": "Replace the address below, on shown in the phone application (Smart WebCam) and launch: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8105296482968791
      ],
      "excerpt": "* OPENMP=1 to build with OpenMP support to accelerate Yolo by using multi-core CPU \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9602088060940327
      ],
      "excerpt": "    \\darknet.sln -> (right click on project) -> properties -> C/C++ -> Preprocessor -> Preprocessor Definitions, and add here: CUDNN_HALF; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8988889521982104
      ],
      "excerpt": "Then add to your created project: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8939573014064925
      ],
      "excerpt": "- add to project all .c & .cu files and file http_stream.cpp from \\src \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9034970316319945
      ],
      "excerpt": "-  (right click on project) -> properties  -> Linker -> Input -> Additional dependecies, put here:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9588146532828058
      ],
      "excerpt": "- (right click on project) -> properties -> C/C++ -> Preprocessor -> Preprocessor Definitions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9426417027936425
      ],
      "excerpt": "Only for small datasets sometimes better to decrease learning rate, for 4 GPUs set learning_rate = 0.00025 (i.e. learning_rate = 0.001 / GPUs). In this case also increase 4x times burn_in = and max_batches = in your cfg-file. I.e. use burn_in = 4000 instead of 1000. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9148490921544745
      ],
      "excerpt": "(Generally filters depends on the classes, coords and number of masks, i.e. filters=(classes + coords + 1)*&lt;number of mask&gt;, where mask is indices of anchors. If mask is absence, then filters=(classes + coords + 1)*num) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8979411005071259
      ],
      "excerpt": "  data/obj/img2.jpg \n  data/obj/img3.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.988266287233394
      ],
      "excerpt": "Do all the same steps as for the full yolo model as described above. With the exception of: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9364235834190711,
        0.8997185071233157,
        0.9748591166852018,
        0.9462966168653406
      ],
      "excerpt": "IoU (intersect over union) - average instersect over union of objects and detections for a certain threshold = 0.24 \nmAP (mean average precision) - mean value of average precisions for each class, where average precision is average value of 11 points on PR-curve for each possible threshold (each probability of detection) for the same class (Precision-Recall in terms of PascalVOC, where Precision=TP/(TP+FP) and Recall=TP/(TP+FN) ), page-11: http://homepages.inf.ed.ac.uk/ckiw/postscript/ijcv_voc09.pdf \nmAP is default metric of precision in the PascalVOC competition, this is the same as AP50 metric in the MS COCO competition. \nIn terms of Wiki, indicators Precision and Recall have a slightly different meaning than in the PascalVOC competition, but IoU always has the same meaning. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8089589788437591
      ],
      "excerpt": "Then there are 2 ways to get mAP: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9086147222393187
      ],
      "excerpt": "(The article specifies the value of mAP = 76.8% for YOLOv2 416\u00d7416, page-4 table-3: https://arxiv.org/pdf/1612.08242v1.pdf. We get values lower - perhaps due to the fact that the model was trained on a slightly different source code than the code on which the detection is was done) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9068681565146853
      ],
      "excerpt": "for training with a large number of objects in each image, add the parameter max=200 or higher value in the last [yolo]-layer or [region]-layer in your cfg-file (the global maximum number of objects that can be detected by YoloV3 is 0,0615234375*(width*height) where are width and height are parameters from [net] section in cfg-file)  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9166013111118131
      ],
      "excerpt": "That is, if only objects that occupied 80-90% of the image were present in the training set, then the trained network will not be able to detect objects that occupy 1-10% of the image. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9053512929171167
      ],
      "excerpt": "Increase network-resolution by set in your .cfg-file (height=608 and width=608) or (height=832 and width=832) or (any value multiple of 32) - this increases the precision and makes it possible to detect small objects: link \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8215478943909726
      ],
      "excerpt": "Here you can find repository with GUI-software for marking bounded boxes of objects and generating annotation files for Yolo v2 & v3: https://github.com/AlexeyAB/Yolo_mark \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Windows and Linux version of Darknet Yolo v3 & v2 Neural Networks for object detection (Tensor Cores are used)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/PolarisAlpha/darknet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 07:50:00 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ParsonsCorp/darknet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ParsonsCorp/darknet",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/PolarisAlpha/darknet/master/image_yolov2.sh",
      "https://raw.githubusercontent.com/PolarisAlpha/darknet/master/video_v2.sh",
      "https://raw.githubusercontent.com/PolarisAlpha/darknet/master/image_yolov3.sh",
      "https://raw.githubusercontent.com/PolarisAlpha/darknet/master/mjpeg_stream.sh",
      "https://raw.githubusercontent.com/PolarisAlpha/darknet/master/net_cam_v3.sh",
      "https://raw.githubusercontent.com/PolarisAlpha/darknet/master/video_yolov3.sh",
      "https://raw.githubusercontent.com/PolarisAlpha/darknet/master/scripts/dice_label.sh",
      "https://raw.githubusercontent.com/PolarisAlpha/darknet/master/scripts/gen_tactic.sh",
      "https://raw.githubusercontent.com/PolarisAlpha/darknet/master/scripts/get_coco_dataset.sh",
      "https://raw.githubusercontent.com/PolarisAlpha/darknet/master/scripts/imagenet_label.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8861518504264562,
        0.9230526238937559
      ],
      "excerpt": "How to compile on Linux \nHow to compile on Windows \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8457052570226492
      ],
      "excerpt": "Yolo v3 source chart for the RetinaNet on MS COCO got from Table 1 (e): https://arxiv.org/pdf/1708.02002.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8290700962917505,
        0.9367573965372659
      ],
      "excerpt": "A Yolo cross-platform Windows and Linux version (for object detection). Contributtors: https://github.com/AlexeyAB/darknet/graphs/contributors \nThis repository is forked from Linux-version: https://github.com/pjreddie/darknet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9271281673501826
      ],
      "excerpt": "both Windows and Linux \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8563869011577235,
        0.8411004553040458
      ],
      "excerpt": "both cuDNN >= v7 \nCUDA >= 7.5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9707277520183856,
        0.9707277520183856,
        0.9707277520183856,
        0.8618165428900759,
        0.9707277520183856
      ],
      "excerpt": "yolov3-openimages.cfg (247 MB COCO Yolo v3) - requires 4 GB GPU-RAM: https://pjreddie.com/media/files/yolov3-openimages.weights \nyolov3-spp.cfg (240 MB COCO Yolo v3) - requires 4 GB GPU-RAM: https://pjreddie.com/media/files/yolov3-spp.weights \nyolov3.cfg (236 MB COCO Yolo v3) - requires 4 GB GPU-RAM: https://pjreddie.com/media/files/yolov3.weights \nyolov3-tiny.cfg (34 MB COCO Yolo v3 tiny) - requires 1 GB GPU-RAM:  https://pjreddie.com/media/files/yolov3-tiny.weights \nyolov2.cfg (194 MB COCO Yolo v2) - requires 4 GB GPU-RAM: https://pjreddie.com/media/files/yolov2.weights \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9201321764091015
      ],
      "excerpt": "yolov2-tiny.cfg (43 MB COCO Yolo v2) - requires 1 GB GPU-RAM: https://pjreddie.com/media/files/yolov2-tiny.weights \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9578757234406691
      ],
      "excerpt": "You can get cfg-files by path: darknet/cfg/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.811319624300472
      ],
      "excerpt": "Start Smart WebCam on your phone \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8044083335257789
      ],
      "excerpt": "Just do make in the darknet directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.976885133954891,
        0.8752615859580927
      ],
      "excerpt": "* GPU=1 to build with CUDA to accelerate by using GPU (CUDA should be in /usr/local/cuda) \n* CUDNN=1 to build with cuDNN v5-v7 to accelerate training by using GPU (cuDNN should be in /usr/local/cudnn) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9841790820267187
      ],
      "excerpt": "If you have MSVS 2015, CUDA 10.0, cuDNN 7.4 and OpenCV 3.x (with paths: C:\\opencv_3.0\\opencv\\build\\include & C:\\opencv_3.0\\opencv\\build\\x64\\vc14\\lib), then start MSVS, open build\\darknet\\darknet.sln, set x64 and Release https://hsto.org/webt/uh/fk/-e/uhfk-eb0q-hwd9hsxhrikbokd6u.jpeg and do the: Build -> Build darknet. Also add Windows system variable cudnn with path to CUDNN: https://hsto.org/files/a49/3dc/fc4/a493dcfc4bd34a1295fd15e0e2e01f26.jpg NOTE: If installing OpenCV, use OpenCV 3.4.0 or earlier. This is a bug in OpenCV 3.4.1 in the C API (see #500). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8971952630465214,
        0.9636135120139189,
        0.9664999979898852,
        0.9309039827099643
      ],
      "excerpt": "1.2 Check that there are bin and include folders in the C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0 if aren't, then copy them to this folder from the path where is CUDA installed \n1.3. To install CUDNN (speedup neural network), do the following: \ndownload and install cuDNN v7.4.1 for CUDA 10.0: https://developer.nvidia.com/cudnn \nadd Windows system variable cudnn with path to CUDNN: https://hsto.org/files/a49/3dc/fc4/a493dcfc4bd34a1295fd15e0e2e01f26.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.917333155087388,
        0.962596104775014
      ],
      "excerpt": "If you have other version of CUDA (not 10.0) then open build\\darknet\\darknet.vcxproj by using Notepad, find 2 places with \"CUDA 10.0\" and change it to your CUDA-version, then do step 1 \nIf you don't have GPU, but have MSVS 2015 and OpenCV 3.0 (with paths: C:\\opencv_3.0\\opencv\\build\\include & C:\\opencv_3.0\\opencv\\build\\x64\\vc14\\lib), then start MSVS, open build\\darknet\\darknet_no_gpu.sln, set x64 and Release, and do the: Build -> Build darknet_no_gpu \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.897830550692884,
        0.8847562642029537
      ],
      "excerpt": "Note: CUDA must be installed only after that MSVS2015 had been installed. \nAlso, you can to create your own darknet.sln & darknet.vcxproj, this example for CUDA 9.1 and OpenCV 3.0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.875650876183317
      ],
      "excerpt": "- (right click on project) -> Build dependecies -> Build Customizations -> set check on CUDA 9.1 or what version you have - for example as here: http://devblogs.nvidia.com/parallelforall/wp-content/uploads/2015/01/VS2013-R-5.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9296625389598782
      ],
      "excerpt": "cusolver64_91.dll, curand64_91.dll, cudart64_91.dll, cublas64_91.dll - 91 for CUDA 9.1 or your version, from C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.1\\bin \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8466183741406523
      ],
      "excerpt": "For OpenCV 2.4.13: opencv_core2413.dll, opencv_highgui2413.dll and opencv_ffmpeg2413_64.dll from  C:\\opencv_2.4.13\\opencv\\build\\x64\\vc14\\bin \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9837438037624533
      ],
      "excerpt": "Download and install Python for Windows: https://www.python.org/ftp/python/3.5.2/python-3.5.2-amd64.exe \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8601214530448917
      ],
      "excerpt": "(Note: To disable Loss-Window use flag -dont_show. If you are using CPU, try darknet_no_gpu.exe instead of darknet.exe.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.829704442551866
      ],
      "excerpt": "Also you can get result earlier than all 45000 iterations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8324839727464387
      ],
      "excerpt": "Download PascalVOC dataset, install Python 3.x and get file 2007_test.txt as described here: https://github.com/AlexeyAB/darknet#how-to-train-pascal-voc-data \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8377090365529959
      ],
      "excerpt": "How to train (Pascal VOC Data) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8413270679831343
      ],
      "excerpt": "fixed usage of [reorg]-layer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.850180242291126,
        0.8625654600996356,
        0.876434860825384
      ],
      "excerpt": "added options -in and -out to the darknet detector test command to accept an input file consisting of multiple image paths and produce JSON output respectively. See example command below \ndarknet/darknet detector test data/obj.data yolo-obj.cfg yolo-obj_20000.weights -dont_show -ext_output -in images.txt -out result.json \n  Example of images.txt input file content - \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9539567401622289
      ],
      "excerpt": "  Example of result.json output file - \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8485251670538358
      ],
      "excerpt": "- add to project all .c & .cu files and file http_stream.cpp from \\src \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401588059931042
      ],
      "excerpt": "Download The Pascal VOC Data and unpack it to directory build\\darknet\\x64\\data\\voc will be created dir build\\darknet\\x64\\data\\voc\\VOCdevkit\\: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9020260040251167
      ],
      "excerpt": "2.1 Download file voc_label.py to dir build\\darknet\\x64\\data\\voc: http://pjreddie.com/media/files/voc_label.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8645231307703959
      ],
      "excerpt": "Run command: python build\\darknet\\x64\\data\\voc\\voc_label.py (to generate files: 2007_test.txt, 2007_train.txt, 2007_val.txt, 2012_train.txt, 2012_val.txt) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8488529539443088
      ],
      "excerpt": "darknet.exe detector train data/voc.data cfg/yolov3-voc.cfg darknet53.conv.74  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.870172463119795,
        0.8685102064981255
      ],
      "excerpt": "Train it first on 1 GPU for like 1000 iterations: darknet.exe detector train data/voc.data cfg/yolov3-voc.cfg darknet53.conv.74 \nThen stop and by using partially-trained model /backup/yolov3-voc_1000.weights run training with multigpu (up to 4 GPUs): darknet.exe detector train data/voc.data cfg/yolov3-voc.cfg /backup/yolov3-voc_1000.weights -gpus 0,1,2,3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": "Training Yolo v3: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.877731550916042,
        0.8202257195562564
      ],
      "excerpt": "Create file obj.names in the directory build\\darknet\\x64\\data\\, with objects names - each in new line \nCreate file obj.data in the directory build\\darknet\\x64\\data\\, containing (where classes = number of objects): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8933741375046061,
        0.8428497312187538
      ],
      "excerpt": "  train  = data/train.txt \n  valid  = data/test.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8237249625365071
      ],
      "excerpt": "Put image-files (.jpg) of your objects in the directory build\\darknet\\x64\\data\\obj\\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8718673695351183
      ],
      "excerpt": "For example for img1.jpg you will be created img1.txt containing: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9410048613256292
      ],
      "excerpt": "Create file train.txt in directory build\\darknet\\x64\\data\\, with filenames of your images, each filename in new line, with path relative to darknet.exe, for example containing: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8650599171564616
      ],
      "excerpt": "Start training by using the command line: darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8157758741178391
      ],
      "excerpt": "8.1. For training with mAP (mean average precisions) calculation for each 4 Epochs (set valid=valid.txt or train.txt in obj.data file) and run: darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74 -map \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8596463556041132
      ],
      "excerpt": "After each 100 iterations you can stop and later start training from this point. For example, after 2000 iterations you can stop training, and later just copy yolo-obj_2000.weights from build\\darknet\\x64\\backup\\ to build\\darknet\\x64\\ and start training using: darknet.exe detector train data/obj.data yolo-obj.cfg yolo-obj_2000.weights \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8291747710658229
      ],
      "excerpt": "* Start training: darknet.exe detector train data/obj.data yolov3-tiny-obj.cfg yolov3-tiny.conv.15 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8719351761670333
      ],
      "excerpt": "2.1. At first, in your file obj.data you must specify the path to the validation dataset valid = valid.txt (format of valid.txt as in train.txt), and if you haven't validation images, just copy data\\train.txt to data\\valid.txt. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8536492942258446
      ],
      "excerpt": "Then download file https://raw.githubusercontent.com/AlexeyAB/darknet/master/scripts/voc_label_difficult.py to the dir build\\darknet\\x64\\data\\ then run voc_label_difficult.py to get the file difficult_2007_test.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8014014222502843
      ],
      "excerpt": "Using Darknet + Python: run the file build/darknet/x64/calc_mAP_voc_py.cmd - you will get mAP for yolo-voc.cfg model, mAP = 75.9% \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8354925384130082,
        0.8074273915509396,
        0.8088485802655296
      ],
      "excerpt": "recalculate anchors for your dataset for width and height from cfg-file: \n  darknet.exe detector calc_anchors data/obj.data -num_of_clusters 9 -width 416 -height 416 \n   then set the same 9 anchors in each of 3 [yolo]-layers in your cfg-file \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8101921643353219
      ],
      "excerpt": "for training with a large number of objects in each image, add the parameter max=200 or higher value in the last [yolo]-layer or [region]-layer in your cfg-file (the global maximum number of objects that can be detected by YoloV3 is 0,0615234375*(width*height) where are width and height are parameters from [net] section in cfg-file)  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8330928405361905
      ],
      "excerpt": "object width in percent from Training dataset ~= object width in percent from Test dataset  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8183645825086063
      ],
      "excerpt": "    then train by using weights file yolov3.conv.81 instead of darknet53.conv.74 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8122973964631659,
        0.8357990185790696
      ],
      "excerpt": "With example of: train.txt, obj.names, obj.data, yolo-obj.cfg, air1-6.txt, bird1-4.txt for 2 classes of objects (air, bird) and train_obj.cmd with example how to train this image-set with Yolo v2 & v3 \nSimultaneous detection and classification of 9000 objects: darknet.exe detector test cfg/combine9k.data cfg/yolo9000.cfg yolo9000.weights data/dog.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.809547384061538
      ],
      "excerpt": "9k.names - \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ParsonsCorp/darknet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "C",
      "Cuda",
      "Python",
      "C++",
      "Batchfile",
      "Makefile",
      "C#",
      "Shell",
      "Objective-C"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/PolarisAlpha/darknet/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'                                  YOLO LICENSE\\n                             Version 2, July 29 2016\\n\\nTHIS SOFTWARE LICENSE IS PROVIDED \"ALL CAPS\" SO THAT YOU KNOW IT IS SUPER\\nSERIOUS AND YOU DON\\'T MESS AROUND WITH COPYRIGHT LAW BECAUSE YOU WILL GET IN\\nTROUBLE HERE ARE SOME OTHER BUZZWORDS COMMONLY IN THESE THINGS WARRANTIES\\nLIABILITY CONTRACT TORT LIABLE CLAIMS RESTRICTION MERCHANTABILITY. NOW HERE\\'S\\nTHE REAL LICENSE:\\n\\n0. Darknet is public domain.\\n1. Do whatever you want with it.\\n2. Stop emailing me about it!\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Yolo-v3 and Yolo-v2 for Windows and Linux",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "darknet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ParsonsCorp",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ParsonsCorp/darknet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* **Linux GCC>=4.9 or Windows MS Visual Studio 2015 (v140)**: https://go.microsoft.com/fwlink/?LinkId=532606&clcid=0x409  (or offline [ISO image](https://go.microsoft.com/fwlink/?LinkId=615448&clcid=0x409))\n* **CUDA 10.0**: https://developer.nvidia.com/cuda-toolkit-archive (on Linux do [Post-installation Actions](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions))\n* **OpenCV 3.3.0**: https://sourceforge.net/projects/opencvlibrary/files/opencv-win/3.3.0/opencv-3.3.0-vc14.exe/download\n* **or OpenCV 2.4.13**: https://sourceforge.net/projects/opencvlibrary/files/opencv-win/2.4.13/opencv-2.4.13.2-vc14.exe/download\n  - OpenCV allows to show image or video detection in the window and store result to file that specified in command line `-out_filename res.avi`\n* **GPU with CC >= 3.0**: https://en.wikipedia.org/wiki/CUDA#GPUs_supported\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 07:50:00 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[![Everything Is AWESOME](http://img.youtube.com/vi/VOC3huqHrss/0.jpg)](https://www.youtube.com/watch?v=VOC3huqHrss \"Everything Is AWESOME\")\n\nOthers: https://www.youtube.com/channel/UC7ev3hNVkx4DzZ3LO19oebg\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "On Linux use `./darknet` instead of `darknet.exe`, like this:`./darknet detector test ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights`\n\n* **Yolo v3** COCO - image: `darknet.exe detector test data/coco.data cfg/yolov3.cfg yolov3.weights -i 0 -thresh 0.25`\n* Output coordinates of objects: `darknet.exe detector test data/coco.data yolov3.cfg yolov3.weights -ext_output dog.jpg`\n* **Yolo v3** COCO - video: `darknet.exe detector demo data/coco.data cfg/yolov3.cfg yolov3.weights -ext_output test.mp4`\n* **Yolo v3** COCO - WebCam 0: `darknet.exe detector demo data/coco.data cfg/yolov3.cfg yolov3.weights -c 0`\n* **Yolo v3** COCO for net-videocam - Smart WebCam: `darknet.exe detector demo data/coco.data cfg/yolov3.cfg yolov3.weights http://192.168.0.80:8080/video?dummy=param.mjpg`\n* **Yolo v3 - save result to the file res.avi**: `darknet.exe detector demo data/coco.data cfg/yolov3.cfg yolov3.weights -thresh 0.25 test.mp4 -out_filename res.avi`\n* **Yolo v3 Tiny** COCO - video: `darknet.exe detector demo data/coco.data cfg/yolov3-tiny.cfg yolov3-tiny.weights test.mp4`\n* **Yolo v3 Tiny** on GPU #0: `darknet.exe detector demo data/coco.data cfg/yolov3-tiny.cfg yolov3-tiny.weights -i 0 test.mp4`\n* Alternative method Yolo v3 COCO - image: `darknet.exe detect cfg/yolov3.cfg yolov3.weights -i 0 -thresh 0.25`\n* 186 MB Yolo9000 - image: `darknet.exe detector test cfg/combine9k.data yolo9000.cfg yolo9000.weights`\n* Remeber to put data/9k.tree and data/coco9k.map under the same folder of your app if you use the cpp api to build an app\n* To process a list of images `data/train.txt` and save results of detection to `result.txt` use:                             \n    `darknet.exe detector test cfg/coco.data yolov3.cfg yolov3.weights -dont_show -ext_output < data/train.txt > result.txt`\n* To calculate anchors: `darknet.exe detector calc_anchors data/obj.data -num_of_clusters 9 -width 416 -height 416`\n* To check accuracy mAP50: `darknet.exe detector map data/obj.data yolo-obj.cfg backup\\yolo-obj_7000.weights`\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. To compile Yolo as C++ DLL-file `yolo_cpp_dll.dll` - open in MSVS2015 file `build\\darknet\\yolo_cpp_dll.sln`, set **x64** and **Release**, and do the: Build -> Build yolo_cpp_dll\n    * You should have installed **CUDA 10.0**\n    * To use cuDNN do: (right click on project) -> properties -> C/C++ -> Preprocessor -> Preprocessor Definitions, and add at the beginning of line: `CUDNN;`\n\n2. To use Yolo as DLL-file in your C++ console application - open in MSVS2015 file `build\\darknet\\yolo_console_dll.sln`, set **x64** and **Release**, and do the: Build -> Build yolo_console_dll\n\n    * you can run your console application from Windows Explorer `build\\darknet\\x64\\yolo_console_dll.exe`\n    **use this command**: `yolo_console_dll.exe data/coco.names yolov3.cfg yolov3.weights test.mp4`\n    \n    * or you can run from MSVS2015 (before this - you should copy 2 files `yolo-voc.cfg` and `yolo-voc.weights` to the directory `build\\darknet\\` )\n    * after launching your console application and entering the image file name - you will see info for each object: \n    `<obj_id> <left_x> <top_y> <width> <height> <probability>`\n    * to use simple OpenCV-GUI you should uncomment line `//#define OPENCV` in `yolo_console_dll.cpp`-file: [link](https://github.com/AlexeyAB/darknet/blob/a6cbaeecde40f91ddc3ea09aa26a03ab5bbf8ba8/src/yolo_console_dll.cpp#L5)\n    * you can see source code of simple example for detection on the video file: [link](https://github.com/AlexeyAB/darknet/blob/ab1c5f9e57b4175f29a6ef39e7e68987d3e98704/src/yolo_console_dll.cpp#L75)\n   \n`yolo_cpp_dll.dll`-API: [link](https://github.com/AlexeyAB/darknet/blob/master/src/yolo_v2_class.hpp#L42)\n```\nclass Detector {\npublic:\n\tDetector(std::string cfg_filename, std::string weight_filename, int gpu_id = 0);\n\t~Detector();\n\n\tstd::vector<bbox_t> detect(std::string image_filename, float thresh = 0.2, bool use_mean = false);\n\tstd::vector<bbox_t> detect(image_t img, float thresh = 0.2, bool use_mean = false);\n\tstatic image_t load_image(std::string image_filename);\n\tstatic void free_image(image_t m);\n\n#:ifdef OPENCV\n\tstd::vector<bbox_t> detect(cv::Mat mat, float thresh = 0.2, bool use_mean = false);\n#:endif\n};\n```\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1603.09025",
      "https://arxiv.org/abs/1412.4864",
      "https://arxiv.org/abs/1512.03385"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The permuted sequential MNIST code was mostly written by Mohammad Pezeshki and Nicolas Ballas, modified by Tegan Maharaj, and is based heavily on code written by Tim Cooijmans and Nicolas Ballas for recurrent batch normalization.\n\nThe char-PTB code was written mostly by Janos Kramar and Tegan Maharaj, based on code written by Mohammad Pezeshki, based on code from MILA's speech group.\nThe word-level PTB code was based on this code, extended by Janos Kramar, Tegan Maharaj, and David Krueger. The text8 code was also based on this code, extended by Tegan Maharaj. The sequence to sequence task is tensorflow code from Erik Rehn, with zoneout implemented by David Krueger, Janos Kramar, and Tegan Maharaj. The semantic consistency task and code were developed by David Krueger. The gradient propagation code is from recurrent batch normalization. \n\nThe original idea for zoneout was proposed by Anirudh Goyal in discussion with David Krueger, and inspired by his earlier conversations with Yoshua Bengio. Initial experiements were run by David Krueger, who then involved Tegan Maharaj, Janos Kramar, and Christopher Pal. Mohammad Pezeshki was independently persuing a similar idea, with Nicolas Ballas, Hugo Larochelle, and Aaron Courville, so we combined forces and code. Experiments were run by Tegan Maharaj, Janos Kramar, Mohammad Pezeshki, Nicolas Ballas, David Krueger, and Rosemary Nan Ke. Theory was mostly develped and elaborated by David Krueger, in discussions with Janos Kramar, Tegan Maharaj, Nicolas Ballas, Mohammad Pezeshki, Chris Pal, Aaron Courville, Hugo Larochelle, and Anirudh Goyal. The paper was written and figures/tables produced by David Krueger, Tegan Maharaj, Janos Kramar, Nicolas Ballas,  Mohammad Pezeshki, Rosemary Nan Ke, and Chris Pal. \n\nWe had important contributing discussions with Christopher Beckham, Chiheb Trabelsi, Marcin Moczulski, Caglar Gulcehre, and others at MILA (the Montreal Institute for Learning Algorithms). Blocks expertise by Mohammad Pezeshki and Dima Bahdanau, Theano wizardry by Nicolas Ballas and David Krueger, lots of other code, general linux fu, and dark stats knowledge by Janos Kramar, general knowing what's going on at any given time and background research mostly David Krueger, this repo put together by Tegan Maharaj.\n\nImportant contributing ideas to this project include [dropout](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf), [stochastic depth](https://arxiv.org/pdf/1603.09382.pdf), [pseudoensembles](https://arxiv.org/abs/1412.4864), [resnets](https://arxiv.org/abs/1512.03385). Similar ideas were developed independently as [recurrent dropout without memory loss](http://arxiv.org/abs/1603.05118) (dropping the input gate), [swapout](https://arxiv.org/pdf/1605.06465.pdf) (idential to zoneout, but in feed-forward nets, where they call it skip-forward), and by [Pranav Shyam](https://github.com/pranv/lrh/blob/master/about.md). Dropout has been studied in recurrent nets by [Moon et al.](http://www.stat.berkeley.edu/~tsmoon/files/Conference/asru2015.pdf) (same units dropped at every time-step), [Gal](http://arxiv.org/abs/1512.05287) (same input and output gates dropped at every timestep + embedding dropout), [Zaremba et al.](http://arxiv.org/abs/1512.05287) (up the stack, not on recurrent connections), and [Pham et al.](https://arxiv.org/pdf/1312.4569.pdf) (on feed-forward connections only). For full references and more explanation of zoneout, see the paper.\n\nPlease feel free to contact the authors with any questions, comments, or suggestions!\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/teganmaharaj/zoneout",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-07-24T02:47:29Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-06T06:41:43Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9811743549717835,
        0.8886572775152454,
        0.9929141245309262,
        0.9062400891830801
      ],
      "excerpt": "This repo contains the code for replicating the results in Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations, as well as gists to help implement zoneout in your code (in Theano and Tensorflow). \nZoneout is a regularizer for RNNs. At each timestep, units have a random probability of maintaining their previous value. This can be seen as dropout using an identity mask instead of zero mask, or like a per-unit version of stochastic depth.  \nWe set state of the art on character-level Penn Treebank with 1.27 BPC, match state of the art 1.36 BPC on text8, and combine with recurrent batch normalization to set state of the art 95.9% accuracy on permuted sequential MNIST. We performed no hyperparameter search to get these results; just used settings/architectures from the previous state-of the art and in some cases searched over zoneout probabilites. \nFor details about each dataset, and why we chose them/what they demonstrate about zoneout, and for the exact hyperparameter settings used in each experiment, please see the 'Experiments' section of the paper (or look at the default arguments in each script). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9396093355854702
      ],
      "excerpt": "Zoneout (zoneout probability 0.15 on both cells and states of an LSTM) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8307192401269643
      ],
      "excerpt": "NOTE: Currently zoneout probabilities are (1-zoneout_probability) TO BE FIXED. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9890715112456975
      ],
      "excerpt": "Zoneout (with probability 0.5 of zoning out on cells and 0.05 on hidden states in LSTM) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8307192401269643
      ],
      "excerpt": "NOTE: Currently zoneout probabilities are (1-zoneout_probability) TO BE FIXED. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9890715112456975
      ],
      "excerpt": "Zoneout (with probability 0.5 of zoning out on cells and 0.05 on hidden states in LSTM) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8307192401269643
      ],
      "excerpt": "NOTE: Currently zoneout probabilities are (1-zoneout_probability) TO BE FIXED. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9890715112456975
      ],
      "excerpt": "Zoneout (with probability 0.2 of zoning out on cells and 0.2 on hidden states in LSTM) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9844287298991223
      ],
      "excerpt": "This is a simplified version of learning to execute, based on Erik Rehn's tensorflow code. These experiments are not yet in the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.918475719046725
      ],
      "excerpt": "A toy task demonstrating that networks with zoneout encourage units to retain semantic consistency over time. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9058434679286276
      ],
      "excerpt": "Code mostly from recurrent batch normalization, to demonstrate that networks with zoneout propagate information across timesteps more effectively. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8985940598657907
      ],
      "excerpt": "The repo contains implementations of zoneout in Theano (both pure Theano, and using the Blocks framework) and Tensorflow. You can adapt the scripts used to run the experiments, described above, or look at the following three gists: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code for experiments with our RNN regularizer, which stochastically forces units to maintain previous values. ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/teganmaharaj/zoneout/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 23,
      "date": "Sat, 25 Dec 2021 12:34:46 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/teganmaharaj/zoneout/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "teganmaharaj/zoneout",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8179300426494623
      ],
      "excerpt": "Zoneout is a regularizer for RNNs. At each timestep, units have a random probability of maintaining their previous value. This can be seen as dropout using an identity mask instead of zero mask, or like a per-unit version of stochastic depth.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8914707919536106
      ],
      "excerpt": "zoneout_pmnist.py --z_prob_states=0.15 --z_prob_cells=0.15 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8914707919536106
      ],
      "excerpt": "zoneout_pmnist.py --z_prob_states=0.15 --z_prob_cells=0.15 --batch_normalization \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "zoneout_char_ptb.py --weight_noise=0.075 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860968659888874
      ],
      "excerpt": "zoneout_char_ptb.py --norm_cost_coeff=50 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "zoneout_char_ptb.py --drop_prob_igates=0.7 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8229752695689834
      ],
      "excerpt": "zoneout_char_ptb.py --z_prob_cells=0.5 --z_prob_states=0.05 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8229752695689834
      ],
      "excerpt": "zoneout_word_ptb.py --z_prob_cells=0.5 --z_prob_states=0.05 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "zoneout_text8.py --weight_noise=0.075 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860968659888874
      ],
      "excerpt": "zoneout_text8.py --norm_cost_coeff=50 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "zoneout_text8.py --drop_prob_igates=0.5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "zoneout_text8.py --z_prob_cells=0.2 --z_prob_states=0.2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8229752695689834
      ],
      "excerpt": "zoneout_seq2seq.py --z_prob_cells=0.5 --z_prob_states=0.05 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/teganmaharaj/zoneout/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Zoneout",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "zoneout",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "teganmaharaj",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/teganmaharaj/zoneout/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 79,
      "date": "Sat, 25 Dec 2021 12:34:46 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1708.05144"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8405785960452465
      ],
      "excerpt": "Click here to see the Arxiv paper. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ghostFaceKillah/expert",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-09-09T20:52:35Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-12-18T06:54:27Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9499116176519303,
        0.9684308647419057
      ],
      "excerpt": "This repository contains code which combines the ACKTR \nalgorithm with expert trajctories.  Our \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8582393837617208,
        0.9719929739849889,
        0.9081518094073766,
        0.9677352638011232,
        0.9354018447282446
      ],
      "excerpt": "Click here to see Montezuma's Revenge gameplay videos \nClick here to see videos of bug exploits in Montezuma's Revenge \nIn the article we evaluate our algorithm on two environments with sparse \nrewards: Montezuma's Revenge and a maze from the ViZDoom suite. In the case of \nMontezuma's Revenge, an agent trained with our method achieves very good \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9896476899759318,
        0.9817904135517787
      ],
      "excerpt": "With an appropriate choice of hyperparameters, our algorithm surpasses the \nperformance of the expert data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8761563388928368,
        0.8010321924824041
      ],
      "excerpt": "exploits an unreported bug in Montezuma's Revenge and scores 804 900 points. \nOn the left, you can see part of typical evaluation in the second \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9671657517138987
      ],
      "excerpt": "Our algorithm is easy to understand and implement. Its core can be expressed in \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9355985515421412,
        0.8719630625841192
      ],
      "excerpt": "On the right, you can see the new loss term added by the algorithm, which is \nsimilar in spirit to the former one, but expectations are computed over batches \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9844203607953528
      ],
      "excerpt": "pseudocode of our algorithm : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9754587763366227
      ],
      "excerpt": "This code is based on OpenAI's baselines. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Expert-augmented actor-critic",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ghostFaceKillah/expert/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Wed, 22 Dec 2021 00:34:00 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ghostFaceKillah/expert/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ghostFaceKillah/expert",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "First, install either CPU-based `tensorflow`:\n```\npip install tensorflow==1.10.1\n```\nor if you have CUDA-enabled GPU and want to use it for this project (see\n[TensorFlow documentation](https://www.tensorflow.org/install/) for more\ndetails about TensorFlow GPU support):\n\n```\npip install tensorflow-gpu==1.10.1\n```\n\nThen install the rest of the requirements:\n\n```\npip install -r requirements.txt\n```\n\nNow you can:\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8210734663425701,
        0.8429504946994983
      ],
      "excerpt": "one formula: \nOn the left, you can see the standard actor-critic A2C loss \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8141111828479212
      ],
      "excerpt": "<img src=\"https://www.mimuw.edu.pl/~henrykm/eaacktr.png\" width=400/> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ghostFaceKillah/expert/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/ghostFaceKillah/expert/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License\\n\\nCopyright (c) 2018 Authors of expert-augmented actor critic algorithm that\\n                   remain anonymous for now (expert-augmented algorithm).\\nCopyright (c) 2017 OpenAI (http://openai.com) (baselines repository)\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\nTHE SOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Expert-augmented actor-critic for Montezuma's Revenge",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "expert",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ghostFaceKillah",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ghostFaceKillah/expert/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The optimal hardware for running these experiments is:\n\n* 1 CUDA GPU (for fast NN)\n* 1 strong CPU with many threads (for simulating many environments at the\n  same time).\n* around 5 GB of hard drive space to download and extract the expert\n      trajectories.\n\nIf you do not have a CPU with a lot of multi-threading, then you will probably\nneed to go down on number of environments (e.g.  `--num_env 16`), which\npotentially could make gradients more noisy.\n\nPlease follow the below steps to run the experiments.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "*Note!* Here you will additionally need `ffmpeg` to write periodic evaluation videos.\nInstall it by executing:\n\n- Mac              ```brew install ffmpeg```\n- Ubuntu 14.04     ```sudo apt-get install libav-tools```\n- for other newer versions of Ubuntu the following should work: ```sudo apt-get install ffmpeg```\n\n\nTo run the training, execute the following from within your virtualenv:\n\n```\npython -m baselines.acktr.run_atari_training\n```\n\nThis will start the training process.  On a computer with i7 CPU and GTX 1080\nGPU we see around 1500 fps.  To get results consistently beating the first\nworld, you will need to push around 200 M frames through the algorithm, so this\nwill take some time - around 36 hours @ 1500 fps.\n\nYou can watch the progress by watching the logs, which are written to\n```\n<project-root-dir>/openai-logs/<date-and-time-dependent-run-dir>\n```\nIf you go to this directory, you can use the command:\n```\nwatch -n1 'tail -n 3 *.monitor.csv'\n```\nto see various statistics of episodes in the sub-environments: episode lenghts,\nfinal scores and so on:\n\n```\n==> 0.monitor.csv <==\n8000.0,5626,6135.852456\n8000.0,1723,6176.941117\n5800.0,1796,6221.852446\n\n==> 1.monitor.csv <==\n8000.0,2819,5958.2911449\n8000.0,3972,6055.5009089\n8000.0,5346,6186.8718729\n\n```\n\nAbove you see output from 2 environments (out of default 32) and in each row\nthe subsequent numbers represent episode reward, episode length in number steps\nand time since training has begun.\n\nAdditionally, the system will periodically run 5 evaluation episodes, which will write:\n\n- some performance stats: episode total rewards, lengths\n- videos from evaluation episodes gameplay\n- current policy network parameters.\n\nYou will find these in folders:\n\n```\n<project-root>/vid/...\n```\n\nThis training code uses a pre-collected set of expert trajectories.  Currently,\nfor the convenience of first-time users of this repo, the default behavior is\nto download our set of expert trajectories.  However, you could potentially use\nyour own trajectories, by changing constants in `run_atari_training.py`.\nBy default, these trajectories are stored in folder:\n\n```\n<project-root>/in_data/\n```\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npython -m baselines.acktr.run_eval --model models/cool_model.npy\n```\n\nThis will load a pretrained model supplied with this repository.  You should\nexpect to see a screen pop up, where the neural net agent is going to play the\ngame. It should clear the first world (as taught by the expert) and pass some\npart of the second world.\n\nThe pre-trained model is stored in `<project-root>/models/cool_model.npy`.\nIf you run training script, it will periodically write policy parameters.\nYou can use the current script, passing the writen policy as `--model`\nparameter, to see how well they are playing.\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Wed, 22 Dec 2021 00:34:00 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npython -m baselines.acktr.run_eval --model models/cool_model.npy\n```\n\nThis will load a pretrained model supplied with this repository.  You should\nexpect to see a screen pop up, where the neural net agent is going to play the\ngame. It should clear the first world (as taught by the expert) and pass some\npart of the second world.\n\nThe pre-trained model is stored in `<project-root>/models/cool_model.npy`.\nIf you run training script, it will periodically write policy parameters.\nYou can use the current script, passing the writen policy as `--model`\nparameter, to see how well they are playing.\n",
      "technique": "Header extraction"
    }
  ]
}
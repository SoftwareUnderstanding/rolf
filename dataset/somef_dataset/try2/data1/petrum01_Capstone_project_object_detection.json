{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1708.02002"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.818289054600784
      ],
      "excerpt": "Training of a neural net for custom class object detection with Tensorflow Object Detection API. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9146894306581498
      ],
      "excerpt": "Custom-class object detection \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8198521980227379
      ],
      "excerpt": "Part 2 : Training the net \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772692606136239
      ],
      "excerpt": "Part 3 : Results \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8669112007448144
      ],
      "excerpt": "(source : https://ngrok.com/docs) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.842790493796475
      ],
      "excerpt": "False positives at 0,2 detection threshold: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9974360846542254
      ],
      "excerpt": "SSD with Mobilenet v1 FPN feature extractor, shared box predictor and focal loss (a.k.a Retinanet). (See Lin et al, https://arxiv.org/abs/1708.02002) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/petrum01/Capstone_project_object_detection",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-07-16T12:35:04Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-25T11:18:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This is a proposition for the Capstone project for the EPFL Extension School Applied Machine Learning program. The objective is to train a neural net for custom class object detection and run inference at the edge by:\n- building a custom data set and annotate it;\n- train a network using data augmentation techniques and transfer learning with fine-tuning of the last layers;\n- (if possible) running inference at the edge on a device with limited computing power.\n\nI will thoroughly document each phase of the project and draw conclusions on the best techniques to use.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8259701277457006
      ],
      "excerpt": "Collecting data for Training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8628942949263135
      ],
      "excerpt": "Choosing the architecture of the net \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860864035335576,
        0.940646734826736
      ],
      "excerpt": "I used this repo on github to collect images from the web. \nI chose a custom class of objects (speed-traps), and searched for specific keywords and also reverse searched for specific images, using the code below : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8296425190671427
      ],
      "excerpt": "It resulted in a very limited dataset (about 100 images), not coherent enough : different types of speed traps, different point of views... As a consequence, this dataset was discarded. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "Methodology for filming : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9673048584909685
      ],
      "excerpt": "- camera mounted on the dashboard of the car \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8129948245434555
      ],
      "excerpt": "I used RectLabel to: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9848205396438892,
        0.9525404988177153
      ],
      "excerpt": "TFRecord is Tensorflow\u2019s own binary storage format. We need to convert the dataset (images in .jpg format and annotations in .xml format) to this format in order to improve the performance of our import pipeline and as a consequence, lowering the training time of our model. \nIndeed, instead of loading the data simply using python code at each step and feed it into a graph, we will use an input pipeline which takes a list of files (in this case in TFRecord format), create a file queue, read, and decode the data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8979411005071259
      ],
      "excerpt": "    --label_map_path=\"creating_dataset/data/label_map.pbtxt\" \\ \n    --output_path=\"creating_dataset/data/\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8135539321839991
      ],
      "excerpt": "a = sum(1 for _ in tf.python_io.tf_record_iterator(\"creating_dataset/data/train.record\")) #: Counting the number of records \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9825773205140215
      ],
      "excerpt": "Frames 249 to 399 from GoPro footage on bad lighting conditions and also with small objects \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9462307360526426
      ],
      "excerpt": "I forked the Tensorflow repo on github and added some code to perform training, evaluation, and inference. I will link to the code I wrote in this readme. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9943427799367113,
        0.9181082645744216
      ],
      "excerpt": "There are a large number of model parameters to configure. The best settings will depend on your given application. Faster R-CNN models are better suited to cases where high accuracy is desired and latency is of lower priority. Conversely, if processing time is the most important factor, SSD models are recommended. \nThe aim is to find a model with a correct balance between detection accuracy and speed in order to make inference at the edge possible. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8676194720592108,
        0.969917252836263
      ],
      "excerpt": "I used Paperspace which is a cloud platform that provides Linux virtual machines with GPU computing power. \nThe setup is comprised of : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8278885601512788,
        0.8746874682508771
      ],
      "excerpt": "- a more detailed list of packages can be found here \nSetting up the virtual machine took quite a long time, as conflicts were frequent between libraries, especially with opencv. Also, finding the right combination of CUDA drivers & Tensorflow version was crucial. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8755522428150866
      ],
      "excerpt": "1. The model configuration. This defines what type of model will be trained \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8781875289236679
      ],
      "excerpt": "3. The eval_config, which determines what set of metrics will be reported for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "model { \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9387949532303894
      ],
      "excerpt": "Also, depending on the model, we will need to change the batch size, the data augmentation options, etc. Data augmentation options are the following (list not exhaustive, complete defintion of these augemntation techniques can be found here): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8267101743614287
      ],
      "excerpt": "Exporting a trained model for inference \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9638619045337637,
        0.9429789786303839
      ],
      "excerpt": "SSD is a popular algorithm in object detection. It\u2019s generally faster than Faster RCNN. Single Shot means that the tasks of object localization and classification are done in a single forward pass of the network (increases speed). \nSo my main goal by choosing this model is to have a decent inference speed, so I could perform inference with the trained model on a device with limited computing capability. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9819538702470982
      ],
      "excerpt": "Mobilenet is at the base of the net to make it faster. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9057470159959982
      ],
      "excerpt": "<!-- results gif are resized to 1280x... --> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9504587077974291,
        0.9034230967300377,
        0.8195579284784155
      ],
      "excerpt": "SSD with Resnet 50 v1 FPN feature extractor, shared box predictor and focal loss (a.k.a Retinanet). By using this model, we are trying to improve small object detection : \n1. resnet would theoretically allow for better detection of small objects by providing additional large-scale context \n2. trained on bigger image size 640x640 (instead of 300x300) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356862109149329
      ],
      "excerpt": "- at 25k : no detection, a bit of false positives (but strangely not exactly on objects, but near them) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908771048929542
      ],
      "excerpt": "But steady detection of some false positives  : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9466916495505272
      ],
      "excerpt": "The trained model still picks up false positives (see below at 0,2 detection threshold) but with less confidence. When bumping the detection threshold to 0,8, these false positives are not \"detected\" anymore (in fact, objects are detected, but bounding boxes are not drawn on the images for detection with a confidence level below 80%). But detection is (still) only effective from close range. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9646438707907522,
        0.9100102035696868,
        0.9533666320180452,
        0.857196767043539
      ],
      "excerpt": "SSD are fast, suited for inference at the edge, but provide poor detection, especially on small objects (i.e. on objects captured by the video from far). It is indeed a common problem that anchor-based detectors deteriorate greatly as objects become smaller. \nAlso, the need for complicated data augmentation suggests it needs a large number of data to train, and the dataset only provides a few hundred images. \nImage input size is also a factor in small objects detection, as ssd_mobilenet_v2_coco accepts only 300x300 images and ssd_resnet_50_fpn_coco accepts 640x640, so small objects in the original images of the dataset (1920x1080) will become almost invisible when resized to these resolutions. \nAdding background images (images with no groundtruth boxes) to the training dataset do decrease the confidence at which false positives are detected, but the overall poor detection discards these SSD models as a base for performing inference at the edge. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9228154786204829,
        0.9596659479379654,
        0.9592975973674531
      ],
      "excerpt": "But slower inference time and too many false positives, even when detection threshold is bumped : \nThe more it is trained, the more steadily the net detects the object, but also picks up the same false positives but with better (false) acuracy (this net was trained to 60k steps, but with no major improvements). \nKITTI datasets are captured by driving around the mid-size city of Karlsruhe, in rural areas and on highways. Up to 15 cars and 30 pedestrians are visible per image. This might be a good match to our detection problem. Raw KITTI images have a resolution of 1242x375 (about 13% more than the ssd_resnet50_v1 input training image size, and 500% bigger than ssd_mobilenet_v2_coco input training image size). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8303902043587585
      ],
      "excerpt": "The mean average precision at 25k is around 0.77: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9913700586747768,
        0.8497635553557195,
        0.981059127213227,
        0.849382889695028,
        0.9305247259870659,
        0.9322063468099394,
        0.9902206385759308,
        0.9422134028203384
      ],
      "excerpt": "The inference time on a machine with GPU (Quadro P4000) is quite slow, so usability of this model on devices with more limited computing power seems to be very unlikely. \nFaster RCNN provide better overall accuracy than SSD, especially on small objects. \nTraining is longer (in part because of the architecture of the net, and also because I had to lower the batch size due to memory limitations) \nThe trained network is too slow for performing inference on devices with limited computing capabilities. \nThe original objective was to (1) train a neural net to recognize a custom class object and (2) to perform inference at the edge on devices with limited computational power (like the Raspberry Pi). \nThe training dataset was challenging because it is composed of high resolution images (1920 x 1080). As a result, in many frames, the object is too small to be detected by fast networks that resize the input image to lower resolutions (300x300 or 640x640). \nUsing more accurate but heavier networks achieved better detection of small objects but these models fall short on objective n\u00b02, as it is always a trade-off between inference speed and accuracy. \nA way to use smaller networks but still achieve correct accuracy on smaller objects will be to train the networks with crops of the initial dataset images (that prevents losing details). Another solution that may help detect smaller objects may lie in the hyper parameters of anchor based detectors : reducing the anchors scale relative to the image. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8372396012058242
      ],
      "excerpt": "1 - faster_rcnn_resnet101_kitti (on Paperspace : training_newset) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9648209002079815
      ],
      "excerpt": "Specifying the keep_aspect_ratio_resizer follows the image resizing scheme described in the Faster R-CNN paper. In this case it always resizes an image so that the smaller edge is 600 pixels and if the longer edge is greater than 1024 edges, it resizes such that the longer edge is 1024 pixels. The resulting image always has the same aspect ratio as the input image. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8098577145853316
      ],
      "excerpt": "mAP see screenshots of tensorboard \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9119570721874409
      ],
      "excerpt": "continue to 80k to improve mAP small, that begun to take off at 10k \n",
      "technique": "Supervised classification"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We want to train the last layers of a model (or fine-tune the model) on our custom dataset. Training from scratch can take a long time, sometimes up to weeks depending on the computing power.\n\nPre-trained weights for different models are available [`here`](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md), models have been trained on different public datasets (COCO, Kitti, etc.)\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/petrum01/Capstone_project_object_detection/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 18:15:16 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/petrum01/Capstone_project_object_detection/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "petrum01/Capstone_project_object_detection",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8953564650381242
      ],
      "excerpt": "    os.mkdir(imdir) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8388727931959046
      ],
      "excerpt": "(old name : TFOD_latest_short.mp4, changed to gopro_footage_edited.mp4) --> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8361522261724501
      ],
      "excerpt": "I used Paperspace which is a cloud platform that provides Linux virtual machines with GPU computing power. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401102300216435
      ],
      "excerpt": "- each with a Quadro P4000 GPU \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8997431272352026
      ],
      "excerpt": "- tensorflow-gpu (1.12.0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9043929270298233
      ],
      "excerpt": "-- source \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8954634234568486
      ],
      "excerpt": "(source : https://ngrok.com/docs) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9296086630418646
      ],
      "excerpt": "weights : download from http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_kitti_2018_01_28.tar.gz \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9043929270298233
      ],
      "excerpt": "Source : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8053261829736755
      ],
      "excerpt": "from : https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8286691868160542
      ],
      "excerpt": "Collecting data for Training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8400662996661539,
        0.8659192988800521
      ],
      "excerpt": "Labelling and annotating train data \nConverting to TFRecord file format \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from google_images_download import google_images_download \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401558704798054
      ],
      "excerpt": "import os \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8140054219159956
      ],
      "excerpt": "Example of footage : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.81030181562507,
        0.8356625309826721
      ],
      "excerpt": "- generate annotation output in xml format for each image \n- splitting dataset into train & test sets : 80 / 20, effectively creating two .txt files with the list of images \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401558704798054
      ],
      "excerpt": "import os \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8007780711884419,
        0.8007780711884419,
        0.8369414384696661,
        0.8038790199104271
      ],
      "excerpt": "filesA = [os.path.splitext(filename)[0] for filename in os.listdir(annot_dir)] \nfilesB = [os.path.splitext(filename)[0] for filename in os.listdir(img_dir)] \nprint (\"images without annotations:\",set(filesB)-set(filesA)) \nTFRecord is Tensorflow\u2019s own binary storage format. We need to convert the dataset (images in .jpg format and annotations in .xml format) to this format in order to improve the performance of our import pipeline and as a consequence, lowering the training time of our model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8508683814789367
      ],
      "excerpt": "- copy annotations in images folder (images/annotation/) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python object_detection/dataset_tools/rectlabel_create_pascal_tf_record.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8454553703666403
      ],
      "excerpt": "    --image_list_path=\"creating_dataset/train.txt\" \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8013803951358645
      ],
      "excerpt": "    --output_path=\"creating_dataset/data/\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8035466385737231
      ],
      "excerpt": "We then can inspect tfrecord files to ensure the integrity of theses files and test if the conversion process went correctly by counting the number of records in the TFRecord train & test files. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174,
        0.9055504824720344,
        0.9537999710995941,
        0.8872117660718866,
        0.9179944178360583,
        0.8803378883708367,
        0.9188430966655352
      ],
      "excerpt": "import tensorflow as tf \nfor example in tf.python_io.tf_record_iterator(\"creating_dataset/data/test.record\"): #: inspecting one record \n    result = tf.train.Example.FromString(example) \na = sum(1 for _ in tf.python_io.tf_record_iterator(\"creating_dataset/data/train.record\")) #: Counting the number of records \nprint('Number of records in train:', a) \nb = sum(1 for _ in tf.python_io.tf_record_iterator(\"creating_dataset/data/test.record\")) \nprint('Number of records in test:', b) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8932655185681747
      ],
      "excerpt": "- 400 labeled images with a 80/20 split bewteen train & test sets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8296693435864978
      ],
      "excerpt": "  batch_size: 24 #:increase or decrease depending of GPU memory usage \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8032907799103481,
        0.8594142235991984
      ],
      "excerpt": "fine_tune_checkpoint: \"/pre-trained-model/model.ckpt\"    #:Path to extracted files of pre-trained model \nfrom_detection_checkpoint: true \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9357722893181073
      ],
      "excerpt": "    input_path: \"/data/train.record\"   #:Path to training TFRecord file \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9041088474871364
      ],
      "excerpt": "    input_path: \"/data/test.record\"  #: Path to testing TFRecord \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174540907975313,
        0.8715456731430311
      ],
      "excerpt": "Starting training \nFrom the training directory, run: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8127936446713937
      ],
      "excerpt": "MODEL_DIR=training/ #:path to the directory where training checkpoints will be saved \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python model_main.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8715456731430311
      ],
      "excerpt": "From the training directory, run: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8637214573224122
      ],
      "excerpt": "TRAINED_CKPT_PREFIX=training/model.ckpt-xxxx #:path to the desired checkpoint \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python export_inference_graph.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401499953318798
      ],
      "excerpt": "After adding 100 background images (images with no groundtruth boxes) to the training dataset, and re-training the previsous ssd_resnet50_v1 model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8057298881066928
      ],
      "excerpt": "| Model name  | Speed (ms) |    mAP | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.822834057556032,
        0.824186192878857
      ],
      "excerpt": "with default config params (batch_size : 64 or 32) : OOM \n- Modified config file : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8404401127821464
      ],
      "excerpt": "solution : Open variables_helper.py in models/research/object_detection/utils/variables_helper.py and replace all occurrences of logging with tf.logging (except for the import) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8507834648323528
      ],
      "excerpt": "REVERT ? variables_helper.py in models/research/object_detection/utils/variables_helper.py and replace all occurrences of logging with tf.logging (except for the import) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9447786322785288
      ],
      "excerpt": "in object_detection/utils/visualization_utils.py : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python model_main.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python export_inference_graph.py \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/petrum01/Capstone_project_object_detection/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Custom-class object detection",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Capstone_project_object_detection",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "petrum01",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/petrum01/Capstone_project_object_detection/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 18:15:16 GMT"
    },
    "technique": "GitHub API"
  }
}
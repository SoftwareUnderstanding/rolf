{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please cite deepface in your publications if it helps your research. Here are examples of its BibTeX entries:\n\n```BibTeX\n@inproceedings{serengil2020lightface,\n  title        = {LightFace: A Hybrid Deep Face Recognition Framework},\n  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},\n  booktitle    = {2020 Innovations in Intelligent Systems and Applications Conference (ASYU)},\n  pages        = {23-27},\n  year         = {2020},\n  doi          = {10.1109/ASYU50717.2020.9259802},\n  url          = {https://doi.org/10.1109/ASYU50717.2020.9259802},\n  organization = {IEEE}\n}\n```\n\n```BibTeX\n@inproceedings{serengil2021lightface,\n  title        = {HyperExtended LightFace: A Facial Attribute Analysis Framework},\n  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},\n  booktitle    = {2021 International Conference on Engineering and Emerging Technologies (ICEET)},\n  year         = {2021},\n  organization = {IEEE}\n}\n```\n\nAlso, if you use deepface in your GitHub projects, please add deepface in the requirements.txt.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{serengil2021lightface,\n  title        = {HyperExtended LightFace: A Facial Attribute Analysis Framework},\n  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},\n  booktitle    = {2021 International Conference on Engineering and Emerging Technologies (ICEET)},\n  year         = {2021},\n  organization = {IEEE}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{serengil2020lightface,\n  title        = {LightFace: A Hybrid Deep Face Recognition Framework},\n  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},\n  booktitle    = {2020 Innovations in Intelligent Systems and Applications Conference (ASYU)},\n  pages        = {23-27},\n  year         = {2020},\n  doi          = {10.1109/ASYU50717.2020.9259802},\n  url          = {https://doi.org/10.1109/ASYU50717.2020.9259802},\n  organization = {IEEE}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/serengil/deepface",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-08T20:42:28Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T19:24:41Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9703159004219826,
        0.8185272556086858
      ],
      "excerpt": "Deepface is a lightweight face recognition and facial attribute analysis (age, gender, emotion and race) framework for python. It is a hybrid face recognition framework wrapping state-of-the-art models: VGG-Face, Google FaceNet, OpenFace, Facebook DeepFace, DeepID, ArcFace and Dlib.  \nExperiments show that human beings have 97.53% accuracy on facial recognition tasks whereas those models already reached and passed that accuracy level. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A Lightweight Face Recognition and Facial Attribute Analysis (Age, Gender, Emotion and Race) Library for Python",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/serengil/deepface/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 665,
      "date": "Tue, 21 Dec 2021 21:45:09 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/serengil/deepface/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "serengil/deepface",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/serengil/deepface/master/tests/Fine-Tuning-Threshold.ipynb"
    ],
    "technique": "File Exploration"
  },
  "identifier": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://doi.org/10.1109/ASYU50717.2020.9259802",
      "technique": "Regular expression"
    }
  ],
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The easiest way to install deepface is to download it from [`PyPI`](https://pypi.org/project/deepface/). It's going to install the library itself and its prerequisites as well. The library is mainly based on TensorFlow and Keras.\n\n```python\npip install deepface\n```\n\nThen you will be able to import the library and use its functionalities.\n\n```python\nfrom deepface import DeepFace\n```\n\n**Facial Recognition** - [`Demo`](https://youtu.be/WnUVYQP4h44)\n\nA modern [**face recognition pipeline**](https://sefiks.com/2020/05/01/a-gentle-introduction-to-face-recognition-in-deep-learning/) consists of 5 common stages: [detect](https://sefiks.com/2020/08/25/deep-face-detection-with-opencv-in-python/), [align](https://sefiks.com/2020/02/23/face-alignment-for-face-recognition-in-python-within-opencv/), [normalize](https://sefiks.com/2020/11/20/facial-landmarks-for-face-recognition-with-dlib/), [represent](https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/) and [verify](https://sefiks.com/2020/05/22/fine-tuning-the-threshold-in-face-recognition/). Deepface handles all these common stages in the background. You can just call its verification, find or analysis function with a single line of code.\n\n**Face Verification** - [`Demo`](https://youtu.be/KRCvkNCOphE)\n\nThis function verifies face pairs as same person or different persons. It expects exact image paths as inputs. Passing numpy or based64 encoded images is also welcome.\n\n```python\nresult = DeepFace.verify(img1_path = \"img1.jpg\", img2_path = \"img2.jpg\")\n```\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-1.jpg\" width=\"95%\" height=\"95%\"></p>\n\n**Face recognition** - [`Demo`](https://youtu.be/Hrjp-EStM_s)\n\n[Face recognition](https://sefiks.com/2020/05/25/large-scale-face-recognition-for-deep-learning/) requires applying face verification many times. Herein, deepface has an out-of-the-box find function to handle this action. It's going to look for the identity of input image in the database path and it will return pandas data frame as output.\n\n```python\ndf = DeepFace.find(img_path = \"img1.jpg\", db_path = \"C:/workspace/my_db\")\n```\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-6-v2.jpg\" width=\"95%\" height=\"95%\"></p>\n\n**Face recognition models** - [`Demo`](https://youtu.be/i_MOwvhbLdI)\n\nDeepface is a **hybrid** face recognition package. It currently wraps many **state-of-the-art** face recognition models: [`VGG-Face`](https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/) , [`Google FaceNet`](https://sefiks.com/2018/09/03/face-recognition-with-facenet-in-keras/), [`OpenFace`](https://sefiks.com/2019/07/21/face-recognition-with-openface-in-keras/), [`Facebook DeepFace`](https://sefiks.com/2020/02/17/face-recognition-with-facebook-deepface-in-keras/), [`DeepID`](https://sefiks.com/2020/06/16/face-recognition-with-deepid-in-keras/), [`ArcFace`](https://sefiks.com/2020/12/14/deep-face-recognition-with-arcface-in-keras-and-python/) and [`Dlib`](https://sefiks.com/2020/07/11/face-recognition-with-dlib-in-python/). The default configuration uses VGG-Face model.\n\n```python\nmodels = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\"]\nresult = DeepFace.verify(img1_path = \"img1.jpg\", img2_path = \"img2.jpg\", model_name = models[1])\ndf = DeepFace.find(img_path = \"img1.jpg\", db_path = \"C:/workspace/my_db\", model_name = models[1])\n```\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-wrapped-models.png\" width=\"95%\" height=\"95%\"></p>\n\nFaceNet, VGG-Face, ArcFace and Dlib [overperforms](https://youtu.be/i_MOwvhbLdI) than OpenFace, DeepFace and DeepID based on experiments. Supportively, FaceNet /w 512d got 99.65%; FaceNet /w 128d got 99.2%; ArcFace got 99.41%; Dlib got 99.38%; VGG-Face got 98.78%; DeepID got 97.05; OpenFace got 93.80% accuracy scores on [LFW data set](https://sefiks.com/2020/08/27/labeled-faces-in-the-wild-for-face-recognition/) whereas human beings could have just 97.53%.\n\n**Similarity**\n\nFace recognition models are regular [convolutional neural networks](https://sefiks.com/2018/03/23/convolutional-autoencoder-clustering-images-with-neural-networks/) and they are responsible to represent faces as vectors. We expect that a face pair of same person should be [more similar](https://sefiks.com/2020/05/22/fine-tuning-the-threshold-in-face-recognition/) than a face pair of different persons.\n\nSimilarity could be calculated by different metrics such as [Cosine Similarity](https://sefiks.com/2018/08/13/cosine-similarity-in-machine-learning/), Euclidean Distance and L2 form. The default configuration uses cosine similarity.\n\n```python\nmetrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\nresult = DeepFace.verify(img1_path = \"img1.jpg\", img2_path = \"img2.jpg\", distance_metric = metrics[1])\ndf = DeepFace.find(img_path = \"img1.jpg\", db_path = \"C:/workspace/my_db\", distance_metric = metrics[1])\n```\n\nEuclidean L2 form [seems](https://youtu.be/i_MOwvhbLdI) to be more stable than cosine and regular Euclidean distance based on experiments.\n\n**Facial Attribute Analysis** - [`Demo`](https://youtu.be/GT2UeN85BdA)\n\nDeepface also comes with a strong facial attribute analysis module including [`age`](https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/), [`gender`](https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/), [`facial expression`](https://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/) (including angry, fear, neutral, sad, disgust, happy and surprise) and [`race`](https://sefiks.com/2019/11/11/race-and-ethnicity-prediction-in-keras/) (including asian, white, middle eastern, indian, latino and black) predictions.\n\n```python\nobj = DeepFace.analyze(img_path = \"img4.jpg\", actions = ['age', 'gender', 'race', 'emotion'])\n```\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-2.jpg\" width=\"95%\" height=\"95%\"></p>\n\nAge model got \u00b1 4.65 MAE; gender model got 97.44% accuracy, 96.29% precision and 95.05% recall as mentioned in its [tutorial](https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/).\n\n**Streaming and Real Time Analysis** - [`Demo`](https://youtu.be/-c9sSJcx6wI)\n\nYou can run deepface for real time videos as well. Stream function will access your webcam and apply both face recognition and facial attribute analysis. The function starts to analyze a frame if it can focus a face sequantially 5 frames. Then, it shows results 5 seconds.\n\n```python\nDeepFace.stream(db_path = \"C:/User/Sefik/Desktop/database\")\n```\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-3.jpg\" width=\"90%\" height=\"90%\"></p>\n\nEven though face recognition is based on one-shot learning, you can use multiple face pictures of a person as well. You should rearrange your directory structure as illustrated below.\n\n```bash\nuser\n\u251c\u2500\u2500 database\n\u2502   \u251c\u2500\u2500 Alice\n\u2502   \u2502   \u251c\u2500\u2500 Alice1.jpg\n\u2502   \u2502   \u251c\u2500\u2500 Alice2.jpg\n\u2502   \u251c\u2500\u2500 Bob\n\u2502   \u2502   \u251c\u2500\u2500 Bob.jpg\n```\n\n**Face Detectors** - [`Demo`](https://youtu.be/GZ2p2hj2H5k)\n\nFace detection and alignment are early stages of a modern face recognition pipeline. Experiments show that just alignment increases the face recognition accuracy almost 1%. [`OpenCV`](https://sefiks.com/2020/02/23/face-alignment-for-face-recognition-in-python-within-opencv/), [`SSD`](https://sefiks.com/2020/08/25/deep-face-detection-with-opencv-in-python/), [`Dlib`](https://sefiks.com/2020/07/11/face-recognition-with-dlib-in-python/),  [`MTCNN`](https://sefiks.com/2020/09/09/deep-face-detection-with-mtcnn-in-python/) and [`RetinaFace`](https://sefiks.com/2021/04/27/deep-face-detection-with-retinaface-in-python/) detectors are wrapped in deepface. OpenCV is the default detector.\n\n```python\nbackends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface']\n\n#:face detection and alignment\ndetected_face = DeepFace.detectFace(img_path = \"img.jpg\", detector_backend = backends[4])\n\n#:face verification\nobj = DeepFace.verify(img1_path = \"img1.jpg\", img2_path = \"img2.jpg\", detector_backend = backends[4])\n\n#:face recognition\ndf = DeepFace.find(img_path = \"img.jpg\", db_path = \"my_db\", detector_backend = backends[4])\n\n#:facial analysis\ndemography = DeepFace.analyze(img_path = \"img4.jpg\", detector_backend = backends[4])\n```\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-detectors.png\" width=\"90%\" height=\"90%\"></p>\n\n[RetinaFace](https://sefiks.com/2021/04/27/deep-face-detection-with-retinaface-in-python/) and [MTCNN](https://sefiks.com/2020/09/09/deep-face-detection-with-mtcnn-in-python/) seem to overperform in detection and alignment stages but they are slower than others. If the speed of your pipeline is more important, then you should use opencv or ssd. On the other hand, if you consider the accuracy, then you should use retinaface or mtcnn.\n\n<!--\n**Ensemble learning for face recognition** - [`Demo`](https://youtu.be/EIBJJJ0ECXU)\n\nA face recognition task can be handled by several models and similarity metrics. Herein, deepface offers a [special boosting and combination solution](https://sefiks.com/2020/06/03/mastering-face-recognition-with-ensemble-learning/) to improve the accuracy of a face recognition task. This provides a huge improvement on accuracy metrics. On the other hand, this runs much slower than single models.\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/stock-4.jpg\" width=\"70%\" height=\"70%\"></p>\n\n```python\nresp_obj = DeepFace.verify(\"img1.jpg\", \"img2.jpg\", model_name = \"Ensemble\")\ndf = DeepFace.find(img_path = \"img1.jpg\", db_path = \"my_db\", model_name = \"Ensemble\")\n```\n-->\n\n**API** - [`Demo`](https://youtu.be/HeKCQ6U9XmI)\n\nDeepface serves an API as well. You can clone [`/api/api.py`](https://github.com/serengil/deepface/tree/master/api/api.py) and pass it to python command as an argument. This will get a rest service up. In this way, you can call deepface from an external system such as mobile app or web.\n\n```\npython api.py\n```\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/deepface-api.jpg\" width=\"90%\" height=\"90%\"></p>\n\nFace recognition, facial attribute analysis and vector representation functions are covered in the API. You are expected to call these functions as http post methods. Service endpoints will be `http://127.0.0.1:5000/verify` for face recognition, `http://127.0.0.1:5000/analyze` for facial attribute analysis, and `http://127.0.0.1:5000/represent` for vector representation. You should pass input images as base64 encoded string in this case. [Here](https://github.com/serengil/deepface/tree/master/api), you can find a postman project.\n\n**Tech Stack** - [`Vlog`](https://youtu.be/R8fHsL7u3eE), [`Tutorial`](https://sefiks.com/2021/03/31/tech-stack-recommendations-for-face-recognition/)\n\nFace recognition models represent facial images as vector embeddings. The idea behind facial recognition is that vectors should be more similar for same person than different persons. The question is that where and how to store facial embeddings in a large scale system. Herein, deepface offers a represention function to find vector embeddings from facial images.\n\n```python\nembedding = DeepFace.represent(img_path = \"img.jpg\", model_name = 'Facenet')\n```\n\nTech stack is vast to store vector embeddings. To determine the right tool, you should consider your task such as face verification or face recognition, priority such as speed or confidence, and also data size.\n\n<p align=\"center\"><img src=\"https://raw.githubusercontent.com/serengil/deepface/master/icon/tech-stack.png\" width=\"90%\" height=\"90%\"></p>\n\n",
      "technique": "Header extraction"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/serengil/deepface/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Sefik Ilkin Serengil\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "deepface",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "deepface",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "serengil",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/serengil/deepface/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2903,
      "date": "Tue, 21 Dec 2021 21:45:09 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "There are many ways to support a project - starring\u2b50\ufe0f the GitHub repo is just one.\n\n",
      "technique": "Header extraction"
    }
  ],
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "face-recognition",
      "vgg-face",
      "facenet",
      "openface",
      "facial-expression-recognition",
      "age-prediction",
      "gender-prediction",
      "race-classification",
      "emotion-recognition",
      "deep-learning",
      "machine-learning",
      "deepface",
      "face-analysis",
      "tensorflow",
      "keras",
      "python",
      "deepid",
      "dlib",
      "arcface"
    ],
    "technique": "GitHub API"
  }
}
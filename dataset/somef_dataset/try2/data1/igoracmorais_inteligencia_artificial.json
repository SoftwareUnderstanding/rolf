{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1312.5602"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.997097607945819,
        0.9982345129564469,
        0.9995281761585764,
        0.9855082304992818,
        0.9988765256697356,
        0.9989915610472565,
        0.9999997521712795,
        0.9999999022088607
      ],
      "excerpt": "O uso de ferramentas de intelig\u00eancia artificial n\u00e3o \u00e9 recente, mas a verdade \u00e9 que, com a maior acessibilidade a softwares e pacotes que permitem o uso de modelos mais elaborados na \u00e1rea, juntamente com a redu\u00e7\u00e3o dos custos de processamento e armazenamento, criou-se o ambiente perfeito para impulsionar essa ci\u00eancia. As aplica\u00e7\u00f5es s\u00e3o v\u00e1rias, indo desde modelos de previs\u00e3o para o mercado financeiro at\u00e9 sistemas inteligentes que est\u00e3o revolucionando o que entendemos como itera\u00e7\u00e3o com as m\u00e1quinas. \nSem ter o intuito de esgotar o debate sobre o tema, esse projeto procura agrupar diversos notebooks do Python com exemplos de uso de ferramentas que envolvem duas importantes \u00e1reas da intelig\u00eancia artificial, Machine Learning e Deep Learning. \nUm problema de classifica\u00e7\u00e3o envolve uma vari\u00e1vel que cont\u00e9m classes (labels) e onde o modelo de previs\u00e3o procura aproximar, a partir de uma fun\u00e7\u00e3o espec\u00edfica, as vari\u00e1veis de input do conjunto de vari\u00e1veis de output que s\u00e3o as classes. Os modelos de classifica\u00e7\u00e3o, em intelig\u00eancia artificial, s\u00e3o denominados de \"aprendizado supervisionado\" (supervised learning). \nH\u00e1 diversos algoritmos em Machine Learning e Deep Learning que podem ser utilizados para problemas de classifica\u00e7\u00e3o e fica dif\u00edcil dizer qual deles performa melhor. Os resultados ir\u00e3o depender do tipo de problema que estamos avaliando e do comportamento dos dados. Abaixo discutimos rapidamente sobre alguns desses algoritmos. \nNesse tipo de algoritmo, denominado de m\u00e9todo de aprendizado supervisionado n\u00e3o param\u00e9trico, temos que as decis\u00f5es sobre o processo de classifica\u00e7\u00e3o ocorrem no formato de \u00e1rvore onde partimos de uma vis\u00e3o top-down. As decis\u00f5es s\u00e3o feitas com base no if-then-else e \u00e9 um algoritmo de f\u00e1cil implementa\u00e7\u00e3o e interpreta\u00e7\u00e3o, mas \u00e9 muito sens\u00edvel a problemas de classifica\u00e7\u00e3o do tipo imbalanced, onde uma classe tem mais dados que outra. Nesse caso, recomenda-se fazer um rebalanceamento das propor\u00e7\u00f5es dos dados antes de implementar o algoritmo. Outro problema com DT \u00e9 quando temos muitas vari\u00e1veis que representam as caracter\u00edsticas (input) e que podem gerar um overfit dos dados. \nEsse algoritmo \u00e9 baseado no teorema de Bayes e usado em problemas de aprendizado supervisionado assumindo que existe uma independ\u00eancia condicional entre os pares de valores das caracter\u00edsticas e classes. Esse algoritmo pode ser usado com poucos dados de treino e para diversos problemas reais acaba produzindo resultados satisfat\u00f3rios. Ele \u00e9 muito utilizado para classifica\u00e7\u00e3o de texto em an\u00e1lises do tipo NLP a partir da hipeotese de dados com distribui\u00e7\u00e3o multinomial. \nEsse \u00e9 um m\u00e9todo utilizado para otimizar o resultado da aplica\u00e7\u00e3o de diferentes algoritmos. A ideia \u00e9 combinar diversos estimadores em apenas um. Isso pode ser feito de tr\u00eas formas. i) fazendo uma m\u00e9dia de todos os estimadores usados, ou seja, selecionamos diferentes amostras. Podemos fazer isso a partir de dois modos, usando o Bagging (BaggingClassifier) ou o Forest of randomized trees, com RandomForestClassifier ou ExtraTreeClassifier; ii) Usa os estimadores de forma sequencial (boosting method) com o objetivo de reduzir o vi\u00e9s do estimador combinado. Podemos fazer isso a partir de dois modos. O primeiro usando o algoritmo AdaBoost ou ent\u00e3o via Gradient Tree Boosting que possui a vantagem de ser um algoritmo robusto a presen\u00e7a de outilier e tem boa capacidade de previs\u00e3o. E, por fim, podemos usar o iii) \u201cvoting classifier\u201d. Aqui, aplicamos diferentes algoritmos de classifica\u00e7\u00e3o e usamos um m\u00e9todo de vota\u00e7\u00e3o da maioria para escolher as classes que ser\u00e3o previstas. Recomenda-se o uso desse algoritmo para selecionar dentre diferentes modelos quando temos v\u00e1rias boas op\u00e7\u00f5es. \nEsse tema, tamb\u00e9m classificado na classe de modelos de Intelig\u00eancia Artificial, explora uma forma diferente de aprendizado onde temos um agente que aprende com as mudan\u00e7as que ocorrem no ambiente em que se encontra e seria uma mistura entre Deep Learning e Reinforcement Learning. Esse desenho acaba por gerar uma gama de aplica\u00e7\u00f5es interessantes como, carros aut\u00f4nomos, jogos, estrat\u00e9gias de marketing dentre outras. Veja que tanto os modelos de Machine Learning quanto os de Deep Learning s\u00e3o processos de aprendizado mas com foco em encontrar padr\u00f5es nos dados. Por outro lado, os modelos de RL (Reinforcement Learning) atuam com tentativa e erro para aprender com os dados, e criamos uma recompensa pelo acerto que acaba criando como objetivo a maximiza\u00e7\u00e3o dessa receita. Isso posto, podemos definir quais s\u00e3o as pe\u00e7as que v\u00e3o fazer parte da constru\u00e7\u00e3o de um modelo de RL. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9507374082549614
      ],
      "excerpt": "2. A\u00e7oes: esta relacionado ao conjunto de possibilidades de decisao que o agente pode fazer; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9869736242523148
      ],
      "excerpt": "Um dos papers mais famosos nesse tema foi publicado em 2013 pelo time de pesquisa do Google (Google's DeepMind) - Playing Atari with Deep Reinforcement Learning (https://arxiv.org/abs/1312.5602). No artigo \u00e9 introduzido o algoritmo \"Deep Q Network\" onde temos a fun\u00e7ao Q(s,a) que depende de dois par\u00e2metos, o estado e a a\u00e7ao. O Q-learning procura aprender com o valor que \u00e9 atribu\u00eddo a um dado estado, que \u00e9 o resultado da escolha de uma a\u00e7\u00e3o, e isso ir\u00e1 influenciar na decis\u00e3o (a\u00e7\u00e3o) seguinte. Esse n\u00e3o seria o \u00fanico m\u00e9todo de pol\u00edticas que governam as a\u00e7\u00f5es dos agentes, outro exemplo nessa linha seria o m\u00e9todo do gradiente, onde mapeamos a melhor fun\u00e7\u00e3o relacionada a uma a\u00e7\u00e3o. Uma das caracter\u00edsticas do Q-learning \u00e9 que podemos regular as decis\u00f5es do agente com base em par\u00e2metros que ir\u00e3o dizer se o foco seria uma recompensa de curto ou de longo prazo.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999996370083669
      ],
      "excerpt": "Veja que para problemas de menor magnitude de estados, o uso da Q-table para avaliar o aprendizado se torna fact\u00edvel, mas para aplica\u00e7\u00f5es onde temos muito mais estados, a matriz (Q-table) seria impratic\u00e1vel. Nesse ponto passamos a usar redes neurais no processo de aprendizado. A vantagem de usar redes neurais para a solu\u00e7\u00e3o do aprendizado \u00e9 que passamos a ter a possibilidade de aplicar qualquer n\u00famero de estados na an\u00e1lise. Para tanto, usamos os estados como input que ir\u00e1 ter como output os resultados de valores em Q-values. A diferen\u00e7a que surge agora nesse processo \u00e9 que antes, com a Q-table, o processo de atualiza\u00e7\u00e3o era feito diretamente na tabela. Agora, usamos uma fun\u00e7\u00e3o perda e o princ\u00edpio do backpropagation para fazer essa atualiza\u00e7\u00e3o, com a vantagem de termos flexibilidade de inserir mais layers, mudar a fun\u00e7\u00e3o de ativa\u00e7\u00e3o, a quantidade de inputs e a pr\u00f3pria fun\u00e7\u00e3o perda. Abaixo est\u00e1 uma extensa lista de op\u00e7\u00f5es de leitura sobre o tema RL. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9747762585923935
      ],
      "excerpt": "https://github.com/changwookjun/StudyBook  (extensa lista de publicacoes - vale a pena ver) <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9604218683075487
      ],
      "excerpt": "https://medium.com/@gaurav1086/machine-learning-for-algorithmic-trading-f79201c8bac6   <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9626356225854676
      ],
      "excerpt": "https://github.com/kh-kim/stock_market_reinforcement_learning   <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9105368110547479
      ],
      "excerpt": "https://github.com/edwardhdlu/q-trader   <br> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/igoracmorais/inteligencia_artificial",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-12-14T21:29:47Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-07T21:15:00Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8819609745237379
      ],
      "excerpt": "https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0 .  (um tutorial simples)  <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8001061113490183,
        0.8714057433826875,
        0.8354371379147127
      ],
      "excerpt": "https://towardsdatascience.com/applications-of-reinforcement-learning-in-real-world-1a94955bcd12   <br> \nhttps://medium.freecodecamp.org/an-introduction-to-q-learning-reinforcement-learning-14ac0b4493cc   <br> \nhttps://www.analyticsvidhya.com/blog/2017/01/introduction-to-reinforcement-learning-implementation/   <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9205723155223648
      ],
      "excerpt": "http://www.wildml.com/2018/02/introduction-to-learning-to-trade-with-reinforcement-learning/   <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Diferentes aplica\u00e7\u00f5es de algoritmos de intelig\u00eancia artificial (Machine Learning e Deep Learning).",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/igoracmorais/inteligencia_artificial/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Fri, 24 Dec 2021 23:28:45 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/igoracmorais/inteligencia_artificial/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "igoracmorais/inteligencia_artificial",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/igoracmorais/inteligencia_artificial/master/Random_Forest.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8965483576075823
      ],
      "excerpt": "https://github.com/PacktPublishing/Predictive-Analytics-with-TensorFlow .  (livro sobre RL) . <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8918974083095406
      ],
      "excerpt": "https://github.com/edwardhdlu/q-trader   <br> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/igoracmorais/inteligencia_artificial/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Inteligencia Artificial",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "inteligencia_artificial",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "igoracmorais",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/igoracmorais/inteligencia_artificial/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Fri, 24 Dec 2021 23:28:45 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Esse m\u00e9todo \u00e9 muito eficiente em problemas de aprendizado supervisionado e pode ser aplicado tanto para regress\u00e3o, classifica\u00e7\u00e3o quanto para detec\u00e7\u00e3o de outliers. Uma das vantagens do uso do SVM \u00e9 que temos diversos par\u00e2metros que podem ser controlados, em especial a fun\u00e7\u00e3o kernel que ir\u00e1 produzir a divis\u00e3o das classes.\n",
      "technique": "Header extraction"
    }
  ],
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "lstm",
      "lstm-neural-networks",
      "deep-learning",
      "inteligencia-artificial",
      "keras-neural-networks"
    ],
    "technique": "GitHub API"
  }
}
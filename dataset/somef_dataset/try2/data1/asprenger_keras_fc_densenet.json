{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1611.09326",
      "https://arxiv.org/abs/1512.03385",
      "https://arxiv.org/abs/1608.06993",
      "https://arxiv.org/abs/1611.09326](https://arxiv.org/abs/1611.09326",
      "https://arxiv.org/abs/1611.09326"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/asprenger/keras_fc_densenet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-09-11T08:26:49Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-04T11:45:57Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Fully Convolutional Networks (FCNs) are a natural extension of CNNs to tackle per pixel prediction problems such as semantic image\nsegmentation. FCNs add upsampling layers to standard CNNs to recover the spatial resolution of the input at the output layer. In \norder to compensate for the resolution loss induced by pooling layers, FCNs introduce skip connections between their downsampling \nand upsampling paths. Skip connections help the upsampling path recover fine-grained information from the downsampling layers.\n\nOne evolution of CNNs are [Residual Networks](https://arxiv.org/abs/1512.03385) (ResNets). ResNets are designed to ease the training of \nvery deep networks by introducing a residual block that sums the non-linear transformation of the input and its identity mapping. \nThe identity mapping is implemented by means of a shortcut connection. ResNets can be extended to work as FCNs. ResNets incorporate \nshortcut paths to FCNs and increase the number of connections within a network. This additional shortcut paths improve the segmentation \naccuracy and also help the network to converge faster.\n\nRecently another CNN architecture called [DenseNet](https://arxiv.org/abs/1608.06993) has been introduced. DenseNets are built from \n*dense blocks* and pooling operations, where each dense block is an iterative concatenation of previous feature maps. This architecture \ncan be seen as an extension of ResNets, which performs iterative summation of previous feature maps. The result of this modification \nis that DenseNets are more efficient in there parameter usage.\n\nThe [https://arxiv.org/abs/1611.09326](https://arxiv.org/abs/1611.09326) paper extends DenseNets to work as FCNs by adding an upsampling \npath to recover the full input resolution.\n \n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9383214353309023,
        0.8836964681318108
      ],
      "excerpt": "This is a Keras implementation of the Fully Convolutional DenseNets for Semantic Segmentation paper. \nThe model is trained on the CamVid dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9523510486394848
      ],
      "excerpt": "Retrain model with full image size 384x480: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Keras implementation of the Fully Convolutional DenseNets for Semantic Segmentation paper. ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/asprenger/keras_fc_densenet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Mon, 20 Dec 2021 15:20:37 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/asprenger/keras_fc_densenet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "asprenger/keras_fc_densenet",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/asprenger/keras_fc_densenet/master/notebooks/Inference%20with%20Estimator.ipynb",
      "https://raw.githubusercontent.com/asprenger/keras_fc_densenet/master/notebooks/Inference%20with%20Graph.ipynb",
      "https://raw.githubusercontent.com/asprenger/keras_fc_densenet/master/notebooks/Test%20random%20crop.ipynb",
      "https://raw.githubusercontent.com/asprenger/keras_fc_densenet/master/notebooks/Plot%20CamVid%20TFRecord%20images%20.ipynb",
      "https://raw.githubusercontent.com/asprenger/keras_fc_densenet/master/notebooks/Inference%20for%20new%20image.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8269424148550226,
        0.9893272198983933
      ],
      "excerpt": "Clone Github repo with CamVid data \ngit clone https://github.com/mostafaizz/camvid.git \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8406656370926594
      ],
      "excerpt": "    --train-path ./camvid-preprocessed/camvid-384x480-train.tfrecords \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8406656370926594
      ],
      "excerpt": "    --train-path ./camvid-preprocessed/camvid-384x480-train.tfrecords \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8747790244230759,
        0.8286689085933078,
        0.9503189345333785,
        0.8551928889545153,
        0.858818203820365
      ],
      "excerpt": "python write_camvid_tfrecords.py --input-path ./camvid --output-path ./camvid-preprocessed --image-height 384 --image-width 480 \nTrain model with cropped image size 224x224: \npython -u train.py \\ \n    --train-path ./camvid-preprocessed/camvid-384x480-train.tfrecords \\ \n    --test-path ./camvid-preprocessed/camvid-384x480-test.tfrecords \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503189345333785,
        0.8551928889545153,
        0.858818203820365
      ],
      "excerpt": "python -u train.py \\ \n    --train-path ./camvid-preprocessed/camvid-384x480-train.tfrecords \\ \n    --test-path ./camvid-preprocessed/camvid-384x480-test.tfrecords \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156781332708049
      ],
      "excerpt": "<img src=\"images/camvid_eval_loss.png\" height=\"384\" width=\"480\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156781332708049
      ],
      "excerpt": "<img src=\"images/camvid_eval_iou.png\" height=\"384\" width=\"480\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156781332708049
      ],
      "excerpt": "<img src=\"images/camvid_eval_accuracy.png\" height=\"384\" width=\"480\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156781332708049
      ],
      "excerpt": "<img src=\"images/camvid_eval_loss_retrain.png\" height=\"384\" width=\"480\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156781332708049
      ],
      "excerpt": "<img src=\"images/camvid_eval_iou_retrain.png\" height=\"384\" width=\"480\"/> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/asprenger/keras_fc_densenet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Keras Fully Connected DenseNet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "keras_fc_densenet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "asprenger",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/asprenger/keras_fc_densenet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Mon, 20 Dec 2021 15:20:37 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "keras",
      "tensorflow",
      "machine-learning",
      "densenet",
      "image-processing"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Here are the color encodings for the labels:\n\n![\"LabelsColorKey\"](images/LabelsColorKey.jpg?raw=true \"LabelsColorKey\")\n\nThe following examples show the original image, the true label map and the predicted label map:\n\n![\"camvid-segmentation-1\"](images/camvid-segmentation-1.png?raw=true \"camvid-segmentation-1\")\n\n![\"camvid-segmentation-1\"](images/camvid-segmentation-2.png?raw=true \"camvid-segmentation-2\")\n\n![\"camvid-segmentation-3\"](images/camvid-segmentation-3.png?raw=true \"camvid-segmentation-3\")\n\n![\"camvid-segmentation-4\"](images/camvid-segmentation-4.png?raw=true \"camvid-segmentation-4\")\n\n![\"camvid-segmentation-5\"](images/camvid-segmentation-5.png?raw=true \"camvid-segmentation-5\")\n\n",
      "technique": "Header extraction"
    }
  ]
}
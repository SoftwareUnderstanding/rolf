{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1509.02971. \n\nThis algorithm builds on the DPG deterministic actor-critic approach proposed by Silver et al in \"Deterministic \nPolicy Gradient Algorithms\", available at http://proceedings.mlr.press/v32/silver14.pdf. DDPG combines this approach with the \nsuccesses of deep learning from DQN. It is model-free, off-policy, and has been shown to learn complex continuous control \ntasks in high dimensions quite well. \n\nStandard stochastic PG involves taking the expectation over the distribution of actions to calculate the gradient step. \nDDPG simply moves the policy in the direction of the gradient of Q, removing the need for an integral over the action space, \nmaking it much more efficient at learning in our environment.\n\nIn DDPG the algorithm builds a critic network to estimate the state action value function, Q(s,a"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8654671031158477
      ],
      "excerpt": "Stanford CS234 Final Project, Winter 2019 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9997466159087042
      ],
      "excerpt": "arXiv at https://arxiv.org/abs/1509.02971.  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bmeyers/VirtualMicrogridSegmentation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-02-15T01:46:56Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-17T02:57:42Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9784281680876207
      ],
      "excerpt": "Project team: Bennet Meyers and Siobhan Powell \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8886728142610594
      ],
      "excerpt": "caused by events such as cyber attacks or extreme weather. A subclass of microgrids, known as \u201cvirtual  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9894442502012627,
        0.8548542585218477
      ],
      "excerpt": "The goal of this project is to train a deep reinforcement learning (RL) agent to create and maintain as many small virtual  \nislands as possible by operating a grids storage resources. The agent is rewarded for separating nodes from the external \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9140286204185826
      ],
      "excerpt": "As our environment is deterministic, we implement PG (policy gradient) and DDPG (deep deterministic policy gradient) algorithms to train the agent, and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9409278561600545
      ],
      "excerpt": "The DDPG algorithm was introduced by Lillicrap et al in \"Continous control with deep reinforcement learning\", available on \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8169927213894398
      ],
      "excerpt": "This algorithm builds on the DPG deterministic actor-critic approach proposed by Silver et al in \"Deterministic  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9818785136726175
      ],
      "excerpt": "successes of deep learning from DQN. It is model-free, off-policy, and has been shown to learn complex continuous control  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9090938266637466,
        0.9700339034337547,
        0.9409974077566531,
        0.9057418446675194
      ],
      "excerpt": "Standard stochastic PG involves taking the expectation over the distribution of actions to calculate the gradient step.  \nDDPG simply moves the policy in the direction of the gradient of Q, removing the need for an integral over the action space,  \nmaking it much more efficient at learning in our environment. \nIn DDPG the algorithm builds a critic network to estimate the state action value function, Q(s,a). An actor network is built to  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9670605067074873,
        0.9630800448610193,
        0.9918051181192655,
        0.978494095823162,
        0.9045920025692501
      ],
      "excerpt": "policy by adding noise to the action choice to properly explore the solution space. The tuning and scheduling of this exploration  \nnoise term is crucial to the success of the algorithm.  \nTo help with convergence and stability, the algorithm is implemented with experience replay and with semi-stationary target \nnetworks. For more information on the theory and the algorithm applied, please refer to the papers. \nThere are two main sides to the code: the network and the agents.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9813013933695146,
        0.9549042413325354,
        0.9117648146304922
      ],
      "excerpt": "and with the powerflow simulations with methods to step in time, calculate the reward, reset the network,  \nreport the state to the agent, and update the network devices. These devices include uncontrollable and controllable devices:  \nloads and static generators are set by an uncontrollable unknown feed;  the powers of storage and diesel generators are  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8555378287755971
      ],
      "excerpt": "The initial network is generated by functions in powerflow/network_generation.py using configurations stored \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8314028759109751,
        0.8415567473460231,
        0.9276582926004067,
        0.8696218034012428,
        0.8051406325308934
      ],
      "excerpt": "elements of the agent set up.    \nThe ActorNetwork and CriticNetwork objects are created in agents/actor_network.py and agents/critic_network.py, and the  \nDDPG object uses them to learn the optimal policy. DDPG manages the training of the actor/critic networks \nand controls the interactions with the grid network model. \nThe main folder contains scratch notebooks for testing, developing, and interacting with the environments. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8280590164441093,
        0.8214092894518994,
        0.8841540483354903
      ],
      "excerpt": "The virtual_microgrids folder contains all the pieces of the simulation. To run you do not need to change anything in here, \nbut to change parameters or change the algorithm you will need to work with these files. \n- The subfolder agents contains the classes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8723283837586853,
        0.9435553404782917
      ],
      "excerpt": "- The powerflow subfolder contains a class to manage the power network and functions to create the networks from the config files \n- The utils subfolder contains tools used throughout the other methods and functions, including the schedules used to generate the noise \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "CS234 Project, Winter 2019",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://pandapower.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bmeyers/VirtualMicrogridSegmentation/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Sat, 25 Dec 2021 12:45:26 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/bmeyers/VirtualMicrogridSegmentation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "bmeyers/VirtualMicrogridSegmentation",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/bmeyers/VirtualMicrogridSegmentation/master/Functioning_environment_test.ipynb",
      "https://raw.githubusercontent.com/bmeyers/VirtualMicrogridSegmentation/master/Siobhan_scratch_testing.ipynb",
      "https://raw.githubusercontent.com/bmeyers/VirtualMicrogridSegmentation/master/Interacting_with_pp_network.ipynb",
      "https://raw.githubusercontent.com/bmeyers/VirtualMicrogridSegmentation/master/POC_6bus.ipynb",
      "https://raw.githubusercontent.com/bmeyers/VirtualMicrogridSegmentation/master/testing.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9241977157816482
      ],
      "excerpt": "The scripts folder contains scripts to run the algorithms. For example, change the environment name or config name \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8782733222605915,
        0.9246227682586091
      ],
      "excerpt": "in run_ddpg.py and then run \npython run_ddpgy.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8624833165058566
      ],
      "excerpt": "create a new config file in the style of six_bus_mvp1.py, for example.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8147407180424245
      ],
      "excerpt": "tensorboard --logdir [path to results folder]  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/bmeyers/VirtualMicrogridSegmentation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 2-Clause \"Simplified\" License",
      "url": "https://api.github.com/licenses/bsd-2-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 2-Clause License\\n\\nCopyright (c) 2019, Bennet Meyers\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n Redistributions of source code must retain the above copyright notice, this\\n  list of conditions and the following disclaimer.\\n\\n Redistributions in binary form must reproduce the above copyright notice,\\n  this list of conditions and the following disclaimer in the documentation\\n  and/or other materials provided with the distribution.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Virtual Microgrid Segmentation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "VirtualMicrogridSegmentation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "bmeyers",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bmeyers/VirtualMicrogridSegmentation/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Sat, 25 Dec 2021 12:45:26 GMT"
    },
    "technique": "GitHub API"
  }
}
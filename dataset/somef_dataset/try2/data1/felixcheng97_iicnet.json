{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Some codes of this repository benefit from [Invertible Image Rescaling (IRN)](https://github.com/pkuxmq/Invertible-Image-Rescaling.git).\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2109.04242"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this work useful, please cite our paper:\n```\n@inproceedings{cheng2021iicnet,\n    title     = {IICNet: A Generic Framework for Reversible Image Conversion}, \n    author    = {Ka Leong Cheng and Yueqi Xie and Qifeng Chen},\n    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},\n    year      = {2021},\n    pages     = {1991--2000}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{cheng2021iicnet,\n    title     = {IICNet: A Generic Framework for Reversible Image Conversion}, \n    author    = {Ka Leong Cheng and Yueqi Xie and Qifeng Chen},\n    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},\n    year      = {2021},\n    pages     = {1991--2000}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9662459403846485
      ],
      "excerpt": "External Links: Pre-recorded Video | Demo Video | Supplements \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222383658450612,
        0.8093058196359648
      ],
      "excerpt": "    |-- DAVIS-2017 \n    |   |-- DAVIS-2017-test-challenge (rename the DAVIS folder from DAVIS-2017-test-challenge-480p.zip) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222383658450612
      ],
      "excerpt": "    |-- DAVIS-2017 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222383658450612
      ],
      "excerpt": "    |-- DAVIS-2017 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222383658450612
      ],
      "excerpt": "    |-- DAVIS-2017 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222383658450612
      ],
      "excerpt": "    |-- DAVIS-2017 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222383658450612
      ],
      "excerpt": "    |-- DAVIS-2017 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/felixcheng97/IICNet",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Feel free to open an issue if you have any question. You could also directly contact us through email at klchengad@connect.ust.hk (Ka Leong Cheng) and yxieay@connect.ust.hk (Yueqi Xie).\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-29T07:25:21Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-24T05:08:53Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Reversible image conversion (RIC) aims to build a reversible transformation between specific visual content (e.g., short videos) and an embedding image, where the original content can be restored from the embedding when necessary. This work develops Invertible Image Conversion Net (IICNet) as a generic solution to various RIC tasks due to its strong capacity and task-independent design. Unlike previous encoder-decoder based methods, IICNet maintains a highly invertible structure based on invertible neural networks (INNs) to better preserve the information during conversion. We use a relation module and a channel squeeze layer to improve the INN nonlinearity to extract cross-image relations and the network flexibility, respectively. Experimental results demonstrate that IICNet outperforms the specifically-designed methods on existing RIC tasks and can generalize well to various newly-explored tasks. With our generic IICNet, we no longer need to hand-engineer task-specific embedding networks for rapidly occurring visual content.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9523697951432702
      ],
      "excerpt": "Official PyTorch Implementation for IICNet: A Generic Framework for Reversible Image Conversion (ICCV2021).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9155898055275765
      ],
      "excerpt": "To enable distributed training with multiple GPUs for a specific task, simply assign a list of gpu_ids in the yml file and run the following script. Note that since training with multiple GPU is not tested yet, we suggest to train a model with a single GPU. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9335255025553768
      ],
      "excerpt": "We provide our trained models in our paper for your reference. Download all the pretrained weights of our models from Google Drive or Baidu Drive (extraction code: e377). Unzip the zip file and place pretrained models under the ./experiments directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "[ICCV2021] IICNet: A Generic Framework for Reversible Image Conversion",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/felixcheng97/iicnet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Sat, 25 Dec 2021 12:32:56 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/felixcheng97/IICNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "felixcheng97/IICNet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We conduct experments on 5 multiple-and-single RIC tasks in the main paper and 2 single-and-single RIC tasks in the supplements. Note that all the datasets are placed under the `./datasets` directory.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Clone this repository and set up the environment.\n```bash\ngit clone https://github.com/felixcheng97/IICNet.git\ncd IICNet/\nconda env create -f iic.yml\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8700643475813605,
        0.9116312771103943
      ],
      "excerpt": "Then run the following scripts for annotation. \ncd codes/scripts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8700643475813605,
        0.9116312771103943
      ],
      "excerpt": "Then run the following scripts for annotation. \ncd codes/scripts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8700643475813605,
        0.9116312771103943
      ],
      "excerpt": "Then run the following scripts for annotation. \ncd codes/scripts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8700643475813605,
        0.9116312771103943
      ],
      "excerpt": "Then run the following scripts for annotation. \ncd codes/scripts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8700643475813605,
        0.9116312771103943
      ],
      "excerpt": "Then run the following scripts for annotation. \ncd codes/scripts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8700643475813605,
        0.9116312771103943
      ],
      "excerpt": "Then run the following scripts for annotation \ncd codes/scripts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9116312771103943
      ],
      "excerpt": "cd codes/scripts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.911824578519624
      ],
      "excerpt": "cd codes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.911824578519624
      ],
      "excerpt": "cd codes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.911824578519624
      ],
      "excerpt": "cd codes \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python davis_annotation.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633989807152664
      ],
      "excerpt": "    |   |-- Test \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python flicker1024_annotation.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python div2kddual_annotation.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8017285540429218,
        0.8017285540429218
      ],
      "excerpt": "    |   |-- Addobe_Deep_Matting_Dataset.zip \n    |   |-- train2014.zip \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091,
        0.9246227682586091
      ],
      "excerpt": "python adobe_process.py \npython adobe_annotation.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091,
        0.9246227682586091
      ],
      "excerpt": "python real_process.py \npython real_annotation.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python flicker_annotation.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python voc2012_annotation.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python div2ksr_annotation.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8062278781444256
      ],
      "excerpt": "OMP_NUM_THREADS=4 python train.py -opt ./conf/train/&lt;xxx&gt;.yml \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/felixcheng97/IICNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 felixcheng97\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "IICNet - Invertible Image Conversion Net",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "IICNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "felixcheng97",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/felixcheng97/IICNet/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 39,
      "date": "Sat, 25 Dec 2021 12:32:56 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/molomono/CartPole_Optimized_DDQN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-06-12T19:40:19Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-08T11:08:41Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9628130221293034,
        0.9825294681546671
      ],
      "excerpt": "This repository contains the implementation of a DDQN agent to solve the CartPole-v0 problem. I use openai_gym to simulate the environment. \nThe network implemented is a Double Deep Q-learning Network. Using Hindsight Experience Replay to perform online mini-batch learning. The framework used is Tensorflow. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9033039926284837,
        0.8585966457387605
      ],
      "excerpt": "This network is implemented as an Agent that interacts with an Environment, which takes an action as input and returns both a reward and an observation as output. \nThe environment used is the OpenAI Gym CartPole-v0 problem which has a 2-dimensional discrete action space and a continuous 4-dimensional system-state observation space. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9794188229359403,
        0.9235452822135312
      ],
      "excerpt": "To further improve the performance of the AI it has been wrapped in a function which takes hyperparameters as input and returns a quality factor indicating the performance of the AI after every epoch. The current implementation uses an epoch of 300 episodes and returns the average cumulative reward for the last 100 episodes of each epoch. \nThis function is passed to a Gaussian Process-based Bayesian Optimizer written by Sheffield Machine Learning. Where the hyperparameters are used as the predictors in a black box equation that returns -1 x Average Commulative Reward. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This repository contains the implementation of a DDQN agent to solve the CartPole-v0 problem. I use openai gym to simulate the environment.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/molomono/CartPole_Optimized_DDQN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 23:08:18 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/molomono/CartPole_Optimized_DDQN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "molomono/CartPole_Optimized_DDQN",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/molomono/CartPole_Optimized_DDQN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "CartPole_Optimized_DDQN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "CartPole_Optimized_DDQN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "molomono",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/molomono/CartPole_Optimized_DDQN/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 27 Dec 2021 23:08:18 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "reinforcement-learning",
      "ddqn",
      "cartpole",
      "openai-gym",
      "tensorflow",
      "keras",
      "hyperparameter-optimization",
      "gaussian-processes",
      "bayesian-optimization"
    ],
    "technique": "GitHub API"
  }
}
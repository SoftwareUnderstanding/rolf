{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1406.2661</a>.\n</li>\n<li>[2]:\nDiederik P Kingma, Max Welling: \u201cAuto-Encoding Variational Bayes\u201d, 2013; <a href='http://arxiv.org/abs/1312.6114'>https://arxiv.org/abs/1312.6114</a>.\n</li>\n<li>[3]:\nIlya Tolstikhin, Olivier Bousquet, Sylvain Gelly, Bernhard Schoelkopf: \u201cWasserstein Auto-Encoders\u201d, 2017; <a href='http://arxiv.org/abs/1711.01558'>https://arxiv.org/abs/1711.01558</a>.\n</li>\n<li>[4]:\nGiorgio Patrini, Rianne van den Berg, Patrick Forr\u00e9, Marcello Carioni, Samarth Bhargav, Max Welling, Tim Genewein, Frank Nielsen: \u201cSinkhorn AutoEncoders\u201d, 2018; <a href='http://arxiv.org/abs/1810.01118'>https://arxiv.org/abs/1810.01118</a>.\n</li>\n</ul>",
      "https://arxiv.org/abs/1312.6114</a>.\n</li>\n<li>[3]:\nIlya Tolstikhin, Olivier Bousquet, Sylvain Gelly, Bernhard Schoelkopf: \u201cWasserstein Auto-Encoders\u201d, 2017; <a href='http://arxiv.org/abs/1711.01558'>https://arxiv.org/abs/1711.01558</a>.\n</li>\n<li>[4]:\nGiorgio Patrini, Rianne van den Berg, Patrick Forr\u00e9, Marcello Carioni, Samarth Bhargav, Max Welling, Tim Genewein, Frank Nielsen: \u201cSinkhorn AutoEncoders\u201d, 2018; <a href='http://arxiv.org/abs/1810.01118'>https://arxiv.org/abs/1810.01118</a>.\n</li>\n</ul>",
      "https://arxiv.org/abs/1711.01558</a>.\n</li>\n<li>[4]:\nGiorgio Patrini, Rianne van den Berg, Patrick Forr\u00e9, Marcello Carioni, Samarth Bhargav, Max Welling, Tim Genewein, Frank Nielsen: \u201cSinkhorn AutoEncoders\u201d, 2018; <a href='http://arxiv.org/abs/1810.01118'>https://arxiv.org/abs/1810.01118</a>.\n</li>\n</ul>",
      "https://arxiv.org/abs/1810.01118</a>.\n</li>\n</ul>"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<ul>\n<li>[1]:\nIan J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio: \u201cGenerative Adversarial Networks\u201d, 2014; <a href='http://arxiv.org/abs/1406.2661'>arXiv:1406.2661</a>.\n</li>\n<li>[2]:\nDiederik P Kingma, Max Welling: \u201cAuto-Encoding Variational Bayes\u201d, 2013; <a href='http://arxiv.org/abs/1312.6114'>arXiv:1312.6114</a>.\n</li>\n<li>[3]:\nIlya Tolstikhin, Olivier Bousquet, Sylvain Gelly, Bernhard Schoelkopf: \u201cWasserstein Auto-Encoders\u201d, 2017; <a href='http://arxiv.org/abs/1711.01558'>arXiv:1711.01558</a>.\n</li>\n<li>[4]:\nGiorgio Patrini, Rianne van den Berg, Patrick Forr\u00e9, Marcello Carioni, Samarth Bhargav, Max Welling, Tim Genewein, Frank Nielsen: \u201cSinkhorn AutoEncoders\u201d, 2018; <a href='http://arxiv.org/abs/1810.01118'>arXiv:1810.01118</a>.\n</li>\n</ul>\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-09T02:12:45Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-02-23T21:39:28Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Data scientists often choose the uniform distribution or the normal distribution as the latent variable distribution when they build representative models of datasets. For example, the studies of the GANs [1] and the VAEs[2] used the uniform random distribution and the normal one, respectively.\n\nAs the approximate function implemented by neural networks is usually continuous, the topological structure of the latent variable distribution is preserved after the transformation from the latent variables space to the observable variables space. Given that the observed variables are distributed on a torus and that networks, for example the GANs, are trained with the latent variables sampled from the normal distribution, the structure of the projected distribution by the trained networks does not meet with the torus, even if residual error is small enough. Imagine another example where the observable variables follow a mixture distribution, of which clusters separate each other, trained variational autoencoder can encode the feature on the latent variable space with high precision, however, the decoded distribution consists of connected clusters since the latent variable is topologically equal with the ball. This means that the topology of the given dataset is not represented by the projection of the trained networks.\n\nIn this short text, we study the consequence of autoencoders' training due to  the topological mismatch. We use the SAE[4] as autoencoders, which is enhanced based on the WAE[3] owing to the sinkhorn algorithm.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9112888402273515,
        0.9535609502351211
      ],
      "excerpt": "Agents consist of encoder and decoder networks. The encoder networks transform observable variables into latent variables and the decoder networks reverse the latent variables into the represented observable variables. \nIn our case studies, we define these two networks as the multilayer perceptron with the following hyperparameters: number of units nH, number of layers nLayer and activation function activation, where the encoder and decoder networks share the same hyperparameters. The values of the hyperparameters are defined in each case study. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "An implementation of Conditional Wasserstein Autoencoder Powered by Sinkhorn Distance",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 00:56:24 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/master/snippet/wae_snippet.ipynb",
      "https://raw.githubusercontent.com/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/master/casestudies/cs02a_postprocess.ipynb",
      "https://raw.githubusercontent.com/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/master/casestudies/cs01a_postprocess.ipynb",
      "https://raw.githubusercontent.com/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/master/casestudies/cs03_postprocess.ipynb",
      "https://raw.githubusercontent.com/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/master/casestudies/cs03c_postprocess.ipynb",
      "https://raw.githubusercontent.com/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/master/casestudies/cs01a_build.ipynb",
      "https://raw.githubusercontent.com/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/master/casestudies/cs03_build.ipynb",
      "https://raw.githubusercontent.com/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/master/casestudies/update_sources.ipynb",
      "https://raw.githubusercontent.com/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/master/casestudies/cs02a_build.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "1. Introduction",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ConditionalWassersteinAutoencoderPoweredBySinkhornDistance",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "allnightlight",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/allnightlight/ConditionalWassersteinAutoencoderPoweredBySinkhornDistance/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 00:56:24 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This case study builds representative models of a two-dimensional 1-torus by using the autoencoder with the latent variables sampled from the two dimensional uniform distribution. We show an example of the consequence caused by the topological mismatch between the observable and latent variables distribution.\n\nModels are trained by using the hyperparameters shown in the table 3.1.1. The figure 3.1.1 (a) and (b) show the learning curves of the following training performances, respectively.\n- Representative error, `mean((Y-Yhat)^2)`, where `Y and Yhat` are the original observed variables and the represented ones, respectively.\n- Discrepancy between the referenced distribution of the latent variables and the projected ones by the trained encoder. Note that the discrepancy is measured by the absolute norm Wasserstein distance.\n\nThe learning curves tell us that the training has converged at the end of the training iterations.\n\nThe figure 3.1.2(a) (or the figure 3.1.2(b)) shows the images projected through the encoder (or decoder) of the trained model which has the average performance among the trained models with `nLayer=7`. The left one is the input image of the observed (or latent) variables approximated by an analytical function and the right one is obtained by projecting the input image via the trained encoder(or decoder). Here are our findings.\n\n- The learning curves in the figure 3.1.1(a) and (b) tell us that the projected samples can match well with the original samples and the distribution of the latent variables looks like the uniform distribution.\n- The figure 3.1.2(a) shows that the hole in the latent variables image is fairly small and that the referenced latent variables distribution is almost covered by the projected one.\n- Seeing the figure 3.1.2(b), the decoder's projected image is topologically identified with the disk, even though the region around the hole is stretched.\n\nThe last two findings say that the encoder and decoder as maps between the observable variables and the latent ones cannot preserve the topological structure. This might cause practical problems. For example, if you optimize a function defined on a 1-torus and if you plan to parameterize the decision variables on the torus by using the latent variables defined by autoencoder, it might be possible that you find a solution at a point of the hole of the torus, which is of course infeasible, because it exists a certain area in the latent variable which can be mapped on the hole of the torus.\n\n\nTable 3.1.1. Hyper parameters \n\n|name|description|value|\n|-|-|-|\n|nEpoch|the number of epochs | 512|\n|nBatch|the sample size of a single batch|512|\n|nH|the number of units of the encoder and decoder network|512|\n|nLayer|the number of layers of the encoder and decoder network| 3, 5 and 7|\n|reg_param|the regularization parameter | 10 |\n\n<img src = \"./casestudies/img/cs01b_representative_error.png\" width = \"50%\"> \nFig 3.1.1(a) Learning curve of the representative error grouped by the number of layers in the network\n\n<img src = \"./casestudies/img/cs01b_latent_distribution_discrepancy.png\" width = \"50%\"> \nFig 3.1.1(b) Learning curve of the discrepancy between the the referenced and the projected  latent variable distributions grouped by the number of layers in the network\n\n<img src = \"./casestudies/img/encoder_projection_cbarbaUWpfmwvNQS.png\" width = \"50%\"> \nFig 3.1.2(a) Input and output image of a trained encoder\n\n<img src = \"./casestudies/img/deccoder_projection_cbarbaUWpfmwvNQS.png\" width = \"50%\"> \nFig 3.1.2(b) Input and output image of a trained decoder\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "We move on to the next case study to see another type of topological mismatch:\nthe one distributes on the twisted surface in the three dimensional space,\nwhile the distribution of the other, not twisted.\nIt's impossible that the autoencoders consilliate this difference\nsince the twisted image (or not twisted) is mapped on to the twisted image (or not twisted).\nWe see the consequence of the autoencoders' training subject to this topological mismatch.\n\nHere is the specifications of our experiment.\nThe environment generates the dataset sampled randomly from the mobius band.\nMore precisely say that the variables `x, y and z` in the three dimensional space randomly distribute on the surface defined in \n[site](https://en.wikipedia.org/wiki/M%C3%B6bius_strip#Geometry_and_topology)\n.\n\nOn the other hand,\nwe define the agent that the distribution of the latent variables `u, v and w` follows\nthe uniform random distribution over a ring as follow:\n\n<img src = \"./casestudies/img/texclip20200826105519.png\" width = \"83%\">\n\nNote that the observable variables' distribution is twisted,\nwhile the latent variables' one is not.\n\nWe train agents by using the hyperparameters in the table 3.2.1 and \nthe figure 3.2.1 shows the learning curves of the pair of performances\nmentioned already in the case study #1.\nIt tells us that the training has converged at the end of the final epoch.\nWe see below in detail an agent among trained agents around the average performance.\n\nThe figure 3.2.2(a) shows how the trained encoder maps the observable variable image\n(the blue in the left) to the latent variable image (the blue one in the right).\nThe projected image on the latent variable space represents well the referenced image(the gray one).\nParticularly, the part mapped from the twisted part of the input image \nis pushed and piled up on the surface of the referenced image \ndue to the fact that the encoder cannot untangle the distortion of the mobius band.\n\nThe figure 3.2.2(b) shows the referenced latent variable image(the red one in the left) \nand its projected image on the observable variable space(the red one in the right)\nby the trained decoder.\nAs mentioned in the case of the encoder, the projected image looks like the referenced observable image(the gray one in the right),\nthough, since the referenced latent image is not twisted, a part of projected image is stretched and flipped in to fit to the twisted part of the mobius band.\nThis happens because the decoder has to preserve the topological structure.\n\nThus, however well autoencoders regenerate datasets of distributions with complex structures\nin the data-driven manner, they cannot represent topological structure.\n\n\nTable 3.2.1. Hyper parameters \n\n|name|description|value|\n|-|-|-|\n|nEpoch|the number of epochs | 512|\n|nBatch|the sample size of a single batch|512|\n|nH|the number of units of the encoder and decoder network|128|\n|nLayer|the number of layers of the encoder and decoder network|3|\n|reg_param|the regularization parameter | 10 |\n\n<img src = \"./casestudies/img/cs02a_score.png\" width = \"50%\"> \nFig 3.2.1 Learning curve of the representative error and the discrepancy between the the referenced and the projected  latent variable distributions\n\n<img src = \"./casestudies/img/cs02a_encoder_projection_SQMQIE81fexBjY9p_azim=270.png\" width = \"75%\"> \nFig 3.2.2(a) Input and output image of a trained encoder\n\n<img src = \"./casestudies/img/cs02a_deccoder_projection_SQMQIE81fexBjY9p_azim=000.png\" width = \"75%\"> \nFig 3.2.2(b) Input and output image of a trained decoder\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "In the third example, \nwe take account of the difference of knots as an example of topological mismatch.\nWe try to represent a type of knot by transforming another type of knot\nand we see what happens to the autoencoders' training due to this discrepancy.\n\nHere is the configuration of agents and environments:\n- The environment randomly samples values from [a trefoil knot](https://en.wikipedia.org/wiki/Trefoil_knot#Descriptions) in three-dimensional space.\n- The latent variables of the agents are sampled from an unknot, namely a simple ring, in three-dimensional space.\n\nThe table 3.3.1 shows the hyperparameter set for the training.\nNote that small batch size is required in this training, \nprobably because a smaller size batch can break better the symmetry across the x-y plane which the observable variables distribution holds.\nThe training has already saturated at the end of epochs, which is confirmed in the learning curves shown in the figure 3.3.1.\n\nWe select one trained agent among the trained agents around average performances and analyze it.\n- The figure 3.3.2(a) shows the transformation of the observable variables distribution\non the latent variables space by the trained encoder\nAlthough the output image is close to the referenced latent variables distribution\n, the output image seemingly preserves the knots of the original image.\n- The figure 3.3.2(b) shows the referenced latent variables image, that is the simple circle,\nand its projected image by the trained decoder on the observable variables space.\nThe output closed loop is approaching the original trefoil knot,\nHowever, it's hard to fit it completely because the projected image cannot make new knots on their own.\n\nIn this way, even if the numerical evaluations of the error and the discrepancy of distributions are small,\nthe autoencoders are not capable of creating new knots.\nThe topological discrepancy cannot be resolved just by the autoencoders.\n\nTable 3.3.1. Hyper parameters \n\n|name|description|value|\n|-|-|-|\n|nEpoch|the number of epochs | 512|\n|nBatch|the sample size of a single batch|32|\n|nH|the number of units of the encoder and decoder network|32|\n|nLayer|the number of layers of the encoder and decoder network|3|\n|reg_param|the regularization parameter | 0.1 |\n|activation|activation function of agent|tanh|\n\n<img src = \"./casestudies/img/cs03c_score.png\" width = \"50%\"> \nFig 3.3.1 Learning curve of the representative error and the discrepancy between the the referenced and the projected  latent variable distributions\n\n<img src = \"./casestudies/img/cs03c_encoder_projection_A8h1YHFMvFCZkzb0_azim=000.png\" width = \"75%\"> \nFig 3.3.2(a) Input and output image of a trained encoder\n\n<img src = \"./casestudies/img/cs03c_decoder_projection_A8h1YHFMvFCZkzb0_azim=000.png\" width = \"75%\"> \nFig 3.3.2(b) Input and output image of a trained decoder\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
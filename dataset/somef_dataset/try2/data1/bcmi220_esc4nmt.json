{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1706.03762",
      "https://arxiv.org/abs/1705.03122"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@inproceedings{li2020explicit,\ntitle={Explicit Sentence Compression for Neural Machine Translation},\nauthor={Zuchao Li and Rui Wang and Kehai Chen and Masao Utiyama and Eiichiro Sumita and Zhuosheng Zhang and Hai Zhao},\nbooktitle={the Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-2020)},\nyear={2020}\n}\n```",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{li2020explicit,\ntitle={Explicit Sentence Compression for Neural Machine Translation},\nauthor={Zuchao Li and Rui Wang and Kehai Chen and Masao Utiyama and Eiichiro Sumita and Zhuosheng Zhang and Hai Zhao},\nbooktitle={the Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-2020)},\nyear={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9274409132073548
      ],
      "excerpt": "AAAI 2020: Explicit Sentence Compression for Neural Machine Translation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8043073075947367
      ],
      "excerpt": "if [ ! -d ./checkpoints/$EXP_NAME/ ]; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "if [ ! -d ./logs/$EXP_NAME/ ]; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9753528691053175
      ],
      "excerpt": "                --source-lang en --target-lang de --source-context en-esc \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bcmi220/esc4nmt",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-12-27T03:28:39Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-11T10:39:12Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8868724867072273
      ],
      "excerpt": "This implementation is based on fairseq. We take en2de NMT experiment for example. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Explicit Sentence Compression for Neural Machine Translation",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bcmi220/esc4nmt/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 06:36:17 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/bcmi220/esc4nmt/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "bcmi220/esc4nmt",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/bcmi220/esc4nmt/master/examples/language_model/prepare-wikitext-103.sh",
      "https://raw.githubusercontent.com/bcmi220/esc4nmt/master/examples/speech_recognition/datasets/prepare-librispeech.sh",
      "https://raw.githubusercontent.com/bcmi220/esc4nmt/master/examples/joint_alignment_translation/prepare-wmt18en2de_no_norm_no_escape_no_agressive.sh",
      "https://raw.githubusercontent.com/bcmi220/esc4nmt/master/examples/roberta/preprocess_GLUE_tasks.sh",
      "https://raw.githubusercontent.com/bcmi220/esc4nmt/master/examples/roberta/preprocess_RACE.sh",
      "https://raw.githubusercontent.com/bcmi220/esc4nmt/master/examples/roberta/commonsense_qa/download_cqa_data.sh",
      "https://raw.githubusercontent.com/bcmi220/esc4nmt/master/examples/backtranslation/sacrebleu.sh",
      "https://raw.githubusercontent.com/bcmi220/esc4nmt/master/examples/backtranslation/tokenized_bleu.sh",
      "https://raw.githubusercontent.com/bcmi220/esc4nmt/master/examples/backtranslation/prepare-wmt18en2de.sh",
      "https://raw.githubusercontent.com/bcmi220/esc4nmt/master/examples/backtranslation/prepare-de-monolingual.sh",
      "https://raw.githubusercontent.com/bcmi220/esc4nmt/master/examples/translation/prepare-wmt14en2fr.sh",
      "https://raw.githubusercontent.com/bcmi220/esc4nmt/master/examples/translation/prepare-iwslt14.sh",
      "https://raw.githubusercontent.com/bcmi220/esc4nmt/master/examples/translation/prepare-iwslt17-multilingual.sh",
      "https://raw.githubusercontent.com/bcmi220/esc4nmt/master/examples/translation/prepare-wmt14en2de.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Download and Preprocess WMT 14 data\n\n    The WMT English to German dataset can be preprocessed using the `prepare-wmt14en2de.sh` script.\n    By default it will produce a dataset that was modeled after [Attention Is All You Need (Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762), but with additional news-commentary-v12 data from WMT'17.\n\n    To use only data available in WMT'14 or to replicate results obtained in the original [Convolutional Sequence to Sequence Learning (Gehring et al., 2017)](https://arxiv.org/abs/1705.03122) paper, please use the `--icml17` option.\n\n    ```bash\n    #: Download and prepare the data\n    cd examples/translation/\n    #: WMT'17 data:\n    bash prepare-wmt14en2de.sh\n    #: or to use WMT'14 data:\n    #: bash prepare-wmt14en2de.sh --icml17\n\n    cd  wmt14_en_de\n    #: cd wmt17_en_de\n\n    mkdir ./tmp/esc/\n\n    sed -r 's/(@@ )|(@@ ?$)//g' train.en > ./tmp/esc/train.esc.tok.en\n    sed -r 's/(@@ )|(@@ ?$)//g' valid.en > ./tmp/esc/valid.esc.tok.en\n    sed -r 's/(@@ )|(@@ ?$)//g' test.en > ./tmp/esc/test.esc.tok.en\n    ../mosesdecoder/scripts/tokenizer/detokenizer.perl -l en < ./tmp/esc/train.esc.tok.en > ./tmp/esc/train.esc.en\n    ../mosesdecoder/scripts/tokenizer/detokenizer.perl -l en < ./tmp/esc/valid.esc.tok.en > ./tmp/esc/valid.esc.en\n    ../mosesdecoder/scripts/tokenizer/detokenizer.perl -l en < ./tmp/esc/test.esc.tok.en > ./tmp/esc/test.esc.en\n\n    rm ./tmp/esc/train.esc.tok.en\n    rm ./tmp/esc/valid.esc.tok.en\n    rm ./tmp/esc/test.esc.tok.en\n\n    ```\n\n\n2. Perform explicit sentence compression\n\n    ```\n\n    CUDA_VISIBLE_DEVICES=0 python ./scripts/generate_esc.py --esc_model_path ./pretrain/model/esc_giga/ --esc_max_len_a 0.6 --esc_max_len_b 0 --esc_min_len 5 --input_path ./examples/translation/wmt14_en_de/tmp/esc/train.esc.en --output_path ./examples/translation/wmt14_en_de/tmp/esc/train.en-esc\n\n    CUDA_VISIBLE_DEVICES=0 python ./scripts/generate_esc.py --esc_model_path ./pretrain/model/esc_giga/ --esc_max_len_a 0.6 --esc_max_len_b 0 --esc_min_len 5 --input_path ./examples/translation/wmt14_en_de/tmp/esc/valid.esc.en --output_path ./examples/translation/wmt14_en_de/tmp/esc/valid.en-esc\n\n\n    CUDA_VISIBLE_DEVICES=0 python ./scripts/generate_esc.py --esc_model_path ./pretrain/model/esc_giga/ --esc_max_len_a 0.6 --esc_max_len_b 0 --esc_min_len 5 --input_path ./examples/translation/wmt14_en_de/tmp/esc/test.esc.en --output_path ./examples/translation/wmt14_en_de/tmp/esc/test.en-esc\n\n    BPEROOT=subword-nmt/subword_nmt\n\n    python $BPEROOT/apply_bpe.py -c ./wmt14_en_de/code < ./wmt14_en_de/tmp/esc/train.en-esc > ./wmt14_en_de/tmp/esc/bpe.train.en-esc\n    python $BPEROOT/apply_bpe.py -c ./wmt14_en_de/code < ./wmt14_en_de/tmp/esc/valid.en-esc > ./wmt14_en_de/tmp/esc/bpe.valid.en-esc\n    python $BPEROOT/apply_bpe.py -c ./wmt14_en_de/code < ./wmt14_en_de/tmp/esc/test.en-esc > ./wmt14_en_de/tmp/esc/bpe.test.en-esc\n\n    cp ./wmt14_en_de/tmp/esc/bpe.train.en-esc ./wmt14_en_de/train.en-esc\n    cp ./wmt14_en_de/tmp/esc/bpe.valid.en-esc ./wmt14_en_de/valid.en-esc\n    cp ./wmt14_en_de/tmp/esc/bpe.test.en-esc ./wmt14_en_de/test.en-esc\n\n    ```\n\n3. Binarize the dataset\n\n```\nTEXT=./examples/translation/wmt14_en_de\npython fairseq_cli/multicontext_preprocess.py --source-lang en --target-lang de --source-context en-esc --trainpref $TEXT/train --validpref $TEXT/valid --destdir data-bin/wmt14_en_de_esc --thresholdtgt 0 --thresholdsrc 0 --joined-dictionary --workers 20\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8381553229756074
      ],
      "excerpt": "                --save-interval-updates 1000 --keep-interval-updates 200 --max-update ${UPDATES} > $LOG_PATH \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9078431934650627
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 python train.py ${DATA_PATH} \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8644885925518727
      ],
      "excerpt": "                --update-freq 1 --no-progress-bar --log-format json --log-interval 50 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8871385674536972
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0 python fairseq_cli/multicontext_translate.py data-bin/wmt14_en_de_esc/ --task multicontext_translation --source-lang en --target-lang de --source-context en-esc --path ./checkpoints/esc4nmt/multicontext_transformer_wmt14_en_de_up200000/${CKPT} --buffer-size 2000 --batch-size 128 --beam 5 --remove-bpe --lenpen 0.6 --input ./examples/translation/wmt14_en_de/test.en --other-input ./examples/translation/wmt14_en_de/test.en-esc --output ./result/wmt14_ende_test.de.pred \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/bcmi220/esc4nmt/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cuda",
      "C++"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "ESC4NMT",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "esc4nmt",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "bcmi220",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bcmi220/esc4nmt/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- OS: macOS or Linux\n- NVIDIA GPU and [NCCL](https://github.com/NVIDIA/nccl)\n- Pytorch\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Wed, 29 Dec 2021 06:36:17 GMT"
    },
    "technique": "GitHub API"
  }
}
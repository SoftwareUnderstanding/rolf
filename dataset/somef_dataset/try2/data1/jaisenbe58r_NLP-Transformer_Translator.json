{
  "citation": [
    {
      "confidence": [
        0.9865374311292784,
        0.9977000120631181,
        0.9999740652035157,
        0.9278824608274014,
        0.9507374082549614
      ],
      "excerpt": "Implementaci\u00f3n de un modelo Transformer para la traducci\u00f3n de texto. \nLos Transformers est\u00e1n dise\u00f1ados para manejar datos secuenciales, como el lenguaje natural, para tareas como la traducci\u00f3n y el resumen de texto. Sin embargo, a diferencia de los RNN, los Transformers no requieren que los datos secuenciales se procesen en orden. Por ejemplo, si los datos de entrada son una oraci\u00f3n en lenguaje natural, el Transformer no necesita procesar el principio antes del final. Debido a esta caracter\u00edstica, el Transformer permite mucha m\u00e1s paralelizaci\u00f3n que los RNN y, por lo tanto, reduce los tiempos de entrenamiento.  \nlos Transformers se han convertido en el modelo de elecci\u00f3n para abordar muchos problemas en la PNL, reemplazando los modelos de redes neuronales recurrentes m\u00e1s antiguos, como la memoria a corto plazo (LSTM). Dado que el modelo Transformer facilita una mayor paralelizaci\u00f3n durante el entrenamiento, ha permitido el entrenamiento en conjuntos de datos m\u00e1s grandes de lo que era posible antes de su introducci\u00f3n.  \nPara m\u00e1s informaci\u00f3n sobre los transformers: https://en.wikipedia.org/wiki/Transformer_(machine_learning_model) \nEl transformer se ha implementado en el m\u00f3dulo nlp de la Librer\u00eda MLearner: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9994954626616064,
        0.9740694216804022
      ],
      "excerpt": "MLearner pretende ser una librer\u00eda de herramientas \u00fatiles para integrar algoritmos de Machine Learning e IA de manera m\u00e1s f\u00e1cil e intuitiva. Puede encontrar m\u00e1s informaci\u00f3n sobre todos los m\u00f3dulos implementados en el siguiente enlace: Repositorio GitHub Libreria MLearner \nLa implementaci\u00f3n del Transformer utilizado est\u00e1 basada en el curso \"Procesamiento del Lenguaje Natural Moderno en Python.\" de la plataforma Udemy, con el profesor Juan Gabriel Gomila. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999999996303472,
        0.9105368110547479
      ],
      "excerpt": "El profesor Juan Gabriel Gomila, tambi\u00e9n dispone de la Ruta de Aprendizaje para Ingenieros de Inteligencia Artificial donde se ofrecen planes de estudio estructurados y cursos con descuentos para los cursos de inteligencia artificial que necesites. Esta Ruta de Aprendizaje proporciona la profundidad, el conocimiento y el car\u00e1cter exigente de un programa acreditado, a la vez que permite aprender a tu propio ritmo en talleres interactivos y bajo demanda. Tambi\u00e9n, estos cursos desaf\u00edan y ponen a prueba tu aprendizaje en una fracci\u00f3n del tiempo en comparaci\u00f3n con un programa de m\u00e1ster universitario, y te dan acceso a cursos con descuento cuando te inscribes, adem\u00e1s del material complementario que viene de regalo con todos los cursos como acceso a comunidades, scripts, libros, apuntes y repositorios de c\u00f3digo. \nEn el Repositorio GitHub - NLP-Transformer_Translator se puede encontrar toda la documentaci\u00f3n, cuadernos jupyter y scripts que se abordan en este art\u00edculo. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906350528336428,
        0.9507374082549614
      ],
      "excerpt": "&gt;&gt;&gt; 'Reanudaci\u00f3n del per\u00edodo de sesiones\\nDeclaro reanudado el per\u00edodo de sesiones del Parlamento Europeo, interrumpido el viernes 17 de diciembre pasado, y reitero a Sus Se\u00f1or\u00edas mi deseo de que hayan tenido unas buenas vacaciones' \nDefinimos funci\u00f3n de procesado de texto basada en expresiones regulares \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "#: Eliminamos la @ y su menci\u00f3n \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Se procesan los textos para cada uno de los idiomas: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "      <td>Reanudaci\u00f3n del per\u00edodo de sesiones</td> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "      <td>Declaro reanudado el per\u00edodo de sesiones del P...</td> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Tama\u00f1o de Vocabulario para los dos idiomas. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.8356013927728488
      ],
      "excerpt": "[ \\INICIO ]: Car\u00e1cter que determina el inicio de frase. \n[ \\FIN ]: Car\u00e1cter que determina el final de frase. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693,
        0.8665716475375693
      ],
      "excerpt": "                     if len(sent) > MAX_LENGTH] \n    if len(idx_to_remove) > 0: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8456806903995955,
        0.8456806903995955
      ],
      "excerpt": "                 if len(sent) &gt; MAX_LENGTH] \nif len(idx_to_remove) &gt; 0: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9737528548338414
      ],
      "excerpt": "A medida que entrenamos con bloques, necesitaremos que cada entrada tenga la misma longitud. Rellenamos con el token apropiado, y nos aseguraremos de que este token de relleno no interfiera con nuestro entrenamiento m\u00e1s adelante. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Bucle de entrenamiento \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8484386050819549
      ],
      "excerpt": "&gt;&gt;&gt; Guardando checkpoint para el epoch 5 en ckpt/ckpt-10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Funci\u00f3n de evaluaci\u00f3n. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "    if predicted_id == VOCAB_SIZE_ES-1: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Funci\u00f3n de Traducci\u00f3n. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9625184728059253,
        0.99998817013062,
        0.9999999999997442
      ],
      "excerpt": "Como podemos observar, las predicciones son bastante aceptables dada la versi\u00f3n reducida del Transformer utilizado respecto al Paper original.  \nTal y como se observa en la fase de entrenamiento, el porcentaje de aciertos ronda casi un 50% para 5 \u00e9pocas de entrenamiento, por ello cabe esperar que las predicciones no sean completamente exactas. Pero lo importante en este caso es analizar si el modelo ha sido capaz de aprender del contexto, con ello aunque falle con alguna palabra observamos que ha inferido la continuaci\u00f3n de la frase con bastante relaci\u00f3n con el contexto general de la frase. \nComo hemos comentado en la introducci\u00f3n, la potencia de los Transformers reside en su capacidad de analizar la frase en todo su conjunto sin la necesidad de centrarse en los datos secuencialmente como ocurre con las RNR (Redes Neuronales Recurrentes). Un ejemplo de ello, es la virtud del algoritmo de detectar una oraci\u00f3n exclamativa en ingl\u00e9s con solo un signo de puntuaci\u00f3n ! al final de la frase, para inferir el resultado de una oraci\u00f3n exclamativa en espa\u00f1ol con dos signos de puntuaci\u00f3n al inicio y al final. Aqu\u00ed es donde se ve potenciada la capacidad de los transformers frente a las RNR gracias a su mecanismo de Atenci\u00f3n, donde consigue un entendimiento global del contexto de la frase sin importar el orden de las palabras. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999827099862031
      ],
      "excerpt": "En el siguiente ejemplo se denota la capacidad del modelo de entender o aprender el idioma m\u00e1s all\u00e1 de una traducci\u00f3n palabra a palabra. Es decir, el transformer en vez de predecir`de manera literal a Yo tengo una casa, ha sido capaz de entender que puede prescindir del pronombre y empezar la oraci\u00f3n con el verbo Tengo una casa, tal y como har\u00edamos cualquier persona de habla espa\u00f1ola. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Como punto final, para mejorar los resultados os invito a aumentar el valor de los hiper par\u00e1metros con los siguientes valores: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "EPOCHS = 10 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jaisenbe58r/NLP-Transformer_Translator",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-26T11:30:26Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-27T19:15:11Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9522942410093052
      ],
      "excerpt": "with open(\"data/europarl-v7.es-en.en\",  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9522942410093052
      ],
      "excerpt": "with open(\"data/europarl-v7.es-en.es\",  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9311374155355033
      ],
      "excerpt": "with open(\"data/P85-Non-Breaking-Prefix.en\",  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9311374155355033
      ],
      "excerpt": "with open(\"data/P85-Non-Breaking-Prefix.en\",  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8211799197213436
      ],
      "excerpt": "&gt;&gt;&gt; 'Resumption of the session\\nI declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive peri' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.866235971120619
      ],
      "excerpt": "    .dataframe tbody tr th:only-of-type { \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9966474696551649
      ],
      "excerpt": "      <td>Resumption of the session</td> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8951274601769342
      ],
      "excerpt": "      <td>I declare resumed the session of the European ...</td> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.866235971120619
      ],
      "excerpt": "    .dataframe tbody tr th:only-of-type { \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "    dump(processor_en, 'data/processor_en.joblib') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "    dump(processor_es, 'data/processor_es.joblib') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8052280108495816
      ],
      "excerpt": "    idx_to_remove = [count for count, sent in enumerate(inputs) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "        for idx in reversed(idx_to_remove): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8366071872589987
      ],
      "excerpt": "idx_to_remove = [count for count, sent in enumerate(outputs) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "    for idx in reversed(idx_to_remove): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9117589742362976
      ],
      "excerpt": "translate(\"This is a problem we have to solve.\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9190601842013154
      ],
      "excerpt": "translate(\"This is an interesting course about Natural Language Processing\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementaci\u00f3n Transformers, adaptaci\u00f3n del curso: \"Procesamiento del Lenguaje Natural Moderno en Python. (Juan Gabriel Gomila)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jaisenbe58r/NLP-Transformer_Translator/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 03:39:34 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/jaisenbe58r/NLP-Transformer_Translator/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "jaisenbe58r/NLP-Transformer_Translator",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/jaisenbe58r/NLP-Transformer_Translator/master/.ipynb_checkpoints/Transformer_para_NLP-checkpoint.ipynb",
      "https://raw.githubusercontent.com/jaisenbe58r/NLP-Transformer_Translator/master/.ipynb_checkpoints/Transformer_para_NLP_v1-checkpoint.ipynb",
      "https://raw.githubusercontent.com/jaisenbe58r/NLP-Transformer_Translator/master/examples/Transformer_para_NLP_v2.ipynb",
      "https://raw.githubusercontent.com/jaisenbe58r/NLP-Transformer_Translator/master/examples/Transformer_para_NLP.ipynb",
      "https://raw.githubusercontent.com/jaisenbe58r/NLP-Transformer_Translator/master/examples/.ipynb_checkpoints/Transformer_para_NLP_v2-checkpoint.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "                              name=\"processor_en\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "                              name=\"processor_es\" \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8401558704798054,
        0.9457175861910134
      ],
      "excerpt": "import os \nimport numpy as np \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8396948529258378,
        0.8589533263077856
      ],
      "excerpt": "import time \nfrom joblib import dump, load \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174,
        0.8628110089442617,
        0.9012248701992861
      ],
      "excerpt": "import tensorflow as tf \nfrom tensorflow.keras import layers \nimport tensorflow_datasets as tfds \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9190315961926722
      ],
      "excerpt": "TRAIN = True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8329015283702058
      ],
      "excerpt": "    europarl_en = f.read() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8329015283702058
      ],
      "excerpt": "    europarl_es = f.read() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8329015283702058
      ],
      "excerpt": "    non_breaking_prefix_en = f.read() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8329015283702058
      ],
      "excerpt": "    non_breaking_prefix_es = f.read() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8226440209499781
      ],
      "excerpt": "return text \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "                              name=\"processor_en\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "                              name=\"processor_es\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8414462858814077
      ],
      "excerpt": "    pd.DataFrame(corpus_en).to_csv(\"data/corpus_en.csv\", index=False) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8414462858814077,
        0.8525447642357499,
        0.8525447642357499
      ],
      "excerpt": "    pd.DataFrame(corpus_es).to_csv(\"data/corpus_es.csv\", index=False) \ncorpus_en = pd.read_csv(\"data/corpus_en.csv\")   \ncorpus_es = pd.read_csv(\"data/corpus_es.csv\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8172342705654815
      ],
      "excerpt": "len(corpus_en), len(corpus_es) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "                                             isclean=True,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "                                             isclean=True,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936606094659785
      ],
      "excerpt": "print(VOCAB_SIZE_EN, VOCAB_SIZE_ES) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731562459058029
      ],
      "excerpt": "                                                       value=0, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731562459058029
      ],
      "excerpt": "                                                        value=0, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8191162518592582,
        0.8154483099248772
      ],
      "excerpt": "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE) \ndataset = dataset.prefetch(tf.data.experimental.AUTOTUNE) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "                  train=TRAIN, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.84760898352076,
        0.8982286858028701
      ],
      "excerpt": "    enc_input = tf.expand_dims(inp_sentence, axis=0) \noutput = tf.expand_dims([VOCAB_SIZE_ES-2], axis=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8505894056809903
      ],
      "excerpt": "    predictions = model_Transformer(enc_input, output, False) #:(1, seq_length, VOCAB_SIZE_ES) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8136939484758023
      ],
      "excerpt": "    predicted_id = tf.cast(tf.argmax(prediction, axis=-1), tf.int32) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8414382856775481,
        0.8994552006436753,
        0.8414382856775481
      ],
      "excerpt": "        return tf.squeeze(output, axis=0) \n    output = tf.concat([output, predicted_id], axis=-1) \nreturn tf.squeeze(output, axis=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.812941059813019
      ],
      "excerpt": "    output = evaluate(sentence).numpy() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9335757557148643,
        0.9335757557148643
      ],
      "excerpt": "print(\"Entrada: {}\".format(sentence)) \nprint(\"Traducci\u00f3n predicha: {}\".format(predicted_sentence)) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/jaisenbe58r/NLP-Transformer_Translator/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "HTML"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "TRANSFORMER para la Traducci\u00f3n de Texto",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "NLP-Transformer_Translator",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "jaisenbe58r",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jaisenbe58r/NLP-Transformer_Translator/blob/master/readme.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 03:39:34 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "nlp",
      "transformers",
      "deep-learning",
      "machine-learning",
      "tensorflow",
      "keras",
      "neural-network",
      "transformer-architecture"
    ],
    "technique": "GitHub API"
  }
}
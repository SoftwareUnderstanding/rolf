{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1406.2661>]\n>\n> 2\\. Backpropagation [<http://neuralnetworksanddeeplearning.com/chap2.html>]\n>\n> 3\\. CNN [<https://brohrer.github.io/how_convolutional_neural_networks_work.html>]\n>\n> 4\\. Adaptive Deconvolutional Networks [<https://ieeexplore.ieee.org/document/6126474>]\n>\n> 5\\. Computer Vision & GANs [<https://www.superdatascience.com/courses/computer-vision-z-learn-opencv-gans-cutting-edge-ai>]\n\nFurther Reading\n---------------\n\n> 1\\.\u00a0[Andrew Y. Ng & Michael I. Jordan](http://www.cs.cmu.edu/~aarti/Class/10701/readings/NgJordanNIPS2001.pdf",
      "https://arxiv.org/abs/1511.06434",
      "https://arxiv.org/abs/1912.04958",
      "https://arxiv.org/abs/1703.10593"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9949147839882485
      ],
      "excerpt": "3. Adaptive Deconvolutional Networks [https://ieeexplore.ieee.org/document/6126474] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278824608274014
      ],
      "excerpt": "Credit:\u00a0Generative Adversarial Nets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9414616401702977,
        0.9531737947012585
      ],
      "excerpt": "Video Prediction \n3D Object Generation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9964838015383283
      ],
      "excerpt": "1. Generative Adversarial Networks [https://arxiv.org/abs/1406.2661] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9949147839882485,
        0.9999099103607783,
        0.8955886365383559
      ],
      "excerpt": "4. Adaptive Deconvolutional Networks [https://ieeexplore.ieee.org/document/6126474] \n5. Computer Vision & GANs [https://www.superdatascience.com/courses/computer-vision-z-learn-opencv-gans-cutting-edge-ai] \n1.\u00a0Andrew Y. Ng & Michael I. Jordan \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Nirav-Agarwal/GANs",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-31T20:13:07Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-31T20:17:15Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8625272256885642,
        0.9993660543976475,
        0.996186923811199
      ],
      "excerpt": "\"We keep moving forward, opening new doors, and doing new things, because we're curious and curiosity keeps leading us down new paths.\" --- Walt Disney \nMachine learning is an integral part of our life. It's everywhere from the thing that lives on the top of our phone's keyboard to the things that drive the field of self-driving cars. The area of machine learning is advancing day-after-day, with innovations and new ideas coming forward. One such contribution of Machine learning, precisely the field of deep learning is GAN --- Generative Adversarial Networks, something which in my opinion is a pure form of magic which is created by science. \nGAN is a class of deep learning framework dedicated to creating new things. Unlike conventional deep learning techniques that are used to detect various things, GAN is used to produce new things. Think of GAN as a painter; it likes to paint. Identifying a particular item, say a hat is something any literate human can do. We can easily mimic this on a computer using a deep learning framework. But, GAN, on the other hand, is a step towards creativity, a level close to intelligence. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9938769717782433,
        0.8761082520450368,
        0.9675981377367461
      ],
      "excerpt": "The image shown above is not of a real person but is generated by a machine from scratch. That is what GAN is all about. \nGAN was proposed by Ian Goodfellow and his colleagues in the year 2014 when Ian was about 28. Being the father of GAN, he is considered as the man who gave machines the gift of imagination. The legends go that Ian was approached by his friends regarding a\u00a0machine that produces images\u00a0at a bar one night. Now, let's have a closer look at Ian's GANs. \nBefore we get a rough idea about how GANs work, I request you to read a little bit about deep learning, all it's general algorithms such as backpropagation and CNN to understand GANs better. Here are some useful links. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9571252511937696
      ],
      "excerpt": "The two main pillars of GAN are generator and discriminator. These are two sophisticated neural networks that are the working hands behind the magic of GAN. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.993365472010169,
        0.9910995811533067
      ],
      "excerpt": "Consider the generator and discriminator to be a student and teaching assistant (TA) respectively. Both of them are present here for an examination. Let's assume both of them know nothing in the beginning. The job of the student (generator) is to write the answers, and the role of the TA (discriminator) is to check the answers from an answer book. Initially, the students scribble out a few random answers and pass that on to the TA. The TA randomly allocates rough marks to those answers, and then he goes on to check the answers with the answer book. In doing so, The TA realizes his mistakes and learns from them while giving the correct marks. \nFurthermore, once the students get the feedback of the marks, he learns about his mistakes and tries to write better, close to the correct answer. This cycle of double looping continues until the answers produced are really close to the right answers. This, in simple terms, is how GAN works. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9953995261998979
      ],
      "excerpt": "As mentioned above, the Generator and Discriminator are both neural networks. The generator, as the name suggests, generates new data instances; on the other hand, discriminator acts as a judge for the generated data instances. Both of these networks are trained from scratch, while they compete with each other in a game of guesses. The game is based on the criteria of data distributions. We won't dive deep into the mathematics of their working. The generator generates fake images from a sample random noise (to be honest, nothing is truly random, so let's call it pseudo-random) and then it passes that on to the discriminator in the hopes that those fake images get accepted as real images by the discriminator. The discriminator is also passed with ground-truth, i.e. real classified dataset. The discriminator tries to identify the real and the fake photos, by firstly giving random probabilities between 0 (fake) and 1 (real) to the images. Then, it learns from its mistakes and back-propagates the error to provide better probabilities. This cycle continues until it gives close to correct probabilities to all the images, i.e. close to 1 for real pictures and close to 0 for fake images. Once this is done, the feedback of the probabilities of the fake images is backpropagated to the generator, which then tries to create new images with better probabilities. This double-cycle continues until the likelihood of the generated images gets close to 1. This, in a nutshell, is how GAN works. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8130396596400972,
        0.8357956242469802
      ],
      "excerpt": "Discriminator learns from the ground-truth dataset and provides more accurate probabilities. Then, it returns it backwards. \nGenerator learns from the returned probabilities and tries to create images with better probabilities. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9741830132188479
      ],
      "excerpt": "Here is a list of some fantastic applications of GAN, listed by\u00a0Jason Brownlee. Please go through his article to learn about all these applications. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9318017684635971
      ],
      "excerpt": "Generate Photographs of Human Faces \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "Photos to Emojis \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9670478733013558,
        0.9623249193129471
      ],
      "excerpt": "You can see GAN in action on this amazing website,\u00a0thispersondoesnotexist.com. This website uses StyleGAN2 and presents to you a computer-generated random picture of a person who doesn't exist in real life whenever you visit this website. Just keep on refreshing. The images generated are shockingly realistic, and this helps to show the real power of GANs. This website was created by Phillip Wang to showcase the potential of StyleGAN2 and GANs in general. Isn't this amazing?! \nNow, that we know what GAN is capable of, let's try to code our own DCGAN in python. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8727602657993437
      ],
      "excerpt": "Tip: You can code the complete DCGAN on Google Colab. In your Goggle Colab notebook, go to Runtime > Change Runtime Type and under hardware accelerator select\u00a0GPU. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "GAN is a class of deep learning framework dedicated to creating new things. Unlike conventional deep learning techniques that are used to detect various things, GAN is used to produce new things. Think of GAN as a painter; it likes to paint. Identifying a particular item, say a hat is something any literate human can do. We can easily mimic this on a computer using a deep learning framework. But, GAN, on the other hand, is a step towards creativity, a level close to intelligence.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Nirav-Agarwal/GANs/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 13:30:42 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Nirav-Agarwal/GANs/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Nirav-Agarwal/GANs",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Nirav-Agarwal/GANs/master/DCGAN.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8082446133560257,
        0.8607322064556925
      ],
      "excerpt": "Note: If you don't want to manually download the dataset or you're having some problem in downloading it, then please don't worry. The fourth code cell in the following Colab file will do it for you. \nTip: You can code the complete DCGAN on Google Colab. In your Goggle Colab notebook, go to Runtime > Change Runtime Type and under hardware accelerator select\u00a0GPU. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8313044918234457
      ],
      "excerpt": "Generate Examples for Image Datasets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9093381040030603
      ],
      "excerpt": "Extract the dataset and put it in folder 'data'. Also, create an empty folder in the same directory to hold the output images. Start a new python file in the directory containing the data and the empty folder. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Nirav-Agarwal/GANs/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "GANS IN DEEP LEARNING\n---------------------\n\nGenerative Adversarial Networks",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "GANs",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Nirav-Agarwal",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Nirav-Agarwal/GANs/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 13:30:42 GMT"
    },
    "technique": "GitHub API"
  }
}
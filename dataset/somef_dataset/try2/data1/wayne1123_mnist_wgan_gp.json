{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1406.2661",
      "https://arxiv.org/abs/1701.07875"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9960512928369745
      ],
      "excerpt": "Based on this Paper: https://arxiv.org/pdf/1704.00028.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "<10 epochs> <br/> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wayne1123/mnist_wgan_gp",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-01-22T09:21:46Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-01-22T12:12:14Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The vanilla GAN (https://arxiv.org/abs/1406.2661) tries to find the Nash Equilibrium between Generator and Discriminator, and it minimizes the Jessen - Shannon Divergence at the optimal point. It is the generative model without the likelihood. However, there were some issues - GAN is very hard to train, and it is precarious. There were many proposed solutions to these problems, as mentioned earlier.\n\nOne of the breakthroughs was WGAN paper (https://arxiv.org/abs/1701.07875). Rather than finding the equilibrium between two neural networks, WGAN paper tries to minimize the 1-Wasserstein Distance(WD) between two networks. Intuitively, WD is the cost function of moving one distribution to the another. As the neural network is a powerful function approximator, WGAN finds the optimal transport from the sample to the real distribution.\n\nHowever, the functions we derived from the WGAN need to meet the 1-Lipschitz condition. WGAN-GP came up with one solution to impose the gradient penalty(GP) as the gradient we obtained from the point between the real data and the samples deviates from 1. This approach works quite well.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9651907066052885
      ],
      "excerpt": "I've implemented WGAN-GP for MNIST data set using PyTorch 1.3.1. I assume that GPUs are available for this implementation and it supports multiple GPUs. You can test by changing the hyperparameters. Sample images are saved for every epoch, and model parameters and losses are recorded periodically. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "WGAN-GP for MNIST ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wayne1123/mnist_wgan_gp/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "cp : 0. ",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 16:36:22 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/wayne1123/mnist_wgan_gp/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "wayne1123/mnist_wgan_gp",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "wd : True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9049913352698458
      ],
      "excerpt": "python train.py --lr 1e-2 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/wayne1123/mnist_wgan_gp/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "## Wasserstein GAN - Gradient Penalty (WGAN-GP) for MNIST",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "mnist_wgan_gp",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "wayne1123",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wayne1123/mnist_wgan_gp/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npython train.py\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 16:36:22 GMT"
    },
    "technique": "GitHub API"
  }
}
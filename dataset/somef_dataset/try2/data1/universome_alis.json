{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2104.06954",
      "https://arxiv.org/abs/2104.06954",
      "https://arxiv.org/abs/2104.06954"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{ALIS,\n  title={Aligning Latent and Image Spaces to Connect the Unconnectable},\n  author={Skorokhodov, Ivan and Sotnikov, Grigorii and Elhoseiny, Mohamed},\n  journal={arXiv preprint arXiv:2104.06954},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "<div style=\"text-align:center\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "<div style=\"text-align:center\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/universome/alis",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-12T16:44:47Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T07:07:14Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9942580209281564,
        0.9257822883417961
      ],
      "excerpt": "This repo contains the official implementation of the Aligning Latent and Image Spaces to Connect the Unconnectable paper. \nIt is a GAN model which can generate infinite images of diverse and complex scenes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9097969617726637
      ],
      "excerpt": "[Project page] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9254448424432901
      ],
      "excerpt": "See StyleGAN2-ADA repo for additional data format details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9643327815784497
      ],
      "excerpt": "This is needed to isolate the code which produces the model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8953881207213729,
        0.8388956730911223
      ],
      "excerpt": "We use the same data format as the original StyleGAN2-ADA repo: it is a zip of images. \nIt is assumed that all data is located in a single directory, specified in configs/main.yml. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9895844594310476,
        0.8786017584977781,
        0.9036800994277991
      ],
      "excerpt": "It is recommended to preprocess the dataset with the procedure described in Algorithm 1 since it noticeably affects the results (see Table 3). \nWe provide checkpoints for the following datasets: \n- LHQ 1024x1024 with FID = 7.8. Note: this checkpoint has patch size of 1024x512, i.e. the image is generated in just 2 halves. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8053737744653506,
        0.8179708415250708
      ],
      "excerpt": "| &boxvr;&nbsp; LHQ1024_jpg | 12G | 90,000 | JPG | LHQ1024 converted to JPG format with quality=95 (with Pillow)* | \n| &boxvr;&nbsp; LHQ256 | 8.7G | 90,000 | PNG | LHQ1024 resized to 256x256 with Lanczos interpolation | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9831806232514576
      ],
      "excerpt": "For details, see lhq.md and Section 4 in the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Aligning Latent and Image Spaces to Connect the Unconnectable [ICCV 2021]",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://pillow.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/universome/alis/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 19,
      "date": "Tue, 21 Dec 2021 07:19:10 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/universome/alis/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "universome/alis",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/universome/alis/master/notebooks/check-equivariance.ipynb",
      "https://raw.githubusercontent.com/universome/alis/master/notebooks/generate.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To install, run the following command:\n```\nconda env create --file environment.yml --prefix ./env\nconda activate ./env\n```\n\nNote: the tensorboard requirement is crucial, because otherwise upfirdn2d will not compile for some magical reason.\nThe repo should work both on Linux/MacOS and Windows machines.\nHowever, on Windows, there might arise difficulties with installing some requirements: please see [#3](https://github.com/universome/alis/issues/3) to troubleshoot.\nAlso, since the current repo is heavily based on StyleGAN2-ADA, it might be helpful to check [the original installation requirements](https://github.com/NVlabs/stylegan2-ada-pytorch#requirements).\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8912736293239448
      ],
      "excerpt": "We will release a filtered version soon. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8001524140415636,
        0.9193041898092811
      ],
      "excerpt": "To train the model, navigate to the project directory and run: \npython infra/launch_local.py hydra.run.dir=. +experiment_name=my_experiment_name +dataset=dataset_name num_gpus=4 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8330958613721006
      ],
      "excerpt": "This training command will create an experiment inside experiments/ directory and will copy the project files into it. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8868313427374724
      ],
      "excerpt": "Put your datasets as zip archives into data/ directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9008463770205759
      ],
      "excerpt": "<img src=\"assets/lhq.png\" alt=\"25 random images from LHQ\" style=\"max-width: 500px\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.809840140954369
      ],
      "excerpt": "| &boxvr;&nbsp; LHQ | 155G | 90,000 | PNG | The complete dataset. Split into 4 zip archives. | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8328925051680184
      ],
      "excerpt": "| &boxvr;&nbsp; LHQ1024_jpg | 12G | 90,000 | JPG | LHQ1024 converted to JPG format with quality=95 (with Pillow)* | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/universome/alis/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Cuda",
      "C++"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "## About",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "alis",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "universome",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/universome/alis/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 156,
      "date": "Tue, 21 Dec 2021 07:19:10 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "gan",
      "infinite",
      "image-generation",
      "nature",
      "landscapes",
      "dataset"
    ],
    "technique": "GitHub API"
  }
}
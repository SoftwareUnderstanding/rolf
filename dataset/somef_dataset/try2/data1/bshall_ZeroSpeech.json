{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1901.08810",
      "https://arxiv.org/abs/1811.06292",
      "https://arxiv.org/abs/1711.00937"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This work is based on:\n\n1.  Chorowski, Jan, et al. [\"Unsupervised speech representation learning using wavenet autoencoders.\"](https://arxiv.org/abs/1901.08810)\n    IEEE/ACM transactions on audio, speech, and language processing 27.12 (2019): 2041-2053.\n\n2.  Lorenzo-Trueba, Jaime, et al. [\"Towards achieving robust universal neural vocoding.\"](https://arxiv.org/abs/1811.06292)\n    INTERSPEECH. 2019.\n    \n3.  van den Oord, Aaron, and Oriol Vinyals. [\"Neural discrete representation learning.\"](https://arxiv.org/abs/1711.00937)\n    Advances in Neural Information Processing Systems. 2017.\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8672318739006013
      ],
      "excerpt": "    For dataset choose between 2019/english or 2019/surprise. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222383658450612
      ],
      "excerpt": "    \"2019\": { \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bshall/ZeroSpeech",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-25T17:44:16Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-24T05:43:07Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9520716409545594
      ],
      "excerpt": "Train and evaluate the VQ-VAE model for our submission to the ZeroSpeech 2020 challenge. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8577437186282095,
        0.888633623156033
      ],
      "excerpt": "containing a list of items with a) the path (relative to in_dir) of the source wav files; \nb) the target speaker (see datasets/2019/english/speakers.json for a list of options); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9755539985120516
      ],
      "excerpt": "The ABX score for the pretrained english model (available here) is: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "VQ-VAE for Acoustic Unit Discovery and Voice Conversion",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bshall/ZeroSpeech/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 37,
      "date": "Mon, 27 Dec 2021 17:14:45 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/bshall/ZeroSpeech/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "bshall/ZeroSpeech",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.870806492193423
      ],
      "excerpt": "Download the train/test splits here  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8515966870466528
      ],
      "excerpt": "    Note: in_dir must be the path to the 2019 folder.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9104125470935532
      ],
      "excerpt": "Train the models or download pretrained weights here: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8562539692762675
      ],
      "excerpt": "    <img width=\"495\" height=\"639\" alt=\"VQ-VAE for Acoustic Unit Discovery\"  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.938507049942355
      ],
      "excerpt": "Download the train/test splits here  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8808892807551543
      ],
      "excerpt": "Preprocess audio and extract train/test log-Mel spectrograms: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9017146079470988
      ],
      "excerpt": "Train the models or download pretrained weights here: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8283455500063625
      ],
      "excerpt": "e.g. python train.py checkpoint_dir=checkpoints/2019english dataset=2019/english \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633989807152664
      ],
      "excerpt": "        \"english/test/S002_0379088085\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8072487830659577
      ],
      "excerpt": "and c) the target file name. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633989807152664
      ],
      "excerpt": "                \"test\": 412.2387509949519 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633989807152664
      ],
      "excerpt": "                \"test\": { \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/bshall/ZeroSpeech/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "VQ-VAE for Acoustic Unit Discovery and Voice Conversion",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ZeroSpeech",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "bshall",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bshall/ZeroSpeech/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "bshall",
        "body": "Pretrained weights for the VQ-VAE models trained on the ZeroSpeech 2019 English and surprise language datasets.\r\n\r\nIncludes the test/train splits used to train and evaluate the models.",
        "dateCreated": "2020-04-19T13:36:58Z",
        "datePublished": "2020-04-19T14:31:38Z",
        "html_url": "https://github.com/bshall/ZeroSpeech/releases/tag/v0.1",
        "name": "ZeroSpeech 2019 english and surprise language models",
        "tag_name": "v0.1",
        "tarball_url": "https://api.github.com/repos/bshall/ZeroSpeech/tarball/v0.1",
        "url": "https://api.github.com/repos/bshall/ZeroSpeech/releases/25654230",
        "zipball_url": "https://api.github.com/repos/bshall/ZeroSpeech/zipball/v0.1"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1.  Ensure you have Python 3 and PyTorch 1.4 or greater.\n\n2.  Install [NVIDIA/apex](https://github.com/NVIDIA/apex) for mixed precision training.\n\n3.  Install pip dependencies:\n    ```\n    pip install -r requirements.txt\n    ```\n\n4.  For evaluation install [bootphon/zerospeech2020](https://github.com/bootphon/zerospeech2020).\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 204,
      "date": "Mon, 27 Dec 2021 17:14:45 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "vq-vae",
      "voice-conversion",
      "zerospeech",
      "acoustic-features",
      "speech-synthesis"
    ],
    "technique": "GitHub API"
  }
}
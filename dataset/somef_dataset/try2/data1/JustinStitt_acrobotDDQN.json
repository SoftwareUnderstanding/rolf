{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1509.06461\n\n[Phil Tabor's excellent repository on all things DQN](https://github.com/philtabor/Deep-Q-Learning-Paper-To-Code"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "https://towardsdatascience.com/double-deep-q-networks-905dd8325412\n\nhttps://arxiv.org/abs/1509.06461\n\n[Phil Tabor's excellent repository on all things DQN](https://github.com/philtabor/Deep-Q-Learning-Paper-To-Code)",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JustinStitt/acrobotDDQN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-28T22:53:49Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-29T03:20:12Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9701453265158827,
        0.9427284780391724,
        0.9552285321277907
      ],
      "excerpt": "see my DQN for Cartpole and Lunar-Lander \nfor a much more detailed writeup on DQN's. \nor see my Digit Recognizer for a supervised Deep Learning model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8616129270886216
      ],
      "excerpt": "Before I get into that, let's look at the results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9236561544540677,
        0.9495842830117994
      ],
      "excerpt": "The objective of Acrobot is to cross the black threshold line near the top of the window. Acrobot can control two joints by  \nadding torque to the left or to the right. Crossing the threshold faster is better, this is why you will see the trained agent move \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9099810649307006,
        0.8795073283643999,
        0.9370710454587404,
        0.9680234179400382,
        0.817910419930161
      ],
      "excerpt": "standard DQN, but it also has a target network that is used to predict the best action that could've been made in any given state. \nThe Problem With a DQN and How a DDQN Solves It \nThe issue with a DQN is that we are using the same network to both train and calculate the best action for a given state. \nFor insight, here is the Bellman equation: \nHere, the same Q evaluation network is being used for both the current (state,action) and (next_state, next_action) -- seen underlined in blue-- . This yields some \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8538976931853335,
        0.9796272064080853,
        0.8384122910939108
      ],
      "excerpt": "Without a target network, the local network is almost blindly following an ever-changing network. \nA DDQN solves this issue because it separates the duality of training and evaluating.  The introduction of a target network adds some stability to the training process \nwhich allows, generally, for better training results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "My first Double DQN model. Used to learn basic control task -- Acrobot -- OpenAI Gym",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JustinStitt/acrobotDDQN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 08:44:50 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/JustinStitt/acrobotDDQN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "JustinStitt/acrobotDDQN",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/JustinStitt/acrobotDDQN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "acrobotDDQN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "acrobotDDQN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "JustinStitt",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JustinStitt/acrobotDDQN/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 08:44:50 GMT"
    },
    "technique": "GitHub API"
  }
}
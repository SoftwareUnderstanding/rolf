{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1801.06146"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/  \n[2] http://thinknook.com/wp-content/uploads/2012/09/Sentiment-Analysis-Dataset.zip  \n[3] https://stackoverflow.com/questions/46387661/how-to-correctly-implement-a-batch-input-lstm-network-in-pytorch  \n[4] https://colah.github.io/posts/2015-08-Understanding-LSTMs/  \n[5] https://arxiv.org/abs/1801.06146\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hpanwar08/sentence-classification-pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-04-15T03:00:51Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-28T09:28:46Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9589087639512793,
        0.8191312592403611,
        0.9046891691360768
      ],
      "excerpt": "This repo contains the code for the this blog. \nOur final aim is to build a simple GRU model with concat pooling [5]. For this post I will use Twitter Sentiment Analysis [1] dataset as this is a much easier dataset compared to the competition. Download dataset from [2] \nThis post focuses on how to implement sequence classification with variable lengths in pure pytorch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8928437663471156
      ],
      "excerpt": "Pad tweets to the max length in the batch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8764652472771289
      ],
      "excerpt": "RNN model (GRU) with concat pooling \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8547385386461036,
        0.8422654724276856,
        0.8422654724276856,
        0.9488056900751765
      ],
      "excerpt": "Add callback for epoch loss and accuracy \nAdd callback for ModelCheckpoint \nAdd callback for EarlyStopping \nAdded a new repository that contains REST API build in Flask to deploy ML models in production. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8430362807811177
      ],
      "excerpt": "Simple Data Analysis \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8764652472771289
      ],
      "excerpt": "GRU model with concat pooling \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Sentiment analysis with variable length sequences in pytorch",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hpanwar08/sentence-classification-pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Sun, 26 Dec 2021 08:34:58 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hpanwar08/sentence-classification-pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "hpanwar08/sentence-classification-pytorch",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/hpanwar08/sentence-classification-pytorch/master/Sentiment%20analysis%20pytorch%201.0.ipynb",
      "https://raw.githubusercontent.com/hpanwar08/sentence-classification-pytorch/master/Sentiment%20analysis%20pytorch.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9096104964140866
      ],
      "excerpt": "Build vocabulary   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.927222224902773
      ],
      "excerpt": "Make batches through pytorch Dataloader   \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": "Ignite training callbacks \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8394619731997299
      ],
      "excerpt": "[x] Add function to make train/validation split \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hpanwar08/sentence-classification-pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Himanshu\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Sentiment Analysis with Variable Length sequences in pytorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "sentence-classification-pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "hpanwar08",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hpanwar08/sentence-classification-pytorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Python 3.6\n* Basic knowledge of [Pytorch 0.3.1](http://pytorch.org/)\n* Understanding of GRU/LSTM [4]\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 33,
      "date": "Sun, 26 Dec 2021 08:34:58 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "deep-learning",
      "nlp",
      "python",
      "sentiment-analysis"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "> Added pytorch 1.0 compatible notebook. It uses pytorch 1.1 and ignite training functions. Also better use of pytorch Dataset and Dataloader. Code is more compact and easy to understand.\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1506.06256",
      "https://arxiv.org/abs/1602.07360"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{ck-date16,\n    title = {{Collective Knowledge}: towards {R\\&D} sustainability},\n    author = {Fursin, Grigori and Lokhmotov, Anton and Plowman, Ed},\n    booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe (DATE'16)},\n    year = {2016},\n    month = {March},\n    url = {https://www.researchgate.net/publication/304010295_Collective_Knowledge_Towards_RD_Sustainability}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{Lokhmotov:2016:OCN:2909437.2909449,\n author = {Lokhmotov, Anton and Fursin, Grigori},\n title = {Optimizing Convolutional Neural Networks on Embedded Platforms with OpenCL},\n booktitle = {Proceedings of the 4th International Workshop on OpenCL},\n series = {IWOCL '16},\n year = {2016},\n location = {Vienna, Austria},\n url = {http://doi.acm.org/10.1145/2909437.2909449},\n acmid = {2909449},\n publisher = {ACM},\n address = {New York, NY, USA},\n keywords = {Convolutional neural networks, OpenCL, collaborative optimization, deep learning, optimization knowledge repository},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9267867627836347
      ],
      "excerpt": "open academic and industrial R&D challenges - \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8423330483425703
      ],
      "excerpt": "<a href=\"https://github.com/ctuning/ck/wiki/Publications\">All related references with BibTex</a> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dividiti/ck-caffe",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-06-06T13:53:26Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-17T03:31:05Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n[CK-Caffe](https://github.com/dividiti/ck-caffe) is an open framework for\r\ncollaborative and reproducible optimisation of convolutional neural networks.\r\nIt's based on the [Caffe](http://caffe.berkeleyvision.org) framework from the\r\nBerkeley Vision and Learning Center ([BVLC](http://bvlc.eecs.berkeley.edu)) and\r\nthe [Collective Knowledge](http://cknowledge.org) framework for customizable\r\ncross-platform builds and experimental workflows with JSON API from the\r\n[cTuning Foundation](http://ctuning.org) (see CK intro for more details: [1](https://arxiv.org/abs/1506.06256),\r\n[2](https://www.researchgate.net/publication/304010295_Collective_Knowledge_Towards_RD_Sustainability) ).\r\nIn essence, CK-Caffe is an open-source suite of convenient wrappers and workflows with unified\r\nJSON API for simple and customized building, evaluation and multi-objective optimisation\r\nof various Caffe implementations (CPU, CUDA, OpenCL) across diverse platforms\r\nfrom mobile devices and IoT to supercomputers.\r\n\r\nAs outlined in our [vision](http://dx.doi.org/10.1145/2909437.2909449),\r\nwe invite the community to collaboratively design and optimize convolutional\r\nneural networks to meet the performance, accuracy and cost requirements for\r\ndeployment on a range of form factors - from sensors to self-driving cars. To\r\nthis end, CK-Caffe leverages the key capabilities of CK to crowdsource\r\nexperimentation across diverse platforms, CNN designs, optimization\r\noptions, and so on; exchange experimental data in a flexible JSON-based format;\r\nand apply leading-edge predictive analytics to extract valuable insights from\r\nthe experimental data.\r\n\r\nSee [cKnowledge.org/ai](http://cKnowledge.org/ai), \r\n[reproducible and CK-powered AI/SW/HW co-design competitions at ACM/IEEE conferences](http://cKnowledge.org/request),\r\n[shared optimization statistics](http://cKnowledge.org/repo),\r\n[reusable AI artifact in the CK format](http://cKnowledge.org/ai-artifacts)\r\nand [online demo of CK AI API with self-optimizing DNN](http://cKnowledge.org/ai/ck-api-demo) for more details.\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9108796694828654
      ],
      "excerpt": "20181205: It seems that Caffe for Android fails with the latest NDK.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9687456492847317
      ],
      "excerpt": "for Android via CK with the NDK r13b and Boost 1.64 as described  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9662085007475413
      ],
      "excerpt": "A suite of open-source tools for collecting knowledge on optimising AI: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9275778553146602
      ],
      "excerpt": "we compare the Top-1 and Top-5 accuracy of 4 models: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9525485888181698,
        0.9274216728790242
      ],
      "excerpt": "The experimental data (stored in the main CK-Caffe repository under 'experiment') essentially confirms that SqueezeNet matches (and even slightly exceeds) the accuracy of AlexNet on the ImageNet validation set (50,000 images). \nWe have performed several detailed performance analysis studies across a range of platforms using CK-Caffe. The following results are publicly available: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8063448462990126
      ],
      "excerpt": "Samsung Chromebook 2 (view on github.com; view on nbviewer.jupyter.org): 3 models, OpenBLAS v0.2.19 (also varying the batch size and the number of threads). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8352840963306578
      ],
      "excerpt": "$ ck crowdbench caffe --user={your email or ID to acknowledge contributions} --env.CK_CAFFE_BATCH_SIZE=5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008610485354856
      ],
      "excerpt": "i.e. using Caffe CPU or OpenCL binaries pre-built by the CK. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9561042324336746
      ],
      "excerpt": "to crowdsource benchmarking of ARM-based Caffe libraries for image recognition. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8067398996003139
      ],
      "excerpt": "public Collective Knowledge repository. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9769706175902023
      ],
      "excerpt": "It is also possible to take advantage of our universal multi-objective CK autotuner \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9570014838234984
      ],
      "excerpt": "All results will be recorded in the local CK repository and  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8558726647836401
      ],
      "excerpt": "When prompted, enter the number of images to convert to LMDB, say, N = 100. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9512797110700942,
        0.9757920243551109
      ],
      "excerpt": "CK-Caffe is part of an ambitious long-term and community-driven \nproject to enable collaborative and systematic optimization \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8939648823176041,
        0.8330822469635556
      ],
      "excerpt": "in terms of performance, energy usage, accuracy, reliability, \nhardware price and other costs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9689273178554816,
        0.8759929906679597
      ],
      "excerpt": "We are working with the community to unify and crowdsource performance analysis \nand tuning of various DNN frameworks (or any representative workloads) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8237106475255666
      ],
      "excerpt": "* Android app for DNN crowd-benchmarking and crowd-tuning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9059128280218887,
        0.9021337056683314,
        0.8511163114172895
      ],
      "excerpt": "We continue to gradually expose various design and optimization \nchoices including full parameterization of existing models. \nWe use crowd-benchmarking and crowd-tuning of such realistic workloads across diverse hardware for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Collective Knowledge workflow for Caffe to automate installation across diverse platforms and to collaboratively evaluate and optimize Caffe-based workloads across diverse hardware, software and data sets (compilers, libraries, tools, models, inputs):",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dividiti/ck-caffe/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 40,
      "date": "Sun, 26 Dec 2021 21:21:29 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dividiti/ck-caffe/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "dividiti/ck-caffe",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size-libs-models/explore-batch-size-libs-models-analysis.ipynb",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/explore_batch_size.ipynb",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-accuracy/explore_accuracy.20160808.ipynb",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-accuracy/explore_accuracy.ipynb",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/check-deps/check_deps.ipynb",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/check-deps/check_deps.xu3.20160808.ipynb",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-dvdt-prof-libs-models/explore-dvdt-prof-libs-models-analysis.ipynb",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size-openblas-threads/explore-batch-size-openblas-threads-analysis.ipynb",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-opencl-build-compile-time/explore-opencl-build-compile-time.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/dataset-voc-2012/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-master-cuda-universal-20171020/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-master-cuda-universal-20171020/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-nvidia-0.16-cudnn-universal/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-nvidia-0.16-cudnn-universal/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-nvidia-0.16-cuda-universal/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-nvidia-0.16-cuda-universal/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-master-cudnn-universal-20171020/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-master-cudnn-universal-20171020/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-armcl-universal/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-clblast-universal/old/arc/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-clblast-universal/old/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-clblast-universal/old/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-clblast-universal/old/scripts.android/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/caffemodel-ssd-coco-300/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-ssd-cpu/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-viennacl-universal/old/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-viennacl-universal/old/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-viennacl-universal/old/scripts.android/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/caffemodel-ssd-voc-300/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/caffemodel-ssd-coco-512/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-nvidia-0.17-cudnn-universal/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-nvidia-0.17-cudnn-universal/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-clblast-universal-20171015/old/arc/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-clblast-universal-20171015/old/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-clblast-universal-20171015/old/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-clblast-universal-20171015/old/scripts.android/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-master-cuda-universal/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-master-cuda-universal/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-viennacl-universal/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-viennacl-universal/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-viennacl-universal/scripts.android/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-clblast-universal/arc/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-clblast-universal/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-clblast-universal/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-clblast-universal/scripts.android/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-master-cudnn-universal/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-master-cudnn-universal/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-master-cpu-universal/arc/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-master-cpu-universal/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-master-cpu-universal/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-master-cpu-universal/scripts.android/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-cpu-universal/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-cpu-universal/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-cpu-universal/scripts.android/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-cuda-universal/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-cuda-universal/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/dataset-voc-2007/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-clblas-universal/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-clblas-universal/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-intel-request-cpu/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-intel-master-cpu/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-intel-master-cpu/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-ssd-cuda/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-1.0-cuda-spack/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-clblast-universal-tune/arc/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-clblast-universal-tune/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-clblast-universal-tune/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-clblast-universal-tune/scripts.android/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-clblast-universal-tune/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-clblast-universal-tune/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-clblast-universal-tune/scripts.android/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-clblas-universal/scripts.linux/install.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/lib-caffe-bvlc-opencl-libdnn-clblas-universal/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/package/caffemodel-ssd-voc-512/scripts.linux/post-install2.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size-libs-models/_explore-batch-size-libs-models-clobber.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size-libs-models/_explore-batch-size-libs-models-convert.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/explore_batch_size_googlenet_clblast_mali_overlay.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/_setup_program_pipeline.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/explore_batch_size_googlenet_clblast_development.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/explore_batch_size_squeezenet_1.0_clblas.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/_clean_program_pipeline.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/_clean_experiment_entries.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/explore_batch_size_alexnet_clblas.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/explore_batch_size_squeezenet_1.0_clblast_mali_overlay.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/explore_batch_size_squeezenet_1.1_clblast_mali_overlay.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/explore_batch_size_squeezenet_1.0_clblast_development.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/explore_batch_size_alexnet_clblast_development.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/plot_batch_size_with_variation.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/explore_batch_size_squeezenet_1.1_clblast_development.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/explore_batch_size_googlenet_clblas.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/explore_batch_size_alexnet_clblast_mali_overlay.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-batch-size/explore_batch_size_squeezenet_1.1_clblas.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-accuracy/_setup_program_pipeline.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-accuracy/explore_accuracy_squeezenet_1.1.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-accuracy/_clean_program_pipeline.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-accuracy/explore_accuracy_alexnet.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-accuracy/explore_accuracy_googlenet.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-accuracy/_clean_experiment_entries.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-accuracy/explore_accuracy_squeezenet_1.0.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/build-caffe/1_clone.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/build-caffe/4_build.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/build-caffe/2_checkout.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/download-caffemodel/download.sh",
      "https://raw.githubusercontent.com/dividiti/ck-caffe/master/script/explore-dvdt-prof-libs-models/_clean_experiment_entries.sh"
    ],
    "technique": "File Exploration"
  },
  "identifier": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://zenodo.org/badge/latestdoi/60531899",
      "technique": "Regular expression"
    }
  ],
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nYou can find details about CK-Caffe installation for Windows, various flavours\r\nof Linux and Android [here](http://github.com/dividiti/ck-caffe/wiki/Installation).\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nWe provided an option in all our AI crowd-tuning tools to let the community report \r\nand share mispredictions (images, correct label and wrong misprediction) \r\nto gradually and collaboratively build realistic data/training sets:\r\n* [Public repository (see \"mispredictions and unexpected behavior)](http://cknowledge.org/repo/web.php?action=index&module_uoa=wfe&native_action=show&native_module_uoa=program.optimization)\r\n* [Misclassified images via CK-based AI web-service](http://cknowledge.org/repo/web.php?action=index&module_uoa=wfe&native_action=show&native_module_uoa=program.optimization)\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n```\r\n $ ck compile program:caffe-classification --speed\r\n $ ck run program:caffe-classification\r\n```\r\n\r\nNote that you will be asked to select a JPEG image from available CK data sets.\r\nWe have added standard demo images (`cat.jpg`, `catgrey.jpg`, `fish-bike.jpg`, `computer_mouse.jpg`)\r\nto the ['ctuning-datasets-min' repository](https://github.com/ctuning/ctuning-datasets-min).\r\n\r\nYou can list them via:\r\n```\r\n $ ck pull repo:ctuning-datasets-min\r\n $ ck search dataset --tags=dnn\r\n```\r\n\r\nYou can minimize interactive selection of multiple software dependencies by adding \"--reuse_deps\" flag during compilation, i.e.\r\n```\r\n $ ck compile program:caffe-classification --speed --reuse_deps\r\n $ ck run program:caffe-classification\r\n```\r\n\r\nIf you have Android SDK and NDK installed, you can compile and run the same classification example on your Android device \r\nconnected to a host machine via ADB as follows:\r\n\r\n```\r\n $ ck compile program:caffe-classification --speed --target_os=android21-arm64\r\n $ ck run program:caffe-classification --target_os=android21-arm64\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nVery often latest Caffe conflicts with the older protobuf version installed on a system.\r\nThat's why we suggest to install protobuf via CK before installing Caffe:\r\n```\r\n$ ck install package --tags=protobuf-host\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n```\r\n$ ck pull repo:ck-caffe --url=https://github.com/dividiti/ck-caffe\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n\r\n```\r\n$ sudo pip install ck\r\n```\r\n\r\nSkip \"sudo\" if installing on Windows.\r\n\r\nAlternatively, you can install CK in a user space as follows:\r\n```\r\n$ git clone http://github.com/ctuning/ck ck-master\r\n$ export PATH=$PWD/ck-master/bin:$PATH\r\n$ export PYTHONPATH=$PWD/ck-master:$PYTHONPATH\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "CK can automatically build the following dependencies from source using versions that should work well together. Installing via `apt`, however, is somewhat faster.\r\n\r\n```\r\n$ sudo apt install libboost-all-dev \\\r\n                   libgflags-dev \\\r\n                   libgoogle-glog-dev \\\r\n                   libhdf5-serial-dev \\\r\n                   liblmdb-dev \\\r\n                   libprotobuf-dev \\\r\n                   protobuf-compiler \\\r\n                   libopencv-dev\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\r\n$ sudo apt install libleveldb-dev \\\r\n                   libsnappy-dev \\\r\n                   gfortran\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n```\r\n$ sudo apt install coreutils \\\r\n                   build-essential \\\r\n                   make \\\r\n                   cmake \\\r\n                   wget \\\r\n                   git \\\r\n                   python \\\r\n                   python-pip\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nPlease refer to our [Installation Guide](https://github.com/dividiti/ck-caffe/wiki/Installation) for detailed instructions for Ubuntu, Gentoo, Yocto, RedHat, CentOS, Windows and Android.\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8487528302784701,
        0.9322609392449874
      ],
      "excerpt": "* CK-MXNet \n* CK-PyTorch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9717106327039013,
        0.9798249181182727
      ],
      "excerpt": "$ ck version \nWe suggest you to configure CK to install packages to the CK virtual environment entries (env): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8238854939270611
      ],
      "excerpt": "During collaborative benchmarking, you can select various engines (which will be built on your machine) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8200272666083938,
        0.8699350291043088
      ],
      "excerpt": "You can also manually install additional flavours of Caffe engines across diverse hardware \nand OS (Linux/Windows/Android on Odroid, Raspberry Pi, ARM, Intel, AMD, NVIDIA, etc.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9604597756854836
      ],
      "excerpt": "You can also install extra models as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9882181486894339
      ],
      "excerpt": " $ ck install package:{name of above packages} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.888068542542079,
        0.8795835510698002,
        0.9545997826268481,
        0.9372567016938239
      ],
      "excerpt": "You can crowd-benchmark Caffe on Windows without re-compilation, \ni.e. using Caffe CPU or OpenCL binaries pre-built by the CK. \nYou should install such binaries as follows: \n$ ck install package:lib-caffe-bvlc-master-cpu-bin-win \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9043881369749348,
        0.8012111825047737
      ],
      "excerpt": "$ ck install package:lib-caffe-bvlc-opencl-libdnn-viennacl-bin-win \nYou can also use this Android app \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9431007113850761,
        0.9681316988171879,
        0.9805553089891352
      ],
      "excerpt": "$ ck install package:lib-caffe2-master-eigen-cpu-universal --env.CAFFE_BUILD_PYTHON=ON \n$ ck install package:lib-tensorflow-1.1.0-cpu \n$ ck install package:lib-tensorflow-1.1.0-cuda \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8873513712364506
      ],
      "excerpt": "When compiling OpenCL version of Caffe on Linux targeting NVidia GPU, select generic x86_64/libOpenCL.so rather than NVidia OpenCL driver when asked by the CK. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8420692765253246
      ],
      "excerpt": "The ILSVRC2012 validation dataset contains 50K images. For quick experiments, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8271866265271554,
        0.8607321697705127
      ],
      "excerpt": "When prompted, enter the number of images to convert to LMDB, say, N = 100. \nThe first N images will be taken. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dividiti/ck-caffe/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "CMake",
      "Python",
      "C++",
      "Shell",
      "Jupyter Notebook",
      "Batchfile",
      "HTML",
      "Roff"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/dividiti/ck-caffe/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'COPYRIGHT\\n\\nAll contributions by the University of California:\\nCopyright (c) 2014, 2015, The Regents of the University of California (Regents)\\nAll rights reserved.\\n\\nAll other contributions:\\nCopyright (c) 2014, 2015, the respective contributors\\nAll rights reserved.\\n\\nCaffe uses a shared copyright model: each contributor holds copyright over\\ntheir contributions to Caffe. The project versioning records all such\\ncontribution and copyright details. If a contributor wants to further mark\\ntheir specific copyright on a particular contribution, they should indicate\\ntheir copyright solely in the commit message of the change when it is\\ncommitted.\\n\\nLICENSE\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met: \\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer. \\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution. \\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR\\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n\\nCONTRIBUTION AGREEMENT\\n\\nBy contributing to the BVLC/caffe repository through pull-request, comment,\\nor otherwise, the contributor releases their content to the\\nlicense and copyright terms herein.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "News",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ck-caffe",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "dividiti",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dividiti/ck-caffe/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "gfursin",
        "body": "Tagging stable version 2018.12.20",
        "dateCreated": "2018-12-19T16:15:47Z",
        "datePublished": "2018-12-20T21:18:11Z",
        "html_url": "https://github.com/dividiti/ck-caffe/releases/tag/20181220",
        "name": "Tagging stable version 2018.12.20",
        "tag_name": "20181220",
        "tarball_url": "https://api.github.com/repos/dividiti/ck-caffe/tarball/20181220",
        "url": "https://api.github.com/repos/dividiti/ck-caffe/releases/14648118",
        "zipball_url": "https://api.github.com/repos/dividiti/ck-caffe/zipball/20181220"
      },
      {
        "authorType": "User",
        "author_name": "gfursin",
        "body": "Tagging stable version 2017.04.29\r\n",
        "dateCreated": "2017-04-28T15:38:27Z",
        "datePublished": "2017-04-29T16:14:49Z",
        "html_url": "https://github.com/dividiti/ck-caffe/releases/tag/20170429",
        "name": "Tagging stable version 2017.04.29",
        "tag_name": "20170429",
        "tarball_url": "https://api.github.com/repos/dividiti/ck-caffe/tarball/20170429",
        "url": "https://api.github.com/repos/dividiti/ck-caffe/releases/6231946",
        "zipball_url": "https://api.github.com/repos/dividiti/ck-caffe/zipball/20170429"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n```\r\n$ sudo apt install coreutils \\\r\n                   build-essential \\\r\n                   make \\\r\n                   cmake \\\r\n                   wget \\\r\n                   git \\\r\n                   python \\\r\n                   python-pip\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\r\n$ sudo apt install libleveldb-dev \\\r\n                   libsnappy-dev \\\r\n                   gfortran\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "CK can automatically build the following dependencies from source using versions that should work well together. Installing via `apt`, however, is somewhat faster.\r\n\r\n```\r\n$ sudo apt install libboost-all-dev \\\r\n                   libgflags-dev \\\r\n                   libgoogle-glog-dev \\\r\n                   libhdf5-serial-dev \\\r\n                   liblmdb-dev \\\r\n                   libprotobuf-dev \\\r\n                   protobuf-compiler \\\r\n                   libopencv-dev\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nThe first time you run caffe benchmark (on Linux or Windows), \r\nCK will build and install all missing dependencies for your machine,\r\ndownload required data sets and will start benchmark:\r\n\r\n```\r\n$ ck run program:caffe\r\n```\r\n\r\nCK may ask you to select some detected software and packages to be used for installation (when multiple choices are available).\r\nIn such cases, we suggest you to either use a default value (just press Enter) or stable (recommended) versions.\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 195,
      "date": "Sun, 26 Dec 2021 21:21:29 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "collaborative-optimization",
      "reproducible-experiments",
      "customizable-workflows",
      "portable-package-manager",
      "caffe",
      "windows",
      "linux",
      "android",
      "json-api",
      "dnn-as-a-service",
      "opencl",
      "cuda",
      "collective-knowledge",
      "performance-portability",
      "accuracy",
      "resources",
      "costs",
      "dnn-optimization"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n* [Simple demo](http://cknowledge.org/repo/web.php?template=ck-ai-basic) to classify images with\r\ncontinuous optimization of DNN engines underneath, sharing of mispredictions and creation of a community training set;\r\nand to predict compiler optimizations based on program features.\r\n\r\n\r\n",
      "technique": "Header extraction"
    }
  ]
}
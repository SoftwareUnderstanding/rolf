{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1808.00897",
      "https://arxiv.org/abs/2004.02147"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8300861446546642
      ],
      "excerpt": "| bisenetv2 | 30.49 | 30.55 | 31.81 | 31.73 | download | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": "cuda 10.2 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CoinCheung/BiSeNet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-11-29T04:27:51Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-27T12:05:54Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9839480391484309
      ],
      "excerpt": "My implementation of BiSeNetV1 and BiSeNetV2. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9111482747081622
      ],
      "excerpt": "The fps is tested in different way from the paper. For more information, please see here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9238725920222055,
        0.9446460152662237
      ],
      "excerpt": "Triton Inference Server(TIS) provides a service solution of deployment. You can go to tis for details. \nMy platform is like this:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9023915794985526
      ],
      "excerpt": "2. I used overall batch size of 16 to train all models. Since cocostuff has 171 categories, it requires more memory to train models on it. I split the 16 images into more gpus than 2, as I do with cityscapes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Add bisenetv2.  My implementation of BiSeNet",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CoinCheung/BiSeNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 204,
      "date": "Tue, 28 Dec 2021 07:52:56 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/CoinCheung/BiSeNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "CoinCheung/BiSeNet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1.cityscapes  \n\nRegister and download the dataset from the official [website](https://www.cityscapes-dataset.com/). Then decompress them into the `datasets/cityscapes` directory:  \n```\n$ mv /path/to/leftImg8bit_trainvaltest.zip datasets/cityscapes\n$ mv /path/to/gtFine_trainvaltest.zip datasets/cityscapes\n$ cd datasets/cityscapes\n$ unzip leftImg8bit_trainvaltest.zip\n$ unzip gtFine_trainvaltest.zip\n```\n\n2.cocostuff   \n\nDownload `train2017.zip`, `val2017.zip` and `stuffthingmaps_trainval2017.zip` split from official [website](https://cocodataset.org/#download). Then do as following:\n```\n$ unzip train2017.zip\n$ unzip val2017.zip\n$ mv train2017/ /path/to/BiSeNet/datasets/coco/images\n$ mv val2017/ /path/to/BiSeNet/datasets/coco/images\n\n$ unzip stuffthingmaps_trainval2017.zip\n$ mv train2017/ /path/to/BiSeNet/datasets/coco/labels\n$ mv val2017/ /path/to/BiSeNet/datasets/coco/labels\n\n$ cd /path/to/BiSeNet\n$ python tools/gen_coco_annos.py\n```\n\n3.custom dataset  \n\nIf you want to train on your own dataset, you should generate annotation files first with the format like this: \n```\nmunster_000002_000019_leftImg8bit.png,munster_000002_000019_gtFine_labelIds.png\nfrankfurt_000001_079206_leftImg8bit.png,frankfurt_000001_079206_gtFine_labelIds.png\n...\n```\nEach line is a pair of training sample and ground truth image path, which are separated by a single comma `,`.   \nThen you need to change the field of `im_root` and `train/val_im_anns` in the configuration files. If you found what shows in `cityscapes_cv2.py` is not clear, you can also see `coco.py`.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8444817417684063
      ],
      "excerpt": "nvidia Tesla T4 gpu, driver 450.51.05 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9322609392449874,
        0.9195795312809855
      ],
      "excerpt": "pytorch 1.8.1 \nI used the following command to train the models: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9132908573381797,
        0.8026389465766129
      ],
      "excerpt": "| bisenetv1 | 75.44 | 76.94 | 77.45 | 78.86 | 68/23 | download | \n| bisenetv2 | 74.95 | 75.58 | 76.53 | 77.08 | 59/21 | download | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8455133804407949
      ],
      "excerpt": "$ python -m torch.distributed.launch --nproc_per_node=2 tools/train_amp.py --finetune-from ./res/model_final.pth --config ./configs/bisenetv2_city.py #: or bisenetv1 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/CoinCheung/BiSeNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C++",
      "Cuda",
      "CMake",
      "C"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 CoinCheung\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "BiSeNetV1 & BiSeNetV2",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "BiSeNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "CoinCheung",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CoinCheung/BiSeNet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "CoinCheung",
        "body": "It is a back up commit of the original implementation which is not so clear. After this release, the code will be refactored.",
        "dateCreated": "2020-07-10T03:40:30Z",
        "datePublished": "2020-08-06T02:21:15Z",
        "html_url": "https://github.com/CoinCheung/BiSeNet/releases/tag/0.0.0",
        "name": "original implementation",
        "tag_name": "0.0.0",
        "tarball_url": "https://api.github.com/repos/CoinCheung/BiSeNet/tarball/0.0.0",
        "url": "https://api.github.com/repos/CoinCheung/BiSeNet/releases/29390306",
        "zipball_url": "https://api.github.com/repos/CoinCheung/BiSeNet/zipball/0.0.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 854,
      "date": "Tue, 28 Dec 2021 07:52:56 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "bisenet",
      "cityscapes",
      "pytorch",
      "bisenetv2",
      "cocostuff",
      "tensorrt",
      "ncnn",
      "openvino",
      "triton-inference-server"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "With a pretrained weight, you can run inference on an single image like this: \n\n```\n$ python tools/demo.py --config configs/bisenetv2_city.py --weight-path /path/to/your/weights.pth --img-path ./example.png\n```\n\nThis would run inference on the image and save the result image to `./res.jpg`.  \n\nOr you can run inference on a video like this:  \n```\n$ python tools/demo_video.py --config configs/bisenetv2_coco.py --weight-path res/model_final.pth --input ./video.mp4 --output res.mp4\n```\nThis would generate segmentation file as `res.mp4`. If you want to read from camera, you can set `--input camera_id` rather than `input ./video.mp4`.   \n\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1610.09585\n\n#### Example\n```\n$ cd acgan/\n$ python3 acgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/acgan.gif\" width=\"640\"\\>\n</p>\n\n### Adversarial Autoencoder\nImplementation of _Adversarial Autoencoder_.\n\n[Code](aae/aae.py",
      "https://arxiv.org/abs/1511.05644\n\n#### Example\n```\n$ cd aae/\n$ python3 aae.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/aae.png\" width=\"640\"\\>\n</p>\n\n### BiGAN\nImplementation of _Bidirectional Generative Adversarial Network_.\n\n[Code](bigan/bigan.py",
      "https://arxiv.org/abs/1605.09782\n\n#### Example\n```\n$ cd bigan/\n$ python3 bigan.py\n```\n\n### BGAN\nImplementation of _Boundary-Seeking Generative Adversarial Networks_.\n\n[Code](bgan/bgan.py",
      "https://arxiv.org/abs/1702.08431\n\n#### Example\n```\n$ cd bgan/\n$ python3 bgan.py\n```\n\n### CC-GAN\nImplementation of _Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks_.\n\n[Code](ccgan/ccgan.py",
      "https://arxiv.org/abs/1611.06430\n\n#### Example\n```\n$ cd ccgan/\n$ python3 ccgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/ccgan.png\" width=\"640\"\\>\n</p>\n\n### CGAN\nImplementation of _Conditional Generative Adversarial Nets_.\n\n[Code](cgan/cgan.py",
      "https://arxiv.org/abs/1411.1784\n\n#### Example\n```\n$ cd cgan/\n$ python3 cgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/cgan.gif\" width=\"640\"\\>\n</p>\n\n### Context Encoder\nImplementation of _Context Encoders: Feature Learning by Inpainting_.\n\n[Code](context_encoder/context_encoder.py",
      "https://arxiv.org/abs/1604.07379\n\n#### Example\n```\n$ cd context_encoder/\n$ python3 context_encoder.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/context_encoder.png\" width=\"640\"\\>\n</p>\n\n### CoGAN\nImplementation of _Coupled generative adversarial networks_.\n\n[Code](cogan/cogan.py",
      "https://arxiv.org/abs/1606.07536\n\n#### Example\n```\n$ cd cogan/\n$ python3 cogan.py\n```\n\n### CycleGAN\nImplementation of _Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks_.\n\n[Code](cyclegan/cyclegan.py",
      "https://arxiv.org/abs/1703.10593\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/cyclegan.png\" width=\"640\"\\>\n</p>\n\n#### Example\n```\n$ cd cyclegan/\n$ bash download_dataset.sh apple2orange\n$ python3 cyclegan.py\n```   \n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/cyclegan_gif.gif\" width=\"640\"\\>\n</p>\n\n\n### DCGAN\nImplementation of _Deep Convolutional Generative Adversarial Network_.\n\n[Code](dcgan/dcgan.py",
      "https://arxiv.org/abs/1511.06434\n\n#### Example\n```\n$ cd dcgan/\n$ python3 dcgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/dcgan2.png\" width=\"640\"\\>\n</p>\n\n### DiscoGAN\nImplementation of _Learning to Discover Cross-Domain Relations with Generative Adversarial Networks_.\n\n[Code](discogan/discogan.py",
      "https://arxiv.org/abs/1703.05192\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/discogan_architecture.png\" width=\"640\"\\>\n</p>\n\n#### Example\n```\n$ cd discogan/\n$ bash download_dataset.sh edges2shoes\n$ python3 discogan.py\n```   \n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/discogan.png\" width=\"640\"\\>\n</p>\n\n### DualGAN\nImplementation of _DualGAN: Unsupervised Dual Learning for Image-to-Image Translation_.\n\n[Code](dualgan/dualgan.py",
      "https://arxiv.org/abs/1704.02510\n\n#### Example\n```\n$ cd dualgan/\n$ python3 dualgan.py\n```\n\n### GAN\nImplementation of _Generative Adversarial Network_ with a MLP generator and discriminator.\n\n[Code](gan/gan.py",
      "https://arxiv.org/abs/1406.2661\n\n#### Example\n```\n$ cd gan/\n$ python3 gan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/gan_mnist5.gif\" width=\"640\"\\>\n</p>\n\n### InfoGAN\nImplementation of _InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets_.\n\n[Code](infogan/infogan.py",
      "https://arxiv.org/abs/1606.03657\n\n#### Example\n```\n$ cd infogan/\n$ python3 infogan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/infogan.png\" width=\"640\"\\>\n</p>\n\n### LSGAN\nImplementation of _Least Squares Generative Adversarial Networks_.\n\n[Code](lsgan/lsgan.py",
      "https://arxiv.org/abs/1611.04076\n\n#### Example\n```\n$ cd lsgan/\n$ python3 lsgan.py\n```\n\n### Pix2Pix\nImplementation of _Image-to-Image Translation with Conditional Adversarial Networks_.\n\n[Code](pix2pix/pix2pix.py",
      "https://arxiv.org/abs/1611.07004\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/pix2pix_architecture.png\" width=\"640\"\\>\n</p>\n\n#### Example\n```\n$ cd pix2pix/\n$ bash download_dataset.sh facades\n$ python3 pix2pix.py\n```   \n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/pix2pix2.png\" width=\"640\"\\>\n</p>\n\n### PixelDA\nImplementation of _Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks_.\n\n[Code](pixelda/pixelda.py",
      "https://arxiv.org/abs/1612.05424\n\n#### MNIST to MNIST-M Classification\nTrains a classifier on MNIST images that are translated to resemble MNIST-M (by performing unsupervised image-to-image domain adaptation",
      "https://arxiv.org/abs/1606.01583\n\n#### Example\n```\n$ cd sgan/\n$ python3 sgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/sgan.png\" width=\"640\"\\>\n</p>\n\n### SRGAN\nImplementation of _Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network_.\n\n[Code](srgan/srgan.py",
      "https://arxiv.org/abs/1609.04802\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/superresgan.png\" width=\"640\"\\>\n</p>\n\n\n#### Example\n```\n$ cd srgan/\n<follow steps at the top of srgan.py>\n$ python3 srgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/srgan.png\" width=\"640\"\\>\n</p>\n\n### WGAN\nImplementation of _Wasserstein GAN_ (with DCGAN generator and discriminator",
      "https://arxiv.org/abs/1701.07875\n\n#### Example\n```\n$ cd wgan/\n$ python3 wgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/wgan2.png\" width=\"640\"\\>\n</p>\n\n### WGAN GP\nImplementation of _Improved Training of Wasserstein GANs_.\n\n[Code](wgan_gp/wgan_gp.py",
      "https://arxiv.org/abs/1704.00028\n\n#### Example\n```\n$ cd wgan_gp/\n$ python3 wgan_gp.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/imp_wgan.gif\" width=\"640\"\\>\n</p>"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "Coupled GANs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1610.09585 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1511.05644 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1605.09782 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1702.08431 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9991295298092048
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1611.06430 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1604.07379 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1606.07536 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1703.10593 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1511.06434 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1703.05192 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1704.02510 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1406.2661 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1606.03657 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9991295298092048
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1611.04076 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9991295298092048
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1611.07004 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1612.05424 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1606.01583 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1609.04802 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1701.07875 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/eriklindernoren/Keras-GAN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-07-11T16:24:53Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T12:45:25Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.997630179801632,
        0.9090926186802062
      ],
      "excerpt": "Collection of Keras implementations of Generative Adversarial Networks (GANs) suggested in research papers. These models are in some cases simplified versions of the ones ultimately described in the papers, but I have chosen to focus on getting the core ideas covered instead of getting every layer configuration right. Contributions and suggestions of GAN varieties to implement are very welcomed. \n<b>See also:</b> PyTorch-GAN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8354361383374207
      ],
      "excerpt": "Implementation of Auxiliary Classifier Generative Adversarial Network. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.881406792706452
      ],
      "excerpt": "Implementation of Adversarial Autoencoder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8354361383374207
      ],
      "excerpt": "Implementation of Bidirectional Generative Adversarial Network. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8510917039116684
      ],
      "excerpt": "Implementation of Boundary-Seeking Generative Adversarial Networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8751773074470844
      ],
      "excerpt": "Implementation of Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8400811089746979
      ],
      "excerpt": "Implementation of Conditional Generative Adversarial Nets. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.865205262360538
      ],
      "excerpt": "Implementation of Context Encoders: Feature Learning by Inpainting. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8404221931259723
      ],
      "excerpt": "Implementation of Coupled generative adversarial networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9386110117500871
      ],
      "excerpt": "Implementation of Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8598058348239862
      ],
      "excerpt": "Implementation of Deep Convolutional Generative Adversarial Network. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9490045236237189
      ],
      "excerpt": "Implementation of Learning to Discover Cross-Domain Relations with Generative Adversarial Networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9674183975060652
      ],
      "excerpt": "Implementation of DualGAN: Unsupervised Dual Learning for Image-to-Image Translation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9281984692190789
      ],
      "excerpt": "Implementation of Generative Adversarial Network with a MLP generator and discriminator. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8424123088513166
      ],
      "excerpt": "Implementation of InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9546049875052692
      ],
      "excerpt": "Implementation of Image-to-Image Translation with Conditional Adversarial Networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8893200065354973
      ],
      "excerpt": "Implementation of Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9688371870178369
      ],
      "excerpt": "Trains a classifier on MNIST images that are translated to resemble MNIST-M (by performing unsupervised image-to-image domain adaptation). This model is compared to the naive solution of training a classifier on MNIST and evaluating it on MNIST-M. The naive model manages a 55% classification accuracy on MNIST-M while the one trained during domain adaptation gets a 95% classification accuracy. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8706509343667636
      ],
      "excerpt": "Implementation of Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9668537005277252
      ],
      "excerpt": "Implementation of Wasserstein GAN (with DCGAN generator and discriminator). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9414505291884958
      ],
      "excerpt": "Implementation of Improved Training of Wasserstein GANs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Keras implementations of Generative Adversarial Networks.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/eriklindernoren/Keras-GAN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3038,
      "date": "Thu, 23 Dec 2021 04:35:52 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/eriklindernoren/Keras-GAN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "eriklindernoren/Keras-GAN",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/eriklindernoren/Keras-GAN/master/discogan/download_dataset.sh",
      "https://raw.githubusercontent.com/eriklindernoren/Keras-GAN/master/cyclegan/download_dataset.sh",
      "https://raw.githubusercontent.com/eriklindernoren/Keras-GAN/master/pix2pix/download_dataset.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    $ git clone https://github.com/eriklindernoren/Keras-GAN\n    $ cd Keras-GAN/\n    $ sudo pip3 install -r requirements.txt\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8961408080037506
      ],
      "excerpt": "<b>See also:</b> PyTorch-GAN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "$ cd pixelda/ \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.899814315839885
      ],
      "excerpt": "    <img src=\"http://eriklindernoren.se/images/cyclegan.png\" width=\"640\"\\> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.899814315839885
      ],
      "excerpt": "    <img src=\"http://eriklindernoren.se/images/discogan_architecture.png\" width=\"640\"\\> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.899814315839885
      ],
      "excerpt": "    <img src=\"http://eriklindernoren.se/images/pix2pix_architecture.png\" width=\"640\"\\> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "$ python3 pixelda.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.899814315839885
      ],
      "excerpt": "    <img src=\"http://eriklindernoren.se/images/superresgan.png\" width=\"640\"\\> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/eriklindernoren/Keras-GAN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2017 Erik Linder-Nor\\xc3\\xa9n\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Keras-GAN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Keras-GAN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "eriklindernoren",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/eriklindernoren/Keras-GAN/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8499,
      "date": "Thu, 23 Dec 2021 04:35:52 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "gan",
      "keras",
      "generative-adversarial-networks",
      "neural-networks"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd acgan/\n$ python3 acgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/acgan.gif\" width=\"640\"\\>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd aae/\n$ python3 aae.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/aae.png\" width=\"640\"\\>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd bigan/\n$ python3 bigan.py\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd bgan/\n$ python3 bgan.py\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd ccgan/\n$ python3 ccgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/ccgan.png\" width=\"640\"\\>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd cgan/\n$ python3 cgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/cgan.gif\" width=\"640\"\\>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd context_encoder/\n$ python3 context_encoder.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/context_encoder.png\" width=\"640\"\\>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd cogan/\n$ python3 cogan.py\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd cyclegan/\n$ bash download_dataset.sh apple2orange\n$ python3 cyclegan.py\n```   \n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/cyclegan_gif.gif\" width=\"640\"\\>\n</p>\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd dcgan/\n$ python3 dcgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/dcgan2.png\" width=\"640\"\\>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd discogan/\n$ bash download_dataset.sh edges2shoes\n$ python3 discogan.py\n```   \n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/discogan.png\" width=\"640\"\\>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd dualgan/\n$ python3 dualgan.py\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd gan/\n$ python3 gan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/gan_mnist5.gif\" width=\"640\"\\>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd infogan/\n$ python3 infogan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/infogan.png\" width=\"640\"\\>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd lsgan/\n$ python3 lsgan.py\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd pix2pix/\n$ bash download_dataset.sh facades\n$ python3 pix2pix.py\n```   \n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/pix2pix2.png\" width=\"640\"\\>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd sgan/\n$ python3 sgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/sgan.png\" width=\"640\"\\>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd srgan/\n<follow steps at the top of srgan.py>\n$ python3 srgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/srgan.png\" width=\"640\"\\>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd wgan/\n$ python3 wgan.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/wgan2.png\" width=\"640\"\\>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd wgan_gp/\n$ python3 wgan_gp.py\n```\n\n<p align=\"center\">\n    <img src=\"http://eriklindernoren.se/images/imp_wgan.gif\" width=\"640\"\\>\n</p>\n",
      "technique": "Header extraction"
    }
  ]
}
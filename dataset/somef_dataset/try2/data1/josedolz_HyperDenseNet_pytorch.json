{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1804.02967"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/josedolz/HyperDenseNet_pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-11-20T03:53:12Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-20T14:13:45Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.98386425715499,
        0.9852406665468408
      ],
      "excerpt": "This is a Pytorch implementation of Hyperdensenet. For the detailed architecture please refer to the original paper: link \nThis is not the original implementation of the paper (Do not use it to reproduce the results). The original code is based on Theano and can be found here \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9406158341506079,
        0.9139549444594673
      ],
      "excerpt": "where n is the number of modalities. \nPatch size, and sampling steps values are hard-coded. We will work on a generalization of this, allowing the user to decide the input patch size and the frequency to sample the patches. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9739372105657262
      ],
      "excerpt": "In the original paper we used a ROI to mask out the background. This will help during sampling patches for training, as well as remove outliers on the testing images, since the receptive field of this network is small. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Pytorch version of the HyperDenseNet deep neural network for multi-modal image segmentation",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/josedolz/HyperDenseNet_pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 10,
      "date": "Tue, 21 Dec 2021 14:41:21 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/josedolz/HyperDenseNet_pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "josedolz/HyperDenseNet_pytorch",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- To use your own data, you will have to specify the path to the folder containing this data (--root_dir).\n- Images have to be in nifti (.nii) format\n- You have to split your data into two folders: Training/Validation. Each folder will contain N sub-folders: N-1 subfolders that will contain each modality and GT, which contain the nifti files for the images and their corresponding ground truths. Then, for training, you only need to specify which subfolders you want to use in the command line. For example:\n```\n--modality_dirs T1 T2_FLAIR\n```\n- Image names should be the same across folders (e.g., )\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8397199892087907
      ],
      "excerpt": "The current version includes HyperDenseNet for 2 and 3 modalities. To run either one or the other, you simply need to specify the number of modalities on the input arg numModal \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python mainHyperDenseNet.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/josedolz/HyperDenseNet_pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Hyperdensenet_Pytorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "HyperDenseNet_pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "josedolz",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/josedolz/HyperDenseNet_pytorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This code depends on the following libraries:\n\n- Python >= 3.5\n- Pytorch 0.3.1 (Testing on more recent versions)\n- nibabel\n- medpy\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 54,
      "date": "Tue, 21 Dec 2021 14:41:21 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "hyperdensenet",
      "deep-learning",
      "3d-convolutional-network",
      "3d-cnn",
      "medical-image-processing",
      "medical-image-segmentation",
      "multi-modal-imaging",
      "multi-modal-learning",
      "segmentation",
      "image-segmentation",
      "pytorch",
      "pytorch-cnn"
    ],
    "technique": "GitHub API"
  }
}
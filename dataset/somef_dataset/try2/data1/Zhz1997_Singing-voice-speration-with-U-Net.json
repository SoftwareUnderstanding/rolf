{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<sup>1</sup> [Singing Voice Separation With Deep U-NET Convolutiinal Networks](https://openaccess.city.ac.uk/id/eprint/19289/1/7bb8d1600fba70dd79408775cd0c37a4ff62.pdf)  \n<sup>2</sup> [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf)  \n<sup>3</sup> [MICCAI BraTS 2017: Scope | Section for Biomedical Image Analysis (SBIA)](https://www.med.upenn.edu/sbia/brats2017.html)  \n\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Zhz1997/Singing-voice-speration-with-U-Net",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-10-13T21:28:31Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-04T13:09:02Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.994670011664527,
        0.827636547594347,
        0.8095050187469054,
        0.8291738205751867
      ],
      "excerpt": "The purpose of this project is to decompose a music audio signal into its vocal and backing track components. Once decomposed, clean vocal or backing signals are useful for other MIR tasks such as singer identification, lyric transcription, and karaoke application [1]. While there are traditional methods for doing source separation of musical audio, deep learning models have emerged as powerful alternatives. In [1], the authors propose a method for decomposing music audio signals into a backing track using modified convolutional neural networks called U-Net [2]. While U-Net was developed for biomedical imaging [2,3], this architecture can be used in the context of singing voice separation. The results of experimentation in [1] shows that U-Net achieves better performance than the other state-of-the-art deep learning technique. We find this paper [1] would be interesting to prove, especially from a video in [4], where the presenter uses U-Net to show how clean this technique does voice separation. \nis a U-shape Convolutional Neural Networks designed for Biomedical Image Segmentation \n(in the context of MIR) allows recreating low-level detail for high quality audio reproduction \nis a type of fully convolutional network (FCN), which has only convolutional layers (i.e. layers are not fully connected). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8303067579976495,
        0.9146490537363318,
        0.8286865105732598
      ],
      "excerpt": "<b>Encoder</b> that learns highly abstract representation of the input image. \n<b>Decoder</b> takes encoder's input and maps it into segmented groundtruth data (e.g. by transposing convolutions and unpooling). \nis a set of convolutional layers that reduce the inputs dimensionality while preserving prevalent information \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9396181711380777
      ],
      "excerpt": "5x5 convolutions (filters) with stride = 2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8563322958625974
      ],
      "excerpt": "each downsampling (maxpooling) step doubles the number of features map \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.855319812546338
      ],
      "excerpt": "is symmetric to the Encoder (i.e. has the same number of filters, sizes, strides, and output dimensions) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8347887510704014
      ],
      "excerpt": "128 size for Mini-batch training, with ADAM optimizer \n",
      "technique": "Supervised classification"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://numba.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Zhz1997/Singing-voice-speration-with-U-Net/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Tue, 28 Dec 2021 09:16:02 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Zhz1997/Singing-voice-speration-with-U-Net/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Zhz1997/Singing-voice-speration-with-U-Net",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Zhz1997/Singing-voice-speration-with-U-Net/main/src/Process_MedleyDB.ipynb",
      "https://raw.githubusercontent.com/Zhz1997/Singing-voice-speration-with-U-Net/main/src/Process_DSD100.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8932838360260839
      ],
      "excerpt": "Speedy compiler for jupyter: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.811754126496847
      ],
      "excerpt": "128 size for Mini-batch training, with ADAM optimizer \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Zhz1997/Singing-voice-speration-with-U-Net/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Singing-voice-speration-with-U-Net",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Singing-voice-speration-with-U-Net",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Zhz1997",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Zhz1997/Singing-voice-speration-with-U-Net/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Tue, 28 Dec 2021 09:16:02 GMT"
    },
    "technique": "GitHub API"
  }
}
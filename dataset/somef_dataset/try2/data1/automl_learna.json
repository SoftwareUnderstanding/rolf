{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1707.06347"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To cite our work, please reference our ICLR 2019 paper\n```\n@inproceedings{\nrunge2018learning,\ntitle={Learning to Design {RNA}},\nauthor={Frederic Runge and Danny Stoll and Stefan Falkner and Frank Hutter},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ByfyHh05tQ},\n}\n```\n---\n\n&nbsp;  \n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{\nrunge2018learning,\ntitle={Learning to Design {RNA}},\nauthor={Frederic Runge and Danny Stoll and Stefan Falkner and Frank Hutter},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=ByfyHh05tQ},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9999639951215599
      ],
      "excerpt": "In Proceedings of the International Conference on Learning Representations (ICLR 2019), 2019. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/automl/learna",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-12-08T11:44:05Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-24T14:03:28Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9839537574574926,
        0.8722480348284171
      ],
      "excerpt": "In this repository we provide the code accompanying our publication \nLearning to Design RNA \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.979168621683914,
        0.9804645288650122,
        0.9159856796451427,
        0.9146168397078724,
        0.996452975893042
      ],
      "excerpt": "Figure 1: Illustration of an action rollout. The agent sequentially builds a candidate solution by choosing actions to place nucleotides. At paired sites, as indicated by a pair of brackets, two nucleotides are placed simultaneously (t = 0 and t = 1); while at unpaired sites a single nucleotide is placed. \nIn our algorithm, we employ deep reinforcement learning to yield agents, capable of designing RNA sequences that satisfy given structural constraints in an end-to-end fashion. In particular, we provide source code to run: \nA ready to use deep reinforcement learning implementation for RNA Design. Utilizing PPO [Schulman et al., 2017], the agent learns a policy for solving individual RNA Design problems in an end-to-end fashion from scratch. \nA meta-learning approach for RNA Design utilizing a single policy, pre-trained across thousands of different RNA design tasks, capable of solving new RNA Design tasks by transfering the learned knowledge. \nA deep reinforcement learning approach combining the strategies of LEARNA and Meta-LEARNA by warmstarting LEARNA using the policy of Meta-LEARNA for initialization of the weights and continuing learning the policy on new RNA Design problems. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8257194645276672
      ],
      "excerpt": "to run LEARNA on a single secondary structure of the Eterna100 dataset for 30 seconds. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9737626360064835
      ],
      "excerpt": "To see a list of all make targets with short explanation, type \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9830306390034743
      ],
      "excerpt": "To limit computational costs we provide commands to reproduce our results for single target structures of any of the benchmarks instead of providing a pipeline directly involving entire datasets. The following commands will run one of the finally selected configurations on a single target structure \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9150684151484718
      ],
      "excerpt": "&lt;id&gt; corresponds to one of the target structures as reported in our publication. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.986711935676777
      ],
      "excerpt": "To have a standardized timing for all algorithms without using internal timeouts, we decided to limit the runtime using pynisher. We provide our script for timed execution and our execution scripts for running our approaches. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.850955253724012
      ],
      "excerpt": "* timeout: The timeout needs to be set in seconds \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8788028608445407
      ],
      "excerpt": "* method: One of LEARNA-10min, LEARNA-30min, Meta-LEARNA \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9272101938589445
      ],
      "excerpt": "* task_id: An id of any target structure of the corresponding dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9191955571156835,
        0.9087166728210964
      ],
      "excerpt": "We used the recently proposed optimizer BOHB [Falkner et al., 2018] to jointly optimize the architecture of our policy networks, the training hyperparameters as well as the state representation. \nFor completeness, we also provide our implementation of workers for BOHB, as well as the main file bohb.py in the src/optimization directory to start BOHB optimizing our approach. A very basic example call of the BOHB pipeline can be run via \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "End-to-end RNA Design using deep reinforcement learning",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/automl/learna/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 13,
      "date": "Sat, 25 Dec 2021 02:06:53 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/automl/learna/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "automl/learna",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/automl/learna/master/utils/execution_scripts/LEARNA-30min.sh",
      "https://raw.githubusercontent.com/automl/learna/master/utils/execution_scripts/LEARNA.sh",
      "https://raw.githubusercontent.com/automl/learna/master/utils/execution_scripts/Meta-LEARNA-Adapt.sh",
      "https://raw.githubusercontent.com/automl/learna/master/utils/execution_scripts/Meta-LEARNA.sh",
      "https://raw.githubusercontent.com/automl/learna/master/utils/execution_scripts/LEARNA-10min.sh",
      "https://raw.githubusercontent.com/automl/learna/master/src/data/download_and_build_rfam_learn.sh",
      "https://raw.githubusercontent.com/automl/learna/master/src/data/secondaries_to_single_files.sh",
      "https://raw.githubusercontent.com/automl/learna/master/src/data/download_and_build_rfam_taneda.sh",
      "https://raw.githubusercontent.com/automl/learna/master/thirdparty/miniconda/make_miniconda.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "&nbsp;   \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "&nbsp;   \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8708246862209853
      ],
      "excerpt": "Additionally, individual datasets can be downloaded and build via the following commands \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8561458347139219
      ],
      "excerpt": "For testing your installation type \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9457589451821369
      ],
      "excerpt": "All installed components, including the conda environment, can be removed via \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9292582965040392
      ],
      "excerpt": "All execution_scripts can be run locally using the timed_execution script. To do so run the following command after activation of the learna environment from the project's root directory \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8496391784928509,
        0.9172573463647683
      ],
      "excerpt": "* results_dir: Any output directory of your choice \n* experiment_group: Any name you would like to provide (defines the name of the output directory inside results_dir \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8368619670185665
      ],
      "excerpt": "This will download all files and save them into the data/ directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9585936350650127
      ],
      "excerpt": "python utils/timed_execution.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8460475968847524
      ],
      "excerpt": "* dataset: One of eterna, rfam_taneda, rfam_learn/test \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/automl/learna/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "TeX",
      "Makefile",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/automl/learna/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright 2018 Danny Stoll and Frederic Runge\\n\\nLicensed under the Apache License, Version 2.0 (the \"License\");\\nyou may not use this file except in compliance with the License.\\nYou may obtain a copy of the License at\\n\\n    http://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing, software\\ndistributed under the License is distributed on an \"AS IS\" BASIS,\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\nSee the License for the specific language governing permissions and\\nlimitations under the License.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "**Learning to Design RNA**",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "learna",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "automl",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/automl/learna/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "&nbsp;   \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "The following software is required to run our code:\n* Python version 3.6 or higher\n* ViennaRNA (recommended version: 2.4.8)\n* numpy\n* pandas version 0.22\n* requests\n* pytest (for running tests only)\n* tensorflow version 1.4.0\n* pynisher\n* hpbandster\n* tqdm\n* Distance\n* tensorforce version 0.3.3\n* dataclasses\n\nTo install all requirements automatically, including the setup of a conda environment called `learna` via miniconda, simply type the following command:\n\n```\nmake requirements\n```\n\nWe tested the installation on the following operating systems:\n* CentOS Linux release 7.4.1708\n* Korora release 26\n* Ubuntu 16.04.5 LTS\n\n&nbsp;  \n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "&nbsp;   \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "&nbsp;   \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "&nbsp;  \n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 44,
      "date": "Sat, 25 Dec 2021 02:06:53 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "&nbsp;   \n\n",
      "technique": "Header extraction"
    }
  ]
}
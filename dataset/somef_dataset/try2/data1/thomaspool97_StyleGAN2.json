{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We thank Ming-Yu Liu for an early review, Timo Viitanen for his help with code release, and Tero Kuosmanen for compute infrastructure.\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1706.08500",
      "https://arxiv.org/abs/1606.03498",
      "https://arxiv.org/abs/1812.04948",
      "https://arxiv.org/abs/1812.04948",
      "https://arxiv.org/abs/1812.04948",
      "https://arxiv.org/abs/1812.04948",
      "https://arxiv.org/abs/1812.04948",
      "https://arxiv.org/abs/1812.04948",
      "https://arxiv.org/abs/1904.06991"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@inproceedings{Karras2019stylegan2,\n  title     = {Analyzing and Improving the Image Quality of {StyleGAN}},\n  author    = {Tero Karras and Samuli Laine and Miika Aittala and Janne Hellsten and Jaakko Lehtinen and Timo Aila},\n  booktitle = {Proc. CVPR},\n  year      = {2020}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{Karras2019stylegan2,\n  title     = {Analyzing and Improving the Image Quality of {StyleGAN}},\n  author    = {Tero Karras and Samuli Laine and Miika Aittala and Janne Hellsten and Jaakko Lehtinen and Timo Aila},\n  booktitle = {Proc. CVPR},\n  year      = {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9941533744942845
      ],
      "excerpt": "Paper: http://arxiv.org/abs/1912.04958<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8334710283794773,
        0.8753150968738145
      ],
      "excerpt": "For business inquiries, please contact researchinquiries@nvidia.com<br> \nFor press and other inquiries, please contact Hector Marinez at hmarinez@nvidia.com<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8956259629933797
      ],
      "excerpt": "| &boxvr;&nbsp; stylegan2-video.mp4 | High-quality version of the video \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8422862053358879
      ],
      "excerpt": "| pr50k3    | 0.689 / 0.492  | 26 min | 17 min  | 12 min | Precision and Recall \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/thomaspool97/StyleGAN2",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-14T01:21:19Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-14T01:30:15Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8967568239890629,
        0.9104210937760416
      ],
      "excerpt": "The NVLabs sources are unchanged from the original, except for this README paragraph, and the addition of the workflow yaml file. \nOnce you create your own copy of this repo and add the repo to a project in your Paperspace Gradient account, you will be able to commit changes, and have the changes automatically validated by running a Gradient workflow using your updates. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8502828471671428
      ],
      "excerpt": "1. Create a Paperspace account with a Gradient subscription that supports GPU machine access, and Gradient github integration. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8861301986251685,
        0.937530315380266
      ],
      "excerpt": "3. Create your own copy of this repo using the \"Use this template\" button in Github. \n4. Create a github connected project by opening the Projects tab, pressing the \"LINK A GITHUB REPO\" button, and following the instructions on the next page. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9249131382579012,
        0.8981128305827252,
        0.9855698271540411,
        0.8776040464351501
      ],
      "excerpt": "6. Once github permissions are set up for Gradient, return to the Gradient project page and select the repo you created in step 3. \n7. At this point Gradient will check that the Gradient github app is associated with the repo.  If it is not, you will need to return to github and add the Gradient app to the repo. \n8. After adding the Gradient app to the repo return to the projects tab again and complete the process of associating the repo with a project. \n9. Now make a small change to the repo such as adding a blank line to the end of this README, then add, commit, and push your changes to your repo. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8802695721951891
      ],
      "excerpt": "Analyzing and Improving the Image Quality of StyleGAN<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9835764315336535
      ],
      "excerpt": "Abstract: The style-based GAN architecture (StyleGAN) yields state-of-the-art results in data-driven unconditional generative image modeling. We expose and analyze several of its characteristic artifacts, and propose changes in both model architecture and training methods to address them. In particular, we redesign generator normalization, revisit progressive growing, and regularize the generator to encourage good conditioning in the mapping from latent vectors to images. In addition to improving image quality, this path length regularizer yields the additional benefit that the generator becomes significantly easier to invert. This makes it possible to reliably detect if an image is generated by a particular network. We furthermore visualize how well the generator utilizes its output resolution, and identify a capacity problem, motivating us to train larger models for additional quality improvements. Overall, our improved model redefines the state of the art in unconditional image modeling, both in terms of existing distribution quality metrics as well as perceived image quality. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693269136233396
      ],
      "excerpt": "&#9733;&#9733;&#9733; NEW: StyleGAN2-ADA-PyTorch is now available; see the full list of versions here &#9733;&#9733;&#9733; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8051988754586414
      ],
      "excerpt": "| &boxvr;&nbsp; stylegan2-paper.pdf | High-quality version of the paper \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8885141820379509
      ],
      "excerpt": "We have verified that the results match the paper when training with 1, 2, 4, or 8 GPUs. Note that training FFHQ at 1024&times;1024 resolution requires GPU(s) with at least 16 GB of memory. The following table lists typical training times using NVIDIA DGX-1 with 8 Tesla V100 GPUs: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8950816142632219,
        0.8826059627549617
      ],
      "excerpt": "For other configurations, see the StyleGAN2 Google Drive folder. \nNote that the metrics are evaluated using a different random seed each time, so the results will vary between runs. In the paper, we reported the average result of running each metric 10 times. The following table lists the available metrics along with their expected runtimes and random variation: \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/thomaspool97/StyleGAN2/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 22 Dec 2021 00:21:13 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/thomaspool97/StyleGAN2/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "thomaspool97/StyleGAN2",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/thomaspool97/StyleGAN2/main/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/thomaspool97/StyleGAN2/tree/main/docs"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Datasets are stored as multi-resolution TFRecords, similar to the [original StyleGAN](https://github.com/NVlabs/stylegan). Each dataset consists of multiple `*.tfrecords` files stored under a common directory, e.g., `~/datasets/ffhq/ffhq-r*.tfrecords`. In the following sections, the datasets are referenced using a combination of `--dataset` and `--data-dir` arguments, e.g., `--dataset=ffhq --data-dir=~/datasets`.\n\n**FFHQ**. To download the [Flickr-Faces-HQ](https://github.com/NVlabs/ffhq-dataset) dataset as multi-resolution TFRecords, run:\n\n```.bash\npushd ~\ngit clone https://github.com/NVlabs/ffhq-dataset.git\ncd ffhq-dataset\npython download_ffhq.py --tfrecords\npopd\npython dataset_tool.py display ~/ffhq-dataset/tfrecords/ffhq\n```\n\n**LSUN**. Download the desired LSUN categories in LMDB format from the [LSUN project page](https://www.yf.io/p/lsun). To convert the data to multi-resolution TFRecords, run:\n\n```.bash\npython dataset_tool.py create_lsun_wide ~/datasets/car ~/lsun/car_lmdb --width=512 --height=384\npython dataset_tool.py create_lsun ~/datasets/cat ~/lsun/cat_lmdb --resolution=256\npython dataset_tool.py create_lsun ~/datasets/church ~/lsun/church_outdoor_train_lmdb --resolution=256\npython dataset_tool.py create_lsun ~/datasets/horse ~/lsun/horse_lmdb --resolution=256\n```\n\n**Custom**. Create custom datasets by placing all training images under a single directory. The images must be square-shaped and they must all have the same power-of-two dimensions. To convert the images to multi-resolution TFRecords, run:\n\n```.bash\npython dataset_tool.py create_from_images ~/datasets/my-custom-dataset ~/my-custom-images\npython dataset_tool.py display ~/datasets/my-custom-dataset\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8117958379731653
      ],
      "excerpt": "This is a Github template repo you can use to create your own copy of the forked StyleGAN2 sample from NVLabs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8371537695304268
      ],
      "excerpt": "There are a few prerequisites you will need to have in place: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8066457388498403,
        0.8210180743166731
      ],
      "excerpt": "4. Create a github connected project by opening the Projects tab, pressing the \"LINK A GITHUB REPO\" button, and following the instructions on the next page. \n5. You next need to authorize Gradient to access your github account if you have not done so already. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8114488624004937
      ],
      "excerpt": "| StyleGAN2 | Main Google Drive folder \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8027133024627905
      ],
      "excerpt": ": Generate uncurated car images \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8344311767521461
      ],
      "excerpt": "  --dataset=car --data-dir=~/datasets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9054017614873153,
        0.8782615320428928,
        0.9054017614873153,
        0.8761283009744154,
        0.9054017614873153,
        0.8761283009744154,
        0.9054017614873153,
        0.896198593558758,
        0.9054017614873153,
        0.896198593558758
      ],
      "excerpt": "python run_training.py --num-gpus=8 --data-dir=~/datasets --config=config-f \\ \n  --dataset=ffhq --mirror-augment=true \npython run_training.py --num-gpus=8 --data-dir=~/datasets --config=config-f \\ \n  --dataset=car --total-kimg=57000 \npython run_training.py --num-gpus=8 --data-dir=~/datasets --config=config-f \\ \n  --dataset=cat --total-kimg=88000 \npython run_training.py --num-gpus=8 --data-dir=~/datasets --config=config-f \\ \n  --dataset=church --total-kimg 88000 --gamma=100 \npython run_training.py --num-gpus=8 --data-dir=~/datasets --config=config-f \\ \n  --dataset=horse --total-kimg 100000 --gamma=100 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9226509042444692
      ],
      "excerpt": "python run_generator.py generate-images --seeds=0-999 --truncation-psi=1.0 \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/thomaspool97/StyleGAN2/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cuda",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Gradient StyleGAN2 Template Repo",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "StyleGAN2",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "thomaspool97",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/thomaspool97/StyleGAN2/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Both Linux and Windows are supported. Linux is recommended for performance and compatibility reasons.\n* 64-bit Python 3.6 installation. We recommend Anaconda3 with numpy 1.14.3 or newer.\n* We recommend TensorFlow 1.14, which we used for all experiments in the paper, but TensorFlow 1.15 is also supported on Linux. TensorFlow 2.x is not supported.\n* On Windows you need to use TensorFlow 1.14, as the standard 1.15 installation does not include necessary C++ headers.\n* One or more high-end NVIDIA GPUs, NVIDIA drivers, CUDA 10.0 toolkit and cuDNN 7.5. To reproduce the results reported in the paper, you need an NVIDIA GPU with at least 16 GB of DRAM.\n* Docker users: use the [provided Dockerfile](./Dockerfile) to build an image with the required library dependencies.\n\nStyleGAN2 relies on custom TensorFlow ops that are compiled on the fly using [NVCC](https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html). To test that your NVCC installation is working correctly, run:\n\n```.bash\nnvcc test_nvcc.cu -o test_nvcc -run\n| CPU says hello.\n| GPU says hello.\n```\n\nOn Windows, the compilation requires Microsoft Visual Studio to be in `PATH`. We recommend installing [Visual Studio Community Edition](https://visualstudio.microsoft.com/vs/) and adding into `PATH` using `\"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\\vcvars64.bat\"`.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 22 Dec 2021 00:21:13 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\\[1\\] Attentional networks for music generation, [arXiv](https://arxiv.org/pdf/2002.03854)\n\n\\[2\\] MuseGAN: Multi-track Sequential Generative Adversarial Networks for Symbolic Music Generation and Accompaniment, [arXiv](https://arxiv.org/pdf/1709.06298.pdf)\n\n\\[3\\] Jukebox: A Generative Model for Music, [arXiv](https://arxiv.org/pdf/2005.00341.pdf)\n\n\\[4\\] Neural Discrete Representation Learning, [arXiv](https://arxiv.org/pdf/1711.00937.pdf)\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/safakkbilici/Synthetic-Music-Generation-with-Deep-Neural-Networks",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-10T10:20:03Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T14:08:51Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9925807854088213,
        0.9475742756769187,
        0.9871018978010438,
        0.9827371907169776,
        0.829563226249133
      ],
      "excerpt": "Music is an art of time. It is formed by the colaboration of instruments -composed with many instruments collectively- harmonization of notes. So, music generation with deep neural networks strictly connected with this features of music. There are many models have been proposed so far for generating music. Some of them based on the structure of Recurrent Neural Networks or Generative Adversarial Networks or Variational Autoencoders. \nIn this work, we tackle the generating music with deep neural networks, especially with Vector Quantized Variational Autoencoders (Oord et al., 2017). \nJukeBox is a generative model for music with singing that is based on Vector Quantized Variational Autoencoders. The models uses raw audio (.wav) for training data. We implemented upsampling section and created music based on different styles. Jukebox is trained on 1.2 million songs with paired lyrics and metadata from LyricWiki. Trained on 32 bit, 44.1 kHz. \nRaw audio is represented as a continuous waveform $$x \\in [-1,1]^T$$  where the number of samples $$T$$ is the product of the audio duration $$t$$ and the sampling rate, typically 16 kHz to 48 kHz. Input of the Vector Quantized Variational is this continuous waveform. \nThe sampler.ipynb notebook is for generate music with pre-trained weigths, using conditional informations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8978728323825513
      ],
      "excerpt": "For more control over the generations, try co-composing with either the 5B or 1B Lyrics Models. Again, specify your artist, genre, and lyrics. However, now instead of generating the entire sample, the model will return 3 short options for the opening of the piece (or up to 16 options if you use the 1B model instead). Choose your favorite, and then continue the loop, for as long as you like. Throughout these steps, you'll be listening to the audio at the top prior level, which means it will sound quite noisy. When you are satisfied with your co-creation, continue on through the upsampling section. This will render the piece in higher audio quality. Your first samples will be located in your local drive folder, please mount the drive and choose your base storage directory.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8497010236565579
      ],
      "excerpt": "Your final samples have to level: level 1 and level 0. The level_1 samples will be available after around one hour (depending on the length of your sample) and are saved under {hps.name}/level_0/item_0.wav, while the fully upsampled level_0 will likely take 4-12 hours. You can access the wav files down below, or using the \"Files\" panel at the left of this colab. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Generating music with Vector Quantized Variational Autoencoders plus Scalable Sparse Transformer: \"JukeBox\". Code for inzva ai projects #5.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/safakkbilici/Synthetic-Music-Generation-with-Deep-Neural-Networks/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 11:29:01 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/safakkbilici/Synthetic-Music-Generation-with-Deep-Neural-Networks/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "safakkbilici/Synthetic-Music-Generation-with-Deep-Neural-Networks",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/safakkbilici/Synthetic-Music-Generation-with-Deep-Neural-Networks/main/jukebox/sampler.ipynb",
      "https://raw.githubusercontent.com/safakkbilici/Synthetic-Music-Generation-with-Deep-Neural-Networks/main/jukebox/.ipynb_checkpoints/sampling-checkpoint.ipynb",
      "https://raw.githubusercontent.com/safakkbilici/Synthetic-Music-Generation-with-Deep-Neural-Networks/main/jukebox/.ipynb_checkpoints/sampler-checkpoint.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/safakkbilici/Synthetic-Music-Generation-with-Deep-Neural-Networks/main/build.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8142711462726017
      ],
      "excerpt": "Run it on colab! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8223962573893714,
        0.8117837979221143
      ],
      "excerpt": "The hyperparameters are for a V100 GPU with 16 GB GPU memory. The 1b_lyrics, 5b, and 5b_lyrics top-level priors take up 3.8 GB, 10.3 GB, and 11.5 GB. \nIf you continue to have memory issues after this (or run into issues on your own home setup), switch to the 1B model. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8680826651557733
      ],
      "excerpt": "python3 mp32wav.py --input /path/to/wav.wav --output /path/to/mp3.mp3 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/safakkbilici/Synthetic-Music-Generation-with-Deep-Neural-Networks/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Music Generation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Synthetic-Music-Generation-with-Deep-Neural-Networks",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "safakkbilici",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/safakkbilici/Synthetic-Music-Generation-with-Deep-Neural-Networks/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- music21==5.7.0\n- Keras==2.4.3\n- NumPy==1.18.5\n- pygame==1.9.6\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 20,
      "date": "Tue, 28 Dec 2021 11:29:01 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "music-generation",
      "jukebox",
      "deep-neural-networks"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[This folder](https://github.com/inzva/music-generation/tree/main/jukebox/samples) contains our examples for music generation. \n\n",
      "technique": "Header extraction"
    }
  ]
}
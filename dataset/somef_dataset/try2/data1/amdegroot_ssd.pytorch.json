{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1409.1556"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Wei Liu, et al. \"SSD: Single Shot MultiBox Detector.\" [ECCV2016]((http://arxiv.org/abs/1512.02325)).\n- [Original Implementation (CAFFE)](https://github.com/weiliu89/caffe/tree/ssd)\n- A huge thank you to [Alex Koltun](https://github.com/alexkoltun) and his team at [Webyclip](http://www.webyclip.com) for their help in finishing the data augmentation portion.\n- A list of other great SSD ports that were sources of inspiration (especially the Chainer repo):\n  * [Chainer](https://github.com/Hakuyume/chainer-ssd), [Keras](https://github.com/rykov8/ssd_keras), [MXNet](https://github.com/zhreshold/mxnet-ssd), [Tensorflow](https://github.com/balancap/SSD-Tensorflow)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9443299173850146
      ],
      "excerpt": "PASCAL VOC: Visual Object Classes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "| 77.2 % | 77.26 % | 58.12% | 77.43 % | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/amdegroot/ssd.pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-02-08T01:50:36Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T13:25:30Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9533606612388286
      ],
      "excerpt": "A PyTorch implementation of Single Shot MultiBox Detector from the 2016 paper by Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang, and Alexander C. Berg.  The official and original Caffe code can be found here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8110779730412633
      ],
      "excerpt": "To make things easy, we provide bash scripts to handle the dataset downloads and setup for you.  We also provide simple dataset loaders that inherit torch.utils.data.Dataset, making them fully compatible with the torchvision.datasets API. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9419855141168803
      ],
      "excerpt": "We have accumulated the following to-do list, which we hope to complete in the near future \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8230353112946118
      ],
      "excerpt": "  * [ ] Support for training on custom datasets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A PyTorch Implementation of Single Shot MultiBox Detector",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "http://jupyter.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```Shell\n#: specify a directory for dataset to be downloaded into, else default is ~/data/\nsh data/scripts/COCO2014.sh\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```Shell\n#: specify a directory for dataset to be downloaded into, else default is ~/data/\nsh data/scripts/VOC2007.sh #: <directory>\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```Shell\n#: specify a directory for dataset to be downloaded into, else default is ~/data/\nsh data/scripts/VOC2012.sh #: <directory>\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- We are trying to provide PyTorch `state_dicts` (dict of weight tensors) of the latest SSD model definitions trained on different datasets.  \n- Currently, we provide the following PyTorch models:\n    * SSD300 trained on VOC0712 (newest PyTorch weights)\n      - https://s3.amazonaws.com/amdegroot-models/ssd300_mAP_77.43_v2.pth\n    * SSD300 trained on VOC0712 (original Caffe weights)\n      - https://s3.amazonaws.com/amdegroot-models/ssd_300_VOC0712.pth\n- Our goal is to reproduce this table from the [original paper](http://arxiv.org/abs/1512.02325)\n<p align=\"left\">\n<img src=\"http://www.cs.unc.edu/~wliu/papers/ssd_results.png\" alt=\"SSD results on multiple datasets\" width=\"800px\"></p>\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/amdegroot/ssd.pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1687,
      "date": "Fri, 24 Dec 2021 02:19:55 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/amdegroot/ssd.pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "amdegroot/ssd.pytorch",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/amdegroot/ssd.pytorch/master/demo/demo.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/amdegroot/ssd.pytorch/master/data/scripts/VOC2007.sh",
      "https://raw.githubusercontent.com/amdegroot/ssd.pytorch/master/data/scripts/VOC2012.sh",
      "https://raw.githubusercontent.com/amdegroot/ssd.pytorch/master/data/scripts/COCO2014.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Install [PyTorch](http://pytorch.org/) by selecting your environment on the website and running the appropriate command.\n- Clone this repository.\n  * Note: We currently only support Python 3+.\n- Then download the dataset by following the [instructions](#datasets) below.\n- We now support [Visdom](https://github.com/facebookresearch/visdom) for real-time loss visualization during training!\n  * To use Visdom in the browser:\n  ```Shell\n  #: First install Python server and client\n  pip install visdom\n  #: Start the server (probably in a screen or tmux)\n  python -m visdom.server\n  ```\n  * Then (during training) navigate to http://localhost:8097/ (see the Train section below for training details).\n- Note: For training, we currently support [VOC](http://host.robots.ox.ac.uk/pascal/VOC/) and [COCO](http://mscoco.org/), and aim to add [ImageNet](http://www.image-net.org/) support soon.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9287467277036058
      ],
      "excerpt": "<a href='#installation'>Installation</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8835572673635612
      ],
      "excerpt": "First download the fc-reduced VGG-16 PyTorch base network weights at:              https://s3.amazonaws.com/amdegroot-models/vgg16_reducedfc.pth \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8902627162932362,
        0.9906248903846466
      ],
      "excerpt": "mkdir weights \ncd weights \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9685004728391048
      ],
      "excerpt": "For instructions on Visdom usage/installation, see the <a href='#installation'>Installation</a> section. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8992738616058049
      ],
      "excerpt": "<img align=\"left\" src= \"https://github.com/amdegroot/ssd.pytorch/blob/master/doc/detection_examples.png\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9008335956509239
      ],
      "excerpt": "<a href='#training-ssd'>Train</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8635353640105476
      ],
      "excerpt": "To train SSD using the train script simply specify the parameters listed in train.py as a flag or manually change them. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503189345333785
      ],
      "excerpt": "python train.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9010185718090522
      ],
      "excerpt": "You can pick-up training from a checkpoint by specifying the path as one of the training parameters (again, see train.py for options) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8943096850060217,
        0.8030282699377912
      ],
      "excerpt": "python eval.py \nYou can specify the parameters listed in the eval.py file by flagging them or manually changing them.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8791394963870022
      ],
      "excerpt": "GTX 1060: ~45.45 FPS \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/amdegroot/ssd.pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2017 Max deGroot, Ellis Brown\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SSD: Single Shot MultiBox Object Detector, in PyTorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ssd.pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "amdegroot",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/amdegroot/ssd.pytorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4502,
      "date": "Fri, 24 Dec 2021 02:19:55 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "deep-learning",
      "ssd",
      "object-detection",
      "computer-vision",
      "machine-learning",
      "image-recognition",
      "webcam"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Make sure you have [jupyter notebook](http://jupyter.readthedocs.io/en/latest/install.html) installed.\n- Two alternatives for installing jupyter notebook:\n    1. If you installed PyTorch with [conda](https://www.continuum.io/downloads) (recommended), then you should already have it.  (Just  navigate to the ssd.pytorch cloned repo and run):\n    `jupyter notebook`\n\n    2. If using [pip](https://pypi.python.org/pypi/pip):\n\n```Shell\n#: make sure pip is upgraded\npip3 install --upgrade pip\n#: install jupyter notebook\npip install jupyter\n#: Run this inside ssd.pytorch\njupyter notebook\n```\n\n- Now navigate to `demo/demo.ipynb` at http://localhost:8888 (by default) and have at it!\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- Works on CPU (may have to tweak `cv2.waitkey` for optimal fps) or on an NVIDIA GPU\n- This demo currently requires opencv2+ w/ python bindings and an onboard webcam\n  * You can change the default webcam in `demo/live.py`\n- Install the [imutils](https://github.com/jrosebr1/imutils) package to leverage multi-threading on CPU:\n  * `pip install imutils`\n- Running `python -m demo.live` opens the webcam and begins detecting!\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1812.04948\n\n<img src=\"illustration.png\" alt=\"illustration\">\nPicture: Generated samples from GANs trained on celebaHQ, fashionGen, DTD.\n\n\n<img src=\"illustartionCelebaHQ.jpg\" alt=\"celeba\">\nPicture: fake faces with celebaHQ\n\nThis code also implements diverse tools:\n- GDPP method from [GDPP: Learning Diverse Generations Using Determinantal Point Process](https://arxiv.org/abs/1812.00068",
      "https://arxiv.org/abs/1812.00068",
      "https://arxiv.org/abs/1906.11661",
      "https://arxiv.org/abs/1610.09585"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.983817389067844,
        0.9944484218006108,
        0.9944484218006108
      ],
      "excerpt": "- Progressive Growing of GAN(PGAN): https://arxiv.org/pdf/1710.10196.pdf \n- DCGAN: https://arxiv.org/pdf/1511.06434.pdf \n- StyleGAN (beta): https://arxiv.org/abs/1812.04948 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/facebookresearch/pytorch_GAN_zoo/main/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/pytorch_GAN_zoo",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to pytorch_GAN_zoo\nWe want to make contributing to this project as easy and transparent as\npossible.\nPull Requests\nWe actively welcome your pull requests.\n\nFork the repo and create your branch from master.\nIf you've added code that should be tested, add tests.\nIf you've changed APIs, update the documentation.\nEnsure the test suite passes.\nMake sure your code lints.\nIf you haven't already, complete the Contributor License Agreement (\"CLA\").\n\nContributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\nComplete your CLA here: https://code.facebook.com/cla\nIssues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\nFacebook has a bounty program for the safe\ndisclosure of security bugs. In those cases, please go through the process\noutlined on that page and do not file a public issue.\nCoding Style\n\nflake8 standards\n\nLicense\nBy contributing to pytorch_GAN_zoo, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-17T09:52:30Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-28T02:56:58Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9783246784308388
      ],
      "excerpt": "A GAN toolbox for researchers and developers with: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8891464724261373
      ],
      "excerpt": "This code also implements diverse tools: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "For celebaHQ: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "For fashionGen: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8429319263273669
      ],
      "excerpt": "Four sub-datasets are available: CLOTHING, SHOES, BAGS and ACCESSORIES. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "For cifar10: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8679238406102242
      ],
      "excerpt": "Models trained on celebaHQ, fashionGen, cifar10 and celeba cropped are available with torch.hub. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8182851068668415
      ],
      "excerpt": "The minimum configuration file for a training session is a json file with the following lines \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8587431944546574
      ],
      "excerpt": "Other fields are available on the configuration file, like: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8641771621721385
      ],
      "excerpt": "With a dataset in the fashionGen format(.h5) it's a dictionary summing up statistics on the class to be sampled. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9635122233590923
      ],
      "excerpt": "miniBatchScheduler(dictionary): dictionary updating the size of the mini batch at different scale of the training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9610278314990557,
        0.8458890926494418
      ],
      "excerpt": "configScheduler(dictionary): dictionary updating the model configuration at different scale of the training \nex {\"2\": {\"baseLearningRate\": 0.1, \"epsilonD\": 1}} meaning that the learning rate and epsilonD will be updated to 0.1 and 1 from scale 2 and beyond \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8298856465710721
      ],
      "excerpt": "For example with a model trained on fashionGen: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8810521839368042
      ],
      "excerpt": "--selfNoise: returns the typical noise of the SWD distance for each resolution \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A mix of GAN implementations including progressive growing",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/pytorch_GAN_zoo/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 235,
      "date": "Tue, 28 Dec 2021 03:51:03 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/facebookresearch/pytorch_GAN_zoo/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "facebookresearch/pytorch_GAN_zoo",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9393686611610709,
        0.8732089505944296
      ],
      "excerpt": "celebAHQ: https://github.com/nperraud/download-celebA-HQ \nfashionGen: https://fashion-gen.com/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8020400165775151
      ],
      "excerpt": "Your checkpoints will be dumped in output_networks/celebaHQ. You should get 1024x1024 generations at the end. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8217864054963596
      ],
      "excerpt": "The above command will train the fashionGen model up resolution 256x256. If you want to train fashionGen on a specific sub-dataset for example CLOTHING, run: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8024024209712117
      ],
      "excerpt": "To this you can add a \"config\" entry giving overrides to the standard configuration. See models/trainer/standard_configurations to see all possible options. For example: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8138858587650843
      ],
      "excerpt": "Then, run your generation with: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.86796577008859
      ],
      "excerpt": "You can add optional arguments: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9202509175650415
      ],
      "excerpt": "<img src=\"illustartionCelebaHQ.jpg\" alt=\"celeba\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.90535917888195,
        0.9531826483104802
      ],
      "excerpt": "python datasets.py celeba_cropped $PATH_TO_CELEBA/img_align_celeba/ -o $OUTPUT_DATASET \npython train.py PGAN -c config_celeba_cropped.json --restart -n celeba_cropped \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.90535917888195,
        0.9531826483104802
      ],
      "excerpt": "python datasets.py celebaHQ $PATH_TO_CELEBAHQ -o $OUTPUT_DATASET - f \npython train.py PGAN -c config_celebaHQ.json --restart -n celebaHQ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.90535917888195,
        0.9531826483104802,
        0.8464679433797433,
        0.9531826483104802
      ],
      "excerpt": "python datasets.py fashionGen $PATH_TO_FASHIONGEN_RES_256 -o $OUTPUT_DIR \npython train.py PGAN -c config_fashionGen.json --restart -n fashionGen \nThe above command will train the fashionGen model up resolution 256x256. If you want to train fashionGen on a specific sub-dataset for example CLOTHING, run: \npython train.py PGAN -c config_fashionGen.json --restart -n fashionGen -v CLOTHING \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.90535917888195,
        0.9531826483104802
      ],
      "excerpt": "python datasets.py dtd $PATH_TO_DTD \npython train.py PGAN -c config_dtd.json --restart -n dtd \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9015553228193918,
        0.9479673017677819
      ],
      "excerpt": "python datasets.py cifar10 $PATH_TO_CIFAR10 -o $OUTPUT_DATASET \npython train.py PGAN -c config_cifar10.json --restart -n cifar10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8214529007322695,
        0.8436966146275674,
        0.8789790716528308,
        0.9531826483104802
      ],
      "excerpt": "See hubconf.py for how to load a checkpoint ! \nTo apply the GDPP loss to your model just add the option --GDPP true to your training command. \nTo run StyleGAN, use the model name StyleGAN when running train.py. Besides,to run StyleGAN you can use the pre-computed configurations for celeba and celebaHQ. For example: \npython train.py StyleGAN -c config_celebaHQ.json --restart -n style_gan_celeba \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8953458769558821
      ],
      "excerpt": "- a folder with all your images in .jpg, .png or .npy format \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8621882743635256
      ],
      "excerpt": "- a .h5 file(cf fashionGen) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8294104314806602
      ],
      "excerpt": "- pathAttribDict(string): path to a .json file matching each image with its attributes. To be more precise with a standard dataset, it is a dictionary with the following entries: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8234050434116794
      ],
      "excerpt": "imagefolderDataset(bool): set to true to handle datasets in the torchvision.datasets.ImageFolder format \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8096120219938144
      ],
      "excerpt": "pathPartition(string): path to a partition of the training dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8190268377724804
      ],
      "excerpt": "For example with a model trained on fashionGen: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8468404242074906
      ],
      "excerpt": "Will plot a batch of T_SHIRTS in visdom. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8602076567673452,
        0.902856876614953
      ],
      "excerpt": "python eval.py laplacian_SWD -c $CONFIGURATION_FILE -n $modelName -m $modelType \nWhere $CONFIGURATION_FILE is the training configuration file called by train.py (see above): it must contains a \"pathDB\" field pointing to path to the dataset's directory. For example, if you followed the instruction of the Quick Training section to launch a training session on celebaHQ your configuration file will be config_celebaHQ.json. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8209183297149978,
        0.8943096850060217
      ],
      "excerpt": "Then run your model: \npython eval.py inspirational_generation -n $modelName -m $modelType --inputImage $pathTotheInputImage -f $PATH_TO_THE_OUTPUT_FEATURE_EXTRACTOR \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/facebookresearch/pytorch_GAN_zoo/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright 2019, Facebook\\n\\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\\n\\n3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Pytorch GAN Zoo",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pytorch_GAN_zoo",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "facebookresearch",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/pytorch_GAN_zoo/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This project requires:\n- pytorch\n- torchvision\n- numpy\n- scipy\n- h5py (fashionGen)\n\nOptional:\n- visdom\n- nevergrad (inspirational generation)\n\nIf you don't already have pytorch or torchvision please have a look at https://pytorch.org/ as the installation command may vary depending on your OS and your version of CUDA.\n\nYou can install all other dependencies with pip by running:\n\n```\npip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npython train.py $MODEL_NAME -c $CONFIGURATION_FILE[-n $RUN_NAME][-d $OUTPUT_DIRECTORY][OVERRIDES]\n```\n\nWhere:\n\n1 - MODEL_NAME is the name of the model you want to run. Currently, two models are available:\n    - PGAN(progressive growing of gan)\n    - PPGAN(decoupled version of PGAN)\n\n2 - CONFIGURATION_FILE(mandatory): path to a training configuration file. This file is a json file containing at least a pathDB entry with the path to the training dataset. See below for more informations about this file.\n\n3 - RUN_NAME is the name you want to give to your training session. All checkpoints will be saved in $OUTPUT_DIRECTORY/$RUN_NAME. Default value is default\n\n4 - OUTPUT_DIRECTORY is the directory were all training sessions are saved. Default value is output_networks\n\n5 - OVERRIDES: you can overrides some of the models parameters defined in \"config\" field of the configuration file(see below) in the command line. For example:\n\n```\npython train.py PPGAN -c coin.json -n PAN --learningRate 0.2\n```\n\nWill force the learning rate to be 0.2 in the training whatever the configuration file coin.json specifies.\n\nTo get all the possible override options, please type:\n\n```\npython train.py $MODEL_NAME --overrides\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "You need to use the eval.py script.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1386,
      "date": "Tue, 28 Dec 2021 03:51:03 GMT"
    },
    "technique": "GitHub API"
  }
}
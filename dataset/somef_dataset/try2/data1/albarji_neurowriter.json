{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Learning models:\n\n* WaveNet paper: https://arxiv.org/pdf/1609.03499.pdf\n* A Keras implementation of WaveNet: https://github.com/usernaamee/keras-wavenet/blob/master/simple-generative-model.py\n* Another one: https://github.com/basveeling/wavenet/blob/master/wavenet.py\n* Facebook's convolutional translation paper: https://arxiv.org/pdf/1705.03122.pdf\n* DenseNet: https://arxiv.org/pdf/1608.06993.pdf\n\t* Keras implementation: https://github.com/tdeboissiere/DeepLearningImplementations/blob/master/DenseNet/densenet.py\n\nModel parallelization in Keras:\n\n* One weird trick for parallelizing convolutional neural networks: https://arxiv.org/pdf/1404.5997.pdf\n* Data parallelism in Keras: https://stackoverflow.com/questions/43821786/data-parallelism-in-keras\n* Other approach to data parallelism in Keras: https://medium.com/@kuza55/transparent-multi-gpu-training-on-tensorflow-with-keras-8b0016fd9012\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9310817226452074
      ],
      "excerpt": "A 10 Money of Presents&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8729393277090676,
        0.8729393277090676
      ],
      "excerpt": "Super Centry&lt;END&gt; \nSuper D10000&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9015781078351486
      ],
      "excerpt": "Anal Fire Part 2&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9321597499656605
      ],
      "excerpt": "Dencie: Ron, licor de melocot\u00f3n y lima.&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9630811906933039,
        0.9321597499656605
      ],
      "excerpt": "Tetsns: Vodka, licor de melocot\u00f3n y Blue kiwi .&lt;END&gt; \nAice Paja: Vodka, licor de melocot\u00f3n y lima.&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9811934373974328,
        0.8258747798972372
      ],
      "excerpt": "Direta: Martini, licor de melocot\u00f3n, zumo de fresa y lima.&lt;END&gt; \nMore: Tequila, licor de melocot\u00f3n, vodka y naranja.&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9811934373974328
      ],
      "excerpt": "El menca: Vodka, licor de de mora.&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9321597499656605
      ],
      "excerpt": "Esko Mei: Granadina, ron, licor de melocot\u00f3n y granadina&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9811934373974328
      ],
      "excerpt": "Chula Vara: Licor de mora, Licor de avellana y granadina&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9507374082549614,
        0.9865374311292784,
        0.9964189199332645,
        0.8356013927728488,
        0.9071552692524211,
        0.9946379808099154,
        0.9507374082549614
      ],
      "excerpt": "LA LUZ DE MARTE \nCuando en la esperanza de la frente \nde la mano de la fortuna cr\u00eda \npor que en la esperanza y el pecho ardiente \nen la vida el sol de aquel que no gu\u00eda. \nPar que se le han de que la luz de Marte, \ny la aurora la que es el m\u00e1rmol que siento \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.8356013927728488,
        0.9507374082549614,
        0.9507374082549614,
        0.999054375125654,
        0.8356013927728488,
        0.9865374311292784,
        0.9865374311292784,
        0.9806856444823063
      ],
      "excerpt": "FE DE CERA \nPor un fe de su deidad m\u00e1s se ofrece \nde un tiempo y la tierra que se ve y en el cielo \npor fin de tus l\u00e1grimas, y por la mano \nde la vida y de m\u00e1s alas de la pena. \nSi el alma que en la luz desvelada \nla causa de esta parte de su aliento \nen ver de su virtud la fe m\u00e1s de cera, \ny no hay que de la luz de dolor no siento.&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.9278824608274014,
        0.9865374311292784,
        0.9278824608274014
      ],
      "excerpt": "Yo un huego que de un nieto y su misma parte \nde tu mano alimenta un semblante \nde la vejez del tiempo de su gloria \ny en el que la queja lo que tu aliento \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.999054375125654
      ],
      "excerpt": "Cap\u00edtulo XXXVIII. De la aventura del sol fue Sancho, con la flaca de la se\u00f1ora \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9586556701111782,
        0.9887693216051685
      ],
      "excerpt": "de que el que estaba apartada y con su espada de monte la fe que me \nhab\u00eda de hacer en el lugar de don Quijote de la Mancha, y alab\u00f3 -dijo \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8592871015078071
      ],
      "excerpt": "este caballo, fue a lo que el don Quijote se partiese de la mano, porque, antes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9995078555087972
      ],
      "excerpt": "dio la historia de la soledad, no se m\u00e1s de tocar de aquella cueva de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8592871015078071
      ],
      "excerpt": "-S\u00ed ten\u00eda -dijo don Quijote-, y es que ha de ser en fe y la d\u00e9 a todos \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9513176864807809,
        0.9243188970772274
      ],
      "excerpt": "no en qu\u00e9 favor les he visto de los hombres en el mundo, porque me quiere, y \nque yo te acuerdo de la fecha. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9946379808099154,
        0.9985065536444201,
        0.9737528548338414
      ],
      "excerpt": "-El cual se puede ser tomar la imagen de que le da de verse en \n\u00e1nimo que la atreva de las ni\u00f1er\u00edas y de su que me tiene de la historia \ndisposici\u00f3n de la cabeza, no hay contado alguna para dormir que m\u00e1s de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8318362334106357,
        0.8318362334106357,
        0.8592871015078071,
        0.9737528548338414,
        0.8318362334106357,
        0.8356013927728488,
        0.9997507821127818,
        0.9788914761692258,
        0.9998703394684532
      ],
      "excerpt": "hubiera de ver a la ley que vio el cual, finalmente, yo no s\u00e9 que no me \nrede con que en \u00e9l no parece que no lo ha sido de la batalla. \n-Si la vida de una carca vuestra merced -respondi\u00f3 don Quijote-, que \nno es algo de un verdadera que se hab\u00eda de estar que yo lo hab\u00eda de hacer en \nel negocio de no lejos que trataba, y est\u00e1 un mundo no tiene la salud y \nquerido la medario, y quiz\u00e1 con sus pensamientos como se amenaza. \nEL Y los reyes de la tierra y de la tierra y de los siglos. Y el \u00e1ngel toc\u00f3 la trompeta, y el que est\u00e1 en  \nel cielo y las cosas que est\u00e1n en \u00e9l, y de la tierra y el que est\u00e1 sentado sobre el mar, y la tierra y vi  \na los hombres que no se halla de la tierra y de la tierra y de los siglos de los siglos. Y el templo de  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906174419333412,
        0.9997507821127818,
        0.9788914761692258
      ],
      "excerpt": "La mujer que estaba sentado en el cielo y las cosas que est\u00e1n en \u00e9l me dijo: Estas son los que se llama  \nde los siglos. Y el \u00e1ngel toc\u00f3 la trompeta, y la gloria y la tierra y el que es el libro de la tierra y  \nel que est\u00e1 sentado en el cielo y las cosas que est\u00e1n en \u00e9l el nombre de la tierra y de los siglos. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9243188970772274
      ],
      "excerpt": "La mensada de oro, y los que hab\u00eda en el cielo y las cosas que est\u00e1n en ella se ha azufre. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8654671031158477
      ],
      "excerpt": "\"He was dead!\" \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/albarji/neurowriter",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-07-28T12:23:22Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-19T06:10:56Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9782479178745397
      ],
      "excerpt": "This is is a single document corpus. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8130878246250616
      ],
      "excerpt": "And now for something different! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9616326739847701
      ],
      "excerpt": "This is a multidocument. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8630564436224898
      ],
      "excerpt": "Other columns present in the file are loaded, but at present not used in the learning process. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9349847433958779
      ],
      "excerpt": "The Other Side of the Wind,['Drama'] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9481364653712357
      ],
      "excerpt": "of the document. Othe fields present in the document are loaded, but at present not used in the learning process. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9349847433958779
      ],
      "excerpt": "        \"text\" : \"The Other Side of the Wind\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8849655664944147
      ],
      "excerpt": "A Tokenizer is a procedure for breaking down a document into its basic pieces. Neurowriter provides the following \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8002902029290747,
        0.9778136007754653
      ],
      "excerpt": "SubWordTokenizer: breaks down the document into basic characters + frequent subword pieces, using a BPE algorithm. \nFor a corpus of documents that are more than a few words long, it is recommended to use the SubWordTokenizer. Note \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9679413659589003
      ],
      "excerpt": "model architecture: by default an LSTM model is used, but faster or more expressive models are also included. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8254368783601863
      ],
      "excerpt": "at the end of each generated document, then proceeding to generate another one. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9306402483904449
      ],
      "excerpt": "significant: small values force the model to produce only high probability sequences, while higher \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8234971522331328
      ],
      "excerpt": "The Secret of the Cast&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8234971522331328
      ],
      "excerpt": "The Tale of the Trome&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.927818493621294
      ],
      "excerpt": "Search for All Are Episode Waters There Is the Superture and the Earth Home&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9667079940912727
      ],
      "excerpt": "The Man of the End of There's It Health Tall to Sea Pilot&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8192146815270039
      ],
      "excerpt": "Headth St! Story of His for Million&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9291558785922454
      ],
      "excerpt": "The Devil Is the Man of a Berrellist&lt;END&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.992146931571488
      ],
      "excerpt": "In the sound of the shadowy streets and stalk masonry of the black city, as the chill of vast dark and  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9438091982926609,
        0.9807231523621024,
        0.9826256116851301,
        0.929126829536131,
        0.9950759478677067,
        0.967006158173895,
        0.9235188733869806,
        0.9457194980575659,
        0.9842478895857304
      ],
      "excerpt": "As I almost tried to be a revolver that the doctor drew the place to the cold and Sianian glen he had  \ncome to the door and the and scenes of Georgian chiselled back to the liness, and strewn up again to a  \ncontinuous laws of the  most probable soul. The rites high in the town came in a scene to the eyes of  \nleague as the motor-great hoveral  often happened in the cohort otic young priest and the entire wind  \nand and shocking and one with the intellectual  open streets of the corner of that crawl of something  \nthe touch of the yellow polished graves and prying head to  the at the other city which had kept a  \nshaped thing, and in the parctive way gave it a strange body on the house  and or it not against him.  \nDubl abode the gnawed and lower and illusion had been the dark and concreated daemon of on the  \nterrible ward--Alhazred horror, and with the sight of the moon and which a Roman the cryptic town had  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9679362669261483,
        0.9538743487186003,
        0.9880689859114516,
        0.9805504892662315,
        0.9776374166672673,
        0.9914187628180032,
        0.9912228579730481,
        0.9880211695626913,
        0.8490037945672047,
        0.8490037945672047,
        0.9757103272143696,
        0.8589831172245448,
        0.8284718041788491,
        0.9684176174469331,
        0.9576495206385742,
        0.9620117976667197,
        0.9432195085988289,
        0.9659049448537378
      ],
      "excerpt": "The the ancient Mwan Halus, and in the ancient but a nameless and face of the far door of the dark  \naltar and and the old man and in the northern and the a strange thing that the strange world was not  \nto be the glass and the and  uncovered cemeteries of the light and the illimitable prop of the tiny  \nVusan of the the cellar and the nameless of the place. It was the old man in the old man when I had  \nseen the old man and the first and the in the wall of the old thing and the Saria of the town was of  \nthe old coil. It was a face of the day of the queer people of the low bungalow and the corridors of the  \nthe face of the Babylon, and when the cost of a the low cohort was every time  \nand uncovering the ritual of the moon of the door and held the very day. [...] \nTHE DODOEKLEH \nTHE HATES I YOOR \nBut I had not said to the boy of his face and the sentient in the crowning whispering dance and opening  \nthe city as I had one to the Pirkon, of what had been murderous and consoled to the before the room.  \nThis night, it was a faint sun of then and loud and half-with the slumber it had been at the year, and  \nwho was a small moon, and had still to nothing an unsancied blackness of some time to me that the Thur  \nhad was the muffled poe of this where his dream and books and the blottle doesn of the honour. The great  \nCzar would ought to fly down to the the great paintings and  crouching of the unearthly hand. The boy  \nhad been a room of body as one in the summit of the old man should not see. The cubes of my legion was  \nthe next day and the mo and in the same moment \"I was relieved that is over the sanity [...] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.968837345403298
      ],
      "excerpt": "\"I have never been able to get a matter of a Death Eater,\" said Harry, \"and I knew what it is a little  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8642908868118947
      ],
      "excerpt": "\"No time to break down, Severus, you are not going to keep it at the same time to see you,\" said  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9321863699216456
      ],
      "excerpt": "you can have to get a lot of the other other Potter and her old boy and your head wants to be a chance  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8314692756579747,
        0.9343651597060778
      ],
      "excerpt": "\"What is it, Voldemort?\" Harry asked, and he had never seen the Death Eaters in the castle. \"You know how  \nI have been and the Death Eaters we found out of the forest of the Death Eaters will be to find him, he  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9195549011033236,
        0.9211929964013124,
        0.9737430841951671
      ],
      "excerpt": "\"I see it for him and I must be able to get in the castle, and you are not the same time you think he was  \nthe same time, and I know I will not have seen a little curse and to tell him that he could be able to  \nfight him and we have been a few years ago, and it was a word of the Order of the Phoenix with the boy - \"  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9420022170796158
      ],
      "excerpt": "\"I could not speak to you, I got the way to the Chamber of Secrets,\" said Harry, looking at him at once. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9014439889578808,
        0.9220901244323764,
        0.889299335382011,
        0.8787132362305986,
        0.9698197172048701,
        0.907206565206338,
        0.841745073020112,
        0.9642001630713183,
        0.8724109376152085
      ],
      "excerpt": "course, I thought I saw you to come to the Great Hall, and the Death Eaters were head of the room at  \nHogwarts, and we can keep the students in the hall of the full castle, and they know that you can be the  \nlast time he was listening to the plan to be a little fight. You have been in the castle for the place  \nwhere you have been and the Sorting Hat Potter is not on the back of the castle, and you can have a hundred  \ndeath of the Slytherin House of the Dark Arts in the world  well do you like to do a man and he was in the  \nforest, was all the same time to do it, and I can see that you were trying to be the way to have a few  \nsteps to the castle, the only thing he was two inches at Hogwarts, and he had to do here, but you know what  \nhe was going to be brave in the Order of the Phoenix to see it, but you were up to the castle and he was  \nlying here . . . I was at the moment that he was not to have a matter of the last time he was  that you  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8878641487968607
      ],
      "excerpt": "Since this is still work in progress, here are some ideas I might try in the future: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9202096267729252,
        0.8062284318267852
      ],
      "excerpt": "Include the position of each token in the document and/or in the input as a parallel embedding \nSome amusing corpus to try: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Framework to imitate writing styles using deep learning",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/albarji/neurowriter/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Thu, 30 Dec 2021 00:05:59 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/albarji/neurowriter/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "albarji/neurowriter",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/albarji/neurowriter/master/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "A corpus is a set of documents that will be used to train the text generator. You will need to adequate your corpus\naccording to one of the following formats:\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "You will need an **Anaconda Python 3** distribution. Then run the following commands to install the required\npython packages in your active environment:\n\n    make install\n    \nor, if you want to build the project with GPU support, run\n\n    make install-gpu\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "You can make use of neurowriter either through a dockerized version, or you may install it locally in your computer. \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8516192991881895,
        0.8399415121791932
      ],
      "excerpt": "make build-image \nto build the Neurowriter Docker image. If instead you want to build this image with GPU support, you will also need  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9728763758903046
      ],
      "excerpt": "make build-image-gpu \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8545223018164689
      ],
      "excerpt": "You will need to provide the following arguments:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8886869671129654
      ],
      "excerpt": "that you are hiding you to fight the place that You-Know-Who would be to keep the snake to see you in the  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8369233264650713
      ],
      "excerpt": "A text file containing a single document. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9093028863208709
      ],
      "excerpt": "A text file containing multiple documents, one document per line.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8992816855277125
      ],
      "excerpt": "The file stores one document per line. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8525637049770236
      ],
      "excerpt": "A CSV file with one row per document.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8455689393588379
      ],
      "excerpt": "A JSON file in the form [{doc1}, {doc2}, ...] where each document must contain a \"text\" attibute with the contents \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "        \"text\" : \"Na Boca da Noite\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "        \"text\" : \"Prata Palomares\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9215693103233217
      ],
      "excerpt": "python tokenizecorpus.py corpus/toyseries.txt multilinetxt toyseries_bpe.json \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801143116105935
      ],
      "excerpt": "Name of the input corpus file \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9181692935148131
      ],
      "excerpt": "Name of output tokenize corpus file \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8923771895705674,
        0.9283135535189326
      ],
      "excerpt": "To train the generator use the train.py script. For example: \npython train.py toyseries_bpe.json json toyseries.enc toyseries.h5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8668807378406393
      ],
      "excerpt": "Name of the (previously tokenized) corpus file \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8805870058627074,
        0.868757254134729
      ],
      "excerpt": "Output file with model token encodings. \nOutput file with model weights. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8773433138469842,
        0.9156274458184526
      ],
      "excerpt": "Use the generate.py script to generate text! \npython generate.py toyseries.h5 toyseries.enc \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421369221402946,
        0.8245366458545469
      ],
      "excerpt": "File with previously trained model token encodings. \nFile with previously trained model weights. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8213021920304038
      ],
      "excerpt": "again and again, an increase in creativity might help, whereas the generator producing garbage text will need a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8160677842987113
      ],
      "excerpt": "7 El que tiene o\u00eddo, oiga lo que estaban en el cielo y las cosas que est\u00e1n en ella se ha a venir; y el  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/albarji/neurowriter/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Makefile",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2017 \\xc3\\x81lvaro Barbero Jim\\xc3\\xa9nez\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Install",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "neurowriter",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "albarji",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/albarji/neurowriter/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 62,
      "date": "Thu, 30 Dec 2021 00:05:59 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The basic process to create a text generator is the following:\n\n* Prepare a **corpus** of documents in a **proper format**.\n* **Tokenize** the corpus (optional, but strongly recommended).\n* Select a **model architecture** to learn from the corpus and run the **training** process.\n* Use the created model to generate new texts!\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Pre-trained models are available for some of these examples: check the **samplemodels** folder.\n\n",
      "technique": "Header extraction"
    }
  ]
}
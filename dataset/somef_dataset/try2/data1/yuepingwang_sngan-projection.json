{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1802.05637",
      "https://arxiv.org/abs/ 1802.05637.\n\nThe author's implementation using Chainer can be found in this repo [here] (https://github.com/pfnet-research/sngan_projection)\n\n## Techniques in cGAN\n\nThe cGAN network build on top of the Spectral Normalization method, which is an effective way to ensure K-Lipschitz continuity at each layer and thus bounds the gradient of the discriminator. As proposed in the [paper](https://arxiv.org/abs/1802.05637), we fixed the spectral norm of the layer by replacing the original weight *w* with *W/\u03c3(W)*, where \u03c3(W) is the largest singular value of w. This significantly improves the stability of the training, and made the multi-class generative network possible.\n\nIt is implemented in the Discriminator's residual blocks using PyTorch's *torch.nn.utils.spectral_norm*\n'''\n    def __init__(self, in_ch, out_ch, h_ch=None, ksize=3, pad=1,\n                 activation=F.relu, downsample=False):\n        super(Block, self).__init__()\n\n        self.activation = activation\n        self.downsample = downsample\n\n        self.learnable_sc = (in_ch != out_ch) or downsample\n        if h_ch is None:\n            h_ch = in_ch\n        else:\n            h_ch = out_ch\n\n        self.c1 = utils.spectral_norm(nn.Conv2d(in_ch, h_ch, ksize, 1, pad))\n        self.c2 = utils.spectral_norm(nn.Conv2d(h_ch, out_ch, ksize, 1, pad))\n        if self.learnable_sc:\n            self.c_sc = utils.spectral_norm(nn.Conv2d(in_ch, out_ch, 1, 1, 0))\n\n        self._initialize()\n'''\n\nThe cGAN paper introduced a new way to add conditioning to the network. While earlier works on conditional GANs explored ways to concatenate the class-encoding vector *y* into part of the network, the authors of *cGAN with Projection Discriminators* shows that by incorporating *y* as an inner product with the network, it can more effectively interact with the hidden layers of the network and allow for more stable training.\n\n![Comparisons of different conditioning for the discriminator](images/cgan_paper_fig1.png)\n\nTo implement class-conditional batch normalization, we first need to create a base class for conditional batch normalization. This should both inherit from PyTorch's BatchNorm2d class, and introduce the conditional weighting and bias terms for the batch normalization layer:\n'''\nclass ConditionalBatchNorm2d(nn.BatchNorm2d):\n\n    \"\"\"Conditional Batch Normalization\"\"\"\n\n    def __init__(self, num_features, eps=1e-05, momentum=0.1,\n                 affine=False, track_running_stats=True):\n        super(ConditionalBatchNorm2d, self).__init__(\n            num_features, eps, momentum, affine, track_running_stats\n        )\n\n    def forward(self, input, weight, bias, **kwargs):\n        self._check_input_dim(input)\n\n        exponential_average_factor = 0.0\n\n        if self.training and self.track_running_stats:\n            self.num_batches_tracked += 1\n            if self.momentum is None:  # use cumulative moving average\n                exponential_average_factor = 1.0 / self.num_batches_tracked.item()\n            else:  # use exponential moving average\n                exponential_average_factor = self.momentum\n\n        output = F.batch_norm(input, self.running_mean, self.running_var,\n                              self.weight, self.bias,\n                              self.training or not self.track_running_stats,\n                              exponential_average_factor, self.eps)\n        if weight.dim() == 1:\n            weight = weight.unsqueeze(0)\n        if bias.dim() == 1:\n            bias = bias.unsqueeze(0)\n        size = output.size()\n        weight = weight.unsqueeze(-1).unsqueeze(-1).expand(size)\n        bias = bias.unsqueeze(-1).unsqueeze(-1).expand(size)\n        return weight * output + bias \n'''\n\nOn top of this, we create the CategoricalConditionalBatchNorm2d that extends the weight and bias to accommodate for any number of classes. By using *torch.nn.Embedding*, we turn the weights and biases to a look up table that correspond to each class label:\n'''\nclass CategoricalConditionalBatchNorm2d(ConditionalBatchNorm2d):\n\n    def __init__(self, num_classes, num_features, eps=1e-5, momentum=0.1,\n                 affine=False, track_running_stats=True):\n        super(CategoricalConditionalBatchNorm2d, self).__init__(\n            num_features, eps, momentum, affine, track_running_stats\n        )\n        self.weights = nn.Embedding(num_classes, num_features)\n        self.biases = nn.Embedding(num_classes, num_features)\n\n        self._initialize()\n\n    def _initialize(self):\n        init.ones_(self.weights.weight.data)\n        init.zeros_(self.biases.weight.data)\n\n    def forward(self, input, c, **kwargs):\n        weight = self.weights(c)\n        bias = self.biases(c)\n\n        return super(CategoricalConditionalBatchNorm2d, self).forward(\n                     input, weight, bias)\n'''\n\n## Output Results\n\nFor training, I used the [Tiny ImageNet](https://tiny-imagenet.herokuapp.com/) dataset, which by default contains 64*64 images from 200 categories.\n\nI first trained using only the spectrial normalization GAN, without conditioning on class labels. While the result after 40000 iterations shows improvements in capturing edges and textures, it is far from synthesizing high level features.\n\n![output1_sngan](images/output1_sngan.png)\n\nI then used cGAN to train for the same dataset. However, the output images after the same number of interations didn't show better class-based features than the spectrial normalization GAN. \nMy interpretation is that the total number of classes for a GAN can not be arbitrarily large. The number of categories to train for should depend on the network's input feature size.\n\n![output0](images/output0.png)\n\nEventually, I trained with a smaller number of image classes, and was able to get class-specific generative results. \n\n![output1](images/output1.jpg)\n\nI also noticed that the training is significantly faster when the training images have simpler geometries and textures. For example, to train for 6 categories of geometric shapes only took 6000 interations to get a good result. his allows me to quickly test out feature interpolation.\n\n![colors_1](images/colors_1.jpg) ![interpolate](images/interpolate.jpg)\n\nHere is a [link](https://colab.research.google.com/drive/1HLZBceHtiz_aTjNw_QP1yGB7HFJYePAv) to Colab Demo for using the Generator and mixing class features for the output image."
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8043073075947367
      ],
      "excerpt": "    if self.learnable_sc: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yuepingwang/sngan-projection",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-29T02:33:48Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-17T16:07:24Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9073686968230809
      ],
      "excerpt": "An un-official PyTorch implementation for the paper cGAN with Projection Discriminator, arXiv: 1802.05637. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9904246623452648,
        0.8499553712684752
      ],
      "excerpt": "The cGAN network build on top of the Spectral Normalization method, which is an effective way to ensure K-Lipschitz continuity at each layer and thus bounds the gradient of the discriminator. As proposed in the paper, we fixed the spectral norm of the layer by replacing the original weight w with W/\u03c3(W), where \u03c3(W) is the largest singular value of w. This significantly improves the stability of the training, and made the multi-class generative network possible. \nIt is implemented in the Discriminator's residual blocks using PyTorch's torch.nn.utils.spectral_norm \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9958288660105317
      ],
      "excerpt": "The cGAN paper introduced a new way to add conditioning to the network. While earlier works on conditional GANs explored ways to concatenate the class-encoding vector y into part of the network, the authors of cGAN with Projection Discriminators shows that by incorporating y as an inner product with the network, it can more effectively interact with the hidden layers of the network and allow for more stable training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8918251745182324,
        0.8770834760578408,
        0.9171853623871784
      ],
      "excerpt": "My interpretation is that the total number of classes for a GAN can not be arbitrarily large. The number of categories to train for should depend on the network's input feature size. \nEventually, I trained with a smaller number of image classes, and was able to get class-specific generative results.  \nI also noticed that the training is significantly faster when the training images have simpler geometries and textures. For example, to train for 6 categories of geometric shapes only took 6000 interations to get a good result. his allows me to quickly test out feature interpolation. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yuepingwang/sngan-projection/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 10:36:42 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yuepingwang/sngan-projection/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "yuepingwang/sngan-projection",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/yuepingwang/sngan-projection/master/cGAN_Generate_Images.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8114816121523112,
        0.8114816121523112
      ],
      "excerpt": "    self.c1 = utils.spectral_norm(nn.Conv2d(in_ch, h_ch, ksize, 1, pad)) \n    self.c2 = utils.spectral_norm(nn.Conv2d(h_ch, out_ch, ksize, 1, pad)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8114816121523112
      ],
      "excerpt": "        self.c_sc = utils.spectral_norm(nn.Conv2d(in_ch, out_ch, 1, 1, 0)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8768801849289117
      ],
      "excerpt": "             affine=False, track_running_stats=True): \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yuepingwang/sngan-projection/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook",
      "Tcl",
      "PowerShell",
      "Batchfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Class-Conditional Image Generation using Projection Discriminators",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "sngan-projection",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "yuepingwang",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yuepingwang/sngan-projection/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 10:36:42 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "                exponential_average_factor = 1.0 / self.num_batches_tracked.item()\n            else:  ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "                exponential_average_factor = self.momentum\n\n        output = F.batch_norm(input, self.running_mean, self.running_var,\n                              self.weight, self.bias,\n                              self.training or not self.track_running_stats,\n                              exponential_average_factor, self.eps)\n        if weight.dim() == 1:\n            weight = weight.unsqueeze(0)\n        if bias.dim() == 1:\n            bias = bias.unsqueeze(0)\n        size = output.size()\n        weight = weight.unsqueeze(-1).unsqueeze(-1).expand(size)\n        bias = bias.unsqueeze(-1).unsqueeze(-1).expand(size)\n        return weight * output + bias \n'''\n\nOn top of this, we create the CategoricalConditionalBatchNorm2d that extends the weight and bias to accommodate for any number of classes. By using *torch.nn.Embedding*, we turn the weights and biases to a look up table that correspond to each class label:\n'''\nclass CategoricalConditionalBatchNorm2d(ConditionalBatchNorm2d):\n\n    def __init__(self, num_classes, num_features, eps=1e-5, momentum=0.1,\n                 affine=False, track_running_stats=True):\n        super(CategoricalConditionalBatchNorm2d, self).__init__(\n            num_features, eps, momentum, affine, track_running_stats\n        )\n        self.weights = nn.Embedding(num_classes, num_features)\n        self.biases = nn.Embedding(num_classes, num_features)\n\n        self._initialize()\n\n    def _initialize(self):\n        init.ones_(self.weights.weight.data)\n        init.zeros_(self.biases.weight.data)\n\n    def forward(self, input, c, **kwargs):\n        weight = self.weights(c)\n        bias = self.biases(c)\n\n        return super(CategoricalConditionalBatchNorm2d, self).forward(\n                     input, weight, bias)\n'''\n\n",
      "technique": "Header extraction"
    }
  ]
}
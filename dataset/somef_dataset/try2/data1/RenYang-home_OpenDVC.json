{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2003.01966",
      "https://arxiv.org/abs/2006.15862",
      "https://arxiv.org/abs/1809.10452",
      "https://arxiv.org/abs/2006.15862"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{yang2020opendvc,\n  title={Open{DVC}: An Open Source Implementation of the {DVC} Video Compression Method},\n  author={Yang, Ren and Van Gool, Luc and Timofte, Radu},\n  journal={arXiv preprint arXiv:2006.15862},\n  year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9999999998990745
      ],
      "excerpt": "Lu, Guo, et al. \"DVC: An end-to-end deep video compression framework.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2019. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.997977641019694
      ],
      "excerpt": "If our open source codes are helpful for your research, especially if you compare with the MS-SSIM model of OpenDVC in your paper, please cite our technical report: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.9733008541963115
      ],
      "excerpt": "Ren Yang @ ETH Zurich, Switzerland \nEmail: ren.yang@vision.ee.ethz.ch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9417635092274106
      ],
      "excerpt": "def find(pattern, path): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9712749768232812
      ],
      "excerpt": "            if fnmatch.fnmatch(name, pattern): \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RenYang-home/OpenDVC",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-25T18:41:42Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-16T03:37:07Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9161135672764912
      ],
      "excerpt": "An open source Tensorflow implementation of the paper: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9843908629828426,
        0.9298424157388897
      ],
      "excerpt": "The original DVC method is only optimized for PSNR. In our OpenDVC codes, we provide the PSNR-optimized re-implementation, denoted as OpenDVC (PSNR), and also the MS-SSIM-optimized model, denoted as OpenDVC (MS-SSIM). \nIf our open source codes are helpful for your research, especially if you compare with the MS-SSIM model of OpenDVC in your paper, please cite our technical report: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9890371805880878
      ],
      "excerpt": "Note that, OpenDVC currently only supports the frames with the height and width as the multiples of 16. The original DVC method requires the multiples of 32. Therefore, when using OpenDVC, please first crop frames, e.g., \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8610470371313417
      ],
      "excerpt": "--metric, evaluate quality in terms of PSNR or MS-SSIM; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8265825341559935
      ],
      "excerpt": "--CA_model_path, the path to CA_EntropyModel_Test of Lee et al., ICLR 2019 (only used for the MS-SSIM models); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9966474696551649
      ],
      "excerpt": "--Height, the height of frames; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8265825341559935
      ],
      "excerpt": "--CA_model_path, the path to CA_EntropyModel_Test of Lee et al., ICLR 2019 (only used for the MS-SSIM models); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8571922612270221
      ],
      "excerpt": "We also provide the encoder for compressing one frame (OpenDVC_test_P-frame.py), which can be used more flexibly. The arguments are as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8610470371313417
      ],
      "excerpt": "--metric, evaluate quality in terms of PSNR or MS-SSIM; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8117089515884509
      ],
      "excerpt": "The corresponding decoder for one frame is OpenDVC_test_P-frame_decoder.py, whose auguments are the same the encoder, excluding \"--raw\" and \"--metric\". \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9424298702305338
      ],
      "excerpt": "Compress I-frames. In OpenDVC (PSNR), we compress I-frames (im1.png) by BPG 444 at QP = 22, 27, 32 and 37 for the models of lambda = 2048, 1024, 512 and 256, respectively. In OpenDVC (MS-SSIM), we compress I-frames by Lee et al., ICLR 2019 at quality level = 2, 3, 5 and 7 for the models of lambda = 8, 16, 32 and 64. The Vimeo90k dataset has ~90k 7-frame clips, we need to compress \"im1.png\" in each clip as I-frame. For example: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9742120858124161
      ],
      "excerpt": "We fine-tune the MS-SSIM models of lambda = 8, 16, 32 and 64 from the PSNR models of lambda = 256, 512, 1024 and 2048, respectively. For instance, \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RenYang-home/OpenDVC/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 29,
      "date": "Wed, 29 Dec 2021 04:08:23 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/RenYang-home/OpenDVC/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "RenYang-home/OpenDVC",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8489009363723199
      ],
      "excerpt": "--path_com, the path to save the decoded frames; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8800128043939355
      ],
      "excerpt": "--com, the path to save the compressed frame; \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8172034057683939
      ],
      "excerpt": "ffmpeg -pix_fmt yuv420p -s WidthxHeight -i Name.yuv -vframes Frame path_to_PNG/f%03d.png \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8507905423537824
      ],
      "excerpt": "We uploaded a prepared sequence BasketballPass here as a test demo, which contains the PNG files of the first 100 frames. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8284635361097942,
        0.8104597834838346
      ],
      "excerpt": "--mode, compress with the PSNR or MS-SSIM optimized model; \n--metric, evaluate quality in terms of PSNR or MS-SSIM; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8833819597448699
      ],
      "excerpt": "--l, lambda value. The pre-trained PSNR models are trained by 4 lambda values, i.e., 256, 512, 1024 and 2048, with increasing bit-rate/PSNR. The MS-SSIM models are trained with lambda values of 8, 16, 32 and 64, with increasing bit-rate/MS-SSIM; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216270093103228,
        0.8688493096352915,
        0.8818644043331939
      ],
      "excerpt": "For example: \npython OpenDVC_test_video.py --path BasketballPass --mode PSNR  --metric PSNR --l 1024 \npython OpenDVC_test_video.py --path BasketballPass --mode MS-SSIM  --metric MS-SSIM --python python --CA_model_path ./CA_EntropyModel_Test --l 32 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.808556329939479
      ],
      "excerpt": "path_bin = args.path + '_bin_' + args.mode  + '_' + str(args.l) + '/' #: path to encoded bit-streams \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8284635361097942
      ],
      "excerpt": "--mode, compress with the PSNR or MS-SSIM optimized model; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731562459058029
      ],
      "excerpt": "--l, lambda value; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216270093103228,
        0.9281497158805102
      ],
      "excerpt": "For example: \npython OpenDVC_test_video_decoder.py --path_bin BasketballPass_bin_PSNR_1024 --path_com BasketballPass_dec_PSNR_1024 --mode PSNR --l 1024 --Height 240 --Width 416 --GOP 10 --frame 100 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8284635361097942,
        0.8104597834838346,
        0.8731562459058029
      ],
      "excerpt": "--mode, compress with the PSNR or MS-SSIM optimized model; \n--metric, evaluate quality in terms of PSNR or MS-SSIM; \n--l, lambda value; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216270093103228,
        0.8536454708417429
      ],
      "excerpt": "For example: \npython OpenDVC_test_P-frame.py --ref BasketballPass_com/f001.png --raw BasketballPass/f002.png --com BasketballPass_com/f002.png --bin BasketballPass_bin/002.bin --mode PSNR  --metric PSNR --l 1024 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216270093103228,
        0.8470800933637316,
        0.8535594533541048
      ],
      "excerpt": "For example: \npython OpenDVC_test_P-frame_decoder.py --ref BasketballPass_com/f001.png --bin BasketballPass_bin/002.bin --com BasketballPass_com/f002.png  --mode PSNR --l 1024 \nDownload the training data. We train the models on the Vimeo90k dataset (Download link) (82G). After downloading, please run the following codes to generate \"folder.npy\" which contains the directories of all training samples. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8102780086823556
      ],
      "excerpt": "    result = [] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8958964778353483
      ],
      "excerpt": "np.save('folder.npy', folder) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9117295849848807,
        0.9047261165158212,
        0.8221410740428703,
        0.9419402168114301,
        0.9246227682586091
      ],
      "excerpt": "python path_to_CA_model/encode.py --model_type 1 --input_path im1.png --compressed_file_path im1_level5.bin --quality_level 5 \npython path_to_CA_model/decode.py --compressed_file_path im1_level5.bin --recon_path im1_level5_ssim.png \nDownload the pre-trained models of optical flow. Download the folder \"motion_flow\" (Download link) to the same directory as the codes. \nRun OpenDVC_train_PSNR.py to train the PSNR models, e.g., \npython OpenDVC_train_PSNR.py --l 1024 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8407727034036028
      ],
      "excerpt": "python OpenDVC_train_MS-SSIM.py --l 32 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/RenYang-home/OpenDVC/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\n\\nCopyright (c) 2020, Ren Yang\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n3. Neither the name of the copyright holder nor the names of its\\n   contributors may be used to endorse or promote products derived from\\n   this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "OpenDVC -- An open source implementation of the DVC Video Compression Method",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "OpenDVC",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "RenYang-home",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RenYang-home/OpenDVC/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Tensorflow 1.12\n\n- Tensorflow-compression 1.0 ([Download link](https://github.com/tensorflow/compression/releases/tag/v1.0))\n\n  (*After downloading, put the folder \"tensorflow_compression\" to the same directory as the codes.*)\n\n- Pre-trained models ([Download link](https://drive.google.com/drive/folders/1gUkf9FNjiZw6Pcr5U_bl3jgbM1_ZpB2K?usp=sharing))\n\n  (*Download the folder \"OpenDVC_model\" to the same directory as the codes.*)\n\n- BPG ([Download link](https://bellard.org/bpg/))  -- needed only for the PSNR models\n\n  (*In our PSNR model, we use BPG to compress I-frames instead of training learned image compression models.*)\n\n- Context-adaptive image compression model, Lee et al., ICLR 2019 ([Paper](https://arxiv.org/abs/1809.10452), [Model](https://github.com/JooyoungLeeETRI/CA_Entropy_Model)) -- needed only for the MS-SSIM models\n\n  (*In our MS-SSIM model, we use Lee et al., ICLR 2019 to compress I-frames.*)\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 125,
      "date": "Wed, 29 Dec 2021 04:08:23 GMT"
    },
    "technique": "GitHub API"
  }
}
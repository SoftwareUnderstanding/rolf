{
  "citation": [
    {
      "confidence": [
        0.9806932018241261,
        0.9977994744046882
      ],
      "excerpt": "SVRG paper : https://papers.nips.cc/paper/4937-accelerating-stochastic-gradient-descent-using-predictive-variance-reduction.pdf \nSAGA paper : https://arxiv.org/pdf/1407.0202.pdf \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kilianFatras/variance_reduced_neural_networks",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-11-22T06:40:40Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-04T10:35:33Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8861337016896279,
        0.9536192351817234,
        0.9796065098986384
      ],
      "excerpt": "Stochastic gradient (SGD) is the most used optimization algorithm to backpropagate through neural networks because it has a smaller cost than gradient descent. However, it has a very slow convergence rate and it needs to have a decreasing learning rate to converge. \nIn 2013 and 2014, two new 'hybrid algorithms' came out. Stochastic Variance Reduced Gradient (SVRG) and Stochatic Average Gradient Augmented (SAGA) are hybrids because they use an unbiaised estimate of the gradient but they have a vanishing variance. These 2 algorithms have an exponentiel convergence speed. While their behaviour is weel known for machine learning purpose, they are not used for deep learning topics. For instance, you can now use SAGA in the scikit learn library (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) \nFor this project, I wanted to code these algorithms for deep learning purpose. I have coded these algorithms with the PyTorch framework. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8786545791953133,
        0.9529120138242481
      ],
      "excerpt": "This code is written in Python3 and I used jupyter notebook. You will need to download the following libraries : numpy, PyTorch, matplotlib, copy and time. Note that I tested my code on the CIFAR10 dataset :). I also tried it for MNIST and SVRG worked fine. \nCurrently, SAGA works for a batch of size 1. An extension would be to adapt it for any batch size. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation of SVRG and SAGA optimization algorithms for deep learning topics.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kilianFatras/variance_reduced_neural_networks/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 17,
      "date": "Thu, 23 Dec 2021 17:57:09 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kilianFatras/variance_reduced_neural_networks/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "kilianFatras/variance_reduced_neural_networks",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/kilianFatras/variance_reduced_neural_networks/master/SVRG.ipynb",
      "https://raw.githubusercontent.com/kilianFatras/variance_reduced_neural_networks/master/optimization_algorithms_convex_case.ipynb",
      "https://raw.githubusercontent.com/kilianFatras/variance_reduced_neural_networks/master/SAGA.ipynb",
      "https://raw.githubusercontent.com/kilianFatras/variance_reduced_neural_networks/master/SGD.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9375421665693383
      ],
      "excerpt": "This code is written in Python3 and I used jupyter notebook. You will need to download the following libraries : numpy, PyTorch, matplotlib, copy and time. Note that I tested my code on the CIFAR10 dataset :). I also tried it for MNIST and SVRG worked fine. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.907799906975263
      ],
      "excerpt": "To start with PyTorch : http://pytorch.org/tutorials/ \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8587476985249702
      ],
      "excerpt": "Usage :  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kilianFatras/variance_reduced_neural_networks/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Stochastic variance reduced algorithms : Implementation of SVRG and SAGA optimization algorithms for deep learning.",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "variance_reduced_neural_networks",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "kilianFatras",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kilianFatras/variance_reduced_neural_networks/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 48,
      "date": "Thu, 23 Dec 2021 17:57:09 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2111.01264",
      "https://arxiv.org/abs/1602.01783",
      "https://arxiv.org/abs/2106.05449"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{daley2021human,\n  title={Human-Level Control without Server-Grade Hardware},\n  author={Daley, Brett and Amato, Christopher},\n  journal={arXiv preprint arXiv:2106.05449},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "Synchronized Multi-Threaded Execution. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/brett-daley/fast-dqn",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-30T01:02:41Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-10T18:42:02Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8825692832131153,
        0.8584155137135203,
        0.9000805325363248,
        0.9876855902541544,
        0.9813420561309143,
        0.8124138816193528
      ],
      "excerpt": "was a landmark achievement for reinforcement learning (RL) by generating human-level policies for playing Atari games directly from pixels and a reward signal. \nAlthough first published back in 2015, DQN still requires an enormous amount of computation to fully replicate the original results on all 49 games. \nThis code provides a modified DQN implementation whose speed is optimized for multi-core, single-GPU computers. \nThe goal of this project is to promote access to deep RL by providing a fast and well-tested DQN baseline that does not require large server clusters to be feasible. \nFor more details, see the accompanying paper: \nHuman-Level Control without Server-Grade Hardware. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8600366785504484
      ],
      "excerpt": "Generally speaking, the number of samplers should match the number of threads available on your CPU for the best performance. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.952382972606582
      ],
      "excerpt": "Currently, the code has some hardcoded assumptions that restrict it to playing Atari games only. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8543787153867232,
        0.8542690416176831
      ],
      "excerpt": "Make sure to also adjust any data preprocessing, etc., elsewhere in the code as needed. \nWe also include a reference DQN implementation that follows identical experiment procedures to the DeepMind Nature paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8038504063891423,
        0.8677690421614916
      ],
      "excerpt": "Note that this command is not equivalent to \nrun_fast_dqn.py with 1 worker and concurrency/synchronization disabled (due to how the worker temporarily buffers experiences). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.822016995572795,
        0.8508004234951537
      ],
      "excerpt": "either the CPU or GPU is idle at any given time. \nThe implementation here introduces two major changes to resolve this. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8208269014898286
      ],
      "excerpt": "As done by many deep RL methods like \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9200676805361148
      ],
      "excerpt": "Our implementation executes threads synchronously and batches their Q-value predictions together to utilize the GPU more efficiently. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A concurrent/synchronized DQN implementation optimized for multi-CPU, single-GPU systems.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/brett-daley/fast-dqn/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 03:42:57 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/brett-daley/fast-dqn/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "brett-daley/fast-dqn",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The code is based on Python 3.5+ and TensorFlow 2.\n\nTo get started, clone this repository and install the required packages:\n\n```\ngit clone https://github.com/brett-daley/fast-dqn.git\ncd fast-dqn\npip install -r requirements.txt\n```\n\nMake sure that appropriate versions of CUDA and cuDNN are also installed to enable\n[TensorFlow with GPU support](https://www.tensorflow.org/install/gpu).\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8575148957315478
      ],
      "excerpt": "To get a list of all available games, run the following in a Python script: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8264233734935511
      ],
      "excerpt": "When the CPU is updating the environment, the GPU can be processing the training minibatches. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python run_fast_dqn.py --game=pong --workers=8 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import atari_py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python run_dqn.py --game=pong \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": "Concurrent Training. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/brett-daley/fast-dqn/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Brett Daley\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Human-Level Control without Server-Grade Hardware",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "fast-dqn",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "brett-daley",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/brett-daley/fast-dqn/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "brett-daley",
        "body": "Initial implementation of Fast DQN with concurrent training and synchronized execution.\r\n\r\nThis code was used for all experiments in the ICLR 2022 paper submission.",
        "dateCreated": "2021-09-29T01:39:12Z",
        "datePublished": "2021-10-12T19:57:05Z",
        "html_url": "https://github.com/brett-daley/fast-dqn/releases/tag/iclr-2022-submission",
        "name": "ICLR 2022 Submission",
        "tag_name": "iclr-2022-submission",
        "tarball_url": "https://api.github.com/repos/brett-daley/fast-dqn/tarball/iclr-2022-submission",
        "url": "https://api.github.com/repos/brett-daley/fast-dqn/releases/51237019",
        "zipball_url": "https://api.github.com/repos/brett-daley/fast-dqn/zipball/iclr-2022-submission"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Fri, 24 Dec 2021 03:42:57 GMT"
    },
    "technique": "GitHub API"
  }
}
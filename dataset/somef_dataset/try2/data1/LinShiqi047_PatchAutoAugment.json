{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2103.11099",
      "https://arxiv.org/abs/2103.11099"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please cite us if you find this work helps.\n```\n@article{lin2021patch,\n  title={Patch AutoAugment},\n  author={Lin, Shiqi and Yu, Tao and Feng, Ruoyu and Chen, Zhibo},\n  journal={arXiv preprint arXiv:2103.11099},\n  year={2021}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{lin2021patch,\n  title={Patch AutoAugment},\n  author={Lin, Shiqi and Yu, Tao and Feng, Ruoyu and Chen, Zhibo},\n  journal={arXiv preprint arXiv:2103.11099},\n  year={2021}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/LinShiqi047/PatchAutoAugment",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-20T01:47:31Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-07T07:07:57Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Data augmentation (DA) plays a critical role in improving the generalization of deep learning models. Recent works on automatically searching for DA policies from data have achieved great success. However, existing automated DA methods generally perform the search at the image level, which limits the exploration of diversity in local regions. In this paper, we propose a more fine-grained automated DA approach, dubbed Patch AutoAugment, to divide an image into a grid of patches and search for the joint optimal augmentation policies for the patches. We formulate it as a multi-agent reinforcement learning (MARL) problem, where each agent learns an augmentation policy for each patch based on its content together with the semantics of the whole image. The agents cooperate with each other to achieve the optimal augmentation effect of the entire image by sharing a team reward. We show the effectiveness of our method on multiple benchmark datasets of image classification and fine-grained image recognition (e.g., CIFAR-10, CIFAR-100, ImageNet, CUB-200-2011, Stanford Cars and FGVC-Aircraft). Extensive experiments demonstrate that our method outperforms the state-of-the-art DA methods while requiring fewer computational resources.\n<div align=center> <img src=https://github.com/LinShiqi047/PatchAutoAugment/blob/main/figure/PAA.png /> </div>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9631013033727219,
        0.9892784804458042
      ],
      "excerpt": "This is the official implementation of Local Patch AutoAugment with Multi-Agent Collaboration. \nPatch AutoAugment (PAA) learns the optimal augmentation policies for different regions of an image and achieving the joint optimal on the whole image. We are working with the official Kornia team to integrate PAA into Kornia package. The Kornia-build-in PAA is coming soon. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "PyTorch implementation of PatchAutoAugment",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/LinShiqi047/PatchAutoAugment/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Thu, 23 Dec 2021 16:39:48 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/LinShiqi047/PatchAutoAugment/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "LinShiqi047/PatchAutoAugment",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/LinShiqi047/PatchAutoAugment/main/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Here, we take CIFAR and fine-grained datasets [CUB-200-2011](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html), [Stanford Dogs](http://vision.stanford.edu/aditya86/ImageNetDogs/) to illustrate how to use our PatchAutoAugment.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "This project is run on GPU (NVIDIA 2TX 2080Ti).\nWe conduct experiments under python 3.8, pytorch 1.6.0, cuda 10.1 and cudnn7. \nYou can download [dockerfile](https://github.com/LinShiqi047/PatchAutoAugment/blob/main/Dockerfile).\nWe use [Kornia](https://github.com/kornia/kornia), a differentiable computer vision library that can be used to accelerate augmentation operations on tensors.\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8170342077060574
      ],
      "excerpt": "<div align=center> <img src=https://github.com/LinShiqi047/PatchAutoAugment/blob/main/figure/imagelevel_v.s_patchlevel.jpg width=600 height=350 /> </div> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/LinShiqi047/PatchAutoAugment/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Local Patch AutoAugment with Multi-Agent Collaboration",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "PatchAutoAugment",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "LinShiqi047",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/LinShiqi047/PatchAutoAugment/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 20,
      "date": "Thu, 23 Dec 2021 16:39:48 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "First, import PAA module.\n```\nfrom augs.PAA import *   \nfrom augs.A2Cmodel import ActorCritic\n```\nThen, \n```\nif args.aug == 'PAA':\n        model_a2c = ActorCritic(len(ops)).cuda()\n        optimizer_a2c = torch.optim.SGD(model_a2c.parameters(), hyper_params['lr_a2c'], \n                                    momentum=0.9, nesterov=True,\n                                    weight_decay=1e-4)\n        scheduler_a2c = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_a2c, len(train_loader)* hyper_params['epochs'])\n```\nThirdly, \n```\nif args.aug == 'PAA':\n    losses_a2c = AverageMeter()\n    model_a2c.train()\n\n    \n    for i, (input, target) in enumerate(train_loader):\n        target = target.cuda(non_blocking=True)\n        input = input.cuda(non_blocking=True)\n\n        if args.aug == 'PAA':\n            #: patch data augmentation\n            operations ,operation_logprob , operation_entropy , state_value = \\\n                rl_choose_action(input, model_a2c)\n            input_aug = patch_auto_augment(input, operations, args.batch_size, epochs=hyper_params['epochs'], epoch=epoch)\n\n            output = model(input_aug.detach())\n            loss = criterion(output, target)\n\n            #: PAA loss\n            reward = loss.detach()\n            loss_a2c = a2closs(operation_logprob, operation_entropy, state_value, reward)\n\n            #: update PAA model\n            optimizer_a2c.zero_grad()\n            loss_a2c.backward()\n            optimizer_a2c.step()\n            scheduler_a2c.step()\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "For example, train Wide-ResNet-28-10, PyramidNet+ShakeDrop on CIFAR-10 \n```\npython /code/CIFAR/train.py --dataset cifar10 --model WRN --aug PAA\npython /code/CIFAR/train.py --dataset cifar10 --model SD --aug PAA --lr_a2c 0.0001\n```\nSome available options:\n- ```--dataset```: Training and testing dataset, support cifar10 | cifar100\n- ```--batch-size```: Batch size\n- ```--model```: Target training network, support Wide-ResNet-28-10 (WRN) | ShakeShake (SS) | PyramidNet+ShakeDrop (SD)\n- ```--SS_w_base```: ShakeShake (26 2x32d) | SS (26 2x96d) | SS (26 2x112d)\n- ```--aug```: Augmentation method, support baseline (base), Cutout (cutout), AutoAugment+Cutout (AA), AutoAugment (onlyAA), PatchAutoAugment (PAA)\n- ```--lr_a2c```: PAA learning rate, default = 1e-3\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "For example, train ResNet-50 (pretrained) on Stanford Dogs\n```\npython /code/Fine_grained_dataset/tools/train.py --cfg /code/DOG/experiments/cls_res50.yaml --AUG PAA --N_GRID 4 --DATASET dog --IMAGE_SIZE 224 --EPOCHS 50 --BATCH_SIZE 32\n```\nSome available options:\n- ```--AUG```: Augmentation method, support baseline (base), AutoAugment (AA), PatchAutoAugment (PAA)\n- ```--N_GRID```: Number of patches, support 1 | 2 | 4 | 7 | 14.\n- ```--DATASET```: Training and testing dataset, CUB-200-2011 (cub) | Stanford Dogs (dog).\n- ```--IMAGE_SIZE```: Image size, support 224 | 448.\n- ```--EPOCHS```: Training epochs.\n- ```--BATCH_SIZE```: Batch size.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Further, we use the [PatchSequential](https://github.com/kornia/kornia/blob/master/kornia/augmentation/container/patch.py) in [Kornia](https://github.com/kornia/kornia) to implement PAA.\n```\npython /code/Kornia_PAA/tools/train.py --cfg /code/DOG/experiments/cls_res50.yaml --AUG PAA --N_GRID 2 --DATASET dog --IMAGE_SIZE 224 --EPOCHS 50 --BATCH_SIZE 32\n```\n\nThe Kornia-build-in PAA is coming soon.\n\n<!-- ",
      "technique": "Header extraction"
    }
  ]
}
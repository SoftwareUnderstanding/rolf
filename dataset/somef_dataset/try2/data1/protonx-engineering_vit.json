{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2010.11929"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8755077570994062
      ],
      "excerpt": "Github: bangoc123 and tiena2cva \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/protonx-engineering/vit",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-09T07:13:06Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-17T10:57:32Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9816135314152117
      ],
      "excerpt": "Our implementation of paper: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale, using tensorflow 2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Our implementation for paper: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/protonx-engineering/vit/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 18:43:38 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/protonx-engineering/vit/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "protonx-engineering/vit",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/protonx-engineering/vit/tree/main/docs"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Create 2 folders `train` and `validation` in the `data` folder (which was created already). Then `Please copy` your images with the corresponding names into these folders.\n\n- `train` folder was used for the training process\n- `validation` folder was used for validating training result after each epoch\n\nThis library use `image_dataset_from_directory` API from `Tensorflow 2.0` to load images. Make sure you have some understanding of how it works via [its document](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory).\n\nStructure of these folders.\n\n```\nmain_directory/\n...class_a/\n......a_image_1.jpg\n......a_image_2.jpg\n...class_b/\n......b_image_1.jpg\n......b_image_2.jpg\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Make sure you have installed Miniconda. If not yet, see the setup document [here](https://conda.io/en/latest/user-guide/install/index.html#regular-installation).\n\n2. Clone this repository: `git clone https://github.com/bangoc123/vit`\n3. `cd` into `vit` and install dependencies package: `pip install -r requirements.txt`\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9356142157017944
      ],
      "excerpt": "python predict.py --test-image ${test_image_path} \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/protonx-engineering/vit/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Vision transformer",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "vit",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "protonx-engineering",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/protonx-engineering/vit/blob/main/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We create `train.py` for training model.\n\n```\nusage: train.py [-h] [--model MODEL] [--num-classes CLASSES]\n                [--patch-size PATH_SIZE] [--num-heads NUM_HEADS]\n                [--att-size ATT_SIZE] [--num-layer NUM_LAYER]\n                [--mlp-size MLP_SIZE] [--lr LR] [--weight-decay WEIGHT_DECAY]\n                [--batch-size BATCH_SIZE] [--epochs EPOCHS]\n                [--image-size IMAGE_SIZE] [--image-channels IMAGE_CHANNELS]\n                [--train-folder TRAIN_FOLDER] [--valid-folder VALID_FOLDER]\n                [--model-folder MODEL_FOLDER]\n\noptional arguments:\n  -h, --help            \n    show this help message and exit\n\n  --model MODEL       \n    Type of ViT model, valid option: custom, base, large, huge\n\n  --num-classes CLASSES     \n    Number of classes\n  \n  --patch-size PATH_SIZE\n    Size of image patch\n  \n  --num-heads NUM_HEADS\n    Number of attention heads\n  \n  --att-size ATT_SIZE   \n    Size of each attention head for value\n  \n  --num-layer NUM_LAYER\n    Number of attention layer\n  \n  --mlp-size MLP_SIZE   \n    Size of hidden layer in MLP block\n  \n  --lr LR               \n    Learning rate\n  \n  --batch-size BATCH_SIZE\n    Batch size\n  \n  --epochs EPOCHS       \n    Number of training epoch\n  \n  --image-size IMAGE_SIZE\n    Size of input image\n  \n  --image-channels IMAGE_CHANNELS\n    Number channel of input image\n  \n  --train-folder TRAIN_FOLDER\n    Where training data is located\n  \n  --valid-folder VALID_FOLDER\n    Where validation data is located\n  \n  --model-folder MODEL_FOLDER\n    Folder to save trained model\n```\n\nThere are some `important` arguments for the script you should consider when running it:\n\n- `train-folder`: The folder of training images. If you not specify this argument, the script will use the CIFAR-10 dataset for training.\n- `valid-folder`: The folder of validation images\n- `num-classes`: The number of your problem classes.\n- `batch-size`: The batch size of the dataset\n- `lr`: The learning rate of Adam Optimizer\n- `model-folder`: Where the model after training saved\n- `model`: The type of model you want to train. If you want to train with `base` or `large` or `huge` model, you need to specify `patch-size`, `num-heads`, `att-size` and `mlp-size` argument.\n\nExample:\n\nYou want to train a model in 10 epochs with CIFAR-10 dataset:\n\n```bash\n!python train.py --train-folder ${train_folder} --valid-folder ${valid_folder} --num-classes 2 --patch-size 5 --image-size 150 --lr 0.0001 --epochs 200 --num-heads 12 \n```\n\nAfter training successfully, your model will be saved to `model-folder` defined before\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 10,
      "date": "Wed, 29 Dec 2021 18:43:38 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "tensorflow2"
    ],
    "technique": "GitHub API"
  }
}
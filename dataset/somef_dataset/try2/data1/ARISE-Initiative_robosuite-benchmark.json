{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1812.05905"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ARISE-Initiative/robosuite-benchmark",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-09-21T18:31:31Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T07:34:03Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9965308539143477
      ],
      "excerpt": "Welcome to the robosuite v1.0 benchmarking repository! This repo is intended for ease of replication of our benchmarking results, as well as providing a skeleton for further experiments or benchmarking using our identical training environment. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Benchmarking Repository for robosuite + SAC",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ARISE-Initiative/robosuite-benchmark/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "For any problems encountered when running this repo, please submit an issue!\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 10,
      "date": "Thu, 30 Dec 2021 04:52:44 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ARISE-Initiative/robosuite-benchmark/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ARISE-Initiative/robosuite-benchmark",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ARISE-Initiative/robosuite-benchmark/master/notebooks/create_plots.ipynb",
      "https://raw.githubusercontent.com/ARISE-Initiative/robosuite-benchmark/master/notebooks/create_benchmark_environments.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ARISE-Initiative/robosuite-benchmark/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "robosuite v1.0 Benchmarking",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "robosuite-benchmark",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ARISE-Initiative",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ARISE-Initiative/robosuite-benchmark/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To validate our results on your own machine, or to experiment with another set of hyperparameters, we provide a [training script](scripts/train.py) as an easy entry point for executing individual experiments. Note that this repository must be added to your `PYTHONPATH` before running any scripts; this can be done like so:\n\n```bash\n$ (rb_bench) cd <PATH_TO_YOUR_ROBOSUITE_BENCHMARKING_REPO_DIR>\n$ (rb_bench) export PYTHONPATH=.:$PYTHONPATH\n```\n\nFor a given training run, a configuration must be specified -- this can be done in one of two ways:\n\n1. **Command line arguments.** It may be useful to specify your desired configuration on the fly, from the command line. However, as there are many potential arguments that can be provided for training, we have modularized and organized them within a separate [arguments](util/arguments.py) module that describes all potential arguments for a given script. Note that for this training script, the `robosuite`, `agent`, and `training_args` are relevant here. Note that there are default values already specified for most of these values.\n\n2. **Configuration files.** It is often more succinct and efficient to specify a configuration file (`.json`), and load this during runtime for training. If the `--variant` argument is specified, the configuration will be loaded and used for training. In this case, the resulting script execution line will look like so:\n\n```bash\n$ (rb_bench) python scripts/train.py --variant <PATH_TO_CONFIG>.json\n```\n\nThis is also a useful method for automatically validating our benchmarking experiments on your own machine, as every experiment's configuration is saved and provided on this repo. For an example of the structure and values expected within a given configuration file, please see [this example](runs/Door-Panda-OSC-POSE-SEED17/Door_Panda_OSC_POSE_SEED17_2020_09_13_00_26_44_0000--s-0/variant.json).\n\nNote that, by default, all training runs are stored in `log/runs/` directory, though this location may be changed by setting a different file location with the `--log_dir` flag.\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 22,
      "date": "Thu, 30 Dec 2021 04:52:44 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Our benchmark consists of training [Soft Actor-Critic](https://arxiv.org/abs/1812.05905) agents implemented from [rlkit](https://github.com/vitchyr/rlkit). We built on top of rlkit's standard functionality to provide extra features useful for our purposes, such as video recording of rollouts and asymmetrical exploration / evaluation horizons.\n\nTo begin, start by cloning this repository from your terminal and moving into this directory:\n```bash\n$ git clone https://github.com/ARISE-Initiative/robosuite-benchmark.git\n$ cd robosuite-benchmark\n```\n\nOur benchmarking environment consists of a Conda-based Python virtual environment running Python 3.7.4, and is supported for Mac OS X and Linux. Other versions / machine configurations have not been tested. [Conda](https://docs.conda.io/en/latest/) is a useful tool for creating virtual environments for Python, and can be installed [here](https://docs.conda.io/projects/conda/en/latest/user-guide/install/).\n\nAfter installing Conda, create a new virtual environment using our pre-configured environment setup, and activate this environment. Note that we have to unfortunately do a two-step installation process in order to avoid some issues with precise versions:\n\n```bash\n$ conda env create -f environments/rb_bench_[linux/mac]_env.yml\n$ source activate rb_bench\n$ pip install -r requirements.txt\n```\n\nNext, we must install rlkit. Go the the [rlkit](https://github.com/vitchyr/rlkit) repository and clone and install it, in your preferred directory. Note that we currently require a specific rlkit version as the current release is incompatible with our repo:\n```bash\n$ (rb_bench) cd <PATH_TO_YOUR_RLKIT_LOCATION>\n$ (rb_bench) git clone https://github.com/rail-berkeley/rlkit.git\n$ (rb_bench) cd rlkit\n$ (rb_bench) git reset --hard b7f97b2463df1c5a1ecd2d293cfcc7a4971dd0ab\n$ (rb_bench) pip install -e .\n```\n\nLastly, for visualizing active runs, we utilize rlkit's extraction of [rllab](https://github.com/rll/rllab)'s [viskit](https://github.com/vitchyr/viskit) package:\n```bash\n$ (rb_bench) cd <PATH_TO_YOUR_VISKIT_LOCATION>\n$ (rb_bench) git clone https://github.com/vitchyr/viskit.git\n$ (rb_bench) cd viskit\n$ (rb_bench) pip install -e .\n\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
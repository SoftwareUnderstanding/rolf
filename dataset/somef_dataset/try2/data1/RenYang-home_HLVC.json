{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2006.13560",
      "https://arxiv.org/abs/2006.15862",
      "https://arxiv.org/abs/2003.01966",
      "https://arxiv.org/abs/1809.10452"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{yang2020Learning,\n  title={Learning for Video Compression with Hierarchical Quality and Recurrent Enhancement},\n  author={Yang, Ren and Mentzer, Fabian and Van Gool, Luc and Timofte, Radu},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n  year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9999999998796625,
        0.9997739683644092
      ],
      "excerpt": "Ren Yang, Fabian Mentzer, Luc Van Gool and Radu Timofte, \"Learning for Video Compression with Hierarchical Quality and Recurrent Enhancement\", in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020. [Paper].  \nIf our paper and codes are useful for your research, please cite: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.9733008541963115
      ],
      "excerpt": "Ren Yang @ ETH Zurich, Switzerland    \nEmail: ren.yang@vision.ee.ethz.ch \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RenYang-home/HLVC",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-29T20:21:43Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-16T08:00:31Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "![ ](Figures/Introduction.png)\n\nThis paper proposes a Hierarchical Learned Video Compression (HLVC) method with three hierarchical quality layers and a recurrent enhancement network. As illustrated in Figure 1, the frames in layers 1, 2 and 3 are compressed with the highest, medium and the lowest quality, respectively. The benefits of hierarchical quality are two-fold: First, the high quality frames, which provide high quality references, are able to improve the compression performance of other frames at the encoder side; Second, because of the high correlation among neighboring frames, at the decoder side, the low quality frames can be enhanced by making use of the advantageous information in high quality frames. The enhancement improves quality without bit-rate overhead, thus improving the rate-distortion performance. For example, the frames 3 and 8 in Figure 1, which belong to layer 3, are compressed with low quality and bit-rate. Then, our recurrent enhancement network significantly improves their quality, taking advantage of higher quality frames, e.g., frames 0 and 5. As a result, the frames 3 and 8 reach comparable quality to frame 5 in layer 2, but consume much less bit-rate. Therefore, our HLVC approach achieves efficient video compression.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9773027360242977
      ],
      "excerpt": "The project page for the paper: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8774540660757398
      ],
      "excerpt": "We provide the codes for compressing video frame in various manners, i.e., \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8528653510021645
      ],
      "excerpt": "HLVC_layer3_BP-frame(_decoder).py -- BP-frames combination with low quality (layer 3), using the \"single frame\" strategy. It includes the compression of medium-distance P-frame and short-distance B-frame. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9077176486456713
      ],
      "excerpt": "We also provide the demo codes for compress a video sequence, i.e.,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9915675533364244
      ],
      "excerpt": "Note that, our HLVC codes currently only support the frames with the height and width as the multiples of 16. Therefore, when using these codes, if the height and width of frames are not the multiples of 16, please first crop frames, e.g., \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9517044795740106
      ],
      "excerpt": "The WRQE enhancement network cannot be applied to a single frame, since it contains bi-directional recurrent cells. Please refer to the video compression in the following for the enhancement network WRQE. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8157839562445641
      ],
      "excerpt": "--raw, the raw frame to be compressed. (only in the encoder) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9034709364552593
      ],
      "excerpt": "--l, the lambda value. For layer 2, l = 32, 64, 128 and 256 for MS-SSIM, and l = 1024, 2048, 4096 and 8192 for PSNR. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8035611178743056
      ],
      "excerpt": "Similar to HLVC_layer2_P-frame(_decoder).py but needs two reference frames. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8765810237326833
      ],
      "excerpt": "The same network as HLVC_layer2_P-frame(_decoder).py. Since we use BPG to compressed I-frames for the PSNR model and BPG has different distortion features from learned compressed, we train two PSNR models for the Layer 3 frames near from Layer 1 (I-frames) and near from layer 2. That is, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.904877043509607
      ],
      "excerpt": "For example, in Figure 1, the frames 1, 2, 8 and 9 are near layer 1 and the frames 3, 4, 6 and 7 are near layer 2. Note that, for layer 3, lambda = 8, 16, 32 and 64 for MS-SSIM, and lambda = 256, 512, 1024 and 2048 for PSNR. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9914743384494034
      ],
      "excerpt": "The combination of short distance B- and P-frames, using the \"single motion\" strategy proposed in Section 3.3 of our paper.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9224373526164792,
        0.9272797684604343,
        0.803351893805737,
        0.803351893805737
      ],
      "excerpt": "--raw_1, the raw frame (next to reference) to be compressed. (only in the encoder) \n--raw_2, the raw frame (next to --raw_1) to be compressed. (only in the encoder) \n--com_1, the path to save the compressed/decompressed frame of --raw_1. \n--com_2, the path to save the compressed/decompressed frame of --raw_2. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8861689846209259
      ],
      "excerpt": "--nearlayer, the same as that in HLVC_layer3_P-frame(_decoder).py. (only for PSNR models) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8658168591607555
      ],
      "excerpt": "--l, the lambda value. For layer 3, l = 8, 16, 32 and 64 for MS-SSIM, and l = 256, 512, 1024 and 2048 for PSNR. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9888172791047969
      ],
      "excerpt": "We provide two demo codes for compressing a video sequence. In HLVC_video_fast.py, the B-frames are used for layer 2 and the BP-frames combination is used for layer 3. In HLVC_video_slow, we try different networks for compresseing layers 2 and 3 in an exhaustive manner, and select the best performed network. This way, the performance can be improved at the cost of higher complexity. To compare two compression networks, in the case of Quality_2 - Quality_1 > 0 and bpp_2 - bpp_1 > 0, if (Quality_2 - Quality_1)/(bpp_2 - bpp_1) > threshold, the 2nd network is considered as the better one. We empirically set the threshold as 10 for PSNR (dB) and 0.1 for MS-SSIM index.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8435583296186886,
        0.8261257208444185
      ],
      "excerpt": "--CA_model_path, the path to CA_EntropyModel_Test of Lee et al., ICLR 2019 (only used for MS-SSIM model); \n--l, lambda value. l = 256, 512, 1024 and 2048 for PSNR, and l = 8, 16, 32 and 64 for MS-SSIM; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9107260302361604
      ],
      "excerpt": "Notice: Although WRQE shoule be at the decoder side, we also add it to the encoder in this demo to make users easier to get the complete results. The compressed frames before WRQE will be stored as ./(output_path)/frames_beforeWRQE/fxxx.png, and the output after WRQE (if enabled) will be stored as ./(output_path)/frames_HLVC/fxxx.png, which is the final result of the HLVC approach. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8435583296186886,
        0.8261257208444185
      ],
      "excerpt": "--CA_model_path, the path to CA_EntropyModel_Test of Lee et al., ICLR 2019 (only used for MS-SSIM model); \n--l, lambda value. l = 256, 512, 1024 and 2048 for PSNR, and l = 8, 16, 32 and 64 for MS-SSIM; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9369732888432212,
        0.9566977270906971
      ],
      "excerpt": "We test our HLVC approach on the JCT-VC (Classes B, C and D) and the UVG datasets. Among them, the UVG and JCT-VC Class B are high resolution (1920 x 1080) datasets, and the JCT-VC Classes C and D have resolutions of 832 x 480 and 416 x 240, respectively. For a fair comparison with Lu et al., DVC, we follow Lu et al., DVC to test JCT-VC videos on the first 100 frames, and test UVG videos on all frames. Note that, the UVG dataset has been enlarged recently. To compare with previous approaches, we only test on the original 7 videos in UVG, i.e., Beauty, Bosphorus, HoneyBee, Jockey, ReadySetGo, ShakeNDry and YachtRide. \nIn our approach, the entropy model requires each dimension to be a multiple of 16, and therefore we crop the 1920 x 1080 videos to 1920 x 1072 by cutting the bottom 8 pixels, using the following command. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.903516491642198
      ],
      "excerpt": "We calculate the Bj\u00f8ntegaard-Delta Bit-Rate (BDBR) values with the anchor of x265 LDP very fast, which is implemented by the following command with Quality = 15, 19, 23, 27 for the JCT-VC dataset, and Quality = 11, 15, 19, 23 for UVG videos (to make the bit-rate range reasonable for comparison). \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RenYang-home/HLVC/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 16,
      "date": "Mon, 27 Dec 2021 17:56:50 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/RenYang-home/HLVC/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "RenYang-home/HLVC",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8800128043939355
      ],
      "excerpt": "--com, the path to save the compressed/decompressed frame. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8839116612712498
      ],
      "excerpt": "ffmpeg -pix_fmt yuv420p -s WidthxHeight -i Name.yuv -filter:v \"crop=1920:1072:0:0\" Name_crop.yuv \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8172034057683939
      ],
      "excerpt": "ffmpeg -pix_fmt yuv420p -s WidthxHeight -i Name.yuv -vframes Frame path_to_PNG/f%03d.png \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8226478957258798
      ],
      "excerpt": "We uploaded a prepared sequence BasketballPass here as a test demo, which contains the PNG files of the first 101 frames. Note that, ffmpeg generates frames starting from f001.png in the folder \"BasketballPass\", while in Figure 1, the frame index begins from 0. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8117162239886311,
        0.8357096974298381,
        0.8220206998335087
      ],
      "excerpt": "--bin, the path to save/read the compressed bitstream. \n--mode, select the PSNR/MS-SSIM optimized model. \n--l, the lambda value. For layer 2, l = 32, 64, 128 and 256 for MS-SSIM, and l = 1024, 2048, 4096 and 8192 for PSNR. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216270093103228,
        0.8476727353052346,
        0.8470800933637316
      ],
      "excerpt": "For example, \npython HLVC_layer2_P-frame.py --ref f001_com.png --raw f006.png --com f006_com.png --bin f006.bin --mode PSNR --l 4096 \npython HLVC_layer2_P-frame_decoder.py --ref f001_com.png --bin f006.bin --com f006_dec.png --mode PSNR --l 4096 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216270093103228,
        0.8409244845532599,
        0.8416761410458339
      ],
      "excerpt": "For example, \npython HLVC_layer2_B-frame.py --ref_1 f001_com.png --ref_2 f011_com.png --raw f006.png --com f006_com.png --bin f006.bin --mode PSNR --l 4096 \npython HLVC_layer2_B-frame_decoder.py --ref_1 f001_com.png --ref_2 f011_com.png --bin f006.bin --com f006_dec.png --mode PSNR --l 4096 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.835537099242559
      ],
      "excerpt": "parser.add_argument(\"--nearlayer\", type=int, default=1, choices=[1, 2]) #: not used in MS-SSIM models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8117162239886311
      ],
      "excerpt": "--bin, the path to save/read the compressed bitstream. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8357096974298381,
        0.8046584477441348
      ],
      "excerpt": "--mode, select the PSNR/MS-SSIM optimized model. \n--l, the lambda value. For layer 3, l = 8, 16, 32 and 64 for MS-SSIM, and l = 256, 512, 1024 and 2048 for PSNR. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216270093103228,
        0.8523948591645615,
        0.877200233380555
      ],
      "excerpt": "For example, \npython HLVC_layer3_BP-frame.py --ref f001_com.png --raw_1 f001.png --com_1 f001_com.png --raw_2 f002.png --com_2 f002_com.png --bin f001_002.bin --nearlayer 1 --mode PSNR --l 1024 \npython HLVC_layer3_BP-frame_decoder.py --ref f001_com.png --com_1 f001_com.png --com_2 f002_com.png --bin f001_002.bin --nearlayer 1 --mode PSNR --l 1024 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.836466371016978
      ],
      "excerpt": "--mode, PSNR or MS-SSIM; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216270093103228,
        0.8798018395768394
      ],
      "excerpt": "For example, \npython HLVC_video_fast/slow.py --path BasketballPass --frame 101 --mode PSNR --l 1024 --enh 1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8282168427983371,
        0.9336801098518991
      ],
      "excerpt": "os.system('mv result.png ' + path_com + 'f' + str(f + 1).zfill(3) + '.png') \n- HLVC_video_decoder.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.836466371016978
      ],
      "excerpt": "--mode, PSNR or MS-SSIM; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216270093103228,
        0.8797197900975243
      ],
      "excerpt": "For example, \npython HLVC_video_decoder.py --path_bin BasketballPass_com_slow_PSNR_1024 --path_raw BasketballPass --frame 101 --mode PSNR --l 1024 --enh 1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8958119171146303
      ],
      "excerpt": "ffmpeg -pix_fmt yuv420p -s WidthxHeight -r Framerate  -i  Name.yuv -vframes Frame -c:v libx265 -preset veryfast -tune zerolatency -x265-params \"crf=Quality:keyint=10:verbose=1\" Name.mkv \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/RenYang-home/HLVC/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\n\\nCopyright (c) 2020, Ren Yang\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n3. Neither the name of the copyright holder nor the names of its\\n   contributors may be used to endorse or promote products derived from\\n   this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Learning for Video Compression with Hierarchical Quality and Recurrent Enhancement",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "HLVC",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "RenYang-home",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RenYang-home/HLVC/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Tensorflow 1.12\n\n- Tensorflow-compression 1.0 ([Download link](https://github.com/tensorflow/compression/releases/tag/v1.0))\n\n  (*After downloading, put the folder \"tensorflow_compression\" to the same directory as the codes.*)\n\n- Pre-trained models ([Download link](https://data.vision.ee.ethz.ch/reyang/HLVC_model.zip))\n\n  (*Download the folder \"HLVC_model\" to the same directory as the codes.*)\n\n- BPG ([Download link](https://bellard.org/bpg/))  -- needed only for the PSNR model\n\n  (*In our PSNR model, we use BPG to compress I-frames instead of training learned image compression models.*)\n\n- Context-adaptive image compression model, Lee et al., ICLR 2019 ([Paper](https://arxiv.org/abs/1809.10452), [Model](https://github.com/JooyoungLeeETRI/CA_Entropy_Model)) -- needed only for the MS-SSIM model\n\n  (*In our MS-SSIM model, we use Lee et al., ICLR 2019 to compress I-frames.*)\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 98,
      "date": "Mon, 27 Dec 2021 17:56:50 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We would like to thank [EDSR](https://github.com/thstkdgus35/EDSR-PyTorch), [DRLN](https://github.com/saeed-anwar/DRLN), [DDet](https://github.com/ykshi/DDet), [Pytorch-ssim](https://github.com/Po-Hsun-Su/pytorch-ssim), [CBAM](https://github.com/Jongchan/attention-module), [CGD](https://github.com/HolmesShuan/Compact-Global-Descriptor) and [RealSR](https://github.com/Alan-xw/RealSR) for sharing their codes. Our methods are built on those inspiring works. We still borrow some ideas from [NTIRE2019](https://openaccess.thecvf.com/CVPR2019_workshops/CVPR2019_NTIRE) leading methods, such as [OANet](https://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Du_Orientation-Aware_Deep_Neural_Network_for_Real_Image_Super-Resolution_CVPRW_2019_paper.pdf) and [KPN](https://github.com/csjcai/RealSR). We appreciate the tremendous efforts of previous methods. \n\n",
      "technique": "Header extraction"
    }
  ],
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this repository useful, please cite:\n```\n@misc{AIM2020RealSR,\n  author = {Xiangyu He},\n  title = {AIM2020-RealSR},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/HolmesShuan/AIM2020-RealSR}},\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{AIM2020RealSR,\n  author = {Xiangyu He},\n  title = {AIM2020-RealSR},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/HolmesShuan/AIM2020-RealSR}},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": "    def init(self, clip_min=1.0, clip_max=10.0): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9848179726092176
      ],
      "excerpt": "--chop-size 600 600 600 600 --shave-size 100 100 10 10 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/HolmesShuan/AIM2020-Real-Super-Resolution",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-12T00:22:11Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-06T08:56:56Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9966980763537967,
        0.9517842206007752
      ],
      "excerpt": "Our solution to AIM2020 Real Image x2 Super-Resolution Challenge (co-organized with ECCV2020). SSIM Rank 3rd at the end of the Development phase (2020.7.10). We propose a new \"crop-ensemble\" and it is compatible with model-ensemble and self-ensemble to achieve higher performances. \nOur solution consists of four basic models (model ensemble): OADDet, Deep-OADDet, original EDSR and original DRLN. (further details in Training Scripts and Dataset).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9758686073357864
      ],
      "excerpt": "Our core modules of OADDets are heavily borrowed from DDet, Inception and OANet with minor improvements, such as fewer attention modules, skip connections and LeakyReLU. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8597024769910001
      ],
      "excerpt": ": For testing on 2080Ti \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8626402676140121
      ],
      "excerpt": "Our testset results can be found here (Google Drive). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9657604528149929
      ],
      "excerpt": "We release all our training scripts to help reproduce our results and hopefully, the following methods may benefit from our works. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9063076668659176,
        0.853723962135467,
        0.897374587600388,
        0.9502737028679948
      ],
      "excerpt": "I found that many photos in the training dataset are not pixel-wise aligned. Actually, there are different types of misalignment: camera shift, moving objects (e.x. trees, grass). \nHowever, looking at the dataset, I found that there are very large shifts in some crops. For example, 000012, 000016, 000018, 000021. \nThere is also a colour mismatch sometimes between LR and HR: for example 000022. \nit seems that the official dataset is unsatisfactory. Therefore, we manually washed x2/x3/x4 datasets to obtain three subsets. There are about 300 damaged image pairs in each original dataset. The washed datasets are now publicly available: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8783506484838536,
        0.9412797623462442
      ],
      "excerpt": "Though AIM2020 x2 dataset contains 19K real LR/HR pairs, our models still suffer from overfishing. In light of this, we use x3 LR/HR pairs to fine-tune x2 models. Specifically, we downsample x3 HR images to x2 size (i.e., HR_img.resize(H//3*2, W//3*2)), which generates a larger AIM x2 dataset with 37118 images, namely AIM_washed_Large.  \nThis setting contributes to better visualization results on hard samples. Left subfigure is only trained on x2 washed and right subfigure is trained on x2+x3. However, this training strategy results in a chromatism problem.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8945019044446825
      ],
      "excerpt": "To solve the noisy data problem, we propose a new loss function for CNN-based low-level computer vision tasks. As the name implies, ClipL1 Loss combines Clip function and L1 loss. self.clip_min sets the gradients of well-trained pixels to zeros and clip_max works as a noise filter.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8818344058267661
      ],
      "excerpt": "    #: data range [0, 255], for [0,1] please set clip_min to 1/255=0.003921. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9822708178093253
      ],
      "excerpt": "To alleviate the chromatism problem, we use self-ensemble and model ensemble at inference time. Left subfigure is ensembled and right subfigure is a single model baseline. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9361783728361806
      ],
      "excerpt": "We further propose a new ensemble method called crop-ensemble. The motivation is to hide the seam artifact caused by cropping input images: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9898695802546503
      ],
      "excerpt": "Please refer to model/__init__.py Line59 for more information. Different colors of boxes indicate different crop sizes. Small boxes cover the seams between predicted large image patches and vice versa. In our experiments, crop-ensemble noticeably improves the performance and the more the better!    \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Our solution to AIM2020 Real Image Super-Resolution Challenge (x2)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/HolmesShuan/AIM2020-RealSR/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```shell\n#: subset1 contains 000-019.png\nCUDA_VISIBLE_DEVICES=0,1 python main.py --model WDDet --n_resblocks 40 --n_feats 128 --res_scale 1.0 --data_test Demo --scale 2 --save AIM_WDDet_x2_TEST --test_only --dir_demo ../TestLRX2/TestLR_PART1 --pre_train ../experiment/AIM_WDDet/model/AIM_WDDET_X2.pt --n_GPUs 2 --chop --chop-size 450 450 450 450 --shave-size 80 80 10 10 --save_results\n#: subset2 contains 020-039.png\nCUDA_VISIBLE_DEVICES=0,1 python main.py --model WDDet --n_resblocks 40 --n_feats 128 --res_scale 1.0 --data_test Demo --scale 2 --save AIM_WDDet_x2_TEST --test_only --dir_demo ../TestLRX2/TestLR_PART2 --pre_train ../experiment/AIM_WDDet/model/AIM_WDDET_X2.pt --n_GPUs 2 --chop --chop-size 450 450 450 450 --shave-size 80 80 10 10 --save_results\n#: subset3 contains 040-059.png\nCUDA_VISIBLE_DEVICES=0,1 python main.py --model WDDet --n_resblocks 40 --n_feats 128 --res_scale 1.0 --data_test Demo --scale 2 --save AIM_WDDet_x2_TEST --test_only --dir_demo ../TestLRX2/TestLR_PART3 --pre_train ../experiment/AIM_WDDet/model/AIM_WDDET_X2.pt --n_GPUs 2 --chop --chop-size 450 450 450 450 --shave-size 80 80 10 10 --save_results\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Tue, 21 Dec 2021 17:36:55 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/HolmesShuan/AIM2020-Real-Super-Resolution/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "HolmesShuan/AIM2020-Real-Super-Resolution",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/HolmesShuan/AIM2020-RealSR/master/src/reproduce_testset_results.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8184984610380921
      ],
      "excerpt": "We conduct experiments on Nvidia GPUs (NVIDIA Tesla V100 SXM2 16GB x 12). The total training time is about 2000 GPU hours on V100. It takes about 32GB DRAM during training. We have tested our codes in the following environment (Please install the same version of torch,CUDA,numpy,Pillow,etc. Otherwise the results may differ from ours.): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9452797457628369,
        0.9023697225149864
      ],
      "excerpt": "cd ./src \nsh reproduce_testset_results.sh \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8940397663252039
      ],
      "excerpt": "<img src=\"./img/OADDet.jpg\" width=\"500\" height=\"250\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8940397663252039
      ],
      "excerpt": "<img src=\"./img/OADDet_Network.jpg\" width=\"640\" height=\"360\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8629400568140789
      ],
      "excerpt": "cd ./src \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.929148326326487
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0,1 python main.py --model DDDet --n_resblocks 32 --n_feats 128 --res_scale 1.0 --data_test Demo --scale 2 --save Demo_x2_ouptut --test_only --save_results --dir_demo /your/image/dir/ --pre_train ../experiment/AIM_DDet/model/AIM_DDET_X2.pt --n_GPUs 2 --chop --chop-size 500 --shave-size 100 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9401800424791653
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0,1 python main.py --model DDDet --n_resblocks 32 --n_feats 128 --res_scale 1.0 --data_test Demo --scale 2 --save Demo_x2_ouptut --test_only --save_results --dir_demo /your/image/dir/ --pre_train ../experiment/AIM_DDet/model/AIM_DDET_X2.pt --n_GPUs 2 --chop --chop-size 600 600 300 300 --shave-size 100 10 10 100 --self_ensemble \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9263053395014437,
        0.8805531614655945,
        0.9143534086134393
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --model DDDet --scale 2 --save DIV2K_DDet_x2 --n_resblocks 32 --n_feats 128 --res_scale 1.0 --data_train DIV2K --data_test DIV2K --batch_size 32 --dir_data /data/ --ext bin --n_GPUs 4 --reset --patch_size 96 --n_threads 4 --split_batch 1 --lr 1e-4 --decay 100-200 --epochs 300 \nCUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --model DDDet --scale 2 --save AIM_DDet_x2 --n_resblocks 32 --n_feats 128 --res_scale 1.0 --data_train AIM --data_test AIM --batch_size 32 --dir_data /data/ --ext bin --n_GPUs 4 --reset --patch_size 128 --n_threads 2 --split_batch 1 --lr 5e-5 --decay 150-300-450-600 --epochs 600 --pre_train ../experiment/DIV2K_DDet_x2/model/model_best.pt --save_models --chop \nCUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --model DDDet --scale 2 --save AIM_DDet_x2_SSIM_finetune --n_resblocks 32 --n_feats 128 --res_scale 1.0 --data_train AIM --data_test AIM --batch_size 4 --dir_data /data/AIM_washed --ext bin --n_GPUs 4 --reset --patch_size 420 --n_threads 4 --split_batch 1 --lr 1e-6 --decay 100 --epochs 100 --pre_train ../experiment/AIM_DDet_x2/model/model_latest.pt --chop --loss 20.0*SSIM \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9244925714107499,
        0.9152318579393871,
        0.9137689302944698,
        0.9254078227455159
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --model WDDet --scale 2 --save DIV2K_WDDet_x2 --n_resblocks 40 --n_feats 128 --res_scale 1.0 --data_train DIV2K --data_test DIV2K --batch_size 32 --dir_data /data/ --ext bin --n_GPUs 4 --reset --patch_size 96 --n_threads 4 --split_batch 1 --lr 1e-4 --decay 30 --epochs 30 \nCUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --model WDDet --scale 2 --save AIM_WDDet_x2 --n_resblocks 40 --n_feats 128 --res_scale 1.0 --data_train AIM --data_test AIM --batch_size 32 --dir_data /data/AIM_washed --ext bin --n_GPUs 4 --reset --patch_size 128 --n_threads 2 --split_batch 1 --lr 5e-5 --decay 100-200-300 --epochs 350 --pre_train ../experiment/DIV2K_WDDet_x2/model/model_best.pt --save_models --chop \nCUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --model WDDet --scale 2 --save AIM_WDDet_x2_L1_finetune --n_resblocks 40 --n_feats 128 --res_scale 1.0 --data_train AIM --data_test AIM --batch_size 32 --dir_data /data/AIM_washed_Large --ext bin --n_GPUs 4 --reset --patch_size 128 --n_threads 4 --split_batch 1 --lr 5e-5 --decay 100-200-300 --epochs 350 --pre_train ../experiment/AIM_WDDet_x2/model/model_latest.pt --chop --loss 1.0*L1 \nCUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --model WDDet --scale 2 --save AIM_WDDet_x2_SSIM_finetune --n_resblocks 40 --n_feats 128 --res_scale 1.0 --data_train AIM --data_test AIM --batch_size 4 --dir_data /data/AIM_washed --ext bin --n_GPUs 4 --reset --patch_size 400 --n_threads 4 --split_batch 1 --lr 1e-5 --decay 100 --epochs 100 --pre_train ../experiment/AIM_WDDet_x2_L1_finetune/model/model_latest.pt --chop --loss 20.0*SSIM \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.847222278372137,
        0.8560705729010067,
        0.8560705729010067,
        0.8749410379472465
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --template EDSR--pre_train ../../pre_train/edsr_x2.pt --save AIM_EDSR_X2 --data_train AIM --data_test AIM --n_GPUs 4 --batch_size 24 --patch_size 128 --scale 2 --decay 150 --lr 1e-4 --loss 1*L1 --epoch 300 \nCUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --template EDSR--pre_train ../experiment/AIM_EDSR_X2/model/model_best_2.pt --save AIM_EDSR_X2_finetune --data_train AIM --data_test AIM --n_GPUs 4 --batch_size 16 --patch_size 200 --scale 2 --decay 150 --lr 1e-5 --loss 1*L1 --epoch 300 \nCUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --template EDSR--pre_train ../experiment/AIM_EDSR_X2_finetune /model/model_best_2.pt --save AIM_EDSR_X2_finetune --data_train AIM --data_test AIM --n_GPUs 4 --batch_size 16 --patch_size 200 --scale 2 --decay 150 --lr 1e-6 --loss 1*L1 --epoch 300 \nCUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --template EDSR--pre_train ../experiment/AIM_EDSR_X2_finetune /model/model_best_2.pt --save AIM_EDSR_X2_finetune --data_train AIM --data_test AIM --n_GPUs 4 --batch_size 16 --patch_size 200 --scale 2 --decay 150 --lr 1e-7 --loss 1*L1 --epoch 100 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8712724390533645,
        0.8741362403209133,
        0.8741362403209133,
        0.8908948937277381
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --model DRLN--pre_train ../../pre_train/drln_x2.pt --save AIM_DRLN_X2 --data_train AIM --data_test AIM --n_GPUs 4 --batch_size 24 --patch_size 128 --scale 2 --decay 150 --lr 1e-4 --loss 1*L1 --epoch 300 \nCUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --model DRLN--pre_train ../experiment/AIM_DRLN_X2 /model/model_best_2.pt --save AIM_DRLN_X2_finetune --data_train AIM --data_test AIM --n_GPUs 4 --batch_size 16 --patch_size 200 --scale 2 --decay 150 --lr 1e-5 --loss 1*L1 --epoch 300 \nCUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --model DRLN--pre_train ../experiment/AIM_DRLN_X2_finetune /model/model_best_2.pt --save AIM_DRLN_X2_finetune --data_train AIM --data_test AIM --n_GPUs 4 --batch_size 16 --patch_size 200 --scale 2 --decay 150 --lr 1e-6 --loss 1*L1 --epoch 300 \nCUDA_VISIBLE_DEVICES=0,1,2,3 python main.py --model DRLN --pre_train ../experiment/AIM_DRLN_X2_finetune /model/model_best_2.pt --save AIM_DRLN_X2_finetune --data_train AIM --data_test AIM --n_GPUs 4 --batch_size 16 --patch_size 200 --scale 2 --decay 150 --lr 1e-7 --loss 1*L1 --epoch 100 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8029066229510416
      ],
      "excerpt": "Original Dataset | Original number of images | Ours | Clean Image ID Download Link \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8978678680001447
      ],
      "excerpt": "<img src=\"./img/cmp.jpg\" width=\"700\" height=\"315\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8907927991571063
      ],
      "excerpt": "<img src=\"./img/cmp2.jpg\" width=\"700\" height=\"315\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8940397663252039
      ],
      "excerpt": "<img src=\"./img/cmp3.jpg\" width=\"350\" height=\"450\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8940397663252039
      ],
      "excerpt": "<img src=\"./img/shave-ensemble.jpg\" width=\"500\" height=\"360\" /> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/HolmesShuan/AIM2020-Real-Super-Resolution/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 2-Clause \"Simplified\" License",
      "url": "https://api.github.com/licenses/bsd-2-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 2-Clause License\\n\\nCopyright (c) 2020, Shuan\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "AIM2020-RealSR (Team AiAiR, Final Rank 4th, SSIM Rank 3rd)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "AIM2020-Real-Super-Resolution",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "HolmesShuan",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/HolmesShuan/AIM2020-Real-Super-Resolution/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```shell\n#: subset1 contains 000-019.png\nCUDA_VISIBLE_DEVICES=0,1 python main.py --model WDDet --n_resblocks 40 --n_feats 128 --res_scale 1.0 --data_test Demo --scale 2 --save AIM_WDDet_x2_TEST --test_only --dir_demo ../TestLRX2/TestLR_PART1 --pre_train ../experiment/AIM_WDDet/model/AIM_WDDET_X2.pt --n_GPUs 2 --chop --chop-size 450 450 450 450 --shave-size 80 80 10 10 --save_results\n#: subset2 contains 020-039.png\nCUDA_VISIBLE_DEVICES=0,1 python main.py --model WDDet --n_resblocks 40 --n_feats 128 --res_scale 1.0 --data_test Demo --scale 2 --save AIM_WDDet_x2_TEST --test_only --dir_demo ../TestLRX2/TestLR_PART2 --pre_train ../experiment/AIM_WDDet/model/AIM_WDDET_X2.pt --n_GPUs 2 --chop --chop-size 450 450 450 450 --shave-size 80 80 10 10 --save_results\n#: subset3 contains 040-059.png\nCUDA_VISIBLE_DEVICES=0,1 python main.py --model WDDet --n_resblocks 40 --n_feats 128 --res_scale 1.0 --data_test Demo --scale 2 --save AIM_WDDet_x2_TEST --test_only --dir_demo ../TestLRX2/TestLR_PART3 --pre_train ../experiment/AIM_WDDet/model/AIM_WDDET_X2.pt --n_GPUs 2 --chop --chop-size 450 450 450 450 --shave-size 80 80 10 10 --save_results\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 16,
      "date": "Tue, 21 Dec 2021 17:36:55 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "super-resolution",
      "convolutional-neural-networks",
      "aim2020",
      "real-image-super-resolution"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please first download the pre-trained models and move all of them into `AIM2020-RealSR/experiment` dir. Please unzip downloaded `TestLRX2.zip` to `AIM2020-RealSR/TestLRX2`. Then, run the following scripts in the `AIM2020-RealSR/src` directory.\n\nModel | Download Link | -\n------------ | ------------- | ------------- \nOADDet | [Link](https://pan.cstcloud.cn/s/QogthNSWTuo) (code: lriu) | move to `AIM2020-RealSR/experiment/AIM_DDet/model/`\nDeep-OADDet | [Link](https://pan.cstcloud.cn/s/CmwQfREEQk) (code: 3g8u) | move to `AIM2020-RealSR/experiment/AIM_WDDet/model/`\nEDSR | [Link](https://pan.cstcloud.cn/s/oXcaoOOuQQ) (code: h7a7) | move to `AIM2020-RealSR/experiment/AIM_EDSR/model/`\nDRLN | [Link](https://pan.cstcloud.cn/s/vG9WQ0LgRIE) (code: 6fpg) | move to `AIM2020-RealSR/experiment/AIM_DRLN/model/`\n\n",
      "technique": "Header extraction"
    }
  ]
}
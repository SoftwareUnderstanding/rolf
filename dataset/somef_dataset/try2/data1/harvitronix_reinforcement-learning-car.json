{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "I'm grateful to the following people and the work they did that helped me learn how to do this:\n\n- Playing Atari with Deep Reinforcement Learning - http://arxiv.org/pdf/1312.5602.pdf\n- Deep learning to play Atari games: https://github.com/spragunr/deep_q_rl\n- Another deep learning project for video games: https://github.com/asrivat1/DeepLearningVideoGames\n- A great tutorial on reinforcement learning that a lot of my project is based on: http://outlace.com/Reinforcement-Learning-Part-3/\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/harvitronix/reinforcement-learning-car",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-02-05T14:52:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-09T17:27:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Recent Ubuntu releases come with python3 installed. I use pip3 for installing dependencies so install that with `sudo apt install python3-pip`. Install git if you don't already have it with `sudo apt install git`.\n\nThen clone this repo with `git clone https://github.com/harvitronix/reinforcement-learning-car.git`. It has some pretty big weights files saved in past commits, so to just get the latest the fastest, do `git clone https://github.com/harvitronix/reinforcement-learning-car.git --depth 1`.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9945959790616776,
        0.9841450434370888,
        0.9639878280654316
      ],
      "excerpt": "This is a hobby project I created to learn the basics of reinforcement learning. It uses Python3, Pygame, Pymunk, Keras and Theanos. It employes a Q-learning (unsupervised) algorithm to learn how to move an object around a screen (drive itself) without running into obstacles. \nThe purpose of this project is to eventually use the learnings from the game to operate a real-life remote-control car, using distance sensors. I am carrying on that project in another GitHub repo here: https://github.com/harvitronix/rl-rc-car \nThis version of the code attempts to simulate the use of sensors to get us a step closer to being able to use this in the real world. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9483229309512897
      ],
      "excerpt": "Part 3 (for this version of the code): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.958610047523051
      ],
      "excerpt": "It can take anywhere from an hour to 36 hours to train a model, depending on the complexity of the network and the size of your sample. However, it will spit out weights every 25,000 frames, so you can move on to the next step in much less time. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9889589287307483
      ],
      "excerpt": "That's all there is to it. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Using reinforcement learning to teach a car to avoid obstacles.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/harvitronix/reinforcement-learning-car/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 204,
      "date": "Wed, 22 Dec 2021 01:48:37 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/harvitronix/reinforcement-learning-car/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "harvitronix/reinforcement-learning-car",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This is the physics engine used by the simulation. It just went through a pretty significant rewrite (v5) so you need to grab the older v4 version. v4 is written for Python 2 so there are a couple extra steps.\n\nGo back to your home or downloads and get Pymunk 4:\n\n`wget https://github.com/viblo/pymunk/archive/pymunk-4.0.0.tar.gz`\n\nUnpack it:\n\n`tar zxvf pymunk-4.0.0.tar.gz`\n\nUpdate from Python 2 to 3:\n\n`cd pymunk-pymukn-4.0.0/pymunk`\n\n`2to3 -w *.py`\n\nInstall it:\n\n`cd ..`\n`python3 setup.py install`\n\nNow go back to where you cloned `reinforcement-learning-car` and make sure everything worked with a quick `python3 learning.py`. If you see a screen come up with a little dot flying around the screen, you're ready to go!\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Install Pygame's dependencies with:\n\n`sudo apt install mercurial libfreetype6-dev libsdl-dev libsdl-image1.2-dev libsdl-ttf2.0-dev libsmpeg-dev libportmidi-dev libavformat-dev libsdl-mixer1.2-dev libswscale-dev libjpeg-dev`\n\nThen install Pygame itself:\n\n`pip3 install hg+http://bitbucket.org/pygame/pygame`\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "These instructions are for a fresh Ubuntu 16.04 box. Most of the same should apply to OS X. If you have issues installing, feel free to open an issue with your error and I'll do my best to help.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.832878622458115
      ],
      "excerpt": "NOTE: If you're coming here from parts 1 or 2 of the Medium posts, you want to visit the releases section and check out version 1.0.0, as the code has evolved passed that. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8615528806048325
      ],
      "excerpt": "Full writeups that pertain to version 1.0.0 can be found here: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8402736181495462
      ],
      "excerpt": "First, you need to train a model. This will save weights to the saved-models folder. You may need to create this folder before running. You can train the model by running: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8872364176358806
      ],
      "excerpt": "Edit the playing.py file to change the path name for the model you want to load. Sorry about this, I know it should be a command line argument. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "python3 playing.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8764170158949871
      ],
      "excerpt": "python3 plotting.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/harvitronix/reinforcement-learning-car/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License (MIT)\\n\\nCopyright (c) 2016 Matthew Harvey\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Using reinforcement learning to train an autonomous vehicle to avoid obstacles",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "reinforcement-learning-car",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "harvitronix",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/harvitronix/reinforcement-learning-car/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "harvitronix",
        "body": "This version strays from the first version in a couple ways:\n1. Instead of a bunch of 0/1 pixel readings, the state is instead 3 distances, which is a step towards a real-world scenario where we'll use sonar to detect the state of the room.\n2. Obstacles are no longer randomly created, but they now move in an effort to combat over-fitting.\n\nThis is a bit of a \"step\" version, as in the next version, we'll be focused entirely on trying to apply this simulation to a real RC car.\n",
        "dateCreated": "2016-03-05T03:07:34Z",
        "datePublished": "2016-03-05T03:09:27Z",
        "html_url": "https://github.com/harvitronix/reinforcement-learning-car/releases/tag/2.0.0",
        "name": "Simulating sonar",
        "tag_name": "2.0.0",
        "tarball_url": "https://api.github.com/repos/harvitronix/reinforcement-learning-car/tarball/2.0.0",
        "url": "https://api.github.com/repos/harvitronix/reinforcement-learning-car/releases/2749687",
        "zipball_url": "https://api.github.com/repos/harvitronix/reinforcement-learning-car/zipball/2.0.0"
      },
      {
        "authorType": "User",
        "author_name": "harvitronix",
        "body": "This is the code used in parts 1 and 2 of the series of blog posts on Medium.\n\nPart 1: https://medium.com/@harvitronix/using-reinforcement-learning-in-python-to-teach-a-virtual-car-to-avoid-obstacles-6e782cc7d4c6\n\nPart 2: https://medium.com/@harvitronix/reinforcement-learning-in-python-to-teach-a-virtual-car-to-avoid-obstacles-part-2-93e614fcd238#.vbakopk4o\n",
        "dateCreated": "2016-02-25T06:30:29Z",
        "datePublished": "2016-03-05T02:56:44Z",
        "html_url": "https://github.com/harvitronix/reinforcement-learning-car/releases/tag/1.0.0",
        "name": "Original version of Robocar",
        "tag_name": "1.0.0",
        "tarball_url": "https://api.github.com/repos/harvitronix/reinforcement-learning-car/tarball/1.0.0",
        "url": "https://api.github.com/repos/harvitronix/reinforcement-learning-car/releases/2749669",
        "zipball_url": "https://api.github.com/repos/harvitronix/reinforcement-learning-car/zipball/1.0.0"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "`pip3 install numpy keras h5py`\n\nThat should install a slew of other libraries you need as well.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 451,
      "date": "Wed, 22 Dec 2021 01:48:37 GMT"
    },
    "technique": "GitHub API"
  }
}
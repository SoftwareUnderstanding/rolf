{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1904.08779",
      "https://arxiv.org/abs/1710.09412",
      "https://arxiv.org/abs/1901.01189",
      "https://arxiv.org/abs/1904.08779](https://arxiv.org/abs/1904.08779), 2019.\n\n[2] Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, and David Lopez-Paz, &quot;_mixup: Beyondempirical risk minimization_&quot;, [https://arxiv.org/abs/1710.09412](https://arxiv.org/abs/1710.09412), 2017.\n\n[3] Eduardo Fonseca, Manoj Plakal, Daniel P. W. Ellis, Frederic Font, Xavier Favory, Xavier Serra, &quot;_Learning Sound Event Classifiers from Web Audio with Noisy Labels_&quot;, [https://arxiv.org/abs/1901.01189](https://arxiv.org/abs/1901.01189), 2019.",
      "https://arxiv.org/abs/1710.09412](https://arxiv.org/abs/1710.09412), 2017.\n\n[3] Eduardo Fonseca, Manoj Plakal, Daniel P. W. Ellis, Frederic Font, Xavier Favory, Xavier Serra, &quot;_Learning Sound Event Classifiers from Web Audio with Noisy Labels_&quot;, [https://arxiv.org/abs/1901.01189](https://arxiv.org/abs/1901.01189), 2019.",
      "https://arxiv.org/abs/1901.01189](https://arxiv.org/abs/1901.01189), 2019."
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] Daniel S. Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph, Ekin D. Cubuk, Quoc V. Le, &quot;_SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition_&quot;, [arXiv:1904.08779](https://arxiv.org/abs/1904.08779), 2019.\n\n[2] Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, and David Lopez-Paz, &quot;_mixup: Beyondempirical risk minimization_&quot;, [arXiv:1710.09412](https://arxiv.org/abs/1710.09412), 2017.\n\n[3] Eduardo Fonseca, Manoj Plakal, Daniel P. W. Ellis, Frederic Font, Xavier Favory, Xavier Serra, &quot;_Learning Sound Event Classifiers from Web Audio with Noisy Labels_&quot;, [arXiv:1901.01189](https://arxiv.org/abs/1901.01189), 2019.\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lRomul/argus-freesound",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-20T08:24:56Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-08T06:40:29Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9888555369030897
      ],
      "excerpt": "This repo contains the source code of the 1st place solution for Freesound Audio Tagging 2019 Challenge. The goal of the competition is to develop an algorithm for automated multi-label audio tagging. The main research problem of this competition is to properly utilize a small amount of reliable, manually-labeled data, and a larger quantity of noisy audio data from the web in a multi-label classification task with a large vocabulary (80 categories). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9896360219645699
      ],
      "excerpt": "* CNN model with attention, skip connections and auxiliary classifiers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9366749392125545,
        0.8955937172146908,
        0.9748643632793093,
        0.9224586657758662
      ],
      "excerpt": "* Hand relabeling of the curated dataset samples with a low score \n* Ensembling with an MLP second-level model and a geometric mean blending \nThe Argus framework for PyTorch was employed. It makes the learning process more straightforward and the code briefer. \nLog-scaled mel-spectrograms is the modern standard way of the data representation in CNN-based audio scene classification. Converting audio to spectrograms in this solution was inspired by the daisukelab's data preprocessing notebook. Audio config parameters: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9385182606510609
      ],
      "excerpt": "    #: SpecAugment [1], masking blocks of frequency channels, and masking blocks of time steps \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9563475328695238
      ],
      "excerpt": "MixUp [2] augmentation was found to be beneficial in the competition. This method creates a new training sample based on the weighted average of two items from the original dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9304853508306838
      ],
      "excerpt": "Loss: BCE on curated, Lsoft [3] with beta 0.7 on noisy data   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8237419242076015,
        0.8302816340041216,
        0.9058653453480794,
        0.8379840607024406,
        0.8475353383995251
      ],
      "excerpt": "Use different probabilities for sampling curated and noisy data   \nTraining on hand relabeled curated samples with a low lwlrap score by previous models   \nTraining with BCE on noisy samples with a high lwlrap score by previous models \nMixed precision training with apex.amp allows using batch size 128 with input size 256x128 px \nThe geometric mean of 7 first-level models and 3 second-level models was used for the final submission. MLPs trained with different hyperparameters were used as second-level models. Seven first-level models were chosen by enumeration of combinations of training experiments to finding the highest CV score.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9382790546464315
      ],
      "excerpt": "The progress of the solution during the competition can be seen in the laboratory journal. It describes all the experiments and ideas, but it is partially in Russian, sorry :). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9968029537584643
      ],
      "excerpt": "32GB of RAM \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8406077118300532
      ],
      "excerpt": "For example, take the experiment corr_noisy_008, which currently is in the train_folds.py: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8437676351265894
      ],
      "excerpt": "It was quite challenging to manage the project without a way to split the solution into modules. The idea of kernel building from the first place solution of the Mercari Price Suggestion Challenge was used. You can find the build system template here.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Kaggle | 1st place solution for Freesound Audio Tagging 2019",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lRomul/argus-freesound/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 51,
      "date": "Thu, 23 Dec 2021 08:44:23 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lRomul/argus-freesound/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "lRomul/argus-freesound",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/lRomul/argus-freesound/master/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/lRomul/argus-freesound/master/ensemble_pipeline.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Clone the repo, build docker image. \n    ```bash\n    git clone https://github.com/lRomul/argus-freesound.git\n    cd argus-freesound\n    make build\n    ```\n\n* Download and extract [dataset](https://www.kaggle.com/c/freesound-audio-tagging-2019/data) to `data` folder\n\n    Folder structure should be:\n    ```\n    data\n    \u251c\u2500\u2500 README.md\n    \u251c\u2500\u2500 sample_submission.csv\n    \u251c\u2500\u2500 test\n    \u251c\u2500\u2500 train_curated\n    \u251c\u2500\u2500 train_curated.csv\n    \u251c\u2500\u2500 train_noisy\n    \u2514\u2500\u2500 train_noisy.csv\n    ```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8651637749985343
      ],
      "excerpt": "2080ti or another GPU with fp16 support and at least 12GB memory \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8722381597154575
      ],
      "excerpt": "If you want to reproduce the whole ensemble, you should train all experiments in stacking_predict.py, script ensemble_pipeline.sh can help: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833114516308531,
        0.9023697225149864
      ],
      "excerpt": "    bash \n    ./ensemble_pipeline.sh \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8085734041330799
      ],
      "excerpt": "        PadToSize(size, mode='constant'),  #: Pad with a minimum value \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.811854372964597
      ],
      "excerpt": "                            freq_masking=0.15, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8165133697532291
      ],
      "excerpt": "Mixed precision training with apex.amp allows using batch size 128 with input size 256x128 px \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8667179705992778
      ],
      "excerpt": "python train_folds.py --experiment corr_noisy_008 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.845250065680203
      ],
      "excerpt": "Predict train and test, evaluate metrics  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8667179705992778
      ],
      "excerpt": "python predict_folds.py --experiment corr_noisy_008 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8189178120484644,
        0.8182255268637888
      ],
      "excerpt": "If you want to reproduce the whole ensemble, you should train all experiments in stacking_predict.py, script ensemble_pipeline.sh can help: \nDownload and extract data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8598890383710137
      ],
      "excerpt": "Models weights will be saved in data/experiments. You can zip experiments folder and upload the archive to kaggle dataset. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lRomul/argus-freesound/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "Dockerfile",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Ruslan Baikulov\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Argus solution Freesound Audio Tagging 2019",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "argus-freesound",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "lRomul",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lRomul/argus-freesound/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Run docker container \n    ```bash\n    make run\n    ```\n\n* Create a file with folds split\n    ```bash\n    python make_folds.py\n    ```\n \n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 284,
      "date": "Thu, 23 Dec 2021 08:44:23 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "kaggle",
      "pytorch",
      "deep-learning",
      "audio",
      "classification",
      "tagging"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Run recognition on the audio coming from the microphone.\n \n```bash\nmake run-demo\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
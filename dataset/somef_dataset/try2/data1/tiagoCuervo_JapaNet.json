{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1904.07850",
      "https://arxiv.org/abs/1512.03385",
      "https://arxiv.org/abs/1905.02244",
      "https://arxiv.org/abs/1901.05555"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [1] A. Lamb, *How Machine Learning Can Help Unlock the World of Ancient Japan*, The Gradient https://thegradient.pub/machine-learning-ancient-japan/ (2019), last accessed 15.03.2021\n\n- [2] *Kuzushiji Recognition*, URL: https://www.kaggle.com/c/kuzushiji-recognition/data, last accessed 18.04.2021\n\n- [3] Zhou et al., [*Objects as Points*](https://arxiv.org/abs/1904.07850), Computer Vision and Pattern Recognition (2019)\n\n- [4] He et al., [*Deep residual learning for image recognition*](https://arxiv.org/abs/1512.03385), Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2016)\n\n- [5] Howard et al., [*Searching for MobileNetV3*](https://arxiv.org/abs/1905.02244), IEEE/CVF International Conference on Computer Vision (ICCV) (2019)\n\n- [6] Cui et al., [*Class-Balanced Loss Based on Effective Number of Samples*](https://arxiv.org/abs/1901.05555), Computer Vision and Pattern Recognition (2019)\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/tiagoCuervo/JapaNet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-14T11:21:54Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-15T12:09:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9688279043519038,
        0.9821622429687115,
        0.8550144370891126
      ],
      "excerpt": "The main goal of this project has been to develop a model (models) that would perform detection and classification of ancient Japanese characters (Kuzushiji cursive script), in which classification consists of mapping the Kuzushiji characters to their modern Japanese counterparts.  \nThe main motivation behind the project choice has been to utilize artificial intelligence tools to contribute to a wider ongoing research aimed at making ancient Japanese culture and history more available to people[1]. Sources written in Kuzushiji cannot be read nor appreciated without appropriate translation by anyone except only a small number of experts. Being able to make the ancient Japanese heritage more accessible to a wider public seemed like a fantastic real-life application of Machine Learning. \nData for the project has been taken from the Kaggle competition[2] aimed at improving the current models developed for Kuzushiji recognition. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "\u251c\u2500\u2500 data/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8014049914318055,
        0.9536537356874091
      ],
      "excerpt": "Script for downloading the data available on Kaggle website[2]. Zip files are downloaded directly to the data/ directory. \nScript for unpacking the zipped data and creating TensorFlow.records input pipelines for the detection and classification tasks, as well as the config json file to be used later by main.py. Users need to specify the kind of model for which they intend to use the data using the flags (names are self-explanatory): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8557229710242427,
        0.9636181337022608
      ],
      "excerpt": "dataloader.py has a set of default parameters to be saved in the config file, but accepts custom values through the appropriate flags. See --help for more information. \nScript containing the detection and classification models used in main.py. At the moment, detection is performed using the CenterNet[3] model only. For classification, users can use the --classifierName flag to choose one of the currently supported models: ConvNetBaseline (custom default), ResNet(18 or 34)[4] or MobileNetV3 Large[5]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8167192369683476,
        0.8531493531705215,
        0.900375892176453,
        0.9861330507422338
      ],
      "excerpt": "evaluate : Evaluate on the evaluation data (requires previous training of both models or a path to saved models specified with the flags --detectorPath and --classifierPath). \nBelow we present sample images showing the results of our experiments regarding the detection task. \nLearning curves obtained from the training process of the CenterNet detection model: \nThe model was trained for over 150 epochs with a batch size of 1024 using the Adam optimizer. We applied a reduce on plateau learning rate schedule starting from 0.01, and cyclical learning restarting about every 60 epochs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9827446500462649
      ],
      "excerpt": "The first channel is a heat map of the predicted center of the character. The brightness of the dots in the second and third channel is proportional to the predicted size of the object horizontally and vertically, respectively. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9871974302484461,
        0.8728862543401597
      ],
      "excerpt": "Overall, the model performs nicely for small and close to average characters (left. Bear in mind that the small anotations on the sides of the columns are meant to be ignored by the model), but as can be seen (right), it can fail for unusually large characters, as these were rather uncommon on the train set. \nBelow we present sample images showing the results of our experiments regarding the classification task. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9230503436666824
      ],
      "excerpt": "Training of the baseline convolutional net has been performed with a constant learning rate of 0.001, categorical cross-entropy loss, Adam optimizer, batch size of 512 and 20 epochs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9781431957286247
      ],
      "excerpt": "Aside from our own simple baseline model, we have tried using the well known ResNet model, more specifically the ResNet18 architecture. The model has been implemented by hand. The training process was performed with a reduce on plateau learning rate schedule, categorical cross-entropy loss, Adam optimizer, batch size of 256 and 100 epochs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9715505257279601,
        0.9868251265265308
      ],
      "excerpt": "The core of the MobileNetV3 Large[5] model available in the keras.applications package with an additional densely connected layer (units=1024) followed by batch normalization, leaky ReLU (alpha=0.1) and dropout (rate=0.25) layers before the final output layer with a suitable number of outputs (4206) has been used for the purposes of our experiments.  \nThe training process has been performed with a random initialization of model weights, reduce on plateau learning schedule, minimal learning rate of 1e-4, categorical cross-entropy loss, Adam optimizer, batch size of 4096 and 100 epochs. For this model we additionally used the class weighting scheme described in [6] to try to counter the considerable class imbalance present in the data set. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9878301951206354,
        0.9796253168236453,
        0.860059181823877
      ],
      "excerpt": "Due to time limitations of the project, we were not able to train the MobileNet model with more epochs. However, considering the above learning curves we can observe some highly probable possibility of improvement if we allowed more epochs for training. \nThe following are the results of evaluating the F1 score using the union of the detection and classification models: \n| Model             | F1 Score  | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Detection and classification of Kuzushiji characters for the Kuzushiji Recognition Kaggle challenge using CenterNet as detector and multiple classifiers",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    \u251c\u2500\u2500 trained_models/         ",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/tiagoCuervo/JapaNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 17:23:59 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/tiagoCuervo/JapaNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "tiagoCuervo/JapaNet",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/tiagoCuervo/JapaNet/main/notebooks/tf_dataset_identifier.ipynb",
      "https://raw.githubusercontent.com/tiagoCuervo/JapaNet/main/notebooks/initial_eda.ipynb",
      "https://raw.githubusercontent.com/tiagoCuervo/JapaNet/main/notebooks/centernet.ipynb",
      "https://raw.githubusercontent.com/tiagoCuervo/JapaNet/main/notebooks/binarize_test.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8956592552362523
      ],
      "excerpt": "Trained models are available for download at the following links: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8587476985249702
      ],
      "excerpt": "Suggested Usage \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9336801098518991,
        0.9285065137266004
      ],
      "excerpt": "\u251c\u2500\u2500 dataloader.py \n\u251c\u2500\u2500 download_dataset.py \n\u251c\u2500\u2500 main.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8006327431814643
      ],
      "excerpt": "Script for unpacking the zipped data and creating TensorFlow.records input pipelines for the detection and classification tasks, as well as the config json file to be used later by main.py. Users need to specify the kind of model for which they intend to use the data using the flags (names are self-explanatory): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.825477065025162
      ],
      "excerpt": "train : Fit the estimator using the training data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8833646928349504
      ],
      "excerpt": "Examples of the input and first three output channels from the trained CenterNet: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/tiagoCuervo/JapaNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Detection and classification of ancient Japanese Kuzushiji characters",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "JapaNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "tiagoCuervo",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/tiagoCuervo/JapaNet/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Python 3.8\n- tqdm\n- pandas\n- requests\n- Tensorflow 2.4\n- tensorflow-addons\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    \u2514\u2500\u2500 model.py                ",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 26 Dec 2021 17:23:59 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "classification",
      "object-detection",
      "centernet-detection-model",
      "centernet-tensorflow2",
      "resnet-18",
      "resnet-34",
      "kuzushiji-recognition"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The suggested usage of the project's resources available here is as follows (the users are however free to use them at their will):\n\n1. Install requirements.\n\n    ```shell\n    pip install -r requirements.txt\n    ```\n\n2. Download the raw data set[2]:\n\n    ```shell\n    python download_dataset.py\n    ```\n    \n3. Unpack the zipped data and pre-process it to create a TensorFlow input pipeline and a config json file used by `main.py` for a desired task using `dataloader.py` (remember to specify the kind of model for which you intend to use the data using appropriate flag):\n\n    ```shell\n    python dataloader.py --detector\n    ```\n\n4. Finally, train the desired model using `main.py`:\n\n    ```shell\n    python main.py --detector --mode train --numEpochs 20 --gpu 1 --minLr 1e-4\n    ```\n    \nThe model hyperparameters should be supplied through appropriate flags. Use --help for more information.\n\n",
      "technique": "Header extraction"
    }
  ]
}
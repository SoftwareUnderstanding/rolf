{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2007.01434",
      "https://arxiv.org/abs/1907.02893",
      "https://arxiv.org/abs/1911.08731",
      "https://arxiv.org/abs/2001.00677",
      "https://arxiv.org/abs/1711.07910",
      "https://arxiv.org/abs/1710.03463",
      "https://arxiv.org/abs/1607.01719",
      "https://arxiv.org/abs/1505.07818",
      "https://arxiv.org/abs/1910.11645",
      "https://arxiv.org/abs/2007.02931",
      "https://arxiv.org/abs/2003.00688",
      "https://arxiv.org/abs/2007.02454",
      "https://arxiv.org/abs/2011.09468",
      "https://arxiv.org/abs/2009.00329",
      "https://arxiv.org/abs/2008.01883",
      "https://arxiv.org/abs/2104.09841",
      "https://arxiv.org/abs/2106.02266",
      "https://arxiv.org/abs/2109.02934",
      "https://arxiv.org/abs/2110.09940",
      "https://arxiv.org/abs/2106.06607",
      "https://arxiv.org/abs/2106.06607",
      "https://arxiv.org/abs/1512.03385",
      "https://arxiv.org/abs/1508.07680",
      "https://arxiv.org/abs/1907.02893",
      "https://arxiv.org/abs/1710.03077",
      "https://arxiv.org/abs/1706.07522",
      "https://arxiv.org/abs/1807.04975",
      "https://arxiv.org/abs/2001.03483",
      "https://arxiv.org/abs/2012.07421",
      "https://arxiv.org/abs/1711.07846",
      "https://arxiv.org/abs/2012.07421"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9916116566211683,
        0.894110301647197,
        0.9806436886311394,
        0.9574771561767284,
        0.9995601342386659,
        0.9987693502455032,
        0.978880890753955,
        0.9655820167251902,
        0.9990621218032678,
        0.981629575446343,
        0.9808787771308614,
        0.8351541540159684,
        0.9659924798488342,
        0.9302785107180478
      ],
      "excerpt": "Invariant Risk Minimization (IRM, Arjovsky et al., 2019) \nGroup Distributionally Robust Optimization (GroupDRO, Sagawa et al., 2020) \nInterdomain Mixup (Mixup, Yan et al., 2020) \nMarginal Transfer Learning (MTL, Blanchard et al., 2011-2020) \nMeta Learning Domain Generalization (MLDG, Li et al., 2017) \nMaximum Mean Discrepancy (MMD, Li et al., 2018) \nDeep CORAL (CORAL, Sun and Saenko, 2016) \nDomain Adversarial Neural Network (DANN, Ganin et al., 2015) \nConditional Domain Adversarial Neural Network (CDANN, Li et al., 2018) \nStyle Agnostic Networks (SagNet, Nam et al., 2020) \nAdaptive Risk Minimization (ARM, Zhang et al., 2020), contributed by @zhangmarvin \nVariance Risk Extrapolation (VREx, Krueger et al., 2020), contributed by @zdhNarsil \nRepresentation Self-Challenging (RSC, Huang et al., 2020), contributed by @SirRob1997 \nSpectral Decoupling (SD, Pezeshki et al., 2020) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9217651752833435,
        0.9553055233818778
      ],
      "excerpt": "Gradient Matching for Domain Generalization (Fish, Shi et al., 2021) \nSelf-supervised Contrastive Regularization (SelfReg, Kim et al., 2021) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9613750500933089
      ],
      "excerpt": "Send us a PR to add your algorithm! Our implementations use ResNet50 / ResNet18 networks (He et al., 2015) and the hyper-parameter grids described here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9712438395444837,
        0.9916116566211683,
        0.9302785107180478,
        0.9992579236028358,
        0.996669306913299,
        0.9911959320294913,
        0.9977770699763112,
        0.9712438395444837,
        0.9944679645115037,
        0.9989706971230793
      ],
      "excerpt": "RotatedMNIST (Ghifary et al., 2015) \nColoredMNIST (Arjovsky et al., 2019) \nVLCS  (Fang et al., 2013) \nPACS (Li et al., 2017) \nOffice-Home (Venkateswara et al., 2017) \nA TerraIncognita (Beery et al., 2018) subset \nDomainNet (Peng et al., 2019) \nA SVIRO (Dias Da Cruz et al., 2020) subset \nWILDS (Koh et al., 2020) FMoW (Christie et al., 2018) about satellite images \nWILDS (Koh et al., 2020) Camelyon17 (Bandi et al., 2019) about tumor detection in tissues \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/facebookresearch/DomainBed/main/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/DomainBed",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to DomainBed\nWe want to make contributing to this project as easy and transparent as\npossible.\nPull Requests\nWe actively welcome your pull requests.\n\nFork the repo and create your branch from master.\nIf you've added code that should be tested, add tests.\nIf you've changed APIs, update the documentation.\nEnsure the test suite passes.\nMake sure your code lints.\nIf you haven't already, complete the Contributor License Agreement (\"CLA\").\n\nContributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\nComplete your CLA here: https://code.facebook.com/cla\nIssues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\nFacebook has a bounty program for the safe\ndisclosure of security bugs. In those cases, please go through the process\noutlined on that page and do not file a public issue.\nLicense\nBy contributing to DomainBed, you agree that your contributions\nwill be licensed under the LICENSE file in the root directory of this source\ntree.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-29T21:32:09Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-24T07:13:28Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9549140243591314,
        0.8642462328946654,
        0.838386298870489
      ],
      "excerpt": "DomainBed is a PyTorch suite containing benchmark datasets and algorithms for domain generalization, as introduced in In Search of Lost Domain Generalization. \nFull results for commit 7df6f06 in LaTeX format available here. \nThe currently available algorithms are: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8652426636277925
      ],
      "excerpt": "Group Distributionally Robust Optimization (GroupDRO, Sagawa et al., 2020) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9012833045073455,
        0.8537574908463825
      ],
      "excerpt": "Learning Explanations that are Hard to Vary (AND-Mask, Parascandolo et al., 2020) \nOut-of-Distribution Generalization with Maximal Invariant Predictor (IGA, Koyama et al., 2020) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9023574722952638
      ],
      "excerpt": "Learning Representations that Support Robust Transfer of Predictors (TRM, Xu et al., 2021) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9432466323339161,
        0.9070672670147929
      ],
      "excerpt": "Send us a PR to add your algorithm! Our implementations use ResNet50 / ResNet18 networks (He et al., 2015) and the hyper-parameter grids described here. \nThe currently available datasets are: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8333183435984673,
        0.9647785473975831,
        0.9361639743253276,
        0.8181154954068026
      ],
      "excerpt": "Send us a PR to add your dataset! Any custom image dataset with folder structure dataset/domain/class/image.xyz is readily usable. While we include some datasets from the WILDS project, please use their official code if you wish to participate in their leaderboard. \nModel selection criteria differ in what data is used to choose the best hyper-parameters for a given model: \nIIDAccuracySelectionMethod: A random subset from the data of the training domains. \nLeaveOneOutSelectionMethod: A random subset from the data of a held-out (not training, not testing) domain. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "DomainBed is a suite to test domain generalization algorithms",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/DomainBed/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 133,
      "date": "Sat, 25 Dec 2021 12:34:28 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/facebookresearch/DomainBed/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "facebookresearch/DomainBed",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/facebookresearch/DomainBed/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "TeX"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License\\n\\nCopyright (c) Facebook, Inc. and its affiliates.\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Welcome to DomainBed",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DomainBed",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "facebookresearch",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/DomainBed/blob/main/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "DomainBed includes some unit tests and end-to-end tests. While not exhaustive, but they are a good sanity-check. To run the tests:\n\n```sh\npython -m unittest discover\n```\n\nBy default, this only runs tests which don't depend on a dataset directory. To run those tests as well:\n\n```sh\nDATA_DIR=/my/datasets/path python -m unittest discover\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 583,
      "date": "Sat, 25 Dec 2021 12:34:28 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Download the datasets:\n\n```sh\npython3 -m domainbed.scripts.download \\\n       --data_dir=./domainbed/data\n```\n\nTrain a model:\n\n```sh\npython3 -m domainbed.scripts.train\\\n       --data_dir=./domainbed/data/MNIST/\\\n       --algorithm IGA\\\n       --dataset ColoredMNIST\\\n       --test_env 2\n```\n\nLaunch a sweep:\n\n```sh\npython -m domainbed.scripts.sweep launch\\\n       --data_dir=/my/datasets/path\\\n       --output_dir=/my/sweep/output/path\\\n       --command_launcher MyLauncher\n```\n\nHere, `MyLauncher` is your cluster's command launcher, as implemented in `command_launchers.py`. At the time of writing, the entire sweep trains tens of thousands of models (all algorithms x all datasets x 3 independent trials x 20 random hyper-parameter choices). You can pass arguments to make the sweep smaller:\n\n```sh\npython -m domainbed.scripts.sweep launch\\\n       --data_dir=/my/datasets/path\\\n       --output_dir=/my/sweep/output/path\\\n       --command_launcher MyLauncher\\\n       --algorithms ERM DANN\\\n       --datasets RotatedMNIST VLCS\\\n       --n_hparams 5\\\n       --n_trials 1\n```\n\nAfter all jobs have either succeeded or failed, you can delete the data from failed jobs with ``python -m domainbed.scripts.sweep delete_incomplete`` and then re-launch them by running ``python -m domainbed.scripts.sweep launch`` again. Specify the same command-line arguments in all calls to `sweep` as you did the first time; this is how the sweep script knows which jobs were launched originally.\n\nTo view the results of your sweep:\n\n````sh\npython -m domainbed.scripts.collect_results\\\n       --input_dir=/my/sweep/output/path\n````\n\n",
      "technique": "Header extraction"
    }
  ]
}
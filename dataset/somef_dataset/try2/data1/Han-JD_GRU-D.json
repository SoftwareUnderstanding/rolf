{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1606.01865",
      "https://arxiv.org/abs/1708.02182\nAn Analysis of Neural Language Modeling at Multiple Scales https://arxiv.org/abs/1803.08240",
      "https://arxiv.org/abs/1803.08240",
      "https://arxiv.org/abs/1512.05287.\n  + mloss : Semeniuta, S., Severyn, A., & Barth, E. (2016). Recurrent dropout without memory loss. arXiv preprint https://arxiv.org/abs/1603.05118.\n  \nplanning to work on implenting weighted dropout\nhttps://github.com/salesforce/awd-lstm-lm\nRegularizing and Optimizing LSTM Language Models https://arxiv.org/abs/1708.02182\nAn Analysis of Neural Language Modeling at Multiple Scales https://arxiv.org/abs/1803.08240",
      "https://arxiv.org/abs/1603.05118.\n  \nplanning to work on implenting weighted dropout\nhttps://github.com/salesforce/awd-lstm-lm\nRegularizing and Optimizing LSTM Language Models https://arxiv.org/abs/1708.02182\nAn Analysis of Neural Language Modeling at Multiple Scales https://arxiv.org/abs/1803.08240"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8404870410415647
      ],
      "excerpt": "AUC score (mean \u00b1 std) for mortality prediction in the paper: 0.8424 \u00b1 0.012; my research got: 0.8431. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9995064250556769,
        0.8607653380545827,
        0.9999258422788395
      ],
      "excerpt": "  + moon : [Moon et al.2015] Taesup Moon, Heeyoul Choi, Hoshik Lee, and Inchul Song. 2015. Rn- ndrop: A novel dropout for rnns in asr. Au- tomatic Speech Recognition and Understanding (ASRU). \n  + Gal : [Gal2015] Yarin Gal. 2015. A theoretically grounded application of dropout in recurrent neural networks. arXiv:1512.05287. \n  + mloss : Semeniuta, S., Severyn, A., & Barth, E. (2016). Recurrent dropout without memory loss. arXiv preprint arXiv:1603.05118. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Han-JD/GRU-D",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-09-17T19:24:26Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T10:10:55Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9853009667471611,
        0.9800438924046951,
        0.8880754810586239,
        0.8870448208495074,
        0.9676670773613563,
        0.9865372690808214,
        0.9585512819445478,
        0.979935121445575
      ],
      "excerpt": "This is my first Python3, Pythorch, and neural network project. After taking \u2018Deep learning specialization\u2019 at Coursera, I became interested in the multivariate time series problems. For these problems, I tried various models, such as the ARIMA model, LSTM, and GRU. I decided to use GRU-D as the model because of its effectiveness. \nUpon conducting further research, I found a variation of the code that was developed by a user, zhiyongc, in Github. I found that his code is not the same as the paper. I tried to make a new variation of GRU-D through Pytorch code. I got help from zhiyongc\u2019s code, Pytorch code, and many other resources on the web that helped me develop this GRU-D variation. \nI try to get the same results as the paper, but I am still far from there. \n1. I only tried PhysioNet data (https://physionet.org/challenge/2012/) because this one described the processes and outcomes better than other data. \n2. In the paper, they used 33 inputs, but I found more than 33 inputs (37 including MechVent). The mean number of time steps and the maximum number of time steps also did not match with the raw data, suggesting that I might have missed something. \n3. In the paper, the number of hidden states(h) of GRU-D is 49, but I do not have any clue why that is. \n4. The number of parameters in the paper is 18838 with 33 input variables and 49 hidden states. According to Rahul Dey and Fathi M. Salem (2017), the total number of parameters in the GRU RNN equals 3\u00d7(n^2+nm+n). where m is the input dimension and n is the output dimension. Since GRU-D has a different structure, the way to calculate would be similar. \n5. I am unsure of the process of selecting the time steps when the data has to be shortened. I tried random selection, but, in the end, I chose the timeline with most parameters with the first and last one. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9424348169396172
      ],
      "excerpt": "I plan to work on functions like dropout, early stopping, and bidirectional. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.848896344498424
      ],
      "excerpt": "plane dropout with three variation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9832374657025496
      ],
      "excerpt": "planning to work on implenting weighted dropout \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "inspired by 'Recurrent Neural Networks for Multivariate Time Series with Missing Values' pytorch ver",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Han-JD/GRU-D/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 28,
      "date": "Sun, 26 Dec 2021 21:27:53 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Han-JD/GRU-D/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Han-JD/GRU-D",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Han-JD/GRU-D/master/GRUD_mean.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Han-JD/GRU-D/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "GRU-D",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "GRU-D",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Han-JD",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Han-JD/GRU-D/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 78,
      "date": "Sun, 26 Dec 2021 21:27:53 GMT"
    },
    "technique": "GitHub API"
  }
}
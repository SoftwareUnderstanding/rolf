{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1805.08318",
      "https://arxiv.org/abs/1805.08318",
      "https://arxiv.org/abs/1802.05957",
      "https://arxiv.org/abs/1805.08318 (2018)](https://arxiv.org/abs/1805.08318).**\n\n## Meta overview\nThis repository provides a PyTorch implementation of [SAGAN](https://arxiv.org/abs/1805.08318). Both wgan-gp and wgan-hinge loss are ready, but note that wgan-gp is somehow not compatible with the spectral normalization. Remove all the spectral normalization at the model for the adoption of wgan-gp. Self-attentions are applied before CNN of both discriminator and generator.\n\n##### Self Attention Layer\n<p align=\"center\"><img width=\"100%\" src=\"image/main_model.PNG\" /></p>\n\n## Original Repo status\n* Unsupervised setting (use no label yet)\n* Applied: [Spectral Normalization](https://arxiv.org/abs/1802.05957), code from [here](https://github.com/christiancosgrove/pytorch-spectral-normalization-gan)\n* Implemented: self-attention module, two-timescale update rule (TTUR), wgan-hinge loss, wgan-gp loss\n\n## Current Repo status\n- [x] Parallel Computation on multi-GPU\n- [x] Tensorboard loggings\n- [x] Attention visualization on 64 * 64 image\n- [x] Create Attention map of 64 * 64 image (4096 * 4096)\n- [x] Change custom ([hearthstone](https://github.com/schmich/hearthstone-card-images)) dataset\n- [ ] Create 256*256 image [branch pix256]\n\n##### Warning: 64*64 is the maximum 2power size of attention map for training in 2 Nvidia GTX 1080 Ti (24GB RAM)\n\n\n## Prerequisites\n* [Python 3.5+](https://www.continuum.io/downloads)\n* [PyTorch 0.3.0](http://pytorch.org/)\n* [opencv-python](https://pypi.org/project/opencv-python/)\n* Details in `requirements.txt`\n\n## Usage\n\n#### 1. Clone the repository\n```bash\n$ git clone https://github.com/heykeetae/Self-Attention-GAN.git\n$ cd Self-Attention-GAN\n# for conda user\n$ conda create -n sagan python=3.5\n$ conda activate sagan\n$ conda install pytorch=0.3.0\n\n$ pip install -r requirements.txt\n```\n\n#### 2. Install datasets (CelebA or LSUN or Hearthstone)\n```bash\n$ cd data\n$ bash download.sh CelebA (404 not found)\n# or\n$ bash download.sh LSUN\n# For Hearthstone player\n$ mkdir hearthstone-card-images\n$ cd hearthstone-card-images\n$ wget https://www.dropbox.com/s/vvaxb4maoj4ri34/hearthstone_card.zip?dl=0\n$ unzip hearthstone_card.zip?dl=0\n ```\n\n#### 3. Train\n##### (i) Train in CelebA or Sagan dataset\n```bash\n$ python main.py --batch_size 64 --imsize 64 --dataset celeb --adv_loss hinge --version sagan_celeb\n# or\n$ python main.py --batch_size 64 --imsize 64 --dataset lsun --adv_loss hinge --version sagan_lsun\n```\n\n##### (ii) Custom parameteric Train in Hearthstone dataset\n```bash\n$ python main.py --batch_size 16 --imsize 64 --dataset hearthstone --adv_loss hinge --version sagan_hearth_at1 --num_workers 16 --use_tensorboard True --parallel True --total_step 100000 --log_step 100\n```\nFor argument details, please read parameter.py\n\n#### 4. Attention & Statistics visualization\n ```bash\n tensorboard --logdir ./logs/sagan_hearth_at1\n ```\n\n#### 5. Fake images located at\n```bash\n$ cd samples/sagan_celeb\n# or\n$ cd samples/sagan_lsun\n# or\n$ cd samples/sagan_hearth_at1\n\n```\nSamples generated every 100 iterations are located. The rate of sampling could be controlled via --sample_step (ex, --sample_step 100).\n\n\n## 64*64 Results (step #95500)\n\n<p align=\"center\"><img width=\"100%\" src=\"image/6464_95500.png\" /></p>\n\n### 64*64 Attention result on Hearthstone (step #95500)\n\n- Colormap from opencv(https://docs.opencv.org/2.4/modules/contrib/doc/facerec/colormaps.html)\n- Most attent part shows in RED (1) , most non-attent part shows in BLUE(0)\n- Scores are ranged in [0,1]:\n![alt text](https://docs.opencv.org/2.4/_images/colorscale_jet.jpg)\n\n<p align=\"center\"><img width=\"100%\" src=\"image/6464_95500_attn.png\" /></p>\n\n&nbsp;"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9999998531289515
      ],
      "excerpt": "Han Zhang, Ian Goodfellow, Dimitris Metaxas and Augustus Odena, \"Self-Attention Generative Adversarial Networks.\" arXiv preprint arXiv:1805.08318 (2018). \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hinofafa/Self-Attention-HearthStone-GAN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-02-11T12:20:49Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-15T02:31:58Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9974703352158408
      ],
      "excerpt": "This repository provides a PyTorch implementation of SAGAN. Both wgan-gp and wgan-hinge loss are ready, but note that wgan-gp is somehow not compatible with the spectral normalization. Remove all the spectral normalization at the model for the adoption of wgan-gp. Self-attentions are applied before CNN of both discriminator and generator. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8441733033925691,
        0.8994814069406488
      ],
      "excerpt": "[x] Attention visualization on 64 * 64 image \n[x] Create Attention map of 64 * 64 image (4096 * 4096) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This repository provides a PyTorch implementation of SAGAN cited by heykeetae/Self-Attention-GAN. This repository provide an efficient method to generate large resolution images and attention weights visualisation using tensorboard platform. Tensorboard is a robust platform to monitor generated images and learning weights in computer vision learning experiment.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hinofafa/Self-Attention-GAN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 02:15:01 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hinofafa/Self-Attention-HearthStone-GAN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "hinofafa/Self-Attention-HearthStone-GAN",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/hinofafa/Self-Attention-GAN/master/notebook/Image%20Processing.ipynb",
      "https://raw.githubusercontent.com/hinofafa/Self-Attention-GAN/master/notebook/.ipynb_checkpoints/Image%20Processing-checkpoint.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/hinofafa/Self-Attention-GAN/master/download.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\n$ cd data\n$ bash download.sh CelebA (404 not found)\n#: or\n$ bash download.sh LSUN\n#: For Hearthstone player\n$ mkdir hearthstone-card-images\n$ cd hearthstone-card-images\n$ wget https://www.dropbox.com/s/vvaxb4maoj4ri34/hearthstone_card.zip?dl=0\n$ unzip hearthstone_card.zip?dl=0\n ```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9829922351927534,
        0.9355532161343175,
        0.8055581828979477,
        0.954950449355536,
        0.9770335174395833,
        0.9994466678157792,
        0.9979947896609701
      ],
      "excerpt": "$ git clone https://github.com/heykeetae/Self-Attention-GAN.git \n$ cd Self-Attention-GAN \n: for conda user \n$ conda create -n sagan python=3.5 \n$ conda activate sagan \n$ conda install pytorch=0.3.0 \n$ pip install -r requirements.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9003729605384843
      ],
      "excerpt": "$ cd samples/sagan_celeb \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9003729605384843
      ],
      "excerpt": "$ cd samples/sagan_lsun \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9003729605384843
      ],
      "excerpt": "$ cd samples/sagan_hearth_at1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9025202107133544
      ],
      "excerpt": "Colormap from opencv(https://docs.opencv.org/2.4/modules/contrib/doc/facerec/colormaps.html) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8840144066250328
      ],
      "excerpt": "<p align=\"center\"><img width=\"100%\" src=\"image/banner.jpg\" /></p> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8532985168798555
      ],
      "excerpt": "<p align=\"center\"><img width=\"100%\" src=\"image/main_model.PNG\" /></p> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8872631907776422
      ],
      "excerpt": "$ python main.py --batch_size 64 --imsize 64 --dataset celeb --adv_loss hinge --version sagan_celeb \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8872631907776422
      ],
      "excerpt": "$ python main.py --batch_size 64 --imsize 64 --dataset lsun --adv_loss hinge --version sagan_lsun \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9353806208786257
      ],
      "excerpt": "$ python main.py --batch_size 16 --imsize 64 --dataset hearthstone --adv_loss hinge --version sagan_hearth_at1 --num_workers 16 --use_tensorboard True --parallel True --total_step 100000 --log_step 100 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8532985168798555
      ],
      "excerpt": "<p align=\"center\"><img width=\"100%\" src=\"image/6464_95500.png\" /></p> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8532985168798555
      ],
      "excerpt": "<p align=\"center\"><img width=\"100%\" src=\"image/6464_95500_attn.png\" /></p> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hinofafa/Self-Attention-HearthStone-GAN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Self-Attention GAN in Hearthstone",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Self-Attention-HearthStone-GAN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "hinofafa",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hinofafa/Self-Attention-HearthStone-GAN/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* [Python 3.5+](https://www.continuum.io/downloads)\n* [PyTorch 0.3.0](http://pytorch.org/)\n* [opencv-python](https://pypi.org/project/opencv-python/)\n* Details in `requirements.txt`\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Tue, 28 Dec 2021 02:15:01 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "gan",
      "pytorch",
      "deep-learning",
      "self-attention"
    ],
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1602.07360",
      "https://arxiv.org/abs/1602.07360"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size](https://arxiv.org/abs/1602.07360)\n\n```\nAuthor = Forrest N. Iandola, Song Han, Matthew W. Moskewicz, Khalid Ashraf, William J. Dally and Kurt Keutzer\nTitle = SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size\nJournal = {arXiv:1602.07360}\nYear = 2016\n```\n\nCIFAR-10 Documentation ~\n[Learning Multiple Layers of Features from Tiny Images](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf)\n\n```\nAuthor = Alex Krizhevsky\nTitle = Learning Multiple Layers of Features from Tiny Images\nYear = 2009\n```\n\nAlexNet paper -\n[ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n\n```\nAuthor = Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton\nTitle = ImageNet Classification with Deep Convolutional Neural Networks\nYear = 2012\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9742177718389462
      ],
      "excerpt": "def SqueezeNet(input_shape = (32,32,3), classes = 10): \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zshancock/SqueezeNet_vs_CIFAR10",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-09T00:13:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-17T16:42:12Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "SqueezeNet is focused on size and performance over outright accuracy, however, it still achieved AlexNet-level accuracy in the paper by Iandola in 2016. The actual SqueezeNet architecture is different than what I will refer to as 'Squeeze Net' so I encourage you to read the paper (cited below) and visit the [Deepscale/SqueezeNet github page](https://github.com/deepscale/squeezenet). My model did not reach [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)-level accuracy (89%) but did reach approximately 80% with only 122k parameters (AlexNet is ~ 60million, VGG is 130million+). Additionally, my model is much smaller than even that referenced in the SqueezeNet paper. \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9476218298883087
      ],
      "excerpt": "Inspired by the 'SqueezeNet' architecture proposed by Forrest Iandola et al. (2016), created a smaller model for CIFAR-10 data set using similar components (fire module, etc). The basis of the fire module is shown below (Iandola 2016). Essentially, the fire module implements a strategy wherein it minimizes the input parameters by utilizing a 'squeeze layer' that only uses 1x1 filters. After the 'squeeze layer' is a series of both 1x1 and 3x3 filters in the 'expand layer'. The expand layer is then concatenated.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9659528997023643
      ],
      "excerpt": "#: initalize naming convention of components of the fire module \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9060612079837806
      ],
      "excerpt": "Using the fire module outlined above, the architecture was completed. Max Pooling happens after the very first convolution layer, followed by 4 fire modules. After the last fire module, 50% dropout is committed before the last convolution layer. Global pooling is committed right before softmax activation into 10 classes. The original SqueezeNet proposed by Iandola was much larger, but the CIFAR images are considerably smaller than ImageNet ~ additionally, my local machine could struggle with a larger model.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "return model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Inspired by the 'SqueezeNet' proposed by Forrest Iandola et al. (2016) architecture, created a smaller model for CIFAR-10 data set using similar components (fire module, etc). ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zshancock/SqueezeNet_vs_CIFAR10/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Sat, 25 Dec 2021 03:29:07 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/zshancock/SqueezeNet_vs_CIFAR10/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "zshancock/SqueezeNet_vs_CIFAR10",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/zshancock/SqueezeNet_vs_CIFAR10/master/visualize_cifar.ipynb",
      "https://raw.githubusercontent.com/zshancock/SqueezeNet_vs_CIFAR10/master/squeezenet_architecture.ipynb",
      "https://raw.githubusercontent.com/zshancock/SqueezeNet_vs_CIFAR10/master/deploy_squeezenet.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "x = layers.Activation('relu', name= fid + relu + squeeze1x1)(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521,
        0.8661176197453521
      ],
      "excerpt": "expand_1x1 = layers.Convolution2D(expand, (1,1), padding='valid', name= fid + expand1x1)(x) \nexpand_1x1 = layers.Activation('relu', name= fid + relu + expand1x1)(expand_1x1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "expand_3x3 = layers.Activation('relu', name= fid + relu + expand3x3)(expand_3x3) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "x = layers.concatenate([expand_1x1, expand_3x3], axis = 3, name = fid + 'concat') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521,
        0.8661176197453521
      ],
      "excerpt": "x = layers.Activation('relu', name='relu_conv1')(x) \nx = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "x = layers.Dropout(0.5, name='drop9')(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "x = layers.Activation('relu', name='relu_conv10')(x) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.810518085418094
      ],
      "excerpt": "expand_3x3 = layers.Convolution2D(expand, (3,3), padding='same', name= fid + expand3x3)(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8400671188742603
      ],
      "excerpt": "x = layers.concatenate([expand_1x1, expand_3x3], axis = 3, name = fid + 'concat') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8004865921467169
      ],
      "excerpt": "img_input = layers.Input(shape=input_shape) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8664924311284102
      ],
      "excerpt": "model = models.Model(img_input, out, name='squeezenet') \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/zshancock/SqueezeNet_vs_CIFAR10/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SqueezeNet vs. CIFAR10",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SqueezeNet_vs_CIFAR10",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "zshancock",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zshancock/SqueezeNet_vs_CIFAR10/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 03:29:07 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "squeezenet",
      "tensorflow",
      "cifar10",
      "fire-module"
    ],
    "technique": "GitHub API"
  }
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We would like to thank the authors of the [Tensor2Tensor](https://github.com/tensorflow/tensor2tensor) and [OpenNMT-py](https://github.com/OpenNMT/OpenNMT-py) libraries for the valuable insights offered by their respective model implementations.\n\n",
      "technique": "Header extraction"
    }
  ],
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you decide to use NEMATODE in your work, please provide a link to this repository in the corresponding documentation.\n\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/demelin/nematode",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-10-02T18:33:10Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-08-13T22:38:24Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "NEMATODE is a light-weight neural machine translation toolkit built around the [transformer](https://arxiv.org/pdf/1706.03762.pdf) model. As the name suggests, it was originally derived from the [Nematus](https://github.com/EdinburghNLP/nematus) toolkit and eventually deviated from Nematus into a stand-alone project, by adopting the transformer model and a custom data serving pipeline. Many of its components (most notably the transformer implementation) were subsequently merged into Nematus.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9990879580962737,
        0.8235625784879188
      ],
      "excerpt": "NEMATODE is maintained with readability and modifiability in mind, and seeks to provide users with an easy to extend sandbox centered around a state-of-the-art NMT model. In this way, we hope to contribute our small part towards facilitating interesting research. Nematode is implemented in TensorFlow and supports useful features such as dynamic batching, multi-GPU training, gradient aggregation, and checkpoint averaging which allow for replication of experiments originally conducted on a large number of GPUs on a limited computational budget. \nWhile the core transformer implementation if fully functional, the toolkit continues to be a work-in-progress. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9611590999665153
      ],
      "excerpt": "Following the training regime described in 'Attention is All You Need', our transformer-BASE implementation achieves 27.45 BLEU on the WMT2014 English-to-German task after 148k update steps (measured on newstest2014). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9482321850215075
      ],
      "excerpt": "| --model_type {transformer} | type of the model to be trained / used for inference (default: transformer) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8124019749146697,
        0.9630295501559012
      ],
      "excerpt": "| --ffn_hidden_size INT | inner dimensionality of feed-forward sub-layers in FAN models (default: 2048) | \n| --hidden_size INT | dimensionality of the model's hidden representations (default: 512) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8102973768359533
      ],
      "excerpt": "| --warmup_steps INT | number of initial updates during which the learning rate is increased linearly during learning rate scheduling (default: 4000) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9765513331613056
      ],
      "excerpt": "| --dropout_embeddings FLOAT | dropout applied to sums of word embeddings and positional encodings (default: 0.1) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8848730619110207
      ],
      "excerpt": "| --dropout_relu FLOAT | dropout applied to the internal activation of the feed-forward sub-layers (default: 0.1) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9107424055425546
      ],
      "excerpt": "| --gradient_delay INT | number of steps by which the optimizer updates are to be delayed; longer delays correspond to larger effective batch sizes (default: 0) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9008999366055155
      ],
      "excerpt": "|  --beam_size INT | size of the decoding beam (default: 4) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.878838954931478
      ],
      "excerpt": "| --length_normalization_alpha FLOAT | adjusts the severity of length penalty during beam decoding (default: 0.6) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "NEMATODE is a light-weight neural machine translation toolkit built around the transformer model. Implemented in TensorFlow.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/demelin/nematode/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 26 Dec 2021 09:54:37 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/demelin/nematode/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "demelin/nematode",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/demelin/nematode/master/example_traning_script.sh",
      "https://raw.githubusercontent.com/demelin/nematode/master/eval/bleu_script.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8629367045241233
      ],
      "excerpt": "On one Nvidia GeForce GTX Titan X (Pascal) GPU with CUDA 9.0, our transformer-BASE implementation achieves the following training speeds: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8184492622557387
      ],
      "excerpt": "| --summary_dir PATH | directory for saving summaries (default: same as --save_to) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9007101666659444
      ],
      "excerpt": "| --valid_source_dataset PATH | source validation corpus (default: None) | \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8470468508467528
      ],
      "excerpt": "| --model_name MODEL_NAME | model file name (default: nematode_model) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401740176632562
      ],
      "excerpt": "| --max_len INT | maximum sequence length for training and validation (default: 100) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8520816029867516
      ],
      "excerpt": "| --max_epochs INT | maximum number of training epochs (default: 100) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8007013069759684
      ],
      "excerpt": "| --teacher_forcing_off | disable teacher-forcing during model training (DOES NOTHING FOR NOW) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109882376424422
      ],
      "excerpt": "| --save_to PATH | model checkpoint location (default: model) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8031751177981125
      ],
      "excerpt": "| --summary_dir PATH | directory for saving summaries (default: same as --save_to) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8257924409329388
      ],
      "excerpt": "| --log_file PATH | log file location (default: None) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8002211128027256
      ],
      "excerpt": "| --translation_max_len INT | Maximum length of translation output sentence (default: 100) | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/demelin/nematode/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Perl",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Denis Emelin\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "NEMATODE: Light-weight NMT toolkit",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "nematode",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "demelin",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/demelin/nematode/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- python >= 3.5.2\n- tensorflow >= 1.9\n- CUDA >= 9.0\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 26 Dec 2021 09:54:37 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "nmt",
      "machine-translation-toolkit",
      "neural-machine-translation",
      "transformer"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To train a transformer model, modify the provided example training script - `example_training_script.sh` - as required.\n\n",
      "technique": "Header extraction"
    }
  ]
}
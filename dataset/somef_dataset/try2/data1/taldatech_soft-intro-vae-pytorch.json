{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2012.13253\">2012.13253</a></h4>\n\n\n- [soft-intro-vae-pytorch](#soft-intro-vae-pytorch",
      "https://arxiv.org/abs/2004.04467",
      "https://arxiv.org/abs/2012.13253 (2020).\n>\n    @InProceedings{Daniel_2021_CVPR,\n    author    = {Daniel, Tal and Tamar, Aviv"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Adversarial Latent Autoencoders, Pidhorskyi et al., CVPR 2020 - [Code](https://github.com/podgorskiy/ALAE), [Paper](https://arxiv.org/abs/2004.04467).\n* FID is calculated natively in PyTorch using Seitzer implementation - [Code](https://github.com/mseitzer/pytorch-fid)\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Daniel, Tal, and Aviv Tamar. \"Soft-IntroVAE: Analyzing and Improving the Introspective Variational Autoencoder.\" arXiv preprint arXiv:2012.13253 (2020).\n>\n    @InProceedings{Daniel_2021_CVPR,\n    author    = {Daniel, Tal and Tamar, Aviv},\n    title     = {Soft-IntroVAE: Analyzing and Improving the Introspective Variational Autoencoder},\n    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n    month     = {June},\n    year      = {2021},\n    pages     = {4391-4400}\n}\n\n<h4 align=\"center\">Preprint on ArXiv: <a href=\"https://arxiv.org/abs/2012.13253\">2012.13253</a></h4>\n\n\n- [soft-intro-vae-pytorch](#soft-intro-vae-pytorch)\n- [Soft-IntroVAE](#soft-introvae)\n  * [Citation](#citation)\n  * [Prerequisites](#prerequisites)\n  * [Repository Organization](#repository-organization)\n  * [Credits](#credits)\n    \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@InProceedings{Daniel_2021_CVPR,\nauthor    = {Daniel, Tal and Tamar, Aviv},\ntitle     = {Soft-IntroVAE: Analyzing and Improving the Introspective Variational Autoencoder},\nbooktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\nmonth     = {June},\nyear      = {2021},\npages     = {4391-4400}\n\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9336221125029482
      ],
      "excerpt": "[CVPR 2021 Oral] Soft-IntroVAE: Analyzing and Improving Introspective Variational Autoencoders \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8715509475085587,
        0.8715509475085587
      ],
      "excerpt": "    <a href=\"https://taldatech.github.io\">Tal Daniel</a> \u2022 \n    <a href=\"https://avivt.github.io/avivt/\">Aviv Tamar</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9554441738822752,
        0.9729033900912072
      ],
      "excerpt": "<h4 align=\"center\">CVPR 2021 Oral</h4> \n<h4 align=\"center\"><a href=\"https://taldatech.github.io/soft-intro-vae-web\">Project Website</a> \u2022 <a href=\"https://www.youtube.com/watch?v=1NfsSYoHnBg\">Video</a></h4> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9947390633981341
      ],
      "excerpt": "    <a href=\"https://colab.research.google.com/github/taldatech/soft-intro-vae-pytorch\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/taldatech/soft-intro-vae-pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-12-15T08:11:58Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T19:56:57Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9886931587457857
      ],
      "excerpt": "<h4 align=\"center\">Official repository of the paper</h4> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9976492370077363
      ],
      "excerpt": "Abstract: The recently introduced introspective variational autoencoder (IntroVAE) exhibits outstanding image generations, and allows for amortized inference using an image encoder. The main idea in IntroVAE is to train a VAE adversarially, using the VAE encoder to discriminate between generated and real data samples. However, the original IntroVAE loss function relied on a particular hinge-loss formulation that is very hard to stabilize in practice, and its theoretical convergence analysis ignored important terms in the loss. In this work, we take a step towards better understanding of the IntroVAE model, its practical implementation, and its applications. We propose the Soft-IntroVAE, a modified IntroVAE that replaces the hinge-loss terms with a smooth exponential loss on generated samples. This change significantly improves training stability, and also enables theoretical analysis of the complete algorithm. Interestingly, we show that the IntroVAE converges to a distribution that minimizes a sum of KL distance from the data distribution and an entropy term. We discuss the implications of this result, and demonstrate that it induces competitive image generation and reconstruction. Finally, we describe two applications of Soft-IntroVAE to unsupervised image translation and out-of-distribution detection, and demonstrate compelling results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "[CVPR 2021 Oral] Official PyTorch implementation of Soft-IntroVAE from the paper \"Soft-IntroVAE: Analyzing and Improving Introspective Variational Autoencoders\"",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/taldatech/soft-intro-vae-pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 20,
      "date": "Mon, 27 Dec 2021 05:57:39 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/taldatech/soft-intro-vae-pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "taldatech/soft-intro-vae-pytorch",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/taldatech/soft-intro-vae-pytorch/main/soft_intro_vae_tutorial/soft_intro_vae_image_code_tutorial.ipynb",
      "https://raw.githubusercontent.com/taldatech/soft-intro-vae-pytorch/main/soft_intro_vae_tutorial/soft_intro_vae_2d_code_tutorial.ipynb",
      "https://raw.githubusercontent.com/taldatech/soft-intro-vae-pytorch/main/soft_intro_vae_tutorial/soft_intro_vae_bootstrap_code_tutorial.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8209509183308601
      ],
      "excerpt": "|File name         | Content | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/taldatech/soft-intro-vae-pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Apache License 2.0",
      "url": "https://api.github.com/licenses/apache-2.0"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Tolga Birdal\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "soft-intro-vae-pytorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "soft-intro-vae-pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "taldatech",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/taldatech/soft-intro-vae-pytorch/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* For your convenience, we provide an `environemnt.yml` file which installs the required packages in a `conda` environment name `torch`.\n    * Use the terminal or an Anaconda Prompt and run the following command `conda env create -f environment.yml`.\n* For Style-SoftIntroVAE, more packages are required, and we provide them in the `style_soft_intro_vae` directory.\n\n\n|Library         | Version |\n|----------------------|----|\n|`Python`|  `3.6 (Anaconda)`|\n|`torch`|  >= `1.2` (tested on `1.7`)|\n|`torchvision`|  >= `0.4`|\n|`matplotlib`|  >= `2.2.2`|\n|`numpy`|  >= `1.17`|\n|`opencv`|  >= `3.4.2`|\n|`tqdm`| >= `4.36.1`|\n|`scipy`| >= `1.3.1`|\n\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 129,
      "date": "Mon, 27 Dec 2021 05:57:39 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "vae-pytorch",
      "vae",
      "pytorch",
      "cvpr2021",
      "soft-introvae",
      "soft-intro-vae",
      "variational-autoencoder",
      "image-generation",
      "density-estimation"
    ],
    "technique": "GitHub API"
  }
}
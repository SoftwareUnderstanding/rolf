{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1704.04861",
      "https://arxiv.org/abs/1409.1556",
      "https://arxiv.org/abs/1704.04861",
      "https://arxiv.org/abs/1711.07767"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please cite our paper in your publications if it helps your research:\n\n    @article{liu2017RFB,\n        title = {Receptive Field Block Net for Accurate and Fast Object Detection},\n        author = {Songtao Liu, Di Huang and Yunhong Wang},\n        booktitle = {arxiv preprint arXiv:1711.07767},\n        year = {2017}\n    }\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{liu2017RFB,\n    title = {Receptive Field Block Net for Accurate and Fast Object Detection},\n    author = {Songtao Liu, Di Huang and Yunhong Wang},\n    booktitle = {arxiv preprint arXiv:1711.07767},\n    year = {2017}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9978142703335351
      ],
      "excerpt": "By Songtao Liu, Di Huang, Yunhong Wang \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ZTao-z/multiflow-resnet-ssd",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-02T04:56:55Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-07T08:56:32Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Inspired by the structure of Receptive Fields (RFs) in human visual systems, we propose a novel RF Block (RFB) module, which takes the relationship between the size and eccentricity of RFs into account, to enhance the discriminability and robustness of features. We further  assemble the RFB module to the top of SSD with a lightweight CNN model, constructing the RFB Net detector. You can use the code to train/evaluate the RFB Net for object detection. For more details, please refer to our [arXiv paper](https://arxiv.org/pdf/1711.07767.pdf). \n\n<img align=\"right\" src=\"https://github.com/ruinmessi/RFBNet/blob/master/doc/rfb.png\">\n\n&nbsp;\n&nbsp;\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9655782900836182
      ],
      "excerpt": "| Faster R-CNN (VGG16) | 73.2 | 7 |  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9107004630627823,
        0.8924212690395703,
        0.8420764844668767,
        0.8924212690395703,
        0.8924212690395703
      ],
      "excerpt": "| R-FCN (ResNet-101)| 80.5| 9 | \n| SSD300* (VGG16) | 77.2 | 46 | \n| SSD512* (VGG16) | 79.8 | 19 | \n| RFBNet300 (VGG16) | 80.5 |83* |  \n| RFBNet512 (VGG16) | 82.2 | 38* | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9252149099759455
      ],
      "excerpt": "| Faster R-CNN++ (ResNet-101) | 34.9 | 3.36s |  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8924212690395703,
        0.8924212690395703
      ],
      "excerpt": "| SSD300* (VGG16) | 25.1 | 22ms | \n| SSD512* (VGG16) | 28.8 | 53ms | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8924212690395703,
        0.8924212690395703,
        0.8924212690395703,
        0.9505453556032087
      ],
      "excerpt": "| RFBNet300 (VGG16) | 29.9 |15ms* |  \n| RFBNet512 (VGG16) | 33.8 | 30ms* | \n| RFBNet512-E (VGG16) | 34.4 | 33ms* |   \nNote: * The speed here is tested on the newest pytorch and cudnn version (0.2.0 and cudnnV6), which is obviously faster than the speed reported in the paper (using pytorch-0.1.12 and cudnnV5). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8781082440810162
      ],
      "excerpt": "*: slightly better than the original ones in the paper (20.5). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8892759274612161
      ],
      "excerpt": "To make things easy, we provide simple VOC and COCO dataset loader that inherits torch.utils.data.Dataset making it fully compatible with the torchvision.datasets API. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8360823672040374
      ],
      "excerpt": "UPDATE: The current COCO dataset has released new train2017 and val2017 sets which are just new splits of the same image sets. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8962784274206155,
        0.8873647171116077
      ],
      "excerpt": "or from our BaiduYun Driver  \nMobileNet pre-trained basenet is ported from MobileNet-Caffe, which achieves slightly better accuracy rates than the original one reported in the paper, weight file is available at: https://drive.google.com/open?id=13aZSApybBDjzfGIdqN1INBlPsddxCK14 or BaiduYun Driver. \n",
      "technique": "Supervised classification"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```Shell\n#: specify a directory for dataset to be downloaded into, else default is ~/data/\nsh data/scripts/VOC2007.sh #: <directory>\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```Shell\n#: specify a directory for dataset to be downloaded into, else default is ~/data/\nsh data/scripts/VOC2012.sh #: <directory>\n```\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ZTao-z/multiflow-resnet-ssd/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sat, 25 Dec 2021 19:42:19 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ZTao-z/multiflow-resnet-ssd/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ZTao-z/multiflow-resnet-ssd",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ZTao-z/multiflow-resnet-ssd/master/make.sh",
      "https://raw.githubusercontent.com/ZTao-z/multiflow-resnet-ssd/master/data/scripts/VOC2007.sh",
      "https://raw.githubusercontent.com/ZTao-z/multiflow-resnet-ssd/master/data/scripts/VOC2012.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Install [PyTorch-0.2.0](http://pytorch.org/) by selecting your environment on the website and running the appropriate command.\n- Clone this repository. This repository is mainly based on [ssd.pytorch](https://github.com/amdegroot/ssd.pytorch) and [Chainer-ssd](https://github.com/Hakuyume/chainer-ssd), a huge thank to them.\n  * Note: We currently only support Python 3+.\n- Compile the nms and coco tools:\n```Shell\n./make.sh\n```\n*Note*: Check you GPU architecture support in utils/build.py, line 131. Default is:\n``` \n'nvcc': ['-arch=sm_52',\n```\n- Install [pyinn](https://github.com/szagoruyko/pyinn) for MobileNet backbone:\n```Shell\npip install git+https://github.com/szagoruyko/pyinn.git@master\n```\n- Then download the dataset by following the [instructions](#download-voc2007-trainval--test) below and install opencv. \n```Shell\nconda install opencv\n```\nNote: For training, we currently  support [VOC](http://host.robots.ox.ac.uk/pascal/VOC/) and [COCO](http://mscoco.org/). \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9389743899733008
      ],
      "excerpt": "Install the MS COCO dataset at /path/to/coco from official website, default is ~/data/COCO. Following the instructions to prepare minival2014 and valminusminival2014 annotations. All label files (.json) should be under the COCO/annotations/ folder. It should have this basic structure \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8835572673635612
      ],
      "excerpt": "First download the fc-reduced VGG-16 PyTorch base network weights at:    https://s3.amazonaws.com/amdegroot-models/vgg16_reducedfc.pth \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8902627162932362,
        0.9906248903846466
      ],
      "excerpt": "mkdir weights \ncd weights \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9446366290009977
      ],
      "excerpt": "-v: choose backbone version, RFB_VGG, RFB_E_VGG or RFB_mobile. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.800442136572464
      ],
      "excerpt": "| RetinaNet500 (ResNet-101-FPN) | 34.4| 90ms| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8442074382241295
      ],
      "excerpt": "To train RFBNet using the train script simply specify the parameters listed in train_RFB.py as a flag or manually change them. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8513754098094971
      ],
      "excerpt": "python train_RFB.py -d VOC -v RFB_vgg -s 300 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8760053104035261
      ],
      "excerpt": "You can pick-up training from a checkpoint by specifying the path as one of the training parameters (again, see train_RFB.py for options) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8437115476895466,
        0.8048294781477846
      ],
      "excerpt": "python test_RFB.py -d VOC -v RFB_vgg -s 300 --trained_model /path/to/model/weights \nBy default, it will directly output the mAP results on VOC2007 test or COCO minival2014. For VOC2012 test and COCO test-dev results, you can manually change the datasets in the test_RFB.py file, then save the detection results and submitted to the server. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ZTao-z/multiflow-resnet-ssd/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C",
      "Cuda",
      "Shell",
      "C++"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2017 Max deGroot, Ellis Brown\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Receptive Field Block Net for Accurate and Fast Object Detection",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "multiflow-resnet-ssd",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ZTao-z",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ZTao-z/multiflow-resnet-ssd/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 19:42:19 GMT"
    },
    "technique": "GitHub API"
  }
}
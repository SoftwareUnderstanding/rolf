{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please cite our paper if you use this code in your own work:\n\n```BibTeX\n@inproceedings{salha2019gravity,\n  title={Gravity-Inspired Graph Autoencoders for Directed Link Prediction},\n  author={Salha, Guillaume and Limnios, Stratis and Hennequin, Romain and Tran, Viet Anh and Vazirgiannis, Michalis},\n  booktitle={ACM International Conference on Information and Knowledge Management (CIKM)},\n  year={2019}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{salha2019gravity,\n  title={Gravity-Inspired Graph Autoencoders for Directed Link Prediction},\n  author={Salha, Guillaume and Limnios, Stratis and Hennequin, Romain and Tran, Viet Anh and Vazirgiannis, Michalis},\n  booktitle={ACM International Conference on Information and Knowledge Management (CIKM)},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9950284072676877
      ],
      "excerpt": "This repository provides Python code to reproduce experiments from the article Gravity-Inspired Graph Autoencoders for Directed Link Prediction published in the proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM 2019). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8028046190715653,
        0.8028046190715653
      ],
      "excerpt": "- General Directed Link Prediction \n- Biased Negative Samples Directed Link Prediction \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/deezer/gravity_graph_autoencoders",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-08-30T09:38:01Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-13T08:13:01Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8658635312805215,
        0.9520983721577001
      ],
      "excerpt": "This repository provides Python code to reproduce experiments from the article Gravity-Inspired Graph Autoencoders for Directed Link Prediction published in the proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM 2019). \nWe release Tensorflow implementations of the following four directed graph embedding models from the paper: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8181806031492236,
        0.9869243429308012
      ],
      "excerpt": "together with standard Graph Autoencoders (AE) and Graph Variational Autoencoders (VAE) models from Kipf and Welling (2016).  \nWe evaluate all six models on the three directed link prediction tasks introduced in section 4.1 of our paper: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9447422900485815
      ],
      "excerpt": "Our code builds upon Thomas Kipf's original Tensorflow implementation of standard Graph AE/VAE. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.902930368546404
      ],
      "excerpt": "| model     | string | Name of the model, among:<br> - gcn_ae: Graph AE from Kipf and Welling (2016), with 2-layer<br> GCN encoder and inner product decoder<br> - gcn_vae: Graph VAE from Kipf and Welling (2016), with Gaussian <br> distributions, 2-layer GCN encoders and inner product decoder<br> - source_target_gcn_ae: Source-Target Graph AE, as introduced <br> in section 2.6 of paper, with 2-layer GCN encoder and asymmetric inner product decoder <br> - source_target_gcn_vae: Source-Target Graph VAE, as introduced <br> in section 2.6, with Gaussian distributions, 2-layer GCN encoders and asymmetric inner product<br> - gravity_gcn_ae: Gravity-Inspired Graph AE, as introduced in <br> section 3.3 of paper, with 2-layer GCN encoder and  gravity-inspired asymmetric decoder <br> - gravity_gcn_vae: Gravity-Inspired Graph VAE, as introduced in <br> section 3.4 of paper, with Gaussian distributions, 2-layer GCN encoders and gravity-inspired decoder| gcn_ae | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9006143011678134,
        0.9713966250393112
      ],
      "excerpt": "| features| boolean | Include node features or not in GCN encoder | False | \n| lamb| float | \"Lambda\" parameter from Gravity AE/VAE models as introduced in <br> section 3.5 of paper, to balance mass and proximity terms' | 1. | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.822822918590079
      ],
      "excerpt": "| dimension| int | Dimension of GCN output. It is: <br> - equal to embedding dimension for standard AE/VAE <br> and Source-Target AE/VAE models <br> - equal to (embedding dimension - 1) for gravity-inspired AE/VAE <br> models, as the last dimension captures the \"mass\" parameter <br> <br> Dimension must be even for Source-Target AE/VAE model | 32 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9361340373974291
      ],
      "excerpt": "| epsilon| float | For Gravity models: add epsilon to L2 distances computations, for numerical stability | 0.01| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9143301005681685
      ],
      "excerpt": "| prop_val| float | Proportion of edges in validation set (for Task 1) | 5. | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8197773192898737
      ],
      "excerpt": "| validation| boolean | Whether to report validation results  at each epoch (for Task 1) | False | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Source code from the CIKM 2019 article \"Gravity-Inspired Graph Autoencoders for Directed Link Prediction\" by G. Salha, S. Limnios, R. Hennequin, V.A. Tran and M. Vazirgiannis",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/deezer/gravity_graph_autoencoders/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Mon, 27 Dec 2021 15:45:24 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/deezer/gravity_graph_autoencoders/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "deezer/gravity_graph_autoencoders",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\npython setup.py install\n```\n\nRequirements: tensorflow (1.x), networkx, numpy, scikit-learn, scipy\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.897953614168866
      ],
      "excerpt": "  <img height=\"550\" src=\"graph_visu_cora.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8605842440898621
      ],
      "excerpt": "| epoch| int | Number of epochs in model training | 200 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8366862911707245
      ],
      "excerpt": "| nb_run| integer | Number of model runs + tests | 1 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.821173138420557,
        0.887970848988341
      ],
      "excerpt": "| validation| boolean | Whether to report validation results  at each epoch (for Task 1) | False | \n| verbose| boolean | Whether to print full comments details | True | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8886061075915488,
        0.8886061075915488,
        0.8886061075915488,
        0.8886061075915488,
        0.9020894835480753,
        0.9020894835480753
      ],
      "excerpt": "python train.py --dataset=cora --model=gcn_vae --task=task_1 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=cora --model=gcn_ae --task=task_1 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=cora --model=source_target_gcn_vae --task=task_1 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=cora --model=source_target_gcn_ae --task=task_1 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=cora --model=gravity_gcn_vae --task=task_1 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=33 --lamb=1.0 --nb_run=5 \npython train.py --dataset=cora --model=gravity_gcn_ae --task=task_1 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=33 --lamb=1.0 --nb_run=5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8886061075915488,
        0.8886061075915488,
        0.8886061075915488,
        0.8879477055067863,
        0.8955228935329985,
        0.923686540358382
      ],
      "excerpt": "python train.py --dataset=cora --model=gcn_vae --task=task_2 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=cora --model=gcn_ae --task=task_2 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=cora --model=source_target_gcn_vae --task=task_2 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=cora --model=source_target_gcn_ae --task=task_2 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=64 --nb_run=5 \npython train.py --dataset=cora --model=gravity_gcn_vae --task=task_2 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=33 --lamb=0.05 --nb_run=5 \npython train.py --dataset=cora --model=gravity_gcn_ae --task=task_2 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=33 --lamb=0.05 --normalize=True --nb_run=5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8886061075915488,
        0.8886061075915488,
        0.8886061075915488,
        0.8886061075915488,
        0.9020894835480753,
        0.9020894835480753
      ],
      "excerpt": "python train.py --dataset=cora --model=gcn_vae --task=task_3 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=cora --model=gcn_ae --task=task_3 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=cora --model=source_target_gcn_vae --task=task_3 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=cora --model=source_target_gcn_ae --task=task_3 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=cora --model=gravity_gcn_vae --task=task_3 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=33 --lamb=1.0 --nb_run=5 \npython train.py --dataset=cora --model=gravity_gcn_ae --task=task_3 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=33 --lamb=1.0 --nb_run=5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8886061075915488,
        0.8886061075915488,
        0.8886061075915488,
        0.8886061075915488,
        0.9020894835480753,
        0.9020894835480753
      ],
      "excerpt": "python train.py --dataset=citeseer --model=gcn_vae --task=task_1 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=citeseer --model=gcn_ae --task=task_1 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=citeseer --model=source_target_gcn_vae --task=task_1 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=citeseer --model=source_target_gcn_ae --task=task_1 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=citeseer --model=gravity_gcn_vae --task=task_1 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=33 --lamb=1.0 --nb_run=5 \npython train.py --dataset=citeseer --model=gravity_gcn_ae --task=task_1 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=33 --lamb=1.0 --nb_run=5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8886061075915488,
        0.8886061075915488,
        0.8886061075915488,
        0.8886061075915488,
        0.8955228935329985,
        0.923686540358382
      ],
      "excerpt": "python train.py --dataset=citeseer --model=gcn_vae --task=task_2 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=citeseer --model=gcn_ae --task=task_2 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=citeseer --model=source_target_gcn_vae --task=task_2 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=citeseer --model=source_target_gcn_ae --task=task_2 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=citeseer --model=gravity_gcn_vae --task=task_2 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=33 --lamb=0.05 --nb_run=5 \npython train.py --dataset=citeseer --model=gravity_gcn_ae --task=task_2 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=33 --lamb=0.05 --normalize=True --nb_run=5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8886061075915488,
        0.8886061075915488,
        0.8886061075915488,
        0.8886061075915488,
        0.9020894835480753,
        0.9020894835480753
      ],
      "excerpt": "python train.py --dataset=citeseer --model=gcn_vae --task=task_3 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=citeseer --model=gcn_ae --task=task_3 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=citeseer --model=source_target_gcn_vae --task=task_3 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=citeseer --model=source_target_gcn_ae --task=task_3 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=citeseer --model=gravity_gcn_vae --task=task_3 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=33 --lamb=1.0 --nb_run=5 \npython train.py --dataset=citeseer --model=gravity_gcn_ae --task=task_3 --epochs=200 --learning_rate=0.1 --hidden=64 --dimension=33 --lamb=1.0 --nb_run=5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8766529446257546,
        0.8766529446257546,
        0.8766529446257546,
        0.8766529446257546,
        0.9043518354843578,
        0.9043518354843578
      ],
      "excerpt": "python train.py --dataset=google --model=gcn_vae --task=task_1 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=google --model=gcn_ae --task=task_1 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=google --model=source_target_gcn_vae --task=task_1 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=google --model=source_target_gcn_ae --task=task_1 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=google --model=gravity_gcn_vae --task=task_1 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=33 --lamb=10.0 --nb_run=5 \npython train.py --dataset=google --model=gravity_gcn_ae --task=task_1 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=33 --lamb=10.0 --nb_run=5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8766529446257546,
        0.8766529446257546,
        0.8766529446257546,
        0.8766529446257546,
        0.8841952853464563,
        0.9145887083323833
      ],
      "excerpt": "python train.py --dataset=google --model=gcn_vae --task=task_2 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=google --model=gcn_ae --task=task_2 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=google --model=source_target_gcn_vae --task=task_2 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=google --model=source_target_gcn_ae --task=task_2 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=google --model=gravity_gcn_vae --task=task_2 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=33 --lamb=0.05 --nb_run=5 \npython train.py --dataset=google --model=gravity_gcn_ae --task=task_2 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=33 --lamb=0.05 --normalize=True --epsilon=1.0 --nb_run=5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8766529446257546,
        0.8766529446257546,
        0.8766529446257546,
        0.8766529446257546,
        0.9043518354843578,
        0.9043518354843578
      ],
      "excerpt": "python train.py --dataset=google --model=gcn_vae --task=task_3 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=google --model=gcn_ae --task=task_3 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=google --model=source_target_gcn_vae --task=task_3 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=google --model=source_target_gcn_ae --task=task_3 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=32 --nb_run=5 \npython train.py --dataset=google --model=gravity_gcn_vae --task=task_3 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=33 --lamb=10.0 --nb_run=5 \npython train.py --dataset=google --model=gravity_gcn_ae --task=task_3 --epochs=200 --learning_rate=0.2 --hidden=64 --dimension=33 --lamb=10.0 --nb_run=5 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/deezer/gravity_graph_autoencoders/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Gravity-Inspired Graph Autoencoders for Directed Link Prediction",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "gravity_graph_autoencoders",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "deezer",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/deezer/gravity_graph_autoencoders/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\ncd gravity_gae\npython train.py --model=gcn_vae --dataset=cora --task=task_1\npython train.py --model=gravity_gcn_vae --dataset=cora --task=task_1\n```\n\nThe above commands will train a *Graph VAE (line 2)* and a *Gravity-Inspired Graph VAE (line 3)* on *Cora dataset* and will evaluate node embdeddings on *Task 1: General Directed Link Prediction*, with all parameters set to default values.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 30,
      "date": "Mon, 27 Dec 2021 15:45:24 GMT"
    },
    "technique": "GitHub API"
  }
}
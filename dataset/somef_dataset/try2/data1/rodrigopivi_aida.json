{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1801.06146"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rodrigopivi/aida",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-08-04T16:03:50Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-02T17:31:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9804388065407523,
        0.8659770019204338
      ],
      "excerpt": "It's a chatbott running from the browser using Tensorflow.js and using the Web Speech API for speach to text and text to speach. \nYou can train from the browser using Javascript and Tensorflow.js (using your local GPU resources) or from the browser using Python and Tensorflow with Keras thanks to Google Colaboratory's free TPU's. There is no need to setup a local environment, the trained models can be saved for later use. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9918249288386958
      ],
      "excerpt": "Experiment with multi layer language models based on character features like bigrams or trigrams for transfer learning, probably using a custom BiLSTM or LSTM architecture similar but simplier to Universal Language Model Fine-tuning for Text Classification (blog post). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "\ud83e\udd16\ud83d\udcac Tiny experimental NLP deep learning library for text classification and NER. Built with Tensorflow.js, Keras and Chatito. Implemented in JS and Python.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rodrigopivi/aida/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 21,
      "date": "Mon, 27 Dec 2021 20:31:22 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/rodrigopivi/aida/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "rodrigopivi/aida",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/rodrigopivi/aida/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/rodrigopivi/aida/master/python/main.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Alternatively to training online and using npm package, you can setup the project locally. Clone the GH proejct and install dependencies for node and python (given NodeJS with yarn and Python3 are installed):\n\n  - Run `yarn install` from the `./typescript` directory\n  - Run `pip3 install -r requirements.txt` from the `./python` directory\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- Install the npm package:\n\n```\nyarn add aida-nlp\n```\n\n  - Create your chatito definition files, here you define your intents and your possible sentence models in mutiple `.chatito` files, and save them to a directory. e.g.: \u00b4./chatito\u00b4\n\n  - Create a config file like `aida_config.json` where you define the path to your chatito definition files, the chatito dataset output path and the output path for the trained NLP models:\n\n```\n{\n  \"chatito\": {\n    \"inputPath\": \"./chatito\",\n    \"outputPath\": \"./dataset\"\n  },\n  \"aida\": {\n    \"outputPath\": \"./model\",\n    \"language\": \"en\"\n  }\n}\n```\n\n  - Generate and encode the dataset for training: `npx aida-nlp aida_config.json --action dataset`. The dataset will be available at the configured output path.\n\n  - Start training: `npx aida-nlp aida_config.json --action train`. The models will be saved at the configured output path.\n\n  - Run `npx aida-nlp aida_config.json --action test` for trying the generated testing dataset.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8501505611284652
      ],
      "excerpt": "You can train from the browser using Javascript and Tensorflow.js (using your local GPU resources) or from the browser using Python and Tensorflow with Keras thanks to Google Colaboratory's free TPU's. There is no need to setup a local environment, the trained models can be saved for later use. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.849526981049292
      ],
      "excerpt": "Then, from ./typescript directory, run npm run dataset:en:process. This will generate many files at the ./typescript/public/models directory. The dataset, the dataset parameters, the testing parameters and the embeddings dictionary. (Note: Aida also supports spanish language, if you need other language you can add if you first download the fastText embeddings for that language). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9077041898158771
      ],
      "excerpt": "      - For python: open ./python/main.ipynb with jupyter notebook or jupyter lab. Python will load your custom settings generated at step 3. And save the models in a TensorflowJS compatible format at the output directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8418202151379088
      ],
      "excerpt": "  - For Node.js: from `./typescript` run `npm run node:start`. This will load the previously dataset generated files from `./typescript/public/models`. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8535111148329926
      ],
      "excerpt": "      - For python: open ./python/main.ipynb with jupyter notebook or jupyter lab. Python will load your custom settings generated at step 3. And save the models in a TensorflowJS compatible format at the output directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8555093124730343
      ],
      "excerpt": "Add tests \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/rodrigopivi/aida/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "TypeScript",
      "Python",
      "Jupyter Notebook",
      "JavaScript"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Rodrigo Pimentel\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# [Check the demo](https://aida.dor.ai/demo)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "aida",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "rodrigopivi",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rodrigopivi/aida/blob/master/readme.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 69,
      "date": "Mon, 27 Dec 2021 20:31:22 GMT"
    },
    "technique": "GitHub API"
  }
}
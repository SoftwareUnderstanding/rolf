{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2002.06652",
      "https://arxiv.org/abs/1908.10084",
      "https://arxiv.org/abs/1810.04805",
      "https://arxiv.org/abs/2002.06652",
      "https://arxiv.org/abs/2002.06652"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find our model is useful in your research, please consider cite our paper: [SBERT-WK: A Sentence Embedding Method By Dissecting BERT-based Word Models](https://arxiv.org/abs/2002.06652):\n\n``` \n@ARTICLE{SBERT-WK,\n  author={B. {Wang} and C. -. J. {Kuo}},\n  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, \n  title={{SBERT-WK}: A Sentence Embedding Method by Dissecting {BERT}-Based Word Models}, \n  year={2020},\n  volume={28},\n  pages={2146-2157},}\n```\n\n```\n@article{SBERT-WK,\n    title = {{SBERT-WK}: A Sentence Embedding Method By Dissecting BERT-based Word Models},\n    author = {Wang, Bin and Kuo, C-C Jay},\n    journal={arXiv preprint arXiv:2002.06652},\n    year={2020}\n}\n```\n\nOne paper that shows SBERT-WK works well in real world applications: https://arxiv.org/pdf/2009.02931.pdf\n\nContact person: Bin Wang, bwang28c@gmail.com\n\nhttp://mcl.usc.edu/\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@ARTICLE{SBERT-WK,\n  author={B. {Wang} and C. -. J. {Kuo}},\n  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, \n  title={{SBERT-WK}: A Sentence Embedding Method by Dissecting {BERT}-Based Word Models}, \n  year={2020},\n  volume={28},\n  pages={2146-2157},}\n@article{SBERT-WK,\n    title = {{SBERT-WK}: A Sentence Embedding Method By Dissecting BERT-based Word Models},\n    author = {Wang, Bin and Kuo, C-C Jay},\n    journal={arXiv preprint arXiv:2002.06652},\n    year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9421445313892791
      ],
      "excerpt": "| Citation                                             | Reference Link                    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8444342525991423
      ],
      "excerpt": "| BERT - CLS               | 27.58 | 22.52 | 25.63 | 32.11 | 42.69 | 52.14 | 70.05  | 38.96  | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BinWang28/SBERT-WK-Sentence-Embedding",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-01-13T19:16:55Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-09T11:13:54Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9859586853208963,
        0.9934743095760711
      ],
      "excerpt": "SBERT-WK provides a way to generate sentence embedding by dissecting deep contextualized models. Because pre-trained language models are quite powerful in a wide range of NLP tasks, but how to generate sentence embedding from deep language models is still challenging. Deep models mostly provide word/token level representation. Previous approaches includes averaging token representations or use CLS tokens provides rather poor performance in either textual similarity tasks, clustering and supervised tasks. Through geometric analysis, our model is capable in finding salient components in representation arocss layers and unified token representations. We evaluate our approach on a wide range of tasks and showed its effectiveness. \nOur model is applicable to any deep contextualized models and requires no further training. Details of our method can be found in our publication: SBERT-WK. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8668049197650731
      ],
      "excerpt": "We have more scripts for using different pre-trained models\uff1a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8719131107991709,
        0.9246997682431486
      ],
      "excerpt": "    --model_type 'binwang/bert-base-nli' #:      #: BERT Model finetuned on NLI data           (12 layers) \n    --model_type 'binwang/bert-base-nli-stsb'   #: BERT Model finetuned on NLI and STSB data  (12 layers) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8140501752797538,
        0.8584190258453707
      ],
      "excerpt": "    --model_type 'binwang/bert-large-nli-stsb'  #: Large BERT finetuned on NLI and STSB data  (24 layers) \nThe way to obtain the sentence embedding from the deep contextualized model can be two ways: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8475855090725422
      ],
      "excerpt": "Choose tasks to evaluate on: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "|    Model                 | STS12 | STS13 | STS14 | STS15 | STS16 | STS-B | SICK-R | Avg.   | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8004856391232574
      ],
      "excerpt": "Many thanks for  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code for Paper: SBERT-WK: A Sentence Embedding Method By  Dissecting BERT-based Word Models",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BinWang28/BERT_Sentence_Embedding/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 22,
      "date": "Sun, 26 Dec 2021 13:26:17 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/BinWang28/SBERT-WK-Sentence-Embedding/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "BinWang28/SBERT-WK-Sentence-Embedding",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/BinWang28/BERT_Sentence_Embedding/master/example1.sh",
      "https://raw.githubusercontent.com/BinWang28/BERT_Sentence_Embedding/master/example2.sh",
      "https://raw.githubusercontent.com/BinWang28/BERT_Sentence_Embedding/master/scripts/sentence-bert/bert-base-nli.sh",
      "https://raw.githubusercontent.com/BinWang28/BERT_Sentence_Embedding/master/scripts/bert-base-nli/bert-base-nli.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We provde a script as an example for generate sentence embedding by giving sentences as strings.\n\nSimply run the script\n```\nchmod +x example2.sh\n./example2.sh\n```\nYou should see the following interaction asking for sentence:\n<p align=\"center\">\n<img src=\"figure2.png\" alt=\"Paris\" class=\"center\" width=\"1000\">\n</p>\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- **bert-base-uncased**: 12 layers, released with paper [BERT](https://arxiv.org/abs/1810.04805)\n- **bert-large-uncased**:\n- **bert-large-nli**:\n- **bert-large-nli-stsb**:\n- **roberta-base**:\n- **xlnet-base-cased**:\n- **bert-large**:\n- **bert-large-nli**:\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "We are using Python 3.7 and the model is implemented with Pytorch 1.3.\nWe also use [transformers v2.2.2](https://github.com/huggingface/transformers)\n\n**Create a new environment**\n```\nconda create -n SBERT-WK python=3.7\nconda activate SBERT-WK\n```\n\n**Install the dependencies**\n\n```\nconda install numpy\nconda install pytorch=1.3 torchvision cudatoolkit=10.1 -c pytorch\npip install transformers==2.2.2\nconda install -c anaconda scikit-learn\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9861497652571211
      ],
      "excerpt": "| Installation                                     | How to setup the environment      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9182112239374733
      ],
      "excerpt": "We have shared 7 models from the https://huggingface.co/models. All the models can be easily accessed by changing the model_type in the above command. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8481812410439217
      ],
      "excerpt": "<img src=\"figure1.png\" alt=\"Paris\" class=\"center\" width=\"500\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python SBERT_WK.py \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/BinWang28/SBERT-WK-Sentence-Embedding/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "sed"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Apache License 2.0",
      "url": "https://api.github.com/licenses/apache-2.0"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD License\\n\\nFor SentEval software\\n\\nCopyright (c) 2017-present, Facebook, Inc. All rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without modification,\\nare permitted provided that the following conditions are met:\\n\\n * Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n * Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n * Neither the name Facebook nor the names of its contributors may be used to\\n   endorse or promote products derived from this software without specific\\n   prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# SBERT-WK: A Sentence Embedding Method By Dissecting BERT-based Word Models",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SBERT-WK-Sentence-Embedding",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "BinWang28",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BinWang28/SBERT-WK-Sentence-Embedding/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n./example1.sh\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 151,
      "date": "Sun, 26 Dec 2021 13:26:17 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We provde a script as an example for generate sentence embedding by giving sentences as strings.\n\nSimply run the script\n```\nchmod +x example2.sh\n./example2.sh\n```\nYou should see the following interaction asking for sentence:\n<p align=\"center\">\n<img src=\"figure2.png\" alt=\"Paris\" class=\"center\" width=\"1000\">\n</p>\n\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
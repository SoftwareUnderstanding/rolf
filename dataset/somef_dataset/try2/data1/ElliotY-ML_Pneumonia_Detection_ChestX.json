{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1711.05225",
      "https://arxiv.org/abs/1711.05225",
      "https://arxiv.org/abs/1711.05225, Dec 2017. [Link](https://arxiv.org/abs/1711.05225)   \n[2]  Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, MohammadhadiBagheri, Ronald M. Summers. \"ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases\", IEEE CVPR, pp. 3462-3471,2017 [Link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf)\n\n\n### Dataset\nThis project uses the ChestX-ray14 dataset curated by Wang et al. and released by NIH Clinical Center. \nIt is comprised of 112,120 X-Ray images with disease labels from 30,805 unique patients.  \nThe disease labels for each image were created using Natural Language Processing (NLP) to process \nassociated radiological reports for fourteen common pathologies. The estimated accuracy of the NLP labeling accuracy is estimated to be >90%.\n\n**References**  \n[1]  Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, MohammadhadiBagheri, Ronald M. Summers. \"ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases\", IEEE CVPR, pp. 3462-3471,2017 [Link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf)\n\n## Getting Started\n\n1. Set up your Anaconda environment.  \n2. Clone `https://github.com/ElliotY-ML/Pneumonia_Detection_ChestX.git` GitHub repo to your local machine.\n3. Open `1_EDA.ipynb` with Jupyter Notebook for exploratory data analysis.\n4. Open `2_Build_and_Train_Model.ipynb` with Jupyter Notebook for image pre-processing with Keras ImageDataGenerator, \nImageNet VGG16 CNN model fine-tuning, and threshold analysis.\n5. Open `3_Inference.ipynb` with Jupyter Notebook for inference with a DICOM file.\n6. Complete project results discussion can be found in `FDA_Preparation.md`.\n\n### Dependencies  \nUsing Anaconda consists of the following:\n\n1. Install [`miniconda`](http://conda.pydata.org/miniconda.html) on your computer, by selecting the latest Python version for your operating system. If you already have `conda` or `miniconda` installed, you should be able to skip this step and move on to step 2.\n2. Create and activate * a new `conda` [environment](http://conda.pydata.org/docs/using/envs.html).\n\n\\* Each time you wish to work on any exercises, activate your `conda` environment!\n\n---\n\n## 1. Installation\n\n**Download** the latest version of `miniconda` that matches your system.\n\n|        | Linux | Mac | Windows | \n|--------|-------|-----|---------|\n| 64-bit | [64-bit (bash installer)][lin64] | [64-bit (bash installer)][mac64] | [64-bit (exe installer)][win64]\n| 32-bit | [32-bit (bash installer)][lin32] |  | [32-bit (exe installer)][win32]\n\n[win64]: https://repo.continuum.io/miniconda/Miniconda3-latest-Windows-x86_64.exe\n[win32]: https://repo.continuum.io/miniconda/Miniconda3-latest-Windows-x86.exe\n[mac64]: https://repo.continuum.io/miniconda/Miniconda3-latest-MacOSX-x86_64.sh\n[lin64]: https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n[lin32]: https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86.sh\n\n**Install** [miniconda](https://docs.conda.io/en/latest/miniconda.html) on your machine. Detailed instructions:\n\n- **Linux:** https://docs.conda.io/en/latest/miniconda.html#linux-installers\n- **Mac:** https://docs.conda.io/en/latest/miniconda.html#macosx-installers\n- **Windows:** https://docs.conda.io/en/latest/miniconda.html#windows-installers\n\n## 2. Create and Activate the Environment\n\nFor Windows users, these following commands need to be executed from the **Anaconda prompt** as opposed to a Windows terminal window. For Mac, a normal terminal window will work. \n\n#### Git and version control\nThese instructions also assume you have `git` installed for working with GitHub from a terminal window, but if you do not, you can download that first with the command:\n```\nconda install git\n```\n\n**Create local environment**\n\n1. Clone the repository, and navigate to the downloaded folder. This may take a minute or two to clone due to the included image data.\n\n```\ngit clone https://github.com/ElliotY-ML/Pneumonia_Detection_ChestX.git\ncd Pneumonia_Detection_ChestX\n```\n\n2. Create and activate a new environment, named `ChestX-Pneumonia` with Python 3.8.  Be sure to run the command from the project root directory since the environment.yml file is there.  If prompted to proceed with the install `(Proceed [y]/n)` type y and press `ENTER`.\n\n\t- __Linux__ or __Mac__: \n\t```\n\tconda env create -f environment.yml\n\tsource activate ChestX-Pneumonia\n\t```\n\t- __Windows__: \n\t```\n\tconda env create -f environment.yml\n\tconda activate ChestX-Pneumonia\n\t```\n\t\n\tAt this point your command line should look something like: `(ChestX-Pneumonia) <User>:USER_DIR <user>$`. The `(ChestX-Pneumonia)` indicates that your environment has been activated.\n\n\n## Repository Instructions\n\nUdacity's original project instructions can be read in the `Project_Overview.md` file.\n\n**Project Overview**\n\n   1. Exploratory Data Analysis\n   2. Building and Training Your Model\n   3. Inference\n   4. FDA Preparation\n\n### Part 1: Exploratory Data Analysis  \n\nOpen `1_EDA.ipynb` with Jupyter Notebook for exploratory data analysis.  The following data are examined:\n1.  ChestX-ray14 Dataset metadata contains information for each X-Ray image file, the associated disease findings, patient gender, age, patient position during X-ray, and image shape.\n2.  Pixel level assessment of X-Ray image files by graphing Intensity Profiles of normalized image pixels.  X-Rays are also displayed using scikit-image.\n\n\n### Part 2: Building and Training Your Model, Fine Tuning Convolutional Neural Network VGG16 for Pneumonia Detection from X-Rays  \n\nInputs:\n- ChestX-ray14 dataset containing 112,120 X-Ray images (.png) in `data/images` and metadata in `data/Data_Entry_2017.csv` file [1].  \n**NOTE:** The dataset is not included in this GitHub repo, because the dataset size is greater than 42GB.  Please download a copy of the dataset from [https://nihcc.app.box.com/v/ChestXray-NIHCC](https://nihcc.app.box.com/v/ChestXray-NIHCC) and unpack into `/data/images`.\n\nOutput:\n- CNN model trained to classify a chest X-Ray image for presence or absence of pneumonia in `/out/my_model1.json`. \n- `/out/xray_class_my_model.best.hdf5` containing model weights.  \n**NOTE:** This is not included in this GitHub repo.\n\n1.  Open `2_Build_and_Train_Model` with Jupyter Notebook.\n2.  Create training data and validation data splits with scikit-learn train_test_split function.\n3.  Ensure training data split is balanced for positive and negative cases.  Ensure validation data split has a positive to negative case ratio that reflects clinical scenarios.  Also check that each split has demographics that are reflective of the overall dataset.\n4.  Prepare image preprocessing for each data split using Keras ImageDataGenerator.\n5.  To fine-tune the ImageNet VGG16 model, create a new Keras Sequential model by adding VGG16 model layers and freezing their ImageNet-trained weights.  Subsequently add Dense and Dropout layers, which will have their weights trained \nfor classifying chest X-Ray images for pneumonia.\n6.  The model training will have a history to show loss metrics at each training epoch.  The best model weights are also captured at each training epoch.\n7.  Model predictions initially return as probabilities between 0 and 1.  These probabilistic results were compared against ground truth labels.  \n8.  A threshold analysis was completed to select the boundary at which probabilistic results are converted into binary results of either pneumonia presence or absence.\n \nThe CheXNet algorithm achieved an F1 score of 0.435, while a panel of four independent Radiologists averaged an F1 score of 0.387 [2]. \nThis project's final F1 score is 0.36, which is similar in performance to the panel of Radiologist. \n\n**References**  \n[1]  Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, Ronald M. Summers. \"ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases\", IEEE CVPR, pp. 3462-3471,2017 [Link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf)  \n[2]  Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, Matthew P. Lungren, Andrew Y. Ng, \"CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning,\"  https://arxiv.org/abs/1711.05225, Dec 2017. [Link](https://arxiv.org/abs/1711.05225)   \n\n\n### Part 3: Inference  \nThe [`3_Inference Jupyter Notebook`](https://github.com/ElliotY-ML/Pneumonia_Detection_ChestX/blob/master/3_Inference.ipynb)\ncontains the functions to load DICOM files, pre-process DICOM image, load the model built in 2_Build_and_Train_Model, and predict the presence of pneumonia from the DICOM image.\n\nInputs:\n- .dcm DICOM medical imaging file, contains metadata and a medical image\n\nOutput:\n- DICOM image is displayed with a prediction of whether the patient is Positive or Negative for Pneumonia\n\nThe following steps should be performed to analyze a chest X-Ray DICOM file:\n1.  Load DICOM file with `check_dicom(filename)` function.  It's output is the DICOM pixel_array or an error message if the DICOM file is not a Chest X-Ray.    \n2.  Pre-process the loaded DICOM image with `preprocess_image(img=pixel_array, img_mean=0, img_std=1, img_size=(1,224,224,3))` function.\n3.  Load trained model with `load_model(model_path, weight_path)`.\n4.  Make prediction with `predict_image(model, img, thresh=0.245)`.\n\n\n\n\n### Part 4: FDA Preparation  \nComplete project results discussion can be found in `FDA_Preparation.md`\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](./LICENSE.md)",
      "https://arxiv.org/abs/1711.05225, Dec 2017. [Link](https://arxiv.org/abs/1711.05225)   \n\n\n### Part 3: Inference  \nThe [`3_Inference Jupyter Notebook`](https://github.com/ElliotY-ML/Pneumonia_Detection_ChestX/blob/master/3_Inference.ipynb)\ncontains the functions to load DICOM files, pre-process DICOM image, load the model built in 2_Build_and_Train_Model, and predict the presence of pneumonia from the DICOM image.\n\nInputs:\n- .dcm DICOM medical imaging file, contains metadata and a medical image\n\nOutput:\n- DICOM image is displayed with a prediction of whether the patient is Positive or Negative for Pneumonia\n\nThe following steps should be performed to analyze a chest X-Ray DICOM file:\n1.  Load DICOM file with `check_dicom(filename)` function.  It's output is the DICOM pixel_array or an error message if the DICOM file is not a Chest X-Ray.    \n2.  Pre-process the loaded DICOM image with `preprocess_image(img=pixel_array, img_mean=0, img_std=1, img_size=(1,224,224,3))` function.\n3.  Load trained model with `load_model(model_path, weight_path)`.\n4.  Make prediction with `predict_image(model, img, thresh=0.245)`.\n\n\n\n\n### Part 4: FDA Preparation  \nComplete project results discussion can be found in `FDA_Preparation.md`\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE.md](./LICENSE.md)"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8892200163403953
      ],
      "excerpt": "The paper of Pranav Rajpurkar et al. (2017), \"CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning\",  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9969284097440679
      ],
      "excerpt": "performance in identifying pneumonia(Wang et al., 2017).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9998697829863598,
        0.9999995525663798
      ],
      "excerpt": "[1]  Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, Matthew P. Lungren, Andrew Y. Ng, \"CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning,\"  arXiv:1711.05225, Dec 2017. Link  \n[2]  Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, MohammadhadiBagheri, Ronald M. Summers. \"ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases\", IEEE CVPR, pp. 3462-3471,2017 Link \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999995525663798
      ],
      "excerpt": "[1]  Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, MohammadhadiBagheri, Ronald M. Summers. \"ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases\", IEEE CVPR, pp. 3462-3471,2017 Link \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999995525663798,
        0.9998697829863598
      ],
      "excerpt": "[1]  Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, Ronald M. Summers. \"ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases\", IEEE CVPR, pp. 3462-3471,2017 Link \n[2]  Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, Matthew P. Lungren, Andrew Y. Ng, \"CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning,\"  arXiv:1711.05225, Dec 2017. Link \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ElliotY-ML/Pneumonia_Detection_ChestX",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-12-30T22:37:45Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-08T17:40:24Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.992743443416831,
        0.9600541176522139,
        0.935971187600677
      ],
      "excerpt": "This repository contains a completed cap-stone project for Udacity's \"Applying AI to 2D Medical Imaging Data\" course,  \npart of the AI for Healthcare Nanodegree program.  It has been reviewed by Udacity instructors and met project specifications. \nAdvancements in deep learning and computer vision allow new opportunities to create software to assist medical \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9695940079326258,
        0.9875245744477251,
        0.9411983875138624,
        0.9284307684504146
      ],
      "excerpt": "In this project, computer vision with a convolutional neural network (CNN) model is trained to predict the presence  \nor absence of pneumonia from chest X-Ray images. The VGG16 CNN model was fine-tuned for this classification task. The intended use for this model is to pre-screen chest X-Ray images prior to radiologists' review to reduce their workload.   \nThe paper of Pranav Rajpurkar et al. (2017), \"CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning\",  \nprovides benchmarks to compare pneumonia classification performance against.  This paper established F1-scores as the metric to compare radiologists' and algorithms'  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9785094144983475,
        0.9736146046899163,
        0.9978108383025658,
        0.8992162238671468,
        0.8363068195869524
      ],
      "excerpt": "F1-scores are the harmonic average of the precision and recall of a model's predictions against ground truth labels. \nIn a subset of 420 images from the ChestX-ray14 dataset, the CheXNet algorithm achieved an F1 score of 0.435, while a panel of four independent Radiologists averaged an F1 score of 0.387.  \nThis project's final F1 score is 0.36, which is similar in performance to the panel of radiologists.  \nThis project is organized in three Jupyter Notebooks: \n- 1_EDA (Exploratory Data Analysis): NIH X-Ray Dataset metadata analysis and X-ray image pixel-level analysis.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9111837671763932
      ],
      "excerpt": "and convert probabilistic outputs to binary predictions. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633227427815967,
        0.8882648268465417,
        0.961411123161879
      ],
      "excerpt": "It is comprised of 112,120 X-Ray images with disease labels from 30,805 unique patients. \nThe disease labels for each image were created using Natural Language Processing (NLP) to process  \nassociated radiological reports for fourteen common pathologies. The estimated accuracy of the NLP labeling accuracy is estimated to be >90%. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8252672762646083
      ],
      "excerpt": "Clone the repository, and navigate to the downloaded folder. This may take a minute or two to clone due to the included image data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8928507211217556,
        0.8767627939209865
      ],
      "excerpt": "Project Overview \nExploratory Data Analysis \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9553156136217841
      ],
      "excerpt": "Open 1_EDA.ipynb with Jupyter Notebook for exploratory data analysis.  The following data are examined: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9457001915403493
      ],
      "excerpt": "2.  Pixel level assessment of X-Ray image files by graphing Intensity Profiles of normalized image pixels.  X-Rays are also displayed using scikit-image. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9878960052642799
      ],
      "excerpt": "- CNN model trained to classify a chest X-Ray image for presence or absence of pneumonia in /out/my_model1.json.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8094900707312603,
        0.8556422219728629,
        0.9506651688964911,
        0.9541253803979916,
        0.8874900088682771,
        0.9230802822200761
      ],
      "excerpt": "NOTE: This is not included in this GitHub repo. \nOpen 2_Build_and_Train_Model with Jupyter Notebook. \nCreate training data and validation data splits with scikit-learn train_test_split function. \nEnsure training data split is balanced for positive and negative cases.  Ensure validation data split has a positive to negative case ratio that reflects clinical scenarios.  Also check that each split has demographics that are reflective of the overall dataset. \nPrepare image preprocessing for each data split using Keras ImageDataGenerator. \nTo fine-tune the ImageNet VGG16 model, create a new Keras Sequential model by adding VGG16 model layers and freezing their ImageNet-trained weights.  Subsequently add Dense and Dropout layers, which will have their weights trained  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8951913477713105,
        0.9797757491282495,
        0.9846513489843463,
        0.9978108383025658
      ],
      "excerpt": "Model predictions initially return as probabilities between 0 and 1.  These probabilistic results were compared against ground truth labels.   \nA threshold analysis was completed to select the boundary at which probabilistic results are converted into binary results of either pneumonia presence or absence. \nThe CheXNet algorithm achieved an F1 score of 0.435, while a panel of four independent Radiologists averaged an F1 score of 0.387 [2].  \nThis project's final F1 score is 0.36, which is similar in performance to the panel of Radiologist.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9327430397309686
      ],
      "excerpt": "contains the functions to load DICOM files, pre-process DICOM image, load the model built in 2_Build_and_Train_Model, and predict the presence of pneumonia from the DICOM image. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9946211916438883
      ],
      "excerpt": "- DICOM image is displayed with a prediction of whether the patient is Positive or Negative for Pneumonia \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Udacity AI for Healthcare Nanodegree Project:  Deep Learning Model for Detecting Pneumonia in 2-D Chest X-Rays ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ElliotY-ML/Pneumonia_Detection_ChestX/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 26 Dec 2021 17:28:09 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ElliotY-ML/Pneumonia_Detection_ChestX/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ElliotY-ML/Pneumonia_Detection_ChestX",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ElliotY-ML/Pneumonia_Detection_ChestX/master/3_Inference.ipynb",
      "https://raw.githubusercontent.com/ElliotY-ML/Pneumonia_Detection_ChestX/master/1_EDA.ipynb",
      "https://raw.githubusercontent.com/ElliotY-ML/Pneumonia_Detection_ChestX/master/2_Build_and_Train_Model.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Complete project results discussion can be found in `FDA_Preparation.md`\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "**Download** the latest version of `miniconda` that matches your system.\n\n|        | Linux | Mac | Windows | \n|--------|-------|-----|---------|\n| 64-bit | [64-bit (bash installer)][lin64] | [64-bit (bash installer)][mac64] | [64-bit (exe installer)][win64]\n| 32-bit | [32-bit (bash installer)][lin32] |  | [32-bit (exe installer)][win32]\n\n[win64]: https://repo.continuum.io/miniconda/Miniconda3-latest-Windows-x86_64.exe\n[win32]: https://repo.continuum.io/miniconda/Miniconda3-latest-Windows-x86.exe\n[mac64]: https://repo.continuum.io/miniconda/Miniconda3-latest-MacOSX-x86_64.sh\n[lin64]: https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n[lin32]: https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86.sh\n\n**Install** [miniconda](https://docs.conda.io/en/latest/miniconda.html) on your machine. Detailed instructions:\n\n- **Linux:** https://docs.conda.io/en/latest/miniconda.html#linux-installers\n- **Mac:** https://docs.conda.io/en/latest/miniconda.html#macosx-installers\n- **Windows:** https://docs.conda.io/en/latest/miniconda.html#windows-installers\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.986699019070457,
        0.9917679656889693,
        0.9995467759691481,
        0.832502444423176
      ],
      "excerpt": "For Windows users, these following commands need to be executed from the Anaconda prompt as opposed to a Windows terminal window. For Mac, a normal terminal window will work. \nThese instructions also assume you have git installed for working with GitHub from a terminal window, but if you do not, you can download that first with the command: \nconda install git \nCreate local environment \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9893272198983933,
        0.9906248903846466,
        0.9330357745629474,
        0.869220493838264,
        0.9632347459754548,
        0.9554169436001461,
        0.9401400739544492,
        0.9632347459754548,
        0.9770335174395833
      ],
      "excerpt": "git clone https://github.com/ElliotY-ML/Pneumonia_Detection_ChestX.git \ncd Pneumonia_Detection_ChestX \nCreate and activate a new environment, named ChestX-Pneumonia with Python 3.8.  Be sure to run the command from the project root directory since the environment.yml file is there.  If prompted to proceed with the install (Proceed [y]/n) type y and press ENTER. \nLinux or Mac:  \nconda env create -f environment.yml \nsource activate ChestX-Pneumonia \nWindows:  \nconda env create -f environment.yml \nconda activate ChestX-Pneumonia \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8385306302772959
      ],
      "excerpt": "Open 2_Build_and_Train_Model with Jupyter Notebook. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8941393892979759
      ],
      "excerpt": "The 3_Inference Jupyter Notebook \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401545985922884
      ],
      "excerpt": "The following steps should be performed to analyze a chest X-Ray DICOM file: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8814039732929427
      ],
      "excerpt": "Figure 1. Example of in-line prediction output in 3_Inference.ipynb Jupyter Notebook  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8985358801707597
      ],
      "excerpt": "- ChestX-ray14 dataset containing 112,120 X-Ray images (.png) in data/images and metadata in data/Data_Entry_2017.csv file [1]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8634460559962234
      ],
      "excerpt": "1.  Load DICOM file with check_dicom(filename) function.  It's output is the DICOM pixel_array or an error message if the DICOM file is not a Chest X-Ray.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.846029179272124
      ],
      "excerpt": "3.  Load trained model with load_model(model_path, weight_path). \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ElliotY-ML/Pneumonia_Detection_ChestX/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'PROJECT LICENSE\\n\\nThis project was submitted by Elliot Yu as part of the Nanodegree At Udacity.\\n\\nAs agreed upon under the Udacity Honor code, your submissions must be your own work.  \\nIf you submit this project as your own work, you break the Udacity Honor Code and risk\\nthe suspension of your Udacity account.\\n\\nI, the author of the project, allow you to check the code only as a reference. \\nThe author shall not be liable for any claim, damages, or other liability if you \\npresent this project as your own work.\\n\\nCopyright (c) 2020 Elliot Yu\\n\\n\\nThe following license applies and this license notice\\nshall be included in all works derived from this project.\\n\\n\\nMIT License\\n\\nCopyright (c) 2020 Udacity\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Pneumonia Detection From X-Rays",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Pneumonia_Detection_ChestX",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ElliotY-ML",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ElliotY-ML/Pneumonia_Detection_ChestX/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Using Anaconda consists of the following:\n\n1. Install [`miniconda`](http://conda.pydata.org/miniconda.html) on your computer, by selecting the latest Python version for your operating system. If you already have `conda` or `miniconda` installed, you should be able to skip this step and move on to step 2.\n2. Create and activate * a new `conda` [environment](http://conda.pydata.org/docs/using/envs.html).\n\n\\* Each time you wish to work on any exercises, activate your `conda` environment!\n\n---\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 26 Dec 2021 17:28:09 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "cnn-keras",
      "image-classification",
      "dicom",
      "xray-detection"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Set up your Anaconda environment.  \n2. Clone `https://github.com/ElliotY-ML/Pneumonia_Detection_ChestX.git` GitHub repo to your local machine.\n3. Open `1_EDA.ipynb` with Jupyter Notebook for exploratory data analysis.\n4. Open `2_Build_and_Train_Model.ipynb` with Jupyter Notebook for image pre-processing with Keras ImageDataGenerator, \nImageNet VGG16 CNN model fine-tuning, and threshold analysis.\n5. Open `3_Inference.ipynb` with Jupyter Notebook for inference with a DICOM file.\n6. Complete project results discussion can be found in `FDA_Preparation.md`.\n\n",
      "technique": "Header extraction"
    }
  ]
}
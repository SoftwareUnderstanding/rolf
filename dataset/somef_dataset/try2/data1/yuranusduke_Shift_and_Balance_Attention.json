{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1709.01507 "
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Shift-and-Balance Attention [[arXiv]](https://arxiv.org/pdf/2103.13080)\n- Squeeze-and-Excitation Networks [[arXiv]](https://arxiv.org/abs/1709.01507 )\n\n***<center>Veni\uff0cvidi\uff0cvici --Caesar</center>***\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yuranusduke/Shift_and_Balance_Attention",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-28T13:36:08Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-26T07:49:31Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9939521117284813
      ],
      "excerpt": "First of all, thank the authors very much for sharing this excellent paper Shift-and-Balance Attention with us. This repository contains SB Attention and simple verification for modified VGG16 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9540715918169895,
        0.9509865270527353
      ],
      "excerpt": "In this paper, authors rethink the idea from SE net. They argue that SE may make gradient vanishing and lead to the wastage of channels due the use of Sigmoid function, and also it constrains the attention \nbranch to a certain degree, scaled attention is too sensitive to coordinate and balance the two branches\u2019 contributions. Therefore, they propose Shift-and-Balance(SB) Attention to address above problems. The diagram shows as follows, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8451472718380851
      ],
      "excerpt": "--attn_ratio=0.5 #: hidden size ratio in the SB or SE operation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "| Model             | Acc.        | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementations of paper <Shift-and-Balance Attention>",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yuranusduke/Shift_and_Balance_Attention/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Wed, 29 Dec 2021 03:59:26 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yuranusduke/Shift_and_Balance_Attention/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "yuranusduke/Shift_and_Balance_Attention",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.933920285581959
      ],
      "excerpt": "--device='cuda' #: 'cuda' for gpu, 'cpu' otherwise \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8131657483702079
      ],
      "excerpt": "--batch_size=64 #: batch size \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9595166124706711
      ],
      "excerpt": "    python example.py main \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "        --use_sb=True \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yuranusduke/Shift_and_Balance_Attention/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 yuranus\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Reproducing ***Shift-and-Balance Attention***",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Shift_and_Balance_Attention",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "yuranusduke",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yuranusduke/Shift_and_Balance_Attention/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```Python\npip install -r requirements.txt \n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Wed, 29 Dec 2021 03:59:26 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "| Activation        | Acc.        |\n| ----------------- | ----------- |\n| Tanh            \t| 92.22%      |\n| Sigmoid         \t| **92.66%**  |\n| ReLU   \t\t\t| 92.24%      |\n| Softmax   \t\t| 92.30%      |\n| Linear   \t\t\t| 92.18%      |\n\n**Note**: I can't use Tanh in SB to get great performance to surpass SE, but Sigmoid may be promising.\n\n",
      "technique": "Header extraction"
    }
  ]
}
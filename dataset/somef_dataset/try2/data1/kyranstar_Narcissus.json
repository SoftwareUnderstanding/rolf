{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1701.01879"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9976709956161752
      ],
      "excerpt": "     Implementation of Gacav, C.; Benligiray, B.; Topal, C., \"Greedy search for descriptive spatial face features,\" International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2017. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8177918124334298
      ],
      "excerpt": "PG GAN for face generation: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kyranstar/Narcissus",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-12-03T02:16:54Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-12-25T11:53:18Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nNarcissus is an interactive art installation which takes an image of the viewer, compresses it into a set of descriptive features, and produces the \"reflection\" of those features as a neural network sees it. Particularly, this Generative Adversarial Network (GAN) draws the viewer's reflection from its artificial, distinctly neural \"latent\" space which it learns from its training dataset. I used a GAN trained on a well-known celebrity face dataset, CelebA-HQ, meaning that the neural network learns to reproduce faces of celebrities. Narcissus intends to raise more self-reflecting questions in the viewer than it answers, many of which are becoming increasingly relevant.\r\n\r\nWhen the viewer looks into the mirror and sees a foreign face stare back, similarities and differences are visceral. What makes a celebrity\u2019s face different from ours? How does the generated face staring back at us reflect what we deem as special, as 'celebrity', or as beautiful? More broadly, how do the deep-seated biases inherent in our everyday society lie hidden in the datasets we collect?\r\n\r\nThese questions are all the more important in the new age of artificial intelligence; those biased datasets we use lead to inherently biased data-driven artificial intelligence models. Without sufficient checks and balances, data-driven systems can also create feedback loops resulting in an amplification of these biases, such as in [recidivism prediction](https://www.technologyreview.com/s/612775/algorithms-criminal-justice-ai/). As well as this, since data is necessarily a reduction of objective reality, models that learn only from training data will never have the full picture and there will always be cases where it lacks common sense. For example, if a model is trained on current recidivism data to predict recidivism rates, even if the data contains no information about race, the model might learn that certain crimes are committed by certain classes of people corresponding to race, and use that information to predict rates that might still be disproportionate across race. We must be careful not to blindly believe that these systems will not perpetuate the biases and mistakes of our current or previous societies.\r\n\r\nAs well as this, the model often makes mistakes that seem obvious to us, producing a celebrity that looks totally different from the viewer. Even though the celebrity is a product of the viewer's data, *is* it the viewer? This again brings to attention the point that data is simply a reduction of objective reality. How can we reduce the important features of a human to a representation in data? Is there a minimum amount of data that can represent a human? Corporations are collecting and consolidating data into unprecedented [data lakes]() with data sources from [amazon ring](https://www.usatoday.com/story/tech/2019/10/29/amazon-ring-doorbell-cams-police-home-security/2493974001/), [](), and [](). While this data can be used to build powerful models, these models will never operate on objective reality, but just a reduction of it. As we progress into the age of big data and powerful models that are increasingly replacing humans in important decision-making including punishment sentencing, [facial recognition in HK](https://www.nytimes.com/2019/07/26/technology/hong-kong-protests-facial-recognition-surveillance.html), and [healthcare](https://www.nytimes.com/2019/03/21/science/health-medicine-artificial-intelligence.html), we need to be wary of the inadvertant effects caused by a general lack of human \"common sense\" in these models due to inherent properties of data.\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9797058122497933
      ],
      "excerpt": "This is my implementation of the system behind my artwork, Narcissus. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8930901044020226,
        0.9706224007426627
      ],
      "excerpt": "Face features: \n     Implementation of Gacav, C.; Benligiray, B.; Topal, C., \"Greedy search for descriptive spatial face features,\" International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2017. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9623416687248536
      ],
      "excerpt": "     Implementation of \"Progressive Growing of GANs for Improved Quality, Stability, and Variation\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9891785691729262,
        0.9973735307516538,
        0.9805526553753238,
        0.8959796327609657
      ],
      "excerpt": "Picture is featurized \nFeatures are converted to GAN latent space with learned inverter model \nLatent space is generated to create neural mirror image \nNeural image is displayed \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "The system for my interactive art exhibition, Narcissus.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kyranstar/Narcissus/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 00:30:05 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kyranstar/Narcissus/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "kyranstar/Narcissus",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.85576814798418
      ],
      "excerpt": "<img src=\"demo_img/img1.png\" height=\"256\" width=\"256\"> <img src=\"demo_img/img2.png\" height=\"256\" width=\"256\"> <img src=\"demo_img/img3.png\" height=\"256\" width=\"256\"> <img src=\"demo_img/img4.png\" height=\"256\" width=\"256\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8475120437410435
      ],
      "excerpt": "Download PG GAN .pkl file from here and put it in models/pg_gan \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kyranstar/Narcissus/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2017 Yin Guobing\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Narcissus:",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Narcissus",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "kyranstar",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kyranstar/Narcissus/blob/master/readme.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n* Both Linux and Windows are supported.\r\n* 64-bit Python 3.6 installation with numpy 1.13.3 or newer. We recommend Anaconda3.\r\n* One or more GPUs to run Tensorflow on. Has been tested with a GTX 980 and works with very little lag.\r\n* NVIDIA driver 391.25 or newer, CUDA toolkit 9.0 or newer, cuDNN 7.1.2 or newer.\r\n* Additional Python packages listed in `requirements.txt`\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Train models\r\n2. Run `python generate_live_video_multi.py`\r\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 00:30:05 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1905.04899",
      "https://arxiv.org/abs/1610.02915",
      "https://arxiv.org/abs/1802.02375",
      "https://arxiv.org/abs/1710.09412",
      "https://arxiv.org/abs/1806.05236",
      "https://arxiv.org/abs/1708.04552",
      "https://arxiv.org/abs/1810.12890",
      "https://arxiv.org/abs/1512.03385",
      "https://arxiv.org/abs/1710.09412",
      "https://arxiv.org/abs/1806.05236",
      "https://arxiv.org/abs/1708.04552",
      "https://arxiv.org/abs/1805.09501",
      "https://arxiv.org/abs/1810.12890"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\r\n@inproceedings{yun2019cutmix,\r\n    title={CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features},\r\n    author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},\r\n    booktitle = {International Conference on Computer Vision (ICCV)},\r\n    year={2019},\r\n    pubstate={published},\r\n    tppubtype={inproceedings}\r\n}\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{yun2019cutmix,\n    title={CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features},\n    author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},\n    booktitle = {International Conference on Computer Vision (ICCV)},\n    year={2019},\n    pubstate={published},\n    tppubtype={inproceedings}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9702105236373249
      ],
      "excerpt": "Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, Youngjoon Yoo. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9047552191178093
      ],
      "excerpt": "23 May, 2019: Initial upload \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/clovaai/CutMix-PyTorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-29T02:32:07Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-28T01:27:07Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9652426000431177
      ],
      "excerpt": "Official Pytorch implementation of CutMix regularizer | Paper | Pretrained Models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9943069599812117
      ],
      "excerpt": "Our implementation is based on these repositories: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8722545289928759,
        0.9866575067581979,
        0.8539093695470306
      ],
      "excerpt": "Regional dropout strategies have been proposed to enhance the performance of convolutional neural network classifiers.  \nThey have proved to be effective for guiding the model to attend on less discriminative parts of objects  \n(e.g. leg as opposed to head of a person), thereby letting the network generalize better and have better object localization capabilities. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8883380788518697,
        0.959354299296714,
        0.952930061092774,
        0.9079583746381914,
        0.9328475362629037
      ],
      "excerpt": "Such removal is not desirable because it leads to information loss and inefficiency during training. \nWe therefore propose the CutMix augmentation strategy: patches are cut and pasted among training images where the ground truth labels are also mixed proportionally to the area of the patches. \nBy making efficient use of training pixels and retaining the regularization effect of regional dropout, CutMix consistently outperforms the state-of-the-art augmentation strategies on CIFAR and ImageNet classification tasks, as well as on the ImageNet weakly-supervised localization task. \nMoreover, unlike previous augmentation methods, our CutMix-trained ImageNet classifier, when used as a pretrained model, results in consistent performance gains in Pascal detection and MS-COCO image captioning benchmarks. \nWe also show that CutMix improves the model robustness against input corruptions and its out-of-distribution detection performances. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Official Pytorch implementation of CutMix regularizer",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/clovaai/CutMix-PyTorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 143,
      "date": "Tue, 28 Dec 2021 09:18:38 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/clovaai/CutMix-PyTorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "clovaai/CutMix-PyTorch",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9322609392449874
      ],
      "excerpt": "- PyramidNet-PyTorch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.910754799098298
      ],
      "excerpt": "Pytorch-CutMix by @hysts \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8890818307099057
      ],
      "excerpt": "<img width=\"600\" alt=\"teaser\" src=\"./img1.PNG\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8610030811827639
      ],
      "excerpt": "ResNet50+Mixup | 22.58 | 45.84 | 49.3 | 76.6 | 73.9 | 23.2 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/clovaai/CutMix-PyTorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright (c) 2019-present NAVER Corp.\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\nTHE SOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Accepted at ICCV 2019 (oral talk) !!",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "CutMix-PyTorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "clovaai",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/clovaai/CutMix-PyTorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Python3\r\n- PyTorch (> 1.0)\r\n- torchvision (> 0.2)\r\n- NumPy\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 935,
      "date": "Tue, 28 Dec 2021 09:18:38 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "cutmix",
      "augmentation",
      "regularization",
      "transfer-learning",
      "iccv2019"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- CIFAR-100: We used 2 GPUs to train CIFAR-100.\r\n```\r\npython train.py \\\r\n--net_type pyramidnet \\\r\n--dataset cifar100 \\\r\n--depth 200 \\\r\n--alpha 240 \\\r\n--batch_size 64 \\\r\n--lr 0.25 \\\r\n--expname PyraNet200 \\\r\n--epochs 300 \\\r\n--beta 1.0 \\\r\n--cutmix_prob 0.5 \\\r\n--no-verbose\r\n```\r\n- ImageNet: We used 4 GPUs to train ImageNet. \r\n```\r\npython train.py \\\r\n--net_type resnet \\\r\n--dataset imagenet \\\r\n--batch_size 256 \\\r\n--lr 0.1 \\\r\n--depth 50 \\\r\n--epochs 300 \\\r\n--expname ResNet50 \\\r\n-j 40 \\\r\n--beta 1.0 \\\r\n--cutmix_prob 1.0 \\\r\n--no-verbose\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- Download [CutMix-pretrained PyramidNet200 (top-1 error: 14.23)](https://www.dropbox.com/sh/o68qbvayptt2rz5/AACy3o779BxoRqw6_GQf_QFQa?dl=0) \r\n```\r\npython test.py \\\r\n--net_type pyramidnet \\\r\n--dataset cifar100 \\\r\n--batch_size 64 \\\r\n--depth 200 \\\r\n--alpha 240 \\\r\n--pretrained /set/your/model/path/model_best.pth.tar\r\n```\r\n- Download [CutMix-pretrained ResNet50 (top-1 error: 21.40)](https://www.dropbox.com/sh/w8dvfgdc3eirivf/AABnGcTO9wao9xVGWwqsXRala?dl=0)\r\n```\r\npython test.py \\\r\n--net_type resnet \\\r\n--dataset imagenet \\\r\n--batch_size 64 \\\r\n--depth 50 \\\r\n--pretrained /set/your/model/path/model_best.pth.tar\r\n```\r\n\r\n<h2 id=\"experiments\">Experimental Results and Pretrained Models</h2>\r\n\r\n- PyramidNet-200 pretrained on CIFAR-100 dataset:\r\n\r\nMethod | Top-1 Error | Model file\r\n-- | -- | --\r\nPyramidNet-200 [[CVPR'17](https://arxiv.org/abs/1610.02915)] (baseline) | 16.45 | [model](https://www.dropbox.com/sh/6rfew3lr761jq6c/AADrdQOXNx5tWmgOSnAw9NEVa?dl=0)\r\nPyramidNet-200 + **CutMix** | **14.23** | [model](https://www.dropbox.com/sh/o68qbvayptt2rz5/AACy3o779BxoRqw6_GQf_QFQa?dl=0)\r\nPyramidNet-200 + Shakedrop [[arXiv'18](https://arxiv.org/abs/1802.02375)] + **CutMix**  | **13.81** | -\r\nPyramidNet-200 + Mixup [[ICLR'18](https://arxiv.org/abs/1710.09412)] | 15.63 | [model](https://www.dropbox.com/sh/g55jnsv62v0n59s/AAC9LPg-LjlnBn4ttKs6vr7Ka?dl=0)\r\nPyramidNet-200 + Manifold Mixup [[ICML'19](https://arxiv.org/abs/1806.05236)] | 16.14 | [model](https://www.dropbox.com/sh/nngw7hhk1e8msbr/AABkdCsP0ABnQJDBX7LQVj4la?dl=0)\r\nPyramidNet-200 + Cutout [[arXiv'17](https://arxiv.org/abs/1708.04552)] | 16.53 | [model](https://www.dropbox.com/sh/ajjz4q8c8t6qva9/AAAeBGb2Q4TnJMW0JAzeVSpfa?dl=0)\r\nPyramidNet-200 + DropBlock [[NeurIPS'18](https://arxiv.org/abs/1810.12890)] | 15.73 | [model](https://www.dropbox.com/sh/vefjo960gyrsx2i/AACYA5wOJ_yroNjIjdsN1Dz2a?dl=0)\r\nPyramidNet-200 + Cutout + Labelsmoothing | 15.61 | [model](https://www.dropbox.com/sh/1mur0kjcfxdn7jn/AADmghqrj0dXAG0qY1v3Csb6a?dl=0)\r\nPyramidNet-200 + DropBlock + Labelsmoothing | 15.16 | [model](https://www.dropbox.com/sh/n1dn6ggyxjcoogc/AADpSSNzvaraSCqWtHBE0qMca?dl=0)\r\nPyramidNet-200 + Cutout + Mixup | 15.46 | [model](https://www.dropbox.com/sh/5run1sx8oy0v9oi/AACiR_wEBQVp2HMZFx6lGl3ka?dl=0)\r\n\r\n\r\n- ResNet models pretrained on ImageNet dataset:\r\n\r\nMethod | Top-1 Error | Model file\r\n-- | -- | --\r\nResNet-50 [[CVPR'16](https://arxiv.org/abs/1512.03385)] (baseline) | 23.68 | [model](https://www.dropbox.com/sh/phwbbrtadrclpnx/AAA9QUW9G_xvBdI-mDiIzP_Ha?dl=0)\r\nResNet-50 + **CutMix** | **21.40** | [model](https://www.dropbox.com/sh/w8dvfgdc3eirivf/AABnGcTO9wao9xVGWwqsXRala?dl=0)\r\nResNet-50 + **Feature CutMix** | **21.80** | [model](https://www.dropbox.com/sh/zj1wptsg0hwqf0k/AABRNzvjFmIS7_vOEQkqb6T4a?dl=0)\r\nResNet-50 + Mixup [[ICLR'18](https://arxiv.org/abs/1710.09412)] | 22.58 | [model](https://www.dropbox.com/sh/g64c8bda61n12if/AACyaTZnku_Sgibc9UvOSblNa?dl=0)\r\nResNet-50 + Manifold Mixup [[ICML'19](https://arxiv.org/abs/1806.05236)] | 22.50 | [model](https://www.dropbox.com/sh/bjardjje11pti0g/AABFGW0gNrNE8o8TqUf4-SYSa?dl=0)\r\nResNet-50 + Cutout [[arXiv'17](https://arxiv.org/abs/1708.04552)] | 22.93 | [model](https://www.dropbox.com/sh/ln8zk2z7zt2h1en/AAA7z8xTBlzz7Ofbd5L7oTnTa?dl=0)\r\nResNet-50 + AutoAugment [[CVPR'19](https://arxiv.org/abs/1805.09501)] | 22.40* | -\r\nResNet-50 + DropBlock [[NeurIPS'18](https://arxiv.org/abs/1810.12890)] | 21.87* | -\r\nResNet-101 + **CutMix** | **20.17** | [model](https://www.dropbox.com/sh/1z4xnp9nwdmpzb5/AACQX4KU8XkTN0JSTfjkCktNa?dl=0)\r\nResNet-152 + **CutMix** | **19.20** | [model](https://www.dropbox.com/s/6vq1mzy27z8qxko/resnet152_cutmix_acc_80_80.pth?dl=0)\r\nResNeXt-101 (32x4d) + **CutMix** | **19.47** | [model](https://www.dropbox.com/s/maysvgopsi17qi0/resnext_cutmix.pth.tar?dl=0)\r\n\r\n\\* denotes results reported in the original papers\r\n\r\n",
      "technique": "Header extraction"
    }
  ]
}
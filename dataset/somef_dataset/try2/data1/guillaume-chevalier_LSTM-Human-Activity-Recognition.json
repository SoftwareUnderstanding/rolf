{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Human Activity Recognition (HAR) using smartphones dataset and an LSTM RNN. Classifying the type of movement amongst six categories:\n- WALKING,\n- WALKING_UPSTAIRS,\n- WALKING_DOWNSTAIRS,\n- SITTING,\n- STANDING,\n- LAYING.\n\nCompared to a classical approach, using a Recurrent Neural Networks (RNN) with Long Short-Term Memory cells (LSTMs) require no or almost no feature engineering. Data can be fed directly into the neural network who acts like a black box, modeling the problem correctly. [Other research](https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.names) on the activity recognition dataset can use a big amount of feature engineering, which is rather a signal processing approach combined with classical data science techniques. The approach here is rather very simple in terms of how much was the data preprocessed.\n\nLet's use Google's neat Deep Learning library, TensorFlow, demonstrating the usage of an LSTM, a type of Artificial Neural Network that can process sequential data / time series.\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1708.08989"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Copyright (c) 2016 Guillaume Chevalier. To cite my code, you can point to the URL of the GitHub repository, for example:\n\n> Guillaume Chevalier, LSTMs for Human Activity Recognition, 2016,\n> https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition\n\nMy code is available for free and even for private usage for anyone under the [MIT License](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/blob/master/LICENSE), however I ask to cite for using the code.\n\nHere is the BibTeX citation code: \n```\n@misc{chevalier2016lstms,\n  title={LSTMs for human activity recognition},\n  author={Chevalier, Guillaume},\n  year={2016}\n}\n```\n\nI've also published a second paper, with contributors, regarding a [second iteration as an improvement of this work](https://github.com/guillaume-chevalier/HAR-stacked-residual-bidir-LSTMs), with deeper neural networks. The paper is available on [arXiv](https://arxiv.org/abs/1708.08989). Here is the BibTeX citation code for this newer piece of work based on this project: \n```\n@article{DBLP:journals/corr/abs-1708-08989,\n  author    = {Yu Zhao and\n               Rennong Yang and\n               Guillaume Chevalier and\n               Maoguo Gong},\n  title     = {Deep Residual Bidir-LSTM for Human Activity Recognition Using Wearable\n               Sensors},\n  journal   = {CoRR},\n  volume    = {abs/1708.08989},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1708.08989},\n  archivePrefix = {arXiv},\n  eprint    = {1708.08989},\n  timestamp = {Mon, 13 Aug 2018 16:46:48 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-08989},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "The [dataset](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) can be found on the UCI Machine Learning Repository:\n\n> Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{DBLP:journals/corr/abs-1708-08989,\n  author    = {Yu Zhao and\n               Rennong Yang and\n               Guillaume Chevalier and\n               Maoguo Gong},\n  title     = {Deep Residual Bidir-LSTM for Human Activity Recognition Using Wearable\n               Sensors},\n  journal   = {CoRR},\n  volume    = {abs/1708.08989},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1708.08989},\n  archivePrefix = {arXiv},\n  eprint    = {1708.08989},\n  timestamp = {Mon, 13 Aug 2018 16:46:48 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-08989},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{chevalier2016lstms,\n  title={LSTMs for human activity recognition},\n  author={Chevalier, Guillaume},\n  year={2016}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9613066758008434
      ],
      "excerpt": "  <a href=\"https://youtu.be/XOEN9W05_4A\"><center>[Watch video]</center></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": ": Useful Constants \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9466614351006817
      ],
      "excerpt": "plt.title(\"Training session's progress over iterations\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9195926162616405
      ],
      "excerpt": "Machine Learning Consulting \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-05-18T02:00:21Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T09:10:00Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9692725644518796
      ],
      "excerpt": "Follow this link to see a video of the 6 activities recorded in the experiment with one of the participants: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9946048329797945,
        0.9741490522672118,
        0.983339738155277,
        0.9117634968192243,
        0.9602104195424678,
        0.9870745637479839,
        0.9602104195424678,
        0.8372396012058242
      ],
      "excerpt": "I will be using an LSTM on the data to learn (as a cellphone attached on the waist) to recognise the type of activity that the user is doing. The dataset's description goes like this: \nThe sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. \nThat said, I will use the almost raw data: only the gravity effect has been filtered out of the accelerometer  as a preprocessing step for another 3D feature as an input to help learning. If you'd ever want to extract the gravity by yourself, you could fork my code on using a Butterworth Low-Pass Filter (LPF) in Python and edit it to have the right cutoff frequency of 0.3 Hz which is a good frequency for activity recognition from body sensors. \nAs explained in this article, an RNN takes many input vectors to process them and output other vectors. It can be roughly pictured like in the image below, imagining each rectangle has a vectorial depth and other special hidden quirks in the image below. In our case, the \"many to one\" architecture is used: we accept time series of feature vectors (one vector per time step) to convert them to a probability vector at the output for classification. Note that a \"one to one\" architecture would be a standard feedforward neural network. \nLearn more on RNNs \nAn LSTM is an improved RNN. It is more complex, but easier to train, avoiding what is called the vanishing gradient problem. I recommend this course for you to learn more on LSTMs. \nLearn more on LSTMs \nScroll on! Nice visuals awaits. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9225059859290892
      ],
      "excerpt": ": Those are separate normalised input features for the neural network \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8414859152072585
      ],
      "excerpt": ": Output classes to learn how to classify \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9323692409731557,
        0.8828593860674969
      ],
      "excerpt": "Here are some core parameter definitions for the training. \nFor example, the whole neural network's structure could be summarised by enumerating those parameters and the fact that two LSTM are used one on top of another (stacked) output-to-input as hidden layers through time steps. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.937281642477713
      ],
      "excerpt": "n_hidden = 32 #: Hidden layer num of features \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8621727709312228,
        0.9465750742249861,
        0.8735050286564938
      ],
      "excerpt": "    #: Moreover, two LSTM cells are stacked which adds deepness to the neural network. \n    #: Note, some code of this notebook is inspired from an slightly different \n    #: RNN architecture used on another dataset, some of the credits goes to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865,
        0.9053797560938441
      ],
      "excerpt": "_X = tf.transpose(_X, [1, 0, 2])  #: permute n_steps and batch_size \n#: Reshape to prepare input to hidden activation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.969873105431799
      ],
      "excerpt": "#: Split data because rnn cell needs a list of inputs for the RNN inner loop \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9225958592679936
      ],
      "excerpt": "#: as in the image describing RNNs at the top of this page \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9102402451063443
      ],
      "excerpt": "    #: Function to fetch a \"batch_size\" amount of data from \"(X|y)_train\" data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.876420504158502
      ],
      "excerpt": ": To keep track of training's performance \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8115604960247547
      ],
      "excerpt": "#: Evaluate network only at some steps for faster training: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "Instructions for updating: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9878117704832673
      ],
      "excerpt": "print(\"so it is normal that more than a 6th of the data is correctly classifier in the last category.\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8702140655389747,
        0.9970061781383103
      ],
      "excerpt": "Note: training and testing data is not equally distributed amongst classes, \nso it is normal that more than a 6th of the data is correctly classifier in the last category. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9778490803649609,
        0.9890573770267095,
        0.9810498861894561,
        0.981600088614108,
        0.9971132622840887,
        0.9968080132192175,
        0.9703705800403688,
        0.9928990314195647,
        0.8380463177898574
      ],
      "excerpt": "Outstandingly, the final accuracy is of 91%! And it can peak to values such as 93.25%, at some moments of luck during the training, depending on how the neural network's weights got initialized at the start of the training, randomly. \nThis means that the neural networks is almost always able to correctly identify the movement type! Remember, the phone is attached on the waist and each series to classify has just a 128 sample window of two internal sensors (a.k.a. 2.56 seconds at 50 FPS), so it amazes me how those predictions are extremely accurate given this small window of context and raw data. I've validated and re-validated that there is no important bug, and the community used and tried this code a lot. (Note: be sure to report something in the issue tab if you find bugs, otherwise Quora, StackOverflow, and other StackExchange sites are the places for asking questions.) \nI specially did not expect such good results for guessing between the labels \"SITTING\" and \"STANDING\". Those are seemingly almost the same thing from the point of view of a device placed at waist level according to how the dataset was originally gathered. Thought, it is still possible to see a little cluster on the matrix between those classes, which drifts away just a bit from the identity. This is great. \nIt is also possible to see that there was a slight difficulty in doing the difference between \"WALKING\", \"WALKING_UPSTAIRS\" and \"WALKING_DOWNSTAIRS\". Obviously, those activities are quite similar in terms of movements. \nI also tried my code without the gyroscope, using only the 3D accelerometer's 6 features (and not changing the training hyperparameters), and got an accuracy of 87%. In general, gyroscopes consumes more power than accelerometers, so it is preferable to turn them off. \nIn another open-source repository of mine, the accuracy is pushed up to nearly 94% using a special deep LSTM architecture which combines the concepts of bidirectional RNNs, residual connections, and stacked cells. This architecture is also tested on another similar activity dataset. It resembles the nice architecture used in \"Google\u2019s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\", without an attention mechanism, and with just the encoder part - as a \"many to one\" architecture instead of a \"many to many\" to be adapted to the Human Activity Recognition (HAR) problem. I also worked more on the problem and came up with the LARNN, however it's complicated for just a little gain. Thus the current, original activity recognition project is simply better to use for its simplicity. We've also coded a non-deep learning machine learning pipeline on the same datasets using classical featurization techniques and older machine learning algorithms. \nIf you want to learn more about deep learning, I have also built a list of the learning ressources for deep learning which have revealed to be the most useful to me here. You may also be interested in my online course on Deep Learning and Recurrent Neural Networks (DL&RNN). \nI also have made even more improvements as seen just below with the few lines of code for easier usage and for reaching an even better score. Note this this is still an ongoing project, subscribe here to learn more. \nVisit Neuraxio's Time Series Solution product page for more information. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8306040624625453
      ],
      "excerpt": "Join our slack workspace for time series processing, where you can:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9694437062816835,
        0.8819727725731455,
        0.9749436397641429
      ],
      "excerpt": "Do business with us and other companies for services and products related to time series processing, in the #business channel; \nTalk about how to do Clean Machine Learning using Neuraxle, in the #neuraxle channel; \nI have created a course on Deep Learning and Recurrent Neural Networks (DL&RNN). Watch a preview of the Deep Learning and Recurrent Neural Networks (DL&RNN) course here. It is the most richly dense and accelerated course out there on this precise topic to make you understand RNNs and other advanced neural networks techniques quickly. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Human Activity Recognition example using TensorFlow on smartphone sensors dataset and an LSTM RNN. Classifying the type of movement amongst six activity categories - Guillaume Chevalier",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\n#: Note: Linux bash commands start with a \"!\" inside those \"ipython notebook\" cells\n\nDATA_PATH = \"data/\"\n\n!pwd && ls\nos.chdir(DATA_PATH)\n!pwd && ls\n\n!python download_dataset.py\n\n!pwd && ls\nos.chdir(\"..\")\n!pwd && ls\n\nDATASET_PATH = DATA_PATH + \"UCI HAR Dataset/\"\nprint(\"\\n\" + \"Dataset is now located at: \" + DATASET_PATH)\n\n```\n\n    /home/ubuntu/pynb/LSTM-Human-Activity-Recognition\n    data\t LSTM_files  LSTM_OLD.ipynb  README.md\n    LICENSE  LSTM.ipynb  lstm.py\t     screenlog.0\n    /home/ubuntu/pynb/LSTM-Human-Activity-Recognition/data\n    download_dataset.py  source.txt\n\n    Downloading...\n    --2017-05-24 01:49:53--  https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n    Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\n    Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected.\n    HTTP request sent, awaiting response... 200 OK\n    Length: 60999314 (58M) [application/zip]\n    Saving to: \u2018UCI HAR Dataset.zip\u2019\n\n    100%[======================================>] 60,999,314  1.69MB/s   in 38s    \n\n    2017-05-24 01:50:31 (1.55 MB/s) - \u2018UCI HAR Dataset.zip\u2019 saved [60999314/60999314]\n\n    Downloading done.\n\n    Extracting...\n    Extracting successfully done to /home/ubuntu/pynb/LSTM-Human-Activity-Recognition/data/UCI HAR Dataset.\n    /home/ubuntu/pynb/LSTM-Human-Activity-Recognition/data\n    download_dataset.py  __MACOSX  source.txt  UCI HAR Dataset  UCI HAR Dataset.zip\n    /home/ubuntu/pynb/LSTM-Human-Activity-Recognition\n    data\t LSTM_files  LSTM_OLD.ipynb  README.md\n    LICENSE  LSTM.ipynb  lstm.py\t     screenlog.0\n\n    Dataset is now located at: data/UCI HAR Dataset/\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 878,
      "date": "Tue, 21 Dec 2021 10:21:44 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/guillaume-chevalier/LSTM-Human-Activity-Recognition/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "guillaume-chevalier/LSTM-Human-Activity-Recognition",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/master/LSTM.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\nTRAIN = \"train/\"\nTEST = \"test/\"\n\n\n#: Load \"X\" (the neural network's training and testing inputs)\n\ndef load_X(X_signals_paths):\n    X_signals = []\n\n    for signal_type_path in X_signals_paths:\n        file = open(signal_type_path, 'r')\n        #: Read dataset from disk, dealing with text files' syntax\n        X_signals.append(\n            [np.array(serie, dtype=np.float32) for serie in [\n                row.replace('  ', ' ').strip().split(' ') for row in file\n            ]]\n        )\n        file.close()\n\n    return np.transpose(np.array(X_signals), (1, 2, 0))\n\nX_train_signals_paths = [\n    DATASET_PATH + TRAIN + \"Inertial Signals/\" + signal + \"train.txt\" for signal in INPUT_SIGNAL_TYPES\n]\nX_test_signals_paths = [\n    DATASET_PATH + TEST + \"Inertial Signals/\" + signal + \"test.txt\" for signal in INPUT_SIGNAL_TYPES\n]\n\nX_train = load_X(X_train_signals_paths)\nX_test = load_X(X_test_signals_paths)\n\n\n#: Load \"y\" (the neural network's training and testing outputs)\n\ndef load_y(y_path):\n    file = open(y_path, 'r')\n    #: Read dataset from disk, dealing with text file's syntax\n    y_ = np.array(\n        [elem for elem in [\n            row.replace('  ', ' ').strip().split(' ') for row in file\n        ]],\n        dtype=np.int32\n    )\n    file.close()\n\n    #: Substract 1 to each output class for friendly 0-based indexing\n    return y_ - 1\n\ny_train_path = DATASET_PATH + TRAIN + \"y_train.txt\"\ny_test_path = DATASET_PATH + TEST + \"y_test.txt\"\n\ny_train = load_y(y_train_path)\ny_test = load_y(y_test_path)\n\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8366431036224414
      ],
      "excerpt": "#: Get LSTM cell output \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.858204411280099
      ],
      "excerpt": "Instructions for updating: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8966655221085083
      ],
      "excerpt": "matplotlib.rc('font', **font) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8049066583339194
      ],
      "excerpt": "\" target=\"_blank\"><img src=\"http://img.youtube.com/vi/XOEN9W05_4A/0.jpg\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9457175861910134,
        0.8347306400897082,
        0.9068127677393759
      ],
      "excerpt": "import numpy as np \nimport matplotlib \nimport matplotlib.pyplot as plt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401558704798054
      ],
      "excerpt": "import os \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8090667506781878
      ],
      "excerpt": ": Input Data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.859752585228192,
        0.8803814925812397,
        0.8529439008035645
      ],
      "excerpt": "test_data_count = len(X_test)  #: 2947 testing series \nn_steps = len(X_train[0])  #: 128 timesteps per series \nn_input = len(X_train[0][0])  #: 9 input parameters per timestep \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": ": Training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8346102310250131
      ],
      "excerpt": "display_iter = 30000  #: To show test set accuracy during training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8313842615121313
      ],
      "excerpt": "print(\"Some useful info to get an insight on dataset's shape and normalisation:\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9522775221181328
      ],
      "excerpt": "print(X_test.shape, y_test.shape, np.mean(X_test), np.std(X_test)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8390882438420114
      ],
      "excerpt": "#: input shape: (batch_size, n_steps, n_input) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "_X = tf.nn.relu(tf.matmul(_X, _weights['hidden']) + _biases['hidden']) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "_X = tf.split(_X, n_steps, 0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8977568198203725,
        0.8977568198203725,
        0.8977568198203725
      ],
      "excerpt": "lstm_cell_1 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True) \nlstm_cell_2 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True) \nlstm_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell_1, lstm_cell_2], state_is_tuple=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8073342545470485
      ],
      "excerpt": "outputs, states = tf.contrib.rnn.static_rnn(lstm_cells, _X, dtype=tf.float32) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8319826475730414
      ],
      "excerpt": "    #: Function to fetch a \"batch_size\" amount of data from \"(X|y)_train\" data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.80897680582524,
        0.910045228799717
      ],
      "excerpt": "shape[0] = batch_size \nbatch_s = np.empty(shape) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9234939137406798
      ],
      "excerpt": "return np.eye(n_classes)[np.array(y_, dtype=np.int32)]  #: Returns FLOATS \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8827687194620136
      ],
      "excerpt": "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9031137155824516
      ],
      "excerpt": "    print(\"Training iter #:\" + str(step*batch_size) + \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8522783337629388
      ],
      "excerpt": "    print(\"PERFORMANCE ON TEST SET: \" + \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9399752851367198
      ],
      "excerpt": "print(\"FINAL RESULT: \" + \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8709496144384266,
        0.8924058922337247,
        0.9609924549136967,
        0.9677452435162166
      ],
      "excerpt": "plt.figure(figsize=(width, height)) \nindep_train_axis = np.array(range(batch_size, (len(train_losses)+1)*batch_size, batch_size)) \nplt.plot(indep_train_axis, np.array(train_losses),     \"b--\", label=\"Train losses\") \nplt.plot(indep_train_axis, np.array(train_accuracies), \"g--\", label=\"Train accuracies\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9378132806536351
      ],
      "excerpt": "    np.array(range(batch_size, len(test_losses)*display_iter, display_iter)[:-1]), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9613147993245891,
        0.968071796486256
      ],
      "excerpt": "plt.plot(indep_test_axis, np.array(test_losses),     \"b-\", label=\"Test losses\") \nplt.plot(indep_test_axis, np.array(test_accuracies), \"g-\", label=\"Test accuracies\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8520783338545628
      ],
      "excerpt": "plt.legend(loc='upper right', shadow=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8142386332096372
      ],
      "excerpt": "plt.xlabel('Training iteration') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8282443366383991,
        0.8620181188290899,
        0.8789901163957392,
        0.8629173234436704,
        0.8061603637074384
      ],
      "excerpt": "print(\"Testing Accuracy: {}%\".format(100*accuracy)) \nprint(\"Precision: {}%\".format(100metrics.precision_score(y_test, predictions, average=\"weighted\"))) \nprint(\"Recall: {}%\".format(100metrics.recall_score(y_test, predictions, average=\"weighted\"))) \nprint(\"f1_score: {}%\".format(100*metrics.f1_score(y_test, predictions, average=\"weighted\"))) \nprint(\"Confusion Matrix:\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9358842237487396,
        0.9258311928569909,
        0.8107672651379841
      ],
      "excerpt": "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100 \nprint(\"Confusion matrix (normalised to % of total test data):\") \nprint(\"Note: training and testing data is not equally distributed amongst classes, \") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8756831816265702
      ],
      "excerpt": ": Plot Results: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8709496144384266
      ],
      "excerpt": "plt.figure(figsize=(width, height)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8691280342508078
      ],
      "excerpt": "tick_marks = np.arange(n_classes) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8763028080958872
      ],
      "excerpt": "plt.ylabel('True label') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8430757466358213,
        0.811854372964597
      ],
      "excerpt": "Confusion matrix (normalised to % of total test data): \n[[ 15.81269073   0.06786563   0.88225317   0.           0.06786563   0.        ] \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/guillaume-chevalier/LSTM-Human-Activity-Recognition/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License (MIT)\\n\\nCopyright (c) 2016 Guillaume Chevalier\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "<a title=\"Activity Recognition\" href=\"https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition\" > LSTMs for Human Activity Recognition</a>",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "LSTM-Human-Activity-Recognition",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "guillaume-chevalier",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2944,
      "date": "Tue, 21 Dec 2021 10:21:44 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This activity recognition project has been seen in:\n\n- [Hacker News 1st page](https://news.ycombinator.com/item?id=13049143)\n- [Awesome TensorFlow](https://github.com/jtoy/awesome-tensorflow#tutorials)\n- [TensorFlow World](https://github.com/astorfi/TensorFlow-World#some-useful-tutorials)\n- And more.\n\n",
      "technique": "Header extraction"
    }
  ],
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "machine-learning",
      "deep-learning",
      "lstm",
      "human-activity-recognition",
      "neural-network",
      "rnn",
      "recurrent-neural-networks",
      "tensorflow",
      "activity-recognition"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\n#: Note: Linux bash commands start with a \"!\" inside those \"ipython notebook\" cells\n\nDATA_PATH = \"data/\"\n\n!pwd && ls\nos.chdir(DATA_PATH)\n!pwd && ls\n\n!python download_dataset.py\n\n!pwd && ls\nos.chdir(\"..\")\n!pwd && ls\n\nDATASET_PATH = DATA_PATH + \"UCI HAR Dataset/\"\nprint(\"\\n\" + \"Dataset is now located at: \" + DATASET_PATH)\n\n```\n\n    /home/ubuntu/pynb/LSTM-Human-Activity-Recognition\n    data\t LSTM_files  LSTM_OLD.ipynb  README.md\n    LICENSE  LSTM.ipynb  lstm.py\t     screenlog.0\n    /home/ubuntu/pynb/LSTM-Human-Activity-Recognition/data\n    download_dataset.py  source.txt\n\n    Downloading...\n    --2017-05-24 01:49:53--  https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n    Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\n    Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected.\n    HTTP request sent, awaiting response... 200 OK\n    Length: 60999314 (58M) [application/zip]\n    Saving to: \u2018UCI HAR Dataset.zip\u2019\n\n    100%[======================================>] 60,999,314  1.69MB/s   in 38s    \n\n    2017-05-24 01:50:31 (1.55 MB/s) - \u2018UCI HAR Dataset.zip\u2019 saved [60999314/60999314]\n\n    Downloading done.\n\n    Extracting...\n    Extracting successfully done to /home/ubuntu/pynb/LSTM-Human-Activity-Recognition/data/UCI HAR Dataset.\n    /home/ubuntu/pynb/LSTM-Human-Activity-Recognition/data\n    download_dataset.py  __MACOSX  source.txt  UCI HAR Dataset  UCI HAR Dataset.zip\n    /home/ubuntu/pynb/LSTM-Human-Activity-Recognition\n    data\t LSTM_files  LSTM_OLD.ipynb  README.md\n    LICENSE  LSTM.ipynb  lstm.py\t     screenlog.0\n\n    Dataset is now located at: data/UCI HAR Dataset/\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\n\n#: Graph input/output\nx = tf.placeholder(tf.float32, [None, n_steps, n_input])\ny = tf.placeholder(tf.float32, [None, n_classes])\n\n#: Graph weights\nweights = {\n    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])), #: Hidden layer weights\n    'out': tf.Variable(tf.random_normal([n_hidden, n_classes], mean=1.0))\n}\nbiases = {\n    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n    'out': tf.Variable(tf.random_normal([n_classes]))\n}\n\npred = LSTM_RNN(x, weights, biases)\n\n#: Loss, optimizer and evaluation\nl2 = lambda_loss_amount * sum(\n    tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()\n) #: L2 loss prevents this overkill neural network to overfit the data\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)) + l2 #: Softmax loss\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) #: Adam Optimizer\n\ncorrect_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
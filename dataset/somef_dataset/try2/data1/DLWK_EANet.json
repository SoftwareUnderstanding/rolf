{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1802.06955\n3. \"Rethinking Atrous Convolution for Semantic Image Segmentation\" IEEE TPAMI, 2018\ndoi: https://arxiv.org/abs/1706.05587\n4. \"Unet++: A nested u-net architecture for medical image segmentation\" IEEE TMI, 2019\ndoi: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7329239/\n5. \"U-Net: Convolutional networks for biomed- ical image segmentation\" MICCAI, 2015.\n6. \"FCN8s\uff1aFully Convolutional Networks for Semantic Segmentation\" CVPR, 2015.\ndoi:https://arxiv.org/abs/1411.4038\n\n### 1.4. Visualization Results\n<p align=\"center\">\n    <img src=\"./fig/covid.png\"/> <br />\n    <em> \n    Figure 2:Visual comparison of COVID-19 infection segmentation results, where the red and\ngreen labels indicate the predicted segmentation and ground truth, respectively.\n    </em>\n</p>\n\n<p align=\"center\">\n    <img src=\"./fig/jzx.png\"/> <br />\n    <em> \n    Figure 3:The visual comparison of results on the TN-SCUI dataset, where the blue and\ngreen labels indicate the predicted segmentation and ground truth, respectively\n    </em>\n</p>\n\n<p align=\"center\">\n    <img src=\"./fig/33.png\"/> <br />\n    <em> \n    Figure 4:Visual comparison of feature maps for showing the effect of multi-level pairwise\nregression module (MPR",
      "https://arxiv.org/abs/1706.05587\n4. \"Unet++: A nested u-net architecture for medical image segmentation\" IEEE TMI, 2019\ndoi: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7329239/\n5. \"U-Net: Convolutional networks for biomed- ical image segmentation\" MICCAI, 2015.\n6. \"FCN8s\uff1aFully Convolutional Networks for Semantic Segmentation\" CVPR, 2015.\ndoi:https://arxiv.org/abs/1411.4038\n\n### 1.4. Visualization Results\n<p align=\"center\">\n    <img src=\"./fig/covid.png\"/> <br />\n    <em> \n    Figure 2:Visual comparison of COVID-19 infection segmentation results, where the red and\ngreen labels indicate the predicted segmentation and ground truth, respectively.\n    </em>\n</p>\n\n<p align=\"center\">\n    <img src=\"./fig/jzx.png\"/> <br />\n    <em> \n    Figure 3:The visual comparison of results on the TN-SCUI dataset, where the blue and\ngreen labels indicate the predicted segmentation and ground truth, respectively\n    </em>\n</p>\n\n<p align=\"center\">\n    <img src=\"./fig/33.png\"/> <br />\n    <em> \n    Figure 4:Visual comparison of feature maps for showing the effect of multi-level pairwise\nregression module (MPR",
      "https://arxiv.org/abs/1411.4038\n\n### 1.4. Visualization Results\n<p align=\"center\">\n    <img src=\"./fig/covid.png\"/> <br />\n    <em> \n    Figure 2:Visual comparison of COVID-19 infection segmentation results, where the red and\ngreen labels indicate the predicted segmentation and ground truth, respectively.\n    </em>\n</p>\n\n<p align=\"center\">\n    <img src=\"./fig/jzx.png\"/> <br />\n    <em> \n    Figure 3:The visual comparison of results on the TN-SCUI dataset, where the blue and\ngreen labels indicate the predicted segmentation and ground truth, respectively\n    </em>\n</p>\n\n<p align=\"center\">\n    <img src=\"./fig/33.png\"/> <br />\n    <em> \n    Figure 4:Visual comparison of feature maps for showing the effect of multi-level pairwise\nregression module (MPR"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8944178096468923,
        0.9312907016997455,
        0.9312907016997455
      ],
      "excerpt": "Kun Wang, \nXiaohong Zhang, \nXiangbo Zhang, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9782759268835692,
        0.8356013927728488
      ],
      "excerpt": "Sheng Huang, \n Dan Yang \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.992655734473065,
        0.8955886365383559
      ],
      "excerpt": "[2021/04/22]:Submitted to the journal of \" Pattern Recognition \" \uff08Under Review\uff09 \n[2021/08/27]: (PR2021 Major Revision) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.98942227946877,
        0.9917183956575526,
        0.9997406109957181,
        0.9934055854260033,
        0.9997406109957181,
        0.9947654700457569,
        0.9787862678699186,
        0.8829209118112641,
        0.914268857023597
      ],
      "excerpt": "\"CE-Net: Context encoder network for 2d medical image segmentation\" TMI, 2019. \n\"Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net) for Medical Image Segmentation\" 2018. \ndoi: https://arxiv.org/abs/1802.06955 \n\"Rethinking Atrous Convolution for Semantic Image Segmentation\" IEEE TPAMI, 2018 \ndoi: https://arxiv.org/abs/1706.05587 \n\"Unet++: A nested u-net architecture for medical image segmentation\" IEEE TMI, 2019 \ndoi: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7329239/ \n\"U-Net: Convolutional networks for biomed- ical image segmentation\" MICCAI, 2015. \n\"FCN8s\uff1aFully Convolutional Networks for Semantic Segmentation\" CVPR, 2015. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8084754346209235
      ],
      "excerpt": "    Figure 2:Visual comparison of COVID-19 infection segmentation results, where the red and \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DLWK/EANet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-17T14:05:18Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T03:20:16Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8323143003842037,
        0.8190513636399263
      ],
      "excerpt": "[2021/04/22]:fire: Release the inference code! \n[2021/04/20] Create repository. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.819140824305833,
        0.9342054389613959,
        0.9040660884642566,
        0.9745408950297633
      ],
      "excerpt": "clinical diagnosis and analysis. However, it remains a challenging task due to (1) \nthe diversity of scale in the medical image targets and (2) the complex context \nenvironments of medical images, including ambiguity of structural boundaries, \ncomplexity of shapes, and the heterogeneity of textures. To comprehensively \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8210360801022429
      ],
      "excerpt": "adjusts the receptive fields to extract multi-scale contextual information efficiently. Second, an edge-attention preservation (EAP) module is employed to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9453213808478185,
        0.9230178247366526
      ],
      "excerpt": "(MPR) module is designed to combine the complementary edge and region information for refining the ambiguous structure. This iterative optimization helps \nto learn better representations and more accurate saliency maps. Extensive experimental results demonstrate that the proposed network achieves superior segmentation performance to state-of-the-art methods in four different challenging medical segmentation tasks, including lung nodule segmentation, COVID-19 infection segmentation, lung segmentation, and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9607172463642429
      ],
      "excerpt": "    Figure 1: Overview of the proposed EANet. Our network is in an encoder-decoder style, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8426416158617289,
        0.9189948158038642
      ],
      "excerpt": "D1 \u223c D5 and multilevel pairwise regression (MPR) module. HFF denotes hybrid feature fusion block, which is \na component of MPR. The final prediction is the generated global map (Sg) after iterative \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8177988817067283
      ],
      "excerpt": "    Figure 2:Visual comparison of COVID-19 infection segmentation results, where the red and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.915839385647101
      ],
      "excerpt": "    Figure 3:The visual comparison of results on the TN-SCUI dataset, where the blue and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9118394285026654,
        0.8554450710751982,
        0.8799638680199318
      ],
      "excerpt": "    Figure 4:Visual comparison of feature maps for showing the effect of multi-level pairwise \nregression module (MPR). D5 \u223c D1 denote the feature maps of each decoder block. The odd \nand even rows show the baseline results without or with MPR, respectively. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8466528409211563
      ],
      "excerpt": ":fire:If you have any questions about our work, please do not hesitate to contact us by emails. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "The Code of \u201cEANet:  Iterative Edge Attention Network for Medical Image Segmentation\u201d",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Download the datasets and unzip them into `data` folder\n- [COVID-19](https://medicalsegmentation.com/covid19/)\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DLWK/EANet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 26 Dec 2021 17:49:30 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/DLWK/EANet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "DLWK/EANet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9893272198983933,
        0.9906248903846466
      ],
      "excerpt": "git clone https://github.com/DLWK/EANet.git \ncd EANet/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9835567625497421
      ],
      "excerpt": " cd train/ \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.950563948951535
      ],
      "excerpt": " python3 train.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9114265942596803
      ],
      "excerpt": "    <img src=\"./fig/1.png\"/> <br /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9114265942596803
      ],
      "excerpt": "    <img src=\"./fig/covid.png\"/> <br /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9114265942596803
      ],
      "excerpt": "    <img src=\"./fig/jzx.png\"/> <br /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9114265942596803
      ],
      "excerpt": "    <img src=\"./fig/33.png\"/> <br /> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/DLWK/EANet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "EANet: Iterative Edge Attention Network for Medical Image Segmentation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "EANet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "DLWK",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DLWK/EANet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [Python 3.5](https://www.python.org/)\n- [Pytorch 1.3](http://pytorch.org/)\n- [OpenCV 4.0](https://opencv.org/)\n- [Numpy 1.15](https://numpy.org/)\n- [TensorboardX](https://github.com/lanpa/tensorboardX)\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Sun, 26 Dec 2021 17:49:30 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "medical-image-analysis",
      "segmentation",
      "covid-19",
      "lung-segmentation",
      "lung-cancer"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "![gif](./fig/my.gif) \n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1505.04597",
      "https://arxiv.org/abs/1802.06955",
      "https://arxiv.org/abs/1804.03999",
      "https://arxiv.org/abs/1505.04597",
      "https://arxiv.org/abs/1802.06955",
      "https://arxiv.org/abs/1804.03999",
      "https://arxiv.org/abs/1505.04597",
      "https://arxiv.org/abs/1802.06955",
      "https://arxiv.org/abs/2003.05056, 2020, download [link](https://128.84.21.199/pdf/2003.05056.pdf).\n\n\n#### Please consider starring us, if you found it useful. Thanks\n\n## Updates\n- July 20, 2020: SEDU model added to the Skin Lesion segmentation code (inside models.py), now you can use this model for higher performance on skin lesion segmentation, inside the train file call the SEDU_Net_D3 model). \n- March 5, 2020: An extended version of the network has been released(Complete implemenation for [SKin Lesion Segmentation on ISIC 217](https://challenge.kitware.com/#challenge/583f126bcad3a51cc66c8d9a), [Skin Lesion Segmentation PH2 Dataset](https://www.fc.up.pt/addi/ph2%20database.html) and [cell nuclei]() along with the network implementation will be update soon). \n- December 4, 2019: Document Image Binarization using BCDU-Net on DIBCO Challenges has been implemented, best performance on DIBCO series [link](https://github.com/rezazad68/BCDUnet_DIBCO)\n- Augest 28, 2019: First release (Complete implemenation for [SKin Lesion Segmentation on ISIC 218](https://challenge2018.isic-archive.com/), [Retina Blood Vessel Segmentation](http://www.isi.uu.nl/Research/Databases/DRIVE/) and [Lung segmentation](https://www.kaggle.com/kmader/finding-lungs-in-ct-data/data) dataset added.)\n- Augest 27, 2019: Paper Accepted in the [ICCV workshop](https://sites.google.com/view/iccv19-vrmi/home?authuser=0]) 2019 (Oral presentation).\n\n## Prerequisties and Run\nThis code has been implemented in python language using Keras libarary with tensorflow backend and tested in ubuntu OS, though should be compatible with related environment. following Environement and Library needed to run the code:\n\n- Python 3\n- Keras - tensorflow backend\n\n\n## Run Demo\nFor training deep model for each task, go to the related folder and follow the bellow steps:\n\n#### Skin Lesion Segmentation\n1- Download the ISIC 2018 train dataset from [this](https://challenge.kitware.com/#phase/5abcb19a56357d0139260e53) link and extract both training dataset and ground truth folders inside the `dataset_isic18`. </br>\n2- Run `Prepare_ISIC2018.py` for data preperation and dividing data to train,validation and test sets. </br>\n3- Run `train_isic18.py` for training BCDU-Net model using trainng and validation sets. The model will be train for 100 epochs and it will save the best weights for the valiation set. You can also train U-net model for this dataset by changing model to unet, however, the performance will be low comparing to BCDU-Net. </br>\n4- For performance calculation and producing segmentation result, run `evaluate.py`. It will represent performance measures and will saves related figures and results in `output` folder.</br>\n\n#### Retina Blood Vessel Segmentation\n1- Download Drive dataset from [this](https://drive.google.com/open?id=17wVfELqgwbp4Q02GD247jJyjq6lwB0l6) link and extract both training  and test  folders in a folder name DRIVE (make a new folder with name DRIVE) </br>\n2- Run `prepare_datasets_DRIVE.py` for reading whole data. This code will read all the train and test samples and will saves them as a hdf5 file in the `DRIVE_datasets_training_testing` folder. </br>\n3- The next step is to extract random patches from the training set to train the model, to do so, Run `save_patch.py`, it will extract random patches with size 64*64 and will save them as numpy file. This code will use `help_functions.py`, `spre_processing.py` and `extract_patches.py` functions for data normalization and patch extraction.  \n4- For model training, run `train_retina.py`, it will load the training data and will use 20% of training samples as a validation set. The model will be train for 50 epochs and it will save the best weights for the valiation set.</br>\n4- For performance calculation and producing segmentation result, run `evaluate.py`. It will represent performance measures and will saves related figures and results in `test` folder.</br>\nNote: For image pre-processing and patch extraction we used [this](https://github.com/orobix/retina-unet) github's code.</br>\n\n#### Lung Segmentation\n1- Download the Lung Segmentation dataset from [Kaggle](https://www.kaggle.com/kmader/finding-lungs-in-ct-data/data) link and extract it. </br>\n2- Run `Prepare_data.py` for data preperation, train/test seperation and generating new masks around the lung tissues.\n3- Run `train_lung.py` for training BCDU-Net model using trainng and validation sets (20 percent of the training set). The model will be train for 50 epochs and it will save the best weights for the valiation set. You can train either BCDU-net model with 1 or 3 densly connected convolutions. </br>\n4- For performance calculation and producing segmentation result, run `evaluate_performance.py`. It will represent performance measures and will saves related figures and results.</br>\n\n\n\n## Quick Overview\n![Diagram of the proposed method](https://github.com/rezazad68/LSTM-U-net/blob/master/output_images/bcdunet.png)\n\n### Structure of the Bidirection Convolutional LSTM that used in our network\n![Diagram of the proposed method](https://github.com/rezazad68/LSTM-U-net/blob/master/output_images/convlstm.png)\n\n### Structure of the BConvLSTM+SE that used in our network (MCGU-Net)\n![Feature encoder of the MCGU-Net](https://github.com/rezazad68/BCDU-Net/blob/master/output_images/SEBConvLSTM.png)\n\n## Results\nFor evaluating the performance of the proposed method, Two challenging task in medical image segmentaion has been considered. In bellow, results of the proposed approach illustrated.\n</br>\n#### Task 1: Retinal Blood Vessel Segmentation\n\n\n#### Performance Comparision on Retina Blood Vessel Segmentation\nIn order to compare the proposed method with state of the art appraoches on retinal blood vessel segmentation, we considered Drive dataset.  \n\nMethods | Year |F1-scores | Sensivity| Specificaty| Accuracy | AUC\n------------ | -------------|----|-----------------|----|---- |---- \nChen etc. all [Hybrid Features](https://link.springer.com/article/10.1007/s00138-014-0638-x)        |2014\t  |\t-       |0.7252\t  |0.9798\t  |0.9474\t  |0.9648\nAzzopardi  et. all [Trainable COSFIRE filters ](https://www.sciencedirect.com/science/article/abs/pii/S1361841514001364)   |2015\t  |\t-       |0.7655\t  |0.9704\t  |0.9442\t  |0.9614\nRoychowdhury and et. all [Three Stage Filtering](https://ieeexplore.ieee.org/document/6848752)|2016 \t|\t-       |0.7250\t  |**0.9830**\t  |0.9520\t  |0.9620\nLiskowsk  etc. all[Deep Model](https://ieeexplore.ieee.org/document/7440871)\t  |2016\t  |\t-       |0.7763\t  |0.9768\t  |0.9495\t  |0.9720\nQiaoliang  et. all [Cross-Modality Learning Approach](https://ieeexplore.ieee.org/document/7161344)|2016\t  |\t-       |0.7569\t  |0.9816\t  |0.9527\t  |0.9738\nRonneberger and et. all [U-net](https://arxiv.org/abs/1505.04597)\t     \t    |2015   | 0.8142\t|0.7537\t  |0.9820\t  |0.9531   |0.9755\nAlom  etc. all [Recurrent Residual U-net](https://arxiv.org/abs/1802.06955)\t|2018\t  | 0.8149  |0.7726\t  |0.9820\t  |0.9553\t  |0.9779\nOktay  et. all [Attention U-net](https://arxiv.org/abs/1804.03999)\t|2018\t  | 0.8155\t|0.7751\t  |0.9816\t  |0.9556\t  |0.9782\nAlom  et. all [R2U-Net](https://arxiv.org/ftp/arxiv/papers/1802/1802.06955.pdf)\t        |2018\t  | 0.8171\t|0.7792\t  |0.9813\t  |0.9556\t  |0.9784\nAzad et. all [Proposed BCDU-Net](https://github.com/rezazad68/LSTM-U-net/edit/master/README.md)\t  |2019 \t| **0.8222**\t|**0.8012**\t  |0.9784\t  |**0.9559**\t  |**0.9788**\n\n\n#### Retinal blood vessel segmentation result on test data\n\n![Retinal Blood Vessel Segmentation result 1](https://github.com/rezazad68/LSTM-U-net/blob/master/output_images/Figure_1.png)\n![Retinal Blood Vessel Segmentation result 2](https://github.com/rezazad68/LSTM-U-net/blob/master/output_images/Figure_2.png)\n![Retinal Blood Vessel Segmentation result 3](https://github.com/rezazad68/LSTM-U-net/blob/master/output_images/Figure_3.png)\n\n\n## Skin Lesion Segmentation\n\n#### Performance Evalution on the Skin Lesion Segmentation task\n\nMethods | Year |F1-scores | Sensivity| Specificaty| Accuracy | PC | JS \n------------ | -------------|----|-----------------|----|---- |---- |---- \nRonneberger and etc. all [U-net](https://arxiv.org/abs/1505.04597)\t     \t    |2015   | 0.647\t|0.708\t  |0.964\t  |0.890  |0.779 |0.549\nAlom  et. all [Recurrent Residual U-net](https://arxiv.org/abs/1802.06955)\t|2018\t  | 0.679 |0.792 |0.928 |0.880\t  |0.741\t  |0.581\nOktay  et. all [Attention U-net](https://arxiv.org/abs/1804.03999)\t|2018\t  | 0.665\t|0.717\t  |0.967\t  |0.897\t  |0.787 | 0.566 \nAlom  et. all [R2U-Net](https://arxiv.org/ftp/arxiv/papers/1802/1802.06955.pdf)\t        |2018\t  | 0.691\t|0.726\t  |0.971\t  |0.904\t  |0.822 | 0.592\nAzad et. all [Proposed BCDU-Net](https://github.com/rezazad68/LSTM-U-net/edit/master/README.md)\t  |2019 \t| **0.847**\t|**0.783**\t  |**0.980**\t  |**0.936**\t  |**0.922**| **0.936**\nAzad et. all [MCGU-Net](https://128.84.21.199/pdf/2003.05056.pdf)\t  |2020\t| **0.895**\t|**0.848**\t  |**0.986**\t  |**0.955**\t  |**0.947**| **0.955**\n\n\n\n\n#### Skin Lesion Segmentation results\n\n![Skin Lesion Segmentation result 1](https://github.com/rezazad68/LSTM-U-net/blob/master/output_images/1%20(1).png)\n![Skin Lesion Segmentation result 1](https://github.com/rezazad68/LSTM-U-net/blob/master/output_images/1%20(2).png)\n![Skin Lesion Segmentation result 1](https://github.com/rezazad68/LSTM-U-net/blob/master/output_images/1%20(3).png)\n![Skin Lesion Segmentation result 1](https://github.com/rezazad68/LSTM-U-net/blob/master/output_images/1%20(4).png)\n\n\n## Lung Segmentation\n\n#### Performance Evalution on the Lung Segmentation task\n\nMethods | Year |F1-scores | Sensivity| Specificaty| Accuracy | AUC | JS \n------------ | -------------|----|-----------------|----|---- |---- |---- \nRonneberger and etc. all [U-net](https://arxiv.org/abs/1505.04597)\t     \t    |2015   | 0.9658\t|0.9696\t  |0.9872\t  |0.9872  |0.9784 |0.9858\nAlom  et. all [Recurrent Residual U-net](https://arxiv.org/abs/1802.06955)\t|2018\t  | 0.9638 |0.9734 |0.9866 |0.9836\t  |0.9800\t  |0.9836\nAlom  et. all [R2U-Net](https://arxiv.org/ftp/arxiv/papers/1802/1802.06955.pdf)\t        |2018\t  | 0.9832\t|**0.9944**\t  |0.9832\t  |0.9918\t  |0.9889 | 0.9918\nAzad et. all [Proposed BCDU-Net](https://github.com/rezazad68/LSTM-U-net/edit/master/README.md)\t  |2019 \t| **0.9904**\t|0.9910\t  |**0.9982**\t  |**0.9972**\t  |**0.9946**| **0.9972**\n\n\n\n\n\n#### Lung Segmentation results\n![Lung Segmentation result 1](https://github.com/rezazad68/LSTM-U-net/blob/master/output_images/es3.png)\n![Lung Segmentation result 2](https://github.com/rezazad68/LSTM-U-net/blob/master/output_images/es5.png)\n![Lung Segmentation result 3](https://github.com/rezazad68/LSTM-U-net/blob/master/output_images/est2.png)\n\n## Cell Nuclei Segmentation\n#### Cell Nuclei Segmentation results\n![Cell Nuclei Segmentation results](https://github.com/rezazad68/BCDU-Net/blob/master/output_images/Nuclei2.png)\n\n\n### Model weights\nYou can download the learned weights for each task in the following table. \n\nTask | Dataset |Learned weights\n------------ | -------------|----\nRetina Blood Vessel Segmentation | [Drive](http://www.isi.uu.nl/Research/Databases/DRIVE/) |[BCDU_net_D3](https://drive.google.com/open?id=1_hpfspGGJcWyFcGLXkFUa4k1NdUyOSOb)\nSkin Lesion Segmentation | [ISIC2018](https://challenge.kitware.com/#phase/5abcb19a56357d0139260e53) |[BCDU_net_D3](https://drive.google.com/open?id=1EPRC-YmMk0AjHbdjoVy53jlSuweSbAHX)\nLung Segmentation | [Lung kaggle](https://www.kaggle.com/kmader/finding-lungs-in-ct-data/data) | [BCDU_net_D3](https://drive.google.com/open?id=1pHOntUOdqd0MSz4cHUOHi2Ssn3KBH-fU)\n\n\n\n### Query\nAll implementation done by Reza Azad. For any query please contact us for more information.\n\n```python\nrezazad68@gmail.com\n\n```"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9956012149569575
      ],
      "excerpt": "R. Azad, M. Asadi, Mahmood Fathy and Sergio Escalera \"Bi-Directional ConvLSTM U-Net with Densely Connected Convolutions \", ICCV, 2019, download link. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9293165158874254,
        0.9981885259449148
      ],
      "excerpt": "Augest 28, 2019: First release (Complete implemenation for SKin Lesion Segmentation on ISIC 218, Retina Blood Vessel Segmentation and Lung segmentation dataset added.) \nAugest 27, 2019: Paper Accepted in the ICCV workshop 2019 (Oral presentation). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9202222245543838
      ],
      "excerpt": "Methods | Year |F1-scores | Sensivity| Specificaty| Accuracy | AUC \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906210319394867
      ],
      "excerpt": "Azzopardi  et. all Trainable COSFIRE filters    |2015      | -       |0.7655   |0.9704     |0.9442     |0.9614 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8669112007448144,
        0.9763162561870891,
        0.9530054940186298,
        0.9886309484278976,
        0.9760264441480357,
        0.9760264441480357,
        0.9643527176249604,
        0.9202222245543838
      ],
      "excerpt": "Liskowsk  etc. allDeep Model      |2016   | -       |0.7763   |0.9768     |0.9495     |0.9720 \nQiaoliang  et. all Cross-Modality Learning Approach|2016      | -       |0.7569   |0.9816     |0.9527     |0.9738 \nRonneberger and et. all U-net               |2015   | 0.8142    |0.7537   |0.9820     |0.9531   |0.9755 \nAlom  etc. all Recurrent Residual U-net |2018     | 0.8149  |0.7726   |0.9820     |0.9553     |0.9779 \nOktay  et. all Attention U-net  |2018     | 0.8155  |0.7751   |0.9816     |0.9556     |0.9782 \nAlom  et. all R2U-Net         |2018     | 0.8171  |0.7792   |0.9813     |0.9556     |0.9784 \nAzad et. all Proposed BCDU-Net   |2019     | 0.8222    |0.8012   |0.9784     |0.9559     |0.9788 \nMethods | Year |F1-scores | Sensivity| Specificaty| Accuracy | PC | JS  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.93830706830732,
        0.9914489068662127,
        0.9760264441480357,
        0.9760264441480357,
        0.9856072637169764,
        0.8283268420643993,
        0.9202222245543838
      ],
      "excerpt": "Ronneberger and etc. all U-net              |2015   | 0.647 |0.708    |0.964      |0.890  |0.779 |0.549 \nAlom  et. all Recurrent Residual U-net  |2018     | 0.679 |0.792 |0.928 |0.880    |0.741      |0.581 \nOktay  et. all Attention U-net  |2018     | 0.665   |0.717    |0.967      |0.897      |0.787 | 0.566  \nAlom  et. all R2U-Net         |2018     | 0.691   |0.726    |0.971      |0.904      |0.822 | 0.592 \nAzad et. all Proposed BCDU-Net   |2019     | 0.847 |0.783    |0.980      |0.936      |0.922| 0.936 \nAzad et. all MCGU-Net     |2020 | 0.895 |0.848    |0.986      |0.955      |0.947| 0.955 \nMethods | Year |F1-scores | Sensivity| Specificaty| Accuracy | AUC | JS  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.93830706830732,
        0.9914489068662127,
        0.9760264441480357,
        0.9643527176249604
      ],
      "excerpt": "Ronneberger and etc. all U-net              |2015   | 0.9658    |0.9696   |0.9872     |0.9872  |0.9784 |0.9858 \nAlom  et. all Recurrent Residual U-net  |2018     | 0.9638 |0.9734 |0.9866 |0.9836    |0.9800     |0.9836 \nAlom  et. all R2U-Net         |2018     | 0.9832  |0.9944   |0.9832     |0.9918     |0.9889 | 0.9918 \nAzad et. all Proposed BCDU-Net   |2019     | 0.9904    |0.9910   |0.9982     |0.9972     |0.9946| 0.9972 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rezazad68/BCDU-Net",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-22T10:59:00Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-29T05:45:21Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9059292378803329
      ],
      "excerpt": "Deep auto-encoder-decoder network for medical image segmentation with state of the art results on skin lesion segmentation, lung segmentation, and retinal blood vessel segmentation. This method applies bidirectional convolutional LSTM layers in U-net structure to non-linearly encode both semantic and high-resolution information with non-linearly technique. Furthermore, it applies densely connected convolution layers to include collective knowledge in representation and boost convergence rate with batch normalization layers. If this code helps with your research please consider citing the following papers: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9652754271405648
      ],
      "excerpt": "For evaluating the performance of the proposed method, Two challenging task in medical image segmentaion has been considered. In bellow, results of the proposed approach illustrated. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9759509947349007
      ],
      "excerpt": "In order to compare the proposed method with state of the art appraoches on retinal blood vessel segmentation, we considered Drive dataset.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8016066472258047
      ],
      "excerpt": "Ronneberger and et. all U-net               |2015   | 0.8142    |0.7537   |0.9820     |0.9531   |0.9755 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.942108884517295
      ],
      "excerpt": "All implementation done by Reza Azad. For any query please contact us for more information. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "BCDU-Net : Medical Image Segmentation",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rezazad68/BCDU-Net/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 179,
      "date": "Wed, 29 Dec 2021 23:22:24 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/rezazad68/BCDU-Net/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "rezazad68/BCDU-Net",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.9105239047902157,
        0.8066743430640884
      ],
      "excerpt": "2- Run Prepare_ISIC2018.py for data preperation and dividing data to train,validation and test sets. </br> \n3- Run train_isic18.py for training BCDU-Net model using trainng and validation sets. The model will be train for 100 epochs and it will save the best weights for the valiation set. You can also train U-net model for this dataset by changing model to unet, however, the performance will be low comparing to BCDU-Net. </br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8432195409659055,
        0.945900256971066,
        0.9303391258436962,
        0.9077598741819156
      ],
      "excerpt": "1- Download Drive dataset from this link and extract both training  and test  folders in a folder name DRIVE (make a new folder with name DRIVE) </br> \n2- Run prepare_datasets_DRIVE.py for reading whole data. This code will read all the train and test samples and will saves them as a hdf5 file in the DRIVE_datasets_training_testing folder. </br> \n3- The next step is to extract random patches from the training set to train the model, to do so, Run save_patch.py, it will extract random patches with size 64*64 and will save them as numpy file. This code will use help_functions.py, spre_processing.py and extract_patches.py functions for data normalization and patch extraction. \n4- For model training, run train_retina.py, it will load the training data and will use 20% of training samples as a validation set. The model will be train for 50 epochs and it will save the best weights for the valiation set.</br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8412969169775034,
        0.8528419367856235
      ],
      "excerpt": "2- Run Prepare_data.py for data preperation, train/test seperation and generating new masks around the lung tissues. \n3- Run train_lung.py for training BCDU-Net model using trainng and validation sets (20 percent of the training set). The model will be train for 50 epochs and it will save the best weights for the valiation set. You can train either BCDU-net model with 1 or 3 densly connected convolutions. </br> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/rezazad68/BCDU-Net/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "[Bi-Directional ConvLSTM U-Net with Densely Connected Convolutions ](http://openaccess.thecvf.com/content_ICCVW_2019/papers/VRMI/Azad_Bi-Directional_ConvLSTM_U-Net_with_Densley_Connected_Convolutions_ICCVW_2019_paper.pdf)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "BCDU-Net",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "rezazad68",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rezazad68/BCDU-Net/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This code has been implemented in python language using Keras libarary with tensorflow backend and tested in ubuntu OS, though should be compatible with related environment. following Environement and Library needed to run the code:\n\n- Python 3\n- Keras - tensorflow backend\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "For training deep model for each task, go to the related folder and follow the bellow steps:\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 422,
      "date": "Wed, 29 Dec 2021 23:22:24 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "lstm",
      "unet-keras",
      "abcdu-net",
      "segmentation",
      "medical-image-processing",
      "medical-image-segmentation",
      "lung-segmentation",
      "skin-lesion-segmentation",
      "retinal-vessel-segmentation",
      "deep-learning",
      "convolutional-autoencoder",
      "convolutional-neural-networks",
      "medical",
      "medical-application",
      "cancer-detection",
      "semantic",
      "semantic-segmentation",
      "bcdu-net",
      "unet",
      "keras"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "For training deep model for each task, go to the related folder and follow the bellow steps:\n\n",
      "technique": "Header extraction"
    }
  ]
}
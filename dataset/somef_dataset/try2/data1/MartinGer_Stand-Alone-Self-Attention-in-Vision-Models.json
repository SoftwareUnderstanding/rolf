{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1906.05909 \"Stand-Alone Self-Attention in Vision Models\""
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MartinGer/Stand-Alone-Self-Attention-in-Vision-Models",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-27T11:33:03Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-15T13:59:55Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9712050421640835,
        0.967955651171819,
        0.8413207598172175,
        0.9811126961587034,
        0.9664334852608234
      ],
      "excerpt": "This is a pytorch implementation of the paper Stand-Alone Self-Attention in Vision Models  by Prajit Ramachandran, Niki Parmar, Ashish Vaswani, Irwan Bello, Anselm Levskaya and Jonathon Shlens. \nThe paper implements the attention mechanism into different ResNet architectures. The used formula for Single-headed attention to compute the output for one pixel is \nGlobal Self-Attention on images is subject to the problem, that it can only be applied after a significant \nspatial downsampling of the input. Every pixels relation is calculated to every other pixel so learning gets computationally very expensive, which prevents its usage across all layers in a fully attentional model. \nTo migitate this issue the authors introduce a local attention mechanism, that applies attention only on a first extracted local region of pixels with spatial extent k centered around the current pixel. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Pytorch implementation of the paper Stand-Alone Self-Attention in Vision Models",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MartinGer/Stand-Alone-Self-Attention-in-Vision-Models/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 18:00:05 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/MartinGer/Stand-Alone-Self-Attention-in-Vision-Models/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "MartinGer/Stand-Alone-Self-Attention-in-Vision-Models",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/MartinGer/Stand-Alone-Self-Attention-in-Vision-Models/master/example.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9083657406301109
      ],
      "excerpt": "I only tested the implementation with ResNet50 for now. The used ResNet V1.5 architectures are adapted from https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/MartinGer/Stand-Alone-Self-Attention-in-Vision-Models/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Stand-Alone-Self-Attention-in-Vision-Models",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Stand-Alone-Self-Attention-in-Vision-Models",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "MartinGer",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MartinGer/Stand-Alone-Self-Attention-in-Vision-Models/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- pytorch\n- I use [fast.ai](https://www.fast.ai/) and the [imagenette](https://github.com/fastai/imagenette) dataset for the examples\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Wed, 29 Dec 2021 18:00:05 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "See the jupyter notebook or the example training script\n\n",
      "technique": "Header extraction"
    }
  ]
}
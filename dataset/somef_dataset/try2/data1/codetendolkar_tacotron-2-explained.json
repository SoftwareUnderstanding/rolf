{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1712.05884",
      "https://arxiv.org/abs/1712.05884]()\n2. Location Sensitive Attention adapted from Tacotron 2 implementation by [Keith Ito](https://github.com/keithito) - [GitHub link](https://github.com/keithito/tacotron/tree/c94ab2757d52e4294dcd6a8da03f49d251b2dec4)\n3. Zoneout Wrapper for RNNCell adapted from Tensorflow's official repository for [MaskGan](https://github.com/tensorflow/models/tree/master/research/maskgan). The code contributed by [A Dai](https://github.com/a-dai) - [GitHub link](https://github.com/tensorflow/models/blob/master/research/maskgan/regularization/zoneout.py)\n4. And obviously - all the contributors of [Tensorflow](https://github.com/tensorflow)\n5. Internet"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. \"Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions\"\nJonathan Shen, Ruoming Pang, Ron J. Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, RJ Skerry-Ryan, Rif A. Saurous, Yannis Agiomyrgiannakis, Yonghui Wu\n[arXiv:1712.05884]()\n2. Location Sensitive Attention adapted from Tacotron 2 implementation by [Keith Ito](https://github.com/keithito) - [GitHub link](https://github.com/keithito/tacotron/tree/c94ab2757d52e4294dcd6a8da03f49d251b2dec4)\n3. Zoneout Wrapper for RNNCell adapted from Tensorflow's official repository for [MaskGan](https://github.com/tensorflow/models/tree/master/research/maskgan). The code contributed by [A Dai](https://github.com/a-dai) - [GitHub link](https://github.com/tensorflow/models/blob/master/research/maskgan/regularization/zoneout.py)\n4. And obviously - all the contributors of [Tensorflow](https://github.com/tensorflow)\n5. Internet\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/codetendolkar/tacotron-2-explained",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-09-08T22:36:41Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-25T12:42:05Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9982887630586823
      ],
      "excerpt": "This repository is meant to teach the intricacies of writing advanced Recurrent Neural Networks in Tensorflow. The code is used as a guide, in weekly Deep Learning meetings at Ohio State University, for teaching - \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9299329554529834
      ],
      "excerpt": "2. How to implement it in Tensorflow \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9043433914604763
      ],
      "excerpt": "2. Tachotron 2 was released less than a year ago (as of 2018) and is a relatively simple model (compared to something like GNTM). The associated paper explains the architecture well \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9633016390777119
      ],
      "excerpt": "4. Public datasets are available to achieve state of the art results \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9610173854670502,
        0.9850178960179186,
        0.9269460319364529,
        0.9728188976494909,
        0.8841063197727789,
        0.9622824463675269,
        0.8066129971415142
      ],
      "excerpt": "Note: This code has no affiliation with the companies I worked at. I used none of the proprietery knowledge of any of those companies to write this code. This was purely an exercise in self study. \nThe paper followed in this repository is - Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions. The repository only implements the Text to Mel Spectrogram part (called Tacotron 2). The repository does not include the vocoder used to synthesize audio. \nThis is a production grade code which can be used as state of the art TTS frontend. The blog post [TODO] shows some audio samples synthesized with a Griffin Lin vocoder. But the code has excess comments to aid a novice Tensorflow user which could be a hindrance. To read the code, start from train.py \nThe repository also uses Tensorflow's tf.data API for pre-processing and [TODO] Estimator API for modularity \nThe directory structure followed is as specified in Stanford's CS230 Notes on Tensorflow. We modify the structure a bit to suite our needs. \ndata/ (Contains all data) \nmodel/ (Contains model architecture) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Walk through insanely commented code for an advanced recurrent model in TensorFlow",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/codetendolkar/tacotron-2-explained/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 16,
      "date": "Wed, 29 Dec 2021 10:47:01 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/codetendolkar/tacotron-2-explained/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "codetendolkar/tacotron-2-explained",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Setup python 3 virtual environment. If you dont have ```virtualenv```, install it with\n\n```\npip install virtualenv\n```\n\n2. Then create the environment with\n\n```\nvirtualenv -p $(which python3) env\n```\n\n3. Activate the environment\n\n```\nsource env/bin/activate\n```\n\n4. Install tensorflow\n\n```\npip install tensorflow==1.8.0\n```\n\n5. Clone the repository\n\n```\ngit clone https://gitlab.com/codetendolkar/tacotron-2-explained.git\n```\n\n6. Run the training script\n\n```\ncd tacotron2\npython train.py\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8767419816019438
      ],
      "excerpt": "1. Encoder-Decoder architectures contain more complexities then standard DNNs. Implementing one helps you master concepts you would otherwise overlook \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8095050485030715
      ],
      "excerpt": "4. Training requires ~10 days given access to a GPU (comparable to GTX 1080) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8488192064358981,
        0.933219223557725,
        0.9586232994076559
      ],
      "excerpt": "    input_fn.py (Input data pipeline) \n    model_fn.py (Main model) \n    utils.py (Utility functions) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8867640924077753
      ],
      "excerpt": "    wrappers.py (Wrappers for RNN cells) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.810137388437919,
        0.9336801098518991,
        0.9642790804578881
      ],
      "excerpt": "        attention.py (Location sensitive attention) \n        zoneout_wrapper.py (Zoneout) \ntrain.py (Run training) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/codetendolkar/tacotron-2-explained/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Tacotron 2 Explained",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "tacotron-2-explained",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "codetendolkar",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/codetendolkar/tacotron-2-explained/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The repository uses Tensorflow 1.8.0. Some code may be incompatible with older versions of Tensorflow (specifically the Location Sensitive Attention Wrapper).\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 42,
      "date": "Wed, 29 Dec 2021 10:47:01 GMT"
    },
    "technique": "GitHub API"
  }
}
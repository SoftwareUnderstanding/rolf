{
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{pathakCVPR16context,\n    Author = {Pathak, Deepak and Kr\\\"ahenb\\\"uhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei},\n    Title = {Context Encoders: Feature Learning by Inpainting},\n    Booktitle = {Computer Vision and Pattern Recognition ({CVPR})},\n    Year = {2016}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9999898566166306,
        0.9975788273939303,
        0.9758652426555272,
        0.999999776578843,
        0.9954488832581693
      ],
      "excerpt": "If you find Context Encoders useful in your research, please cite: \n    Author = {Pathak, Deepak and Kr\\\"ahenb\\\"uhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei}, \n    Title = {Context Encoders: Feature Learning by Inpainting}, \n    Booktitle = {Computer Vision and Pattern Recognition ({CVPR})}, \n    Year = {2016} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8314842251106657
      ],
      "excerpt": "  #: on client side, open in browser: http://localhost:8000/ \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pathak22/context-encoder",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-04-22T19:48:36Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-27T08:44:20Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9503271367272395
      ],
      "excerpt": "This is the training code for our CVPR 2016 paper on Context Encoders for learning deep feature representation in an unsupervised manner by image inpainting. Context Encoders are trained jointly with reconstruction and adversarial loss. This repo contains quick demo, training/testing code for center region inpainting and training/testing code for arbitray random region inpainting. This code is adapted from an initial fork of Soumith's DCGAN implementation. Scroll down to try out a quick demo or train your own inpainting models! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9683632493530783
      ],
      "excerpt": "Project Website \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.985559335742294
      ],
      "excerpt": "Checkout the TensorFlow implementation of our paper by Taeksoo here. However, it does not implement full functionalities of our paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "[CVPR 2016] Unsupervised Feature Learning by Image Inpainting using GANs",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Features for context encoder trained with reconstruction loss.\n\n- [Prototxt](https://www.cs.cmu.edu/~dpathak/context_encoder/resources/ce_features.prototxt)\n- [Caffemodel](https://www.cs.cmu.edu/~dpathak/context_encoder/resources/ce_features.caffemodel)\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pathak22/context-encoder/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 203,
      "date": "Tue, 28 Dec 2021 09:20:07 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/pathak22/context-encoder/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "pathak22/context-encoder",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/pathak22/context-encoder/master/models/scripts/download_inpaintCenter_models.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.816810208757971,
        0.9460447861584744
      ],
      "excerpt": "If you could successfully run the above demo, run following steps to train your own context encoder model for image inpainting. \n[Optional] Install Display Package as follows. If you don't want to install it, then set display=0 in train.lua. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9038295358981701,
        0.9906248903846466
      ],
      "excerpt": "  luarocks install https://raw.githubusercontent.com/szym/display/master/display-scm-0.rockspec \n  cd ~ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8099845580541413
      ],
      "excerpt": "  mkdir -p /path_to_wherever_you_want/mydataset/train/images/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9065470885836698
      ],
      "excerpt": "  cd context-encoder/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9102094707971919
      ],
      "excerpt": "  DATA_ROOT=dataset/train display_id=11 name=inpaintCenter overlapPred=4 wtl2=0.999 nBottleneck=4000 niter=500 loadSize=350 fineSize=128 gpu=1 th train.lua \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030404457686118
      ],
      "excerpt": "  DATA_ROOT=dataset/train display_id=11 name=inpaintRandomNoOverlap useOverlapPred=0 wtl2=0.999 nBottleneck=4000 niter=500 loadSize=350 fineSize=128 gpu=1 th train_random.lua \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8672778244504319
      ],
      "excerpt": "  DATA_ROOT=dataset/train display_id=11 name=inpaintRandomNoOverlap useOverlapPred=0 wtl2=0.999 nBottleneck=4000 niter=500 loadSize=350 fineSize=64 gpu=1 th train_random.lua \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8181813356563167
      ],
      "excerpt": "Sample results on held-out images:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8447634792014815
      ],
      "excerpt": "Download Dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8462841852220856,
        0.8993271348843357
      ],
      "excerpt": "  mkdir -p /path_to_wherever_you_want/mydataset/train/images/ \n  #: put all training images inside mydataset/train/images/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589658548129034
      ],
      "excerpt": "Train the model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.913257516706108
      ],
      "excerpt": "  DATA_ROOT=dataset/train display_id=11 name=inpaintCenter overlapPred=4 wtl2=0.999 nBottleneck=4000 niter=500 loadSize=350 fineSize=128 gpu=1 th train.lua \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8965356881081553
      ],
      "excerpt": "  DATA_ROOT=dataset/train display_id=11 name=inpaintRandomNoOverlap useOverlapPred=0 wtl2=0.999 nBottleneck=4000 niter=500 loadSize=350 fineSize=128 gpu=1 th train_random.lua \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.879058517102802
      ],
      "excerpt": "  DATA_ROOT=dataset/train display_id=11 name=inpaintRandomNoOverlap useOverlapPred=0 wtl2=0.999 nBottleneck=4000 niter=500 loadSize=350 fineSize=64 gpu=1 th train_random.lua \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8615162427447648
      ],
      "excerpt": "Test the model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9170851600632525,
        0.9170851600632525,
        0.8523441640427077,
        0.890340468456579,
        0.890340468456579
      ],
      "excerpt": "  DATA_ROOT=dataset/val net=checkpoints/inpaintCenter_500_net_G.t7 name=test_patch overlapPred=4 manualSeed=222 batchSize=30 loadSize=350 gpu=1 th test.lua \n  DATA_ROOT=dataset/val net=checkpoints/inpaintCenter_500_net_G.t7 name=test_full overlapPred=4 manualSeed=222 batchSize=30 loadSize=129 gpu=1 th test.lua \n#: For testing random region inpainting model, run (with fineSize=64 or 124, same as training): \n  DATA_ROOT=dataset/val net=checkpoints/inpaintRandomNoOverlap_500_net_G.t7 name=test_patch_random useOverlapPred=0 manualSeed=222 batchSize=30 loadSize=350 gpu=1 th test_random.lua \n  DATA_ROOT=dataset/val net=checkpoints/inpaintRandomNoOverlap_500_net_G.t7 name=test_full_random useOverlapPred=0 manualSeed=222 batchSize=30 loadSize=129 gpu=1 th test_random.lua \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/pathak22/context-encoder/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Lua",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'UC Berkeley\\'s Standard Copyright and Disclaimer Notice:\\n\\nCopyright (c) 2016, Deepak Pathak\\nand The Regents of the University of California (Regents). \\nAll Rights Reserved. \\n\\nPermission to use, copy, modify, and distribute this software and its \\ndocumentation for educational, research, and not-for-profit purposes, without \\nfee and without a signed licensing agreement, is hereby granted, provided that \\nthe above copyright notice, this paragraph and the following two paragraphs appear \\nin all copies, modifications, and distributions. Contact The Office of Technology \\nLicensing, UC Berkeley, 2150 Shattuck Avenue, Suite 510, Berkeley, CA 94720-1620, \\n(510) 643-7201, for commercial licensing opportunities.\\n\\nIN NO EVENT SHALL REGENTS BE LIABLE TO ANY PARTY FOR DIRECT, INDIRECT, SPECIAL, \\nINCIDENTAL, OR CONSEQUENTIAL DAMAGES, INCLUDING LOST PROFITS, ARISING OUT OF THE \\nUSE OF THIS SOFTWARE AND ITS DOCUMENTATION, EVEN IF REGENTS HAS BEEN ADVISED OF THE \\nPOSSIBILITY OF SUCH DAMAGE. REGENTS SPECIFICALLY DISCLAIMS ANY WARRANTIES, INCLUDING, \\nBUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR \\nPURPOSE. THE SOFTWARE AND ACCOMPANYING DOCUMENTATION, IF ANY, PROVIDED HEREUNDER IS \\nPROVIDED \"AS IS\". REGENTS HAS NO OBLIGATION TO PROVIDE MAINTENANCE, SUPPORT, UPDATES, \\nENHANCEMENTS, OR MODIFICATIONS.\\n\\n--------------------------------------------------------\\n\\nThis code is adapted from an initial fork of dcgan.torch software. \\nThe License for which is as follows:\\n\\nCopyright (c) 2015, Facebook, Inc. All rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without modification,\\nare permitted provided that the following conditions are met:\\n\\n * Redistributions of source code must retain the above copyright notice, this\\n    list of conditions and the following disclaimer.\\n\\n * Redistributions in binary form must reproduce the above copyright notice,\\n    this list of conditions and the following disclaimer in the documentation\\n\\t   and/or other materials provided with the distribution.\\n\\n * Neither the name Facebook nor the names of its contributors may be used to\\n    endorse or promote products derived from this software without specific\\n\\t   prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Context Encoders: Feature Learning by Inpainting",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "context-encoder",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "pathak22",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pathak22/context-encoder/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 792,
      "date": "Tue, 28 Dec 2021 09:20:07 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "image-inpainting",
      "context-encoders",
      "unsupervised-learning",
      "machine-learning",
      "generative-adversarial-network",
      "deep-learning",
      "computer-vision",
      "gan",
      "dcgan",
      "computer-graphics"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Install Torch:  http://torch.ch/docs/getting-started.html#_\n\n2. Clone the repository\n  ```Shell\n  git clone https://github.com/pathak22/context-encoder.git\n  ```\n  \n3. Demo\n  ```Shell\n  cd context-encoder\n  bash ./models/scripts/download_inpaintCenter_models.sh\n  #: This will populate the `./models/` folder with trained models.\n\n  net=models/inpaintCenter/paris_inpaintCenter.t7 name=paris_result imDir=images/paris overlapPred=4 manualSeed=222 batchSize=21 gpu=1 th demo.lua\n  net=models/inpaintCenter/imagenet_inpaintCenter.t7 name=imagenet_result imDir=images/imagenet overlapPred=4 manualSeed=222 batchSize=21 gpu=1 th demo.lua\n  net=models/inpaintCenter/paris_inpaintCenter.t7 name=ucberkeley_result imDir=images/ucberkeley overlapPred=4 manualSeed=222 batchSize=4 gpu=1 th demo.lua\n  #: Note: If you are running on cpu, use gpu=0\n  #: Note: samples given in ./images/* are held-out images\n  ```\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Part of this code is inspired by Zhirong Wu's unsupervised learning algorithm [lemniscate](https://github.com/zhirongw/lemniscate.pytorch).\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1911.05722",
      "https://arxiv.org/abs/1805.01978",
      "https://arxiv.org/abs/1906.05849"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this repo useful for your research, please consider citing the paper\n\n```\n@article{tian2019contrastive,\n  title={Contrastive Multiview Coding},\n  author={Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},\n  journal={arXiv preprint arXiv:1906.05849},\n  year={2019}\n}\n```\nFor any questions, please contact Yonglong Tian (yonglong@mit.edu).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{tian2019contrastive,\n  title={Contrastive Multiview Coding},\n  author={Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},\n  journal={arXiv preprint arXiv:1906.05849},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8245369283321426,
        0.977180975530823
      ],
      "excerpt": "Nov 26, 2019 - New results updated. Implementation of MoCo and InsDis added. \nJan 18, 2019 - Weights of InsDis and MoCo added. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/szq0214/CMC_with_Image_Mixture",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-11T00:39:16Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-04T02:55:15Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9647447240783197,
        0.9075646324464065
      ],
      "excerpt": "This repo covers the implementation for CMC (as well as Momentum Contrast and Instance Discrimination), which learns representations from multiview data in a self-supervised way (by multiview, we mean multiple sensory, multiple modal data, or literally multiple viewpoint data. It's flexible to define what is a \"view\"): \n\"Contrastive Multiview Coding\" Paper, Project Page. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9375338307449735
      ],
      "excerpt": "We found that, the more views we train with, the better the representation (of each single view). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8749469006487666
      ],
      "excerpt": "We compare the contrastive objective to cross-view prediction, finding an advantage to the contrastive approach. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8424624529889236
      ],
      "excerpt": "Several ResNets trained with our unsupervised CMC objective surpasses supervisedly trained AlexNet on ImageNet classification ( e.g., 68.4% v.s. 59.3%). For this first time on ImageNet classification, unsupervised methods are surpassing the classic supervised-AlexNet proposed in 2012 (CPC++ and AMDIM also achieve this milestone concurrently). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9114310561077588
      ],
      "excerpt": "Nov 26, 2019 - New results updated. Implementation of MoCo and InsDis added. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8016665534892699,
        0.8282431397563331
      ],
      "excerpt": "- --nce_k: number of negatives to contrast for each positive. Default: 4096 \n- --nce_m: the momentum for dynamically updating the memory. Default: 0.5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.8623089371369858
      ],
      "excerpt": "Model flag: \n- --model: specify which model to use, including alexnet, resnets18, resnets50, and resnets101 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.91551281322552
      ],
      "excerpt": "- --IM_type: specify the type of IM and other augmentation methods that we implement, including: 'IM', 'global', 'region', 'Cutout', 'RandomErasing'. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9825077929160404
      ],
      "excerpt": "To support mixed precision training, simply append the flag --amp, which, however is likely to harm the downstream classification. I measure it on ImageNet100 subset and the gap is about 0.5-1%. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8745015599808337
      ],
      "excerpt": "Model flag --model is similar as above and should be specified. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8297032442491137
      ],
      "excerpt": "This repo provides 3 ways to train the linear classifier: single GPU, data parallel, and distributed data parallel. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9195316177950839
      ],
      "excerpt": "Note: When training linear classifiers on top of ResNets, it's important to use large learning rate, e.g., 30~50. Specifically, change --learning_rate 0.1 --layer 5 to --learning_rate 30 --layer 6 for resnet50v1 and resnet50v2, to --learning_rate 50 --layer 6 for resnet50v3. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8703857545464165
      ],
      "excerpt": "- CMC weights are trained with NCE loss, Lab color space, 4096 negatives and amp option. Switching to softmax-ce loss, YCbCr, 65536 negatives, and turning off amp option, are likely to improve the results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8954056917745187
      ],
      "excerpt": "InsDis and MoCo are trained using the same hyperparameters as in MoCo (epochs=200, lr=0.03, lr_decay_epochs=120,160, weight_decay=1e-4), but with only 4 GPUs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "pytorch implementation of \"Contrastive Multiview Coding\", \"Momentum Contrast for Unsupervised Visual Representation Learning\", and \"Unsupervised Feature Learning via Non-Parametric Instance-level Discrimination\"",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/szq0214/CMC_with_Image_Mixture/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Fri, 24 Dec 2021 15:26:08 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/szq0214/CMC_with_Image_Mixture/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "szq0214/CMC_with_Image_Mixture",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This repo was tested with Ubuntu 16.04.5 LTS, Python 3.5, PyTorch 0.4.0, and CUDA 9.0. But it should be runnable with recent PyTorch versions >=0.4.0\n\n**Note:** It seems to us that training with Pytorch version >= 1.0 yields slightly worse results. If you find the similar discrepancy and figure out the problem, please report this since we are trying to fix it as well.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8344099021597466
      ],
      "excerpt": " --tb_path /path/to/tensorboard \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8344099021597466
      ],
      "excerpt": " --tb_path path/to/tensorboard \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8331008273004277,
        0.8344099021597466
      ],
      "excerpt": " --save_path /path/to/save \\ \n --tb_path /path/to/tensorboard \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8244453191770256
      ],
      "excerpt": "Note:  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8171577874467769,
        0.8285537148196056
      ],
      "excerpt": "- --data_folder: specify the ImageNet data folder. \n- --model_path: specify the path to save model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8603760879160054,
        0.8496785639887214
      ],
      "excerpt": "An example of command line for training CMC (Default: AlexNet on Single GPU) \nCUDA_VISIBLE_DEVICES=0 python train_CMC.py --batch_size 256 --num_workers 36 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8013627068085554
      ],
      "excerpt": " --model_path /path/to/save  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9071872482675597
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0,1,2,3 python train_CMC.py --model resnet50v1 --batch_size 128 --num_workers 24 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8013627068085554
      ],
      "excerpt": " --model_path path/to/save \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8173943521354973
      ],
      "excerpt": "- --data_folder: specify the ImageNet data folder. Should be the same as above. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8770578718257225
      ],
      "excerpt": "Specify the checkpoint that you want to evaluate with --model_path flag, this path should directly point to the .pth file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8605287650171406,
        0.8713270762419942
      ],
      "excerpt": "An example of command line for evaluating, say ./models/alexnet.pth, should look like: \nCUDA_VISIBLE_DEVICES=0 python LinearProbing.py --dataset imagenet \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8722812450412569
      ],
      "excerpt": " --model_path ./models/alexnet.pth \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/szq0214/CMC_with_Image_Mixture/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Contrastive Multiview Coding",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "CMC_with_Image_Mixture",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "szq0214",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/szq0214/CMC_with_Image_Mixture/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 16,
      "date": "Fri, 24 Dec 2021 15:26:08 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "I have implemented and tested MoCo and InsDis on a ImageNet100 subset (but the code allows one to train on full ImageNet simply by setting the flag `--dataset imagenet`):\n\nThe pre-training stage:\n\n- For InsDis:\n    ```\n    CUDA_VISIBLE_DEVICES=0,1,2,3 python train_moco_ins.py \\\n     --batch_size 128 --num_workers 24 --nce_k 16384 --softmax\n    ```\n- For MoCo:\n    ```\n    CUDA_VISIBLE_DEVICES=0,1,2,3 python train_moco_ins.py \\\n     --batch_size 128 --num_workers 24 --nce_k 16384 --softmax --moco\n    ```\n  \nThe linear evaluation stage:\n- For both InsDis and MoCo (lr=10 is better than 30 on this subset, for full imagenet please switch to 30):\n    ```\n    CUDA_VISIBLE_DEVICES=0 python eval_moco_ins.py --model resnet50 \\\n     --model_path /path/to/model --num_workers 24 --learning_rate 10\n    ```\n  \nThe comparison of `CMC` (using YCbCr), `MoCo` and `InsDIS` on my ImageNet100 subset, is tabulated as below:\n\n|          |Arch | #Params(M) | Loss  | #Negative  | Accuracy |\n|----------|:----:|:---:|:---:|:---:|:---:|\n|  InsDis | ResNet50 | 24  | NCE  | 16384  |  --  |\n|  InsDis | ResNet50 | 24  | Softmax-CE  | 16384  |  69.1  |\n|  MoCo | ResNet50 | 24  | NCE  | 16384  |  --  |\n|  MoCo | ResNet50 | 24  | Softmax-CE  | 16384  |  73.4  |\n|  CMC | 2xResNet50half | 12  | NCE  | 4096  |  --  |\n|  CMC | 2xResNet50half | 12  | Softmax-CE  | 4096  |  75.8  |\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
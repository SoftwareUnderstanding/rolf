{
  "citation": [
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": "| --patience INT        | early stopping patience (default: 10) | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/samihadouaj/siyanWork",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-14T17:47:46Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-14T17:54:38Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9159701410234803
      ],
      "excerpt": "| --no_shuffle         |  disable shuffling of training data (for each epoch) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278701362913904
      ],
      "excerpt": "| --maxibatch_size INT |  size of maxibatch (number of minibatches that are sorted by length) (default: 20) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8718944408282925
      ],
      "excerpt": "more instructions to train a model, including a sample configuration and \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/samihadouaj/siyanWork/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 03:13:12 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/samihadouaj/siyanWork/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "samihadouaj/siyanWork",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/samihadouaj/siyanWork/master/commmitgen/test.sh",
      "https://raw.githubusercontent.com/samihadouaj/siyanWork/master/commmitgen/train.sh",
      "https://raw.githubusercontent.com/samihadouaj/siyanWork/master/commmitgen/runwrap.sh",
      "https://raw.githubusercontent.com/samihadouaj/siyanWork/master/commmitgen/validate.sh",
      "https://raw.githubusercontent.com/samihadouaj/siyanWork/master/commmitgen/postprocess-dev.sh",
      "https://raw.githubusercontent.com/samihadouaj/siyanWork/master/commmitgen/run.sh",
      "https://raw.githubusercontent.com/samihadouaj/siyanWork/master/test/test_train.sh",
      "https://raw.githubusercontent.com/samihadouaj/siyanWork/master/data/postprocess.sh",
      "https://raw.githubusercontent.com/samihadouaj/siyanWork/master/data/merge.sh",
      "https://raw.githubusercontent.com/samihadouaj/siyanWork/master/data/preprocess.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "| parameter            | description |\n|---                   |--- |\n| --datasets PATH PATH |  parallel training corpus (source and target) |\n| --dictionaries PATH [PATH ...] | network vocabularies (one per source factor, plus target vocabulary) |\n| --model PATH         |  model file name (default: model.npz) |\n| --saveFreq INT       |  save frequency (default: 30000) |\n| --reload             |  load existing model (if '--model' points to existing model) |\n| --overwrite          |  write all models to same file |\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9125945762597037
      ],
      "excerpt": "execute nematus/nmt.py to train a model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8230019213958345
      ],
      "excerpt": "| --dim INT            |  hidden layer size (default: 1000) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8610064261332286
      ],
      "excerpt": "| --dim_per_factor INT [INT ...] | list of word vector dimensionalities (one per factor): '--dim_per_factor 250 200 50' for total dimensionality of 500 (default: None) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8454855050993229
      ],
      "excerpt": "| --batch_size INT     | minibatch size (default: 80) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8253679049493864
      ],
      "excerpt": "| --no_shuffle         |  disable shuffling of training data (for each epoch) | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.835948233524803
      ],
      "excerpt": "| --finetune_only_last |  train with all layers except output layer fixed | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8431515624772767
      ],
      "excerpt": "| --valid_batch_size INT | validation minibatch size (default: 80) | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/samihadouaj/siyanWork/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Perl",
      "Emacs Lisp",
      "JavaScript",
      "PHP",
      "Shell",
      "Smalltalk",
      "Ruby",
      "NewLisp",
      "Slash",
      "SystemVerilog"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright (c) 2015, Kyunghyun Cho\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n Redistributions of source code must retain the above copyright notice, this\\n  list of conditions and the following disclaimer.\\n\\n Redistributions in binary form must reproduce the above copyright notice,\\n  this list of conditions and the following disclaimer in the documentation\\n  and/or other materials provided with the distribution.\\n\\n* Neither the name of Nematus nor the names of its\\n  contributors may be used to endorse or promote products derived from\\n  this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "## TRAINING",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "siyanWork",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "samihadouaj",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/samihadouaj/siyanWork/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 03:13:12 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "| parameter            | description |\n|---                   |--- |\n| -k K                 | Beam size (default: 5)) |\n|-p P                  | Number of processes (default: 5)) |\n| -n                   | Normalize scores by sentence length |\n| -v                   | verbose mode. |\n| --models MODELS [MODELS ...], -m MODELS [MODELS ...] | model to use. Provide multiple models (with same vocabulary) for ensemble decoding |\n|--input PATH, -i PATH | Input file (default: standard input) |\n| --output PATH, -o PATH | Output file (default: standard output) |\n| --output_alignment PATH, -a PATH | Output file for alignment weights (default: standard output) |\n| --json_alignment     | Output alignment in json format |\n| --n-best             | Write n-best list (of size k) |\n| --suppress-unk       | Suppress hypotheses containing UNK. |\n| --print-word-probabilities, -wp | Print probabilities of each word |\n| --search_graph, -sg  | Output file for search graph rendered as PNG image |\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "| parameter              | description |\n|---                     |--- |\n| -b B                   |   Minibatch size (default: 80)) |\n| -n                     |   Normalize scores by sentence length |\n| -v                     |   verbose mode. |\n| --models MODELS [MODELS ...], -m MODELS [MODELS ...] | model to use. Provide multiple models (with same vocabulary) for ensemble decoding |\n| --source PATH, -s PATH | Source text file |\n| --target PATH, -t PATH | Target text file |\n| --output PATH, -o PATH | Output file (default: standard output) |\n| --walign, -w           | Whether to store the alignment weights or not. If specified, weights will be saved in <target>.alignment |\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "The n-best list is assumed to have the same format as Moses:\n\n    sentence-ID (starting from 0) ||| translation ||| scores\n\nnew scores will be appended to the end. `rescore.py` has the same arguments as `score.py`, with the exception of this additional parameter:\n\n| parameter             | description |\n|---                    |--- |\n| --input PATH, -i PATH | Input n-best list file (default: standard input) |\n\n\nsample models, and instructions on using them for translation, are provided in the `test` directory, and at http://statmt.org/rsennrich/wmt16_systems/\n\nPUBLICATIONS\n------------\n\nthe code is based on the following model:\n\nDzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio (2015): Neural Machine Translation by Jointly Learning to Align and Translate, Proceedings of the International Conference on Learning Representations (ICLR).\n\nfor the changes specific to Nematus, please consider the following papers:\n\nSennrich, Rico, Haddow, Barry, Birch, Alexandra (2016): Edinburgh Neural Machine Translation Systems for WMT 16, Proc. of the First Conference on Machine Translation (WMT16). Berlin, Germany\n\nSennrich, Rico, Haddow, Barry (2016): Linguistic Input Features Improve Neural Machine Translation, Proc. of the First Conference on Machine Translation (WMT16). Berlin, Germany\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\r\n@article{yao2021latent,\r\n  title={A Latent Transformer for Disentangled Face Editing in Images and Videos},\r\n  author={Yao, Xu and Newson, Alasdair and Gousseau, Yann and Hellier, Pierre},\r\n  journal={2021 International Conference on Computer Vision},\r\n  year={2021}\r\n}\r\n```\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{yao2021latent,\n  title={A Latent Transformer for Disentangled Face Editing in Images and Videos},\n  author={Yao, Xu and Newson, Alasdair and Gousseau, Yann and Hellier, Pierre},\n  journal={2021 International Conference on Computer Vision},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8828916065398277
      ],
      "excerpt": "[Video Editing Results] \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/InterDigitalInc/latent-transformer",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-16T20:46:55Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T16:35:16Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.917886175211024
      ],
      "excerpt": "Official implementation for paper: A Latent Transformer for Disentangled Face Editing in Images and Videos.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9257711934979646
      ],
      "excerpt": "We also provide an interactive visualization notebooks/visu_manipulation.ipynb, where the user can choose the desired attributes for manipulation and define the magnitude of edit for each attribute. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Official implementation for paper: A Latent Transformer for Disentangled Face Editing in Images and Videos.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/InterDigitalInc/Latent-Transformer/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 11,
      "date": "Fri, 24 Dec 2021 09:12:05 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/InterDigitalInc/latent-transformer/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "InterDigitalInc/latent-transformer",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/InterDigitalInc/Latent-Transformer/master/notebooks/visu_manipulation.ipynb",
      "https://raw.githubusercontent.com/InterDigitalInc/Latent-Transformer/master/notebooks/figure_supplementary.ipynb",
      "https://raw.githubusercontent.com/InterDigitalInc/Latent-Transformer/master/notebooks/figure_sequential_edit.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/InterDigitalInc/Latent-Transformer/master/download.sh",
      "https://raw.githubusercontent.com/InterDigitalInc/Latent-Transformer/master/run_video_manip.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n* We use the pretrained StyleGAN2 encoder and generator released from paper [Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation](https://arxiv.org/pdf/2008.00951.pdf). Download and save the [official implementation](https://github.com/eladrich/pixel2style2pixel.git) to `pixel2style2pixel/` directory. Download and save the [pretrained model](https://drive.google.com/file/d/1bMTNWkh5LArlaWSc_wa8VKyq2V42T2z0/view) to `pixel2style2pixel/pretrained_models/`.\r\n\r\n* In order to save the latent codes to the designed path, we slightly modify `pixel2style2pixel/scripts/inference.py`.\r\n\r\n    ```\r\n    #: modify run_on_batch()\r\n    if opts.latent_mask is None:\r\n        result_batch = net(inputs, randomize_noise=False, resize=opts.resize_outputs, return_latents=True)\r\n        \r\n    #: modify run()\r\n    tic = time.time()\r\n    result_batch, latent_batch = run_on_batch(input_cuda, net, opts) \r\n    latent_save_path = os.path.join(test_opts.exp_dir, 'latent_code_%05d.npy'%global_i)\r\n    np.save(latent_save_path, latent_batch.cpu().numpy())\r\n    toc = time.time()\r\n    ```\r\n\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8001062344951293,
        0.9414980760431254,
        0.8548781402692205
      ],
      "excerpt": "To train the latent transformers, you can download our prepared dataset to the directory data/ and the pretrained latent classifier to the directory models/.  \nsh download.sh \nYou can also prepare your own training data. To achieve that, you need to map your dataset to latent codes using the StyleGAN2 encoder. The corresponding label file is also required. You can continue to use our pretrained latent classifier. If you want to train your own latent classifier on new labels, you can use pretraining/latent_classifier.py.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801518360241807
      ],
      "excerpt": "Make sure that the latent classifier is downloaded to the directory models/ and the StyleGAN2 encoder is prepared as required. After training your latent transformers, you can use test.py to run the latent transformer for the images in the test directory data/test/. We also provide several pretrained models here (run download.sh to download them). The output images will be saved in the folder outputs/. You can change the desired attribute with --attr. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd pixel2style2pixel/ \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8153674015789776
      ],
      "excerpt": "To train the latent transformers, you can download our prepared dataset to the directory data/ and the pretrained latent classifier to the directory models/.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8450640714658065,
        0.9317135315960992,
        0.8615990503927848,
        0.8944577955512857
      ],
      "excerpt": "You can modify the training options of the config file in the directory configs/. \npython train.py --config 001 \nMake sure that the latent classifier is downloaded to the directory models/ and the StyleGAN2 encoder is prepared as required. After training your latent transformers, you can use test.py to run the latent transformer for the images in the test directory data/test/. We also provide several pretrained models here (run download.sh to download them). The output images will be saved in the folder outputs/. You can change the desired attribute with --attr. \npython test.py --config 001 --attr Eyeglasses --out_path ./outputs/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.896858500678198,
        0.896858500678198
      ],
      "excerpt": "--data_path=../data/test/ \\ \n--exp_dir=../data/test/ \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/InterDigitalInc/latent-transformer/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# A Latent Transformer for Disentangled Face Editing in Images and Videos",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "latent-transformer",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "InterDigitalInc",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/InterDigitalInc/latent-transformer/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n- Python 3.6\r\n- PyTorch 1.8\r\n- Opencv\r\n- Tensorboard_logger\r\n\r\nYou can install a new environment for this repo by running\r\n```\r\nconda env create -f environment.yml\r\nconda activate lattrans \r\n```\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 53,
      "date": "Fri, 24 Dec 2021 09:12:05 GMT"
    },
    "technique": "GitHub API"
  }
}
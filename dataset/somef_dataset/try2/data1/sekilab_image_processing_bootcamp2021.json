{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2105.01601",
      "https://arxiv.org/abs/2012.00759",
      "https://arxiv.org/abs/2104.14540",
      "https://arxiv.org/abs/2010.16404",
      "https://arxiv.org/abs/2102.06171.](https://arxiv.org/pdf/2102.06171.pdf)\n\n- **Content**:  \n[materials](https://drive.google.com/file/d/1GLjVOQEsgNdWnSIga92vhsAwgtgnspvu/view?usp=sharing)\n\n\n## Session 2\n\n- **Date**:  \n2021/04/22 (Thu) 13:00-14:00\n\n- **Speaker**:  \nSato\n\n- **Paper**:  \n[Seto, T., Sekimoto, Y., Asahi, K., & Endo, T. (2020, November). Constructing a digital city on a web-3D platform: simultaneous and consistent generation of metadata and tile data from a multi-source raw dataset. In Proceedings of the 3rd ACM SIGSPATIAL International Workshop on Advances in Resilient and Intelligent Cities (pp. 1-9).](https://dl.acm.org/doi/10.1145/3423455.3430316)\n\n- **Content**:  \nIn [this Google Slide](https://docs.google.com/presentation/d/1lVhKxUh8XSkqwQOFwaUidxYcMGRGi2TEA9PYwSY3YNE/edit?usp=sharing), P13-P37 is the Session 2 content.\n\n\n## Session 3\n\n- **Date**:  \n2021/05/27 (Thu) 13:00-14:00\n\n- **Speaker**:  \nNakamura\n\n- **Paper**:\n[Mescheder, Lars, et al. \"Occupancy networks: Learning 3d reconstruction in function space.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.](https://avg.is.tuebingen.mpg.de/publications/occupancy-networks)\n\n- **Content**: \n [materials](https://drive.google.com/file/d/1sfd4E_SvzvKLL3LnU9UV0O3G_S2BcYtz/view?usp=sharing)\n\n\n\n## Session 4\n\n- **Date**:  \n2021/05/27 (Thu) 13:00-14:00\n\n- **Speaker**:  \nYang\n\n- **Paper**:\n[Takafumi Taketomi1*, Hideaki Uchiyama2 and Sei Ikeda3.(2017)Visual SLAM algorithms: a survey from 2010 to 2016.DOI 10.1186/s41074-017-0027-2](https://www.researchgate.net/publication/318235730_Visual_SLAM_algorithms_a_survey_from_2010_to_2016)\n\n- **Content**: \n [Presentation material](https://drive.google.com/file/d/1da2YDlEdPpBtqELqDfNfnRva9xlWYtl2/view?usp=sharing)\n\n\n## Session 5\n\n- **Date**:  \n2021/06/10 (Thu) 13:00-14:00\n\n- **Speaker**:  \nMiyoshi\n\n- **Paper**:\n[Tolstikhin, I, et al. (2021) MLP-Mixer: An all-MLP Architecture for Vision](https://arxiv.org/abs/2105.01601)\n\n- **Content**: \n [Presentation material](https://docs.google.com/presentation/d/1-mVMggvct15wzjYPQUhO-IiKrzE-43sr66BjxwbKIqg/view)\n\n\n\n## Session 6\n\n- **Date**:  \n2021/06/24 (Thu) 13:00-14:00\n\n- **Speaker**:  \nMaeda\n\n- **Content**: \nhttps://docs.google.com/presentation/d/1-GiXIkadvNTEY8CoX0gNQY04YeYy7kV9DIXK8AowTbM/edit?usp=sharing\n\n## Session 7\n\n- **Date**:  \n2021/07/08 (Thu) 13:00-14:00\n\n- **Speaker**:  \nAsh\n\n- **Paper**:\n[Evaluating Multiple Object Tracking Performance: The CLEAR MOT Metrics](https://jivp-eurasipjournals.springeropen.com/articles/10.1155/2008/246309)\n\n- **Content**: \n[In the MLI Bootcamp folder](https://docs.google.com/presentation/d/1yb6NJKHGcVcG-5sY3bTueF4KhfzOdx5fwn74PWbS5R0/edit?usp=sharing)\n\n## Session 8\n\n- **Date**:  \n2021/10/14 (Thu) 13:00-14:00\n\n- **Speaker**:  \nYang\n\n- **Paper**:\n[Vision-Based Distance Measurement in Advanced Driving Assistance Systems](https://www.mdpi.com/2076-3417/10/20/7276)\n\n- **Content**: \n[In the MLI Bootcamp folder](https://docs.google.com/presentation/d/1vHCgXirk1Cj0t2zfBRYEnIxd0QVI5eZR/edit?usp=sharing&ouid=109891689458810314396&rtpof=true&sd=true)\n\n\n## Session 9\n\n- **Date**:  \n2021/10/28 (Thu) 13:00-14:00\n\n- **Speaker**:  \nSato\n\n- **Paper**:\n[Campbell, A., Both, A., & Sun, Q. C. (2019) Detecting and mapping traffic signs from Google Street View images using deep learning and GIS. Computers, Environment and Urban Systems, 77, 101350.](https://www.sciencedirect.com/science/article/pii/S0198971519300870)\n\n- **Content**: \n[In the MLI Bootcamp folder](https://docs.google.com/presentation/d/125s5ulN7NKNeGvg5-QNI0srCI4z0W4F1PhrlkLc49cs/edit?usp=sharing)\n\n\n## Session 10\n\n- **Date**:  \n2021/11/11 (Thu) 13:00-14:00\n\n- **Speaker**:  \nAsh\n\n- **Paper**:\nTensorRT: A C++ library for high performance inference on NVIDIA GPUs and deep learning accelerators.\n\n- **Content**: \n[In the MLI Bootcamp folder](https://docs.google.com/presentation/d/10ZsdDbA5M9QACoGjENl52lUqw_1BJau0/edit?usp=sharing&ouid=107112930861688689808&rtpof=true&sd=true)\n\n\n## Session 11\n\n- **Date**:  \n2021/11/25 (Thu) 13:00-14:00\n\n- **Speaker**:  \nNakamura\n\n- **Paper**:\n[Huiyu Wang, Yukun Zhu, Hartwig Adam, Alan Yuille, Liang-Chieh Chen (2021) MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers](https://arxiv.org/abs/2012.00759)\n\n- **Content**: \n[In the MLI Bootcamp folder](https://drive.google.com/file/d/14lFtzlTxRDt-YLGRu_Y4SyRJsaFvqH-f/view?usp=sharing)\n\n\n## Session 12\n\n- **Date**:  \n2021/12/9 (Thu) 13:00-14:00\n\n- **Speaker**:  \nYang\n\n- **Paper**:\n[The Temporal Opportunist: Self-Supervised Multi-Frame Monocular Depth](https://arxiv.org/abs/2104.14540)\n\n- **Content**: \n[In the MLI Bootcamp folder](https://docs.google.com/presentation/d/1vHCgXirk1Cj0t2zfBRYEnIxd0QVI5eZR/edit?usp=sharing&ouid=109891689458810314396&rtpof=true&sd=true)\n\n\n## Session 13\n\n- **Date**:  \n2021/12/23 (Thu) 13:00-14:00\n\n- **Speaker**:  \nSato\n\n- **Paper**:\n[Li, H., Gordon, A., Zhao, H., Casser, V., & Angelova, A. (2020). Unsupervised monocular depth learning in dynamic scenes. arXiv preprint https://arxiv.org/abs/2010.16404.\n](https://arxiv.org/abs/2010.16404)\n\n- **Content**: \n[In the MLI Bootcamp folder](https://docs.google.com/presentation/d/1Uq6vFeFoS_Ap-zXEn-aLi8oT3UkhaVXp5L6gsrkSB-g/edit?usp=sharing)\n\n\n## Session 14\n\n- **Date**:  \n2022/01/13 (Thu) 13:00-14:00\n\n- **Speaker**:  \nAsh\n\n",
      "https://arxiv.org/abs/2010.16404.\n](https://arxiv.org/abs/2010.16404)\n\n- **Content**: \n[In the MLI Bootcamp folder](https://docs.google.com/presentation/d/1Uq6vFeFoS_Ap-zXEn-aLi8oT3UkhaVXp5L6gsrkSB-g/edit?usp=sharing)\n\n\n## Session 14\n\n- **Date**:  \n2022/01/13 (Thu) 13:00-14:00\n\n- **Speaker**:  \nAsh\n\n"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9187666642965994,
        0.9499963145257574
      ],
      "excerpt": "A laboratory study session on image processing. \nFY 2019 (Lab Member Only) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9925345988519223
      ],
      "excerpt": "Paper title \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8202342109601906
      ],
      "excerpt": "8. Source codes and examples link. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.999936948480441
      ],
      "excerpt": "Brock, A., De, S., Smith, S. L., & Simonyan, K. (2021). High-Performance Large-Scale Image Recognition Without Normalization. arXiv preprint arXiv:2102.06171. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9510037796481425
      ],
      "excerpt": "Seto, T., Sekimoto, Y., Asahi, K., & Endo, T. (2020, November). Constructing a digital city on a web-3D platform: simultaneous and consistent generation of metadata and tile data from a multi-source raw dataset. In Proceedings of the 3rd ACM SIGSPATIAL International Workshop on Advances in Resilient and Intelligent Cities (pp. 1-9). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999999994778079
      ],
      "excerpt": "Mescheder, Lars, et al. \"Occupancy networks: Learning 3d reconstruction in function space.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999404638976817
      ],
      "excerpt": "Takafumi Taketomi1*, Hideaki Uchiyama2 and Sei Ikeda3.(2017)Visual SLAM algorithms: a survey from 2010 to 2016.DOI 10.1186/s41074-017-0027-2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": "2021/06/10 (Thu) 13:00-14:00 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8184923311737462
      ],
      "excerpt": "Vision-Based Distance Measurement in Advanced Driving Assistance Systems \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": "2021/10/28 (Thu) 13:00-14:00 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8444342525991423
      ],
      "excerpt": "2021/11/11 (Thu) 13:00-14:00 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9895660788435471
      ],
      "excerpt": "Huiyu Wang, Yukun Zhu, Hartwig Adam, Alan Yuille, Liang-Chieh Chen (2021) MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8198521980227379
      ],
      "excerpt": "The Temporal Opportunist: Self-Supervised Multi-Frame Monocular Depth \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999695749889125
      ],
      "excerpt": "Li, H., Gordon, A., Zhao, H., Casser, V., & Angelova, A. (2020). Unsupervised monocular depth learning in dynamic scenes. arXiv preprint arXiv:2010.16404. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sekilab/image_processing_bootcamp2021",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-04T07:28:55Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T01:36:51Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9216147503345695,
        0.8964531139877469,
        0.8968723963985524,
        0.8625747640142094
      ],
      "excerpt": "1. What is this paper in short? \n2. What is the difference between this paper and related works? \n3. What is the technical contribution? \n4. What is the evaluation method? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9527900820128546
      ],
      "excerpt": "Seto, T., Sekimoto, Y., Asahi, K., & Endo, T. (2020, November). Constructing a digital city on a web-3D platform: simultaneous and consistent generation of metadata and tile data from a multi-source raw dataset. In Proceedings of the 3rd ACM SIGSPATIAL International Workshop on Advances in Resilient and Intelligent Cities (pp. 1-9). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9809903820673723
      ],
      "excerpt": "In this Google Slide, P13-P37 is the Session 2 content. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9414556272894106
      ],
      "excerpt": "TensorRT: A C++ library for high performance inference on NVIDIA GPUs and deep learning accelerators. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sekilab/image_processing_bootcamp2021/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 14:50:43 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sekilab/image_processing_bootcamp2021/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "sekilab/image_processing_bootcamp2021",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8161838980599615
      ],
      "excerpt": "2021/11/11 (Thu) 13:00-14:00 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sekilab/image_processing_bootcamp2021/issues{/number}",
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Image Processing Bootcamp 2021",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "image_processing_bootcamp2021",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "sekilab",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sekilab/image_processing_bootcamp2021/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Tue, 21 Dec 2021 14:50:43 GMT"
    },
    "technique": "GitHub API"
  }
}
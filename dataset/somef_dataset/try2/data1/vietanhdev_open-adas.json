{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1904.07850](https://arxiv.org/abs/1904.07850",
      "https://arxiv.org/abs/1904.07850",
      "https://arxiv.org/abs/1505.04597](https://arxiv.org/abs/1505.04597",
      "https://arxiv.org/abs/1505.04597",
      "https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385",
      "https://arxiv.org/abs/1512.03385"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Objects as Points - Xingyi Zhou, Dequan Wang, Philipp Kr\u00e4henb\u00fchl: [https://arxiv.org/abs/1904.07850](https://arxiv.org/abs/1904.07850).\n\n- U-Net: Convolutional Networks for Biomedical Image Segmentation - Olaf Ronneberger, Philipp Fischer, Thomas Brox: [https://arxiv.org/abs/1505.04597](https://arxiv.org/abs/1505.04597).\n\n- Deep Residual Learning for Image Recognition - Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun: [https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385).\n\n- Dark Theme for Qt5 by Juergen Skrotzky: [https://github.com/Jorgen-VikingGod/Qt-Frameless-Window-DarkStyle](https://github.com/Jorgen-VikingGod/Qt-Frameless-Window-DarkStyle).\n\n- ICSim: <https://github.com/zombieCraig/ICSim>.\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9990397322358974
      ],
      "excerpt": "Issue:  /usr/bin/ld: cannot find -lcudart, /usr/bin/ld: cannot find -lcublas \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vietanhdev/open-adas",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Development\nYou will need to install protobuf and numpy to build ONNX. An easy\nway to get these dependencies is via Anaconda:\n```\nUse conda-forge protobuf, as defaults doesn't come with protoc\nconda install -c conda-forge protobuf numpy\n```\nDuring development, it's convenient to install ONNX in development mode (for ONNX-ML, set environment variable ONNX_ML=1):\ngit clone --recursive https://github.com/onnx/onnx.git\npip install -e onnx/\nThen, after you have made changes to Python and C++ files:\n\nPython files: the changes are effective immediately in your installation. You don't need to install these again.\nC++ files: you need to install these again to trigger the native extension build.\n\nFolder structure\n\nonnx/: the main folder that all code lies under\nonnx.proto: the protobuf (v2.6.1) that contains all the structures\nchecker.py: a utility to check whether a serialized ONNX proto is legal\nhelper.py: tools for graph operation\ndefs/: a subfolder that defines the ONNX operators\ntest/: test files\n\nGenerated operator documentation\nOperator docs in Operators.md are automatically generated based on C++ operator definitions. To refresh these docs, remember to re-install (see above) and then run the following command from the repo root and commit the results:\npython onnx/defs/gen_doc.py\nAdding a new operator\nONNX is an open standard, and we encourage developers to contribute high\nquality operators to ONNX specification.\nBefore proposing a new operator, please read the tutorial.\nTesting\nONNX uses pytest as a test driver. To run tests, you'll first need to install pytest:\npip install pytest nbval\nAfter installing pytest, run\npytest\nto begin the tests.\nStatic typing (mypy)\nWe use mypy to run static type checks on the onnx code base. To check that your code passes, you'll first need to install the mypy type checker. If you're using python 3, call from your onnx source folder:\npip install -e .[mypy]\nThe type checker cannot run in a python 2 environment (but it will check python 2 code).\nIf you're using python 2, you need to install mypy into your system packages instead:\npip3 install mypy==[version]\nNote: You'll find the version we're currently using in setup.py.\nAfter having installed mypy, you can run the type checks:\npython setup.py typecheck\nOther developer documentation\n\nHow to implement ONNX backend (ONNX to something converter)\nBackend test infrastructure and how to add tests\n\nLicense\nMIT License\nCode of Conduct\nONNX Open Source Code of Conduct",
    "technique": "File Exploration"
  },
  "contributors": {
    "confidence": [
      1.0
    ],
    "excerpt": "People who have agreed to one of the CLAs and can contribute patches.\nThe AUTHORS file lists the copyright holders; this file\nlists people.  For example, Google employees are listed here\nbut not in AUTHORS, because Google holds the copyright.\n\nNames should be added to this file only after verifying that\nthe individual or the individual's organization has agreed to\nthe appropriate Contributor License Agreement, found here:\n\nhttps://developers.google.com/open-source/cla/individual\nhttps://developers.google.com/open-source/cla/corporate\n\nThe agreement for individuals can be filled out on the web.\n\nWhen adding J Random Contributor's name to this file,\neither J's name or J's organization's name should be\nadded to the AUTHORS file, depending on whether the\nindividual or corporate CLA was used.\n\nNames should be added to this file as:\nName <email address>\n\nPlease keep the list sorted.\nAlbert Pretorius &#112;&#114;&#101;&#116;&#111;&#97;&#108;&#98;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nArne Beer &#97;&#114;&#110;&#101;&#64;&#116;&#119;&#111;&#98;&#101;&#101;&#114;&#46;&#100;&#101;\nBilly Robert O'Neal III &#98;&#105;&#108;&#108;&#121;&#46;&#111;&#110;&#101;&#97;&#108;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109; &#98;&#105;&#111;&#110;&#64;&#109;&#105;&#99;&#114;&#111;&#115;&#111;&#102;&#116;&#46;&#99;&#111;&#109;\nChris Kennelly &#99;&#107;&#101;&#110;&#110;&#101;&#108;&#108;&#121;&#64;&#103;&#111;&#111;&#103;&#108;&#101;&#46;&#99;&#111;&#109; &#99;&#107;&#101;&#110;&#110;&#101;&#108;&#108;&#121;&#64;&#99;&#107;&#101;&#110;&#110;&#101;&#108;&#108;&#121;&#46;&#99;&#111;&#109;\nChristopher Seymour &#99;&#104;&#114;&#105;&#115;&#46;&#106;&#46;&#115;&#101;&#121;&#109;&#111;&#117;&#114;&#64;&#104;&#111;&#116;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nDavid Coeurjolly &#100;&#97;&#118;&#105;&#100;&#46;&#99;&#111;&#101;&#117;&#114;&#106;&#111;&#108;&#108;&#121;&#64;&#108;&#105;&#114;&#105;&#115;&#46;&#99;&#110;&#114;&#115;&#46;&#102;&#114;\nDeniz Evrenci &#100;&#101;&#110;&#105;&#122;&#101;&#118;&#114;&#101;&#110;&#99;&#105;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nDominic Hamon &#100;&#109;&#97;&#64;&#115;&#116;&#114;&#105;&#112;&#121;&#115;&#111;&#99;&#107;&#46;&#99;&#111;&#109; &#100;&#111;&#109;&#105;&#110;&#105;&#99;&#64;&#103;&#111;&#111;&#103;&#108;&#101;&#46;&#99;&#111;&#109;\nDominik Czarnota &#100;&#111;&#109;&#105;&#110;&#105;&#107;&#46;&#98;&#46;&#99;&#122;&#97;&#114;&#110;&#111;&#116;&#97;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nEric Fiselier &#101;&#114;&#105;&#99;&#64;&#101;&#102;&#99;&#115;&#46;&#99;&#97;\nEugene Zhuk &#101;&#117;&#103;&#101;&#110;&#101;&#46;&#122;&#104;&#117;&#107;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nEvgeny Safronov &#100;&#105;&#118;&#105;&#115;&#105;&#111;&#110;&#52;&#57;&#52;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nFelix Homann &#108;&#105;&#110;&#117;&#120;&#97;&#117;&#100;&#105;&#111;&#64;&#115;&#104;&#111;&#119;&#108;&#97;&#98;&#111;&#114;&#46;&#100;&#101;\nIsmael Jimenez Martinez &#105;&#115;&#109;&#97;&#101;&#108;&#46;&#106;&#105;&#109;&#101;&#110;&#101;&#122;&#46;&#109;&#97;&#114;&#116;&#105;&#110;&#101;&#122;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nJern-Kuan Leong &#106;&#101;&#114;&#110;&#107;&#117;&#97;&#110;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nJianXiong Zhou &#122;&#104;&#111;&#117;&#106;&#105;&#97;&#110;&#120;&#105;&#111;&#110;&#103;&#50;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nJoao Paulo Magalhaes &#106;&#111;&#97;&#111;&#112;&#112;&#109;&#97;&#103;&#97;&#108;&#104;&#97;&#101;&#115;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nJohn Millikin &#106;&#109;&#105;&#108;&#108;&#105;&#107;&#105;&#110;&#64;&#115;&#116;&#114;&#105;&#112;&#101;&#46;&#99;&#111;&#109;\nJussi Knuuttila &#106;&#117;&#115;&#115;&#105;&#46;&#107;&#110;&#117;&#117;&#116;&#116;&#105;&#108;&#97;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nKai Wolf &#107;&#97;&#105;&#46;&#119;&#111;&#108;&#102;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nKishan Kumar &#107;&#117;&#109;&#97;&#114;&#46;&#107;&#105;&#115;&#104;&#97;&#110;&#64;&#111;&#117;&#116;&#108;&#111;&#111;&#107;&#46;&#99;&#111;&#109;\nKaito Udagawa &#117;&#109;&#105;&#114;&#101;&#111;&#110;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nLei Xu &#101;&#100;&#100;&#121;&#120;&#117;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nMatt Clarkson &#109;&#97;&#116;&#116;&#121;&#99;&#108;&#97;&#114;&#107;&#115;&#111;&#110;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nMaxim Vafin &#109;&#97;&#120;&#118;&#97;&#102;&#105;&#110;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nNick Hutchinson &#110;&#115;&#104;&#117;&#116;&#99;&#104;&#105;&#110;&#115;&#111;&#110;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nOleksandr Sochka &#115;&#97;&#115;&#104;&#97;&#46;&#115;&#111;&#99;&#104;&#107;&#97;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nPascal Leroy &#112;&#104;&#108;&#64;&#103;&#111;&#111;&#103;&#108;&#101;&#46;&#99;&#111;&#109;\nPaul Redmond &#112;&#97;&#117;&#108;&#46;&#114;&#101;&#100;&#109;&#111;&#110;&#100;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nPierre Phaneuf &#112;&#112;&#104;&#97;&#110;&#101;&#117;&#102;&#64;&#103;&#111;&#111;&#103;&#108;&#101;&#46;&#99;&#111;&#109;\nRadoslav Yovchev &#114;&#97;&#100;&#111;&#115;&#108;&#97;&#118;&#46;&#116;&#109;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nRaul Marin &#114;&#109;&#114;&#111;&#100;&#114;&#105;&#103;&#117;&#101;&#122;&#64;&#99;&#97;&#114;&#116;&#111;&#100;&#98;&#46;&#99;&#111;&#109;\nRay Glover &#114;&#97;&#121;&#46;&#103;&#108;&#111;&#118;&#101;&#114;&#64;&#117;&#107;&#46;&#105;&#98;&#109;&#46;&#99;&#111;&#109;\nRobert Guo &#114;&#111;&#98;&#101;&#114;&#116;&#46;&#103;&#117;&#111;&#64;&#109;&#111;&#110;&#103;&#111;&#100;&#98;&#46;&#99;&#111;&#109;\nRoman Lebedev &#108;&#101;&#98;&#101;&#100;&#101;&#118;&#46;&#114;&#105;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nShuo Chen &#99;&#104;&#101;&#110;&#115;&#104;&#117;&#111;&#64;&#99;&#104;&#101;&#110;&#115;&#104;&#117;&#111;&#46;&#99;&#111;&#109;\nTobias Ulvg\u00e5rd &#116;&#111;&#98;&#105;&#97;&#115;&#46;&#117;&#108;&#118;&#103;&#97;&#114;&#100;&#64;&#100;&#105;&#114;&#97;&#99;&#46;&#115;&#101;\nTom Madams &#116;&#111;&#109;&#46;&#101;&#106;&#46;&#109;&#97;&#100;&#97;&#109;&#115;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109; &#116;&#109;&#97;&#100;&#97;&#109;&#115;&#64;&#103;&#111;&#111;&#103;&#108;&#101;&#46;&#99;&#111;&#109;\nYixuan Qiu &#121;&#105;&#120;&#117;&#97;&#110;&#113;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nYusuke Suzuki &#117;&#116;&#97;&#116;&#97;&#110;&#101;&#46;&#116;&#101;&#97;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\nZbigniew Skowron &#122;&#98;&#121;&#99;&#104;&#115;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-22T05:57:00Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T15:12:23Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9125211522528794,
        0.9158889895765342
      ],
      "excerpt": "An advanced driver-assistance system on Jetson Nano embedded computer with four main functions: forward collision warning, lane departure warning, traffic sign recognition and overspeed warning. This repository contains source code for Jetson Nano, not including the source code for model training and conversion. \nDownload models and testing data here and put into root folder of this project. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8422087224281612
      ],
      "excerpt": "  with any of the following names: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "How to fix? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "How to fix?  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "An open source advanced driver assistance system (ADAS) that uses Jetson Nano as the hardware. Features: Traffic sign detection, Forward collision warning, Lane departure warning.",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- **(Blog) Intro and Hardware:** <https://aicurious.io/posts/adas-jetson-nano-intro-and-hardware/>.\n- **(Blog) Software stack**: <https://aicurious.io/posts/adas-jetson-nano-software/>.\n- **(Blog) Deep neural networks:** <https://aicurious.io/posts/adas-jetson-nano-deep-neural-networks/>.\n- **(Documentation) OpenADAS:** *Design, CANbus, Calibration, Model training and deployment notes*: [docs/open-adas.md](docs/open-adas.md).\n- **(Documentation) How to setup on a Jetson Xavier:** [docs/setup-jetson-xavier.md](docs/setup-jetson-xavier.md).\n\n**For TensorRT 7 support:** Currently, only TensorRT 5 and 6 are supported. TensorRT 7 has a lot of deprecated APIs and I think there is no way to run this project directly with that version. I don't have time to continue with this project soon, so I really need your contributions to extend this project further.\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vietanhdev/open-adas/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 65,
      "date": "Fri, 24 Dec 2021 07:52:58 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/vietanhdev/open-adas/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "vietanhdev/open-adas",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/vietanhdev/open-adas/tree/master/docs",
      "https://github.com/vietanhdev/open-adas/tree/master/src/perception/common/onnx_models/docs",
      "https://github.com/vietanhdev/open-adas/tree/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/docs",
      "https://github.com/vietanhdev/open-adas/tree/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/third_party/pybind11/docs",
      "https://github.com/vietanhdev/open-adas/tree/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/third_party/benchmark/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/onnx/examples/check_model.ipynb",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/onnx/examples/load_model.ipynb",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/onnx/examples/optimize_onnx.ipynb",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/onnx/examples/np_array_tensorproto.ipynb",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/onnx/examples/save_model.ipynb",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/onnx/examples/Protobufs.ipynb",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/onnx/examples/make_model.ipynb",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/onnx/examples/shape_inference.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/run_smartcam.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/build.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/setup_vcan.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/build_engines.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/third_party/pybind11/tools/check-style.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/third_party/benchmark/.travis-libcxx-setup.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/conda/build.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/.travis/setup.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/.travis/after_success.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/.travis/script.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/.travis/install.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/.travis/after_failure.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/.travis/before_install.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/tools/update_doc.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/.circleci/test.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/src/perception/common/onnx_models/onnx-tensorrt/third_party/onnx/.circleci/build.sh",
      "https://raw.githubusercontent.com/vietanhdev/open-adas/master/sounds/traffic_signs/convert_to_wav.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Install QT:\n\n```\nsudo apt-get install build-essential\nsudo apt-get install qt5-default qtcreator qt5-doc qt5-doc-html qtbase5-doc-html qtbase5-examples -y\nsudo /sbin/ldconfig -v\n```\n\n- Install OpenCV\n\n```\nhttps://linuxize.com/post/how-to-install-opencv-on-ubuntu-18-04/\n```\n\n- Install protobuf 3.6.1\n\n```\nhttps://github.com/protocolbuffers/protobuf\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "I created an image of my SD card [here](https://1drv.ms/u/s!Av71xxzl6mYZgdZxDoxDnxR-sOERSw?e=S2o1uR). You can flash and run this image on Jetson Nano.\n\n**Note:**\n\n- The source code and binary files in this SD card image is older than in `master` branch. Please upgrade to the lastest source code and recompile on your device.\n- Use Alt+F4 to exit the GUI and start editing your source code.\n- Login information:\n    + Username: `smartcam`.\n    + Password: Open Terminal and type `sudo passwd smartcam` to change the password.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9090847936590888
      ],
      "excerpt": "Note: The paths can be different on your computer. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9379399526742241,
        0.8338195372547608
      ],
      "excerpt": "sudo apt-get install qttools5-dev-tools libqt5svg5-dev qtmultimedia5-dev \nIssue:  Need to specify CUDA root \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9565332780871698
      ],
      "excerpt": "You should change the path corresponding to your environment. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8436472367697798
      ],
      "excerpt": "Download models and testing data here and put into root folder of this project. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/vietanhdev/open-adas/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "C++",
      "Cuda",
      "Python",
      "CMake",
      "C",
      "SWIG",
      "Dockerfile",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b\"NemaTode is released under the ZLib license.\\n\\nThis software is provided 'as-is', without any express or implied\\nwarranty. In no event will the authors be held liable for any damages\\narising from the use of this software.\\n\\nPermission is granted to anyone to use this software for any purpose,\\nincluding commercial applications, and to alter it and redistribute it\\nfreely, subject to the following restrictions:\\n\\n    1. The origin of this software must not be misrepresented; you must not\\n    claim that you wrote the original software. If you use this software\\n    in a product, an acknowledgment in the product documentation would be\\n    appreciated but is not required.\\n    2. Altered source versions must be plainly marked as such, and must not be\\n    misrepresented as being the original software.\\n    3. This notice may not be removed or altered from any source\\n    distribution.\"",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "OpenADAS - An advanced driver-assistance system using Jetson Nano",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "open-adas",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "vietanhdev",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vietanhdev/open-adas/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "vietanhdev",
        "body": "- Traffic sign detection\r\n- Forward collision warning\r\n- Lane departure warning\r\n- Virtual CAN bus for reading car speed\r\n- Deployed and tested on Jetson Nano",
        "dateCreated": "2021-03-01T15:50:37Z",
        "datePublished": "2021-03-04T16:23:21Z",
        "html_url": "https://github.com/vietanhdev/open-adas/releases/tag/0.1",
        "name": "The first version on Jetson Nano",
        "tag_name": "0.1",
        "tarball_url": "https://api.github.com/repos/vietanhdev/open-adas/tarball/0.1",
        "url": "https://api.github.com/repos/vietanhdev/open-adas/releases/39286717",
        "zipball_url": "https://api.github.com/repos/vietanhdev/open-adas/zipball/0.1"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- CMake >= 3.10\n- Qt 5\n- OpenCV >= 4.0.1\n- C++ 17 compiler\n- CUDA 10.x\n- TensorRT 5.1.5-1+cuda10.1, or - TensorRT 6.0.1.8+10.2. **This project should work with TensorRT 5 and TensorRT 6. TensorRT 7 is not supported for now.**\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Update `GPU_ARCHS`: Modify `GPU_ARCHS` in `CMakeLists.txt` to suit your GPU. For Jetson Nano, GPU_ARCHS = 53 and for my RTX 2070, GPU_ARCHS = 75. Read more in following posts:\n  + <https://www.programmersought.com/article/28125950847/>\n  + <https://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/>\n\n- Compile\n```\ncd <project directory>\nmkdir build\ncd build\ncmake -DCUDA_INCLUDE_DIRS=/usr/local/cuda-10.2/include ..\nmake\n```\n\nReplace `CUDA_INCLUDE_DIRS` with your own path.\n\n- Setup virtual CAN (run once)\n\n```\nsudo bash setup_vcan.sh\n```\n\n- Run\n```\ncd build/bin\n./OpenADAS\n```\n\n**Arguments:**\n\n- `--input_source` | default: `simulation` : Input source. 'camera' or 'simulation'.\n- `--input_video_path` | optional : Path to video file for simulation.\n- `--input_data_path`  | optional : Path to data file for simulation.\n- `--on_dev_machine`   | default: `true` : On development machine or not. When this value is set to `false`, OpenADAS will be launched in fullscreen mode without mouse (touch UI). You should this value to `true` in development environment.\n\nSpecify `input_video_path` and `input_data_path` if you want to load a simulation scenario by default. Otherwise, you can select scenarios from simulation selector.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 165,
      "date": "Fri, 24 Dec 2021 07:52:58 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "adas",
      "object-detection",
      "semantic-segmentation",
      "jetson-nano",
      "lane-lines-detection"
    ],
    "technique": "GitHub API"
  }
}
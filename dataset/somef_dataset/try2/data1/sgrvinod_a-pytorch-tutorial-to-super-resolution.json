{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1609.04802"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Super-Resolution",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-10T05:42:10Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T07:15:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9439772299835275,
        0.9742822604241931
      ],
      "excerpt": "Super-resolution (SR) models essentially hallucinate new pixels where previously there were none. In this tutorial, we will try to quadruple the dimensions of an image i.e. increase the number of pixels by 16x! \nWe're going to be implementing Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network. It's not just that the results are very impressive... it's also a great introduction to GANs! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network | a PyTorch Tutorial to Super-Resolution",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sgrvinod/a-pytorch-tutorial-to-super-resolution/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 52,
      "date": "Thu, 23 Dec 2021 04:33:23 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sgrvinod/a-PyTorch-Tutorial-to-Super-Resolution/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "sgrvinod/a-PyTorch-Tutorial-to-Super-Resolution",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8314823419435533
      ],
      "excerpt": "<img src=\"./img/man.png\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sgrvinod/a-PyTorch-Tutorial-to-Super-Resolution/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Sagar Vinodababu\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contents",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "a-PyTorch-Tutorial-to-Super-Resolution",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "sgrvinod",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Super-Resolution/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 249,
      "date": "Thu, 23 Dec 2021 04:33:23 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch-tutorial",
      "pytorch",
      "super-resolution",
      "srgan",
      "generative-adversarial-network",
      "gan",
      "gans"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "I am still writing this tutorial.\n\n<p align=\"center\">\n<img src=\"./img/incomplete.jpg\">\n</p>\n\nIn the meantime, **you could take a look at the code** \u2013 it works!\n\nModel checkpoints are available [here](https://drive.google.com/drive/folders/12OG-KawSFFs6Pah89V4a_Td-VcwMBE5i?usp=sharing).\n\nWhile the authors of the paper trained their models on a 350k-image subset of the ImageNet data, I simply used about 120k COCO images (_train2014_ and _val2014_ folders). They're a lot easier to obtain. If you wish to do the same, you can download them from the links listed in [my other tutorial](https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning#dataset).\n\nHere are the results (with the paper's results in parantheses):\n\n||PSNR|SSIM||PSNR|SSIM||PSNR|SSIM|\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n|**SRResNet**|31.927 (32.05)|0.902 (0.9019)||28.588 (28.49)|0.799 (0.8184)||27.587 (27.58)|0.756 (0.7620)|\n|**SRGAN**|29.719 (29.40)|0.859 (0.8472)||26.509 (26.02)|0.729 (0.7397)||25.531 (25.16)|0.678 (0.6688)|\n||**Set5**|**Set5**||**Set14**|**Set14**||**BSD100**|**BSD100**|\n\nErm, huge grain of salt. The paper emphasizes repeatedly that PSNR and SSIM _aren't really_ an indication of the quality of super-resolved images. The less realistic and overly smooth SRResNet images score better than those from the SRGAN. This is why the authors of the paper conduct an opinion score test, which is obviously beyond our means here.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "The images in the following examples (from [Cyberpunk 2077](https://www.cyberpunk.net/in/en/)) are quite large. If you are viewing this page on a 1080p screen, you would need to **click on the image to view it at its actual size** to be able to effectively see the 4x super-resolution.\n\n\n<p align=\"center\">\n  <i>Click on image to view at full size.</i>\n</p>\n\n![](./img/cyberpunk1.png)\n\n---\n\n<p align=\"center\">\n  <i>Click on image to view at full size.</i>\n</p>\n\n![](./img/cyberpunk7.png)\n\n---\n\n<p align=\"center\">\n  <i>Click on image to view at full size.</i>\n</p>\n\n![](./img/cyberpunk6.png)\n\n---\n\n<p align=\"center\">\n  <i>Click on image to view at full size.</i>\n</p>\n\n<p align=\"center\">\n<img src=\"./img/cyberpunk4.png\">\n</p>\n\n---\n\n<p align=\"center\">\n  <i>Click on image to view at full size.</i>\n</p>\n\n<p align=\"center\">\n<img src=\"./img/cyberpunk9.png\">\n</p>\n\n---\n\n<p align=\"center\">\n  <i>Click on image to view at full size.</i>\n</p>\n\n![](./img/cyberpunk8.png)\n\n---\n",
      "technique": "Header extraction"
    }
  ]
}
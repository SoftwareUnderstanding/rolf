{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1603.06937"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@inproceedings{li2020deformation,\n  title={Deformation-aware Unpaired Image Translation for Pose Estimation on Laboratory Animals},\n  author={Li, Siyuan and G\\\"unel, Semih and Ostrek, Mirela and Ramdya, Pavan and Fua, Pascal and Rhodin, Helge},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={13158--13168},\n  year={2020}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{li2020deformation,\n  title={Deformation-aware Unpaired Image Translation for Pose Estimation on Laboratory Animals},\n  author={Li, Siyuan and G\\\"unel, Semih and Ostrek, Mirela and Ramdya, Pavan and Fua, Pascal and Rhodin, Helge},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={13158--13168},\n  year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9802436690516569
      ],
      "excerpt": "Siyuan Li, Semih G\u00fcnel, Mirela Ostrek, Pavan Ramdya, Pascal Fua, Helge Rhodin. In CVPR 2020. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/siyliepfl/deformation-aware-unpaired-image-translation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-18T20:00:46Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-26T13:35:56Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8466296707279766,
        0.9605393959164472
      ],
      "excerpt": "We propose a method to transfer synthetic images and their keypoint annotations to realistically looking images using \nonly unpaired examples of the two domains. Our method enables training of a pose detector that can be applied to real \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9842730782514749
      ],
      "excerpt": "The main part of our model is to transfer the images and annotations across domains.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8193210308746416
      ],
      "excerpt": "* ANIMALS: the name of your dataset and model. For instance, fly, worm or fish. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8170527600581721,
        0.8170527600581721
      ],
      "excerpt": "* maskA : mask of foreground object in trainA \n* maskB : mask of foreground object in trainB \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This repo contains code for CVPR2020 paper: Deformation-aware Unpaired Image Translation for Pose Estimation on Laboratory Animals",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/siyliepfl/deformation-aware-unpaired-image-translation/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 23 Dec 2021 23:26:01 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/siyliepfl/deformation-aware-unpaired-image-translation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "siyliepfl/deformation-aware-unpaired-image-translation",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npython -m visdom.server\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "You can download animal datasets from [here](https://drive.google.com/drive/folders/16A0aPG7takJRat5866sojS1s548gTdmN?usp=sharing).\nNote that for real images we can only provide drosophila dataset for now. For C. elegans and Zebra fish, we don't own the data. If you need those data, you can find the sources from our paper.\n\nPut the download models in folder\n```\n./dataset\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Clone this repo:\n```\ngit clone https://github.com/siyliepfl/deformation-aware-unpaired-image-translation.git\n```\nInstall dependencies:\n```\npip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8109808573003489
      ],
      "excerpt": "You can also train it by running: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8242394294399712
      ],
      "excerpt": "You can also train our model on your custom dataset. You need to prepare 4 folders:  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8696247773237322,
        0.8170139850689345
      ],
      "excerpt": "<img src=\"./imgs/teaser.gif\" width=\"700\"> \n<img src=\"./imgs/human.png\" width=\"700\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8950684039448203
      ],
      "excerpt": "Download pretrained models here and put the download models in following folder \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8551284438891735
      ],
      "excerpt": "python test.py --dataroot ./dataset/unpaired_dataset/fly/ --name fly --model deform_transfer --gpu_ids 0 --dataset_mode unpaired --num_test 100 --transfer_anno --render_pose --which_animal fly \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9670309135065599
      ],
      "excerpt": "python test.py --dataroot ./dataset/unpaired_dataset/worm/ --name worm --model deform_transfer --gpu_ids 0 --dataset_mode unpaired --num_test 100 --transfer_anno --render_pose --which_animal worm --input_nc 1 --output_nc 1 --source_anno_dir ./dataset/unpaired_dataset/worm/syn_anno.pth \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8898503839362603
      ],
      "excerpt": "python test.py --dataroot ./dataset/unpaired_dataset/fish/ --name fish --model deform_transfer --gpu_ids 0 --dataset_mode unpaired --num_test 100 --transfer_anno --render_pose --which_animal fish --input_nc 1 --output_nc 1 --source_anno_dir ./dataset/unpaired_dataset/fish/syn_anno.pth  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8696247773237322
      ],
      "excerpt": "<img src=\"./imgs/pose_estimation.gif\" width=\"500\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8036933722978647
      ],
      "excerpt": "python test.py --dataroot ./dataset/test/fly/  --name fly --model pose --gpu_ids 0 --input_nc 1 --output_nc 30 --netG pose --dataset_mode pose --target_anno_dir ./dataset/test/fly/test_anno.pth --pose_img_dir ./dataset/test/fly/imgs/  --render_pose --which_animal fly --pose_mode --evaluate --transfer_anno \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8935134882702829
      ],
      "excerpt": "python test.py --dataroot ./dataset/test/worm/  --name worm --model pose --gpu_ids 0 --input_nc 1 --output_nc 7 --netG pose --dataset_mode pose --target_anno_dir ./dataset/test/worm/test_anno.pth --pose_img_dir ./dataset/test/worm/imgs/  --render_pose --which_animal worm --pose_mode --evaluate --transfer_anno \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8459058592022525
      ],
      "excerpt": "python test.py --dataroot ./dataset/test/fish/  --name fish --model pose --gpu_ids 0 --input_nc 1 --output_nc 3 --netG pose --dataset_mode pose --target_anno_dir ./dataset/test/fish/test_anno.pth --pose_img_dir ./dataset/test/fish/imgs/  --render_pose --which_animal fish --pose_mode --evaluate --transfer_anno \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9553788672930474
      ],
      "excerpt": "python train.py --dataroot ./dataset/unpaired_dataset/ANIMALS/ --name ANIMALS_init --model deform_transfer  --lr 2e-5 --niter 100 --niter_decay 100  --save_epoch_freq 200 --save_latest_freq 1000 --lambda_TV 1 --lambda_S 0 --lambda_affine 1e7 --lambda_bias 1e6  --dataset_mode unpaired --init_mode \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8708418164972118
      ],
      "excerpt": "python ./train.py --dataroot ./dataset/unpaired_dataset/fly/ --name fly --init_dir ./saved_models/fly_init/ --model deform_transfer  --lr 2e-5 --niter 50 --niter_decay 0 --gpu_ids 0 --batch_size 4 --save_epoch_freq 2 --lambda_I 1e-5  --lambda_identity 1 --lambda_TV 1e-3 --lambda_S 1 --lambda_affine 1 --lambda_bias 1e-2  --dataset_mode unpaired --lr_GS 2e-5 --lr_DS 2e-6 --lr_GI 2e-3 --lr_DI 2e-3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8926671700564499
      ],
      "excerpt": "python train.py --dataroot ./dataset/unpaired_dataset/worm/ --name worm --init_dir ./saved_models/worm_init/ --model deform_transfer  --lr 2e-5 --niter 70 --niter_decay 0 --gpu_ids 0 --batch_size 4 --save_epoch_freq 2 --lambda_I 1e-5  --lambda_identity 1 --lambda_TV 1e-3 --lambda_S 1 --lambda_affine 1 --lambda_bias 1e-2  --dataset_mode unpaired --lr_GS 2e-5 --lr_DS 2e-6 --lr_GI 2e-4 --lr_DI 2e-4 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8820580821173587
      ],
      "excerpt": "python ./train.py --dataroot ./dataset/unpaired_dataset/fish/ --name fish --init_dir ./saved_models/fish_init/ --model deform_transfer  --lr 2e-5 --niter 100 --niter_decay 0 --gpu_ids 0 --batch_size 4 --save_epoch_freq 2 --lambda_I 1e-4  --lambda_identity 1 --lambda_TV 1e-3 --lambda_S 1 --lambda_affine 1e-2 --lambda_bias 1e-3  --dataset_mode unpaired --lr_GS 2e-5 --lr_DS 2e-7 --lr_GI 2e-4 --lr_DI 2e-4 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8531735069929604
      ],
      "excerpt": "python train.py --dataroot ./dataset/unpaired_dataset/fly/ --name fly_pose --model pose --lr 0.0002 --niter 100 --niter_decay 100 --gpu_ids 0 --batch_size 12 --input_nc 1 --output_nc 30 --netG pose --dataset_mode pose --rot 30 --target_anno_dir ./results/fly/test_latest_latest/target_anno.pth  --pose_mode \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8871715970809405
      ],
      "excerpt": "python train.py --dataroot ./dataset/unpaired_dataset/worm/ --name worm_pose --model pose --lr 0.0002 --niter 100 --niter_decay 100 --gpu_ids 0 --batch_size 12 --input_nc 1 --output_nc 7 --netG pose --dataset_mode pose --rot 0 --target_anno_dir ./results/worm/test_latest_latest/target_anno.pth --pose_img_dir ./results/worm/test_latest_latest/images --pose_mode \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665532046064356
      ],
      "excerpt": "python train.py --dataroot ./dataset/unpaired_dataset/fish/ --name fish_pose --model pose --lr 0.0002 --niter 100 --niter_decay 100 --gpu_ids 0 --batch_size 12 --input_nc 1 --output_nc 3 --netG pose --dataset_mode pose --rot 0 --target_anno_dir ./results/fish/test_latest_latest/target_anno.pth --pose_img_dir ./results/fish/test_latest_latest/images --pose_mode \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8384781514692213,
        0.8068068636029423
      ],
      "excerpt": "And one annotation file for keypoints: syn_anno.pth \nThe keypoints annotation should be saved in a python dictionary and the key is the name of each image in trainA and the value is a 2D numpy array ([[x,y],[x,y]...]). The coordinates should be mapped to [0, 1]. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/siyliepfl/deformation-aware-unpaired-image-translation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 siyliepfl\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Deformation-aware Unpaired Image Translation for Pose Estimation on Laboratory Animals",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "deformation-aware-unpaired-image-translation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "siyliepfl",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/siyliepfl/deformation-aware-unpaired-image-translation/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Clone this repo:\n```\ngit clone https://github.com/siyliepfl/deformation-aware-unpaired-image-translation.git\n```\nInstall dependencies:\n```\npip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can download the pretrained model and test as following. If you want to train the model by yourself, please follow the steps in next sections.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Thu, 23 Dec 2021 23:26:01 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "These instructions will get you a copy of the project up and running on your local machine.\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1511.02680, 2015.\n\nhttp://arxiv.org/abs/1511.00561\nVijay Badrinarayanan, Alex Kendall and Roberto Cipolla \"SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation.\" PAMI, 2017. \n\n## License\n\nThis software is released under a creative commons license which allows for personal and research use only. For a commercial license please contact the authors. You can view a license summary here:\nhttp://creativecommons.org/licenses/by-nc/4.0/\n\n\n## Contact\n\nAlex Kendall\n\nagk34@cam.ac.uk\n\nCambridge University\n"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9800277544866333
      ],
      "excerpt": "Alex Kendall, Vijay Badrinarayanan and Roberto Cipolla \"Bayesian SegNet: Model Uncertainty in Deep Convolutional Encoder-Decoder Architectures for Scene Understanding.\" arXiv preprint arXiv:1511.02680, 2015. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mrmtn86/python1",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Alex Kendall\n\nagk34@cam.ac.uk\n\nCambridge University\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-24T16:30:43Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-04-01T18:31:07Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8446436607261736
      ],
      "excerpt": "For more information about the SegNet architecture: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "denemeler oolcak gibi",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mrmtn86/python1/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 15:12:02 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mrmtn86/python1/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "mrmtn86/python1",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/mrmtn86/python1/master/docker/gpu/Dockerfile",
      "https://raw.githubusercontent.com/mrmtn86/python1/master/docker/cpu/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/mrmtn86/python1/master/train_test.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8150053624611836,
        0.8213850580352281
      ],
      "excerpt": "SegNet requires a modified version of Caffe to run. Please download and compile caffe-segnet to use these models: \nThis version supports cudnn v2 acceleration. @TimoSaemann has a branch supporting a more recent version of Caffe (Dec 2016) with cudnn v5.1: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mrmtn86/python1/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C++",
      "Jupyter Notebook",
      "MATLAB",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SegNet and Bayesian SegNet Tutorial",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "python1",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "mrmtn86",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mrmtn86/python1/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 15:12:02 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This repository contains all the files for you to complete the 'Getting Started with SegNet' and the 'Bayesian SegNet' tutorials here:\nhttp://mi.eng.cam.ac.uk/projects/segnet/tutorial.html\n\nPlease see this link for detailed instructions.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "If you would just like to try out an example model, then you can find the model used in the [SegNet webdemo](http://mi.eng.cam.ac.uk/projects/segnet/) in the folder ```Example_Models/```. You will need to download the weights separately using the link in the [SegNet Model Zoo](https://github.com/alexgkendall/SegNet-Tutorial/blob/master/Example_Models/segnet_model_zoo.md).\n\nFirst open ```Scripts/webcam_demo.py``` and edit line 14 to match the path to your installation of SegNet. You will also need a webcam, or alternatively edit line 39 to input a video file instead. To run the demo use the command:\n\n```python Scripts/webcam_demo.py --model Example_Models/segnet_model_driving_webdemo.prototxt --weights /Example_Models/segnet_weights_driving_webdemo.caffemodel --colours /Scripts/camvid12.png```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Use docker to compile caffe and run the examples. In order to run caffe on the gpu using docker, please install nvidia-docker (see https://github.com/NVIDIA/nvidia-docker or using ansbile: https://galaxy.ansible.com/ryanolson/nvidia-docker/)\n\nto run caffe on the CPU:\n```\ndocker build -t bvlc/caffe:cpu ./cpu \n#: check if working\ndocker run -ti bvlc/caffe:cpu caffe --version\n#: get a bash in container to run examples\ndocker run -ti --volume=$(pwd):/SegNet -u $(id -u):$(id -g) bvlc/caffe:cpu bash\n```\n\nto run caffe on the GPU:\n```\ndocker build -t bvlc/caffe:gpu ./gpu\n#: check if working\ndocker run -ti bvlc/caffe:gpu caffe device_query -gpu 0\n#: get a bash in container to run examples\ndocker run -ti --volume=$(pwd):/SegNet -u $(id -u):$(id -g) bvlc/caffe:gpu bash\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "A number of example models for indoor and outdoor road scene understanding can be found in the [SegNet Model Zoo](https://github.com/alexgkendall/SegNet-Tutorial/blob/master/Example_Models/segnet_model_zoo.md).\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1908.07919\n[simdr]: http://arxiv.org/abs/2107.03332\n[psa]: https://arxiv.org/abs/2107.00782\n[rlepose]: https://arxiv.org/abs/2107.11291\n\n[hrnetw32]: https://drive.google.com/file/d/1YlPrQMZdNTMWIX3QJ5iKixN3qd0NCKFO/view?usp=sharing\n[hrnetw48]: https://drive.google.com/file/d/1hug4ptbf9Y125h9ZH72x4asY2lHt7NA6/view?usp=sharing\n\n[phrnetw32]: https://drive.google.com/file/d/1os6T42ri4zsVPXwceli3J3KtksIaaGgu/view?usp=sharing\n[phrnetw48]: https://drive.google.com/file/d/1MbEjiXkV83Pm3G2o_Rni4j9CT_jRDSAQ/view?usp=sharing\n[simdrw32]: https://drive.google.com/file/d/1Bd8h2H30tCN8WuLIhuSRF9ViN6zghj29/view?usp=sharing\n[simdrw48]: https://drive.google.com/file/d/1WU_9e0MxgrO8X4W6wKo16L8siCdwgLSZ/view?usp=sharing\n[sasimdrw48]: https://drive.google.com/file/d/1Tj9bGL7g7XRyL2F1a-uAcWhgYXnXpqBY/view?usp=sharing\n\n<details open>\n  <summary><strong>COCO-val with 56.4 Detector AP</strong></summary>\n\nModel | Backbone | Image Size | AP | AP<sup>50 | AP<sup>75 | Params <br><sup>(M",
      "https://arxiv.org/abs/2107.00782\n[rlepose]: https://arxiv.org/abs/2107.11291\n\n[hrnetw32]: https://drive.google.com/file/d/1YlPrQMZdNTMWIX3QJ5iKixN3qd0NCKFO/view?usp=sharing\n[hrnetw48]: https://drive.google.com/file/d/1hug4ptbf9Y125h9ZH72x4asY2lHt7NA6/view?usp=sharing\n\n[phrnetw32]: https://drive.google.com/file/d/1os6T42ri4zsVPXwceli3J3KtksIaaGgu/view?usp=sharing\n[phrnetw48]: https://drive.google.com/file/d/1MbEjiXkV83Pm3G2o_Rni4j9CT_jRDSAQ/view?usp=sharing\n[simdrw32]: https://drive.google.com/file/d/1Bd8h2H30tCN8WuLIhuSRF9ViN6zghj29/view?usp=sharing\n[simdrw48]: https://drive.google.com/file/d/1WU_9e0MxgrO8X4W6wKo16L8siCdwgLSZ/view?usp=sharing\n[sasimdrw48]: https://drive.google.com/file/d/1Tj9bGL7g7XRyL2F1a-uAcWhgYXnXpqBY/view?usp=sharing\n\n<details open>\n  <summary><strong>COCO-val with 56.4 Detector AP</strong></summary>\n\nModel | Backbone | Image Size | AP | AP<sup>50 | AP<sup>75 | Params <br><sup>(M",
      "https://arxiv.org/abs/2107.11291\n\n[hrnetw32]: https://drive.google.com/file/d/1YlPrQMZdNTMWIX3QJ5iKixN3qd0NCKFO/view?usp=sharing\n[hrnetw48]: https://drive.google.com/file/d/1hug4ptbf9Y125h9ZH72x4asY2lHt7NA6/view?usp=sharing\n\n[phrnetw32]: https://drive.google.com/file/d/1os6T42ri4zsVPXwceli3J3KtksIaaGgu/view?usp=sharing\n[phrnetw48]: https://drive.google.com/file/d/1MbEjiXkV83Pm3G2o_Rni4j9CT_jRDSAQ/view?usp=sharing\n[simdrw32]: https://drive.google.com/file/d/1Bd8h2H30tCN8WuLIhuSRF9ViN6zghj29/view?usp=sharing\n[simdrw48]: https://drive.google.com/file/d/1WU_9e0MxgrO8X4W6wKo16L8siCdwgLSZ/view?usp=sharing\n[sasimdrw48]: https://drive.google.com/file/d/1Tj9bGL7g7XRyL2F1a-uAcWhgYXnXpqBY/view?usp=sharing\n\n<details open>\n  <summary><strong>COCO-val with 56.4 Detector AP</strong></summary>\n\nModel | Backbone | Image Size | AP | AP<sup>50 | AP<sup>75 | Params <br><sup>(M"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@article{WangSCJDZLMTWLX19,\n  title={Deep High-Resolution Representation Learning for Visual Recognition},\n  author={Jingdong Wang and Ke Sun and Tianheng Cheng and \n          Borui Jiang and Chaorui Deng and Yang Zhao and Dong Liu and Yadong Mu and \n          Mingkui Tan and Xinggang Wang and Wenyu Liu and Bin Xiao},\n  journal   = {TPAMI}\n  year={2019}\n}\n\n@misc{li20212d,\n  title={Is 2D Heatmap Representation Even Necessary for Human Pose Estimation?}, \n  author={Yanjie Li and Sen Yang and Shoukui Zhang and Zhicheng Wang and Wankou Yang and Shu-Tao Xia and Erjin Zhou},\n  year={2021},\n  eprint={2107.03332},\n  archivePrefix={arXiv},\n  primaryClass={cs.CV}\n}\n\n```",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "* https://github.com/leoxiaobin/deep-high-resolution-net.pytorch\n* https://github.com/ultralytics/yolov5\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{li20212d,\n  title={Is 2D Heatmap Representation Even Necessary for Human Pose Estimation?}, \n  author={Yanjie Li and Sen Yang and Shoukui Zhang and Zhicheng Wang and Wankou Yang and Shu-Tao Xia and Erjin Zhou},\n  year={2021},\n  eprint={2107.03332},\n  archivePrefix={arXiv},\n  primaryClass={cs.CV}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{WangSCJDZLMTWLX19,\n  title={Deep High-Resolution Representation Learning for Visual Recognition},\n  author={Jingdong Wang and Ke Sun and Tianheng Cheng and \n          Borui Jiang and Chaorui Deng and Yang Zhao and Dong Liu and Yadong Mu and \n          Mingkui Tan and Xinggang Wang and Wenyu Liu and Bin Xiao},\n  journal   = {TPAMI}\n  year={2019}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sithu31296/pose-estimation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-27T06:03:44Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-27T14:15:36Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Pose estimation find the keypoints belong to the people in the image. There are two methods exist for pose estimation.\n\n* **Bottom-Up** first finds the keypoints and associates them into different people in the image. (Generally faster and lower accuracy)\n* **Top-Down** first detect people in the image and estimate the keypoints. (Generally computationally intensive but better accuracy)\n\nThis repo will only include top-down pose estimation models.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8839116615100168
      ],
      "excerpt": "Note: FPS is tested on a GTX1660ti with one person per frame including pre-processing, model inference and post-processing. Both detection and pose models are in PyTorch FP32. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8002173297097015
      ],
      "excerpt": "To test with a webcam, set to 0. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Easy to use SOTA Top-Down Multi-person Pose Estimation Models in PyTorch",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sithu31296/pose-estimation/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 27 Dec 2021 23:07:17 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sithu31296/pose-estimation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "sithu31296/pose-estimation",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8029621750362915
      ],
      "excerpt": "  <summary><strong>COCO-test with 60.9 Detector AP</strong> (click to expand)</summary> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8096422022825122,
        0.8096422022825122
      ],
      "excerpt": "HRNet-w32 | [download][hrnetw32] \nHRNet-w48 | [download][hrnetw48] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8155271735909926
      ],
      "excerpt": "Download a YOLOv5m trained on CrowdHuman dataset from here. (The weights are from deepakcrk/yolov5-crowdhuman.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9652472391227556
      ],
      "excerpt": "Run the following command. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8081755319473457
      ],
      "excerpt": "Model | Backbone | Image Size | AP | AP<sup>50 | AP<sup>75 | Params <br><sup>(M) | FLOPs <br><sup>(B) | FPS | Weights \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8429817107935659,
        0.8473700408921951,
        0.8340163939396521,
        0.8407220786147631
      ],
      "excerpt": "[PoseHRNet][hrnet] | HRNet-w32 | 256x192 | 74.4 | 90.5 | 81.9 | 29 | 7 | 25 | [download][phrnetw32] \n| | HRNet-w48 | 256x192 | 75.1 | 90.6 | 82.2 | 64 | 15 | 24 | [download][phrnetw48] \n[SimDR][simdr] | HRNet-w32 | 256x192 | 75.3 | - | - | 31 | 7 | 25 | [download][simdrw32] \n| | HRNet-w48 | 256x192 | 75.9 | 90.4 | 82.7 | 66 | 15 | 24 | [download][simdrw48] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8103139412005752
      ],
      "excerpt": "[SimDR*][simdr] | HRNet-w48 | 256x192 | 75.4 | 92.4 | 82.7 | 66 | 15 | [download][sasimdrw48] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.810870454768102,
        0.810870454768102
      ],
      "excerpt": "HRNet-w32 | [download][hrnetw32] \nHRNet-w48 | [download][hrnetw48] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8113950689689594
      ],
      "excerpt": "$ python infer.py --source TEST_SOURCE --det-model DET_MODEL_PATH --pose-model POSE_MODEL_PATH --img-size 640 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9034655003202487,
        0.9350130629836972
      ],
      "excerpt": "To test an image, set to image file path. (For example, assests/test.jpg) \nTo test a folder containing images, set to folder name. (For example, assests/) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.802628170774571
      ],
      "excerpt": "det-model: YOLOv5 model's weights path \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sithu31296/pose-estimation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 sithu3\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Top-Down Multi-person Pose Estimation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pose-estimation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "sithu31296",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sithu31296/pose-estimation/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "sithu31296",
        "body": "Improve keypoint decoding and SimDR speed increase",
        "dateCreated": "2021-09-18T18:38:23Z",
        "datePublished": "2021-09-18T18:46:00Z",
        "html_url": "https://github.com/sithu31296/pose-estimation/releases/tag/v0.2.0",
        "name": "v0.2.0",
        "tag_name": "v0.2.0",
        "tarball_url": "https://api.github.com/repos/sithu31296/pose-estimation/tarball/v0.2.0",
        "url": "https://api.github.com/repos/sithu31296/pose-estimation/releases/49799547",
        "zipball_url": "https://api.github.com/repos/sithu31296/pose-estimation/zipball/v0.2.0"
      },
      {
        "authorType": "User",
        "author_name": "sithu31296",
        "body": "Add SimDR models",
        "dateCreated": "2021-09-14T15:34:23Z",
        "datePublished": "2021-09-14T15:36:35Z",
        "html_url": "https://github.com/sithu31296/pose-estimation/releases/tag/v0.1.5",
        "name": "v0.1.5",
        "tag_name": "v0.1.5",
        "tarball_url": "https://api.github.com/repos/sithu31296/pose-estimation/tarball/v0.1.5",
        "url": "https://api.github.com/repos/sithu31296/pose-estimation/releases/49539735",
        "zipball_url": "https://api.github.com/repos/sithu31296/pose-estimation/zipball/v0.1.5"
      },
      {
        "authorType": "User",
        "author_name": "sithu31296",
        "body": "HRNet and inference",
        "dateCreated": "2021-09-14T07:22:49Z",
        "datePublished": "2021-09-14T07:25:07Z",
        "html_url": "https://github.com/sithu31296/pose-estimation/releases/tag/v0.1.0",
        "name": "v0.1.0",
        "tag_name": "v0.1.0",
        "tarball_url": "https://api.github.com/repos/sithu31296/pose-estimation/tarball/v0.1.0",
        "url": "https://api.github.com/repos/sithu31296/pose-estimation/releases/49506038",
        "zipball_url": "https://api.github.com/repos/sithu31296/pose-estimation/zipball/v0.1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* torch >= 1.8.1\n* torchvision >= 0.9.1\n\nOther requirements can be installed with `pip install -r requirements.txt`.\n\nClone the repository recursively:\n\n```bash\n$ git clone --recursive https://github.com/sithu31296/pose-estimation.git\n```\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 20,
      "date": "Mon, 27 Dec 2021 23:07:17 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pose-estimation",
      "human-pose-estimation",
      "deep-learning",
      "computer-vision",
      "hrnet"
    ],
    "technique": "GitHub API"
  }
}
{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kushagra06/DDPG",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-08-30T06:17:18Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-11-25T11:19:48Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9019933843718482
      ],
      "excerpt": "TensorFlow/PyTorch implementation of Deep Deterministic Policy Gradient (https://arxiv.org/pdf/1509.02971.pdf)(deep reinforcement learning algorithm) on OpenAI gym's inverted pendulum environment. The goal is to swing the pendulum up so it stays upright. (https://gym.openai.com/envs/Pendulum-v0/) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9547205075335577,
        0.9277738374433832
      ],
      "excerpt": "Some utility functions to get parameters of the gym environment used, e.g. number of states and actions. \nsrc/model.py: Deep learning network for the agent.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9539674350297469,
        0.861402859632461,
        0.8776327251933534
      ],
      "excerpt": "pendulum.py: Implementation of the algorithm for training and testing on the  \ntask of inverted pendulum (default).  \nparam_search.py: Code to randomly search for the best parameters for OU process. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Deep Deterministic Policy Gradient (Deep RL algorithm)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kushagra06/DDPG/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 14:28:20 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kushagra06/DDPG/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "kushagra06/DDPG",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/kushagra06/DDPG/master/pendulum.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.9664150841647992
      ],
      "excerpt": "src/gym_utils.py:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8954476805673591,
        0.8000085820044692
      ],
      "excerpt": "src/replay_buffer.py: A replay buffer to store state-action transitions and then randomly sample from it. \nsrc/stochastic_process.py: Function simulating Ornstein Ohlenbeck (OU) process, added as noise to the selected action.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8209695944201478
      ],
      "excerpt": "scatter.py Code to plot the final results while changing the parameters for OU process. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kushagra06/DDPG/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Deep Deterministic Policy Gradient",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DDPG",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "kushagra06",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kushagra06/DDPG/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To run the code, you need to have installed the following libraries/softwares on your system (preferably Ubuntu or any linux distro):\n* python: Required version >= 3.5. Also, install pip using `sudo apt install python3-pip`. (if your package manager is apt)\n* TensorFlow: Recommeded to install via pip. https://www.tensorflow.org/install/pip\n* PyTorch: Recommended to install via pip. https://pytorch.org/\n* numpy: `pip install numpy`\n* jupyter: `pip install jupyter`\n* matplotlib: `pip install matplotlib`\n* seaborn: `pip install seaborn`\n* IPython: `sudo apt install python3-ipython`\n* tqdm: `pip install tqdm` \n* OpenAI gym: https://gym.openai.com/docs/\n\nIt is recommended to run the code in a virtualenv.\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Install the required softwares and clone this repo. To test the code or perform experiments run a new jupyter session using\n```\njupyter notebook\n```\non terminal which launches the jupyter notebook app in a browser. In the notebook dashboard, navigate to find the notebook named `pendulum` and run it.\nTo train/test the model, execute \n```\npython pendulum.py\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 14:28:20 GMT"
    },
    "technique": "GitHub API"
  }
}
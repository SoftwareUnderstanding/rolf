{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2004.05718](https://arxiv.org/abs/2004.05718",
      "https://arxiv.org/abs/2004.05718"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "@inproceedings{NEURIPS2020_a32d7eea,\n author = {Vignac, Cl\\'{e}ment and Loukas, Andreas and Frossard, Pascal},\n booktitle = {Advances in Neural Information Processing Systems},\n editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},\n pages = {14143--14155},\n publisher = {Curran Associates, Inc.},\n title = {Building powerful and equivariant graph neural networks with structural message-passing},\n url = {https://proceedings.neurips.cc/paper/2020/file/a32d7eeaae19821fd9ce317f3ce952a7-Paper.pdf},\n volume = {33},\n year = {2020}\n}\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{NEURIPS2020_a32d7eea,\n author = {Vignac, Cl\\'{e}ment and Loukas, Andreas and Frossard, Pascal},\n booktitle = {Advances in Neural Information Processing Systems},\n editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},\n pages = {14143--14155},\n publisher = {Curran Associates, Inc.},\n title = {Building powerful and equivariant graph neural networks with structural message-passing},\n url = {https://proceedings.neurips.cc/paper/2020/file/a32d7eeaae19821fd9ce317f3ce952a7-Paper.pdf},\n volume = {33},\n year = {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8490817347094297
      ],
      "excerpt": "Cl\u00e9ment Vignac, Andreas Loukas and Pascal Frossard. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944550559552731,
        0.8998593429438314
      ],
      "excerpt": "  - The multi-task regression of graph properties presented in https://arxiv.org/abs/2004.05718 \n  - Constrained solubility regression on ZINC \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cvignac/SMP",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-24T12:21:43Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-14T18:46:39Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9493299701750327
      ],
      "excerpt": "This paper contains code for the paper Building powerful and equivariant graph neural networks with structural message-passing (Neurips 2020) by \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9433201931350604
      ],
      "excerpt": "Link to the paper \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8768785515930476,
        0.918583727155617,
        0.8135526519132866,
        0.8980757783018011,
        0.8128040577469373
      ],
      "excerpt": "Message-passing has proved to be an effective way to design graph neural networks, \nas it is able to leverage both permutation equivariance and an inductive bias towards \nlearning local structures in order to achieve good generalization. However, current \nmessage-passing architectures have a limited representation power and fail to learn \nbasic topological properties of graphs. We address this problem and propose a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.966841874064656,
        0.8741270595623006
      ],
      "excerpt": "we propagate a one-hot encoding of the nodes, in addition to the features, in order \nto learn a local context matrix around each node. This matrix contains rich local \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9633074258027728
      ],
      "excerpt": "node representations. Second, we propose methods for the parametrization of the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9791508259317291,
        0.8652431463597157,
        0.8667033386580746,
        0.9796771661283494
      ],
      "excerpt": "representation that is independent of the specific choice of the one-hot encoding \npermits inductive reasoning and leads to better generalization properties. Experi- \nmentally, our model can predict various graph topological properties on synthetic \ndata more accurately than previous methods and achieves state-of-the-art results on \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8212200604073884
      ],
      "excerpt": "This folder contains the source code used for Structural Message passing for three tasks: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8436294547918824
      ],
      "excerpt": "We use the pytorch-geometric downloader, there should be nothing to to by hand. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9387725192360066
      ],
      "excerpt": "The model used for each task is located in the model folder (model_cycles, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8078364196416116
      ],
      "excerpt": "They all use some of the SMP layers parametrized in the smp_layers file.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9501789319175714,
        0.9680361125541909,
        0.9054312026942869
      ],
      "excerpt": "to tensors of another order using a predefined set of equivariant transformations. \nIn order to train SMP, specify the cycle length, the size of the graphs that is used, and potentially the proportion of the training data \nthat is kept. For example, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8462662238844535
      ],
      "excerpt": "will train the 4-cycle on graph with on average 12 nodes on 1.0 * 100 = 100% of the training data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9239753849503217
      ],
      "excerpt": "For MPNN and GIN, transforms can be specified in order to add a one-hot encoding of the node degrees, \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cvignac/SMP/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Mon, 27 Dec 2021 09:56:35 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/cvignac/SMP/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "cvignac/SMP",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8165321618308552
      ],
      "excerpt": "Source code for the second task is adapted from https://github.com/lukecavabarrett/pna. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "python -m datasets_generation.multitask_dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8854297101284528
      ],
      "excerpt": " or one-hot identifiers. The available options can be seen by using \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "python3 datasets_generation/build_cycles.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8049470137000115,
        0.833465294565941,
        0.8356222314306038
      ],
      "excerpt": "Each task is launched by running the corresponding main file (cycles_main, zinc_main, multi_task_main). \nThe model parameters can be changed in the associated config.yaml file, while training parameters are modified \nwith command line arguments.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8256397413339659
      ],
      "excerpt": "python3 cycle_main.py --k 4 --n 12 --proportion 1.0 --gpu 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8035291063325766,
        0.8001287499800376
      ],
      "excerpt": "In order to run another model, modify models.config.yaml. To run a MPNN that has the \nsame architecture as SMP, set use_x=True in this file.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8846824354595363
      ],
      "excerpt": "python3 cycles_main.py --help \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8846824354595363
      ],
      "excerpt": "python3 multi_task_main.py --help \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9115556414340709
      ],
      "excerpt": "python3 multi_task_main.py --gpu 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.800811710849104
      ],
      "excerpt": "the beginning of zinc_main.py. Model parameters can be changed in config_zinc.yaml.  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/cvignac/SMP/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Gabriele Corso, Luca Cavalleri\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Building powerful and equivariant graph neural networks with structural message-passing",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SMP",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "cvignac",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cvignac/SMP/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[https://pytorch-geometric.readthedocs.io/en/latest/](Pytorch geometric) v1.6.1 was used. Please follow the instructions on the\nwebsite, as simple installations via pip do not work. In particular, the version of pytorch used must match the one of torch-geometric.\n\nThen install the other dependencies:\n```\npip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 19,
      "date": "Mon, 27 Dec 2021 09:56:35 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This code is currently not available as a library, so you will need to copy-paste files to adapt it to your \nown data. \nWhile most of the code can be reused, you may need to adapt the model to your own problem. We advise you to look at the\ndifferent model files (model_cycles, model_multi_task, model_zinc) to see how they are built. They all follow the same\ndesign:\n  - A local context is first created using the functions in models.utils.misc. If you have node features that\n  you wish to use in SMP, use `map_x_to_u` to include them in the local contexts.\n  - One of the three SMP layers (SMP, FastSMP, SimplifiedFastSMP) is used at each layer to update the local context.\n  Then either some node-level features or some graph-level features are extracted. For this purpose, you can use\n  the `NodeExtractor` and `GraphExtractor` classes in `models.utils.layers.py`.\n  - The extracted features are processed by a standard neural network. You can use a multi-layer perceptron here, or\n  a more complex structure such as a Gated Recurrent Network that will take as input the features extracted at\n  each layer.\n  \nTo sum up, you need to copy the following files to your own folder:\n  - models.smp_layers.py\n  - models.utils.layers.py and models.utils.misc.py\n\nand to adapt the following files to your own problem:\n  - the main file (e.g. zinc_main.py)\n  - the config file (e.g. config_zinc.yaml)\n  - the model file (e.g. models/model_zinc.py)\n  \nWe advise you to use the \"weights and biases\" library as well, as we found it very convenient to store results.\n\n",
      "technique": "Header extraction"
    }
  ]
}
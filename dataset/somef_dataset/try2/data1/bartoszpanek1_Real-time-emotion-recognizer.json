{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "  If you want to run real-time emotion recognition using already built model, just run the camera.py file. To get the best results, your face should be in front of the camera, the source of light should not be behind you.\n  \n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1409.1556\n  \n## Data set\n\nhttps://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data\n\n## Installation\n\nI'm using the package manager [pip](https://pip.pypa.io/en/stable/installing/"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bartoszpanek1/Real-time-emotion-recognizer",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-20T13:32:05Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-21T15:12:48Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.91662259987362,
        0.836759703199892
      ],
      "excerpt": "This is a model trained using FER2013 dataset and later used for real-time emotion recognition. Predicted emotions are visualized using emotes. \nThis model - 62.6% accuracy. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9085413050827033
      ],
      "excerpt": "This model is a VGG13 deep convolutional neural network. It is described in this paper: https://arxiv.org/abs/1409.1556 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This is a model trained on FER2013 dataset and used for real-time emotion recognition.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bartoszpanek1/Real-time-emotion-recognizer/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 05:01:11 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/bartoszpanek1/Real-time-emotion-recognizer/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "bartoszpanek1/Real-time-emotion-recognizer",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "  If you want to test model using FER2013 test set, run the 'test_model' function in model.py file. Note that this functions needs fer2013.csv dataset to proceed.\n\n  \n  \n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "I'm using the package manager [pip](https://pip.pypa.io/en/stable/installing/) to install Pytorch, Pandas and OpenCV.\n\nhttps://pytorch.org/ for pytorch installation\n\n```bash\npip install pandas\npip install opencv-python\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data\n\n",
      "technique": "Header extraction"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/bartoszpanek1/Real-time-emotion-recognizer/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Real-time-emotion-recognizer",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Real-time-emotion-recognizer",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "bartoszpanek1",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bartoszpanek1/Real-time-emotion-recognizer/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 05:01:11 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "  I used pytorch for building, training and evaluating the neural network. OpenCV captures frames from the camera and finds all faces in the image. Only a face which covers biggest area of the screen is picked, resized and fed into previosly trained model.\n  \n  The model does good job in predicting 'happy','angry','neutral','suprised' and 'fear' faces. On the other hand, it does not work very well when it comes to 'sad' and 'disgusted' faces.\n  \n",
      "technique": "Header extraction"
    }
  ]
}
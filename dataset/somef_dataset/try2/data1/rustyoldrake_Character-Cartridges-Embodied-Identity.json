{
  "citation": [
    {
      "confidence": [
        0.9421445313892758
      ],
      "excerpt": " https://eecs.berkeley.edu/turing-colloquium/schedule/blum  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9966489686656222
      ],
      "excerpt": "and https://arxiv.org/pdf/2001.09977.pdf   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490817347094297,
        0.9391244324849896
      ],
      "excerpt": "Isolation often drives inspiration and innovation\u2026 \nIsaac Newton and William Shakespeare, isolated by European plagues, created marvelous works of science and literature.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.971679416046096
      ],
      "excerpt": "\u2022   Consider \u2018observe \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9324341764681972
      ],
      "excerpt": "Key embodiments of intelligence \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8940583111730483
      ],
      "excerpt": "Story and Narrative Generation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8940583111730483
      ],
      "excerpt": "\u2022   Story and Narrative Generation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8422862053358879
      ],
      "excerpt": "\u00b7   Understand context and remember things \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "o   Emotion & Identity \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.831065370266005
      ],
      "excerpt": "o   Sensemaking systems \u201cknow you\u201d \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8324396639683825
      ],
      "excerpt": "Storytelling for Knowledge Transfer (and Character Bootstrapping?) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rustyoldrake/Character-Cartridges-Embodied-Identity",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-10-05T07:24:49Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-28T20:51:35Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "https://dreamtolearn.com/ryan/cognitivewingman/18/en\n\nCharacter Cartridges - Embodied Identity\n\nWe are entering a magical convergence phase in media and technology. The next dozen years through 2030 are going to be very interesting as we begin to understand how to develop character and identity for sensemaking systems, leveraging AI.\n\nMultiple technologies \u2013 including in mobile, AR, and deep learning - are rapidly converging to enable organizations to compose AI-powered systems only dreamt of in Sci-Fi novels and Hollywood movies.  \n\nThese sensemaking (and empathetic) systems will quickly enable assistants who can play roles that include a \u201cCognitive Wingman\u201d \u2013 similar to the automated intelligence seen in media: JARVIS (Iron Man); KITT (Knight Rider); HAL (Space Odyssey); Samantha (Her); TARS (Interstellar).  \n\n \nThese systems will:\n\u00b7 Talk and listen\n\u00b7 Have identity\n\u00b7 Have relationships\n\u00b7 Are situationally aware\n\u00b7 Reason, Understand and Learn\n\u00b7 Understand context and remember things\n\u00b7 Can hold state for multiple \u2018conversation turns\u2019\n\u00b7 Behave in a manner that simulates emotional intelligence\n\n \n\nWith readily available technology - can build alpha versions of these systems today.  Mind you many POC's quite crappy \u2013 but it\u2019s a start - and demonstrates feasibility.  And with widely available ML tools and techniques, and our human tendency to improve on things \u2013 good stuff will happen soon.\n\n \n\nA key component for the creation of Digital Humans (for applications extending well beyond gaming) is a sense of identity and character.   Empathetic systems that embody cognitive elements need personality.   The best rendered face and eyes, is still just a collection of high resolution pixels \u2013 until we add voice, emotion, identity and soul.\n\n ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9015702156898052
      ],
      "excerpt": "POC for Sensemaking Systems with Emotional &amp; Anthropomorphic Traits - and synthetic identity \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9991201349293338
      ],
      "excerpt": "\"The sensibleness of a chatbot is the fraction of responses labeled \u201csensible\u201d, and specificity is the fraction of responses that are marked \u201cspecific\u201d. The average of these two is the SSA score. The results below demonstrate that Meena does much better than existing state-of-the-art chatbots by large margins in terms of SSA scores, and is closing the gap with human performance. \" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9807595509486934
      ],
      "excerpt": "Announcing ML-Agents Unity Package v1.0!ML-Agents is an open-source project that enables games and simulations to serve as environments for training intelligent agents. It includes a C \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865,
        0.8514875026314488,
        0.9791307222313095
      ],
      "excerpt": "Isolation often drives inspiration and innovation\u2026 \nIsaac Newton and William Shakespeare, isolated by European plagues, created marvelous works of science and literature.   \nMary Shelley in the volcanic winter of 1816, took refuge with Lord Byron by Lake Geneva in Switzerland.  She produced the story of Victor Frankenstein, inspired by Prometheus, a Titan who created humanity by blending clay with stolen god-fire. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9866598757845413,
        0.8522158750390424
      ],
      "excerpt": "You are a Martian Astronaut, on a resupply spaceship headed to Mars.  Your 23 crew mates are in a deep sleep for the next 6 months.   Your daily jobs of checking in on the ship and crew health, take just a small portion of your time.  Communications with earth sucks (given the 10-minute delay) and watching movies and playing video games got a stale after 2 months\u2026 so time for a little inspiration and innovation \u2013 Prometheus style!  \nThe ship has a VR training simulator for Martian construction tasks.  But with some tinkering, you\u2019ve figured out how to build a VR lab to compose virtual characters. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9113919506609675
      ],
      "excerpt": "\u2022   D\u00e9cor & Design - As a fan of all things 1980\u2019s \u2013 you\u2019re making your virtual lab with an 80\u2019s vibe.  VHS video tapes, 80\u2019s fonts and colors, and general 80\u2019s feel.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8515809708787168,
        0.8966075625628166,
        0.8873879619877524,
        0.8064259753334045
      ],
      "excerpt": "\u2022   Types of cartridges initially will include simple things like \u201cvalues\u201d and \u201cneeds\u201d and personality facets (like assertiveness) \u2013 but latter will explore compositions \n\u2022   About 50 cartridges will  be available initially -  but option to unlock (from special glass case) hundreds more, as the user  interface evolves.  \n\u2022   Observation Area - for early testing, you want to be able to make a bunch of characters (e.g. 2-12) put them in an area \u2013 see how different characters behave \n\u2022   Stimulus- the observation area needs something for interaction.  Could be a \u2018thing\u2019, animal, virtual TV playing content, science experiment, or something else that would result in differing responses from variety of characters. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.818083103542058,
        0.923128122908597
      ],
      "excerpt": "\u2022   You OBSERVE a couple of lifeless avatars, appear to be dormant or sleeping \n\u2022   You see Character Cartridges (color coded) on a table in front of you \u2013 RED Cartridges for VALUES; Orang for NEEDS and a selection of blue for personality TRAITS/FACETS. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906453870774559,
        0.9916367693352197
      ],
      "excerpt": "\u2022   When you push Pushes Animation Lever, FLASH! light show, transmission of some animation and/or flashing lights AVATAR Comes to life \u2013 eyes open, stand up straight, and activation of orb-of-identity ORB of identity hovers in/near chest and represents - later the Avatar BEHAVIOR will vary depending on combination of Char Chars \n\u2022   You OBSERVE an Orb of identity \u2013 which floats o n /near character - which is a representation of your Character\u2019s identity, personality and traits; You also observe the character stretching , like waking from  a long sleep \u2013 before stepping off the pedestal , and WALKING (moving) to the \u201cROOM OF OBSERVATION\u201d \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9163148600456512,
        0.9631126285649763
      ],
      "excerpt": "\u2022   After creating 1, 2 or a half dozen characters, it\u2019s time to \u201cObserve the Observers\u201d \u2013 see how they interact in an environment. \n\u2022   The room of Observation has less of an 80\u2019s vibe compared to the lab \u2013 at least initially. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8296097008833857,
        0.9339889819986149,
        0.8372752043895155,
        0.9230047664520791,
        0.8343873367437715
      ],
      "excerpt": "\u2022   STIMULUS \u2013 in addition to each other, the room has at least one \u201cthing\u201d that has meaning for the Characters \u2013 and can stimulate changes in (a) Cognitive Emotional State; (b) Physical location in the room.  (the former drives the latter) \n\u2022   Interpersonal \u2013 initially \u2013 the characters don\u2019t really interact with each other, but later on, they might \u2013 like in a sense of Hierarchy.  \n\u2022   EXAMPLE 1 \u2013 Fear / Curiosity \u2013 Room has table at one end \u2013 on the table are three items, a knife, a lit candle (fire), and an box with \u201copen me\u201d on side.  Cautious and incurious characters will stand at the far side of the room (fear trumps curiosity); Curious and assertive, souls will move towards the Table.  (near term , it\u2019s simply a stand where you are most comfortable equation) \n\u2022   EXAMPLE 2 \u2013 Content Affinity \u2013 Room has four corners \u2013 each with artefacts in each one \u2013 (i) Play pen full of dogs/puppies/kittens; (ii) Science gear, tools and lab equipment; (iiii) food on table; and (iv) bamboo and rock (quiet area) \n\u2022   LOCATION OF CHARACTERS \u2013 As we change characters, we see where they go in room \u2013 their inner workings guide their external location \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246249269010299,
        0.8430946673443168,
        0.9003188354470159,
        0.9761966503456352
      ],
      "excerpt": " in this vidoe - a dozen humanoids are platonic representations of data / people - they march out and can be interrogated by voice \nKey embodiments of intelligence \nSo how do we begin to solve for that? \nWell, let\u2019s begin with a brainstorm - by segmenting into three big buckets, things that are knowable about our acronym-heavy friends above.   Most elements of our AI Cognitive Wingmen can tie out to being: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8578274334817181,
        0.8881273225736415,
        0.9529671982784762
      ],
      "excerpt": "DELCARED \u2013 this one is easy.   What\u2019s the name of the \u201cother\u201d?   Is it physical or virtual form?  What\u2019s the unique identifier, if one exists?  What is the stated purpose?  What are the ethical and moral guardrails? \nMEASURED \u2013 measured elements are a little more complicated.  But include components that are perceivable or measurable.   Low battery?   Riding in a car?   Damaged?   Lost?  Perceiving joy or frustration in the environment from humans?  Sensing a command to behave a certain way? \nINFERRED \u2013 if the system has been programmed to convey emotion \u2013 is it happy or sad?  (based on stimulus and interaction);   If the character is learning and evolving, what type of character is it?  Introvert/extrovert?  Confident/submissive?   Rude/polite?  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9102817533936005
      ],
      "excerpt": "I'm not sure if this method of organizing is the best - but it's a place to start. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9822791510366387
      ],
      "excerpt": "I grew up in the late 70\u2019s and early 80\u2019s.  Stranger Things indeed.   At the time, the state of the art for electronic tech (when not playing D&D) was Atart, Intellivision and ColecoVision.  The beauty of Atari and similar systems is once you decided on the game - you could grab the physical game cartridge and slam it into the console.   Then flip on the system.  80% of the time it would fire up - the other 20% you'd need to re-seat the cartridge (jiggle and retry) which usually worked \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.973698280213486,
        0.9760246515985999,
        0.9369141818044382
      ],
      "excerpt": "The CHARACTERS (2) can be thought of as \"Observing Bots\" - the watchers .  No chat, no dialog required. but they do Watch.  have emotional states (3) that are impacted by the Data/Traffic/Chatter/Context of Situation (4) - and differing REACTIONS (8) on how they see the world. different lenses \nOBSERVABLE world - the data - could be call center traffic, twitter streams, a twich channel in esports, unstructured observable data that is sliced along time domain (6) and analyzed (7) using standard and/or custom tools like NLC NLU NLP Tone extraction, and/or ML/DL filters \nINTERPRETER considers information in front from (7) along with Character Type (2) ; Emotional State at a moment in time (3) (e.g. is the Character already upset or angry?; and (4) Context - e.g. is it appropriate to use profanity workplace (no) ; or with friends at pub (perhaps yes); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9423970921676738,
        0.822643709733239,
        0.9484436278705484,
        0.9458543663725598,
        0.9605509985993439,
        0.9815100381527845,
        0.9693233393948762,
        0.8490037945672047,
        0.9563786870710804
      ],
      "excerpt": "Evolution of Storytelling: Augmented Reality, Virtual Reality & First/Shift Person Storytelling is Evolving - Within Media and Entertainment, the number of distribution vectors continues to grow, as do the differing forms of story experiences.   Non-linear choose-your-own-adventure stories on Netflix; Augmented Reality Star Wars Storm-troopers on iPhones, Virtual Reality immersive games and first person and \u201cshift person\u201d stories.   The sector is experiencing a period of punctuated evolution. \nFoundation Artificial Intelligence & Cognitive Computing Cognitive Test Kitchen - Rapid advances in Cognitive Computing and Artificial Intelligence are accelerating innovation in consumer goods, enterprise, and entertainment.  Using the metaphor of a well-equipped \u2018test kitchen\u2019 we discuss how the technology ingredients can be used for exploration and innovation \u2013 developing recipes to move from cupcakes to wedding cakes. \nSkills Building \u2013 Expanding Studio Capabilities through 2050 Skills Building - Agencies and studios wishing to compete in a rapidly evolving \u201cnew-media\u201d space will need to build capabilities and culture to foster evolution.  The type and composition of talent require to deliver non-traditional media in 2050 will differ greatly from present day. Storytellers will need to expand skills, and create connections to technologists, and leverage technology without losing the core artistic and storytelling elements. In this section we explore \u2018what might be\u2019 by examining early adopters \u2013 and lessons learned from successes & failures. \nDigital Humans and Digital Assistants \u2013 An Evolution of Technology & Ideas Widely adopted Conversational Agents such as Amazon\u2019s Alexa, have set the stage for more sophisticated Digital Humans and Digital Assistants. What was once pure science fiction (KITT, HAL, Ash, JARVIS, and TARS) now seem closer than ever. As the space matures to a second generation \u201cCognitive Wingman\u201d \u2013 we explore questions such as: What will they look and sound like? How will they emote and behave?  How much access to personal information should they have?  \nArchitecting Empathetic Systems \u2013 Empathy & Emotional Intelligence We explore the degree to which Identity, Empathy and Emotional Intelligence, can support use cases and enhance a user\u2019s experience.  Signal extraction services such as tone and emotion analyzer, natural language understanding, custom Natural Language Classification models, sentiment analysis, alongside standardized personality model and type mapping, can provide systems to adjust to the emotion of user, and in cases, emulate emotions and emotional responses. \nCharacters and Content \u2013 New World and New Channels Studios and Media Conglomerates own characters worth billions of dollars.  For example, Marvel Cinematic Universe (MCU) purchased by Disney in 2009 for $4b and has grossed more than $11b at the box office. We explore how evolving technology and media vectors are potential opportunities for studios character assets, to unlock potential \u2013 from both user experience and financial aspects.   Is having your own augmented reality \"Jarvis\" as a cognitive wingman an appealing value proposition? if so, how valuable, and why? \nStepping Stones to a Master Composer \n\u2022   Observe the Observing Agents (Watching the Watchers) \n\u2022   Verbal Summary of Character using NLC NLU and clustering to find best approximation of  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9907767604538971
      ],
      "excerpt": "4.  Wingman / Sidekick (mechanical) \u2013 KITT, Jarvis, Hal \u2013 embodied identity, but relationship is clear this is a robot identity with personality (non-human-OK) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.952024180523774,
        0.9908817161159846,
        0.8496308373276642,
        0.992915728398979
      ],
      "excerpt": "KNOWLEDGE /CORPUS (Brains) \u2013 Knowledge.  This is actually the easy part.  Creating a system that can tap public internet knowledge, aggregate, curate and disseminate data, information, knowledge and wisdom (DIKW).     The Avatar needs to know stuff \u2013 so this knowledge needs to be available.            \nVR / VISUAL  / AUDIO (Eyes and Ears) \u2013 Sensory.  In this case I\u2019m assuming a headset worn to deliver AR or VR photons into eyeballs \u2013 but could be a flat screen or an immersive room.  But the avatar needs to be seen and heard (and to also see and hear);   A beautifully rendered AV Piece is essential, but also requires the other ingredients \nDIALOG & CONTEXT (Story & Script) \u2013 Experience.  whether it\u2019s a 10 second interaction to discuss a shopping list, or a multi-decade relationship \u2013 there is a story arc to the relationship.  Dialog.  Scripts,  Flow, are needed.  Done well, they will produce what seems to be emotional intelligence \u2013 and moments of \u201cAha\u201d (serotonin shots) \nAVATAR (Heart and Soul) \u2013 Authenticity.  Relationship.  Empathy.  When the other ingredients are composed - this where the magic happens \u2013 when the eggs, flour and sugar become a wedding cake.   It\u2019s where the user feels there is an \u201cother\u201d being interacted with.  An \u201cI believe\u201d moment sufficient to overcome periodic trespasses and errors of logic. System that can remember, hold state, know context and react with a reasonable level of emotional intelligence. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8075317703844515
      ],
      "excerpt": "\u00b7   Reason, Understand and Learn \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8446511180562112
      ],
      "excerpt": "o   Flavors of people.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8243304761890682
      ],
      "excerpt": "o   Surface more characters (e.g. MCU) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9043346952299157,
        0.8519272421750755
      ],
      "excerpt": "Storytelling for Knowledge Transfer (and Character Bootstrapping?) \nManaging Blue \u2013 what is the subject? what are we thinking about? what is the goal? Can look at the big picture. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9601237393901887
      ],
      "excerpt": "Emotions Red \u2013 intuitive or instinctive gut reactions or statements of emotional feeling (but not any justification). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979519391800447
      ],
      "excerpt": "Optimistic response Yellow \u2013 logic applied to identifying benefits, seeking harmony. Sees brighter side of situations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "POC for Sensemaking Systems with Emotional & Anthropomorphic Traits - and synthetic identity",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rustyoldrake/Character-Cartridges-Embodied-Identity/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Fri, 24 Dec 2021 23:29:29 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/rustyoldrake/Character-Cartridges-Embodied-Identity/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "rustyoldrake/Character-Cartridges-Embodied-Identity",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "https://blogs.unity3d.com/2020/05/12/announcing-ml-agents-unity-package-v1-0/\n\n\nMay 8  2020\nhttps://openai.com/blog/emergent-tool-use/\nIn terms of observing autonomous or semi autonomous agents, Our character cartridge infused agents could be observed in a similar environment but instead of hide and seek for goal seeking there\u2019s something more around curiosity or stress or cortisol  (thanks for reminder lucy)_\n\n\nJake update video - APril 28\nhttps://www.youtube.com/watch?v=0VyLE_fG_7o&feature=youtu.be\nExplosions and also first cut of the room of observation / monitoring room\n\nJake update  bideo  march  31sat  - Orb tests, switch throw, Regina and John/Jake\nhttps://youtu.be/IBpVZaGsWrI\nAvatars \"animated\"  after switch tthrrow (check  out 1:45 'big stretch')\n\n \n \nTest video Feb 5  - Three Toasters loading - BLue5 Red1 Yellow1\nhttps://www.youtube.com/watch?v=UzgKLKAutXM\n\nJake Test Video - Feb 4 2020\nA short demo of some concepts to discuss in call \nhttps://drive.google.com/open?id=13J85ERDewAGbgYWj1rneY7uiung7H61D\n\nPrototype - Cartridges for Personality\nhttps://drive.google.com/open?id=1fhQMKUT-NH52kjPctRO0ZeSbR8H_ZoIj\n\nPad Thai Data driven avatars\n https://drive.google.com/file/d/0B3WOmvm7uBq-RXZ1dlRYZWg5cmM/view\n\nBubbleman Avatar\nhttps://youtu.be/fOfFrGsNwHo\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9296286067625201
      ],
      "excerpt": "As you begin to build your virtual lab, you\u2019ve decided a few things: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8001563621218657
      ],
      "excerpt": "\u2022   VR User (you!) enter your virtual lab ready to create several Characters and  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8368435637404119
      ],
      "excerpt": "\u2022   You DECIDE which one you want to ANIMATE, by pointing the switch (or pushing a button) to select character in focus. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/rustyoldrake/Character-Cartridges-Embodied-Identity/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "R"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Apache License 2.0",
      "url": "https://api.github.com/licenses/apache-2.0"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'                                 Apache License\\n                           Version 2.0, January 2004\\n                        http://www.apache.org/licenses/\\n\\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\\n\\n   1. Definitions.\\n\\n      \"License\" shall mean the terms and conditions for use, reproduction,\\n      and distribution as defined by Sections 1 through 9 of this document.\\n\\n      \"Licensor\" shall mean the copyright owner or entity authorized by\\n      the copyright owner that is granting the License.\\n\\n      \"Legal Entity\" shall mean the union of the acting entity and all\\n      other entities that control, are controlled by, or are under common\\n      control with that entity. For the purposes of this definition,\\n      \"control\" means (i) the power, direct or indirect, to cause the\\n      direction or management of such entity, whether by contract or\\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\\n      outstanding shares, or (iii) beneficial ownership of such entity.\\n\\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\\n      exercising permissions granted by this License.\\n\\n      \"Source\" form shall mean the preferred form for making modifications,\\n      including but not limited to software source code, documentation\\n      source, and configuration files.\\n\\n      \"Object\" form shall mean any form resulting from mechanical\\n      transformation or translation of a Source form, including but\\n      not limited to compiled object code, generated documentation,\\n      and conversions to other media types.\\n\\n      \"Work\" shall mean the work of authorship, whether in Source or\\n      Object form, made available under the License, as indicated by a\\n      copyright notice that is included in or attached to the work\\n      (an example is provided in the Appendix below).\\n\\n      \"Derivative Works\" shall mean any work, whether in Source or Object\\n      form, that is based on (or derived from) the Work and for which the\\n      editorial revisions, annotations, elaborations, or other modifications\\n      represent, as a whole, an original work of authorship. For the purposes\\n      of this License, Derivative Works shall not include works that remain\\n      separable from, or merely link (or bind by name) to the interfaces of,\\n      the Work and Derivative Works thereof.\\n\\n      \"Contribution\" shall mean any work of authorship, including\\n      the original version of the Work and any modifications or additions\\n      to that Work or Derivative Works thereof, that is intentionally\\n      submitted to Licensor for inclusion in the Work by the copyright owner\\n      or by an individual or Legal Entity authorized to submit on behalf of\\n      the copyright owner. For the purposes of this definition, \"submitted\"\\n      means any form of electronic, verbal, or written communication sent\\n      to the Licensor or its representatives, including but not limited to\\n      communication on electronic mailing lists, source code control systems,\\n      and issue tracking systems that are managed by, or on behalf of, the\\n      Licensor for the purpose of discussing and improving the Work, but\\n      excluding communication that is conspicuously marked or otherwise\\n      designated in writing by the copyright owner as \"Not a Contribution.\"\\n\\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\\n      on behalf of whom a Contribution has been received by Licensor and\\n      subsequently incorporated within the Work.\\n\\n   2. Grant of Copyright License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      copyright license to reproduce, prepare Derivative Works of,\\n      publicly display, publicly perform, sublicense, and distribute the\\n      Work and such Derivative Works in Source or Object form.\\n\\n   3. Grant of Patent License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      (except as stated in this section) patent license to make, have made,\\n      use, offer to sell, sell, import, and otherwise transfer the Work,\\n      where such license applies only to those patent claims licensable\\n      by such Contributor that are necessarily infringed by their\\n      Contribution(s) alone or by combination of their Contribution(s)\\n      with the Work to which such Contribution(s) was submitted. If You\\n      institute patent litigation against any entity (including a\\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\\n      or a Contribution incorporated within the Work constitutes direct\\n      or contributory patent infringement, then any patent licenses\\n      granted to You under this License for that Work shall terminate\\n      as of the date such litigation is filed.\\n\\n   4. Redistribution. You may reproduce and distribute copies of the\\n      Work or Derivative Works thereof in any medium, with or without\\n      modifications, and in Source or Object form, provided that You\\n      meet the following conditions:\\n\\n      (a) You must give any other recipients of the Work or\\n          Derivative Works a copy of this License; and\\n\\n      (b) You must cause any modified files to carry prominent notices\\n          stating that You changed the files; and\\n\\n      (c) You must retain, in the Source form of any Derivative Works\\n          that You distribute, all copyright, patent, trademark, and\\n          attribution notices from the Source form of the Work,\\n          excluding those notices that do not pertain to any part of\\n          the Derivative Works; and\\n\\n      (d) If the Work includes a \"NOTICE\" text file as part of its\\n          distribution, then any Derivative Works that You distribute must\\n          include a readable copy of the attribution notices contained\\n          within such NOTICE file, excluding those notices that do not\\n          pertain to any part of the Derivative Works, in at least one\\n          of the following places: within a NOTICE text file distributed\\n          as part of the Derivative Works; within the Source form or\\n          documentation, if provided along with the Derivative Works; or,\\n          within a display generated by the Derivative Works, if and\\n          wherever such third-party notices normally appear. The contents\\n          of the NOTICE file are for informational purposes only and\\n          do not modify the License. You may add Your own attribution\\n          notices within Derivative Works that You distribute, alongside\\n          or as an addendum to the NOTICE text from the Work, provided\\n          that such additional attribution notices cannot be construed\\n          as modifying the License.\\n\\n      You may add Your own copyright statement to Your modifications and\\n      may provide additional or different license terms and conditions\\n      for use, reproduction, or distribution of Your modifications, or\\n      for any such Derivative Works as a whole, provided Your use,\\n      reproduction, and distribution of the Work otherwise complies with\\n      the conditions stated in this License.\\n\\n   5. Submission of Contributions. Unless You explicitly state otherwise,\\n      any Contribution intentionally submitted for inclusion in the Work\\n      by You to the Licensor shall be under the terms and conditions of\\n      this License, without any additional terms or conditions.\\n      Notwithstanding the above, nothing herein shall supersede or modify\\n      the terms of any separate license agreement you may have executed\\n      with Licensor regarding such Contributions.\\n\\n   6. Trademarks. This License does not grant permission to use the trade\\n      names, trademarks, service marks, or product names of the Licensor,\\n      except as required for reasonable and customary use in describing the\\n      origin of the Work and reproducing the content of the NOTICE file.\\n\\n   7. Disclaimer of Warranty. Unless required by applicable law or\\n      agreed to in writing, Licensor provides the Work (and each\\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\\n      implied, including, without limitation, any warranties or conditions\\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\\n      PARTICULAR PURPOSE. You are solely responsible for determining the\\n      appropriateness of using or redistributing the Work and assume any\\n      risks associated with Your exercise of permissions under this License.\\n\\n   8. Limitation of Liability. In no event and under no legal theory,\\n      whether in tort (including negligence), contract, or otherwise,\\n      unless required by applicable law (such as deliberate and grossly\\n      negligent acts) or agreed to in writing, shall any Contributor be\\n      liable to You for damages, including any direct, indirect, special,\\n      incidental, or consequential damages of any character arising as a\\n      result of this License or out of the use or inability to use the\\n      Work (including but not limited to damages for loss of goodwill,\\n      work stoppage, computer failure or malfunction, or any and all\\n      other commercial damages or losses), even if such Contributor\\n      has been advised of the possibility of such damages.\\n\\n   9. Accepting Warranty or Additional Liability. While redistributing\\n      the Work or Derivative Works thereof, You may choose to offer,\\n      and charge a fee for, acceptance of support, warranty, indemnity,\\n      or other liability obligations and/or rights consistent with this\\n      License. However, in accepting such obligations, You may act only\\n      on Your own behalf and on Your sole responsibility, not on behalf\\n      of any other Contributor, and only if You agree to indemnify,\\n      defend, and hold each Contributor harmless for any liability\\n      incurred by, or claims asserted against, such Contributor by reason\\n      of your accepting any such warranty or additional liability.\\n\\n   END OF TERMS AND CONDITIONS\\n\\n   APPENDIX: How to apply the Apache License to your work.\\n\\n      To apply the Apache License to your work, attach the following\\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\\n      replaced with your own identifying information. (Don\\'t include\\n      the brackets!)  The text should be enclosed in the appropriate\\n      comment syntax for the file format. We also recommend that a\\n      file or class name and description of purpose be included on the\\n      same \"printed page\" as the copyright notice for easier\\n      identification within third-party archives.\\n\\n   Copyright [yyyy] [name of copyright owner]\\n\\n   Licensed under the Apache License, Version 2.0 (the \"License\");\\n   you may not use this file except in compliance with the License.\\n   You may obtain a copy of the License at\\n\\n       http://www.apache.org/licenses/LICENSE-2.0\\n\\n   Unless required by applicable law or agreed to in writing, software\\n   distributed under the License is distributed on an \"AS IS\" BASIS,\\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n   See the License for the specific language governing permissions and\\n   limitations under the License.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Character-Cartridges-Embodied-Identity",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Character-Cartridges-Embodied-Identity",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "rustyoldrake",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rustyoldrake/Character-Cartridges-Embodied-Identity/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Fri, 24 Dec 2021 23:29:29 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\u2022\tMedia, Entertainment, Gaming & Fantasy - Sophisticated VR allows users to make-believe.  Multiplayer, massive communities, realistic, exciting, and immersive.  Value drivers of modern cinema , plus player immersion inside plots \u2013 which will include adult entertainment.  Bend physics, time & space in a Holodeck and \u2018virtual worlds\u2019; Media and Entertainment (AR VR XR) \u2013 populating characters in virtual environments; \n\u2022\tDecision Support Help humans summon and engage data to help with decisions.   Consumer: high-value feature rich options (home decorating, automobile) helps buyers compare & understand (see) options.  ERP / Strategic:  Executives with data-on-demand, verbal command & control BI ERP integrations. Shared visualizations\n\u2022\tCognitive Extenders - Help executives and innovators reduce cognitive load and extend cognitive range.  Better reasoning, recall, decision support, social navigation & connection making. Context aware information augmentation.  Instant context-aware data recall and visualization for decision support.  Collaboration catalyst.  LEARNING & COGNITIVE EXTENDERS -> Helping create connections and amplify abilities \u2013 Loci; COMPREHEND & CLARIFY CONTENT -> Helping to surface signal and distill information\n\u2022\tCognitive Wingman - Jarvis, KITT, HAL.  Sensemaking systems understand context, to help. Use cases include autism, eldercare, Alzheimer\u2019s & PTSD.  Cognitive Wingman is a human assistive AI/ADA buddy embedded inside AR headset \u2013 microphones & camera enable sensemaking & AR projection & audio to guide - or to guard.  Can also be used as moment-recall by therapists and caregivers.\n\u2022\tExpertise Projection - Amplify and project scarce expertise.  Highly skilled medical specialists projecting expertise 2000 miles away to nurse practitioners who touch patients.   Industrial \u2013 leverage expert engineers at distance to help low skilled workers repair or deploy complex assets.  Hands free.  Information overlay.\n\u2022\tKnowledge Map & Recall - Dark Data / Data Exhaust. Enterprises are drowning in data.  Knowledge & expertise fuels continuing innovation and digital transformation. Workers retiring, taking key knowledge. AR enables knowledge capture & recall across time/space. Verbal command/control, visual delivery. Leverage spatial memory. Neural Prosthetics.\n\u2022\tUnified Communications - The final destination for UC?  As close to being present, without actually being present.  Project remote attendee into an empty seat at a board meeting 3000 miles away.  Re-watch 2 year old meetings.  Look into the eyes & face of job applicant. AR for UC3.0 enables human communications at distance\n\u2022\tInfrastructure - AR enables engineers to see into, and project onto, complex and/or aging infrastructure assets to make best use of data, in field, real time.  Touches Digital Twin;  Decision Support;  Knowledge Mapping and recall, to enable AR equipped user ; Digital Twin / Industrial - Digital Twin is virtual/digital representation of a physical entity or system, living model that evolves over time, includes structured and unstructured data.  IOT, Edge appliances and predictive analytics.  \n\u2022\tNeural Adaptive - (Speculative) NLU powered context gathering / sensemaking.  Emotion and eye tracking. Neural network & deep learning powered systems to recognize patterns from biometric signals (EEG/FMRI). Education optimization. AR content & agents serving as baseline reference for neural adaptive AR systems.\n\u2022\tEducation - AR opens up new ways for children and adults to interact with, and consume and retain knowledge, in the most efficient and effective way \u2013 for each person.  Customization;  interactivity; flexibility and leverage spatial and visual components of AR for learners most benefiting from methods. Key Elements of Solution:  1. Augments known educational best practices (learning outcomes, learning pathways) with insights gained from ML/DL analysis combined with traditional data science // 2. Leverages dynamic segmentation and clustering (cohorts, archetypes) // 3. Uses deep learning to surface key features in natural language and knowledge set / ontology // 4. Uses Machine Learning (e.g. Random Forest) to surface key features in learning path // 5. Applies Natural Language Understanding for signal extraction from students & teachers // 6. Interacts \u2013 Provides natural language and visual interactions to exchange information, including but not limited to Augmented Reality, Virtual Reality and Digital Humans. // 7. Learns.  Evolves with the content, learners and teachers to improve over time\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
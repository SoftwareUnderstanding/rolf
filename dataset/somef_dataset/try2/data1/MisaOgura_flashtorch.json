{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1404.5997"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```txt\nMisa Ogura, & Ravi Jain. (2020, January 2).\nMisaOgura/flashtorch: 0.1.2 (Version v0.1.2).\nZenodo. http://doi.org/10.5281/zenodo.3596650\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9112228336001563
      ],
      "excerpt": "EBU AI IN PRODUCTION AND DISTRIBUTION WORKSHOP, November 2019 - slide deck \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/MisaOgura/flashtorch/master/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MisaOgura/flashtorch",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "How to contribute to FlashTorch\nFirst off, thanks for taking the time to contribute! \ud83c\udf89\ud83d\udc4d\nDid you find a bug?\n\n\nEnsure the bug was not already reported by searching on GitHub under Issues.\n\n\nIf you're unable to find an open issue addressing the problem, open a new one. Be sure to include a title and clear description, as much relevant information as possible, and a code sample or an executable test case demonstrating the expected behavior that is not occurring.\n\n\nDid you write a patch that fixes a bug?\n\n\nOpen a new GitHub pull request with the patch.\n\n\nEnsure the PR description clearly describes the problem and solution with appropriate tests. Include the relevant issue number if applicable.\n\n\nDid you fix whitespace, format code, or make a purely cosmetic patch?\nChanges that are cosmetic in nature and do not add anything substantial to the stability, functionality, or testability of FlashTorch will generally not be accepted.\nDo you intend to add a new feature or change an existing one?\n\nIf you are not sure about your change, open an issue with your request to discuss further.\n\nDo you have questions about the source code?\n\nAsk any question about how to use FlashTorch, please email me at misa.ogura01_at_gmail.com.\n\nMany thanks :yellow_heart:\n(Adopted from Ruby on Rails guildline)",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-22T13:00:57Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-26T11:43:58Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9274277082131618,
        0.9348305093575181,
        0.948697947167169
      ],
      "excerpt": "A Python visualization toolkit, built with PyTorch, for neural networks in PyTorch. \nNeural networks are often described as \"black box\". The lack of understanding on how neural networks make predictions enables unpredictable/biased models, causing real harm to society and a loss of trust in AI-assisted systems. \nFeature visualization is an area of research, which aims to understand how neural networks perceive images. However, implementing such techniques is often complicated. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9338512926168662,
        0.9664396197893934
      ],
      "excerpt": "You can apply feature visualization techniques (such as saliency maps and activation maximization) on your model, with as little as a few lines of code. \nIt is compatible with pre-trained models that come with torchvision, and seamlessly integrates with other custom models built in PyTorch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "How to contribute \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8905621073704336,
        0.8001435978062945,
        0.952418703016288,
        0.9233736520342727,
        0.813932299208802,
        0.9799876561624935
      ],
      "excerpt": "Saliency map with backpropagation notebook \nGoogle Colab version - best for trying it out \nSaliency in human visual perception is a subjective quality that makes certain things within the field of view stand out from the rest and grabs our attention. \nSaliency maps in computer vision provide indications of the most salient regions within images. By creating a saliency map for neural networks, we can gain some intuition on \"where the network is paying the most attention to\" in an input image. \nUsing flashtorch.saliency module, let's visualize image-specific class saliency maps of AlexNet pre-trained on ImageNet classification tasks. \nThe network is focusing on the sunken eyes and the round head for this owl. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8001435978062945,
        0.9973378051372007
      ],
      "excerpt": "Google Colab version - best for trying it out \nActivation maximization is one form of feature visualization that allows us to visualize what CNN filters are \"looking for\", by applying each filter to an input image and updating the input image so as to maximize the activation of the filter of interest (i.e. treating it as a gradient ascent task with filter activation values as the loss). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9858440194795093
      ],
      "excerpt": "Concepts such as 'eyes' (filter 45) and 'entrances (?)' (filter 271) seem to appear in the conv5_1 layer of VGG16. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8483013633370959,
        0.9418478639718614
      ],
      "excerpt": "Here is how to setup a dev environment for FlashTorch. \nFrom the project root: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.858764155858196
      ],
      "excerpt": "Add a kernel to Jupyter notebook. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8000831239104046,
        0.938053188072068
      ],
      "excerpt": "Thanks for your interest in contributing! \nPlease first head over to the Code of Conduct, which helps set the ground rules for participation in communities and helps build a culture of respect. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9558322670732099
      ],
      "excerpt": "Still here? Great! There are many ways to contribute to this project. Get started here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8802701704097646,
        0.9432867760983565,
        0.9373165394626017,
        0.8129077424336769,
        0.9123758060373144,
        0.8186826679770812,
        0.9141763699141326,
        0.950128109053593
      ],
      "excerpt": "Uncovering what neural nets \u201csee\u201d with FlashTorch \nGaining insights on transfer learning with FlashTorch \nIntroduction and overview of feature visualization: Feature Visualization \nThe latest development in feature visualization: Exploring Neural Networks with Activation Atlases \nUsing backpropagation for gradient visualization: Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps \nGuided backprobagation: Striving for Simplicity: The All Convolutional Net \nActivation maximization: Visualizing Higher-Layer Features of a Deep Network \npytorch-cnn-visualizations by utkuozbulak \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Visualization toolkit for neural networks in PyTorch! Demo -->",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MisaOgura/flashtorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 78,
      "date": "Thu, 30 Dec 2021 06:40:50 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/MisaOgura/flashtorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "MisaOgura/flashtorch",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/MisaOgura/flashtorch/master/presentations/ebu-ai-workshop/notebook.ipynb",
      "https://raw.githubusercontent.com/MisaOgura/flashtorch/master/presentations/Hopperx1London/notebook.ipynb",
      "https://raw.githubusercontent.com/MisaOgura/flashtorch/master/tests/test_saliency_backprop.ipynb",
      "https://raw.githubusercontent.com/MisaOgura/flashtorch/master/tests/test_activmax_gradientascent.ipynb",
      "https://raw.githubusercontent.com/MisaOgura/flashtorch/master/examples/visualize_saliency_with_backprop_colab.ipynb",
      "https://raw.githubusercontent.com/MisaOgura/flashtorch/master/examples/image_handling.ipynb",
      "https://raw.githubusercontent.com/MisaOgura/flashtorch/master/examples/activation_maximization_colab.ipynb",
      "https://raw.githubusercontent.com/MisaOgura/flashtorch/master/examples/create_saliency_maps_for_torchvision_models_colab.ipynb",
      "https://raw.githubusercontent.com/MisaOgura/flashtorch/master/examples/visualize_saliency_with_backprop.ipynb",
      "https://raw.githubusercontent.com/MisaOgura/flashtorch/master/examples/activation_maximization.ipynb",
      "https://raw.githubusercontent.com/MisaOgura/flashtorch/master/examples/create_saliency_maps_for_torchvision_models.ipynb"
    ],
    "technique": "File Exploration"
  },
  "identifier": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://zenodo.org/badge/latestdoi/177140934",
      "technique": "Regular expression"
    }
  ],
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "These are currently available modules.\n\n- `flashtorch.utils`: some useful utility functions for data handling & transformation\n- `flashtorch.utils.imagenet`: `ImageNetIndex` class for easy-ish retrieval of class index\n- `flashtorch.saliency.backprop`: `Backprop` class for calculating gradients\n- `flashtorch.activmax.gradient_ascent`: `GradientAscent` class for activation maximization\n\nYou can inspect each module with Python built-in function `help`. The output of that is available on [Quick API Guide](https://github.com/MisaOgura/flashtorch/wiki/Quick-API-Guide) for your convenience.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "If you are installing FlashTorch for the first time:\n\n```bash\n$ pip install flashtorch\n```\n\nOr if you are upgrading it:\n\n```bash\n$ pip install flashtorch -U\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9035311127838745
      ],
      "excerpt": "Here is how to setup a dev environment for FlashTorch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.979350721346897,
        0.9632347459754548,
        0.9779906815418535,
        0.9770335174395833,
        0.9015910503836494,
        0.999746712887969
      ],
      "excerpt": "Create a conda environment. \n$ conda env create -f environment.yml \nActivate the environment. \n$ conda activate flashtorch \nInstall FlashTorch in a development mode. \n$ pip install -e . \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233131101979801,
        0.9876422738722964
      ],
      "excerpt": "Add a kernel to Jupyter notebook. \n$ python -m ipykernel install --user --name flashtorch \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8820234121644812
      ],
      "excerpt": "$ jupyter notebook \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8905831790420032
      ],
      "excerpt": "Next, please make sure that you have a dev environment set up (see the Develop FlashTorch section above). \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8434777135234066
      ],
      "excerpt": "$ flake8 flashtorch tests &amp;&amp; pytest \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8986361356141102
      ],
      "excerpt": "Open a notebook in the ./examples directory. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/MisaOgura/flashtorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "HTML",
      "Jupyter Notebook",
      "Python",
      "CSS"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Misa Ogura\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "FlashTorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "flashtorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "MisaOgura",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MisaOgura/flashtorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "MisaOgura",
        "body": "# Install steps\r\n- `pip install flashtorch`\r\n\r\n# Upgrade steps\r\n- `pip install flashtorch -U`\r\n\r\n# Breaking changes\r\n- None\r\n\r\n# New features\r\n- None\r\n\r\n# Bug fixes\r\n- None\r\n\r\n# Improvements\r\n- Requested improvement: #30 \r\n  - Implemented by #31 \r\n  - Quick summary: `flashtorch.saliency.Backprop` can now handle models with mono-channel/grayscale input images\r\n\r\n# Other changes\r\n- None",
        "dateCreated": "2020-05-29T14:37:29Z",
        "datePublished": "2020-05-29T14:39:38Z",
        "html_url": "https://github.com/MisaOgura/flashtorch/releases/tag/v0.1.3",
        "name": "0.1.3",
        "tag_name": "v0.1.3",
        "tarball_url": "https://api.github.com/repos/MisaOgura/flashtorch/tarball/v0.1.3",
        "url": "https://api.github.com/repos/MisaOgura/flashtorch/releases/27034271",
        "zipball_url": "https://api.github.com/repos/MisaOgura/flashtorch/zipball/v0.1.3"
      },
      {
        "authorType": "User",
        "author_name": "MisaOgura",
        "body": "# Install steps\r\n- `pip install flashtorch`\r\n\r\n# Upgrade steps\r\n- `pip install flashtorch -U`\r\n\r\n# Breaking changes\r\n- None\r\n\r\n# New features\r\n- None\r\n\r\n# Bug fixes\r\n- Reported bug: #18 \r\n  - Fixed by: #25 \r\n  - Quick summary: `flashtorch.saliency.Backprop.visualize` now correctly passes `use_gpu` flag down to the `calculate_gradient`.\r\n\r\n# Improvements\r\n- None\r\n\r\n# Other changes\r\n- None",
        "dateCreated": "2020-01-02T10:52:20Z",
        "datePublished": "2020-01-02T11:01:14Z",
        "html_url": "https://github.com/MisaOgura/flashtorch/releases/tag/v0.1.2",
        "name": "0.1.2",
        "tag_name": "v0.1.2",
        "tarball_url": "https://api.github.com/repos/MisaOgura/flashtorch/tarball/v0.1.2",
        "url": "https://api.github.com/repos/MisaOgura/flashtorch/releases/22550480",
        "zipball_url": "https://api.github.com/repos/MisaOgura/flashtorch/zipball/v0.1.2"
      },
      {
        "authorType": "User",
        "author_name": "MisaOgura",
        "body": "# Install steps\r\n- `pip install flashtorch`\r\n\r\n# Upgrade steps\r\n- `pip install flashtorch -U`\r\n\r\n# Breaking changes\r\n- None\r\n\r\n# New features\r\n- None\r\n\r\n# Bug fixes\r\n- Removes a dependency on `README.md` in `setup.py`: this is to avoid getting unicode decoding error (reported by #14). `setup.py` now gets the `long_description` from its docstring.\r\n\r\n# Improvements\r\n- None\r\n\r\n# Other changes\r\n- None",
        "dateCreated": "2019-09-26T10:39:31Z",
        "datePublished": "2019-09-26T10:45:21Z",
        "html_url": "https://github.com/MisaOgura/flashtorch/releases/tag/v0.1.1",
        "name": "0.1.1",
        "tag_name": "v0.1.1",
        "tarball_url": "https://api.github.com/repos/MisaOgura/flashtorch/tarball/v0.1.1",
        "url": "https://api.github.com/repos/MisaOgura/flashtorch/releases/20272889",
        "zipball_url": "https://api.github.com/repos/MisaOgura/flashtorch/zipball/v0.1.1"
      },
      {
        "authorType": "User",
        "author_name": "MisaOgura",
        "body": "# Install steps\r\n- `pip install flashtorch`\r\n\r\n# Upgrade steps\r\n- `pip install flashtorch -U`\r\n\r\n# Breaking changes\r\n- `flashtorch.utils.visualize`: This functionality was specific for creating saliency maps, and therefore has been moved as a class method for `flashtorch.saliency.Backprop`\r\n\r\nRefer to the notebooks below for details and how to use it:\r\n\r\n- [Image-specific class saliency map with backpropagation](https://github.com/MisaOgura/flashtorch/blob/master/examples/visualise_saliency_with_backprop.ipynb)\r\n- [Google Colab version](https://colab.research.google.com/github/MisaOgura/flashtorch/blob/master/examples/visualize_saliency_with_backprop_colab.ipynb): best for playing around\r\n\r\n# New features\r\n- `flashtorch.activmax.GradientAscent`: This is a new API which implements activation maximization via gradient ascent. It has three public facing APIs:\r\n\r\n    - `GradientAscent.optimize`: Generates an image that maximally activates the target filter.\r\n    - `GradientAscent.visualize`: Optimizes for the target layer/filter and visualizes the output.\r\n    - `GradientAscent.deepdream`: Creates DeepDream.\r\n\r\nRefer to the notebooks below for details and how to use it:\r\n\r\n- [Activation maximization](https://github.com/MisaOgura/flashtorch/blob/master/examples/activation_maximization.ipynb)\r\n- [Google Colab version](https://colab.research.google.com/github/MisaOgura/flashtorch/blob/master/examples/activation_maximization_colab.ipynb): best for playing around\r\n\r\n# Bug fixes\r\n- None\r\n\r\n# Improvements\r\n- `flashtorch.utils.standardize_and_clip`: Users can optionally set the `saturation` and `brightness`.\r\n\r\n# Other changes\r\n- None",
        "dateCreated": "2019-09-09T16:13:51Z",
        "datePublished": "2019-09-09T16:27:15Z",
        "html_url": "https://github.com/MisaOgura/flashtorch/releases/tag/v0.1.0",
        "name": "0.1.0",
        "tag_name": "v0.1.0",
        "tarball_url": "https://api.github.com/repos/MisaOgura/flashtorch/tarball/v0.1.0",
        "url": "https://api.github.com/repos/MisaOgura/flashtorch/releases/19856904",
        "zipball_url": "https://api.github.com/repos/MisaOgura/flashtorch/zipball/v0.1.0"
      },
      {
        "authorType": "User",
        "author_name": "MisaOgura",
        "body": "# Install steps\r\n- `pip install flashtorch`\r\n\r\n# Upgrade steps\r\n- `pip install flashtorch -U`\r\n\r\n# Breaking changes\r\n- None \r\n\r\n# New features\r\n- None\r\n\r\n# Bug fixes\r\n- Fixes #2 \r\n\r\n# Improvements\r\n- Users can explicitly set a device to use when calculating gradients when using an instance of `Backprop`, by setting `use_gpu=True`. If it's True and `torch.cuda.is_available`, the computation will be moved to GPU. It defaults to `False` if not provided.\r\n\r\n    ```\r\n    from flashtorch.saliency import Backprop\r\n    \r\n    ... # Prepare input and target_class\r\n    \r\n    model = model()\r\n    backprop = Backprop(model)\r\n    gradients = backprop. calculate_gradients(input, target_class, use_gpu=True)\r\n    ```\r\n\r\n# Other changes\r\n- `setup.py` has better indications of supported Python versions",
        "dateCreated": "2019-07-08T10:16:51Z",
        "datePublished": "2019-07-08T10:45:13Z",
        "html_url": "https://github.com/MisaOgura/flashtorch/releases/tag/v0.0.8",
        "name": "0.0.8",
        "tag_name": "v0.0.8",
        "tarball_url": "https://api.github.com/repos/MisaOgura/flashtorch/tarball/v0.0.8",
        "url": "https://api.github.com/repos/MisaOgura/flashtorch/releases/18467927",
        "zipball_url": "https://api.github.com/repos/MisaOgura/flashtorch/zipball/v0.0.8"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 636,
      "date": "Thu, 30 Dec 2021 06:40:50 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "neural-networks",
      "cnn",
      "interpretability",
      "machine-learning",
      "deep-learning",
      "visualization",
      "explainability"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Below, you can find simple demos to get you started, as well as links to some handy notebooks showing additional examples of using FlashTorch.\n\n",
      "technique": "Header extraction"
    }
  ]
}
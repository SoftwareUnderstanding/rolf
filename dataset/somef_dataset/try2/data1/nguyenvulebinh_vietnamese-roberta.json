{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1907.11692"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```text\n@inproceedings{nguyen20d_interspeech,\n  author={Thai Binh Nguyen and Quang Minh Nguyen and Thi Thu Hien Nguyen and Quoc Truong Do and Chi Mai Luong},\n  title={{Improving Vietnamese Named Entity Recognition from Speech Using Word Capitalization and Punctuation Recovery Models}},\n  year=2020,\n  booktitle={Proc. Interspeech 2020},\n  pages={4263--4267},\n  doi={10.21437/Interspeech.2020-1896}\n}\n```\n**Please CITE** our repo when it is used to help produce published results or is incorporated into other software.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{nguyen20d_interspeech,\n  author={Thai Binh Nguyen and Quang Minh Nguyen and Thi Thu Hien Nguyen and Quoc Truong Do and Chi Mai Luong},\n  title={{Improving Vietnamese Named Entity Recognition from Speech Using Word Capitalization and Punctuation Recovery Models}},\n  year=2020,\n  booktitle={Proc. Interspeech 2020},\n  pages={4263--4267},\n  doi={10.21437/Interspeech.2020-1896}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nguyenvulebinh/vietnamese-roberta",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "nguyenvulebinh@gmail.com\n\n[![Follow](https://img.shields.io/twitter/follow/nguyenvulebinh?style=social)](https://twitter.com/intent/follow?screen_name=nguyenvulebinh)\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-06T02:24:40Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-17T13:31:50Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9925683071249566,
        0.9653683496489902
      ],
      "excerpt": "RoBERTa is an improved recipe for training BERT models that can match or exceed the performance of all of the post-BERT methods. The different between RoBERTa and BERT: \nTraining the model longer, with bigger batches, over more data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9933847820726813
      ],
      "excerpt": "Data to train this model is Vietnamese corpus crawled from many online newspapers: 50GB of text with approximate 7.7 billion words that crawl from many domains on the internet including news, law, entertainment, wikipedia and so on. Data was cleaned using visen library and tokenize using sentence piece. With envibert model, we use another 50GB of text in English, so a total of 100GB text is used to train envibert model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "  for item in resources: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "model = RobertaModel.from_pretrained(model_name,cache_dir=cache_dir) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "text_features = model(text_ids) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9142063019207154
      ],
      "excerpt": ": Using cased model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "roberta = XLMRModel.from_pretrained(pretrained_path, checkpoint_file='model.pt') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8482086298022323
      ],
      "excerpt": ": Extracted feature using roberta model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A Robustly Optimized BERT Pretraining Approach for Vietnamese",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nguyenvulebinh/vietnamese-roberta/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Tue, 28 Dec 2021 20:29:05 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/nguyenvulebinh/vietnamese-roberta/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "nguyenvulebinh/vietnamese-roberta",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Download the model using the following link: [envibert model](https://bit.ly/envibert), [cased model](https://bit.ly/vibert-cased), [uncased model](https://bit.ly/vibert-uncased) and put it in folder data-bin as the following folder structure::\n\n```text\nmodel-bin\n\u251c\u2500\u2500 envibert\n\u2502   \u251c\u2500\u2500 dict.txt\n\u2502   \u251c\u2500\u2500 model.pt\n\u2502   \u2514\u2500\u2500 sentencepiece.bpe.model\n\u2514\u2500\u2500 uncased\n|   \u251c\u2500\u2500 dict.txt\n|   \u251c\u2500\u2500 model.pt\n|   \u2514\u2500\u2500 sentencepiece.bpe.model\n\u2514\u2500\u2500 cased\n    \u251c\u2500\u2500 dict.txt\n    \u251c\u2500\u2500 model.pt\n    \u2514\u2500\u2500 sentencepiece.bpe.model\n\n```\n\n- Install environment library\n```bash\npip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8801854956928516,
        0.8801854956928516,
        0.8801854956928516,
        0.8401558704798054
      ],
      "excerpt": "from transformers import RobertaModel \nfrom transformers.file_utils import cached_path, hf_bucket_url \nfrom importlib.machinery import SourceFileLoader \nimport os \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8794178612306077
      ],
      "excerpt": "  resources = ['envibert_tokenizer.py', 'dict.txt', 'sentencepiece.bpe.model'] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8132392936387923
      ],
      "excerpt": "      tmp_file = hf_bucket_url(model_name, filename=item) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": ": Encode text \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8900486270063179
      ],
      "excerpt": "from fairseq.models.roberta import XLMRModel \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8009529246210325
      ],
      "excerpt": "roberta.eval()  #: disable dropout (or leave in train mode to finetune) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/nguyenvulebinh/vietnamese-roberta/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Pre-trained embedding using RoBERTa architecture on Vietnamese corpus",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "vietnamese-roberta",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "nguyenvulebinh",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nguyenvulebinh/vietnamese-roberta/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 13,
      "date": "Tue, 28 Dec 2021 20:29:05 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "vietnamese",
      "pretrained-models",
      "natural-language-processing",
      "roberta",
      "bert",
      "bert-embeddings",
      "pytorch",
      "fairseq",
      "sentencepiece",
      "vietnamese-nlp",
      "transformer"
    ],
    "technique": "GitHub API"
  }
}
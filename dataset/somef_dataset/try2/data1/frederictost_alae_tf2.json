{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2004.04467\">2004.04467</a></h5>\r\n\r\n**MNIST** dataset is used as a toy example. The **Generator** and **E encoder** are using **Conv2D** and **Conv2DTranspose** instead of a **MLP** (Multi-Layer Perceptron used in the paper",
      "https://arxiv.org/abs/ <a href=\"https://arxiv.org/abs/2004.04467\">2004.04467</a></h5>\r\n\r\n**MNIST** dataset is used as a toy example. The **Generator** and **E encoder** are using **Conv2D** and **Conv2DTranspose** instead of a **MLP** (Multi-Layer Perceptron used in the paper). \r\nThis gives better results but  a longer training.\r\n\r\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/hparams.svg?style=flat-square)\r\n[![License: MIT](https://img.shields.io/badge/License-MIT-brightgreen.svg?style=flat-square)](https://opensource.org/licenses/MIT)\r\n\r\n## Objective\r\n\r\nThe objective is to show how to easily implement the ALAE using the **MNIST** dataset and convolutional networks. Finding the hyperparameters such as learning rate of each optimizer is the most fastidious task. \r\n \r\nAdditional features\r\n- The use of Tensorflow 2.0 **HParams Dashboard** features allows to keep a trace of each run using different hyperparameters.\r\n\r\n![](static/hparam_table_view.png) \r\n\r\n\r\n- 3 losses time history \r\n\r\n| Loss | Time history\r\n| :--- | :----------\r\n| Generator | ![](static/loss_generator.png) \r\n| Discriminator | ![](static/loss_discriminator.png)\r\n| Latent | ![](static/loss_latent.png) \r\n\r\n- the latent loss was splitted into **Reconstruction** loss and **Kullback Leibler (KL)** loss. \r\nKL loss is not used in the original paper, it seems to accelerate the convergence of the Generator/Discriminator.\r\n\r\n    \r\n    K_RECONST_KL = 1.0 # To use full reconstruction (alae_tf2.py)\r\n\r\n## To run the demo\r\n\r\nTo run the demo, you will need to have installed Tensorflow 2.0.0 or more recent (2.1.0, 2.2.0). \r\n\r\nRun the demo\r\n\r\n    python alae_tf2.py\r\n\r\n\r\n\r\n#### Repository structure\r\n\r\n| Path | Description\r\n| :--- | :----------\r\n| alae_tf2.py | Configure the hyperparameters and run the demo.\r\n| alae_tf2_helper.py | Train the neural network. alae_helper is the class that define the losses and the train step function.\r\n| alae_tf2_models.py | Models used in the demo, Encoders F & E, Generator and Discriminator (4 classes).\r\n| utils.py | Useful functions to process and plot images (2 functions).\r\n\r\n## Authors\r\n\r\n- Fr\u00e9d\u00e9ric TOST \u2014 Developer [TOST Corp.](https://tostcorp.com/"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9999999954151519,
        0.9999402704769882
      ],
      "excerpt": "* Stanislav Pidhorskyi, Donald A. Adjeroh, and Gianfranco Doretto. Adversarial Latent Autoencoders. In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), 2020. [to appear]  \n<h5>preprint on arXiv: <a href=\"https://arxiv.org/abs/2004.04467\">2004.04467</a></h5> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/frederictost/alae_tf2/master/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/frederictost/alae_tf2",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-12T09:27:34Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-25T01:46:21Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9359403892506125
      ],
      "excerpt": "This is a Python/Tensorflow 2.0 implementation of the Adversarial Latent AutoEncoders.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9197978540878757
      ],
      "excerpt": "MNIST dataset is used as a toy example. The Generator and E encoder are using Conv2D and Conv2DTranspose instead of a MLP (Multi-Layer Perceptron used in the paper).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9891583712922866,
        0.8174744906558209,
        0.9222973760933967
      ],
      "excerpt": "The objective is to show how to easily implement the ALAE using the MNIST dataset and convolutional networks. Finding the hyperparameters such as learning rate of each optimizer is the most fastidious task.  \nAdditional features \n- The use of Tensorflow 2.0 HParams Dashboard features allows to keep a trace of each run using different hyperparameters. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9830940545583305
      ],
      "excerpt": "KL loss is not used in the original paper, it seems to accelerate the convergence of the Generator/Discriminator. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This is a Python/Tensorflow 2.0 implementation of the Adversarial Latent AutoEncoders.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/frederictost/alae_tf2/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Sat, 25 Dec 2021 20:30:13 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/frederictost/alae_tf2/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "frederictost/alae_tf2",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8730593549943011
      ],
      "excerpt": "| alae_tf2.py | Configure the hyperparameters and run the demo. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9026067970166757
      ],
      "excerpt": "| utils.py | Useful functions to process and plot images (2 functions). \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/frederictost/alae_tf2/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Fr\\xc3\\xa9d\\xc3\\xa9ric TOST\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "ALAE",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "alae_tf2",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "frederictost",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/frederictost/alae_tf2/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nTo run the demo, you will need to have installed Tensorflow 2.0.0 or more recent (2.1.0, 2.2.0). \r\n\r\nRun the demo\r\n\r\n    python alae_tf2.py\r\n\r\n\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Sat, 25 Dec 2021 20:30:13 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "alae",
      "tensorflow",
      "tf2",
      "mnist",
      "autoencoders",
      "gan",
      "vae",
      "vae-gan",
      "tensorflow2",
      "adversarial-latent-autoencoder"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nTo run the demo, you will need to have installed Tensorflow 2.0.0 or more recent (2.1.0, 2.2.0). \r\n\r\nRun the demo\r\n\r\n    python alae_tf2.py\r\n\r\n\r\n\r\n",
      "technique": "Header extraction"
    }
  ]
}
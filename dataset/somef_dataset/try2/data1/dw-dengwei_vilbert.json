{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1912.02315",
      "https://arxiv.org/abs/1908.02265",
      "https://arxiv.org/abs/1908.02265"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this code is useful for your research, please cite our paper\n\n```\n@article{lu2019vilbert,\n  title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},\n  journal={arXiv preprint arXiv:1908.02265},\n  year={2019}\n}\n```\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{lu2019vilbert,\n  title={ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},\n  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},\n  journal={arXiv preprint arXiv:1908.02265},\n  year={2019}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dw-dengwei/vilbert",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-19T08:59:28Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-05T16:58:31Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8156024153123562,
        0.8416503884449552,
        0.860059181823877
      ],
      "excerpt": "Code and pre-trained models for ViLBERT: Pretraining Task-Agnostic VisiolinguisticRepresentations for Vision-and-Language Tasks. \n<span style=\"color:blue\"> *Note: This codebase is still in beta release to replicate the paper's preformance. * </span> \n| Model | Objective | Link | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8902275249940715
      ],
      "excerpt": "2: Update featyres_h5path1 and val_annotations_jsonpath in  vlbert_task.yml to load the Flickr30k testset image feature and jsonfile (defualt is training feature).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8902275249940715
      ],
      "excerpt": "2: Update featyres_h5path1 and val_annotations_jsonpath in  vlbert_task.yml to load the Flickr30k testset image feature and jsonfile (defualt is training feature).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9416518459095269
      ],
      "excerpt": "2: We use the Pre-computed detections/masks from MAttNet for fully-automatic comprehension task, Check the MAttNet repository for more details.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8163004491204304
      ],
      "excerpt": "Once you extracted all the image features, to train a 6-layer ViLBERT model on conceptual caption: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.913324085930547
      ],
      "excerpt": "To fintune a 6-layer ViLBERT model for VQA with 8 GPU. --tasks 0 means VQA tasks. Check vlbert_tasks.yml for more settings for VQA tasks.   \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dw-dengwei/vilbert/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 01:49:49 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dw-dengwei/vilbert/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "dw-dengwei/vilbert",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Check `README.md` under `data` for more details.  Check  `vlbert_tasks.yml` for more details. \n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Create a fresh conda environment, and install all dependencies.\n\n```text\nconda create -n vilbert python=3.6\nconda activate vilbert\ngit clone https://github.com/jiasenlu/vilbert_beta\ncd vilbert_beta\npip install -r requirements.txt\n```\n\n2. Install pytorch\n```\nconda install pytorch torchvision cudatoolkit=10.0 -c pytorch\n```\n\n3. Install apx, follows https://github.com/NVIDIA/apex\n\n4. compile tools\n\n```\ncd tools/refer\nmake\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8649798973105185
      ],
      "excerpt": "2: To test on held out validation split, use the following command:  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8502997220680211
      ],
      "excerpt": "1: Download the pretrained model with objective Conceptual Caption and put it under save \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.922646472797422,
        0.8274010807557309
      ],
      "excerpt": "python eval_retrieval.py --bert_model bert-base-uncased --from_pretrained save/bert_base_6_layer_6_connect/pytorch_model_9.bin --config_file config/bert_base_6layer_6conect.json --task 3 --split test --batch_size 1 --zero_shot \n1: Download the pretrained model with objective Image Retrieval and put it under save \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9363623258345442,
        0.8502997220680211
      ],
      "excerpt": "python eval_retrieval.py --bert_model bert-base-uncased --from_pretrained save/RetrievalFlickr30k_bert_base_6layer_6conect-pretrained/pytorch_model_19.bin --config_file config/bert_base_6layer_6conect.json --task 3 --split test --batch_size 1 \n1: Download the pretrained model with objective VQA and put it under save \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9049066590064228,
        0.8502997220680211
      ],
      "excerpt": "python eval_tasks.py --bert_model bert-base-uncased --from_pretrained save/VQA_bert_base_6layer_6conect-pretrained/pytorch_model_19.bin --config_file config/bert_base_6layer_6conect.json --task 0 --split minval \n1: Download the pretrained model with objective VCR and put it under save \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9042117822751213
      ],
      "excerpt": "python eval_tasks.py --bert_model bert-base-uncased --from_pretrained save/VCR_Q-A-VCR_QA-R_bert_base_6layer_6conect-pretrained/pytorch_model_19.bin --config_file config/bert_base_6layer_6conect.json --task 1 --split val \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9042117822751213,
        0.8502997220680211
      ],
      "excerpt": "python eval_tasks.py --bert_model bert-base-uncased --from_pretrained save/VCR_Q-A-VCR_QA-R_bert_base_6layer_6conect-pretrained/pytorch_model_19.bin --config_file config/bert_base_6layer_6conect.json --task 2 --split val \n1: Download the pretrained model with objective RefCOCO+ and put it under save \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9049066590064228
      ],
      "excerpt": "python eval_tasks.py --bert_model bert-base-uncased --from_pretrained save/refcoco+_bert_base_6layer_6conect-pretrained/pytorch_model_19.bin --config_file config/bert_base_6layer_6conect.json --task 4 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8416776857140243
      ],
      "excerpt": "ig_file config/bert_base_6layer_6conect.json --learning_rate 1e-4 --train_batch_size 512 --save_name pretrained \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8604759490408824
      ],
      "excerpt": "python -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 train_tasks.py --bert_model bert-base-uncased --from_pretrained save/bert_base_6_layer_6_connect_freeze_0/pytorch_model_8.bin  --config_file config/bert_base_6layer_6conect.json  --learning_rate 4e-5 --num_workers 16 --tasks 0 --save_name pretrained \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8604759490408824
      ],
      "excerpt": "python -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 train_tasks.py --bert_model bert-base-uncased --from_pretrained save/bert_base_6_layer_6_connect_freeze_0/pytorch_model_8.bin  --config_file config/bert_base_6layer_6conect.json  --learning_rate 2e-5 --num_workers 16 --tasks 1-2 --save_name pretrained \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8499900699336334
      ],
      "excerpt": "python -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 train_tasks.py --bert_model bert-base-uncased --from_pretrained save/bert_base_6_layer_6_connect_freeze_0/pytorch_model_8.bin  --config_file config/bert_base_6layer_6conect.json  --learning_rate 4e-5 --num_workers 9 --tasks 3 --save_name pretrained \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8604759490408824
      ],
      "excerpt": "python -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 train_tasks.py --bert_model bert-base-uncased --from_pretrained save/bert_base_6_layer_6_connect_freeze_0/pytorch_model_8.bin  --config_file config/bert_base_6layer_6conect.json  --learning_rate 4e-5 --num_workers 16 --tasks 4 --save_name pretrained \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9216236187889036
      ],
      "excerpt": "<img src=\"fig/vilbert.png\" width=\"400\" > \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dw-dengwei/vilbert/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "ViLBERT <img src=\"fig/vilbert_trim.png\" width=\"45\">",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "vilbert",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "dw-dengwei",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dw-dengwei/vilbert/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 23 Dec 2021 01:49:49 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Filckr27 - Y. Kalantidis, LG. Pueyo, M. Trevisiol, R. van Zwol, Y. Avrithis. Scalable Triangulation-based Logo Recognition. In Proceedings of ACM International Conference on Multimedia Retrieval (ICMR 2011), Trento, Italy, April 2011.\n\nDesign Guide for CNN: https://hackernoon.com/a-comprehensive-design-guide-for-image-classification-cnns-46091260fb92 - George Seif\nApril 2018\n\nInception Net Design: https://arxiv.org/pdf/1512.00567v3.pdf - Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens,\nZbigniew Wojna December 2015\n\nScene Classification with Inception-7: http://lsun.cs.princeton.edu/slides/Christian.pdf - Christian Szegedy, Vincent Vanhoucke, Julian\nIbarz\n\nUnderstanding how image quality affects Deep neural networks: https://arxiv.org/pdf/1604.04004.pdf - Samuel Dodge, Lina Karam April\n2016\n\nBenchmarks for popular CNN models: https://github.com/jcjohnson/cnn-benchmarks - Justin Johnson\n\nTutorials on CNN: http://ufldl.stanford.edu/tutorial/supervised/ConvolutionalNeuralNetwork/ - Stanford Education\n\nWhy do deep convolutional networks generalize so poorly to small image transformations?: https://arxiv.org/pdf/1805.12177.pdf - Aharon\nAzulay, Yair Weiss May 2018\n\nHow to Resize, Pad Image to Square Shape and Keep Its Aspect Ratio With Python: https://jdhao.github.io/2017/11/06/resize-image-to-\nsquare-with-padding/ - Jiedong Hao November 2017\n\nRotate images (correctly) with OpenCV and Python: https://www.pyimagesearch.com/2017/01/02/rotate-images-correctly-with-opencv-\nand-python/ - Adrian Rosebrock January 2017\n\nUnderstanding regularization for image classification and machine learning: https://www.pyimagesearch.com/2016/09/19/understanding-\nregularization-for-image-classification-and-machine-learning/ - - Adrian Rosebrock September 2016\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9994178053210071
      ],
      "excerpt": "I would recommend that you look at Siraj's video that was posted on June 2018. Best Laptop for Machine Learning (https://www.youtube.com/watch?v=dtFZrFKMiPI). And yes, I would highly recommend other videos on Machine Learning posted by Siraj. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/premthomas/keras-image-classification",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-07-28T06:35:18Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-05T14:19:56Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "In this study, we try to understand the limits of our system when running a Deep Learning training. The step to train a model is the most time consuming step of the model building process. With contraints put on the hardware, what can we do on the programming side to help us train models better? What if you had a limited amount of time? To try out our hand at augmentation, we will be using the Flickr27 dataset.  \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.973000168279976
      ],
      "excerpt": "This is a research project submitted for credit for a course that we just completed. The results seen here are subjective and should not be considered as final or accurate. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9471536154200975,
        0.9841597573240543,
        0.9413980760190821,
        0.9822506540869542,
        0.9789034737493109,
        0.9562816478782604,
        0.9922082221012374,
        0.9816571866247197,
        0.8329416848349033,
        0.9937477877671407,
        0.8209523763500447,
        0.8180843154003513,
        0.9567588029116127
      ],
      "excerpt": "  2. Can we achieve a target accuracy of at least 90%? (complex model, more data) \n  3. What is the amount of time the model takes for prediction? (simple model) \nThese objectives helps us limiting the amount of data we can process and the complexity of the model we can run. Trading of one for the other might help us understand which would provide better value in the long run. \nLet us view some of the points that we have to consider when working with Deep Learning models.  \n   1. The number of trainable parameters. Each layer in the model would add more capabilities to the model and possibly help in detecting more features but at the same time would increase the model complexity and therefore take more time to run. \n   2. The number of images that the model uses for training and validation. The more (and different) data we have, the model would be able to generalize more accurately. However, running large datasets will make the model run much longer. \n   3. The number of epochs we need to reach an acceptable accuracy. The more time, the more accurate. Sometimes to the point of memorizing. A model which reaches its target accuracy in 10 epochs would suggest that the model is very complex for the problem. \nThis is in no way an exhaustive list but they do constitute some of the most important points that we have to keep in mind.  \nTraining on a CPU with the parameters provided above proved to be next to impossible. Using the inbuilt GPU improved the training time by a factor of 10 (minimum).  \nRegarding the algorithm that we intend on using, we will be testing CNNs (Convolutional Neural Networks). Our intention is to test smaller custom architectures and then move to larger ones. While our code uses a modified version of the InceptionNet v3 architecture, we experimented with others as well and settled for the one with the best performance. \nFlick27 is a collection of 27 classes (such as Apple, Google, McDonald's) with each class containing about 35 images. The rules of Flickr27 state that each picture will contain only one of the 27 logos which have been categorized.The dataset is already broken up into \"train\" (30 images) and \"test\" (5 images) sets. When training any model, we need to have a train and validation set, we therefore broke the train set into two sets: a train (24 images) and a validation (6 images). It is best that you put all the image files into sub-folders whose names represent the class to which it belongs. The test set should not be used until you have acceptable training and validation accuracy.  \nEach of the class, which had 24 original images, were augmented to 1920 images and the validation set which contained 6 images used similar rules and were augmented to 480 images. This means that we will have 5760 images for training and 1440 images for validation. This will be the start of our test and periodically, we shall reduce the number of images (augmentations) to help us understand the impact of lesser data. \nLaptop with: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8226525502478987
      ],
      "excerpt": "  - Intel Core i7 - (7th gernation) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9150393857141185
      ],
      "excerpt": "The following are the list of Python Libraries that have been used for this project. All of these libraries can be installed with basic 'pip' commands. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.92723668141645,
        0.9782047334266752
      ],
      "excerpt": "Here is a list of the code files that were used and their functions: \n  - CreateModel.ipynb: Your first step is to create a model. There are two ways of creating models. You could import a model programmed in Keras directly (read this link for information on available models https://keras.io/applications/) or you could create your own model. In this case, we will be creating our own model using InceptionV3 as the base. The reason in doing so is that most models work with RGB images only and not with Grey-scale. There are a few variables that you will have to change: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.819361217345015,
        0.9894926109649939,
        0.9909321336151222,
        0.9339083654825759,
        0.9976141476647435,
        0.9014192709194802
      ],
      "excerpt": "    - Number of classes: This is important as this will represent your final output layer. In this example, the value is set to 3 \nTrainModel.ipynb: The next step is to train your model. This step could be the most time consuming process. Remember that this will depend on the system and its configuration that is available. In this example, we ran 100 epochs, each of which took approximately 200 seconds. Notice that in the 67th epoch, we have a training accuracy of 99.97% and a validation accuracy of 98.33%. This does represent an over-fitting problem but only very slightly. \nTestModel.ipynb: Finally, we use the trained model (with weights) and predicted classes for the images that we have in our validation set. The results are not as good as we expected. It was 13 correct predictions out of the 15 available, and this translated to 86.6% accuracy. This might also indicate that the model has started to memorize rather than generalize. \nWith a 99.97% training, 98.33% validation, and a 86.66% test, this algorithm does show it is possible to create a highly accurate model with less data.  \nPoint of note here: The development of this model was for a very specific use case and may not work on all instances of the brand logo. We have found reasonable success during our tests in a very specific and controlled source of new data to test the predictions on. We cannot guarantee that we will get the same levels of accuracies on all instances of the logo in new scenarios. \nFind a way to compare images and get a score of the similarity between them. This way we remove duplicates from our train and test sets, thus reducing the training time. This will also give us more space to perhaps even classify a fourth logo. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Grey-scale Image Classification using KERAS",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/premthomas/keras-image-classification/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Sun, 26 Dec 2021 22:16:40 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/premthomas/keras-image-classification/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "premthomas/keras-image-classification",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/premthomas/keras-image-classification/master/CreateAModel.ipynb",
      "https://raw.githubusercontent.com/premthomas/keras-image-classification/master/TestModel.ipynb",
      "https://raw.githubusercontent.com/premthomas/keras-image-classification/master/TrainModel.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8897392049871475
      ],
      "excerpt": "The following are the list of Python Libraries that have been used for this project. All of these libraries can be installed with basic 'pip' commands. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8966655221085083
      ],
      "excerpt": "matplotlib -pyplot \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9866708353533876
      ],
      "excerpt": "NOTE: It is highly recommended that you install these libraries within your environment before you run the code files mentioned in section 7. Some of these may already be available with your current python distribution. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/premthomas/keras-image-classification/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Grey-scale Image Classification using KERAS",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "keras-image-classification",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "premthomas",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/premthomas/keras-image-classification/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "In terms of software requirements, we will be using the following\n  - Python with Keras and Tensorflow\n  - GPU drivers and associated installations. Please refer to the link (https://www.tensorflow.org/install/install_windows) to check if and how to install the GPU\n  - Most of our programming will happen on Jupyter notebooks rather than python programs, as we will require to view output on a line-by-line execution level. Also Jupyter will help us format the code is a format that is presentable. \n  - Highly suggested (but not mandatory) is installing Anaconda. This will help you create separate environments in which you can execute your projects. Should any of the libraries that we use be upgraded or changed, the failure would be contained within the environment and would not affect all the other developments that you have\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Sun, 26 Dec 2021 22:16:40 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        0.9944484218006108,
        0.8111036989382164
      ],
      "excerpt": "* https://arxiv.org/pdf/1811.07522.pdf \n* https://jakevdp.github.io/PythonDataScienceHandbook/05.05-naive-bayes.html \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9785643756558006,
        0.9785643756558006,
        0.9944484218006108
      ],
      "excerpt": "* https://www.sciencedirect.com/science/article/pii/S1877050919302789 \n* https://www.sciencedirect.com/science/article/pii/S2405844018332067 \n* https://arxiv.org/pdf/1509.02971.pdf \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lukebhan/TwitterSentimentAnalysisTool",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-27T04:07:37Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-02T11:04:05Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8235995344060884,
        0.9695858368275372,
        0.9453124408536164
      ],
      "excerpt": "A highly adaptable tool for analyzing twitter data.  \n Auto scrapes Tweets based on user keyword from the previous week and applies a naive bayes classifier to analyze sentiment. Comes prebuilt with a docker postgres server managed by pgadmin \n Includes graphical visuals to analyze and categorize data.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.832302014685922
      ],
      "excerpt": "1. Clone the project  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9210934737607898
      ],
      "excerpt": "4. In terminal navigate to the project and cd to Docker \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693143834783335,
        0.9483413849940364
      ],
      "excerpt": "6. Check localhost:5555 and sign in to postgres using 'user' and 'password' as email and password respectively \n7. create a server with the login 'user' and 'password' and the network 172.XX.0.1 - Look at the terminal for the ip address to fill in the XX \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9556938439284667
      ],
      "excerpt": "The tool consists of a series of classes for managing and classifying twitterdata documented here: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8471467730671532,
        0.8114855744843709,
        0.9308215656245369
      ],
      "excerpt": "* add_{insert_property}(property): * Allows users to update defined properties \n* add_tweet_json(tweet) * When referencing the twitter API, tweets are returned in Json. This parses the json into a tweet obj \n* add_tweet(text,user, favorite_count, retweet_count, follower_count, date, nlp_score, given_score, tokenized_text): * Allows the user to add multiple properties at once. None of the properties are required \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9684915575131307
      ],
      "excerpt": "* Constructor: * Initializes the dict for storing counds a begins indexing \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8764236562825712
      ],
      "excerpt": "* remove_{insert_property}(property): * Removes any tweets in the list matching the proeprty \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8641642593142885,
        0.9530712366927665
      ],
      "excerpt": "* Constructor(consumer_key, consumer_secret, access_token, access_key): * Initializes conncetion with twitter api. Access token and key not required \n* search(keyword, user, start_date, end_date): * Searches twitter and returns a tweet list. Keyword is the only reqauired value. Combinations of {keyword, user},{keyword, user, start_date, end_date}, and {keyword,end_date} are supported \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9039313070661208,
        0.9512636207174452
      ],
      "excerpt": "* list_members(user, slug): * Gets members of a list \n* get_valuable_users(base_user): * Gets all members of all base_users lists \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8468615878896024,
        0.8230389452010228,
        0.9029534657126165
      ],
      "excerpt": "* num_rows(table_name, column_name): * Returns the number of rows in a column \n* update_column_by_id(table_name, column_name, tweet_id, new_value): * Updates the specified column name with a new value any time the id is the tweet_id \n* update_column_by_text(table_name, column_name, text, new_value): * Updates the specified column name with a new value any time the text is equal to the text param \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.940412942125671
      ],
      "excerpt": "* insert_tweet_list(table_name, tweet_list): * Inserts all tweets in order of their storage in tweet_list \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8331157013080948,
        0.9495108743404508
      ],
      "excerpt": "* process_tweets(list_tweets): * Tokenizes a list of tweets and returns their associated tokenized array and label \n* generate_token_array(token_arr): * Transforms the multiarray tokenized list of tweets into single dim array for inserting into db \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8481965992339465
      ],
      "excerpt": "* Constructor(data, db, db_name): * Initializes Widget Values. Set data equal to training set to classify tweets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This tool is developed to scrape twitter data, process the data, and then create either an unsupervised network to identify interesting patterns or can be designed to specifically verify a concept or idea. ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/luke-bhan/TwitterSentimentAnalysisTool/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Sun, 26 Dec 2021 10:42:17 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lukebhan/TwitterSentimentAnalysisTool/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "lukebhan/TwitterSentimentAnalysisTool",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9935459261120722
      ],
      "excerpt": "3. Install requirements.txt \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.897176225947782
      ],
      "excerpt": "Basic Usage: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8944915500358119
      ],
      "excerpt": "9. Run main.py, classify tweets and view projections \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8064454270243467
      ],
      "excerpt": "Advanced Usage: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8220076395621889
      ],
      "excerpt": "* Constructor: * Initializes all the tweet properties to none. Properties include: {Text, User, Retweet_Count, Date, Favorite Count, Follower Count, Nlp Score, Given Score, Tokenized Text \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9054283355306464
      ],
      "excerpt": "* write_data_to_csv(tweet_list, file_name): * Writes tweets to a csv file at the file_name path. File_name defaults to src/Database/output/tweetlist.csv \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8363534821440802
      ],
      "excerpt": "* write_userlist_to_csv(userlist, file_name): * Writes a list of users to a csv file at the file_name path. File_name defaults to src/Database/output/userlist.csv \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8523603572735398
      ],
      "excerpt": "* update_column_by_text(table_name, column_name, text, new_value): * Updates the specified column name with a new value any time the text is equal to the text param \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8267732247882519
      ],
      "excerpt": "* Constructor(data, db, db_name): * Initializes Widget Values. Set data equal to training set to classify tweets \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lukebhan/TwitterSentimentAnalysisTool/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "TwitterSentimentAnalysisTool (TSAT)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "TwitterSentimentAnalysisTool",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "lukebhan",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lukebhan/TwitterSentimentAnalysisTool/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 12,
      "date": "Sun, 26 Dec 2021 10:42:17 GMT"
    },
    "technique": "GitHub API"
  }
}
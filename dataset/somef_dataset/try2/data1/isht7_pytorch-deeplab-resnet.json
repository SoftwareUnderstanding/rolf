{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "A part of the code has been borrowed from [https://github.com/ry/tensorflow-resnet](https://github.com/ry/tensorflow-resnet).\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1606.00915",
      "https://arxiv.org/abs/1606.00915",
      "https://arxiv.org/abs/1606.00915",
      "https://arxiv.org/abs/1606.00915",
      "https://arxiv.org/abs/1606.00915"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9677640385174676
      ],
      "excerpt": "18 July 2017 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9499963145257574
      ],
      "excerpt": "24 June 2017 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/isht7/pytorch-deeplab-resnet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-04-09T23:45:01Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-28T02:46:40Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9268474484210846,
        0.9371869070929585
      ],
      "excerpt": "DeepLab resnet v2 model implementation in pytorch.  \nThe architecture of deepLab-ResNet has been replicated exactly as it is from the caffe implementation. This architecture calculates losses on input images over multiple scales ( 1x, 0.75x, 0.5x ). Losses are calculated individually over these 3 scales. In addition to these 3 losses, one more loss is calculated after merging the output score maps on the 3 scales. These 4 losses are added to calculate the total loss. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9002576643963828
      ],
      "excerpt": "Now, weights over the 3 scales ( 1x, 0.75x, 0.5x ) are shared as in the caffe implementation. Previously, each of the 3 scales had seperate weights. Results are almost same after making this change (more in the results section). However, the size of the trained .pth model has reduced significantly. Memory occupied on GPU(11.9 GB) and time taken (~3.5 hours) during training are same as before. Links to corresponding .pth files have been updated. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9513263583633692
      ],
      "excerpt": "Step 1: Convert init.caffemodel to a .pth file: init.caffemodel contains MS COCO trained weights. We use these weights as initilization for all but the final layer of our model. For the last layer, we use random gaussian with a standard deviation of 0.01 as the initialization. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8145446286819238,
        0.9273118006225848,
        0.9170243144417022,
        0.8852527038258123,
        0.9628512620169765
      ],
      "excerpt": "By default, snapshots are saved in every 1000 iterations in the  data/snapshots. \nThe following features have been implemented in this repository - \n* Training regime is the same as that of the caffe implementation - SGD with momentum is used, along with the poly lr decay policy. A weight decay has been used. The last layer has 10 times the learning rate of other layers. \n* The iter_size parameter of caffe has been implemented, effectively increasing the batch_size to batch_size times iter_size \n* Random flipping and random scaling of input has been used as data augmentation. The caffe implementation uses 4 fixed scales (0.5,0.75,1,1.25,1.5) while in the pytorch implementation, for each iteration scale is randomly picked in the range - [0.5,1.3]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8580821420606445,
        0.9815716927265491
      ],
      "excerpt": "When trained on VOC augmented training set (with 10582 images) using MS COCO pretrained initialization in pytorch, we get a validation performance of 72.40%(evalpyt2.py, on VOC). The corresponding .pth file can be downloaded here. This is in comparision to 75.54% that is acheived by using train_iter_20000.caffemodel released by authors, which can be replicated by running this file . The .pth model converted from .caffemodel using the first section also gives 75.54% mean IOU. \nA previous version of this file reported mean IOU of 78.48% on the pytorch trained model which is caclulated in a different way (evalpyt.py, Mean IOU is calculated for each image and these values are averaged together. This way of calculating mean IOU is different than the one used by authors).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "DeepLab resnet v2 model in pytorch",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/isht7/pytorch-deeplab-resnet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 124,
      "date": "Wed, 29 Dec 2021 12:17:43 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/isht7/pytorch-deeplab-resnet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "isht7/pytorch-deeplab-resnet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8921712151571791
      ],
      "excerpt": "To run convert_deeplab_resnet.py, deeplab v2 caffe and pytorch (python 2.7) are required. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8921712151571791
      ],
      "excerpt": "To run init_net_surgery .py, deeplab v2 caffe and pytorch (python 2.7) are required. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9512310978947944
      ],
      "excerpt": "To run train.py, pytorch (python 2.7) is required. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8038604193129073,
        0.9246227682586091,
        0.8674577382914065
      ],
      "excerpt": "To convert the caffemodel released by authors, download the deeplab-resnet caffemodel (train_iter_20000.caffemodel) pretrained on VOC into the data folder. After that, run \npython convert_deeplab_resnet.py \nto generate the corresponding pytorch model file (.pth). The generated .pth snapshot file can be used to get the exsct same test performace as offered by using the caffemodel in caffe (as shown by numbers in results section). If you do not want to generate the .pth file yourself, you can download it here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9001224866851876,
        0.9246227682586091
      ],
      "excerpt": "To convert init.caffemodel to a .pth file, run (or download the converted .pth here) \npython init_net_surgery.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503189345333785
      ],
      "excerpt": "python train.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503189345333785,
        0.8023295970838971
      ],
      "excerpt": "python train.py -h \nTo run train.py, pytorch (python 2.7) is required. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8103294601226677
      ],
      "excerpt": "* Batchnorm parameters are kept fixed during training. Also, caffe setting use_global_stats = True is reproduced during training. Running mean and variance are not calculated during training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python evalpyt.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091,
        0.8080290587873998
      ],
      "excerpt": "python evalpyt.py -h \nWhen trained on VOC augmented training set (with 10582 images) using MS COCO pretrained initialization in pytorch, we get a validation performance of 72.40%(evalpyt2.py, on VOC). The corresponding .pth file can be downloaded here. This is in comparision to 75.54% that is acheived by using train_iter_20000.caffemodel released by authors, which can be replicated by running this file . The .pth model converted from .caffemodel using the first section also gives 75.54% mean IOU. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/isht7/pytorch-deeplab-resnet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Isht Dwivedi\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "pytorch-deeplab-resnet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pytorch-deeplab-resnet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "isht7",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/isht7/pytorch-deeplab-resnet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 592,
      "date": "Wed, 29 Dec 2021 12:17:43 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "deeplab",
      "pytorch",
      "semantic-segmentation",
      "deeplab-resnet",
      "pascal-voc"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Note that this repository has been tested with python 2.7 only.\n",
      "technique": "Header extraction"
    }
  ]
}
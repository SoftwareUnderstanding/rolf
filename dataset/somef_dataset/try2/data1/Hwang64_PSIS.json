{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1805.09300"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8111036989382164
      ],
      "excerpt": "<img src=\"https://github.com/Hwang64/PSIS/blob/master/img/pipeline.jpg\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266,
        0.9781574687631479
      ],
      "excerpt": "|   ori  |  27.3   | 46.0 | 28.1 |  10.7  | 26.8  |  46.0 |  \n|   Context-DA  |  28.0   | 46.7 | 28.9 |  10.7  | 27.8  |  47.0 | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Hwang64/PSIS",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-28T07:03:00Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-03T11:00:44Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.996384470262484
      ],
      "excerpt": "We proposed a simple yet effective data augmentation for object detection, whose core is a progressive and selective instance-switching (PSIS) method for synthetic image generation. The proposed PSIS as data augmentation for object detection benefits several merits, i.e., increase of diversity of samples, keep of contextual coherence in the original images, no requirement of external datasets, and  consideration of instance balance and class importance. Experimental results demonstrate the effectiveness of our PSIS against the existing data augmentation, including horizontal flipping and training time augmentation for FPN, segmentation masks and training time augmentation for Mask R-CNN, multi-scale training strategy for SNIPER, and Context-DA for BlitzNet. The experiments are conducted on the challenging MS COCO benchmark, and results demonstrate our PSIS brings clear improvement over various state-of-the-art detectors \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8813376261320572
      ],
      "excerpt": "Use the code extract_annotation_pair.py to generate quadruple for each category which satisfy the conditions. The ouput quadruple will saved in a txt file. We also provide the Omega_uni, Omega_equ and Omega_aug in dataset which follow the instance distribution in the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8678642869087744,
        0.9798382565193027,
        0.9734192982843595
      ],
      "excerpt": "The code for class imbalance loss is in \\class_imbalance_loss directory, please refer to the \\class_imbalance_loss\\README.md for detail using. \nWe directly employ this dataset to train four state-of-the-art detectors (i.e., FPN , Mask R-CNN , BlitzNet and SNIPER), and report results on test server for comparing with other augmentation methods. \nWe adopt PSIS to FPN by the publicly availabel toolkit. The configuration files are in the configs/FPN. For more training and testing information, please refer to the code. The results are shown as belows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "|  psis(model)  |  39.8   | 61.0 | 43.4|  22.7 | 44.2  |  52.1 | 32.6 | 51.1  | 53.6 |  34.8 |  59.0 |  68.5 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9561796767415239,
        0.9877519334201663
      ],
      "excerpt": "\u00d72 means two times training epochs, which is regarded as training-time augmentation and * indicates no horizontal fliping. Above results clearly demonstrate our PSIS is superior and complementary to horizontal flipping and training-time augmentation methods. \nWe evaluate PSIS using Mask R-CNN. The configuration files are in the configs/Mask R-CNN. For more training and testing information, please refer to the code. The results are shown as belows:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9563513657226417,
        0.9876754208739305
      ],
      "excerpt": "\u00d72 means two times training epochs, which is regarded as training-time augmentation. Above results clearly demonstrate our PSIS is superior and complementary to training-time augmentation method. \nWe evaluate PSIS with the recently proposed context-based data augmentation method. We adopt PSIS to BlitzNet, For more traning and testing information, please refer to code. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9583582752856209
      ],
      "excerpt": "We use SNIPER to verify the effectiveness of PSIS under multi-scale training strategy. The configuration files are in the configs/SNIPER. For more training and testing information, please refer to the code. The results are shown as belows:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Data Augmentation for Object Detection via Progressive and Selective Instance-Switching",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Hwang64/PSIS/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Mon, 20 Dec 2021 19:04:51 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Hwang64/PSIS/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Hwang64/PSIS",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8830503539333286
      ],
      "excerpt": "OS: Linux 16.02 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9746151682232777,
        0.9460142429167908
      ],
      "excerpt": "CUDA: version 8.0 \nCUDNN: version 5.1 \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8369399081663577
      ],
      "excerpt": "For generting images, just modify the ANN2ann_FILE in file instance_switch(e.g., dataset/omega_uni.txt) and the synthetic images and annotation file will be generated in the corresponding directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8176326963976721
      ],
      "excerpt": "|   ori  |  43.4   | 62.8 | 48.8 |  27.4  | 45.2  |  56.2 | N/A | N/A  | N/A |  N/A |  N/A |  N/A | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Hwang64/PSIS/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C++",
      "Cuda",
      "MATLAB"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "PSIS",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "PSIS",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Hwang64",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Hwang64/PSIS/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 74,
      "date": "Mon, 20 Dec 2021 19:04:51 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Use the code ```extract_mask.m``` to generate instance mask for the images in MS COCO 2017 training dataset.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "We verify the generalization ability of our PSIS on instance segmentation task of MS COCO 2017. The instance segmetatnion results are shown belows:\n\n|Training Sets | AP@0.50:0.95 | AP@0.50 | AP@0.75| AP@Small | AP@Med. | AP@Large |  AR@1 | AR@10 | AR@100 | AR@Small | AR@Med. | AR@Large  | \n|--------------|:------------:|:-------:|:------:|:--------:|:-------:|:--------:|:-----:|:-----:|:------:|:--------:|:-------:|:----:|\n|   ori  |  35.9   | 57.7 | 38.4 |  19.2  | 39.7  |  49.7 | 30.5 | 47.3  | 49.6 |  29.7 |  53.8 |  65.8 |\n|  psis([model](https://drive.google.com/open?id=13kB4zvwR__O9vSGz9cvy4Br3C-mwSTGZ))  |  36.7   | 58.4 | 39.4 |  19.0  | 40.6  |  50.2 | 31.0 | 48.2  | 50.3 |  29.8 |  54.4 |  66.9 |\n| ori\u00d72  |  36.6   | 58.2 | 39.2 |  18.5  |  40.3 |  50.4 | 31.0 | 47.7  | 49.7 |  29.5 |  53.5 |  66.6 |\n| psis\u00d72([Coming Soon]()) |  37.1   | 58.8 | 39.9 |  19.3  |  41.2 |  50.8 | 31.1 | 47.7  | 50.4 |  30.2 |  54.5 |  67.9 |\n\nAbove results clearly show PSIS offers a new and complementary way to use instance masks for improving both detection and segmentation performance.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Here we show some examples of synthetic images generated by our IS strategy. The new (switched) instances are denoted in red boxes, and our instance-switching strategy can clearly preserve contextual coherence in the original images.\n\n<img src=\"https://github.com/Hwang64/PSIS/blob/master/img/examples.jpg\">\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "citation": [
    {
      "confidence": [
        0.8609308683896412
      ],
      "excerpt": "<a href=\"https://nlp.stanford.edu/projects/coref.shtml\"><img src=\"https://nlp.stanford.edu/projects/corefexample.png\" width=\"300\" /></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8874636724325291
      ],
      "excerpt": "Sequence tagging tasks include Named Entity Recognition (NER) and Fine-grained NER. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9056674988540252
      ],
      "excerpt": "Text + Vision \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8504479146659838
      ],
      "excerpt": "pair-classification-esim - Enhanced LSTM trained on SNLI. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9497744906630237
      ],
      "excerpt": "structured-prediction-srl - A reimplementation of a deep BiLSTM sequence prediction model (Stanovsky et al., 2018) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/allenai/allennlp-models",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-10T00:22:21Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T07:33:20Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8464329800418905,
        0.9907777542409757
      ],
      "excerpt": "Using Docker \nThis repository contains the components - such as DatasetReader, Model, and Predictor classes - for applying AllenNLP to a wide variety of NLP tasks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9743145945857622
      ],
      "excerpt": "This is an overview of the tasks supported by the AllenNLP Models library along with the corresponding components provided, organized by category. For a more comprehensive overview, see the AllenNLP Models documentation or the Paperswithcode page. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9708977490655324
      ],
      "excerpt": "Coreference resolution tasks require finding all of the expressions in a text that refer to common entities. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9271447919966229
      ],
      "excerpt": "See nlp.stanford.edu/projects/coref for more details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9390093386838072
      ],
      "excerpt": "This is a broad category for tasks such as Summarization that involve generating unstructered and often variable-length text. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9111421017518314,
        0.8133641697313864
      ],
      "excerpt": "Language modeling tasks involve learning a probability distribution over sequences of tokens. \n\ud83d\udee0 Components provided: Several language model implementations, such as a Masked LM and a Next Token LM. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9128736270051515,
        0.9123977554469754
      ],
      "excerpt": "Multiple choice tasks require selecting a correct choice among alternatives, where the set of choices may be different for each input. This differs from classification where the set of choices is predefined and fixed across all inputs. \n\ud83d\udee0 Components provided: A transformer-based multiple choice model and a handful of dataset readers for specific datasets. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9680589555656947
      ],
      "excerpt": "Pair classification is another broad category that contains tasks such as Textual Entailment, which is to determine whether, for a pair of sentences, the facts in the first sentence imply the facts in the second. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9659046471571552,
        0.9065250741296101
      ],
      "excerpt": "Reading comprehension tasks involve answering questions about a passage of text to show that the system understands the passage. \n\ud83d\udee0 Components provided: Models such as BiDAF and a transformer-based QA model, as well as readers for datasets such as DROP, QuAC, and SQuAD. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9761781540470551
      ],
      "excerpt": "Structured prediction includes tasks such as Semantic Role Labeling (SRL), which is for determining the latent predicate argument structure of a sentence and providing representations that can answer basic questions about sentence meaning, including who did what to whom, etc. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8338768753886198
      ],
      "excerpt": "\ud83d\udee0 Components provided: A Conditional Random Field model and dataset readers for datasets such as  CoNLL-2000, CoNLL-2003, CCGbank, and OntoNotes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9924504022905928
      ],
      "excerpt": "This is a catch-all category for any text + vision multi-modal tasks such Visual Question Answering (VQA), the task of generating a answer in response to a natural language question about the contents of an image. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9935098269221039
      ],
      "excerpt": "Many of these models are also hosted on the AllenNLP Demo and the AllenNLP Project Gallery. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9646476478284655
      ],
      "excerpt": "The output is a dictionary that maps the model IDs to their ModelCard: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9087612488081873
      ],
      "excerpt": "You can load a Predictor for any of these models with the pretrained.load_predictor() helper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9080994949066663
      ],
      "excerpt": "Here is a list of pre-trained models currently available. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.954758601683278,
        0.8815847382069026
      ],
      "excerpt": "coref-spanbert - Higher-order coref with coarse-to-fine inference (with SpanBERT embeddings). \nevaluate_rc-lerc - A BERT model that scores candidate answers from 0 to 1. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9416076103224206,
        0.9415531386337457,
        0.94394537691748,
        0.9294934910676186,
        0.9294934910676186,
        0.9294934910676186,
        0.9051467020738087,
        0.9051467020738087,
        0.8498061180048394,
        0.9125816858373373
      ],
      "excerpt": "glove-sst - LSTM binary classifier with GloVe embeddings. \nlm-masked-language-model - BERT-based masked language model \nlm-next-token-lm-gpt2 - OpenAI's GPT-2 language model that generates the next token. \nmc-roberta-commonsenseqa - RoBERTa-based multiple choice model for CommonSenseQA. \nmc-roberta-piqa - RoBERTa-based multiple choice model for PIQA. \nmc-roberta-swag - RoBERTa-based multiple choice model for SWAG. \nnlvr2-vilbert - ViLBERT-based model for Visual Entailment. \nnlvr2-vilbert - ViLBERT-based model for Visual Entailment. \npair-classification-adversarial-binary-gender-bias-mitigated-roberta-snli - RoBERTa finetuned on SNLI with adversarial binary gender bias mitigation. \npair-classification-binary-gender-bias-mitigated-roberta-snli - RoBERTa finetuned on SNLI with binary gender bias mitigation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8457795504821178
      ],
      "excerpt": "pair-classification-roberta-rte - A pair classification model patterned after the proposed model in Devlin et al, fine-tuned on the SuperGLUE RTE corpus \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9844044108519979,
        0.9710087041128412
      ],
      "excerpt": "rc-bidaf-elmo - BiDAF model with ELMo embeddings instead of GloVe. \nrc-bidaf - BiDAF model with GloVe embeddings. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9686905700872311,
        0.9562408004055258,
        0.894732639902684,
        0.9668507742968228,
        0.894732639902684,
        0.9364739246288152,
        0.8402612545073628
      ],
      "excerpt": "rc-transformer-qa - A reading comprehension model patterned after the proposed model in Devlin et al, with improvements borrowed from the SQuAD model in the transformers project \nroberta-sst - RoBERTa-based binary classifier for Stanford Sentiment Treebank \nsemparse-nlvr - The model is a semantic parser trained on Cornell NLVR. \nsemparse-text-to-sql - This model is an implementation of an encoder-decoder architecture with LSTMs and constrained type decoding trained on the ATIS dataset. \nsemparse-wikitables - The model is a semantic parser trained on WikiTableQuestions. \nstructured-prediction-biaffine-parser - A neural model for dependency parsing using biaffine classifiers on top of a bidirectional LSTM. \nstructured-prediction-constituency-parser - Constituency parser with character-based ELMo embeddings \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9779075313844648
      ],
      "excerpt": "tagging-fine-grained-crf-tagger - This model identifies a broad range of 16 semantic types in the input text. It is a reimplementation of Lample (2016) and uses a biLSTM with a CRF layer, character embeddings and ELMo embeddings. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8708229118049667,
        0.9850524003726768,
        0.9850524003726768
      ],
      "excerpt": "ve-vilbert - ViLBERT-based model for Visual Entailment. \nvgqa-vilbert - ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language. \nvqa-vilbert - ViLBERT (short for Vision-and-Language BERT), is a model for learning task-agnostic joint representations of image content and natural language. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8347498105294331
      ],
      "excerpt": "Both allennlp and allennlp-models are developed and tested side-by-side, so they should be kept up-to-date with each other. If you look at the GitHub Actions workflow for allennlp-models, it's always tested against the main branch of allennlp. Similarly, allennlp is always tested against the main branch of allennlp-models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9684786390120786
      ],
      "excerpt": "isolation and consistency, and also makes it easy to distribute your \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9383686725516074
      ],
      "excerpt": "on Docker Hub to see which CUDA versions are available for a given RELEASE. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Officially supported AllenNLP models",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/allenai/allennlp-models/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 121,
      "date": "Wed, 29 Dec 2021 23:19:39 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/allenai/allennlp-models/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "allenai/allennlp-models",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/allenai/allennlp-models/main/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/allenai/allennlp-models/tree/main/docs"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/allenai/allennlp-models/main/allennlp_models/coref/tools/compile_coref_data.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9409591197467996,
        0.913345215760235
      ],
      "excerpt": "From PyPI \nFrom source \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.932063767136626
      ],
      "excerpt": "To programmatically list the available models, you can run the following from a Python session: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9901062091090956,
        0.997566464659364,
        0.985506860648702,
        0.997566464659364,
        0.9736629876602173
      ],
      "excerpt": "allennlp-models is available on PyPI. To install with pip, just run \npip install allennlp-models \nNote that the allennlp-models package is tied to the allennlp core package. Therefore when you install the models package you will get the corresponding version of allennlp (if you haven't already installed allennlp). For example, \npip install allennlp-models==2.2.0 \npip freeze | grep allennlp \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9950993671228536,
        0.9772873005823686,
        0.9892278522053876,
        0.9771384723171962,
        0.999746712887969,
        0.9961985326545059,
        0.9660926869526204
      ],
      "excerpt": "If you intend to install the models package from source, then you probably also want to install allennlp from source. \nOnce you have allennlp installed, run the following within the same Python environment: \ngit clone https://github.com/allenai/allennlp-models.git \ncd allennlp-models \nALLENNLP_VERSION_OVERRIDE='allennlp' pip install -e . \npip install -r dev-requirements.txt \nThe ALLENNLP_VERSION_OVERRIDE environment variable ensures that the allennlp dependency is unpinned so that your local install of allennlp will be sufficient. If, however, you haven't installed allennlp yet and don't want to manage a local install, just omit this environment variable and allennlp will be installed from the main branch on GitHub. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8613598357697477
      ],
      "excerpt": "If you have GPUs available, you also need to install the nvidia-docker runtime. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.926422947698878
      ],
      "excerpt": "    --build-arg RELEASE=1.2.2 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.890625732822715
      ],
      "excerpt": "Just replace the RELEASE and CUDA build args with what you need. You can check the available tags \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9096104964140866,
        0.9096104964140866
      ],
      "excerpt": "    --build-arg ALLENNLP_COMMIT=d823a2591e94912a6315e429d0fe0ee2efb4b3ee \\ \n    --build-arg ALLENNLP_MODELS_COMMIT=01bc777e0d89387f03037d398cd967390716daf1 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8493022377157884,
        0.8778715115153837
      ],
      "excerpt": "Once you've built your image, you can run it like this: \nmkdir -p $HOME/.allennlp/ \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8998492179403905
      ],
      "excerpt": "from allennlp_models import pretrained \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216270093103228
      ],
      "excerpt": "For example: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/allenai/allennlp-models/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jsonnet",
      "Gherkin",
      "Perl",
      "Makefile",
      "Shell",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Apache License 2.0",
      "url": "https://api.github.com/licenses/apache-2.0"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'                                 Apache License\\n                           Version 2.0, January 2004\\n                        http://www.apache.org/licenses/\\n\\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\\n\\n   1. Definitions.\\n\\n      \"License\" shall mean the terms and conditions for use, reproduction,\\n      and distribution as defined by Sections 1 through 9 of this document.\\n\\n      \"Licensor\" shall mean the copyright owner or entity authorized by\\n      the copyright owner that is granting the License.\\n\\n      \"Legal Entity\" shall mean the union of the acting entity and all\\n      other entities that control, are controlled by, or are under common\\n      control with that entity. For the purposes of this definition,\\n      \"control\" means (i) the power, direct or indirect, to cause the\\n      direction or management of such entity, whether by contract or\\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\\n      outstanding shares, or (iii) beneficial ownership of such entity.\\n\\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\\n      exercising permissions granted by this License.\\n\\n      \"Source\" form shall mean the preferred form for making modifications,\\n      including but not limited to software source code, documentation\\n      source, and configuration files.\\n\\n      \"Object\" form shall mean any form resulting from mechanical\\n      transformation or translation of a Source form, including but\\n      not limited to compiled object code, generated documentation,\\n      and conversions to other media types.\\n\\n      \"Work\" shall mean the work of authorship, whether in Source or\\n      Object form, made available under the License, as indicated by a\\n      copyright notice that is included in or attached to the work\\n      (an example is provided in the Appendix below).\\n\\n      \"Derivative Works\" shall mean any work, whether in Source or Object\\n      form, that is based on (or derived from) the Work and for which the\\n      editorial revisions, annotations, elaborations, or other modifications\\n      represent, as a whole, an original work of authorship. For the purposes\\n      of this License, Derivative Works shall not include works that remain\\n      separable from, or merely link (or bind by name) to the interfaces of,\\n      the Work and Derivative Works thereof.\\n\\n      \"Contribution\" shall mean any work of authorship, including\\n      the original version of the Work and any modifications or additions\\n      to that Work or Derivative Works thereof, that is intentionally\\n      submitted to Licensor for inclusion in the Work by the copyright owner\\n      or by an individual or Legal Entity authorized to submit on behalf of\\n      the copyright owner. For the purposes of this definition, \"submitted\"\\n      means any form of electronic, verbal, or written communication sent\\n      to the Licensor or its representatives, including but not limited to\\n      communication on electronic mailing lists, source code control systems,\\n      and issue tracking systems that are managed by, or on behalf of, the\\n      Licensor for the purpose of discussing and improving the Work, but\\n      excluding communication that is conspicuously marked or otherwise\\n      designated in writing by the copyright owner as \"Not a Contribution.\"\\n\\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\\n      on behalf of whom a Contribution has been received by Licensor and\\n      subsequently incorporated within the Work.\\n\\n   2. Grant of Copyright License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      copyright license to reproduce, prepare Derivative Works of,\\n      publicly display, publicly perform, sublicense, and distribute the\\n      Work and such Derivative Works in Source or Object form.\\n\\n   3. Grant of Patent License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      (except as stated in this section) patent license to make, have made,\\n      use, offer to sell, sell, import, and otherwise transfer the Work,\\n      where such license applies only to those patent claims licensable\\n      by such Contributor that are necessarily infringed by their\\n      Contribution(s) alone or by combination of their Contribution(s)\\n      with the Work to which such Contribution(s) was submitted. If You\\n      institute patent litigation against any entity (including a\\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\\n      or a Contribution incorporated within the Work constitutes direct\\n      or contributory patent infringement, then any patent licenses\\n      granted to You under this License for that Work shall terminate\\n      as of the date such litigation is filed.\\n\\n   4. Redistribution. You may reproduce and distribute copies of the\\n      Work or Derivative Works thereof in any medium, with or without\\n      modifications, and in Source or Object form, provided that You\\n      meet the following conditions:\\n\\n      (a) You must give any other recipients of the Work or\\n          Derivative Works a copy of this License; and\\n\\n      (b) You must cause any modified files to carry prominent notices\\n          stating that You changed the files; and\\n\\n      (c) You must retain, in the Source form of any Derivative Works\\n          that You distribute, all copyright, patent, trademark, and\\n          attribution notices from the Source form of the Work,\\n          excluding those notices that do not pertain to any part of\\n          the Derivative Works; and\\n\\n      (d) If the Work includes a \"NOTICE\" text file as part of its\\n          distribution, then any Derivative Works that You distribute must\\n          include a readable copy of the attribution notices contained\\n          within such NOTICE file, excluding those notices that do not\\n          pertain to any part of the Derivative Works, in at least one\\n          of the following places: within a NOTICE text file distributed\\n          as part of the Derivative Works; within the Source form or\\n          documentation, if provided along with the Derivative Works; or,\\n          within a display generated by the Derivative Works, if and\\n          wherever such third-party notices normally appear. The contents\\n          of the NOTICE file are for informational purposes only and\\n          do not modify the License. You may add Your own attribution\\n          notices within Derivative Works that You distribute, alongside\\n          or as an addendum to the NOTICE text from the Work, provided\\n          that such additional attribution notices cannot be construed\\n          as modifying the License.\\n\\n      You may add Your own copyright statement to Your modifications and\\n      may provide additional or different license terms and conditions\\n      for use, reproduction, or distribution of Your modifications, or\\n      for any such Derivative Works as a whole, provided Your use,\\n      reproduction, and distribution of the Work otherwise complies with\\n      the conditions stated in this License.\\n\\n   5. Submission of Contributions. Unless You explicitly state otherwise,\\n      any Contribution intentionally submitted for inclusion in the Work\\n      by You to the Licensor shall be under the terms and conditions of\\n      this License, without any additional terms or conditions.\\n      Notwithstanding the above, nothing herein shall supersede or modify\\n      the terms of any separate license agreement you may have executed\\n      with Licensor regarding such Contributions.\\n\\n   6. Trademarks. This License does not grant permission to use the trade\\n      names, trademarks, service marks, or product names of the Licensor,\\n      except as required for reasonable and customary use in describing the\\n      origin of the Work and reproducing the content of the NOTICE file.\\n\\n   7. Disclaimer of Warranty. Unless required by applicable law or\\n      agreed to in writing, Licensor provides the Work (and each\\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\\n      implied, including, without limitation, any warranties or conditions\\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\\n      PARTICULAR PURPOSE. You are solely responsible for determining the\\n      appropriateness of using or redistributing the Work and assume any\\n      risks associated with Your exercise of permissions under this License.\\n\\n   8. Limitation of Liability. In no event and under no legal theory,\\n      whether in tort (including negligence), contract, or otherwise,\\n      unless required by applicable law (such as deliberate and grossly\\n      negligent acts) or agreed to in writing, shall any Contributor be\\n      liable to You for damages, including any direct, indirect, special,\\n      incidental, or consequential damages of any character arising as a\\n      result of this License or out of the use or inability to use the\\n      Work (including but not limited to damages for loss of goodwill,\\n      work stoppage, computer failure or malfunction, or any and all\\n      other commercial damages or losses), even if such Contributor\\n      has been advised of the possibility of such damages.\\n\\n   9. Accepting Warranty or Additional Liability. While redistributing\\n      the Work or Derivative Works thereof, You may choose to offer,\\n      and charge a fee for, acceptance of support, warranty, indemnity,\\n      or other liability obligations and/or rights consistent with this\\n      License. However, in accepting such obligations, You may act only\\n      on Your own behalf and on Your sole responsibility, not on behalf\\n      of any other Contributor, and only if You agree to indemnify,\\n      defend, and hold each Contributor harmless for any liability\\n      incurred by, or claims asserted against, such Contributor by reason\\n      of your accepting any such warranty or additional liability.\\n\\n   END OF TERMS AND CONDITIONS\\n\\n   APPENDIX: How to apply the Apache License to your work.\\n\\n      To apply the Apache License to your work, attach the following\\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\\n      replaced with your own identifying information. (Don\\'t include\\n      the brackets!)  The text should be enclosed in the appropriate\\n      comment syntax for the file format. We also recommend that a\\n      file or class name and description of purpose be included on the\\n      same \"printed page\" as the copyright notice for easier\\n      identification within third-party archives.\\n\\n   Copyright [yyyy] [name of copyright owner]\\n\\n   Licensed under the Apache License, Version 2.0 (the \"License\");\\n   you may not use this file except in compliance with the License.\\n   You may obtain a copy of the License at\\n\\n       http://www.apache.org/licenses/LICENSE-2.0\\n\\n   Unless required by applicable law or agreed to in writing, software\\n   distributed under the License is distributed on an \"AS IS\" BASIS,\\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n   See the License for the specific language governing permissions and\\n   limitations under the License.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# In this README",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "allennlp-models",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "allenai",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/allenai/allennlp-models/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "AkshitaB",
        "body": "## What's new\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- Seperate start/end token check in `Seq2SeqDatasetReader` for source and target tokenizers.\r\n\r\n## Commits\r\n\r\nca7e79a6 Prepare for release v2.8.0\r\n5ff0f79f Seperate start/end token check for source and target tokenizer (#308)\r\n84ba7cf0 Fix the `IndexError` when `CNNDailyMailDatasetReader` reads test data. (#306)\r\nd1b81c36 Update torch requirement from <1.10.0,>=1.7.0 to >=1.7.0,<1.11.0 (#305)\r\n39557dd8 pin NLTK to avoid breaking change to meteor score (#304)\r\nc814aa1a Finished record reader (#300)\r\nc57b9315 fix tests for new overrides functionality (#302)\r\n25e2b1af require Python>=3.7 (#301)\r\n\r\n",
        "dateCreated": "2021-11-05T23:03:54Z",
        "datePublished": "2021-11-05T23:05:54Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v2.8.0",
        "name": "v2.8.0",
        "tag_name": "v2.8.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v2.8.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/52820867",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v2.8.0"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "## What's new\r\n\r\n### Added \ud83c\udf89\r\n\r\n- Added some additional `__init__()` parameters to the `T5` model in `allennlp_models.generation` for customizing.\r\n  beam search and other options.\r\n- Added a configuration file for fine-tuning `t5-11b` on CCN-DM (requires at least 8 GPUs).\r\n- Added a configuration to train on the PIQA dataset with AllenNLP Tango.\r\n- Added a transformer classification model.\r\n- Added a configuration to train on the IMDB dataset with AllenNLP Tango.\r\n\r\n### Fixed \u2705\r\n\r\n- Fixed tests for Spacy versions greater than 3.1.\r\n- Fixed the last step decoding when training CopyNet.\r\n- Allow singleton clusters in `ConllCorefScores`.\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- Updated `VisionReader` to yield all of `RegionDetectorOutput`'s keys in processing.\r\n\r\n## Commits\r\n\r\nae7942eb Prepare for release v2.7.0\r\na8a34869 update conll (#298)\r\n54de9d6d IMDB Model (#297)\r\n8d5b21f8 Fix a bug in the last decoding step of training CopyNet (#296)\r\n1156e493 Bump conllu from 4.4 to 4.4.1 (#295)\r\n31649f57 PIQA in Tango (#294)\r\n4eb7c27d Updating vision reader to also produce class probs and labels (#293)\r\n7b7b9c14 Spacy new version (#290)\r\nf991ae0d Update mkdocs-material requirement from <7.2.0,>=5.5.0 to >=5.5.0,<7.3.0 (#289)\r\ndb0e21ae FairScale integration and T5-11B fine-tuning (#271)",
        "dateCreated": "2021-09-01T22:28:13Z",
        "datePublished": "2021-09-01T22:28:33Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v2.7.0",
        "name": "v2.7.0",
        "tag_name": "v2.7.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v2.7.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/48851503",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v2.7.0"
      },
      {
        "authorType": "User",
        "author_name": "dirkgr",
        "body": "## What's new\r\n\r\n### Added \ud83c\udf89\r\n\r\n- Added support for NLVR2 visual entailment, including a data loader, two models, and training configs.\r\n- Added `StanfordSentimentTreeBankDatasetReader.apply_token_indexers()` to add token_indexers rather than in `text_to_instance` \r\n- Added `AdversarialBiasMitigator` tests.\r\n- Added `adversarial-binary-gender-bias-mitigated-roberta-snli` model.\r\n- Added support for Flickr30k image retrieval, including a dataset reader, a model, and a training config.\r\n- Added `label_smoothing` parameter to `CopyNetSeq2Rel` to smooth generation targets.\r\n- Added `vocab` as argument to `beam_search.construct` in all `generation` models.\r\n\r\n### Fixed \u2705\r\n\r\n- Fixed `binary-gender-bias-mitigated-roberta-snli` model card to indicate that model requires `allennlp@v2.5.0`.\r\n- Fixed registered model name in the `pair-classification-roberta-rte` and `vgqa-vilbert` model cards.\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- The multiple choice models now use the new `TransformerTextField` and the transformer toolkit generally.\r\n\r\n## Commits\r\n\r\n146ea765 Pass vocab to beam search (#288)\r\n698b7efc TransformerTextField in the MC models (#286)\r\n07fa1241 Add label smoothing to CopyNet (#287)\r\ne47da991 Flickr30k (#285)\r\nfb35b2d6 Bump mypy from 0.812 to 0.910 (#284)\r\n90f62593 Update Python environment setup in GitHub Actions (#283)\r\nbdf82a18 added AdversarialBiasMitigator tests and model (#281)\r\n8d2d84f9 Test fixes (#282)\r\nef004d3e Update torch requirement from <1.9.0,>=1.7.0 to >=1.7.0,<1.10.0 (#280)\r\n8cb4b085 small CI fix\r\nd7214873 add `StanfordSentimentTreeBankDatasetReader.apply_token_indexers()` (#273)\r\n996adff6 Update pair-classification-binary-gender-bias-mitigated-roberta-snli.json with correct versions of allennlp-models and allennlp (#272)\r\nb17d114e some model card fixes (#274)\r\n0a7901c9 Revert \"CHANGELOG\"\r\n38064e1f CHANGELOG\r\n664f38fe Nlvr2 (#265)\r\ne395e633 tick version for nightly releases\r\n",
        "dateCreated": "2021-07-19T23:09:33Z",
        "datePublished": "2021-07-19T23:10:15Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v2.6.0",
        "name": "",
        "tag_name": "v2.6.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v2.6.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/46442210",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v2.6.0"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "`allennlp-models` release corresponding to [`allennlp v2.5.0`](https://github.com/allenai/allennlp/releases/tag/v2.5.0).\r\n\r\n## What's new\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- Updated all instances of `sanity_checks` to `confidence_checks`.\r\n- The `num_serialized_models_to_keep` parameter is now called `keep_most_recent_by_count`.\r\n- Improvements to the vision models and other models that use `allennlp.modules.transformer` under the hood.\r\n\r\n### Added \ud83c\udf89\r\n\r\n- Added tests for checklist suites for SQuAD-style reading comprehension models (`bidaf`), and textual entailment models (`decomposable_attention` and `esim`).\r\n- Added an optional \"weight\" parameter to `CopyNetSeq2Seq.forward()` for calculating a weighted loss instead of the simple average over the\r\n  the negative log likelihoods for each instance in the batch.\r\n- Added a way to initialize the `SrlBert` model without caching/loading pretrained transformer weights.\r\n  You need to set the `bert_model` parameter to the dictionary form of the corresponding `BertConfig` from HuggingFace.\r\n  See [PR #257](https://github.com/allenai/allennlp-models/pull/257) for more details.\r\n- Added a `beam_search` parameter to the `generation` models so that a `BeamSearch` object can be specified in their configs.\r\n- Added a binary gender bias-mitigated RoBERTa model for SNLI.\r\n\r\n## Commits\r\n\r\na98e13a4 Specify BeamSearch as a parameter (#267)\r\n5dcf2b94 Added binary gender bias-mitigated RoBERTa model for SNLI (#268)\r\n79d25e5f tick version for nightly release\r\n50a04527 Checkpointing (#269)\r\n07f1b560 Update nr-interface requirement from <0.0.4 to <0.0.6 (#266)\r\n8bf4e1c7 cancel redundant GH Actions builds (#270)\r\n2f1b7791 Update roberta-sst.json (#264)\r\ndea182c4 Avoid duplicate tokenization of context in training (#263)\r\ndc633f11 Updates for transformer toolkit changes (#261)\r\n53c61dd0 Renaming sanity_checks to confidence_checks (#262)\r\n3ec87c7a set codecov to 'informational' mode\r\n45068bb4 Vgqa dataset reader (#260)\r\n77315fcf Add weighting option to CopyNet (#258)\r\n845fe4cc Add way to initialize SrlBert without pretrained BERT weights (#257)\r\nab1e86a4 Checklist tests (#255)\r\n659c71f8 Update pretrained.py: Quick fix to be able to load pertained_models directly to GPU. (#254)",
        "dateCreated": "2021-06-03T17:22:16Z",
        "datePublished": "2021-06-03T17:36:51Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v2.5.0",
        "name": "v2.5.0",
        "tag_name": "v2.5.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v2.5.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/44061196",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v2.5.0"
      },
      {
        "authorType": "User",
        "author_name": "dirkgr",
        "body": "## What's new\r\n\r\n### Added \ud83c\udf89\r\n\r\n- Added `T5` model for generation.\r\n- Added a classmethod constructor on `Seq2SeqPredictor`: `.pretrained_t5_for_generation()`.\r\n- Added a parameter called `source_prefix` to `CNNDailyMailDatasetReader`. This is useful with T5, for example, by setting `source_prefix` to \"summarization: \".\r\n- Tests for `VqaMeasure`.\r\n- Distributed tests for `ConllCorefScores` and `SrlEvalScorer` metrics.\r\n\r\n### Fixed \u2705\r\n\r\n- `VqaMeasure` now calculates correctly in the distributed case.\r\n- `ConllCorefScores` now calculates correctly in the distributed case.\r\n- `SrlEvalScorer` raises an appropriate error if run in the distributed setting.\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- Updated `registered_predictor_name` to `null` in model cards for the models where it was the same as the default predictor.\r\n\r\n## Commits\r\n\r\n7a6ee0c0 Add T5 for generation/summarization (#241)\r\n5012f238 Fix name of variable in docstring (#252)\r\nd18c8378 Remove registered_predictor_name from all modelcards where the predictor is the same as the default (#253)\r\ne5789cf7 Distributed metrics (#251)\r\nc733f838 Roberta data reader (#247)\r\n419bc90b Distributed VQA metric (#250)\r\n",
        "dateCreated": "2021-04-23T00:32:06Z",
        "datePublished": "2021-04-23T00:33:01Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v2.4.0",
        "name": "",
        "tag_name": "v2.4.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v2.4.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/41875004",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v2.4.0"
      },
      {
        "authorType": "User",
        "author_name": "AkshitaB",
        "body": "## What's new\r\n\r\n### Fixed \u2705\r\n\r\n- Fixed bug in `experiment_from_huggingface.jsonnet` and `experiment.jsonnet` by changing `min_count` to have key `labels` instead of `answers`. Resolves failure of model checks that involve calling `_extend` in `vocabulary.py`\r\n- `TransformerQA` now outputs span probabilities as well as scores.\r\n- `TransformerQAPredictor` now implements `predictions_to_labeled_instances`, which is required for the interpret module.\r\n\r\n### Added \ud83c\udf89\r\n\r\n- Added script that produces the coref training data.\r\n- Added tests for using `allennlp predict` on multitask models.\r\n\r\n## Commits\r\n\r\neaf76a7 Fix paths in training config\r\nacc3424 Adds tests for multitask predictor (#248)\r\nf4fb932 Making TransformerQAPredictor compatible with interpret modules (#249)\r\n31a9ad3 Fix paths in training config\r\nf1de60f update version in README\r\nb358dad Add list of pretrained models to README (#246)\r\n39f1a0f fix spacing for API docs\r\n048355d big improvements to readme (#243)\r\n2208341 Add best span probs (#244)\r\n15ac4dc fix sanity check tests (#242)\r\n4b13924 Add make_output_human_readable to pair classification models (#235)\r\ne371cef Update mkdocs-material requirement from <7.1.0,>=5.5.0 to >=5.5.0,<7.2.0 (#237)\r\n6b306b0 Adds the coref prep script (#239)\r\n155fd76 Fix label namespace in experiment.jsonnet (#240)\r\nabc7e19 Fixed bug in `experiment_from_huggingface.jsonnet`  (#238)\r\na8e0b00 Make snli dataset reader work with unlabeled instances (#234)\r\neb72cdc Allow example categories to be ordered (#229)\r\nd97ff8e tick version for nightly\r\n",
        "dateCreated": "2021-04-14T23:04:37Z",
        "datePublished": "2021-04-14T23:06:08Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v2.3.0",
        "name": "v2.3.0",
        "tag_name": "v2.3.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v2.3.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/41447521",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v2.3.0"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "## What's new\r\n\r\n### Added \ud83c\udf89\r\n\r\n- Evaluating RC task card and associated LERC model card (@anthonywchen).\r\n- Compatibility with PyTorch 1.8.\r\n- Dataset reader for SuperGLUE BoolQ.\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- Add option `combine_input_fields` in `SnliDatasetReader` to support only having \"non-entailment\" and \"entailment\" as output labels (@leo-liuzy).\r\n- Made all the models run on AllenNLP 2.1.\r\n- Add option `ignore_loss_on_o_tags` in `CrfTagger` to set the flag outside its forward function (@tarohi24).\r\n\r\n### Fixed \u2705\r\n\r\n- Fixed https://github.com/allenai/allennlp/issues/4745 (@leo-liuzy).\r\n- Updated `QaNet` and `NumericallyAugmentedQaNet` models to remove bias for layers that are followed by normalization layers.\r\n- Updated the model cards for `rc-naqanet`, `vqa-vilbert` and `ve-vilbert`.\r\n- Predictors now work for the vilbert-multitask model.\r\n\r\n## Commits\r\n\r\nf5c157b9 Prepare for release v2.2.0\r\n9a237c35 fixes for callback refactor (#233)\r\n8aabfe50 add BoolQ dataset reader (#228)\r\nab2a0d16 Added model card for LERC and task card for evaluating-RC (#226)\r\n986265dc Add `ignore_loss_on_o_tags` to `CrfTagger.__init__()` (#230)\r\n20bc25af Demo Sweep 2 (#227)\r\n2f798c06 Fix sanity checks for models (#224)\r\n3624fdc4 Update torch requirement from <1.8.0,>=1.7.0 to >=1.7.0,<1.9.0 (#225)\r\nec115c63 Fix NextTokenLM bug (#213)\r\nff682033 Add option to collapse non-entailment labels in SNLI dataset reader (#214)\r\n743e0eee Fix QaNet and NaQaNet (#223)\r\n769cda07 small doc fix in CopyNet\r\nef51b670 Fixes Multitask predictions for the vision models (#218)",
        "dateCreated": "2021-03-26T17:47:06Z",
        "datePublished": "2021-03-26T17:50:24Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v2.2.0",
        "name": "v2.2.0",
        "tag_name": "v2.2.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v2.2.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/40555707",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v2.2.0"
      },
      {
        "authorType": "User",
        "author_name": "dirkgr",
        "body": "## What's new\r\n\r\n### Added \ud83c\udf89\r\n\r\n- BART model now adds a `predicted_text` field in `make_output_human_readable` that has the cleaned text corresponding to `predicted_tokens`.\r\n\r\n### Fixed \u2705\r\n\r\n- Made `label` parameter in `TransformerMCReader.text_to_instance` optional with default of `None`.\r\n- Fixed `OpenIePredictor.predict_json` so it treats auxiliary verbs as verbs\r\n  when the language is English.\r\n\r\n## Commits\r\n\r\n63551026 small doc fix in CopyNet\r\n14ffde8f Fix prediction for models using TransformerMCReader (#222)\r\nc411e379 copy over TAG_MAP from spaCy (#219)\r\n8e700bb8 Add `predicted_text` field to BART model output (#217)\r\n845ab1e6 OpenIE fix (#206)\r\n48150a3c Updating modelcards for ModelUsage (#209)\r\n",
        "dateCreated": "2021-03-01T23:31:56Z",
        "datePublished": "2021-03-02T00:17:39Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.5.0",
        "name": "",
        "tag_name": "v1.5.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.5.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/39086728",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.5.0"
      },
      {
        "authorType": "User",
        "author_name": "dirkgr",
        "body": "## What's new\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- `coding_scheme` parameter is now deprecated in `Conll2000DatasetReader`, please use `convert_to_coding_scheme` instead.\r\n\r\n### Added \ud83c\udf89\r\n\r\n- BART model now adds a `predicted_text` field in `make_output_human_readable` that has the cleaned text corresponding to `predicted_tokens`.\r\n\r\n### Fixed \u2705\r\n\r\n- Made `label` parameter in `TransformerMCReader.text_to_instance` optional with default of `None`.\r\n- Updated many of the models for version 2.1.0. Fixed and re-trained many of the models.\r\n\r\n## Commits\r\n\r\n1c006c50 Demo model sweep (#216)\r\n1d44f1ad Fix prediction for models using TransformerMCReader (#222)\r\n91283471 Update mkdocs-material requirement from <6.3.0,>=5.5.0 to >=5.5.0,<7.1.0 (#221)\r\n1b32cae8 Bump mypy from 0.800 to 0.812 (#220)\r\nc645f78e copy over TAG_MAP from spaCy (#219)\r\n431e5d18 Bump conllu from 4.3.1 to 4.4 (#215)\r\n06344123 Add `predicted_text` field to BART model output (#217)\r\ne51c0512 Bump conllu from 4.3 to 4.3.1 (#212)\r\nc258a830 Introduce `convert_to_coding_scheme` and make `coding_scheme` deprecated in CoNLL2000DatasetReader (#211)\r\ndfded468 Remove conll2003_test.py from allennlp-models (#210)\r\n95eb53e3 Updating modelcards for ModelUsage (#209)\r\n",
        "dateCreated": "2021-02-24T21:47:34Z",
        "datePublished": "2021-02-24T21:48:11Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v2.1.0",
        "name": "",
        "tag_name": "v2.1.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v2.1.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/38680568",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v2.1.0"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "## What's new\r\n\r\n### Fixed \u2705\r\n\r\n- Fixed `OpenIePredictor.predict_json` so it treats auxiliary verbs as verbs\r\n  when the language is English.\r\n\r\n## Commits\r\n\r\nca7184c tick version for nightly release\r\nda80d8f adding more examples for lm (#208)\r\n0413882 full image paths (#207)\r\n35cfb57 OpenIE fix (#206)\r\n01a4b28 adding vqa model card, renaming ve modelcard (#205)\r\n42c0450 Description and citation as markdown (#190)\r\n8fd7aaa fix ALLENNLP_COMMIT_SHA",
        "dateCreated": "2021-02-01T19:14:48Z",
        "datePublished": "2021-02-01T19:16:49Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v2.0.1",
        "name": "v2.0.1",
        "tag_name": "v2.0.1",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v2.0.1",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/37196006",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v2.0.1"
      },
      {
        "authorType": "User",
        "author_name": "AkshitaB",
        "body": "## What's new\r\n\r\n#### Note: This release is mainly for the AllenNLP demo.\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- Updated various model cards and task cards.\r\n\r\n## Commits\r\n\r\n80a985b adding more examples for lm (#208)\r\n90d2418 full image paths (#207)\r\nf498854 adding vqa model card, renaming ve modelcard (#205)\r\n0413a7e Description and citation as markdown (#190)",
        "dateCreated": "2021-01-29T23:53:02Z",
        "datePublished": "2021-01-29T23:55:04Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.4.1",
        "name": "v1.4.1",
        "tag_name": "v1.4.1",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.4.1",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/37110489",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.4.1"
      },
      {
        "authorType": "User",
        "author_name": "dirkgr",
        "body": "For the main differences between AllenNLP 2.0 and AllenNLP 1.x, check out the release announcement at https://github.com/allenai/allennlp/releases/tag/v2.0.0!\r\n\r\n## What's new (since v2.0.0rc1)\r\n\r\n### Fixed \u2705\r\n\r\n- Made the training configs compatible with the tensorboard logging changes in the main repo\r\n\r\n## Commits\r\n\r\nf0aff04a fixes for tensorboard changes (#204)\r\n60965a9d ci quick fix\r\n167728cb ci quick fix\r\n2d4c4378 ci quick fix\r\ncbbd58d2 tick version for nightly release\r\nbde73ceb changing text->sentence, more examples (#203)\r\na507f5d9 Merging vision into main (#171)\r\nd1a54d70 adding task card for language modeling (#201)\r\n75e9c1a7 Bump mypy from 0.790 to 0.800 (#200)\r\n392cee74 fix mkdocs config (#198)\r\n5ddc8aab Fix BART (#195)\r\n9472904a Fix TransformerQA distributed dead-lock bug (#193)\r\n54ccc828 Bump conllu from 4.2.2 to 4.3 (#194)\r\n8f18a173 Update mkdocs-material requirement from <6.2.0,>=5.5.0 to >=5.5.0,<6.3.0 (#185)\r\n2644f6a8 Fix small bugs in RC model (#191)\r\n92768ae1 Moving modelcard and taskcard abstractions to main repo (#186)\r\n92f1eeae fix requirements.txt\r\n641c8ef0 fix navbar link\r\n70cd713c Fixes for master->main rename (#188)\r\nc62a3479 ensure latest allennlp commit always used (#187)\r\nb8c858a8 Bump conllu from 4.2.1 to 4.2.2 (#180)\r\n4b16dbc1 fix cache volume (#184)\r\n",
        "dateCreated": "2021-01-27T23:57:11Z",
        "datePublished": "2021-01-27T23:58:59Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v2.0.0",
        "name": "v2.0.0",
        "tag_name": "v2.0.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v2.0.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/37002075",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v2.0.0"
      },
      {
        "authorType": "User",
        "author_name": "dirkgr",
        "body": "## What's new\r\n\r\n### Removed \ud83d\udc4b\r\n\r\n- Moving `ModelCard` and `TaskCard` abstractions out of the models repository.\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- 'master' branch renamed to 'main'\r\n- `SquadEmAndF1` metric can now also accept a batch of predictions and corresponding answers (instead of a single one)\r\n  in the form of list (for each).\r\n\r\n### Fixed \u2705\r\n\r\n- Fixed the potential for a dead-lock when training the `TransformerQA` model on multiple GPUs\r\n  when nodes receive different sized batches.\r\n\r\n### Fixed \u2705\r\n\r\n- Fixed BART. This implementation had some major bugs in it that caused poor performance during prediction.\r\n\r\n## Commits\r\n\r\n1c300d89 Prepare for release v1.3.1\r\n0402f6d3 changing text->sentence, more examples (#203)\r\n7652c6c2 Make the 1.x branch work in CI\r\nd1a54d70 adding task card for language modeling (#201)\r\n75e9c1a7 Bump mypy from 0.790 to 0.800 (#200)\r\n392cee74 fix mkdocs config (#198)\r\n5ddc8aab Fix BART (#195)\r\n9472904a Fix TransformerQA distributed dead-lock bug (#193)\r\n54ccc828 Bump conllu from 4.2.2 to 4.3 (#194)\r\n8f18a173 Update mkdocs-material requirement from <6.2.0,>=5.5.0 to >=5.5.0,<6.3.0 (#185)\r\n2644f6a8 Fix small bugs in RC model (#191)\r\n92768ae1 Moving modelcard and taskcard abstractions to main repo (#186)\r\n92f1eeae fix requirements.txt\r\n641c8ef0 fix navbar link\r\n70cd713c Fixes for master->main rename (#188)\r\nc62a3479 ensure latest allennlp commit always used (#187)\r\nb8c858a8 Bump conllu from 4.2.1 to 4.2.2 (#180)\r\n4b16dbc1 fix cache volume (#184)\r\n",
        "dateCreated": "2021-01-27T01:36:17Z",
        "datePublished": "2021-01-27T01:37:04Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.4.0",
        "name": "v1.4.0",
        "tag_name": "v1.4.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.4.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/36945482",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.4.0"
      },
      {
        "authorType": "User",
        "author_name": "dirkgr",
        "body": "This is the first (and hopefully only) release candidate for AllenNLP 2.0. Please note that this is a release candidate, and the APIs are still subject to change until the final 2.0 release. The big addition is the first item, models for several tasks that combine language and vision. Hopefully these will serve as an example for many future models.\r\n\r\n\r\n## What's new\r\n\r\n### Added \ud83c\udf89\r\n\r\n- Dataset readers, models, metrics, and training configs for VQAv2, GQA, and Visual Entailment\r\n\r\n### Fixed \u2705\r\n\r\n- Fixed `training_configs/pair_classification/bimpm.jsonnet` and `training_configs/rc/dialog_qa.jsonnet`\r\n  to work with new data loading API.\r\n- Fixed the potential for a dead-lock when training the `TransformerQA` model on multiple GPUs\r\n  when nodes receive different sized batches.\r\n- Fixed BART. This implementation had some major bugs in it that caused poor performance during prediction.\r\n\r\n### Removed \ud83d\udc4b\r\n\r\n- Moving `ModelCard` and `TaskCard` abstractions out of the models repository.\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- `master` branch renamed to `main`\r\n- `SquadEmAndF1` metric can now also accept a batch of predictions and corresponding answers (instead of a single one)\r\n  in the form of list (for each).\r\n\r\n## Commits\r\n\r\n07fc94e9 Moving vision models (#199)\r\n493e961e Merge remote-tracking branch 'origin/main' into vision\r\n392cee74 fix mkdocs config (#198)\r\n5ddc8aab Fix BART (#195)\r\n9472904a Fix TransformerQA distributed dead-lock bug (#193)\r\n64fdd591 Merge branch 'main' into vision\r\n953822de fix piqa reader test\r\n54ccc828 Bump conllu from 4.2.2 to 4.3 (#194)\r\n5c8ec4ff merge conflicts\r\n8f18a173 Update mkdocs-material requirement from <6.2.0,>=5.5.0 to >=5.5.0,<6.3.0 (#185)\r\n2644f6a8 Fix small bugs in RC model (#191)\r\nd2d7b55a fixes for data loading updates in core (#192)\r\ndebf15ae VE model card (#189)\r\n92768ae1 Moving modelcard and taskcard abstractions to main repo (#186)\r\n92f1eeae fix requirements.txt\r\n641c8ef0 fix navbar link\r\n70cd713c Fixes for master->main rename (#188)\r\nc62a3479 ensure latest allennlp commit always used (#187)\r\ne80f702c Merge branch 'master' into vision\r\nb8c858a8 Bump conllu from 4.2.1 to 4.2.2 (#180)\r\n4b16dbc1 fix cache volume (#184)\r\ned564d2a Merge remote-tracking branch 'origin/master' into vision\r\nd1d37de5 fix SNLI reader\r\nf5ba4a67 fix LM training config\r\n47401fa1 fix test-install CI job (#172)\r\naf4a7e24 merge with master\r\n058815ef update with master\r\n8b908e03 fix merge conflicts\r\n5e778ace Training config test fix (#157)\r\nbd47e3ba Merge branch 'master' into vision\r\n8385f475 fix TransformerQA predictor test (#145) (#146)\r\n1c7749dc fix merge conflicts\r\nac4fc45b Merge remote-tracking branch 'origin/master' into vision\r\n09fe0b0d improve generation dataset readers (#122)\r\n48bceca6 updates\r\n455ac1f7 ensure vision CI runs on every commit (#120)\r\n4e48a16e Updates for new data loading API (#101)\r\n10b9db33 Merge branch 'master' into vision\r\n182a7bfb Merge branch 'master' into vision\r\ne56b22a6 run on vision PRs\r\nc1178c3f temporarily patch allennlp to data-loading branch\r\n\r\n",
        "dateCreated": "2021-01-22T00:01:29Z",
        "datePublished": "2021-01-22T00:08:29Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v2.0.0rc1",
        "name": "v2.0.0rc1",
        "tag_name": "v2.0.0rc1",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v2.0.0rc1",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/36742969",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v2.0.0rc1"
      },
      {
        "authorType": "User",
        "author_name": "AkshitaB",
        "body": "## What's new\r\n\r\n### Fixed \u2705\r\n\r\n- Fix an index bug in  BART prediction.\r\n- Add `None` check in `PrecoReader`'s `text_to_instance()` method. \r\n- Fixed `SemanticRoleLabelerPredictor.tokens_to_instances` so it treats auxiliary verbs as verbs\r\n  when the language is English\r\n- Added missing folder for `taskcards` in setup.py\r\n\r\n### Added \ud83c\udf89\r\n\r\n- Added link to source code to API docs.\r\n- Information updates for remaining model cards (also includes the ones in demo, but not in the repository).\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- Updated `Dockerfile.release` and `Dockerfile.commit` to work with different CUDA versions.\r\n- Changes required for the `transformers` dependency update to version 4.0.1.\r\n\r\n## Commits\r\n\r\n2c3d00f add missing taskcards (#183)\r\n22cbb2f Update transformers version (#181)\r\n7204469 ci fix (#182)\r\n7c528af Fix typo\r\n780b095 Add check for None before iterating on the clusters. (#179)\r\nef5d422 Treat auxiliary verbs as verbs (#178)\r\nea1f71c fix index bug (#175)\r\n8d09185 More model cards  (#177)\r\n8a8d8b4 add link to source code in docs (#173)\r\n0789d72 update alternative Dockerfiles for different CUDA versions (#170)\r\n01bc777 actions quick fix\r\n\r\n",
        "dateCreated": "2020-12-15T22:22:59Z",
        "datePublished": "2020-12-15T22:25:02Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.3.0",
        "name": "v1.3.0",
        "tag_name": "v1.3.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.3.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/35318809",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.3.0"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "## What's new\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- Changed AllenNLP dependency for releases to allow for a range of versions, instead\r\n  of being pinned to an exact version.\r\n- There will now be multiple Docker images pushed to Docker Hub for releases, each\r\n  corresponding to a different supported CUDA version (currently just 10.2 and 11.0).\r\n\r\n### Fixed \u2705\r\n\r\n- Fixed `pair-classification-esim` pretrained model.\r\n- Fixed `ValueError` error message in `Seq2SeqDatasetReader`.\r\n- Better check for start and end symbols in `Seq2SeqDatasetReader` that doesn't fail for BPE-based tokenizers.\r\n\r\n### Added \ud83c\udf89\r\n\r\n- Added `short_description` field to `ModelCard`. \r\n- Information updates for all model cards.\r\n\r\n## Commits\r\n\r\n98ae92c build quickfix\r\nc5e54c9 Prepare for release v1.2.2\r\n04d1e58 Merge branch 'master' of github.com:allenai/allennlp-models\r\n4905da2 install torch in test Docker image separately\r\n716d48d Merge GH Actions workflows into one, publish release images for multiple supported CUDA versions (#168)\r\n1a17c81 More explicit start/end symbol parsing (#169)\r\n236034f Fix bad start or end symbol error (#167)\r\n8a305a0 Update model cards (#166)\r\n43afd10 allow for range of AllenNLP versions (#165)\r\nf2f4284 upload new esim model with fixed config (#164)",
        "dateCreated": "2020-11-17T23:58:23Z",
        "datePublished": "2020-11-17T23:58:59Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.2.2",
        "name": "v1.2.2",
        "tag_name": "v1.2.2",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.2.2",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/34090604",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.2.2"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "## What's new\r\n\r\n### Added \ud83c\udf89\r\n\r\n- Added the `TaskCard` class and task cards for common tasks.\r\n- Added a test for the interpret functionality\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- Added more information to model cards for pair classification models (`pair-classification-decomposable-attention-elmo`, `pair-classification-roberta-snli`, `pair-classification-roberta-mnli`, `pair-classification-esim`).\r\n\r\n### Fixed \u2705\r\n\r\n- Fixed TransformerElmo config to work with the new AllenNLP\r\n- Pinned the version of torch more tightly to make AMP work\r\n- Fixed the somewhat fragile Bidaf test\r\n\r\n## Commits\r\n\r\na6b5a2c Adds a test that checks the interpret functionality (#163)\r\n6a81154 make naqanet test less flaky (#162)\r\n1e4b67c Transformer ELMo config fixes (#131)\r\nd383ea9 Task cards (#161)\r\nb152d82 Updating pair classification model cards (#160)",
        "dateCreated": "2020-11-11T00:49:49Z",
        "datePublished": "2020-11-11T00:50:53Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.2.1",
        "name": "v1.2.1",
        "tag_name": "v1.2.1",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.2.1",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/33762230",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.2.1"
      },
      {
        "authorType": "User",
        "author_name": "AkshitaB",
        "body": "## What's new\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- Updated docstring for Transformer MC.\r\n- Added more information to model cards for multiple choice models (`mc-roberta-commonsenseqa`,\r\n`mc-roberta-piqa`, and `mc-roberta-swag`).\r\n\r\n### Fixed \u2705\r\n\r\n- Fixed many training configs to work out-of-the box. These include the configs for `bart_cnn_dm`, `swag`, `bidaf`, `bidaf_elmo`,\r\n  `naqanet`, and `qanet`.\r\n- Fixed minor bug in MaskedLanguageModel, where getting token ids used hard-coded assumptions (that\r\n  could be wrong) instead of our standard utility function.\r\n\r\n## Commits\r\n\r\nfcb6758 Prepare for release v1.2.0\r\n43c9b51 remove autocast(False) around RNNs (#158)\r\nbf42ee0 make coref test less flaky\r\n84fb13f Adding info to Multiple Choice model cards (#156)\r\nab4ab67 make more configs work out-of-the-box (#153)\r\nf253c57 Bump conllu from 4.2 to 4.2.1 (#155)\r\n\r\n",
        "dateCreated": "2020-10-29T21:52:08Z",
        "datePublished": "2020-10-29T21:53:22Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.2.0",
        "name": "v1.2.0",
        "tag_name": "v1.2.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.2.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/33243680",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.2.0"
      },
      {
        "authorType": "User",
        "author_name": "AkshitaB",
        "body": "## What's new\r\n\r\n### Added \ud83c\udf89\r\n\r\n- Added dataset reader support for SQuAD 2.0 with both the `SquadReader` and `TransformerSquadReader`.\r\n- Updated the SQuAD v1.1 metric to work with SQuAD 2.0 as well.\r\n- Updated the `TransformerQA` model to work for SQuAD 2.0.\r\n- Added official support for Python 3.8.\r\n- Added a json template for model cards.\r\n- Added `training_config` as a field in model cards.\r\n- Added a `BeamSearchGenerator` registrable class which can be provided to a `NextTokenLM` model\r\n  to utilize beam search for predicting a sequence of tokens, instead of a single next token.\r\n  `BeamSearchGenerator` is an abstract class, so a concrete registered implementation needs to be used.\r\n  One implementation is provided so far: `TransformerBeamSearchGenerator`, registered as `transformer`,\r\n  which will work with any `NextTokenLM` that uses a `PretrainedTransformerEmbedder`.\r\n- Added an `overrides` parameter to `pretrained.load_predictor()`.\r\n\r\n### Changed \u26a0\ufe0f\r\n\r\n- `rc-transformer-qa` pretrained model is now an updated version trained on SQuAD v2.0.\r\n- `skip_invalid_examples` parameter in SQuAD dataset readers has been deprecated. Please use\r\n  `skip_impossible_questions` instead.\r\n\r\n### Fixed \u2705\r\n\r\n- Fixed `lm-masked-language-model` pretrained model.\r\n- Fixed BART for latest `transformers` version.\r\n- Fixed BiDAF predictor and BiDAF predictor tests.\r\n- Fixed a bug with `Seq2SeqDatasetReader` that would cause an exception when\r\n  the desired behavior is to not add start or end symbols to either the source or the target\r\n  and the default `start_symbol` or `end_symbol` are not part of the tokenizer's vocabulary.\r\n\r\n## Commits\r\n\r\n8b5c42c Don't use PretrainedModelInitializer when loading a model (#141)\r\nf789c53 add beam search to NextTokenLm (#149)\r\n414cb48 Bidaf predictor and test quick fix (#154)\r\n2d03ab0 fix docstrings to render correctly in docs (#150)\r\ncdd505e Update mkdocs-material requirement from <6.1.0,>=5.5.0 to >=5.5.0,<6.2.0 (#152)\r\n4cee3bd Model cards update (#148)\r\n223ef71 Bump mypy from 0.782 to 0.790 (#147)\r\n18008d0 fix TransformerQA predictor test (#145)\r\ne827130 update masked lm language model (#143)\r\n83e668c update how env variables set (#140)\r\nd90953a run pretrained tests on CPU-only runner (#142)\r\n0b3853a SQuAD 2.0 support (#134)\r\nbcaf3c8 Fix some typos\r\n0b05944 tick version for nightly releases\r\na330876 fix seq2seq reader bug (#139)\r\ndd36890 Adding more documentation to model cards spec (#137)\r\n436e047 Update mkdocs-material requirement from <5.6.0,>=5.5.0 to >=5.5.0,<6.1.0 (#138)\r\n0cb9e0f Model cards update (#136)\r\n5fabe32 official support Python 3.8 \ud83d\udc0d (#135)\r\n16513bd Bump conllu from 4.1 to 4.2 (#133)\r\na1f9a05 Create Dependabot config file (#132)\r\n3425192 remove TODO\r\n2d7e1f6 Fixes for new transformers release (#130)\r\n57908bb allow multiple token embedders, but only use first with non-empty type (#129)\r\n",
        "dateCreated": "2020-10-22T22:05:18Z",
        "datePublished": "2020-10-22T22:07:46Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.2.0rc1",
        "name": "v1.2.0rc1",
        "tag_name": "v1.2.0rc1",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.2.0rc1",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/32945934",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.2.0rc1"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "## What's new since version 1.0.0\r\n\r\n### Added\r\n\r\n- Added regression tests for training configs that run on a scheduled workflow.\r\n- Added a test for the pretrained sentiment analysis model.\r\n- Added way for questions from quora dataset to be concatenated like the sequences in the SNLI dataset.\r\n- Added BART model\r\n- Added `ModelCard` and related classes. Added model cards for all the pretrained models.\r\n- Added a field `registered_predictor_name` to `ModelCard`.\r\n- Added a method `load_predictor` to `allennlp_models.pretrained`.\r\n- Added support to multi-layer decoder in simple seq2seq model.\r\n- Added two models for fine-grained NER\r\n- Added a category for multiple choice models, including a few reference implementations\r\n\r\n### Changed\r\n\r\n- `CopyNetDatasetReader` no longer automatically adds `START_TOKEN` and `END_TOKEN` to the tokenized source. If you want these in the tokenized source, it's up to the source tokenizer.\r\n- Implemented manual distributed sharding for the SNLI dataset reader.\r\n\r\n### Fixed\r\n\r\n- Fixed evaluation of metrics when using distributed setting.\r\n- Fixed a bug introduced in 1.0 where the SRL model did not reproduce the original result.\r\n- Fixed `GraphParser.get_metrics` so that it expects a dict from `F1Measure.get_metric`.\r\n- `CopyNet` and `SimpleSeq2Seq` models now work with AMP.\r\n- Made the SST reader a little more strict in the kinds of input it accepts.\r\n- Updated the RoBERTa SST config to make proper use of the CLS token\r\n- Updated RoBERTa SNLI and MNLI pretrained models for latest `transformers` version\r\n- Updated the BERT SRL model to be compatible with the new huggingface tokenizers.\r\n- `CopyNetSeq2Seq` model now works with pretrained transformers.\r\n- A bug with `NextTokenLM` that caused simple gradient interpreters to fail.\r\n- A bug in `training_config` of `qanet` and `bimpm` that used the old version of `regularizer` and `initializer`.\r\n- The fine-grained NER transformer model did not survive an upgrade of the transformers library, but it is now fixed.\r\n- Fixed many minor formatting issues in docstrings. Docs are now published at [https://docs.allennlp.org/models/](https://docs.allennlp.org/models/).\r\n\r\n### Commits\r\n\r\n5ffc207 Prepare for release v1.1.0\r\n36ad6b3 Bump conllu from 4.0 to 4.1 (#126)\r\n2c2e4e4 Fixes the BERT SRL model (#124)\r\n44a3ca5 Update BartEncoder docstring for embeddings guidance (#127)\r\n2e54449 Combinable quora sequences (#119)\r\nce8ef9b formatting changes for new version of black (#125)\r\n3742b4a Distributed metrics (#123)\r\n31b00e7 Bump markdown-include from 0.5.1 to 0.6.0 (#121)\r\nc4ef4c8 Prepare for release v1.1.0rc4\r\n27c0ca5 always run configs CI job (#118)\r\n7c3be82 upgrade to actions cache v2 (#116)\r\ndbd46b4 Add test for sentiment analysis (#117)\r\na91f009 run config tests in subprocesses (#115)\r\nc211baf Update simple_seq2seq.py (#90)\r\n267b747 Bump conllu from 3.1.1 to 4.0 (#114)\r\n87570ec validate pretrained configs in CI (#112)\r\n4fa5fc1 Fix RoBERTa SST (#110)\r\n0491690 Only pin mkdocs-material to minor version, ignore specific patch version (#113)\r\n8d27e7b prepare for release v1.1.0rc3\r\n959a5eb Update graph parser metrics (#109)\r\n45f85ce Bump mkdocs-material from 5.5.3 to 5.5.5 (#111)\r\ne69f4c4 fix docs CI\r\n4b96dfa tick version for nightly releases\r\ne5f5c62 Update some models for AMP training (#104)\r\n4f0bca1 Bump mkdocs-material from 5.5.2 to 5.5.3 (#108)\r\ncbd2b57 Adds the pretrained BART model (#107)\r\n5d9098f Bump conllu from 3.0 to 3.1.1 (#105)\r\n92f2a8f Bump mkdocs-material from 5.5.0 to 5.5.2 (#106)\r\na901f9f Prepare for release v1.1.0rc2\r\n04561a8 updates for torch 1.6 (#103)\r\ne7b8247 Update RoBERTa SNLI/MNLI models (#102)\r\n008828b Adding `ModelCard` (#98)\r\neaa331e Roberta SST (#99)\r\n75c8869 Bump mkdocs-material from 5.4.0 to 5.5.0 (#100)\r\na56a103 Implemented BART (#35)\r\na730fed Cuda devices (#97)\r\n4d0e090 Make sure we ship the SRL eval Perl script (#96)\r\n4f2e316 tick version for nightly releases\r\ndd60f94 Prepare for release v1.1.0rc1\r\nda83a4e build and publish models docs (#91)\r\n4b2178b implement manual distributed sharding for SNLI reader (#89)\r\n1a2a8f4 Updates the SRL model (#93)\r\n8a93743 Updated the fine-grained NER transformer model (#92)\r\nb913333 Multiple Choice (#75)\r\n09395d2 updates for new transformers release (#88)\r\n11c6814 fix the bug of bimpm and update CHANGELOG (#87)\r\na735ddd Fix the regularizer of QANet model (#86)\r\n0ce14da fixes for next_token_lm (#85)\r\n37136f8 skip docker build on nightly release\r\n82aa9ac Fine grained NER (#84)\r\n4b5b939 fix test fixture\r\n947beb0 remove unused param in copynet reader\r\n9ec65df fix nightly Docker workflow\r\n3019a4e fix workflow skip conditions\r\ncc60ab9 use small dummy transformer for copynet test (#83)\r\nac9f214 fix nightly workflow\r\n596e6a7 Bump mypy from 0.781 to 0.782 (#82)\r\nd210c2f add nightly releases (#81)\r\n935a2a8 dont add START and END tokens to source in CopyNet (#79)\r\nd6798ce update skip conditions on const-parser-test (#80)\r\n2754f88 Bump mypy from 0.780 to 0.781 (#78)\r\nd3588ad Make CopyNet work with pretrained transformer models (#76)",
        "dateCreated": "2020-09-08T20:45:40Z",
        "datePublished": "2020-09-08T20:50:43Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.1.0",
        "name": "v1.1.0",
        "tag_name": "v1.1.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.1.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/30935594",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.1.0"
      },
      {
        "authorType": "User",
        "author_name": "AkshitaB",
        "body": "## What's new since v1.1.0rc3\r\n\r\n### Added\r\n\r\n- Added regression tests for training configs that run on a scheduled workflow.\r\n- Added a test for the pretrained sentiment analysis model.\r\n\r\n### Commits\r\n\r\n27c0ca5 always run configs CI job (#118)\r\n7c3be82 upgrade to actions cache v2 (#116)\r\ndbd46b4 Add test for sentiment analysis (#117)\r\na91f009 run config tests in subprocesses (#115)\r\nc211baf Update simple_seq2seq.py (#90)\r\n267b747 Bump conllu from 3.1.1 to 4.0 (#114)\r\n87570ec validate pretrained configs in CI (#112)\r\n4fa5fc1 Fix RoBERTa SST (#110)\r\n0491690 Only pin mkdocs-material to minor version, ignore specific patch version (#113)",
        "dateCreated": "2020-08-21T15:20:14Z",
        "datePublished": "2020-08-21T15:23:10Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.1.0rc4",
        "name": "v1.1.0rc4",
        "tag_name": "v1.1.0rc4",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.1.0rc4",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/29986287",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.1.0rc4"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "## What's new since `v1.1.0rc2`\r\n\r\n### Fixed\r\n\r\n- Fixed `GraphParser.get_metrics` so that it expects a dict from `F1Measure.get_metric`.\r\n- `CopyNet` and `SimpleSeq2Seq` models now work with AMP.\r\n\r\n## Commits\r\n\r\n8d27e7b prepare for release v1.1.0rc3\r\n959a5eb Update graph parser metrics (#109)\r\n45f85ce Bump mkdocs-material from 5.5.3 to 5.5.5 (#111)\r\ne69f4c4 fix docs CI\r\n4b96dfa tick version for nightly releases\r\ne5f5c62 Update some models for AMP training (#104)\r\n4f0bca1 Bump mkdocs-material from 5.5.2 to 5.5.3 (#108)\r\ncbd2b57 Adds the pretrained BART model (#107)\r\n5d9098f Bump conllu from 3.0 to 3.1.1 (#105)\r\n92f2a8f Bump mkdocs-material from 5.5.0 to 5.5.2 (#106)",
        "dateCreated": "2020-08-12T21:03:47Z",
        "datePublished": "2020-08-12T21:04:55Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.1.0rc3",
        "name": "v1.1.0rc3",
        "tag_name": "v1.1.0rc3",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.1.0rc3",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/29625444",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.1.0rc3"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "## What's new since `v1.1.0rc1`\r\n\r\n### Changed\r\n\r\n- Updated to PyTorch 1.6.\r\n\r\n### Fixed\r\n\r\n- Updated the RoBERTa SST config to make proper use of the CLS token\r\n- Updated RoBERTa SNLI and MNLI pretrained models for latest `transformers` version\r\n\r\n### Added\r\n\r\n- Added BART model\r\n- Added `ModelCard` and related classes. Added model cards for all the pretrained models.\r\n- Added a method `load_predictor` to `allennlp_models.pretrained`.\r\n\r\n## Commits\r\n\r\na901f9f Prepare for release v1.1.0rc2\r\n04561a8 updates for torch 1.6 (#103)\r\ne7b8247 Update RoBERTa SNLI/MNLI models (#102)\r\n008828b Adding `ModelCard` (#98)\r\neaa331e Roberta SST (#99)\r\n75c8869 Bump mkdocs-material from 5.4.0 to 5.5.0 (#100)\r\na56a103 Implemented BART (#35)\r\na730fed Cuda devices (#97)\r\n4d0e090 Make sure we ship the SRL eval Perl script (#96)\r\n4f2e316 tick version for nightly releases",
        "dateCreated": "2020-07-31T17:25:19Z",
        "datePublished": "2020-07-31T17:27:34Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.1.0rc2",
        "name": "v1.1.0rc2",
        "tag_name": "v1.1.0rc2",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.1.0rc2",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/29174583",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.1.0rc2"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "First v1.1 pre-release candidate. See the corresponding [allennlp v1.1.0rc1](https://github.com/allenai/allennlp/releases/tag/v1.1.0rc1) release candidate.\r\n\r\n## What's new since v1.0.0\r\n\r\n### Fixed\r\n\r\n- Updated the BERT SRL model to be compatible with the new huggingface tokenizers.\r\n- `CopyNetSeq2Seq` model now works with pretrained transformers.\r\n- A bug with `NextTokenLM` that caused simple gradient interpreters to fail.\r\n- A bug in `training_config` of `qanet` and `bimpm` that used the old version of `regularizer` and `initializer`.\r\n- The fine-grained NER transformer model did not survive an upgrade of the transformers library, but it is now fixed.\r\n- Fixed many minor formatting issues in docstrings. Docs are now published at [https://docs.allennlp.org/models/](https://docs.allennlp.org/models/).\r\n\r\n### Changed\r\n\r\n- `CopyNetDatasetReader` no longer automatically adds `START_TOKEN` and `END_TOKEN`\r\n  to the tokenized source. If you want these in the tokenized source, it's up to\r\n  the source tokenizer.\r\n\r\n### Added\r\n\r\n- Added two models for fine-grained NER\r\n- Added a category for multiple choice models, including a few reference implementations\r\n- Implemented manual distributed sharding for SNLI dataset reader.\r\n\r\n## Commits\r\n\r\ndd60f94 Prepare for release v1.1.0rc1\r\nda83a4e build and publish models docs (#91)\r\n4b2178b implement manual distributed sharding for SNLI reader (#89)\r\n1a2a8f4 Updates the SRL model (#93)\r\n8a93743 Updated the fine-grained NER transformer model (#92)\r\nb913333 Multiple Choice (#75)\r\n09395d2 updates for new transformers release (#88)\r\n11c6814 fix the bug of bimpm and update CHANGELOG (#87)\r\na735ddd Fix the regularizer of QANet model (#86)\r\n0ce14da fixes for next_token_lm (#85)\r\n37136f8 skip docker build on nightly release\r\n82aa9ac Fine grained NER (#84)\r\n4b5b939 fix test fixture\r\n947beb0 remove unused param in copynet reader\r\n9ec65df fix nightly Docker workflow\r\n3019a4e fix workflow skip conditions\r\ncc60ab9 use small dummy transformer for copynet test (#83)\r\nac9f214 fix nightly workflow\r\n596e6a7 Bump mypy from 0.781 to 0.782 (#82)\r\nd210c2f add nightly releases (#81)\r\n935a2a8 dont add START and END tokens to source in CopyNet (#79)\r\nd6798ce update skip conditions on const-parser-test (#80)\r\n2754f88 Bump mypy from 0.780 to 0.781 (#78)\r\nd3588ad Make CopyNet work with pretrained transformer models (#76)",
        "dateCreated": "2020-07-14T21:18:19Z",
        "datePublished": "2020-07-14T21:23:18Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.1.0rc1",
        "name": "v1.1.0rc1",
        "tag_name": "v1.1.0rc1",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.1.0rc1",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/28562506",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.1.0rc1"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "Release 1.0 corresponding to the [AllenNLP 1.0 Release](https://github.com/allenai/allennlp/releases/tag/v1.0.0).",
        "dateCreated": "2020-06-16T18:44:31Z",
        "datePublished": "2020-06-16T18:46:44Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.0.0",
        "name": "v1.0.0",
        "tag_name": "v1.0.0",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.0.0",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/27610571",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.0.0"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "## Changed\r\n\r\n- Removed deprecated `\"simple_seq2seq\"` predictor\r\n\r\n## Fixed\r\n\r\n- Replaced `deepcopy` of `Instance`s with new `Instance.duplicate()` method.\r\n- A bug where pretrained sentence taggers would fail to be initialized because some of the models\r\n  were not imported.\r\n- A bug in some RC models that would cause mixed precision training to crash when using NVIDIA apex.\r\n- Predictor names were inconsistently switching between dashes and underscores. Now they all use underscores.\r\n\r\n## Added\r\n\r\n- Added option to SemanticDependenciesDatasetReader to not skip instances that have no arcs, for validation data\r\n- Added a default predictors to several models\r\n- Added sentiment analysis models to pretrained.py\r\n- Added NLI models to pretrained.py\r\n\r\n## Commits\r\n\r\n1b2682b prepare for release v1.0.0rc6\r\nc0821a0 Adds SST and NLI models to the list of pretrained models (#73)\r\n4b010c0 Remove some files I merged by accident (#74)\r\n2b9ca77 Sets a default predictor for several models (#71)\r\n961da3e Fix casing in NLI model (#72)\r\nefe66bc update squad reader\r\n93273f0 Fix capitalization typo in SNLI RoBERTa config (#70)\r\n646d254 fixes on some structured prediction dataset readers (#65)\r\n5086811 Bump mypy from 0.770 to 0.780 (#69)\r\nd20cc8f Fixes for mixed precision training (#68)\r\n28a650c Fix training config (#66)\r\n053f0c0 fix SentenceTaggerPredictor import (#67)\r\n204be1a Update transformer_qa.jsonnet (#59)\r\n0ed63fa transformer qa quick fix\r\nae1c0ec Bump conllu from 2.3.2 to 3.0 (#63)\r\n4f17497 Use new Instance.duplicate() method instead of deepcopy (#64)\r\n6fac5b7 Bump version number",
        "dateCreated": "2020-06-11T22:02:04Z",
        "datePublished": "2020-06-11T22:04:40Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.0.0rc6",
        "name": "v1.0.0rc6",
        "tag_name": "v1.0.0rc6",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.0.0rc6",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/27474037",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.0.0rc6"
      },
      {
        "authorType": "User",
        "author_name": "dirkgr",
        "body": "### Changed\r\n\r\n- Moved the models into categories based on their format\r\n\r\n### Fixed\r\n\r\n- Made `transformer_qa` predictor accept JSON input with the keys \"question\" and \"passage\" to be consistent with the `reading-comprehension` predictor.\r\n\r\n### Added\r\n\r\n- `conllu` dependency (previously part of `allennlp`'s dependencies)\r\n\r\n### Commits\r\n\r\n9b6a2b0 Make the linter happy\r\nac0ed48 removed unused stuff from setup.py (#62)\r\nbd42c2c Update dev-requirements.txt\r\nc7cb218 Update version for release 1.0.0rc5\r\n822202f make transformer qa predictor consistent with other rc predictors (#60)\r\n114c203 add conllu dependency (#61)\r\n888596c Renames the model categories (#58)\r\nd21af08 Update README.md\r\n8ce4d0f add a 'clean' phony make target\r\ne0a590f add a CHANGELOG (#56)\r\n452b213 use tokenless codecov upload (#57)\r\n20fb509 Move seq2seq tests to right test directory (#51)\r\n1de3bac tick version to rc5\r\n",
        "dateCreated": "2020-05-27T00:49:36Z",
        "datePublished": "2020-05-27T00:50:42Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.0.0rc5",
        "name": "Version 1.0.0 Release Candidate 5",
        "tag_name": "v1.0.0rc5",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.0.0rc5",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/26923794",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.0.0rc5"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "## Commits\r\n\r\nef74f37 release workflow fixes\r\na6bd156 Update version for release v1.0.0rc4\r\n794640f Grammar\r\nef4df72 add commit and release Dockerfiles with instructions (#54)\r\nf8bdf21 remove pre-commit dev dependency (#53)\r\n54a5df8 specify namespace in roberta mnli (#52)\r\n05f48c7 Be compatible with the new tokenizers code (#44)\r\n3c764c9 Attach nltk and HF caches to docker containers in CI (#49)\r\n96de66f rename CI workflows\r\n08e7655 Add GPU test workflow (#48)\r\n13bebf0 fix new linting errors (#47)\r\n83a14c4 ensure docker images get commit SHA tag\r\n96d623c Adds the `pretrained` module from allennlp-hub. (#42)\r\n36020d5 fix\r\n98e222d update for new AllenNlpTestCase (#45)\r\n356eacf We need to specify the namespace now (#43)\r\n34204ed Clarify local install instructions (#41)\r\nc833e7b get rid of plugin mechanism (#40)\r\nd764ffc Fixes for ELMo embedder API change (#39)\r\n0449e5b Fix coref interpret test to use the right gradient length (#38)\r\n0b040af Fixes the roberta snli model (#37)\r\n316c909 reduce verbosity of linters (#36)\r\n04a2c73 Depend on an unreleased version of AllenNLP (#33)\r\n3a50436 add install instructions to README (#32)\r\n4e7698b Move default predictors (#31)",
        "dateCreated": "2020-05-14T21:55:46Z",
        "datePublished": "2020-05-14T21:56:21Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.0.0rc4",
        "name": "Version 1.0.0 Release Candidate 4",
        "tag_name": "v1.0.0rc4",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.0.0rc4",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/26535375",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.0.0rc4"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "## Commits\r\n\r\ndcc9674 tick version\r\n5209e07 Even better token annotation (#27)\r\n2cd9a73 try fix package build (#29)\r\nf6cb9ae small CI improvements (#26)\r\n92e6a85 Handles mismatched token annotation better (#24)",
        "dateCreated": "2020-04-28T15:44:01Z",
        "datePublished": "2020-04-28T15:44:55Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.0.0rc3",
        "name": "Version 1.0.0 Release Candidate 3",
        "tag_name": "v1.0.0rc3",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.0.0rc3",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/25969702",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.0.0rc3"
      },
      {
        "authorType": "User",
        "author_name": "epwalsh",
        "body": "## Commits\r\n\r\n8cf8621 Bump pre-commit from 2.2.0 to 2.3.0 (#25)\r\n7515207 Add PyPI badge/link\r\n1f841a3 Load allennlp_models with plugins (#23)\r\n0eff217 Update README.md (#20)\r\ne58d657 ensure setuptools and wheel installed first (#22)\r\n2e1454f Ensure code coverage computed correctly (#21)",
        "dateCreated": "2020-04-23T23:37:44Z",
        "datePublished": "2020-04-23T23:38:40Z",
        "html_url": "https://github.com/allenai/allennlp-models/releases/tag/v1.0.0.rc2",
        "name": "Version 1.0.0 Release Candidate 2",
        "tag_name": "v1.0.0.rc2",
        "tarball_url": "https://api.github.com/repos/allenai/allennlp-models/tarball/v1.0.0.rc2",
        "url": "https://api.github.com/repos/allenai/allennlp-models/releases/25831305",
        "zipball_url": "https://api.github.com/repos/allenai/allennlp-models/zipball/v1.0.0.rc2"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 366,
      "date": "Wed, 29 Dec 2021 23:19:39 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "nlp",
      "allennlp",
      "pytorch"
    ],
    "technique": "GitHub API"
  }
}
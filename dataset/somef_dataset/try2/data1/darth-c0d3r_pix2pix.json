{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<ol>\n\t<li>pix2pix Research Paper: https://arxiv.org/pdf/1611.07004.pdf</li>\n\t<li>GAN Research Paper: https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf</li>\n\t<li>MIT CVCL Dataset: http://cvcl.mit.edu/database.htm</li>\n\t<li>SSIM: https://en.wikipedia.org/wiki/Structural_similarity</li>\n\t<li>Official pix2pix Repo: https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix</li>\n\t<li>PyTorch Website: https://pytorch.org/</li>\n</ol>\n\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/darth-c0d3r/pix2pix",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-10-06T18:37:33Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-04-25T09:02:03Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9386831951616709,
        0.9787363018656788,
        0.9851554572449721,
        0.9799446449295832
      ],
      "excerpt": "CS 663 (Digital Image Processing) Project \nThe problem we are trying to solve is a general conversion of black and white images to colored. For this, we will be using Conditional GANs [Generative Adversarial Networks] to implement and extend the pix2pix network, which is a general neural network model to learn a mapping from one set of images to another, which, in our case will be from the set of black and white images to colored images. \nOur project can be easily extended to other tasks such as day to night, labels to street scene, deblurring images etc. as the basic pix2pix network is shared among all such applications. If time permits, we will try to apply our network to one of the other tasks as well. We will be using the PyTorch framework in Python to implement the network. \nThis is the Research Paper written on the pix2pix network written at the Berkeley AI Research (BAIR) Laboratory, UC Berkeley. This is the research paper that we are trying to replicate and apply to the task of colorizing Black and White images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.956432145537749,
        0.8694316430804894
      ],
      "excerpt": "Contains multiple databases composed of scenes belonging to the same semantic category. All images are of size 256x256, in jpeg format. \nThe evaluation metric that we have used to compare the results is SSIM (Structural Similarity Index) [4] It compares two images and gives an output between 0 and 1. 1 meaning that images are exactly same and 0 meaning that they are completely different. We use it to compare the generated images and the ground truth images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Repository for course project for CS663 (Digital Image Processing)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/darth-c0d3r/pix2pix/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 02:03:25 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/darth-c0d3r/pix2pix/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "darth-c0d3r/pix2pix",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8309873664390687
      ],
      "excerpt": "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8078396853347901
      ],
      "excerpt": "Before training, create a folder named saved_models in which the results will be automatically saved. After successfully creating the dataset and creating the folder, run the following command to start training the model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8011649990133305
      ],
      "excerpt": "The hyperparameters can be tuned by making the relevant changes in train.py, generator.py and discriminator.py files. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/darth-c0d3r/pix2pix/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "pix2pix",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pix2pix",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "darth-c0d3r",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/darth-c0d3r/pix2pix/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sat, 25 Dec 2021 02:03:25 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<ul>\n\t<li>Intro to GANs: https://medium.freecodecamp.org/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394</li>\n\t<li>Generative Models (Stanford): https://www.youtube.com/watch?v=5WoItGTWV54&index=13&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv</li>\n\t<li>GANs in PyTorch (Simple): https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f</li>\n\t<li>GANs in PyTorch (Official): https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html</li>\n\t<li>pix2pix Tutorial: https://towardsdatascience.com/cyclegans-and-pix2pix-5e6a5f0159c4</li>\n\t<li>Colorization with GAN Repo: https://github.com/ImagingLab/Colorizing-with-GANs</li>\n\t<li>GAN Hacks Repo: https://github.com/soumith/ganhacks</li>\n\t<li>Installing CUDA 9.0: https://gist.github.com/zhanwenchen/e520767a409325d9961072f666815bb8</li>\n\t<li>PyTorch Examples: https://cs230-stanford.github.io/pytorch-getting-started.html</li>\n</ul>\n",
      "technique": "Header extraction"
    }
  ]
}
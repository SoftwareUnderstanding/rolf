{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2006.11918",
      "https://arxiv.org/abs/1412.6980",
      "https://arxiv.org/abs/1904.00962",
      "https://arxiv.org/abs/ 2006.11918"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please cite as\n\n```bibtex\n@inproceedings{zhu2020maxva,\n  title = {Adaptive Learning Rates with Maximum Variation Averaging},\n  author = {Zhu, Chen and Cheng, Yu and Gan, Zhe and Huang, Furong and Liu, Jingjing and Goldstein, Tom},\n  booktitle = {arXiv: 2006.11918},\n  year = {2020},\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{zhu2020maxva,\n  title = {Adaptive Learning Rates with Maximum Variation Averaging},\n  author = {Zhu, Chen and Cheng, Yu and Gan, Zhe and Huang, Furong and Liu, Jingjing and Goldstein, Tom},\n  booktitle = {arXiv: 2006.11918},\n  year = {2020},\n}",
      "technique": "Regular expression"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/zhuchen03/maxva/master/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zhuchen03/MaxVA",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to Facebook AI Research Sequence-to-Sequence Toolkit (fairseq)\nWe want to make contributing to this project as easy and transparent as\npossible.\nPull Requests\nWe actively welcome your pull requests.\n\nFork the repo and create your branch from master.\nIf you've added code that should be tested, add tests.\nIf you've changed APIs, update the documentation.\nEnsure the test suite passes.\nMake sure your code lints.\nIf you haven't already, complete the Contributor License Agreement (\"CLA\").\n\nContributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\nComplete your CLA here: https://code.facebook.com/cla\nIssues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\nLicense\nBy contributing to Facebook AI Research Sequence-to-Sequence Toolkit (fairseq),\nyou agree that your contributions will be licensed under the LICENSE file in\nthe root directory of this source tree.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-10-16T21:20:32Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-13T16:03:49Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.990793401931073
      ],
      "excerpt": "This repository contains the implementation of the so-called Maximum Variation Averaging (MaxVA) proposed in our paper, Adaptive Learning Rates with Maximum Variation Averaging \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zhuchen03/maxva/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 30 Dec 2021 06:51:55 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/zhuchen03/MaxVA/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "zhuchen03/MaxVA",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/zhuchen03/maxva/tree/master/nmt_nlu/docs"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/scripts/compound_split_bleu.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/scripts/sacrebleu_pregen.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/language_model/prepare-wikitext-103.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/speech_recognition/datasets/prepare-librispeech.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/byte_level_bpe/get_data.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/joint_alignment_translation/prepare-wmt18en2de_no_norm_no_escape_no_agressive.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/roberta/preprocess_GLUE_tasks.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/roberta/preprocess_RACE.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/roberta/commonsense_qa/download_cqa_data.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/backtranslation/sacrebleu.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/backtranslation/tokenized_bleu.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/backtranslation/prepare-wmt18en2de.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/backtranslation/prepare-de-monolingual.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/translation/prepare-wmt14en2fr.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/translation/prepare-iwslt14.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/translation/prepare-iwslt17-multilingual.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/examples/translation/prepare-wmt14en2de.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/launch/run-iwslt-adabound.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/launch/run-iwslt-amsgrad.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/launch/run-glue-base.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/nmt_nlu/launch/run-iwslt-lamadam-tristage.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/image_classification/launch.sh",
      "https://raw.githubusercontent.com/zhuchen03/maxva/master/image_classification/launch/run_imagenet_largebatch.sh"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/zhuchen03/MaxVA/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "Cuda",
      "C++",
      "Lua",
      "Batchfile",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) Facebook, Inc. and its affiliates.\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Maximum Variation Averaging",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "MaxVA",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "zhuchen03",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zhuchen03/MaxVA/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Thu, 30 Dec 2021 06:51:55 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We used PyTorch v1.4.0 for the experiments. \nWe have divided the experiments into 4 folders:\n\n[synthetic_data](synthetic_data): You could run [`nonconvex.py`](synthetic_data/nonconvex.py) or [`nqm.py`](synthetic_data/nqm.py) to reproduce the experiments for the nonconvex function or the Noisy Quadratic Model. \n\n[image_classification](image_classification): Please refer to [`launch.sh`](image_classification/launch.sh) to launch the experiments on CIFAR10 and CIFAR100. For ImageNet, we provide our [implementation](image_classification/run_iamgenet_largebatch.sh) for large-batch training, which is able to achieve similar performance as reported in [LAMB](https://arxiv.org/abs/1904.00962). You could also plug the same optimizers into the [PyTorch official example code](https://github.com/pytorch/examples/blob/master/imagenet/main.py) and refer to the hyper-parameters in the paper.\n\n[nmt_nlu](nmt_nlu): Please first enter the [`nmt_nlu`](nmt_nlu) directory and then run `pip install --editable .`. \nFor Neural Machine Translation, please first [follow the steps](nmt_nlu/examples/translation#iwslt14-german-to-english-transformer) to download and process the data, and then refer to [`run-iwslt-lamadam-tristage.sh`](nmt_nlu/run-iwslt-lamadam-tristage.sh) to train a transformer with our optimizers from scratch. \n For the GLUE benchmark, again, first [follow the steps](nmt_nlu/examples/roberta/README.glue.md) to prepare the data, download a [`RoBERTa-base`](https://dl.fbaipublicfiles.com/fairseq/models/roberta.base.tar.gz) model and put it under `nmt_nlu/roberta-pretrained`, and use [`run-glue-base.sh`](nmt_nlu/run-glue-base.sh) to fine-tune a RoBERTa-base model on the GLUE tasks.\n\n[bert_pt](bert_pt): We provide the implementation of MAdam for large-batch pretraining of BERT, which integrates gradient clipping by default and is compatible with [Nvidia's BERT pretraining code](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling/BERT).\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1409.1556",
      "https://arxiv.org/abs/1905.13575"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bionic-toucan/Slic",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-23T16:44:52Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-28T12:55:34Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9816808871151049,
        0.9219689578679822,
        0.9608763605632823,
        0.9866318785505884,
        0.9936953507527785,
        0.8360337422315348,
        0.9515155442044695,
        0.9154928913851914
      ],
      "excerpt": "Slic is a fast image classification tool for identifying the large-scale features in a solar dataset. It is based on the VGG-13 convolutional neural network (CNN) and has the following architecture: \nwhere the coloured blocks refer to the convolutional feature detection layers with an increasing number of feature maps from left to right with the red circles between pairs of convolutional layers indicating maxpooling. \nThe grey block at the end is the classifier and consists of two fully-connected blocks along with dropout regularisation: \nThe output of the network is likelihood of the image containing a specific feature which is then modelled by the softmax distribution to give us the feature it is most likely to contain. \nThe initial training of Slic is done on H&alpha; &lambda;6563&#8491; data from Hinode/SOT (Solar Optical Telescope; data available here) and the training set consists of 13175 images split 90% to 10% for training to validation consisting of five features: filaments, flare ribbons, prominences, sunspots and the quiet Sun (i.e. the lack of any of the other four features). \nNote: filaments and prominences are the same physical feature but are geometrically different so are treated as different classes here. \nWe provide a pre-trained model trained for 5 epochs and a learning rate of &eta;=0.0005 that reaches an accuracy of 99.92%. This will be good enough for identifying these features in visible wavelengths. We provide an example notebook of how to use this tool for dataset traversal and give instructions on how to train from scratch if needed. \nThe file data.py contains a prep function for directories of data which reads in directories of fits files and reshapes the image to 256x256 (the input shape of the network), flattens the image and inserts a value corresponding to the label in that image. This can be done by import the function train_test_data from data.py or running \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9686349223319094,
        0.8740745338272614
      ],
      "excerpt": "A Jupyter notebook testing_example.ipynb has been provided with this repository to illustrate how to use this classifier for predictions on unseen data. With the release of this code we have included the trained model, a file called sol_class_4.pth which will need to be used to load the model in our example notebook. \nAn example of classification is shown below. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8500157972226798
      ],
      "excerpt": "We have included the pre-trained model with >99% accuracy - sol_class_4.pth. Alongside the prepped training and validation set that we used - named solar_train_data.npz and solar_test_data.npz, repectively. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A fast tool for solar image classification.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rhero12/Slic/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Thu, 23 Dec 2021 23:25:46 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/bionic-toucan/Slic/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "bionic-toucan/Slic",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/rhero12/Slic/master/testing_example.ipynb"
    ],
    "technique": "File Exploration"
  },
  "identifier": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://zenodo.org/badge/latestdoi/167217584",
      "technique": "Regular expression"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.864675010275582,
        0.8954566254400573,
        0.8128800671052612,
        0.8637914968052843,
        0.9503189345333785,
        0.9034335339604717
      ],
      "excerpt": "The file data.py contains a prep function for directories of data which reads in directories of fits files and reshapes the image to 256x256 (the input shape of the network), flattens the image and inserts a value corresponding to the label in that image. This can be done by import the function train_test_data from data.py or running \npython data.py --dataset \"path/to/dataset/\" --percent_split 10 --save_dir \"path/to/save/\" \nThe train_test_data function will save two .npz files (see documentation here for how the file format works): one for trainign and one for validation. \nThen we want to train the moddel now that the data has been prepped. We want to use the train.py file for this. Within train.py, we have functions for training and validating the model and an example of how to use these by calling the file as \npython train.py \nfollowed by any keyword arguments to be passed to the file. The model can also be trained by import train and validate from train.py but will require also importing solar_classifier from model.py and solar_dataset from dataset.py and then setting up the PyTorch model and loading the data into a PyTorch DataLoader (all of which is done implicitly when running train.py). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9352686999801025
      ],
      "excerpt": "<img src=\"examples/6563flareim.png\" width=\"400\" /> <img src=\"examples/6563flareprob.png\" width=\"400\" /> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/bionic-toucan/Slic/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019-2021 John Armstrong\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Slic: Solar Image Classification using Convolutional Neural Networks",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Slic",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "bionic-toucan",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bionic-toucan/Slic/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "bionic-toucan",
        "body": "Also updated class names to follow Python standard.",
        "dateCreated": "2019-03-08T13:31:10Z",
        "datePublished": "2019-03-08T13:34:32Z",
        "html_url": "https://github.com/bionic-toucan/Slic/releases/tag/1.1.1",
        "name": "New class for doing inference v2",
        "tag_name": "1.1.1",
        "tarball_url": "https://api.github.com/repos/bionic-toucan/Slic/tarball/1.1.1",
        "url": "https://api.github.com/repos/bionic-toucan/Slic/releases/15995243",
        "zipball_url": "https://api.github.com/repos/bionic-toucan/Slic/zipball/1.1.1"
      },
      {
        "authorType": "User",
        "author_name": "bionic-toucan",
        "body": "I have introduced a class for doing the classification and making plots which makes the inference tidier and easier to use (imo). This is reflected in the new testing_example.ipynb notebook.",
        "dateCreated": "2019-03-07T16:13:42Z",
        "datePublished": "2019-03-08T10:33:40Z",
        "html_url": "https://github.com/bionic-toucan/Slic/releases/tag/1.1.0",
        "name": "New class for doing inference",
        "tag_name": "1.1.0",
        "tarball_url": "https://api.github.com/repos/bionic-toucan/Slic/tarball/1.1.0",
        "url": "https://api.github.com/repos/bionic-toucan/Slic/releases/15992158",
        "zipball_url": "https://api.github.com/repos/bionic-toucan/Slic/zipball/1.1.0"
      },
      {
        "authorType": "User",
        "author_name": "bionic-toucan",
        "body": "",
        "dateCreated": "2019-02-28T15:47:49Z",
        "datePublished": "2019-02-28T16:23:04Z",
        "html_url": "https://github.com/bionic-toucan/Slic/releases/tag/1.0.1",
        "name": "Release for compatibility with Zenodo",
        "tag_name": "1.0.1",
        "tarball_url": "https://api.github.com/repos/bionic-toucan/Slic/tarball/1.0.1",
        "url": "https://api.github.com/repos/bionic-toucan/Slic/releases/15838017",
        "zipball_url": "https://api.github.com/repos/bionic-toucan/Slic/zipball/1.0.1"
      },
      {
        "authorType": "User",
        "author_name": "bionic-toucan",
        "body": "This is to coincide with the submission of the Slic paper. Here we include the training and validation data along with the >99.9% accurate model weights.",
        "dateCreated": "2019-02-28T15:47:49Z",
        "datePublished": "2019-02-28T16:12:45Z",
        "html_url": "https://github.com/bionic-toucan/Slic/releases/tag/1.0.0",
        "name": "Initial Release: Paper Submission",
        "tag_name": "1.0.0",
        "tarball_url": "https://api.github.com/repos/bionic-toucan/Slic/tarball/1.0.0",
        "url": "https://api.github.com/repos/bionic-toucan/Slic/releases/15837750",
        "zipball_url": "https://api.github.com/repos/bionic-toucan/Slic/zipball/1.0.0"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "For training:\n\n* NVIDIA GPU\n* CUDA 9.0+\n* `Python 3`+\n* `numpy`\n* `matplotlib`\n* `scipy`\n* `astropy`\n* `scikit-image`\n* `pandas`\n* `tqdm`\n* `PyTorch 0.4+`\n\nFor prediction:\n\n* `Python 3`+\n* `PyTorch 0.4+`\n* `numpy`\n* `matplotlib`\n* `astropy`\n* `scikit-image`\n* `tqdm`\n\nOptional:\n\n* `sunpy`\n* `palettable`\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Thu, 23 Dec 2021 23:25:46 GMT"
    },
    "technique": "GitHub API"
  }
}
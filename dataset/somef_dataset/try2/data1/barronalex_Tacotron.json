{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.10135"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/barronalex/Tacotron",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-04-18T00:23:43Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T22:53:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9578510905941545,
        0.9104595061949097
      ],
      "excerpt": "Implementation of Tacotron, an end-to-end neural network for speech synthesis. \nThe following playlist contain samples produced on unseen inputs by Tacotron trained for 180K steps on the Nancy Corpus with r=2 and scheduled sampling 0.5.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9823988979714658,
        0.9878095248872908,
        0.922912767267405,
        0.8826397270131037
      ],
      "excerpt": "When compared to the old samples, the alignment learned with r=2 is considerably better but the audio quality is noticeably rougher. \nI assume this partially a result of too little training (the original paper trained for at least 20 times longer) but I think it is also related to the scheduled sampling that was necessary to learn the alignment. I also updated the padding which fixed the repetition and corruption at the end of the samples. \nFor best results, use the Nancy corpus from the 2011 Blizzard Challenge. The data is freely availiable for research use on the signing of a license. After obtaining a username and password, add them to the 'download_data.sh' script to fetch it automatically.  \nWe also download the considerably smaller CMU ARCTIC dataset for testing which can be obtained without a license, but don't expect to get good results with it. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9754613306884817,
        0.9367118307692663,
        0.9367118307692663,
        0.9297822226084966
      ],
      "excerpt": "The reason it's so high is because empirically I found that there was around a 2X speed increase when reading the data from memory instead of disk. \nWith a K80 and r=2, we process 1 batch every ~2.5 seconds. \nWith a GTX1080 and r=2, we process 1 batch every ~1.5 seconds.  \nI've begun to implement the multi-speaker tacotron architecture suggested by the Deep Voice 2 paper, but it's currently untested. 'preprocess.py' has the VCTK corpus implemented but you need to download the data. Given the scale of this dataset (40 hours), I assume we'll get better results if we can get it to work. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation of Google's Tacotron in TensorFlow",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/barronalex/Tacotron/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 78,
      "date": "Sun, 26 Dec 2021 15:38:44 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/barronalex/Tacotron/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "barronalex/Tacotron",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/barronalex/Tacotron/master/download_data.sh",
      "https://raw.githubusercontent.com/barronalex/Tacotron/master/download_weights.sh"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/barronalex/Tacotron/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Tacotron",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Tacotron",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "barronalex",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/barronalex/Tacotron/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[Tensorflow 1.2](https://www.tensorflow.org/versions/r1.2/install/)\n\n[Librosa](https://github.com/librosa/librosa)\n\n[tqdm](https://github.com/noamraph/tqdm)\n\n[matplotlib](https://matplotlib.org/)\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 229,
      "date": "Sun, 26 Dec 2021 15:38:44 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To synthesize audio:\n\nFirst fetch the weights using the script provided\n\n\tbash download_weights.sh\n\nThen pass prompts (separated by end lines) to 'test.py' through stdin. The audio appears in Tensorboard.\n\n\tpython3 test.py < prompts.txt\n\t\n\techo \"This is a test prompt for the system to say.\" | python3 test.py\n\nTo train the model:\n\nFirst run the data fetching script (preferably after obtaining a username and password for the Nancy corpus)\n\n\tbash download_data.sh\n\nThen preprocess the data\n\n\tpython3 preprocess.py arctic\n\n\tpython3 preprocess.py nancy \n\n Now we're ready to start training\n\n\tpython3 train.py --train-set nancy (--restore optional)\n\nTo see the audio outputs created by Tacotron, open up Tensorboard.\n\nMonitoring the attention alignments produced under the images tab in Tensorboard is by far the best way to debug your model while its training. You'll likely only see generalization to new examples if/when the attention becomes monotonic. The gif below shows the model learning an alignment using the default parameters on the Nancy dataset.\n\n![Attention Alignments](https://github.com/barronalex/Tacotron/raw/master/images/attention.gif)\n\n",
      "technique": "Header extraction"
    }
  ]
}
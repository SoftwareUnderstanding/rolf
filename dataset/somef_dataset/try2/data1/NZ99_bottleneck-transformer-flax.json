{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2101.11605\">Bottleneck Transformers for Visual Recognition</a>, a powerful hybrid architecture that combines a ResNet-like architecture with global relative position self-attention.\n\nThe code in this repository is limited to the image classification models and based on the <a href=\"https://gist.github.com/aravindsrinivas/56359b79f0ce4449bcb04ab4b56a57a2\">authors' official code</a>.\n\n## Install\n\n```bash\n$ pip install bottleneck-transformer-flax\n```\n\n## Usage\n\n```python\nfrom jax import random\nfrom jax import numpy as jnp\nfrom bottleneck_transformer_flax import BoTNet, BoTNetConfig\n\n#example configuration for BoTNet-S1-128\nconfig = BoTNetConfig(\n    stage_sizes = [3, 4, 23, 12],\n    num_classes = 1000\n"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bibtex\n@misc{srinivas2021bottleneck,\n    title   = {Bottleneck Transformers for Visual Recognition}, \n    author  = {Aravind Srinivas and Tsung-Yi Lin and Niki Parmar and Jonathon Shlens and Pieter Abbeel and Ashish Vaswani},\n    year    = {2021},\n    eprint  = {2101.11605},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV}\n}\n```",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{srinivas2021bottleneck,\n    title   = {Bottleneck Transformers for Visual Recognition}, \n    author  = {Aravind Srinivas and Tsung-Yi Lin and Niki Parmar and Jonathon Shlens and Pieter Abbeel and Ashish Vaswani},\n    year    = {2021},\n    eprint  = {2101.11605},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    stage_sizes = [3, 4, 23, 12], \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    stage_sizes = [3, 4, 6, 12], \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    stage_sizes = [3, 4, 23, 12], \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9507374082549614
      ],
      "excerpt": "T3 | 30.4M | 30.4M | 33.5M \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/NZ99/bottleneck-transformer-flax",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-24T16:34:58Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-08T00:47:51Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9802343401385922
      ],
      "excerpt": "The code in this repository is limited to the image classification models and based on the <a href=\"https://gist.github.com/aravindsrinivas/56359b79f0ce4449bcb04ab4b56a57a2\">authors' official code</a>. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9583052426475669,
        0.9751707528528425
      ],
      "excerpt": "It's worth noting that the models as made available in this repository do not perfectly match the number of parameters as presented in the paper. The majority of the difference can however be explained by what I believe is an error in the script used by the authors to count the parameters: specifically, section 4.8.4 notes that Squeeze-and-Excite layers are only employed in ResNet bottleneck blocks, while the <a href=\"https://gist.github.com/aravindsrinivas/e8a9e33425e10ed0c69c1bf726b81495\">official script</a> does not correctly take this into account. Updating the script (specifically line 111) leads to an almost perfect match. \nThe number of parameters for each model is reported for clarity: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A JAX/Flax implementation of Bottleneck Transformers for Visual Recognition",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/NZ99/bottleneck-transformer-flax/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 22:03:13 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/NZ99/bottleneck-transformer-flax/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "NZ99/bottleneck-transformer-flax",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\n$ pip install bottleneck-transformer-flax\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/NZ99/bottleneck-transformer-flax/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Niccol\\xc3\\xb2 Zanichelli\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Bottleneck Transformers in JAX/Flax",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "bottleneck-transformer-flax",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "NZ99",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/NZ99/bottleneck-transformer-flax/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Mon, 27 Dec 2021 22:03:13 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\nfrom jax import random\nfrom jax import numpy as jnp\nfrom bottleneck_transformer_flax import BoTNet, BoTNetConfig\n\n#:example configuration for BoTNet-S1-128\nconfig = BoTNetConfig(\n    stage_sizes = [3, 4, 23, 12],\n    num_classes = 1000\n)\n\nrng = random.PRNGKey(seed=0)\nmodel = BoTNet(config=config)\nparams = model.init(rng, jnp.ones((1, 256, 256, 3), dtype=config.dtype))\nimg = random.uniform(rng, (2, 256, 256, 3))\nlogits, updated_state = model.apply(params, img, mutable=['batch_stats']) #: logits.shape is (2, 1000)\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "A BoTNet configuration has the following arguments:\n\n```python\nclass BoTNetConfig:\n    stage_sizes: Sequence[int]                                          #: Stages sizes (as in Table 13)\n    num_classes: int = 1000                                             #: Number of classes\n    stride_one: bool = True                                             #: Whether the model is a BoTNet-S1\n    se_ratio: float = 0.0625                                            #: How much to squeeze\n    activation_fn: ModuleDef = nn.swish                                 #: Activation function\n    num_heads: int = 4                                                  #: Number of heads in multi head self attention\n    head_dim: int = 128                                                 #: Head dimension in multi head self attention\n    initial_filters: int = 64                                           #: Resnet stem output channels\n    projection_factor: int = 4                                          #: Ratio between block output and input channels\n    bn_momentum: float = 0.9                                            #: Batch normalization momentum\n    bn_epsilon: float = 1e-5                                            #: Batch normalization epsilon\n    dtype: jnp.dtype = jnp.float32                                      #: dtype of the computation\n    precision: Any = jax.lax.Precision.DEFAULT                          #: Numerical precision of the computation\n    kernel_init: Callable = initializers.he_uniform()                   #: Initializer function for the weight matrix\n    bias_init: Callable = initializers.normal(stddev=1e-6)              #: Initializer function for the bias\n    posemb_init: Callable = initializers.normal(stddev=head_dim**-0.5)  #: Initializer function for positional embeddings\n```\n\nProvided below are example configurations for all BoTNets.\n\n",
      "technique": "Header extraction"
    }
  ]
}
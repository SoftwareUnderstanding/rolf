{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1802.03268\n\n[2] \"Regularized Evolution for Image Classifier Architecture Search\",\nEsteban Real, Alok Aggarwal, Yanping Huang, Quoc V Le, https://arxiv.org/abs/1802.01548\n\n[3] \"DARTS: Differentiable Architecture Search\",\nHanxiao Liu, Karen Simonyan, Yiming Yang, https://arxiv.org/abs/1806.09055\n\n[4] \"Neural Architecture Construction using EnvelopeNets\",\nPurushotham Kamath, Abhishek Singh, Debo Dutta, https://arxiv.org/abs/1803.06744\n\n\n## Questions?\n\n* Documentation: amla.readthedocs.org\n* Twitter: @amla_ai\n* Slack: ciscoai.slack.com/amla\n\n## Authors\n* Utham Kamath pukamath@cisco.com\n* Abhishek Singh abhishs8@cisco.com\n* Debo Dutta dedutta@cisco.com\n\nIf you use AMLA for your research, please cite this [paper](./docs/design/amla.pdf",
      "https://arxiv.org/abs/1802.01548\n\n[3] \"DARTS: Differentiable Architecture Search\",\nHanxiao Liu, Karen Simonyan, Yiming Yang, https://arxiv.org/abs/1806.09055\n\n[4] \"Neural Architecture Construction using EnvelopeNets\",\nPurushotham Kamath, Abhishek Singh, Debo Dutta, https://arxiv.org/abs/1803.06744\n\n\n## Questions?\n\n* Documentation: amla.readthedocs.org\n* Twitter: @amla_ai\n* Slack: ciscoai.slack.com/amla\n\n## Authors\n* Utham Kamath pukamath@cisco.com\n* Abhishek Singh abhishs8@cisco.com\n* Debo Dutta dedutta@cisco.com\n\nIf you use AMLA for your research, please cite this [paper](./docs/design/amla.pdf",
      "https://arxiv.org/abs/1806.09055\n\n[4] \"Neural Architecture Construction using EnvelopeNets\",\nPurushotham Kamath, Abhishek Singh, Debo Dutta, https://arxiv.org/abs/1803.06744\n\n\n## Questions?\n\n* Documentation: amla.readthedocs.org\n* Twitter: @amla_ai\n* Slack: ciscoai.slack.com/amla\n\n## Authors\n* Utham Kamath pukamath@cisco.com\n* Abhishek Singh abhishs8@cisco.com\n* Debo Dutta dedutta@cisco.com\n\nIf you use AMLA for your research, please cite this [paper](./docs/design/amla.pdf",
      "https://arxiv.org/abs/1803.06744\n\n\n## Questions?\n\n* Documentation: amla.readthedocs.org\n* Twitter: @amla_ai\n* Slack: ciscoai.slack.com/amla\n\n## Authors\n* Utham Kamath pukamath@cisco.com\n* Abhishek Singh abhishs8@cisco.com\n* Debo Dutta dedutta@cisco.com\n\nIf you use AMLA for your research, please cite this [paper](./docs/design/amla.pdf"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] \"Efficient Neural Architecture Search via Parameter Sharing\",\nHieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, Jeff Dean, https://arxiv.org/abs/1802.03268\n\n[2] \"Regularized Evolution for Image Classifier Architecture Search\",\nEsteban Real, Alok Aggarwal, Yanping Huang, Quoc V Le, https://arxiv.org/abs/1802.01548\n\n[3] \"DARTS: Differentiable Architecture Search\",\nHanxiao Liu, Karen Simonyan, Yiming Yang, https://arxiv.org/abs/1806.09055\n\n[4] \"Neural Architecture Construction using EnvelopeNets\",\nPurushotham Kamath, Abhishek Singh, Debo Dutta, https://arxiv.org/abs/1803.06744\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@INPROCEEDINGS{kamath18,\n  AUTHOR = {P. Kamath and A. Singh and D. Dutta},\n  TITLE = {{AMLA: An AutoML frAmework for Neural Network Design}}\n  BOOKTITLE = {AutoML Workshop at ICML 2018},\n  CITY = {Stockholm},\n  MONTH = {July},\n  YEAR = {2018},\n  PAGES = {},\n  URL = {}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.940907335143959
      ],
      "excerpt": "* Test scripts: Regression scripts, please! \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CiscoAI/amla",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to AMLA\nFeature enhancements\nIf you have made an improvement to an existing feature, please send us a pull request.\nSee the section on pull requests. \nFeature requests\nFeature requests are welcome. \n\n\nIf you would like to see a new major feature added, please consider making a feature request\nCurrent feature requests are listed in the (issue tracker)(#issuetracker).\nIf you do not see an existing feature request that covers your feature, please add a new feature request to the issue tracker. \nPlease use the label \"Feature Request\" on the issue when adding a new feature request.\n\n\nFeature requests with major codebase changes need a proposal document. \nMinor feature requests don't need an associated proposal.\nIf your feature request already exists in the tracker, there may be already be a proposal submitted for it.\nCurrent proposals are organised by area here\nThe proposals follow the naming convention: docs/proposals/<area>/<github username>-<proposal name>.md, where the proposal name is an area specific name: E.g. docs/proposals/deployer/pkamath-kubeflow.md\nIf your feature request fits in an existing area, and a proposal exists, please consider contributing to \nthe proposal\n\n\nIf a proposal does not exist, please consider authoring a proposal. \nProposals should be reasonably well written, but do not need to be perfect.\nCover at least the following:\n\nDefinition: What the feature is\nProblem/Motivation: Why the feature is needed\nSolution: What the feature will do\nDesign: How the feature will be implemented, why is this the chosen method, other possible ways to implement\nPlan: When the feature development will start and how long it will take\n\n\n\nHere is an example of a proposal.\nOnce your proposal is in reasonable shape, send us a pull request for the proposal and update the issue with your proposal.\nProposals will be discussed by the community. \nIf there are multiple proposals in a single area, the proposals will reviewed and, depending on feedback, may be merged into a single final proposal:  proposals/<area>/proposal-final-<proposal-name>.md\nImplementation will begin once there is agreement within the community on the proposal.\nIssue tracker\nThe issue tracker is the preferred channel for bug reports, features requests and submitting pull requests\n\n\nPlease do not use the issue tracker for personal support requests.\n\n\nUse GitHub's \"reactions\" feature\n  Please do not post comments consisting solely of \"+1\" or \":thumbsup:\".\n\n\nBug reports\nA bug is a demonstrable problem that is caused by the code in the repository.\nGood bug reports are extremely helpful, so thanks!\nGuidelines for bug reports:\n\n\nValidate and lint your code &mdash; to ensure your problem isn't caused by a simple error in your own code.\n\n\nUse the GitHub issue search &mdash; check if the issue has already been reported.\n\n\nCheck if the issue has been fixed &mdash; try to reproduce it using the latest master or development branch in the repository.\n\n\nIsolate the problem &mdash; ideally create a reduced test case.\n\n\nA good bug report shouldn't leave others needing to chase you up for more\ninformation. Please try to be as detailed as possible in your report. What is\nyour environment? What steps will reproduce the issue? All these details will help people to fix\nany potential bugs.\nExample:\n\nShort and descriptive example bug report title\nA summary of the issue and the environment in which it occurs.\nInclude the steps required to reproduce the bug.\n\nThis is the first step\nThis is the second step\nFurther steps, etc.\n\n&lt;url&gt; - a link to the reduced test case\nAny other information you want to share that is relevant to the issue being\nreported. This might include the lines of code that you have identified as\ncausing the bug, and potential solutions (and your opinions on their\nmerits).\n\nPull requests\nGood pull requests\u2014patches, improvements, new features\u2014are a fantastic\nhelp. They should remain focused in scope and avoid containing unrelated\ncommits.\nPlease ask first before embarking on any significant pull request (e.g.\nimplementing features, refactoring code, porting to a different language),\notherwise you risk spending a lot of time working on something that the\nproject's developers might not want to merge into the project.\nAdhering to the following process is the best way to get your work\nincluded in the project:\n\nFork the project, clone your fork,\n   and configure the remotes:\n\nbash\n   # Clone your fork of the repo into the current directory\n   git clone https://github.com/&lt;your-username&gt;/amla.git\n   # Navigate to the newly cloned directory\n   cd amla\n   # Assign the original repo to a remote called \"upstream\"\n   git remote add upstream https://github.com/ciscoai/amla.git\n\nIf you cloned a while ago, get the latest changes from upstream:\n\nbash\n   git checkout master\n   git pull upstream master\n\nCreate a new topic branch (off the main project development branch) to\n   contain your feature, change, or fix:\n\nbash\n   git checkout -b &lt;topic-branch-name&gt;\n\n\nCommit your changes in logical chunks. Use Git's\n   interactive rebase\n   feature to tidy up your commits before making them public.\n\n\nLocally merge (or rebase) the upstream development branch into your topic branch:\n\n\nbash\n   git pull [--rebase] upstream master\n\nPush your topic branch up to your fork:\n\nbash\n   git push origin &lt;topic-branch-name&gt;\n\nOpen a Pull Request with a clear title and description against the master branch.\n\nIMPORTANT: By submitting a patch, you agree to allow the project owners to license your work under the terms of the Apache 2.0 License.\nSemantic Git commit messages\nInspired by Sparkbox's awesome article on semantic commit messages. Please use following commit message format.\n\nchore (updating build tasks etc; no production code change) -> git test -m 'chore: commit-message-here'\ndocs (changes to documentation) -> git commit -m 'docs: commit-message-here'\nfeat (new feature) -> git commit -m 'feat: commit-message-here'\nfix (bug fix) -> git commit -m 'fix: commit-message-here'\nrefactor (refactoring production code) -> git commit -m 'refactor: commit-message-here'\nstyle (formatting, missing semi colons, etc; no code change) -> git commit -m 'style: commit-message-here'\ntest (adding missing tests, refactoring tests; no production code change) -> git test -m 'refactor: commit-message-here'\n\nCode guidelines\nPython\nAdhere to the PEP8 standard.\n\nUse pylint/autopep8 to check your code for coding standards. A score of is 8/10 and higher is considered acceptable.\n\nLicense\nBy contributing your code, you agree to license your contribution under the Apache 2.0 License.\nAcknowledgements\nParts of this document have been adapted from CoreUI's contribution guidelines.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-05-29T18:58:49Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-12T12:25:02Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "AMLA is a common framework to run different AutoML algorithms for neural networks without changing \nthe underlying systems needed to configure, train and evaluate the generated networks. This has two benefits:\n* It ensures that different AutoML algorithms can be easily compared\nusing the same set of hyperparameters and infrastructure, allowing for \neasy evaluation, comparison and ablation studies of AutoML algorithms.\n* It provides a easy way to deploy AutoML algorithms on multi-cloud infrastructure.\n\nWith a framework, we can manage the lifecycle of autoML easily. Without this, hyperparameters and architecture design are spread out, some embedded in the code, others in config files and other as command line parameters, making it hard to compare two algorithms or perform ablation studies.\n\nSome design principles of AMLA:\n* The network generation process is decoupled from the training/evaluation process.\n* The network specification model is independent of the implementation of the training/evaluation/generation code and ML library (i.e. whether it uses TensorFlow/PyTorch etc.).\n\nAMLA currently supports the [NAC using EnvelopeNets](http://arxiv.org/pdf/1803.06744) AutoML algorithm, and we are actively adding newer algorithms to the framework. More information on AutoML algorithms for Neural Networks can be found [here](https://github.com/hibayesian/awesome-automl-papers)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9552461393436432
      ],
      "excerpt": "AMLA is a framework for implementing and deploying AutoML algorithms for Neural Networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8058199761285423
      ],
      "excerpt": "* Scheduler: Starts and stops the AutoML tasks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9382087093982409,
        0.891912772859869
      ],
      "excerpt": "A more detailed description of the current architecture is available here \nThe current branch is limited to operation on a single host i.e. the CLI, scheduler, generation, training and evaluation all run on a single host. The scheduler may be run as a service or a library, while the generate/train and evaluate subtasks are run as processes. A distributed system that allows concurrent execution of multiple training/evaluation tasks and distributed training on a pod of machines is under development. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925427135736507
      ],
      "excerpt": "There are several areas in which development is yet to start or that are under development. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9573422167764913,
        0.8974309146238616,
        0.8546818415015562,
        0.8646015486257553,
        0.8504730880671966,
        0.841702045475098,
        0.8822780475299217
      ],
      "excerpt": "Here is how to contribute. \nHere are some areas that we need help with: \n* New AutoML algorithms Add support for new AutoML algorithms such as NAS, ENAS, AmoebaNet \n* Machine learning frameworks Add support for more machine learning frameworks such as PyTorch etc. \n* Standard model format Improve the model specification (add hyper parameters), support for ONNX, other standard model specification formats. \n* Deployers: Add support for Kubeflow as a deployer  \n* Front end: Contribute to ongoing development using vue.js \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "AutoML frAmework for Neural Networks",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CiscoAI/amla/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 18,
      "date": "Sat, 11 Dec 2021 04:10:32 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/CiscoAI/amla/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "CiscoAI/amla",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/CiscoAI/amla/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n    git clone https://github.com/ciscoai/amla\n    cd amla/amla\n    pip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8423847898464393
      ],
      "excerpt": "Here are some areas that we need help with: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8032978540980282
      ],
      "excerpt": "Run an AutoML algorithm (NAC) to generate/train/evaluate  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8314009762023576
      ],
      "excerpt": ":amla add_task configs/config.run.json \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8658513471116581,
        0.8875217056549277
      ],
      "excerpt": "Run the test training/evaluation task \n:amla add_task configs/config.run.test.json \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/CiscoAI/amla/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Apache License 2.0",
      "url": "https://api.github.com/licenses/apache-2.0"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'                                 Apache License\\n                           Version 2.0, January 2004\\n                        http://www.apache.org/licenses/\\n\\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\\n\\n   1. Definitions.\\n\\n      \"License\" shall mean the terms and conditions for use, reproduction,\\n      and distribution as defined by Sections 1 through 9 of this document.\\n\\n      \"Licensor\" shall mean the copyright owner or entity authorized by\\n      the copyright owner that is granting the License.\\n\\n      \"Legal Entity\" shall mean the union of the acting entity and all\\n      other entities that control, are controlled by, or are under common\\n      control with that entity. For the purposes of this definition,\\n      \"control\" means (i) the power, direct or indirect, to cause the\\n      direction or management of such entity, whether by contract or\\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\\n      outstanding shares, or (iii) beneficial ownership of such entity.\\n\\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\\n      exercising permissions granted by this License.\\n\\n      \"Source\" form shall mean the preferred form for making modifications,\\n      including but not limited to software source code, documentation\\n      source, and configuration files.\\n\\n      \"Object\" form shall mean any form resulting from mechanical\\n      transformation or translation of a Source form, including but\\n      not limited to compiled object code, generated documentation,\\n      and conversions to other media types.\\n\\n      \"Work\" shall mean the work of authorship, whether in Source or\\n      Object form, made available under the License, as indicated by a\\n      copyright notice that is included in or attached to the work\\n      (an example is provided in the Appendix below).\\n\\n      \"Derivative Works\" shall mean any work, whether in Source or Object\\n      form, that is based on (or derived from) the Work and for which the\\n      editorial revisions, annotations, elaborations, or other modifications\\n      represent, as a whole, an original work of authorship. For the purposes\\n      of this License, Derivative Works shall not include works that remain\\n      separable from, or merely link (or bind by name) to the interfaces of,\\n      the Work and Derivative Works thereof.\\n\\n      \"Contribution\" shall mean any work of authorship, including\\n      the original version of the Work and any modifications or additions\\n      to that Work or Derivative Works thereof, that is intentionally\\n      submitted to Licensor for inclusion in the Work by the copyright owner\\n      or by an individual or Legal Entity authorized to submit on behalf of\\n      the copyright owner. For the purposes of this definition, \"submitted\"\\n      means any form of electronic, verbal, or written communication sent\\n      to the Licensor or its representatives, including but not limited to\\n      communication on electronic mailing lists, source code control systems,\\n      and issue tracking systems that are managed by, or on behalf of, the\\n      Licensor for the purpose of discussing and improving the Work, but\\n      excluding communication that is conspicuously marked or otherwise\\n      designated in writing by the copyright owner as \"Not a Contribution.\"\\n\\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\\n      on behalf of whom a Contribution has been received by Licensor and\\n      subsequently incorporated within the Work.\\n\\n   2. Grant of Copyright License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      copyright license to reproduce, prepare Derivative Works of,\\n      publicly display, publicly perform, sublicense, and distribute the\\n      Work and such Derivative Works in Source or Object form.\\n\\n   3. Grant of Patent License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      (except as stated in this section) patent license to make, have made,\\n      use, offer to sell, sell, import, and otherwise transfer the Work,\\n      where such license applies only to those patent claims licensable\\n      by such Contributor that are necessarily infringed by their\\n      Contribution(s) alone or by combination of their Contribution(s)\\n      with the Work to which such Contribution(s) was submitted. If You\\n      institute patent litigation against any entity (including a\\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\\n      or a Contribution incorporated within the Work constitutes direct\\n      or contributory patent infringement, then any patent licenses\\n      granted to You under this License for that Work shall terminate\\n      as of the date such litigation is filed.\\n\\n   4. Redistribution. You may reproduce and distribute copies of the\\n      Work or Derivative Works thereof in any medium, with or without\\n      modifications, and in Source or Object form, provided that You\\n      meet the following conditions:\\n\\n      (a) You must give any other recipients of the Work or\\n          Derivative Works a copy of this License; and\\n\\n      (b) You must cause any modified files to carry prominent notices\\n          stating that You changed the files; and\\n\\n      (c) You must retain, in the Source form of any Derivative Works\\n          that You distribute, all copyright, patent, trademark, and\\n          attribution notices from the Source form of the Work,\\n          excluding those notices that do not pertain to any part of\\n          the Derivative Works; and\\n\\n      (d) If the Work includes a \"NOTICE\" text file as part of its\\n          distribution, then any Derivative Works that You distribute must\\n          include a readable copy of the attribution notices contained\\n          within such NOTICE file, excluding those notices that do not\\n          pertain to any part of the Derivative Works, in at least one\\n          of the following places: within a NOTICE text file distributed\\n          as part of the Derivative Works; within the Source form or\\n          documentation, if provided along with the Derivative Works; or,\\n          within a display generated by the Derivative Works, if and\\n          wherever such third-party notices normally appear. The contents\\n          of the NOTICE file are for informational purposes only and\\n          do not modify the License. You may add Your own attribution\\n          notices within Derivative Works that You distribute, alongside\\n          or as an addendum to the NOTICE text from the Work, provided\\n          that such additional attribution notices cannot be construed\\n          as modifying the License.\\n\\n      You may add Your own copyright statement to Your modifications and\\n      may provide additional or different license terms and conditions\\n      for use, reproduction, or distribution of Your modifications, or\\n      for any such Derivative Works as a whole, provided Your use,\\n      reproduction, and distribution of the Work otherwise complies with\\n      the conditions stated in this License.\\n\\n   5. Submission of Contributions. Unless You explicitly state otherwise,\\n      any Contribution intentionally submitted for inclusion in the Work\\n      by You to the Licensor shall be under the terms and conditions of\\n      this License, without any additional terms or conditions.\\n      Notwithstanding the above, nothing herein shall supersede or modify\\n      the terms of any separate license agreement you may have executed\\n      with Licensor regarding such Contributions.\\n\\n   6. Trademarks. This License does not grant permission to use the trade\\n      names, trademarks, service marks, or product names of the Licensor,\\n      except as required for reasonable and customary use in describing the\\n      origin of the Work and reproducing the content of the NOTICE file.\\n\\n   7. Disclaimer of Warranty. Unless required by applicable law or\\n      agreed to in writing, Licensor provides the Work (and each\\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\\n      implied, including, without limitation, any warranties or conditions\\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\\n      PARTICULAR PURPOSE. You are solely responsible for determining the\\n      appropriateness of using or redistributing the Work and assume any\\n      risks associated with Your exercise of permissions under this License.\\n\\n   8. Limitation of Liability. In no event and under no legal theory,\\n      whether in tort (including negligence), contract, or otherwise,\\n      unless required by applicable law (such as deliberate and grossly\\n      negligent acts) or agreed to in writing, shall any Contributor be\\n      liable to You for damages, including any direct, indirect, special,\\n      incidental, or consequential damages of any character arising as a\\n      result of this License or out of the use or inability to use the\\n      Work (including but not limited to damages for loss of goodwill,\\n      work stoppage, computer failure or malfunction, or any and all\\n      other commercial damages or losses), even if such Contributor\\n      has been advised of the possibility of such damages.\\n\\n   9. Accepting Warranty or Additional Liability. While redistributing\\n      the Work or Derivative Works thereof, You may choose to offer,\\n      and charge a fee for, acceptance of support, warranty, indemnity,\\n      or other liability obligations and/or rights consistent with this\\n      License. However, in accepting such obligations, You may act only\\n      on Your own behalf and on Your sole responsibility, not on behalf\\n      of any other Contributor, and only if You agree to indemnify,\\n      defend, and hold each Contributor harmless for any liability\\n      incurred by, or claims asserted against, such Contributor by reason\\n      of your accepting any such warranty or additional liability.\\n\\n   END OF TERMS AND CONDITIONS\\n\\n   APPENDIX: How to apply the Apache License to your work.\\n\\n      To apply the Apache License to your work, attach the following\\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\\n      replaced with your own identifying information. (Don\\'t include\\n      the brackets!)  The text should be enclosed in the appropriate\\n      comment syntax for the file format. We also recommend that a\\n      file or class name and description of purpose be included on the\\n      same \"printed page\" as the copyright notice for easier\\n      identification within third-party archives.\\n\\n   Copyright [yyyy] [name of copyright owner]\\n\\n   Licensed under the Apache License, Version 2.0 (the \"License\");\\n   you may not use this file except in compliance with the License.\\n   You may obtain a copy of the License at\\n\\n       http://www.apache.org/licenses/LICENSE-2.0\\n\\n   Unless required by applicable law or agreed to in writing, software\\n   distributed under the License is distributed on an \"AS IS\" BASIS,\\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n   See the License for the specific language governing permissions and\\n   limitations under the License.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "AMLA: an AutoML frAmework for Neural Networks",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "amla",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "CiscoAI",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CiscoAI/amla/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Current AMLA supports Tensorflow as the default machine learning library. \nTo install Tensorflow, follow the instructions here: \n- https://www.tensorflow.org/install/install_linux#InstallingVirtualenv\nto install TensorFlow in a virtualenv for GPU/CPU.\n- Alternatively, use an AWS DeepLearning AMI on an AWS GPU instance:\nhttp://aws.amazon.com/blogs/machine-learning/get-started-with-deep-learning-using-the-aws-deep-learning-ami/\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n    python amla.py\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Below are the configuration files to construct networks and run the constructed network for a few widely known AutoML/NAS algorithms.\nIn construction mode, AMLA generates networks using the algorithm.\nIn final network mode, AMLA runs the final network generated by an algorithm.\nFor some algorithms, we have included the config files for the construction as well as the final network.\nFor other algorithms, implementation is in progress, so we have provided only the final network \nconfiguration file, based on the network described in their papers/open source code.\n\n\n| Algorithm             | Dataset            | Mode                     | Config file                      | AMLA result| Paper result    |\n|-----------------------|--------------------|--------------------------|-------------------------------------------------------|----------------|-------------------|\n| NAC/EnvelopeNets<sup>4</sup>      | CIFAR10            | Construction             |  [configs/config.nac.construction.json](amla/configs/config.nac.construction.json)    | 0.25 days| 0.25 days|\n| NAC/EnvelopeNets      | CIFAR10            | Final network            |  [configs/config.nac.final.json](amla/configs/config.nac.final.json)           | 3.33%    | 3.33% |\n| NAC/EnvelopeNets      | Imagenet           | Final network            |  [configs/config.nac.imgnet.json](amla/configs/config.nac.imgnet.json)           | 11.77%  | 15.36% |\n| ENAS (Macrosearch)<sup>1</sup>   | CIFAR10            | Final network            |  [configs/config.enas.json](amla/configs/config.enas.json)   | 4.3%  | 4.23% |\n| ENAS                  | CIFAR10            | Final network            |  [configs/config.enas-micro.json](amla/configs/config.enas-micro.json)   | In Progress | 2.89%  |\n| AmoebaNet-B<sup>2</sup>           | CIFAR10            | Final network            |  [configs/config.amoebanet.b.json](amla/configs/config.amoebanet.b.json)| 5.32%  | 2.13% |\n| DARTS<sup>3</sup>                | CIFAR10            | Final network            |  [configs/config.darts.json](amla/configs/config.darts.json)      | 4.22%  | 2.94% |\n\nThe results columns should be interpreted based on the mode (construction or final network).\nIn construction mode the result is the time to generate the network on a NVidia V100 GPU. \nIn final network mode the result is the classification error rate.\n\nTo run an algorithm/network, run the command: \n```\namla add_task <config file>\n```\nwhere the config file is specified in the table above.\n\n\nNote: \n* The Imagenet network for NAC/EnvelopeNets was based on the CIFAR10 construction hyperparameters modified to values commonly used for Imagenet.\n* Tuning of some networks is in progress, so AMLA results may not yet match paper results.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 117,
      "date": "Sat, 11 Dec 2021 04:10:32 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "automl",
      "neural-architecture-search",
      "neural-networks",
      "deep-learning",
      "image-classification",
      "hyperparameter-tuning",
      "tensorflow",
      "pytorch"
    ],
    "technique": "GitHub API"
  }
}
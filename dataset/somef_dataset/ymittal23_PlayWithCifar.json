{
  "citation": [
    {
      "confidence": [
        0.8382884321903141
      ],
      "excerpt": "Objective: Image Classification on Cifar 10 dataset \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ymittal23/PlayWithCifar",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-09-07T15:49:04Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-09-08T16:23:15Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8485057370222888
      ],
      "excerpt": "Requirements: Since my google credits are expired I have decided to build this project on Google Colab. The project will use keras with tensorflow as backend. We don't need to install libraries on Colab and can start straight away.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9112610094309691
      ],
      "excerpt": "Since I am using Google Colab it will be little difficult to train heavy models like WideResnet which in turn can give really good accuracy (ex- https://github.com/fastai/fastai/blob/master/examples/cifar.ipynb) and tune them in a single day (I planned to finish this in a day), so I have decided to go with not so famous but light architecture 'DavidNet'. There is an online competition about fast training called DAWNBench, and the winner was David C. Page in April 2019, who built a custom 9-layer Residual ConvNet, or ResNet. Here I have used a 3 layer simple architecture referred as 'DavidNet'. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9422571859652716,
        0.8552360704960048
      ],
      "excerpt": "In DavidNet, training images go through the standard Cifar10 transformations, that is, pad 4 pixels to 40x40, crop back to 32x32, and randomly flip left and right. In addition, it applies the popular Cutout augmentation (https://arxiv.org/pdf/1708.04552.pdf) as a regularization measure, which alleviates overfitting. DavidNet trains the model with Stochastic Gradient Descent with Nesterov momentum (https://dominikschmidt.xyz/nesterov-momentum/), with a slanted triangular learning rate schedule. \nWe are using the same hyperparameters used in original model made by David here. Since it is a classification problem I am using categorical cross entropy as my loss function. It can be calculated as \u2212(ylog(p)+(1\u2212y)log(1\u2212p)).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Image Classification on Cifar 10 dataset",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ymittal23/PlayWithCifar/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Making it work in limited time was not easy. Challenge was to achieve more than 90% accuracy with limited resources and time.\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 12 Dec 2021 09:31:19 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ymittal23/PlayWithCifar/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ymittal23/PlayWithCifar",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ymittal23/PlayWithCifar/master/PlayWithCifar.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8506698786620527
      ],
      "excerpt": "Requirements: Since my google credits are expired I have decided to build this project on Google Colab. The project will use keras with tensorflow as backend. We don't need to install libraries on Colab and can start straight away.  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ymittal23/PlayWithCifar/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "PlayWithCifar",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "PlayWithCifar",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ymittal23",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ymittal23/PlayWithCifar/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 12 Dec 2021 09:31:19 GMT"
    },
    "technique": "GitHub API"
  }
}
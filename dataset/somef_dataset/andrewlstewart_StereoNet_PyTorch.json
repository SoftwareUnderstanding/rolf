{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1701.03077",
      "https://arxiv.org/abs/1807.08865\n\nX-StereoLab: https://github.com/meteorshowers/X-StereoLab/blob/9ae8c1413307e7df91b14a7f31e8a95f9e5754f9/disparity/models/stereonet_disp.py\n\nZhiXuanLi: https://github.com/zhixuanli/StereoNet/blob/f5576689e66e8370b78d9646c00b7e7772db0394/models/stereonet.py\n\nI believe ZhiXuanLi's repo follows the paper best up until line 107 (note their CostVolume computation is incorrect"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.806771293453087
      ],
      "excerpt": "Currently training (2021-10-03) (~12hrs per epoch on my 1070) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.994799811898885
      ],
      "excerpt": "Original paper: https://arxiv.org/abs/1807.08865 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9607166231062237
      ],
      "excerpt": "    https://github.com/zhixuanli/StereoNet/issues/12#issuecomment-508327106 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/andrewlstewart/StereoNet_PyTorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-25T04:56:56Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-02T10:47:57Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "for transformer in transformers: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.8649044316261184,
        0.860059181823877,
        0.8571156296511779
      ],
      "excerpt": ": model = StereoNet.load_from_checkpoint(path_to_checkpoint) \n: Here just instantiate the model with random weights \nmodel = StereoNet() \n: Set the model to eval and run the forward method without tracking gradients \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8223107292708446
      ],
      "excerpt": ": Remove the batch diemnsion and switch back to channels last notation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8066569641864957
      ],
      "excerpt": "Max disparity parameter during training = 256 with the mask applied \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9650359880082091
      ],
      "excerpt": "Validation EPE of 3.93 for all pixels (including >256). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8784269072484012,
        0.9370954604560812
      ],
      "excerpt": "Implementation of the StereoNet network to compute a disparity map using stereo RGB images. \nCurrently training, early results are decent.  Validation EPE <img src=\"https://render.githubusercontent.com/render/math?math=\\approx 3.9\"> pixels when using a maximum disparity mask of 256; ie. during training, no penalty is added to the loss value for disparities in the ground truth >256. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9850539694911491,
        0.8130371455066204
      ],
      "excerpt": "Implemented using PyTorch Lightning as a learning exercise to learn about stereo networks, PyTorch, and PyTorch lightning.  Feel free to make any comments or recommendations for better coding practice. \nCurrently implemented \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9680633139048501
      ],
      "excerpt": "When training, a left and right cost volume is computed with the loss arising from the mean of the losses of left and right disparity delta to ground truth. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8687110458923119
      ],
      "excerpt": "Two repos were relied on heavily to inform the network (along with the actual paper) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.919456622926849,
        0.9168677689617059,
        0.86484484667043,
        0.9384560699113289,
        0.8136810850899752,
        0.9551287782053235
      ],
      "excerpt": "I believe the implementation that I have written takes the best of both repos and follows the paper most closely. \nNoteably, the argmin'd disparity is computed prior to the bilinear interpolation (follows X-Stereo but not ZhiXuanLi, the latter do it reverse order). \nFurther, neither repo had a cascade of refinement networks and neither repo trained on both the left and right disparities.  I believe my repo has both of these correctly implemented. \nThe paper clearly states they use (many) batch norm layers while simultaneously using a batch size of 1.  I find this interesting.  I naively tried training on random 50% crops (same crop applied to left/right/and disparities) so that I could get more samples into a batch but I think I was losing too many features so the EPE was consistently high.  Currently, training using a single sample (left/right images and left/right disparity).  I still needed to crop down to 513x912 images in order to not run into GPU memory issues. \nCurrently unclear \nDo I need to have a max_disps parameter to help the model learn faster/better? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "StereoNet PyTorch Lightning",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/andrewlstewart/StereoNet_PyTorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 07 Dec 2021 10:56:10 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/andrewlstewart/StereoNet_PyTorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "andrewlstewart/StereoNet_PyTorch",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9969479943564111,
        0.9989505157564216
      ],
      "excerpt": "Install with: \npip install \"git+https://github.com/andrewlstewart/StereoNet_PyTorch\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8516465086305499
      ],
      "excerpt": "    https://github.com/zhixuanli/StereoNet/issues/12#issuecomment-508327106 \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9457175861910134
      ],
      "excerpt": "import numpy as np \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.803642239203928,
        0.929840116409593
      ],
      "excerpt": "from stereonet.model import StereoNet \nfrom stereonet import utils as utils \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9103899327599202,
        0.8020248056440433
      ],
      "excerpt": ": sample = {'left': utils.image_loader(path_to_left_rgb_image_file), \n:           'right': utils.image_loader(path_to_right_rgb_image_file) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8737288687529231,
        0.9005680313110354,
        0.8618180314646323
      ],
      "excerpt": "rng = np.random.default_rng() \nsample = {'left': (rng.random((540, 960, 3))255).astype(np.uint8),  #: [height, width, channel], \n          'right': (rng.random((540, 960, 3))255).astype(np.uint8)  #: [height, width, channel] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8924976426181745
      ],
      "excerpt": "transformers = [utils.ToTensor(), utils.PadSampleToBatch()] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003751159116907,
        0.8064477138450331
      ],
      "excerpt": "    sample = transformer(sample) \n: Load in the model from the trained checkpoint \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8381520159380502
      ],
      "excerpt": "    batched_prediction = model(sample) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8039436063309573
      ],
      "excerpt": "single_prediction = np.moveaxis(single_prediction, 0, 2)  #: [channel, height, width] -> [height, width, channel] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.887543279220489
      ],
      "excerpt": "<img src=\"./readme_images/Epoch_20_Val.JPG\" alt=\"Validation image\" style=\"width:1000px;\"/> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/andrewlstewart/StereoNet_PyTorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "The Unlicense",
      "url": "https://api.github.com/licenses/unlicense"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'This is free and unencumbered software released into the public domain.\\n\\nAnyone is free to copy, modify, publish, use, compile, sell, or\\ndistribute this software, either in source code form or as a compiled\\nbinary, for any purpose, commercial or non-commercial, and by any\\nmeans.\\n\\nIn jurisdictions that recognize copyright laws, the author or authors\\nof this software dedicate any and all copyright interest in the\\nsoftware to the public domain. We make this dedication for the benefit\\nof the public at large and to the detriment of our heirs and\\nsuccessors. We intend this dedication to be an overt act of\\nrelinquishment in perpetuity of all present and future rights to this\\nsoftware under copyright law.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\\nIN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR\\nOTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\\nARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\\nOTHER DEALINGS IN THE SOFTWARE.\\n\\nFor more information, please refer to https://unlicense.org'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "StereoNet implemented in PyTorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "StereoNet_PyTorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "andrewlstewart",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/andrewlstewart/StereoNet_PyTorch/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Tue, 07 Dec 2021 10:56:10 GMT"
    },
    "technique": "GitHub API"
  }
}
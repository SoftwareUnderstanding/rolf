{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1804.02767"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "YOLOv3 paper\nhttps://arxiv.org/abs/1804.02767\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8464440611196633
      ],
      "excerpt": "- Video processing functions for turning videos to frames and vice versa  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/albertsokol/yolov3-tf2",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-12-10T14:20:31Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-24T04:53:07Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9273441115049308
      ],
      "excerpt": "An implementation of YOLOv3 from scratch in Tensorflow 2! You can use this to train a YOLOv3 model on any data you like, provided it's in the correct format. Uses the Darknet-53 backbone, and YOLOv3 neck and head as per the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9785541837327395
      ],
      "excerpt": "- AP50 callback - calculate the AP50 at the end of each epoch and save the model with the best performance \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8732506685224759
      ],
      "excerpt": "- Video processing functions for turning videos to frames and vice versa  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8732980085668054
      ],
      "excerpt": "Use this to pretrain the Darknet-53 backbone on ImageNet/other data before training the full model. Note the provided pre-trained model further up. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9760537656282653
      ],
      "excerpt": " - CNN_INPUT_SIZE = length and width that the image will be resized to; this is therefore also the input size to the model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8198890177671628
      ],
      "excerpt": " - you can adjust the augmentation parameters by passing in different values for the arguments in the YoloGenerator constructor \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8938547407077921
      ],
      "excerpt": "This is the process of taking the large output tensor from YOLOv3 and converting it into a list of bounding box predictions as well as performing non-max suppression, and saving the output images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8145436144543254
      ],
      "excerpt": " - predict_folder(folder_paths): a list of folder paths to predict on, and save the outputs. Useful for making video frames etc.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "An implementation of YOLOv3 from scratch in Tensorflow 2.3 ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/albertsokol/yolov3-tf2/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 09 Dec 2021 23:57:09 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/albertsokol/yolov3-tf2/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "albertsokol/yolov3-tf2",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8584794248278913
      ],
      "excerpt": "pretrain_darknet.py (optional) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.950563948951535
      ],
      "excerpt": " - pretrain_darknet.py \n - train.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8241063761980817
      ],
      "excerpt": "Train the full YOLOv3 model.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8101807809168117
      ],
      "excerpt": " - Required input format: .csv file with 7 headers: filename, width, height, class, x1, y1, x2, y2. filename should be the name of the image with extension. width and height are the image dimensions. class is the class of the current bounding box. x1 and y1 are the absolute pixel values of the upper-left corner of the bounding box, while x2 and y2 are for the bottom-right corner. See train_labels.csv for an example.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9205404794631962
      ],
      "excerpt": " - Edit the train.py file to set BATCH_SIZE, and NUM_EPOCHS \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8548899265604964,
        0.9503189345333785
      ],
      "excerpt": "Finally, just make sure your paths are set correctly and then run train.py.  \npython train.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.812563613390825
      ],
      "excerpt": "predict.py reads the config.ini file to get some important info like the anchor sizes, the bounding box labels and their order. Make sure you set the path to the trained model.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9139501625343502
      ],
      "excerpt": " - predict(fname=None): used for debugging and quick checking. Open predict.py in the python shell with the command at the bottom of the file. Run yp.predict() to see how the model performs \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/albertsokol/yolov3-tf2/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "YOLOv3 in Tensorflow 2.x",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "yolov3-tf2",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "albertsokol",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/albertsokol/yolov3-tf2/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Tensorflow 2.x\n- pandas \n- matplotlib\n- tqdm (for progress bars) \n- OpenCV (for video processing and pretty bounding boxes)\n- imgaug (for image/bbox augmentation)\n- imageio (for image i/o)\n\nTo create a new anaconda environment with everything you need:\n\n`conda create -n yolov3_env python tensorflow pandas matplotlib tqdm opencv`\n\n`conda activate yolov3_env`\n\n`conda install -c conda-forge imageio imgaug`\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 09 Dec 2021 23:57:09 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[![Demo of model](https://github.com/albertsokol/yolov3-tf2/blob/main/readme_images/youtube_link.png)](https://www.youtube.com/watch?v=tXYPUMHGe7A \"My YOLOv3 implementation : object detection on dashcam footage\")\n\n",
      "technique": "Header extraction"
    }
  ]
}
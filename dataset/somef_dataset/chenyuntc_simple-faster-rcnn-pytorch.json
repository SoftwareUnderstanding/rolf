{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This work builds on many excellent works, which include:\n\n- [Yusuke Niitani's ChainerCV](https://github.com/chainer/chainercv) (mainly)\n- [Ruotian Luo's pytorch-faster-rcnn](https://github.com/ruotianluo/pytorch-faster-rcnn) which based on [Xinlei Chen's tf-faster-rcnn](https://github.com/endernewton/tf-faster-rcnn)\n- [faster-rcnn.pytorch by Jianwei Yang and Jiasen Lu](https://github.com/jwyang/faster-rcnn.pytorch).It mainly refer to [longcw's faster_rcnn_pytorch](https://github.com/longcw/faster_rcnn_pytorch)\n- All the above Repositories have referred to [py-faster-rcnn by Ross Girshick and Sean Bell](https://github.com/rbgirshick/py-faster-rcnn)  either directly or indirectly. \n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1506.01497",
      "https://arxiv.org/abs/1506.01497",
      "https://arxiv.org/abs/1506.01497"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/chenyuntc/simple-faster-rcnn-pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-12-09T13:13:54Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-10T08:18:37Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "**[Update:]** I've further simplified the code to pytorch 1.5, torchvision 0.6, and replace the customized ops roipool and nms with the one from torchvision.  if you want the old version code, please checkout branch [v1.0](https://github.com/chenyuntc/simple-faster-rcnn-pytorch/tree/v1.0)\n\n\n\nThis project is a **Simplified** Faster R-CNN implementation based on [chainercv](https://github.com/chainer/chainercv) and other [projects](#acknowledgement) . I hope it can serve as an start code for those who want to know the detail of Faster R-CNN.  It aims to:\n\n- Simplify the code (*Simple is better than complex*)\n- Make the code more straightforward (*Flat is better than nested*)\n- Match the performance reported in [origin paper](https://arxiv.org/abs/1506.01497) (*Speed Counts and mAP Matters*)\n\nAnd it has the following features:\n- It can be run as pure Python code, no more build affair. \n- It's a minimal implemention in around 2000 lines valid code with a lot of comment and instruction.(thanks to chainercv's excellent documentation)\n- It achieves higher mAP than the origin implementation (0.712 VS 0.699)\n- It achieve speed compariable with other implementation (6fps and 14fps for train and test in TITAN XP)\n- It's memory-efficient (about 3GB for vgg16)\n\n\n![img](imgs/faster-speed.jpg)\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8697567643378653
      ],
      "excerpt": "Note: the training shows great randomness, you may need a bit of luck and more epoches of training to reach the highest mAP. However, it should be easy to surpass the lower bound.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9968029537584643
      ],
      "excerpt": "dataloader: received 0 items of ancdata  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9359144916576442
      ],
      "excerpt": "Licensed under MIT, see the LICENSE for more detail. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A simplified implemention of Faster R-CNN that replicate performance from origin paper",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/chenyuntc/simple-faster-rcnn-pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1062,
      "date": "Sat, 11 Dec 2021 01:49:29 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/chenyuntc/simple-faster-rcnn-pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "chenyuntc/simple-faster-rcnn-pytorch",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/chenyuntc/simple-faster-rcnn-pytorch/master/demo.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Here is an example of create environ **from scratch** with `anaconda`\n\n```sh\n#: create conda env\nconda create --name simp python=3.7\nconda activate simp\n#: install pytorch\nconda install pytorch torchvision cudatoolkit=10.2 -c pytorch\n\n#: install other dependancy\npip install visdom scikit-image tqdm fire ipdb pprint matplotlib torchnet\n\n#: start visdom\nnohup python -m visdom.server &\n\n```\n\nIf you don't use anaconda, then:\n\n- install PyTorch with GPU (code are GPU-only), refer to [official website](http://pytorch.org)\n\n- install other dependencies:  `pip install visdom scikit-image tqdm fire ipdb pprint matplotlib torchnet`\n\n- start visdom for visualization\n\n```Bash\nnohup python -m visdom.server &\n```\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9532281292283433
      ],
      "excerpt": "[1]: make sure you install cupy correctly and only one program run on the GPU. The training speed is sensitive to your gpu status. see troubleshooting for more info. Morever it's slow in the start of the program -- it need time to warm up. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8808408323332929
      ],
      "excerpt": "Windows support \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8894968384106093,
        0.8894968384106093
      ],
      "excerpt": "|    train with caffe pretrained model     | 0.700-0.712 | \n| train with torchvision pretrained model  | 0.685-0.701 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9134772216012153
      ],
      "excerpt": "Download the training, validation, test data and VOCdevkit \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.873092472289916
      ],
      "excerpt": "modify voc_data_dir cfg item in utils/config.py, or pass it to program using argument like --voc-data-dir=/path/to/VOCdevkit/VOC2007/ . \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python misc/convert_caffe_pretrain.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8698978891677359
      ],
      "excerpt": "Then you could specify where caffe-pretraind model vgg16_caffe.pth stored in utils/config.py by setting caffe_pretrain_path. The default path is ok. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/chenyuntc/simple-faster-rcnn-pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/chenyuntc/simple-faster-rcnn-pytorch/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License\\n\\nCopyright (c) 2017 Yun Chen\\n\\nOriginal works by:\\n--------------------------------------------------------\\nchainer/chainercv\\nCopyright (c) 2017 Yusuke Niitani\\nLicensed under The MIT License\\nhttps://github.com/chainer/chainercv/blob/master/LICENSE\\n--------------------------------------------------------\\nFaster R-CNN\\nCopyright (c) 2015 Microsoft\\nLicensed under The MIT License\\nhttps://github.com/rbgirshick/py-faster-rcnn/blob/master/LICENSE\\n--------------------------------------------------------\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\nTHE SOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "A Simple and Fast Implementation of Faster R-CNN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "simple-faster-rcnn-pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "chenyuntc",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/chenyuntc/simple-faster-rcnn-pytorch/blob/master/README.MD",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Here is an example of create environ **from scratch** with `anaconda`\n\n```sh\n#: create conda env\nconda create --name simp python=3.7\nconda activate simp\n#: install pytorch\nconda install pytorch torchvision cudatoolkit=10.2 -c pytorch\n\n#: install other dependancy\npip install visdom scikit-image tqdm fire ipdb pprint matplotlib torchnet\n\n#: start visdom\nnohup python -m visdom.server &\n\n```\n\nIf you don't use anaconda, then:\n\n- install PyTorch with GPU (code are GPU-only), refer to [official website](http://pytorch.org)\n\n- install other dependencies:  `pip install visdom scikit-image tqdm fire ipdb pprint matplotlib torchnet`\n\n- start visdom for visualization\n\n```Bash\nnohup python -m visdom.server &\n```\n\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3414,
      "date": "Sat, 11 Dec 2021 01:49:29 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "object-detection",
      "faster-rcnn",
      "voc",
      "visdom",
      "pythonic",
      "cupy"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Download pretrained model from [Google Drive](https://drive.google.com/open?id=1cQ27LIn-Rig4-Uayzy_gH5-cW-NRGVzY) or [Baidu Netdisk( passwd: scxn)](https://pan.baidu.com/s/1o87RuXW)\n\n\nSee [demo.ipynb](https://github.com/chenyuntc/simple-faster-rcnn-pytorch/blob/master/demo.ipynb) for more detail.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\npython train.py train --env='fasterrcnn' --plot-every=100\n```\n\nyou may refer to `utils/config.py` for more argument.\n\nSome Key arguments:\n\n- `--caffe-pretrain=False`: use pretrain model from caffe or torchvision (Default: torchvison)\n- `--plot-every=n`: visualize prediction, loss etc every `n` batches.\n- `--env`: visdom env for visualization\n- `--voc_data_dir`: where the VOC data stored\n- `--use-drop`: use dropout in RoI head, default False\n- `--use-Adam`: use Adam instead of SGD, default SGD. (You need set a very low `lr` for Adam)\n- `--load-path`: pretrained model path, default `None`, if it's specified, it would be loaded.\n\nyou may open browser, visit `http://<ip>:8097` and see the visualization of training procedure as below:\n\n![visdom](imgs/visdom-fasterrcnn.png)\n\n",
      "technique": "Header extraction"
    }
  ]
}
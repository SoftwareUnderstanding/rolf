{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1605.06409",
      "https://arxiv.org/abs/1703.06211"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[stevens_cr_winchester_sample1]: ./images/AICITY/stevens_cr_winchester_sample1.jpeg \"stevens_cr_winchester_sample1\"\n[stevens_cr_winchester_sample2]: ./images/AICITY/stevens_cr_winchester_sample2.jpeg \"stevens_cr_winchester_sample2\"\n[walsh_santomas_sample1]: ./images/AICITY/walsh_santomas_sample1.jpeg \"walsh_santomas_sample1\"\n[walsh_santomas_sample2]: ./images/AICITY/walsh_santomas_sample2.jpeg \"walsh_santomas_sample2\"\n[480]: ./images/AICITY/480.png \"480\"\n[540]: ./images/AICITY/540.png \"540\"\n[1080]: ./images/AICITY/1080.png \"1080\"\n[mAP_AICity]: ./images/AICITY/mAP_AICity.png \"mAP_AICity\"\n\n[sample1]: ./images/UADETRAC/sample1.jpg \"sample1\"\n[sample2]: ./images/UADETRAC/sample2.jpg \"sample2\"\n[sample3]: ./images/UADETRAC/sample3.jpg \"sample3\"\n[sample4]: ./images/UADETRAC/sample4.jpg \"sample4\"\n[sample5]: ./images/UADETRAC/sample5.jpg \"sample5\"\n[sample6]: ./images/UADETRAC/sample6.jpg \"sample6\"\n[sample7]: ./images/UADETRAC/sample7.jpg \"sample7\"\n[sample8]: ./images/UADETRAC/sample8.jpg \"sample8\"\n[sample9]: ./images/UADETRAC/sample9.jpg \"sample9\"\n[sample10]: ./images/UADETRAC/sample10.jpg \"sample10\"\n[sample11]: ./images/UADETRAC/sample11.jpg \"sample11\"\n[sample12]: ./images/UADETRAC/sample12.jpg \"sample12\"\n[sample13]: ./images/UADETRAC/sample13.jpg \"sample13\"\n[Precision_Recall_curve]: ./images/UADETRAC/Precision_Recall_curve.png \"Precision_Recall_curve\"\n\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/NVIDIAAICITYCHALLENGE/AICity_Team6_ISU",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-08-10T20:21:15Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-09-12T06:01:32Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9808635747677819
      ],
      "excerpt": "This repository contains the source codes of RDFCN implementation for the detection tasks of NVIDIA AICity Challenge and AVSS2017 UA_DETRAC Challenge. This source code is built upon the original Deformable-ConvNets by rearchers from Microsoft Research Asia. The main contribution of this repo to the original repo includes: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8655696162471477
      ],
      "excerpt": "The track one of AI City Challenge by IEEE Smart World and NVIDIA required each paricipating team to detect 14-class objects from urban intersection surveillance cameras using deep learning methods. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.892093824843502
      ],
      "excerpt": "UA-DETRAC dataset consists of 10 hours of videos captured with a Cannon EOS 550D camera at 24 different locations at Beijing and Tianjin in China.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8863907452805428,
        0.9919235591453339,
        0.898289617066589
      ],
      "excerpt": "RDFCN stands for Region-based Deformable Fully Convolutional Networks. RDFCN consitas of two major components: \nR-FCN (Region-based Fully Convolutional Networks). R-FCN is initially described in a NIPS 2016 paper. The Key idea of R-FCN is increasing model inference speed by using more shared convolution. \nDeformable ConvNets (Deformable Convolutional Networks). Deformable ConvNets is initially described in an arxiv tech report. The key idea of Deformable ConvNets is increasing classification accuracy by using adaptive-shaped convolutional filter. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.965789986940569
      ],
      "excerpt": "One major contribution of this repo is adding a transfer learning module to the original implementation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9333138612895997,
        0.8747052558311736,
        0.9446971357290018,
        0.8974647237177427
      ],
      "excerpt": "There are multiple ways of transfer learning in this RFCN structure: \nInitialize using pretrained weights then fine-tune all the weight by training on AICITY data. \nInitialize using pretrained weights, freeze the weights in backbone resnet-101 and RPN, then fine-tune the location-sensitive score maps feature extractor and the output layer by training on AICITY data. \nInitialize using pretrained weights, freeze all the weights except the outlayer, then only fine-tune the outlayer by training on AICITY data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9359836704920265,
        0.886866387641971
      ],
      "excerpt": "Some insights of how we eventually selected transfer learning (the second strategy) can be found in the presentation \"experiments_before_workshop.pptx\" in presentations/ \nSample detections: (Annotations on the left with red boxes, detections on the right with green boxes, thresholded by condidence 0.1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Source code and code description of Team6_ISU for NVIDIA AICity Challenge 2017 track 1",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/NVIDIAAICITYCHALLENGE/AICity_Team6_ISU/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Tue, 07 Dec 2021 18:22:18 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/NVIDIAAICITYCHALLENGE/AICity_Team6_ISU/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "NVIDIAAICITYCHALLENGE/AICity_Team6_ISU",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/NVIDIAAICITYCHALLENGE/AICity_Team6_ISU/master/test_data_install.sh",
      "https://raw.githubusercontent.com/NVIDIAAICITYCHALLENGE/AICity_Team6_ISU/master/demo.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Carefully follow the instructions of the offical implementation for Deformable Convolutional Networks based on MXNet [here](https://github.com/msracver/Deformable-ConvNets). \n\nAt the end of this step: \n\n* The Deformable ConvNets repo should have been downloaded;\n\n* MXNet should have been downloaded and properly compiled;\n\n* The R-FCN demo should be able to run by `python ./rfcn/demo.py`.\n\nNote: \n\nFor installing MXnet on NVIDIA Jetson TX2, if the above [installation instruction](https://github.com/msracver/Deformable-ConvNets) doesn't work, you can try following these steps (The MXnet on Jetson TX2 installation has been verified by [Koray](https://www.linkedin.com/in/koray-ozcan-b003903b/)):\n\na. MxNet is only compatible with opencv-python >= 3.2.0.\nPlease first upgrade the OpenCV libraries for Jetson platform as described in [here](http://www.jetsonhacks.com/2017/04/05/build-opencv-nvidia-jetson-tx2/)\n\nb. Then install MXnet libraries for Jetson TX2 as described [here](http://mxnet.io/get_started/install.html) (Devices - NVIDIA Jetson TX2).  \n\n2. clone this repo into the root/parent directory of Deformable-ConvNets:\n\n`cd path/to/Deformable-ConvNets/..`\n\n`git clone https://github.com/wkelongws/RDFCN_UADETRAC_AICITY`\n\n3. implement the contribution codes in this repo to the Deformable-ConvNets folder:\n\n`cd RDFCN_UADETRAC_AICITY` \n\n`python setup.py`\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8609409144015712
      ],
      "excerpt": "Ubuntu 16.04, NVIDIA TITIAN X GPU, Python 2.7 (both training and inference).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9744789252391839
      ],
      "excerpt": "Finish the Installation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd RDFCN_UADETRAC_AICITY \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd Deformable-ConvNets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd Deformable-ConvNets \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8503924275771436
      ],
      "excerpt": "Add data inference function to output detection .txt files, one per image. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8213924835968616
      ],
      "excerpt": "Download the model weights from here. Put the downloaded file \"rfcn_AICityVOC1080_FreezeCOCO_rpnOnly_all_withsignal-0004.params\" in the root folder of this repo \"RDFCN_UADETRAC_AICITY\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8867967317361476
      ],
      "excerpt": "Comment line 242 in Deformable-ConvNets/rfcn/functions/inference_rcnn.py if you don't want to see labeled images on run time. By commenting line 242, the program will only output .txt detection files to \"Deformable-ConvNets/data/output\". \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.854312356854465
      ],
      "excerpt": "Test the model by running: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8854047914844907
      ],
      "excerpt": "python experiments/rfcn/rfcn_Inference_Shuo_AICity.py --cfg experiments/rfcn/cfgs/resnet_v1_101_voc0712_rfcn_dcn_Shuo_AICityVOC1080_FreezeCOCO_rpnOnly_all_withsignal.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8738153382325341
      ],
      "excerpt": "python experiments/rfcn/rfcn_transfer_learning_train_Shuo_AICity.py --cfg path/to/your/configuration/file \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8177286326313336
      ],
      "excerpt": "Initialize using pretrained weights then fine-tune all the weight by training on AICITY data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8158570819652751
      ],
      "excerpt": "Those three strategies have been implemented in \"transfer_learning_end2end_freezeNo.py\", \"transfer_learning_end2end_freezeRPN.py\", \"transfer_learning_end2end_freezeBoth.py\", respectively. To switch between different strategies, replace the codes in \"transfer_learning_end2end.py\" (placed in rfcn/ after running setup.py) with the one you want. You can choose the initialization weights by changing the codes starting at line 103 in \"transfer_learning_end2end.py\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749,
        0.8359299706379749,
        0.8359299706379749,
        0.8359299706379749
      ],
      "excerpt": "![alt text][stevens_cr_winchester_sample1] \n![alt text][stevens_cr_winchester_sample2] \n![alt text][walsh_santomas_sample1] \n![alt text][walsh_santomas_sample2] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][mAP_AICity] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][480] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][1080] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749,
        0.8359299706379749,
        0.8359299706379749,
        0.8359299706379749,
        0.8359299706379749,
        0.8359299706379749,
        0.8359299706379749,
        0.8359299706379749
      ],
      "excerpt": "![alt text][sample5] \n![alt text][sample6] \n![alt text][sample7] \n![alt text][sample9] \n![alt text][sample10] \n![alt text][sample11] \n![alt text][sample12] \n![alt text][sample13] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][Precision_Recall_curve] \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/NVIDIAAICITYCHALLENGE/AICity_Team6_ISU/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Implementation of multi-class object detection using RDFCN for NVIDIA AICity Challenge 2017 and AVSS2017 UA_DETRAC Challenge",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "AICity_Team6_ISU",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "NVIDIAAICITYCHALLENGE",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/NVIDIAAICITYCHALLENGE/AICity_Team6_ISU/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 20,
      "date": "Tue, 07 Dec 2021 18:22:18 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Download data from UADETRAC and AICity into `data/` folder\n\n2. Create configuration file\n\n3. `cd path/to/Deformable-ConvNets`\n\n4. Model training and Inference\n\n* To train model from scratch (for both AICITY and UADETRAC), run:\n\n`python experiments/rfcn/rfcn_end2end_train_Shuo_UADETRAC.py --cfg path/to/your/configuration/file`\n\nNote: For AICITY, based on our experience \"training from scratch\" doesn't yield good model. Please refer to \"Transfer Learning\" section for other solution.\n\n* To detect vechiles from the test dataset, run:\n\n`python experiments/rfcn/rfcn_Inference_Shuo_UADETRAC.py --cfg path/to/your/configuration/file`\n\n`python experiments/rfcn/rfcn_Inference_Shuo_AICity.py --cfg path/to/your/configuration/file`\n\nTwo sample configuration files, one for UADETRAC and one for AICity, have been added to `experiments/rfcn/cfgs/`\n\nThe weights of submitted model (and the corresponding configuration file) on aic1080 can be downloaded [here](https://1drv.ms/u/s!AmGvrNE6VIsKjUevX-7tNAhS_5AF).\n\nThe weights of submitted model (and the corresponding configuration file) on aic540 can be downloaded [here](https://1drv.ms/u/s!AmGvrNE6VIsKjUmeEitETomFbCXQ).\n\nThe weights of submitted model (and the corresponding configuration file) on aic480 can be downloaded [here](https://1drv.ms/u/s!AmGvrNE6VIsKjUiF1J2qP4TeNsRc).\n\nThe weights of submitted model (and the corresponding configuration file) on UADETRAC can be downloaded [here](https://1drv.ms/u/s!AmGvrNE6VIsKjVK3j5kV6BfDghAU).\n\n",
      "technique": "Header extraction"
    }
  ]
}
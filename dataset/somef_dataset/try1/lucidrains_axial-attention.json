{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1912.12180\">Axial attention</a> in Pytorch. A simple but powerful technique to attend to multi-dimensional data efficiently. It has worked wonders for me and many other researchers.\n\nSimply add some positional encoding to your data and pass it into this handy class, specifying which dimension is considered the embedding, and how many axial dimensions to rotate through. All the permutating, reshaping, will be taken care of for you.\n\nThis paper was actually rejected on the basis of being too simple. And yet, it has since been used successfully in a number of applications, among those <a href=\"https://ai.googleblog.com/2020/03/a-neural-weather-model-for-eight-hour.html\">weather prediction</a>, <a href=\"https://ai.googleblog.com/2020/08/axial-deeplab-long-range-modeling-in.html\"> all-attention image segmentation</a>. Just goes to show.\n\n### Install\n\n```bash\n$ pip install axial_attention\n```\n\n### Usage\n\nImage\n\n```python\nimport torch\nfrom axial_attention import AxialAttention\n\nimg = torch.randn(1, 3, 256, 256"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bibtex\n@misc{ho2019axial,\n    title  = {Axial Attention in Multidimensional Transformers},\n    author = {Jonathan Ho and Nal Kalchbrenner and Dirk Weissenborn and Tim Salimans},\n    year   = {2019},\n    archivePrefix = {arXiv}\n}\n```\n\n```bibtex\n@misc{wang2020axialdeeplab,\n    title   = {Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation},\n    author  = {Huiyu Wang and Yukun Zhu and Bradley Green and Hartwig Adam and Alan Yuille and Liang-Chieh Chen},\n    year    = {2020},\n    eprint  = {2003.07853},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV}\n}\n```\n\n```bibtex\n@inproceedings{huang2019ccnet,\n    title   = {Ccnet: Criss-cross attention for semantic segmentation},\n    author  = {Huang, Zilong and Wang, Xinggang and Huang, Lichao and Huang, Chang and Wei, Yunchao and Liu, Wenyu},\n    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},\n    pages   = {603--612},\n    year    = {2019}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{huang2019ccnet,\n    title   = {Ccnet: Criss-cross attention for semantic segmentation},\n    author  = {Huang, Zilong and Wang, Xinggang and Huang, Lichao and Huang, Chang and Wei, Yunchao and Liu, Wenyu},\n    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},\n    pages   = {603--612},\n    year    = {2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{wang2020axialdeeplab,\n    title   = {Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation},\n    author  = {Huiyu Wang and Yukun Zhu and Bradley Green and Hartwig Adam and Alan Yuille and Liang-Chieh Chen},\n    year    = {2020},\n    eprint  = {2003.07853},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CV}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{ho2019axial,\n    title  = {Axial Attention in Multidimensional Transformers},\n    author = {Jonathan Ho and Nal Kalchbrenner and Dirk Weissenborn and Tim Salimans},\n    year   = {2019},\n    archivePrefix = {arXiv}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucidrains/axial-attention",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-28T19:45:24Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-06T05:31:09Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation of Axial attention - attending to multi-dimensional data efficiently",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucidrains/axial-attention/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 17,
      "date": "Thu, 09 Dec 2021 05:00:33 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lucidrains/axial-attention/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "lucidrains/axial-attention",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\n$ pip install axial_attention\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lucidrains/axial-attention/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Phil Wang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Axial Attention",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "axial-attention",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "lucidrains",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucidrains/axial-attention/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-08-26T01:14:04Z",
        "datePublished": "2021-08-26T01:14:39Z",
        "html_url": "https://github.com/lucidrains/axial-attention/releases/tag/0.6.1",
        "name": "0.6.1",
        "tag_name": "0.6.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/axial-attention/tarball/0.6.1",
        "url": "https://api.github.com/repos/lucidrains/axial-attention/releases/48467720",
        "zipball_url": "https://api.github.com/repos/lucidrains/axial-attention/zipball/0.6.1"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-08-25T16:38:48Z",
        "datePublished": "2021-08-25T16:39:22Z",
        "html_url": "https://github.com/lucidrains/axial-attention/releases/tag/0.6.0",
        "name": "0.6.0",
        "tag_name": "0.6.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/axial-attention/tarball/0.6.0",
        "url": "https://api.github.com/repos/lucidrains/axial-attention/releases/48443598",
        "zipball_url": "https://api.github.com/repos/lucidrains/axial-attention/zipball/0.6.0"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-01-22T17:01:06Z",
        "datePublished": "2021-01-22T17:01:20Z",
        "html_url": "https://github.com/lucidrains/axial-attention/releases/tag/0.5.0",
        "name": "0.5.0",
        "tag_name": "0.5.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/axial-attention/tarball/0.5.0",
        "url": "https://api.github.com/repos/lucidrains/axial-attention/releases/36779462",
        "zipball_url": "https://api.github.com/repos/lucidrains/axial-attention/zipball/0.5.0"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-09-26T02:47:30Z",
        "datePublished": "2020-09-26T02:47:54Z",
        "html_url": "https://github.com/lucidrains/axial-attention/releases/tag/0.4.1",
        "name": "0.4.1",
        "tag_name": "0.4.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/axial-attention/tarball/0.4.1",
        "url": "https://api.github.com/repos/lucidrains/axial-attention/releases/31837335",
        "zipball_url": "https://api.github.com/repos/lucidrains/axial-attention/zipball/0.4.1"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-09-15T22:33:02Z",
        "datePublished": "2020-09-15T22:33:39Z",
        "html_url": "https://github.com/lucidrains/axial-attention/releases/tag/0.4.0",
        "name": "0.4.0",
        "tag_name": "0.4.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/axial-attention/tarball/0.4.0",
        "url": "https://api.github.com/repos/lucidrains/axial-attention/releases/31361216",
        "zipball_url": "https://api.github.com/repos/lucidrains/axial-attention/zipball/0.4.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 165,
      "date": "Thu, 09 Dec 2021 05:00:33 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "artificial-intelligence",
      "deep-learning",
      "attention-mechanism",
      "pytorch"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Image\n\n```python\nimport torch\nfrom axial_attention import AxialAttention\n\nimg = torch.randn(1, 3, 256, 256)\n\nattn = AxialAttention(\n    dim = 3,               #: embedding dimension\n    dim_index = 1,         #: where is the embedding dimension\n    dim_heads = 32,        #: dimension of each head. defaults to dim // heads if not supplied\n    heads = 1,             #: number of heads for multi-head attention\n    num_dimensions = 2,    #: number of axial dimensions (images is 2, video is 3, or more)\n    sum_axial_out = True   #: whether to sum the contributions of attention on each axis, or to run the input through them sequentially. defaults to true\n)\n\nattn(img) #: (1, 3, 256, 256)\n```\n\nChannel-last image latents\n\n```python\nimport torch\nfrom axial_attention import AxialAttention\n\nimg = torch.randn(1, 20, 20, 512)\n\nattn = AxialAttention(\n    dim = 512,           #: embedding dimension\n    dim_index = -1,      #: where is the embedding dimension\n    heads = 8,           #: number of heads for multi-head attention\n    num_dimensions = 2,  #: number of axial dimensions (images is 2, video is 3, or more)\n)\n\nattn(img) #: (1, 20, 20 ,512)\n```\n\nVideo\n\n```python\nimport torch\nfrom axial_attention import AxialAttention\n\nvideo = torch.randn(1, 5, 128, 256, 256)\n\nattn = AxialAttention(\n    dim = 128,           #: embedding dimension\n    dim_index = 2,       #: where is the embedding dimension\n    heads = 8,           #: number of heads for multi-head attention\n    num_dimensions = 3,  #: number of axial dimensions (images is 2, video is 3, or more)\n)\n\nattn(video) #: (1, 5, 128, 256, 256)\n```\n\nImage Transformer, with reversible network\n\n```python\nimport torch\nfrom torch import nn\nfrom axial_attention import AxialImageTransformer\n\nconv1x1 = nn.Conv2d(3, 128, 1)\n\ntransformer = AxialImageTransformer(\n    dim = 128,\n    depth = 12,\n    reversible = True\n)\n\nimg = torch.randn(1, 3, 512, 512)\n\ntransformer(conv1x1(img)) #: (1, 3, 512, 512)\n```\n\nWith axial positional embedding\n\n```python\nimport torch\nfrom axial_attention import AxialAttention, AxialPositionalEmbedding\n\nimg = torch.randn(1, 512, 20, 20)\n\nattn = AxialAttention(\n    dim = 512,\n    heads = 8,\n    dim_index = 1\n)\n\npos_emb = AxialPositionalEmbedding(\n    dim = 512,\n    shape = (20, 20)\n)\n\nimg = pos_emb(img)  #: (1, 512, 20, 20)  - now positionally embedded\nimg = attn(img)     #: (1, 512, 20, 20)\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Parts of the code are based on [tf-image-segmentation](https://github.com/warmspringwinds/tf-image-segmentation). If using, please cite his paper:\n\n      @article{pakhomov2017deep,\n        title={Deep Residual Learning for Instrument Segmentation in Robotic Surgery},\n        author={Pakhomov, Daniil and Premachandran, Vittal and Allan, Max and Azizian, Mahdi and Navab, Nassir},\n        journal={arXiv preprint arXiv:1703.08580},\n        year={2017}\n      }\n    \n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.08580"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{pakhomov2017deep,\n    title={Deep Residual Learning for Instrument Segmentation in Robotic Surgery},\n    author={Pakhomov, Daniil and Premachandran, Vittal and Allan, Max and Azizian, Mahdi and Navab, Nassir},\n    journal={arXiv preprint arXiv:1703.08580},\n    year={2017}\n  }\n\nLicense\nThis project is licensed under the MIT License - see the LICENSE.md file for details.\nUsing the framework\nIf you use the framework, please cite the following paper:\nGsaxner, Christina et al. Exploit 18F-FDG Enhanced Urinary Bladder in PET Data for Deep Learning Ground Truth Generation in CT Scans. SPIE Medical Imaging 2018.\n@inproceedings{gsaxner2018exploit,\n  title={Exploit 18 F-FDG enhanced urinary bladder in PET data for deep learning ground truth generation in CT scans},\n  author={Gsaxner, Christina and Pfarrkirchner, Birgit and Lindner, Lydia and Jakse, Norbert and Wallner, J{\\\"u}rgen and Schmalstieg, Dieter and Egger, Jan},\n  booktitle={Medical Imaging 2018: Biomedical Applications in Molecular, Structural, and Functional Imaging},\n  volume={10578},\n  pages={105781Z},\n  year={2018},\n  organization={International Society for Optics and Photonics}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9908446872115048,
        0.941750211128326,
        0.9502296357725528,
        0.9998626208238877,
        0.9775008735489126
      ],
      "excerpt": "If you use the framework, please cite the following paper: \nGsaxner, Christina et al. Exploit 18F-FDG Enhanced Urinary Bladder in PET Data for Deep Learning Ground Truth Generation in CT Scans. SPIE Medical Imaging 2018. \n  title={Exploit 18 F-FDG enhanced urinary bladder in PET data for deep learning ground truth generation in CT scans}, \n  author={Gsaxner, Christina and Pfarrkirchner, Birgit and Lindner, Lydia and Jakse, Norbert and Wallner, J{\\\"u}rgen and Schmalstieg, Dieter and Egger, Jan}, \n  booktitle={Medical Imaging 2018: Biomedical Applications in Molecular, Structural, and Functional Imaging}, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8944178096468923,
        0.9959021299438506,
        0.9617611649319913
      ],
      "excerpt": "  pages={105781Z}, \n  year={2018}, \n  organization={International Society for Optics and Photonics} \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cgsaxner/UB_Segmentation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-08-13T08:56:46Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-13T06:49:27Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8017336955492185,
        0.8724520110771885
      ],
      "excerpt": "A framework for urinary bladder segmentation in CT images using deep learning. \nContains code to train and test two different deep neural network architectures for semantic segmentation using training and testing data obtained from combined PET/CT scans. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9522991170342245,
        0.9899502371321842,
        0.870477015355188
      ],
      "excerpt": "The data was preprocessed and prepared using the MeVisLab network Exploit 18F-FDG enhanced urinary bladder in PET data for Deep Learning Ground Truth Generation in CT scans. \nThis software produces ground-truth segmentations of the urinary bladder in CT using the co-registered PET data. PET radiotracer 18F-FDG accumulates in the urinary bladder, therefore, this organ can be distinguished using simple thresholding. Furthermore, data augmentation is applied using MeVisLab software. For further information, please refer to the corresponding paper: \nExploit 18F-FDG Enhanced Urinary Bladder in PET Data for Deep Learning Ground Truth Generation in CT Scans. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8165499506596201
      ],
      "excerpt": "The script make_tfrecords_dataset.py contains code to convert a directory of image files to the TensorFlow recommended file format TFRecords. TFRecords files are easy and fast to process in TensorFlow. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9428221349397101,
        0.8384325717288192
      ],
      "excerpt": "FCN is based on FCN-8s by Long et al. using pre-trained VGG. \nResNet is based on DeepLab by Chen et al. using pre-trained ResNet V2. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code for automatic urinary bladder segmentation using Python and Tensorflow.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cgsaxner/UB_Segmentation/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Wed, 08 Dec 2021 19:25:51 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/cgsaxner/UB_Segmentation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "cgsaxner/UB_Segmentation",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8042533607015679,
        0.8042533607015679
      ],
      "excerpt": "True Positive Rate (TPR) \nTrue Negative Rate (TNR) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/cgsaxner/UB_Segmentation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 cgsaxner\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Automatic urinary bladder segmentation in CT images using deep learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "UB_Segmentation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "cgsaxner",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cgsaxner/UB_Segmentation/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To use the framework, you need:\n\n1. [Python](https://www.python.org/download/releases/3.5/) 3.5 with the packages specified in the [requirements.txt](https://github.com/cgsaxner/UB_Segmentation/blob/master/requirements.txt) file\n2. [TensorFlow](https://www.tensorflow.org/versions/r1.3/) 1.3\n3. [TensorFlow-Slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) library\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Wed, 08 Dec 2021 19:25:51 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To use the framework for creating a tf-records file:\n1. Place your images and ground truth in folders called **Images** and **Labels**, respectively.\n2. Specify the path to your data, the desired filename and the desired image size in [`make_tfrecords_dataset.py`](https://github.com/cgsaxner/UB_Segmentation/blob/master/make_tfrecords_dataset.py).\n3. Run the script!\n\nTo use the framework for training:\n1. Download the pre-trained model checkpoint you want to use from [TensorFlow-Slim](https://github.com/tensorflow/models/tree/master/research/slim#Pretrained) and place it in a **\\Checkpoints** folder in your project repository.\n2. Specify your paths in the top section of [`FCN_training.py`](https://github.com/cgsaxner/UB_Segmentation/blob/master/FCN_training.py) or [`ResNet_training.py`](https://github.com/cgsaxner/UB_Segmentation/blob/master/ResNet_training.py).\n3. Run the script!\n\nTo use the framework for testing:\n1. Specify your paths in the top section of [`FCN_testing.py`](https://github.com/cgsaxner/UB_Segmentation/blob/master/FCN_testing.py) or [`ResNet_testing.py`](https://github.com/cgsaxner/UB_Segmentation/blob/master/ResNet_testing.py).\n2. Run the script!\n  \n",
      "technique": "Header extraction"
    }
  ]
}
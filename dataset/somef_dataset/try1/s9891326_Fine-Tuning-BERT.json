{
  "citation": [
    {
      "confidence": [
        0.8356013927728488,
        0.9030859728368266
      ],
      "excerpt": "   1     0.9167    0.9167    0.9167        12 \n   2     0.9000    0.9000    0.9000        10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "click --help \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "            key: \"stable\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "            key: \"canary\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "| 384 | 12 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "| \u539f\u6a21\u578b | 268.65 | 1 | 0.11 | 18.61 | 0.00 | 2.00 | 5000 | 0 | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/s9891326/Fine-Tuning-BERT",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-17T08:20:14Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-29T01:40:41Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8892866267821946
      ],
      "excerpt": "                             (or other data files) for the task.  [required] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8932845613898472
      ],
      "excerpt": "                             save to .h5 format, and convert to savedModel, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8329286418118391
      ],
      "excerpt": "                             used this variable to deploy to tensorFlow \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9440711603776184
      ],
      "excerpt": "  --dropout_rate FLOAT       Discard some neuron in the network to prevent \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8071962534943495
      ],
      "excerpt": "  --do_inference BOOLEAN     Whether to run the model in inference mode on the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.916615265770008
      ],
      "excerpt": "                             to savedmodel, when input have \"tensorRT\" and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9255575360590778
      ],
      "excerpt": "                             save tflite format, but that is not correct work. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8872700807011955,
        0.860059181823877
      ],
      "excerpt": "                             the new model, please set where to load the old \n                             model dir. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9105130445908816,
        0.8488774965944276
      ],
      "excerpt": "                             of tags in the new dataset  [default: 0] \n  --help                     Show this message and exit. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model = TFAutoModel.from_pretrained( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.860059181823877
      ],
      "excerpt": "    model._saved_model_inputs_spec = None \n    sequence_output = model([input_word_ids, input_mask, segment_ids]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.875757795748326
      ],
      "excerpt": "    model = tf.keras.models.Model( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.860059181823877
      ],
      "excerpt": "    model.summary() \n    return model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8477678735851494
      ],
      "excerpt": "model = tf.keras.models.load_model(output_dir) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8488774965944276
      ],
      "excerpt": "--help                          Show this message and exit. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9951603615862957
      ],
      "excerpt": "|   | saved_model.pb | variables.data-00000-of-00001 | model.tflite | \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/s9891326/Fine-Tuning-BERT/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "**\u6a21\u578b\u5132\u5b58**\n\n- How to save the whole model as SavedModel format for inference?\n    - [answer](https://github.com/huggingface/transformers/issues/6864#issuecomment-690086932)\n\n**\u6a21\u578b\u90e8\u5c6c**\n\n- \u53ef\u4ee5\u7528`nvtop`\u9032\u884c\u89c0\u6e2c\uff0c\u770b\u986f\u5361\u7684Memory\u6709\u6c92\u6709\u5403\u5230\n    - Memory\u4e0d\u5920\uff0c\u5c0e\u81f4\u6a21\u578b\u8b80\u4e0d\u9032\u4f86\uff0c\u8abf\u6574bin/run_serving.sh\u5167\u7684docker\u8a2d\u5b9a`CONTAINER_RAM`\u3001`CONTAINER_CPU`\u53ef\u4ee5\u63d0\u9ad8\u70ba`8g`\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 06 Dec 2021 05:59:45 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/s9891326/Fine-Tuning-BERT/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "s9891326/Fine-Tuning-BERT",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/s9891326/Fine-Tuning-BERT/main/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/s9891326/Fine-Tuning-BERT/main/bin/run_serving.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8474895321345809
      ],
      "excerpt": "make build_images \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8474895321345809
      ],
      "excerpt": "make run_fine_tuning_sentiment \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8474895321345809
      ],
      "excerpt": "make run_test_sentiment \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8474895321345809
      ],
      "excerpt": "make run_inference_sentiment \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8474895321345809
      ],
      "excerpt": "make deploy_model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8163335425342525
      ],
      "excerpt": "  --task_name TEXT           The name of the task to train.  [required] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "                                           name=\"input_ids\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "                                       name=\"input_mask\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "                                        name=\"segment_ids\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "        name=\"probabilities\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8474895321345809
      ],
      "excerpt": "make build_images \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8474895321345809
      ],
      "excerpt": "make run_fine_tuning_sentiment \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8474895321345809
      ],
      "excerpt": "make run_load_model_to_train \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8474895321345809
      ],
      "excerpt": "make run_test_sentiment \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8474895321345809
      ],
      "excerpt": "make deploy_model\uff0c\u9700\u6ce8\u610fSERVING_DIR\u5167\u7684\u6a21\u578b\u7248\u672c\u865f\u662f\u5426\u6709\u885d\u7a81 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "        name: 'sentiment', \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8077391938390063
      ],
      "excerpt": "\u90e8\u5c6c\u8a2d\u5b9a\u6a94: /serving/models/models.config \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8606280910157142
      ],
      "excerpt": "Quick start \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9459306480564178
      ],
      "excerpt": "Usage: run_sentiment.py [OPTIONS] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8682167946010096
      ],
      "excerpt": "  --data_dir TEXT            The input data dir. Should contain the .tsv files \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8362634326741164,
        0.8850134201835409
      ],
      "excerpt": "  --task_name TEXT           The name of the task to train.  [required] \n  --output_dir TEXT          The output directory(savedModel) where the model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8155533587988265
      ],
      "excerpt": "  --num_epochs INTEGER       Total number of training epochs to perform. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8879807775655754,
        0.8096808457171215
      ],
      "excerpt": "  --batch_size INTEGER       Total batch size for training.  [default: 32] \n  --max_seq_length INTEGER   The maximum total input sequence length after \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740328029021457
      ],
      "excerpt": "  --do_train BOOLEAN         Whether to run training.  [default: False] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8680324026908611
      ],
      "excerpt": "                             test set.  [default: False] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8038675022973845
      ],
      "excerpt": "                             \"savedmodel\" will save savedmodel with h5 convert \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8029088872180195,
        0.859658165616667
      ],
      "excerpt": "                             model name.  [default: bert-base-chinese] \n  --load_model_dir TEXT      If you want load old model(savedModel) to train \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8708708111228423
      ],
      "excerpt": "\u8b80\u53d6data_dir\u53c3\u6578\u4e0b\u7684\u6a94\u6848(train.tsv\u3001test.tsv)\uff0c\u9032\u884cFine-Tuning BERT\u591a\u985e\u5225\u4efb\u52d9\uff0c\u6700\u5f8c\u5132\u5b58\u6a21\u578b\u5831\u544a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "--do_train=True \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174,
        0.8801854956928516,
        0.8801854956928516
      ],
      "excerpt": "import tensorflow as tf \nfrom transformers import TFAutoModel \nfrom absl import flags \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8873506582052423,
        0.8421074476017179,
        0.8873506582052423,
        0.8421074476017179,
        0.8873506582052423,
        0.8421074476017179
      ],
      "excerpt": "    input_word_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, \n                                           name=\"input_ids\") \n    input_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, \n                                       name=\"input_mask\") \n    segment_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, \n                                        name=\"segment_ids\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "        name=\"probabilities\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8592867698223234
      ],
      "excerpt": "    model = tf.keras.models.Model( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "--do_train=True \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "--do_test=True \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8860016370382856
      ],
      "excerpt": "python example \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174
      ],
      "excerpt": "import tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8688920026396647
      ],
      "excerpt": "model = tf.keras.models.load_model(output_dir) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "--do_inference=True \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8793307677976541
      ],
      "excerpt": "predict result : positive \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8793307677976541
      ],
      "excerpt": "predict result : negative \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9459306480564178
      ],
      "excerpt": "Usage: create_load_dataset.py [OPTIONS] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8871460519365367,
        0.8855868944651558,
        0.8444151608029777
      ],
      "excerpt": "    maximum_digits:     old_dataset_name(str): old datasets file name.    \n    new_dataset_name(str): new datasets file name. \n    output_dataset_name(str): mix old and new datasets file name. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9053678719217502,
        0.845424571062299,
        0.9053678719217502
      ],
      "excerpt": "  --old_dataset_name TEXT         \u820a\u8cc7\u6599\u96c6\u540d\u7a31  [default: train.tsv] \n  --new_dataset_name TEXT         \u65b0\u8cc7\u6599\u96c6\u540d\u7a31  [default: new_train.tsv] \n  --output_dataset_name TEXT      \u6df7\u5408\u8cc7\u6599\u96c6\u540d\u7a31  [default: train.tsv] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432,
        0.8123763140827432
      ],
      "excerpt": "TF serving \u7c21\u55ae\u4ecb\u7d39 \nTF serving\u652f\u63f4\u540c\u6a21\u7d44\u4e0b\u591a\u500b\u7248\u672c\u7684\u6a21\u578b\u540c\u6642\u904b\u884c(\u60c5\u7dd2\u6a21\u578b\u4e0b\u67091\u30012\u7248) \nTF serving\u652f\u63f4\u7121\u75db\u4e0a\u7248\u3001\u9000\u7248\uff0c\u53ea\u9700\u66f4\u6539model.config\u5373\u53ef \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8618300377948696
      ],
      "excerpt": "models.config\u4e2d\u4f7f\u7528version_labels(\u6709key: string => \u81ea\u5b9a\u7fa9\u7684\u540d\u7a31\u3001value: int => \u5c0d\u61c9\u7684\u7248\u672c)\u4f86\u7d81\u5b9a\u4e0d\u540c\u7248\u672c\u5c0d\u61c9\u5230\u7684\u540d\u7a31\uff0c\u4ee5\u5229\u65bcgrpc\u547c\u53eb\u6642\u53ef\u547c\u53eb\u4e0d\u540c\u7248\u672c \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "        name: 'sentiment', \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731562459058029
      ],
      "excerpt": "            value: 1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731562459058029
      ],
      "excerpt": "            value: 2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "| tflite -> tf serving | - | - | 99M | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/s9891326/Fine-Tuning-BERT/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Makefile",
      "Shell",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "OpView\u60c5\u7dd2\u8a13\u7df4\u5de5\u5177",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Fine-Tuning-BERT",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "s9891326",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/s9891326/Fine-Tuning-BERT/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- ubuntu == 18.04\n- python >= 3.6.9\n- [nvidia-docker](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installing-on-ubuntu-and-debian)\n    <details>\n    <summary>\u5b89\u88dd\u6b65\u9a5f</summary>\n    \n    ```\n    sudo apt-get install -y nvidia-docker2\n    sudo systemctl restart docker\n    sudo docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi\n    ```\n    </details>\n- Nvidia \u986f\u5361\u9a45\u52d5(nvidia-smi)\n    <details>\n    <summary>\u5b89\u88dd\u6b65\u9a5f</summary>\n\n    ```\n    \u5b89\u88dd\u6b65\u9a5f\n    1. sudo apt install ubuntu-drivers-common\n    2. ubuntu-drivers devices - \u67e5\u770b\u986f\u5361\u578b\u865f\u548c\u63a8\u85a6\u5b89\u88dd\u9a45\u52d5\u7248\u672c\u865f\uff0c\u4e26\u9078\u64c7\u60f3\u5b89\u88dd\u7684\u7248\u672c\n    2. sudo apt install nvidia-driver-455 - \u5b89\u88dd\u9a45\u52d5\n    3. \u91cd\u65b0\u555f\u52d5 (sudo reboot)\n    4. nvidia-smi - \u6aa2\u67e5GPU\u72c0\u614b\n    ```\n    </details>\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 06 Dec 2021 05:59:45 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- \u78ba\u8a8d\u8cc7\u6599\u96c6(dataset/old_sentiment/)\u662f\u5426\u5b58\u5728\uff0c\u4e14\u5305\u542btrain.tsv\u3001test.tsv\n\n",
      "technique": "Header extraction"
    }
  ]
}
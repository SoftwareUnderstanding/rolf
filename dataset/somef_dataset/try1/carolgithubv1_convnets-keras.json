{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* For the AlexNet network, we have adapted the weights that can be found here : \nTaylor, Graham; Ding, Weiguang, 2015-03, <i>\"Theano-based large-scale visual recognition with multiple GPUs\"</i>, <a href=\"http://hdl.handle.net/10864/10911\">hdl:10864/10911</a> University of Guelph Research Data Repository \n\n* For the VGG networks, we have adapted the code released by baraldilorenzo here : https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\nWe changed it to have the \"heatmap\" option, and we modified the weights in the same way.\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9911135477416111
      ],
      "excerpt": "- VGG16 and VGG19 : http://arxiv.org/pdf/1409.1556.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559,
        0.9243188970772274,
        0.9030859728368266
      ],
      "excerpt": "Top 1 Error                         |   42,94%    |   32,93%    |   32,77%    | \nTop 5 error                         |   20,09%    |   12,39%    |   12,17%    | \nTop 10 error                        |   13,84%    |    7,77%    |    7,80%    | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/carolgithubv1/convnets-keras",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-12-03T15:03:30Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-12-03T15:04:19Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9888959559772054
      ],
      "excerpt": "This repo is regrouping some of of the most used CNN, pre-trained on the ImageNet Dataset, all of them implemented in Keras framework :  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.893736209693237
      ],
      "excerpt": "We also propose a heatmap option, which allow to detect the location of an object from a given synset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9562674576811271
      ],
      "excerpt": "Here, we detect all the objects linked to the synsets cars, and we produce a heatmap :  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9802092741752094,
        0.9163031183855128
      ],
      "excerpt": "The prediction time is computed on a GeForce GTX TITAN X, with a Theano backend, and a batch size of 64. \nAlexNet has lower results than the two VGGs, but it is much more lighter and faster, so it can easily be run on a small GPU (like on AWS), or even on a CPU. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8995951579563478
      ],
      "excerpt": "Networks                            | AlexNet     |     VGG16   |     VGG19   | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8243890128486082
      ],
      "excerpt": "It can be usefull to use the ids of ImageNet (which can be found on <a href =\"http://image-net.org/explore\"> this page </a>, if you want to know the meaning of the classification. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9895668705738931
      ],
      "excerpt": "* id_to_synset is taking an id of the output of the networks, and returning the WordNet synset \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/carolgithubv1/convnets-keras/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 12 Dec 2021 11:51:00 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/carolgithubv1/convnets-keras/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "carolgithubv1/convnets-keras",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The only dependencies are h5py, Theano and Keras. Run the following commands\n```\npip install --user cython h5py\npip install --user git+https://github.com/Theano/Theano.git\npip install --user git+https://github.com/fchollet/keras.git\n```\n\nThen, you need to install the convnetskeras module :\n```\ngit clone https://github.com/heuritech/convnets-keras.git\ncd convnets-keras\nsudo python setup.py install\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from convnetskeras.imagenet_tool import id_to_synset \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/carolgithubv1/convnets-keras/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "convnets-keras",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "convnets-keras",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "carolgithubv1",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/carolgithubv1/convnets-keras/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 12 Dec 2021 11:51:00 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The weights can be found here : \n* <a href=\"http://files.heuritech.com/weights/alexnet_weights.h5\">AlexNet weights</a>\n* <a href=\"http://files.heuritech.com/weights/vgg16_weights.h5\">VGG16 weights</a>\n* <a href=\"http://files.heuritech.com/weights/vgg19_weights.h5\">VGG19 weights</a>\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "**BEWARE** !! : Since the networks have been trained in different settings, the preprocessing is different for the differents networks : \n* For the AlexNet, the images (for the mode without the heatmap) have to be of shape (227,227). It is recommended to resize the images with a size of (256,256), and then do a crop of size (227,227). The colors are in RGB order.\n```python\nfrom keras.optimizers import SGD\nfrom convnetskeras.convnets import preprocess_image_batch, convnet\n\nim = preprocess_image_batch(['examples/dog.jpg'],img_size=(256,256), crop_size=(227,227), color_mode=\"rgb\")\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel = convnet('alexnet',weights_path=\"weights/alexnet_weights.h5\", heatmap=False)\nmodel.compile(optimizer=sgd, loss='mse')\n\nout = model.predict(im)\n```\n\n* For the VGG, the images (for the mode without the heatmap) have to be of shape (224,224). It is recommended to resize the images with a size of (256,256), and then do a crop of size (224,224). The colors are in BGR order.\n```python\nfrom keras.optimizers import SGD\nfrom convnetskeras.convnets import preprocess_image_batch, convnet\n\nim = preprocess_image_batch(['examples/dog.jpg'],img_size=(256,256), crop_size=(224,224), color_mode=\"bgr\")\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n#:#: For the VGG16, use this command\nmodel = convnet('vgg_16',weights_path=\"weights/vgg16_weights.h5\", heatmap=False)\n#:#: For the VGG19, use this one instead\n#: model = convnet('vgg_19',weights_path=\"weights/vgg19_weights.h5\", heatmap=False)\nmodel.compile(optimizer=sgd, loss='mse')\n\nout = model.predict(im)\n\n```\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "The heatmap are produced by converting the model into a fully convolutionize model. The fully connected layers are transformed into convolution layers (by using the same weights), so we are able to compute the output of the network on each sub-frame of size (227,227) (or (224,224)) of a bigger picture. This produces a heatmap for each label of the classifier.\n\nUsing the heatmap is almost the same thing than directly classify. We suppose that we want the heatmap of the all the synsets linked with dogs, which are all the children in Wordnet of the synset \"n02084071\" (see next section to know how to find how we can get all the labels linked with a given synset) : \n```python\nfrom keras.optimizers import SGD\nfrom convnetskeras.convnets import preprocess_image_batch, convnet\nfrom convnetskeras.imagenet_tool import synset_to_dfs_ids\n\nim = preprocess_image_batch(['examples/dog.jpg'], color_mode=\"bgr\")\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel = convnet('alexnet',weights_path=\"weights/alexnet_weights.h5\", heatmap=True)\nmodel.compile(optimizer=sgd, loss='mse')\n\nout = model.predict(im)\n\ns = \"n02084071\"\nids = synset_to_dfs_ids(s)\nheatmap = out[0,ids].sum(axis=0)\n\n#: Then, we can get the image\nimport matplotlib.pyplot as plt\nplt.imsave(\"heatmap_dog.png\",heatmap)\n```\n<img src=https://raw.githubusercontent.com/heuritech/convnets-keras/master/examples/dog.jpg width=\"400px\">\n\n<img src=https://raw.githubusercontent.com/heuritech/convnets-keras/master/examples/heatmap_dog.png width=\"400px\">\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "If you want to detect all cars, you might need to have a classification of higher level than the one given by the wordnets of ImageNet. Indeed, a lot of different synsets are present for different kinds of cars.\nWe can then choose a synset in the tree, and select all the ids of its children : \n```python\n>>>synset_to_dfs_ids(\"n04576211\")\n[670, 870, 880, 444, 671, 565, 705, 428, 791, 561, 757, 829, 866, 847, 547, 820, 408, 573, 575, 803, 407, 436, 468, 511, 609, 627, 656, 661, 751, 817, 665, 555, 569, 717, 864, 867, 675, 734, 656, 586, 847, 802, 660, 603, 612, 690]\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
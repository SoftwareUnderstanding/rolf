{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Thanks to [Nomono](https://nomono.co/) for backing audiomentations.\n\nThanks to [all contributors](https://github.com/iver56/audiomentations/graphs/contributors) who help improving audiomentations.\n",
      "technique": "Header extraction"
    }
  ],
  "citation": [
    {
      "confidence": [
        0.9855105081843352
      ],
      "excerpt": "Inspired by https://arxiv.org/pdf/1904.08779.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8688547589122794
      ],
      "excerpt": "training phase-aware machine learning models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9855105081843352
      ],
      "excerpt": "Inspired by https://arxiv.org/pdf/1904.08779.pdf \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/iver56/audiomentations",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-02-12T16:36:24Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-08T20:28:05Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8216983171550599
      ],
      "excerpt": "albumentations. Useful for deep learning. Runs on \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9135847940242273
      ],
      "excerpt": ": Generate 2 seconds of dummy audio for the sake of example \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8187101110111557
      ],
      "excerpt": "Go to audiomentations/augmentations/transforms.py to see the waveform transforms you can apply, and what arguments they have. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9786801387291061
      ],
      "excerpt": "Note that the gain of the added noise is relative to the amount of signal in the input. This \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.842312015216961
      ],
      "excerpt": "Add gaussian noise to the samples \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8737644747195987
      ],
      "excerpt": "Add gaussian noise to the samples with random Signal to Noise Ratio (SNR) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9388496311230595,
        0.8073611038665628
      ],
      "excerpt": "Some datasets of impulse responses are publicly available: \n- EchoThief containing 115 impulse responses acquired in a wide range of locations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8842004932946362
      ],
      "excerpt": "Apply band-pass filtering to the input audio. The filter steepness is 6 dB per octave. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8576955031209647
      ],
      "excerpt": "overflow or underflow (which results in unintended wrap distortion that can sound \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9730665813997669
      ],
      "excerpt": "Another way of ensuring that all values stay between -1.0 and 1.0 is to apply \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9212885647212598,
        0.9499084623499019,
        0.958887970358552,
        0.9236758624653181,
        0.8316022712938653
      ],
      "excerpt": "This transform is different from ClippingDistortion in that it takes fixed values \nfor clipping instead of clipping a random percentile of the samples. Arguably, this \ntransform is not very useful for data augmentation. Instead, think of it as a very \ncheap and harsh limiter (for samples that exceed the allotted extent) that can \nsometimes be useful at the end of a data augmentation pipeline. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.883536922688216,
        0.8925902332618522
      ],
      "excerpt": "Distort signal by clipping a random percentage of points \nThe percentage of points that will be clipped is drawn from a uniform distribution between \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.913272210042592
      ],
      "excerpt": "Mask some frequency band on the spectrogram. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9361728413039215
      ],
      "excerpt": "technique can help a model become somewhat invariant to the overall gain of the input audio. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9479096744536587
      ],
      "excerpt": "octave below the cutoff frequency, so this filter is fairly gentle. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9604307877293208
      ],
      "excerpt": "octave above the cutoff frequency, so this filter is fairly gentle. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8371265331725327,
        0.8438003318010868
      ],
      "excerpt": "This transform depends on either lameenc or pydub/ffmpeg. \nNote that bitrates below 32 kbps are only supported for low sample rates (up to 24000 hz). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9444101836187436
      ],
      "excerpt": "to the fact that the LAME encoder inserts some silence at the beginning of the audio. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9843245082034592
      ],
      "excerpt": "Apply a constant amount of gain to match a specific loudness. This is an implementation of \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8811770373353008
      ],
      "excerpt": "Apply a constant amount of gain, so that highest signal level present in the sound becomes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9137215817665506
      ],
      "excerpt": "the same compared to the original when played back in isolation. However, when mixed with \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8207455004960723
      ],
      "excerpt": "is sometimes used for audio cancellation or obtaining the difference between two waveforms. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9980091030064044
      ],
      "excerpt": "axis relates to the random flip of an image, which is an augmentation technique that is \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8888178838966732
      ],
      "excerpt": "Shift the samples forwards or backwards, with or without rollover \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9262096162972119
      ],
      "excerpt": "Apply tanh (hyperbolic tangent) distortion to the audio. This technique is sometimes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9802095239249329,
        0.9780557883393209,
        0.8325083342583173
      ],
      "excerpt": "\"soft clipping\" kind of distortion, and the distortion amount is proportional to the \nloudness of the input and the pre-gain. Tanh is symmetric, so the positive and \nnegative parts of the signal are squashed in the same way. This transform can be \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9897445407161569
      ],
      "excerpt": "the timbre of the sound. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9063020458800101
      ],
      "excerpt": "Shuffle the channels of a multichannel spectrogram. This can help combat positional bias. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9640664287486236
      ],
      "excerpt": "Mask a set of frequencies in a spectrogram, \u00e0 la Google AI SpecAugment. This type of data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.904940767140453
      ],
      "excerpt": "The masked frequencies can be replaced with either the mean of the original values or a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.844774499145643
      ],
      "excerpt": "Expects the input dtype to be float32, and have values between -1 and 1. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9420243838764846
      ],
      "excerpt": "Multiprocessing is not officially supported yet. See also #46 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8246806073481829,
        0.9717644360749412
      ],
      "excerpt": "Most transforms, but not all, support 2D numpy arrays with shapes like (num_channels, num_samples) \nThe following table is valid for new versions of audiomentations, like >=0.18.0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008775228180506
      ],
      "excerpt": "| LoudnessNormalization | Yes, up to 5 channels | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9690987271256938
      ],
      "excerpt": "Implement OneOf and SomeOf for applying one of or some of many transforms. Transforms are randomly \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8556698363894553,
        0.8351355634901878,
        0.9644509843753694
      ],
      "excerpt": "Add a new argument apply_to_children (bool) in randomize_parameters, \n freeze_parameters and unfreeze_parameters in Compose and SpecCompose. \nInsert three new parameters in AddBackgroundNoise: noise_rms (defaults to \"relative\", which is  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9870317977205382,
        0.9525217475577372,
        0.9560939516426791
      ],
      "excerpt": "Implement TanhDistortion. Thanks to atamazian and iver56. \nAdd a noise_rms parameter to AddShortNoises. It defaults to relative, which \n is the old behavior. absolute allows for adding loud noises to parts that are \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9870317977205382
      ],
      "excerpt": "Implement BandPassFilter, HighPassFilter, LowPassFilter and Reverse. Thanks to atamazian. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8363547009153594,
        0.8499195918690944,
        0.9693233393948762,
        0.8749134381110876
      ],
      "excerpt": "Add support for float64 wav files. However, the use of this format is discouraged, \n  since float32 is more than enough for audio in most cases. \nImplement Clip. Thanks to atamazian. \nAdd some parameter sanity checks in AddGaussianNoise \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8262393971801569
      ],
      "excerpt": "Rename AddImpulseResponse to ApplyImpulseResponse. The former will still work for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9700154074381703,
        0.8975499976175929,
        0.9872162851725489,
        0.9663587731361021
      ],
      "excerpt": "When using the new parameters min_snr_in_db and max_snr_in_db in AddGaussianSNR, \n  SNRs will be picked uniformly in the decibel scale instead of in the linear amplitude \n  ratio scale. The new behavior aligns more with human hearing, which is not linear. \nImplement SpecCompose for applying a pipeline of spectrogram transforms. Thanks to omerferhatt. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8219163723778805,
        0.8278999869184481,
        0.908925214220865,
        0.9450372019471571
      ],
      "excerpt": "Implement randomize_parameters in Compose. Thanks to SolomidHero. \nAdd multichannel support to AddGaussianNoise, AddGaussianSNR, ClippingDistortion, \nFrequencyMask, PitchShift, Shift, TimeMask and TimeStretch \nLay the foundation for spectrogram transforms. Implement SpecChannelShuffle and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8162951851627928
      ],
      "excerpt": "Officially add multichannel support to Normalize \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8814680529488687
      ],
      "excerpt": "Speed up AddBackgroundNoise, AddShortNoises and AddImpulseResponse by loading wav files with scipy or wavio instead of librosa. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8404005018538712
      ],
      "excerpt": "Add m4a and opus to the list of recognized audio filename extensions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9966450727235545,
        0.9849226854850843
      ],
      "excerpt": "Implement Gain and PolarityInversion. Thanks to Spijkervet for the inspiration. \nImprove the performance of AddBackgroundNoise and AddShortNoises by optimizing the implementation of calculate_rms. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8408777149492545
      ],
      "excerpt": "Remember randomized/chosen effect parameters. This allows for freezing the parameters and applying the same effect to multiple sounds. Use transform.freeze_parameters() and transform.unfreeze_parameters() for this. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9841870475254351,
        0.8667141413408503,
        0.8822119285526606
      ],
      "excerpt": "Add a rollover parameter to Shift. This allows for introducing silence instead of a wrapped part of the sound. \nAdd support for flac in AddImpulseResponse \nImplement AddBackgroundNoise transform. Useful for when you want to add background noise to all of your sound. You need to give it a folder of background noises to choose from. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8323104190056323
      ],
      "excerpt": "Add shuffle parameter in Composer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.902052148816966,
        0.9693233393948762
      ],
      "excerpt": "Add fade parameter to TimeMask \nThanks to askskro \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "Thanks to karpnv \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A Python library for audio data augmentation. Inspired by albumentations. Useful for machine learning.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/iver56/audiomentations/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 102,
      "date": "Thu, 09 Dec 2021 02:35:52 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/iver56/audiomentations/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "iver56/audiomentations",
    "technique": "GitHub API"
  },
  "identifier": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://doi.org/10.5281/zenodo.5470338",
      "technique": "Regular expression"
    }
  ],
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Fix output dtype of `AddGaussianNoise`\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "* Fix a bug in `ClippingDistortion` where the min_percentile_threshold was not respected as expected.\n* Improve handling of empty input\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "* Fix filter instability bug in `FrequencyMask`. Thanks to kvilouras.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "* Improve compatibility of output files written by the demo script. Thanks to xwJohn.\n* Fix division by zero bug in `Normalize`. Thanks to ZFTurbo.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "* Correctly find audio files with upper case filename extensions.\n* Fix a bug where AddBackgroundNoise crashed when trying to add digital silence to an input. Thanks to juheeuu.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "* Fix picklability of instances of `AddImpulseResponse`, `AddBackgroundNoise`\n and `AddShortNoises`\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "* Fix a bug in `SpecChannelShuffle` where it did not support more than 3 audio channels. Thanks to omerferhatt.\n* Limit scipy version range to >=1.0,<1.6 to avoid issues with loading 24-bit wav files.\nSupport for scipy>=1.6 will be added later.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "* Avoid division by zero in `AddImpulseResponse` when input is digital silence (all zeros)\n* Fix inverse SNR characteristics in `AddGaussianSNR`. It will continue working as before\n  unless you switch to the new parameters `min_snr_in_db` and `max_snr_in_db`. If you\n  use the old parameters, you'll get a warning.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "* Remove global `pydub` import which was accidentally introduced in v0.18.0. `pydub` is\n considered an optional dependency and is imported only on demand now.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "![Python version support](https://img.shields.io/pypi/pyversions/audiomentations)\n[![PyPI version](https://img.shields.io/pypi/v/audiomentations.svg?style=flat)](https://pypi.org/project/audiomentations/)\n[![Number of downloads from PyPI per month](https://img.shields.io/pypi/dm/audiomentations.svg?style=flat)](https://pypi.org/project/audiomentations/)\n\n`pip install audiomentations`\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.907683024195154
      ],
      "excerpt": "Need a Pytorch alternative with GPU support? Check out torch-audiomentations! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8033454531647659
      ],
      "excerpt": "augmentation has proved to make speech recognition models more robust. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9605500521740181
      ],
      "excerpt": "The code runs on CPU, not GPU. For a GPU-compatible version, check out pytorch-audiomentations \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8283077525630498
      ],
      "excerpt": "    e.g. from audiomentations import calculate_rms, now you have to do \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9879563455863982
      ],
      "excerpt": "Install the dependencies specified in requirements.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772687832892645
      ],
      "excerpt": "| Name | Github stars | License | Last commit | GPU support? | \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8801854956928516,
        0.9457175861910134
      ],
      "excerpt": "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift \nimport numpy as np \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8819201356605096
      ],
      "excerpt": "samples = np.random.uniform(low=-0.2, high=0.2, size=(32000,)).astype(np.float32) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516,
        0.9457175861910134
      ],
      "excerpt": "from audiomentations import SpecCompose, SpecChannelShuffle, SpecFrequencyMask \nimport numpy as np \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174577072028841
      ],
      "excerpt": "spectrogram = np.random.random((1025, 256, 2)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8325255744714309
      ],
      "excerpt": "    from audiomentations.core.utils import calculate_rms \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/iver56/audiomentations/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Iver Jordal\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Audiomentations",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "audiomentations",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "iver56",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/iver56/audiomentations/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Some features have extra dependencies. Extra python package dependencies can be installed by running\n\n`pip install audiomentations[extras]`\n\n| Feature | Extra dependencies |\n| ------- | ---------------- |\n| `LoudnessNormalization` | `pyloudnorm` |\n| `Mp3Compression` | `ffmpeg` and [`pydub` or `lameenc`] |\n| `LowPassFilter`, `HighPassFilter`, `BandPassFilter` | `pydub` |\n\nNote: `ffmpeg` can be installed via e.g. conda or from [the official ffmpeg download page](http://ffmpeg.org/download.html).\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "`pytest`\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 791,
      "date": "Thu, 09 Dec 2021 02:35:52 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "audio",
      "sound",
      "data-augmentation",
      "augmentation",
      "sound-processing",
      "python",
      "machine-learning",
      "music",
      "deep-learning",
      "audio-effects",
      "audio-data-augmentation",
      "dsp"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "`python -m demo.demo`\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1811.06965",
      "https://arxiv.org/abs/1811.06965",
      "https://arxiv.org/abs/1706.02677",
      "https://arxiv.org/abs/1811.06965"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you apply this library to any project and research, please cite our code:\n\n```\n@article{kim2020torchgpipe,\n    title={torchgpipe: On-the-fly Pipeline Parallelism for Training Giant Models},\n    author={Chiheon Kim and Heungsub Lee and Myungryong Jeong and Woonhyuk Baek and Boogeon Yoon and Ildoo Kim and Sungbin Lim and Sungwoong Kim},\n    year={2020},\n    eprint={2004.09910},\n    archivePrefix={arXiv}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{kim2020torchgpipe,\n    title={torchgpipe: On-the-fly Pipeline Parallelism for Training Giant Models},\n    author={Chiheon Kim and Heungsub Lee and Myungryong Jeong and Woonhyuk Baek and Boogeon Yoon and Ildoo Kim and Sungbin Lim and Sungwoong Kim},\n    year={2020},\n    eprint={2004.09910},\n    archivePrefix={arXiv}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9302785107180478
      ],
      "excerpt": "Batch size | torchgpipe | nn.DataParallel | Goyal et al. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "256        | 21.99\u00b10.13 |      22.02\u00b10.11 |   22.08\u00b10.06 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8351541540159684
      ],
      "excerpt": "SGD by Goyal et al. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.996669306913299
      ],
      "excerpt": "Experiment | Throughput | torchgpipe | Huang et al. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8073645135498088
      ],
      "excerpt": "reported in Table 2 of GPipe by Huang et \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.840510181940132
      ],
      "excerpt": "Chiheon Kim at Kakao Brain, with Sungbin Lim, Ildoo Kim, \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kakaobrain/torchgpipe",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to torchgpipe\ntorchgpipe is currently under development. We will try to make it stable and\nusable. Until v0.1.0, which will be our first production release, we open up\nonly bug reports, but not feature or pull requests. Please wait for a while.\nKakao Brain, the project owner, has authority to update this guide.\nBoundaries\ntorchgpipe is a library, not an experiment.\nThe torchgpipe Python module, which is the torchgpipe folder in this\nrespository, has responsibility to provide GPipe for CUDA in PyTorch, and\noptions with some trade-offs which users have freedom to choose. It would not\naccept any requirement beyond the original GPipe implementation.\nThe \"torchgpipe\" project, which is this repository itself, has responsibility\nto make GPipe easy-to-use by deep learning researchers or engineers. It\nprovides handy resources and documentation for the best practice.\nDelicate reproduction of experiments in GPipe paper is out of the\nresponsibility of this project.\nAfter we release v0.1.0, if your pull request is accepted, we will merge it by\nsquashing regardless of the work history. Your forked repository should keep\nthe history.\nStyleguides\n\nThink of readability, consistency, simplicity, and cohesion.\nDon't put spaces around an operator if it is easier to read\n  (2*i + 1 not 2 * i + 1.)\nLint by mypy and Flake8 with our setup.cfg.\nFormat code by autopep8 and isort with our setup.cfg.\n\nDevelopment\nUnit Testing\nTo run unit tests, you can simply run python setup.py test. But if you want\nto use advanced testing options, run pytest manually:\nsh\n$ pip install pytest\n$ pytest\nFor example, you can filter tests by name:\nsh\n$ pytest -k 'test_gpipe'\nCode Quality\nWe use mypy and Flake8 to check code quality:\nsh\n$ pip install mypy flake8\n$ mypy .\n$ flake8 torchgpipe tests setup.py\nWe highly recommend to use autopep8 and isort to follow the coding style\nautomatically:\nsh\n$ pip install autopep8 isort\n$ autopep8 -ir torchgpipe tests setup.py\n$ isort -rc torchgpipe tests setup.py",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-10T10:25:41Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-11T07:16:40Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9697597530231435
      ],
      "excerpt": "A GPipe implementation in PyTorch. It is \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.860059181823877
      ],
      "excerpt": "model = nn.Sequential(a, b, c, d) \nmodel = GPipe(model, balance=[1, 1, 1, 1], chunks=8) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8733346203529588,
        0.9183410814310469
      ],
      "excerpt": "GPipe is a scalable pipeline parallelism library published by Google Brain, \nwhich allows efficient training of large, memory-consuming models. According to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8316304519107766,
        0.8351257840551243
      ],
      "excerpt": "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism \nGoogle trained AmoebaNet-B with 557M parameters over GPipe. This model has \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8981554454981872,
        0.924511633418865
      ],
      "excerpt": "benchmark (the state-of-the-art performance as of May 2019). \nGPipe uses (a) pipeline parallelism and (b) automatic recomputation of the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9188899406693163
      ],
      "excerpt": "large model. We refer to (b) as checkpointing, following the well-known \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8604058757432884,
        0.9641523621691231,
        0.9107028257011145
      ],
      "excerpt": "<dd>GPipe splits a model into multiple partitions and places each partition on \n    a different device to occupy more memory capacity. And it splits a \n    mini-batch into multiple micro-batches to make the partitions work as \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9514452723752523,
        0.8827921282191157
      ],
      "excerpt": "<dd>Checkpointing is applied to each partition to minimize the overall memory \n    consumption by a model. During forward propagation, only the tensors at the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8252074284332143
      ],
      "excerpt": "    tensors are volatilized, and recomputed during backpropagation when \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9782477514679196
      ],
      "excerpt": "The full details and more benchmarks are available in \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9548024452622592,
        0.8899302405303374
      ],
      "excerpt": "To verify the transparency, we reproduced top-1 error rate of ResNet-101 on \nImageNet, as reported in Table 2(c) of Accurate, Large Minibatch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9854240260779878
      ],
      "excerpt": "-2, -4, -8 denotes that the model is trained with GPipe with the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9380302125960703,
        0.9562253711252022
      ],
      "excerpt": "Here we used a simplified U-Net architecture. The size of a model is determined \nby hyperparameters B and C which are proportional to the number of layers and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.989767084087909
      ],
      "excerpt": "To verify efficiency with skip connections, we measured the throughput of U-Net \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9126961550281655,
        0.9306661020920663,
        0.980077307634847
      ],
      "excerpt": "reported in Table 2 of GPipe by Huang et \nal. Note that we replaced K in the paper with n. \nThis project is functional, but the interface is not confirmed yet. All public \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9713133063643448,
        0.8846754338018986,
        0.958193147145837
      ],
      "excerpt": "torchgpipe project is developed by Heungsub Lee, Myungryong Jeong, and \nChiheon Kim at Kakao Brain, with Sungbin Lim, Ildoo Kim, \nWoonhyuk Baek, and Boogeon Yoon's help. It is distributed under the 3-clause \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A GPipe implementation in PyTorch",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Visit [torchgpipe.readthedocs.io][rtd] for more information including the API\nreferences.\n\n[rtd]: https://torchgpipe.readthedocs.io/\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://torchgpipe.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KakaoBrain/torchgpipe/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 60,
      "date": "Sat, 11 Dec 2021 17:01:57 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kakaobrain/torchgpipe/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "kakaobrain/torchgpipe",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/KakaoBrain/torchgpipe/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from torchgpipe import GPipe \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8719491278656056
      ],
      "excerpt": "output = model(input) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kakaobrain/torchgpipe/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright 2019-2020 Kakao Brain\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright\\n   notice, this list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright\\n   notice, this list of conditions and the following disclaimer in the\\n   documentation and/or other materials provided with the distribution.\\n\\n3. Neither the name of the copyright holder nor the names of its\\n   contributors may be used to endorse or promote products derived from this\\n   software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\\nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\\nPOSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "torchgpipe <img src=\"docs/_static/not-pipe.svg\" height=\"20\" />",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "torchgpipe",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "kakaobrain",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kakaobrain/torchgpipe/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "sublee",
        "body": "Released on September 18, 2020.\r\n\r\nChanged the license to BSD-3-Clause.",
        "dateCreated": "2020-09-18T13:52:59Z",
        "datePublished": "2020-09-18T14:01:00Z",
        "html_url": "https://github.com/kakaobrain/torchgpipe/releases/tag/v0.0.7",
        "name": "v0.0.7",
        "tag_name": "v0.0.7",
        "tarball_url": "https://api.github.com/repos/kakaobrain/torchgpipe/tarball/v0.0.7",
        "url": "https://api.github.com/repos/kakaobrain/torchgpipe/releases/31527832",
        "zipball_url": "https://api.github.com/repos/kakaobrain/torchgpipe/zipball/v0.0.7"
      },
      {
        "authorType": "User",
        "author_name": "sublee",
        "body": "Released on July 29, 2020.\r\n\r\n- Updated docs.\r\n- Added support for PyTorch 1.5.",
        "dateCreated": "2020-07-29T02:34:31Z",
        "datePublished": "2020-07-31T05:11:32Z",
        "html_url": "https://github.com/kakaobrain/torchgpipe/releases/tag/v0.0.6",
        "name": "v0.0.6",
        "tag_name": "v0.0.6",
        "tarball_url": "https://api.github.com/repos/kakaobrain/torchgpipe/tarball/v0.0.6",
        "url": "https://api.github.com/repos/kakaobrain/torchgpipe/releases/29149505",
        "zipball_url": "https://api.github.com/repos/kakaobrain/torchgpipe/zipball/v0.0.6"
      },
      {
        "authorType": "User",
        "author_name": "sublee",
        "body": "Released on November 29, 2019.\r\n\r\n## Featured\r\n\r\n`@skippable` for efficient skip connections. With this interface, `GPipe` copies skip tensors directly to the destination device.\r\n\r\n## Improvements\r\n\r\n- Checkpointing deterministically handles randomness managed by PyTorch.\r\n- `balance_by_size()` analyzes parameters as well.\r\n\r\n## Breaking Changes\r\n\r\n- Moved `torchgpipe_balancing` module to `torchgpipe.balance`.\r\n- Redesigned interface of `balance_by_time()` and `balance_by_size()`.",
        "dateCreated": "2019-11-29T10:48:32Z",
        "datePublished": "2019-11-29T10:04:00Z",
        "html_url": "https://github.com/kakaobrain/torchgpipe/releases/tag/v0.0.5",
        "name": "v0.0.5",
        "tag_name": "v0.0.5",
        "tarball_url": "https://api.github.com/repos/kakaobrain/torchgpipe/tarball/v0.0.5",
        "url": "https://api.github.com/repos/kakaobrain/torchgpipe/releases/21851516",
        "zipball_url": "https://api.github.com/repos/kakaobrain/torchgpipe/zipball/v0.0.5"
      },
      {
        "authorType": "User",
        "author_name": "sublee",
        "body": "Released on October 8, 2019.\r\n\r\n- Reduced GPU memory fragmentation by caching CUDA streams for copy.\r\n- Fixed potential GPU memory violation on tuple of multiple tensors.\r\n- Fixed potential GPU memory violation on shifted view tensors. ([issue #27366](https://github.com/pytorch/pytorch/issues/27366) and [pull request #27371](https://github.com/pytorch/pytorch/pull/27371) on PyTorch)",
        "dateCreated": "2019-10-08T12:14:11Z",
        "datePublished": "2019-10-08T12:16:32Z",
        "html_url": "https://github.com/kakaobrain/torchgpipe/releases/tag/v0.0.4",
        "name": "v0.0.4",
        "tag_name": "v0.0.4",
        "tarball_url": "https://api.github.com/repos/kakaobrain/torchgpipe/tarball/v0.0.4",
        "url": "https://api.github.com/repos/kakaobrain/torchgpipe/releases/20545442",
        "zipball_url": "https://api.github.com/repos/kakaobrain/torchgpipe/zipball/v0.0.4"
      },
      {
        "authorType": "User",
        "author_name": "sublee",
        "body": "Released on September 30, 2019.\r\n\r\n## Featured\r\n\r\ntorchgpipe now overlaps copy and computation using the separate CUDA streams. Previously, GPU could not compute a partition while copying micro-batches across different GPUs because they all happened on the same default CUDA stream.\r\n\r\n## Other Improvements\r\n\r\n- Added support for PyTorch 1.2.\r\n- Redesigned the internal pipeline parallelism to represent dependencies transparently.\r\n- Fixed the hanging issue when an exception is raised in a partition.\r\n- Fixed the unintended size accumulation (#3 by @842974287) of `balance_by_size()`.\r\n\r\n## Breaking Changes:\r\n\r\n- No more support for PyTorch 1.0.\r\n- Changed type of `GPipe.devices` from `tuple` to `list`.\r\n- Removed `current_microbatch()`. This approach turned out to be incompatible with checkpointing.",
        "dateCreated": "2019-09-30T07:37:00Z",
        "datePublished": "2019-09-30T07:41:21Z",
        "html_url": "https://github.com/kakaobrain/torchgpipe/releases/tag/v0.0.3",
        "name": "v0.0.3",
        "tag_name": "v0.0.3",
        "tarball_url": "https://api.github.com/repos/kakaobrain/torchgpipe/tarball/v0.0.3",
        "url": "https://api.github.com/repos/kakaobrain/torchgpipe/releases/20343391",
        "zipball_url": "https://api.github.com/repos/kakaobrain/torchgpipe/zipball/v0.0.3"
      },
      {
        "authorType": "User",
        "author_name": "sublee",
        "body": "Released on June 26, 2019.                                                   \r\n                                                                             \r\n- Added support for PyTorch 1.1.                                             \r\n- Refined public APIs.                                                       \r\n- Detailed documentation.                                                    \r\n- Proper exceptions for invalid usage.                                       \r\n- Provided [automatic balancing](https://torchgpipe.readthedocs.io/en/latest/guide.html#automatic-balancing).                 \r\n- Provided inspecting utilities: [`current_microbatch()`](https://torchgpipe.readthedocs.io/en/latest/api.html#torchgpipe.current_microbatch) and [`is_recomputing()`](https://torchgpipe.readthedocs.io/en/latest/api.html#torchgpipe.is_recomputing).                    \r\n- Reimplemented deferred batch normalization by subclassing.                 ",
        "dateCreated": "2019-06-26T05:55:47Z",
        "datePublished": "2019-06-26T05:58:23Z",
        "html_url": "https://github.com/kakaobrain/torchgpipe/releases/tag/v0.0.2",
        "name": "v0.0.2",
        "tag_name": "v0.0.2",
        "tarball_url": "https://api.github.com/repos/kakaobrain/torchgpipe/tarball/v0.0.2",
        "url": "https://api.github.com/repos/kakaobrain/torchgpipe/releases/18227522",
        "zipball_url": "https://api.github.com/repos/kakaobrain/torchgpipe/zipball/v0.0.2"
      },
      {
        "authorType": "User",
        "author_name": "sublee",
        "body": "Released on May 14, 2019 to evaluate usability and efficiency internally.\r\n\r\nProvided a functional GPipe implementation, including pipeline parallelism, checkpointing, and deferred batch normalization.\r\n\r\nSupported Python 3.6+ and PyTorch 1.0.",
        "dateCreated": "2019-06-26T05:10:37Z",
        "datePublished": "2019-06-26T05:13:38Z",
        "html_url": "https://github.com/kakaobrain/torchgpipe/releases/tag/v0.0.1",
        "name": "v0.0.1",
        "tag_name": "v0.0.1",
        "tarball_url": "https://api.github.com/repos/kakaobrain/torchgpipe/tarball/v0.0.1",
        "url": "https://api.github.com/repos/kakaobrain/torchgpipe/releases/18227091",
        "zipball_url": "https://api.github.com/repos/kakaobrain/torchgpipe/zipball/v0.0.1"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 624,
      "date": "Sat, 11 Dec 2021 17:01:57 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "pytorch",
      "gpipe",
      "model-parallelism",
      "pipeline-parallelism",
      "parallelism",
      "checkpointing"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Currently, torchgpipe requires the following environments:\n\n- Python 3.6+\n- PyTorch 1.1+\n\nTo use torchgpipe, install it via PyPI:\n\n```sh\n$ pip install torchgpipe\n```\n\nTo train a module with GPipe, simply wrap it with `torchgpipe.GPipe`. Your\nmodule must be `nn.Sequential` as GPipe will automatically split the module\ninto partitions with consecutive layers. `balance` argument determines the\nnumber of layers in each partition. `chunks` argument specifies the number of\nmicro-batches. Input, output, and intermediate tensors must be `Tensor` or\n`Tuple[Tensor, ...]`.\n\nThe below example code shows how to split a module with four layers into four\npartitions each having a single layer. This code also splits a mini-batch into\n8 micro-batches:\n\n```python\nfrom torchgpipe import GPipe\n\nmodel = nn.Sequential(a, b, c, d)\nmodel = GPipe(model, balance=[1, 1, 1, 1], chunks=8)\n\nfor input in data_loader:\n    output = model(input)\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
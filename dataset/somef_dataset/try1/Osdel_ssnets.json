{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1605.06211",
      "https://arxiv.org/abs/1505.04597"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Osdel/ssnets",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-10-30T15:51:23Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-23T14:12:39Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.955889161803981,
        0.9858866219376217
      ],
      "excerpt": "Semantic Segmentation is the process of taking an image and label every single pixel to it's corresponding class. We can think of semantic segmentation as image classification at a pixel level. For example, in an image that has many cars, segmentation will label all the objects as car objects. However, a separate class of models known as instance segmentation is able to label the separate instances where an object appears in an image. \nFully Convolutional Network (https://arxiv.org/abs/1605.06211) was released in 2015 and achieved a performance of 67.2% mean IU on PASCAL VOC 2012. FCNs uses ILSVRC classifiers which were casted into fully-convolutional networks and augmented for dense prediction using pixel-wise loss and in-network up-sampling. This means that previous classfier like VGG16, AlexNet or GoogleNet are used as Encoders and the Fully Connected Layers or Dense Layers are replaced by convolutions. Then, the downsampled features are upsampled by transpose convolutions. The upsample layers are initialized with bilinear interpolation but then the upsample operation is learned by the network. Skip connection are used to combine fine layers and coarse layers, which lets the model to make local predictions that respect global structure. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8899377995894457
      ],
      "excerpt": "Our implementation uses a VGG16 network as Encoder. The main differences with the author's implementation are: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8363187765133255,
        0.9748249710322201,
        0.905785336350658
      ],
      "excerpt": "* We have support for depthwise separable convolutions \nInspired by the recent success of Depthwise Separable Convolution we built the FastFCN8 model. Please, this FastFCN8 model IS NOT the model refered in this paper \nThis FCN8 implementation include support for Depthwise Separable Convolution which allows the model to run faster and reduce drastically the memory usage from 124M to 20M without losing performance accuracy. The model's performance is tested in the example notebooks provided. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8902078342025851,
        0.9715906155297448
      ],
      "excerpt": "This paper builds upon the fully convolutional layer and modifies it to work on a few training images and yield more precise segmentation. Ronneberger et al. improve upon the \"fully convolutional\" architecture primarily through expanding the capacity of the decoder module of the network. More concretely, they propose the U-Net architecture which \"consists of a contracting path to capture context and a symmetric expanding path that enables precise localization.\" This simpler architecture has grown to be very popular and has been adapted for a variety of segmentation problems. (credit for this information and images) \nWe provide the MobileNet-V2 U-Net version, where a MobileNet-V2 network is used as Encoder and the Pix2Pix Upsample is used as Decoder. This model was obtained and adapted from Tensorflow Documentation, for more information follow this link. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9545938596558984,
        0.9902145631713429,
        0.8670011589099833,
        0.9843311601169084,
        0.8557519968653434
      ],
      "excerpt": "results on image classification tasks. The idea of DenseNets is based on the observation that if each layer is directly connected to every other layer in a feed-forward fashion then the network will be more accurate and easier to train. \nThe authors achieve state-of-the-art results on urban scene benchmark datasets such as CamVid and Gatech, without any further post-processing module nor pretraining. Moreover, due to smart construction of the model, their approach have much less parameters than \ncurrently published best entries for these datasets.  \nOur implementation IS NOT exactly the implementation of the paper. They use a different Densenet backbone. As Keras provide 121, 169 and 201 Densenet models we changed slighly the way the architecture works. \nThis implementation supports all 3 Keras Densenet models. To build them: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation and examples of Deep Learning Models for Semantic Segmentation.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Osdel/ssnets/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 12 Dec 2021 11:51:39 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Osdel/ssnets/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Osdel/ssnets",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Osdel/ssnets/master/Iris_Segmentation_Tutorial.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8060372108626078,
        0.8060372108626078
      ],
      "excerpt": "FCN8 = build_model(params, conv_type='conv') \nFastFCN8 = build_model(params, conv_type='ds') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from unet_mobilenet import unet_model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from fc_densenet import build_fc_densenet \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Osdel/ssnets/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Semantic Segmentation Nets (SSNeTs)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ssnets",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Osdel",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Osdel/ssnets/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 12 Dec 2021 11:51:39 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The following notebooks will help you to build these models and apply them to your datasets:\n* [Iris Segmentation Tutorial](https://github.com/Osdel/ssnets/blob/master/Iris_Segmentation_Tutorial.ipynb)\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1710.10196 <br>\nTrained Examples at -> https://github.com/akanimax/pro_gan_pytorch-examples\n\n# :star: [New] Pretrained Models:\nPlease find the pretrained models under the `saved_models/` directory at the [drive_link](https://drive.google.com/drive/folders/1ex27dbFD_4Ycic6P9y3V9i63AvcuAe95"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9977994744046882,
        0.8908514573258812
      ],
      "excerpt": "link -> https://arxiv.org/abs/1710.10196 <br> \nTrained Examples at -> https://github.com/akanimax/pro_gan_pytorch-examples \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8730726134075774
      ],
      "excerpt": "<img align=\"center\" src =\"https://github.com/akanimax/pro_gan_pytorch/blob/master/samples/faces_sheet_1.png\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8730726134075774
      ],
      "excerpt": "<img align=\"center\" src =\"https://github.com/akanimax/pro_gan_pytorch/blob/master/samples/faces_sheet_2.png\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "data_path = \"cifar-10/\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "num_epochs = [10, 20, 20, 20] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "pro_gan = pg.ConditionalProGAN(num_classes=10, depth=depth,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9559409615424181
      ],
      "excerpt": "Please feel free to open PRs / issues / suggestions here if  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/alexeyhorkin/ProGAN-PyTorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-21T20:25:40Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-21T20:27:00Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9651398770857402,
        0.906346431368616
      ],
      "excerpt": "Package contains implementation of ProGAN.<br>  \nPaper titled \"Progressive growing of GANs for improved  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8305428635032055
      ],
      "excerpt": "Note that DataParallel is required here because I have trained the models on Multiple GPUs. <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9183695749819312,
        0.8173931719706379
      ],
      "excerpt": "   Which I don't think is feasible for a GAN in general (:D). <br> \nYou can simply load the weights into the gen as it is implemented as a PyTorch Module. <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8166611233355385
      ],
      "excerpt": "   The shadow model contains the Exponential Moving Averaged weights (stable weights). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8365079859687341
      ],
      "excerpt": "medium blog -> https://medium.com/@animeshsk3/the-unprecedented-effectiveness-of-progressive-growing-of-gans-37475c88afa3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016,
        0.9293664399337974
      ],
      "excerpt": "    :param batch_size: batch_size for sgd \n    :param num_workers: num_readers for data reading \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/alexeyhorkin/ProGAN-PyTorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 06 Dec 2021 15:24:11 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/alexeyhorkin/ProGAN-PyTorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "alexeyhorkin/ProGAN-PyTorch",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "        classes = ('plane', 'car', 'bird', 'cat', 'deer',\n                   'dog', 'frog', 'horse', 'ship', 'truck')\n\n        transforms = tv.transforms.ToTensor()\n\n        trainset = tv.datasets.CIFAR10(root=data_path,\n                                       transform=transforms,\n                                       download=download)\n\n        testset = tv.datasets.CIFAR10(root=data_path,\n                                      transform=transforms, train=False,\n                                      download=False)\n\n        return classes, trainset, testset\n\n\n    if __name__ == '__main__':\n\n        ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "<p align=\"center\">\n<img align=\"center\" src =\"https://github.com/akanimax/pro_gan_pytorch/blob/master/samples/celebA-HQ.gif\"\n     height=80% width=80%/>\n</p>\n<br>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8934547715324944
      ],
      "excerpt": "   you wouldn't need to wrap the Generator into a DataParallel if you train on CPU. <br> \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8027645956080801
      ],
      "excerpt": " height=80% width=80%/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8027645956080801
      ],
      "excerpt": " height=80% width=80%/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8084427852231695
      ],
      "excerpt": "def setup_data(download=False): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.809336067966354
      ],
      "excerpt": "    :param download: Boolean for whether to download the data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8639258741734444
      ],
      "excerpt": "depth = 4 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8885001257560987
      ],
      "excerpt": "pro_gan = pg.ConditionalProGAN(num_classes=10, depth=depth,  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/alexeyhorkin/ProGAN-PyTorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "pro_gan_pytorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ProGAN-PyTorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "alexeyhorkin",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/alexeyhorkin/ProGAN-PyTorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 06 Dec 2021 15:24:11 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<p align=\"center\">\n<img align=\"center\" src =\"https://github.com/akanimax/pro_gan_pytorch/blob/master/samples/demo.gif\"\n height=80% width=80%/>\n</p>\n<br>\n\nThe repository now includes a latent-space interpolation animation demo under the `samples/` directory.\nJust download all the pretrained weights from the above mentioned drive_link and put them in the `samples/` \ndirectory alongside the `demo.py` script. Note that there are a few tweakable parameters at the beginning\nof the `demo.py` script so that you can play around with it. <br>\n\nThe demo loads up images for random points and then linearly interpolates among them to generate smooth \nanimation. You need to have a good GPU (atleast GTX 1070) to see formidable FPS in the demo. The demo however \ncan be optimized to do parallel generation of the images (It is completely sequential currently).\n\nIn order to load weights in the Generator, the process is the standard process for PyTorch model loading.\n    \n    import torch as th\n    from pro_gan_pytorch import PRO_GAN as pg\n    \n    device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n    \n    gen = th.nn.DataParallel(pg.Generator(depth=9))\n    gen.load_state_dict(th.load(\"GAN_GEN_SHADOW_8.pth\", map_location=str(device)))\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1.) Install your appropriate version of PyTorch. \nThe torch dependency in this package uses the most basic\n\"cpu\" version. follow instructions on \n<a href=\"http://pytorch.org/\"> http://pytorch.org </a> to \ninstall the \"gpu\" version of PyTorch.<br>\n\n2.)  Install this package using pip:\n    \n    $ workon [your virtual environment]\n    $ pip install pro-gan-pth\n    \n3.) In your code:\n    \n    import pro_gan_pytorch.PRO_GAN as pg\n \n Use the modules `pg.Generator`, `pg.Discriminator` and\n `pg.ProGAN`. Mostly, you'll only need the ProGAN \n module for training. For inference, you will probably \n need the `pg.Generator`.\n\n4.) Example Code for CIFAR-10 dataset:\n\n    import torch as th\n    import torchvision as tv\n    import pro_gan_pytorch.PRO_GAN as pg\n\n    ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "        _, dataset, _ = setup_data(download=True)\n\n        ",
      "technique": "Header extraction"
    }
  ]
}
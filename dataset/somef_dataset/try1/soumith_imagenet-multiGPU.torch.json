{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/soumith/imagenet-multiGPU.torch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2015-03-06T23:34:59Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-05T07:47:52Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- `main.lua` (~30 lines) - loads all other files, starts training.\n- `opts.lua` (~50 lines) - all the command-line options and description\n- `data.lua` (~60 lines) - contains the logic to create K threads for parallel data-loading.\n- `donkey.lua` (~200 lines) - contains the data-loading logic and details. It is run by each data-loader thread. random image cropping, generating 10-crops etc. are in here.\n- `model.lua` (~80 lines) - creates AlexNet model and criterion\n- `train.lua` (~190 lines) - logic for training the network. we hard-code a learning rate + weight decay schedule that produces good results.\n- `test.lua` (~120 lines) - logic for testing the network on validation set (including calculating top-1 and top-5 errors)\n- `dataset.lua` (~430 lines) - a general purpose data loader, mostly derived from [here: imagenetloader.torch](https://github.com/soumith/imagenetloader.torch). That repo has docs and more examples of using this loader.\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9714969351549785
      ],
      "excerpt": "The images dont need to be preprocessed or packaged in any database. It is preferred to keep the dataset on an SSD but we have used the data loader comfortably over NFS without loss in speed. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8976650145574969,
        0.8749529838969387
      ],
      "excerpt": "If your imagenet dataset is on HDD or a slow SSD, run this command to resize all the images such that the smaller dimension is 256 and the aspect ratio is intact. \nThis helps with loading the data from disk faster. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "an imagenet example in torch. ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/soumith/imagenet-multiGPU.torch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 165,
      "date": "Tue, 07 Dec 2021 05:02:40 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/soumith/imagenet-multiGPU.torch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "soumith/imagenet-multiGPU.torch",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8962961161800387
      ],
      "excerpt": "To do this, download ILSVRC2012_img_train.tar ILSVRC2012_img_val.tar and use the following commands: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9709665479546645,
        0.8081676379689953,
        0.9454717233090887
      ],
      "excerpt": "mkdir train && mv ILSVRC2012_img_train.tar train/ && cd train \ntar -xvf ILSVRC2012_img_train.tar && rm -f ILSVRC2012_img_train.tar \nfind . -name \"*.tar\" | while read NAME ; do mkdir -p \"${NAME%.tar}\"; tar -xvf \"${NAME}\" -C \"${NAME%.tar}\"; rm -f \"${NAME}\"; done \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.920758803990339,
        0.8886837401703306
      ],
      "excerpt": "cd ../ && mkdir val && mv ILSVRC2012_img_val.tar val/ && cd val && tar -xvf ILSVRC2012_img_val.tar \nwget -qO- https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh | bash \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8389487865177374
      ],
      "excerpt": "Now you are all set! \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8781026043403396,
        0.8390219230150352
      ],
      "excerpt": ": extract train data \nmkdir train && mv ILSVRC2012_img_train.tar train/ && cd train \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8145330145467943
      ],
      "excerpt": ": extract validation data \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/soumith/imagenet-multiGPU.torch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Lua"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 2-Clause \"Simplified\" License",
      "url": "https://api.github.com/licenses/bsd-2-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright (c) 2016, Soumith Chintala\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n Redistributions of source code must retain the above copyright notice, this\\n  list of conditions and the following disclaimer.\\n\\n Redistributions in binary form must reproduce the above copyright notice,\\n  this list of conditions and the following disclaimer in the documentation\\n  and/or other materials provided with the distribution.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "#Training an Object Classifier in Torch-7 on multiple GPUs over [ImageNet](http://image-net.org/download-images)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "imagenet-multiGPU.torch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "soumith",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/soumith/imagenet-multiGPU.torch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [Install torch on a machine with CUDA GPU](http://torch.ch/docs/getting-started.html#_)\n- If on Mac OSX, run `brew install coreutils findutils` to get GNU versions of `wc`, `find`, and `cut`\n- Download Imagenet-12 dataset from http://image-net.org/download-images . It has 1000 classes and 1.2 million images.\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The training scripts come with several options which can be listed by running the script with the flag --help\n```bash\nth main.lua --help\n```\n\nTo run the training, simply run main.lua\nBy default, the script runs 1-GPU AlexNet with the CuDNN backend and 2 data-loader threads.\n```bash\nth main.lua -data [imagenet-folder with train and val folders]\n```\n\nFor 2-GPU model parallel AlexNet + CuDNN, you can run it this way:\n```bash\nth main.lua -data [imagenet-folder with train and val folders] -nGPU 2 -backend cudnn -netType alexnet\n```\nSimilarly, you can switch the backends to 'cunn' to use a different set of CUDA kernels.\n\nYou can also alternatively train OverFeat using this following command:\n```bash\nth main.lua -data [imagenet-folder with train and val folders] -netType overfeat\n\n#: multi-GPU overfeat (let's say 2-GPU)\nth main.lua -data [imagenet-folder with train and val folders] -netType overfeat -nGPU 2\n```\n\nThe training script prints the current Top-1 and Top-5 error as well as the objective loss at every mini-batch.\nWe hard-coded a learning rate schedule so that AlexNet converges to an error of 42.5% at the end of 53 epochs.\n\nAt the end of every epoch, the model is saved to disk (as model_[xx].t7 where xx is the epoch number).\nYou can reload this model into torch at any time using torch.load\n```lua\nmodel = torch.load('model_10.t7') -- loading back a saved model\n```\n\nSimilarly, if you would like to test your model on a new image, you can use testHook from line 103 in donkey.lua to load your image, and send it through the model for predictions. For example:\n```lua\ndofile('donkey.lua')\nimg = testHook({loadSize}, 'test.jpg')\nmodel = torch.load('model_10.t7')\nif img:dim() == 3 then\n  img = img:view(1, img:size(1), img:size(2), img:size(3))\nend\npredictions = model:forward(img:cuda())\n```\n\nIf you ever want to reuse this example, and debug your scripts, it is suggested to debug and develop in the single-threaded mode, so that stack traces are printed fully.\n```lua\nth main.lua -nDonkeys 0 [...options...]\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 388,
      "date": "Tue, 07 Dec 2021 05:02:40 GMT"
    },
    "technique": "GitHub API"
  }
}
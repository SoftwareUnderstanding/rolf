{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] P. Viola, M. Jones, Rapid object detection using a boosted cascade of simple features, in: Proc. 2001 IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. CVPR 2001, IEEE Comput. Soc, Kauai, HI, USA, 2001: p. I-511-I\u2013518. https://doi.org/10.1109/CVPR.2001.990517.\n\n[2] Z. Zhang, Y. Song, H. Qi, Age Progression/Regression by Conditional Adversarial Autoencoder, ArXiv170208423 Cs. (2017). http://arxiv.org/abs/1702.08423 (accessed October 17, 2020).\n\n[3] O.M. Parkhi, A. Vedaldi, A. Zisserman, Deep Face Recognition, in: Procedings Br. Mach. Vis. Conf. 2015, British Machine Vision Association, Swansea, 2015: p. 41.1-41.12. https://doi.org/10.5244/C.29.41\n\n[4] Y. LeCun, Y. Bengio, G. Hinton, Deep learning, Nature. 521 (2015) 436\u2013444. https://doi.org/10.1038/nature14539.\n\n[5]\tAI Explainability Whitepaper [Whitepaper], (n.d.). https://storage.googleapis.com/cloud-ai-whitepapers/AI%20Explainability%20Whitepaper.pdf.\n\n[6]\tA. Kapishnikov, T. Bolukbasi, F. Vi\u00e9gas, M. Terry, XRAI: Better Attributions Through Regions, ArXiv190602825 Cs Stat. (2019). http://arxiv.org/abs/1906.02825 (accessed October 20, 2020).\n\n[7]\tM. Sundararajan, A. Taly, Q. Yan, Axiomatic Attribution for Deep Networks, ArXiv170301365 Cs. (2017). http://arxiv.org/abs/1703.01365 (accessed October 20, 2020).\n\n[8] M.T. Ribeiro, S. Singh, C. Guestrin, \u201cWhy Should I Trust You?\u201d: Explaining the Predictions of Any Classifier, ArXiv160204938 Cs Stat. (2016). http://arxiv.org/abs/1602.04938 (accessed October 29, 2020).\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yeefantan/Explainable-Health-Prediction-with-Transfer-Learning",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-16T07:32:43Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-29T08:04:42Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9897061217373735,
        0.931367062671588,
        0.9609353044928272,
        0.9970518423956115
      ],
      "excerpt": "This is a project studied on the sick and normal faces classification with Transfer Learning. Explainble AI technique is applied to find the attributes of each decision. \nIn this study, the dataset composed of two categories as normal faces and faces with ill symptoms. The normal faces dataset is obtained from the UTKFace dataset [1]. The ill faces images are collected through online searching using keywords on Google. There are 1000 images is the normal faces category and 600 images in the sick faces category. \nThe data is then being pre-processed with Haar Cascade Classifier [2]. Data augmentation is applied to increase the dataset size. \nVGGFace-16 model [3] is used in extracting the image's features before training. The model is trained with the imagenet weights. After that, CNN [4] is designed and trained to classify the features. The accuracy obtained for training, validation, and testing are respectively 0.99, 0.98, and 0.98. The proposed method obtained a very high accuracy, but there is no clue in knowing the model's behaviour in making the decision. Hence, Explainable AI [5-8] techniques are applied to know the model's decision behaviour. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9949584916712302,
        0.995995111633624,
        0.9669549762544685
      ],
      "excerpt": "Integrated Gradient is an attribution method used to attribute the essential and main values to the trained model\u2019s input. . This technique combined the axioms of Sensitivity and Implementation Invariance. This method can be applied to different deep neural networks by attributing the predicted outcome of a model to the input. \nXRAI is another attribution method that is specialized for image input only. It combines Integrated Gradient with over-segmentation and region selection to find the attribution. However, the attribution determined is as a level of regions, but not pixels. XRAI is proved to be able to produce a better result than other saliency methods for common models. This method can be applied to any deep neural network model.  \nBoth the XRAI and Integrated Gradients model are tested on Google Cloud Explainable AI Platform. The file \"XRAI_and_IG.ipynb\" in notebooks directory presented the setup codes in the platform. The methods of setting parameters for different visualization, importing the model, and getting explantions are demonstrated in the notebook file. The results obtained from the proposed methods are presented as follow: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9804777994225446
      ],
      "excerpt": "LIME can be applied to any machine learning model without knowing its underlying processing or internal representation. This is used to recognize the interpretable model on the interpretable attributes which are faithful to the regressor or classifier.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.884743353925709
      ],
      "excerpt": "The results obtained from LIME is shown as below.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Explainable AI Techniques and comparison for trained deep learning models",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yeefan1999/Explainable-Health-Prediction-with-Transfer-Learning/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 12 Dec 2021 17:50:28 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yeefantan/Explainable-Health-Prediction-with-Transfer-Learning/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "yeefantan/Explainable-Health-Prediction-with-Transfer-Learning",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/yeefan1999/Explainable-Health-Prediction-with-Transfer-Learning/main/notebooks/Transfer%20Learning.ipynb",
      "https://raw.githubusercontent.com/yeefan1999/Explainable-Health-Prediction-with-Transfer-Learning/main/notebooks/LIME.ipynb",
      "https://raw.githubusercontent.com/yeefan1999/Explainable-Health-Prediction-with-Transfer-Learning/main/notebooks/XRAI_and_IG.ipynb",
      "https://raw.githubusercontent.com/yeefan1999/Explainable-Health-Prediction-with-Transfer-Learning/main/notebooks/.ipynb_checkpoints/XRAI_and_IG-checkpoint.ipynb",
      "https://raw.githubusercontent.com/yeefan1999/Explainable-Health-Prediction-with-Transfer-Learning/main/notebooks/.ipynb_checkpoints/LIME-checkpoint.ipynb",
      "https://raw.githubusercontent.com/yeefan1999/Explainable-Health-Prediction-with-Transfer-Learning/main/notebooks/.ipynb_checkpoints/Transfer%20Learning-checkpoint.ipynb",
      "https://raw.githubusercontent.com/yeefan1999/Explainable-Health-Prediction-with-Transfer-Learning/main/colab/LIME.ipynb",
      "https://raw.githubusercontent.com/yeefan1999/Explainable-Health-Prediction-with-Transfer-Learning/main/utils/.ipynb_checkpoints/Untitled-checkpoint.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8213375712911213
      ],
      "excerpt": "Alternatively, you can experiment it on  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yeefantan/Explainable-Health-Prediction-with-Transfer-Learning/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Explainable Health Prediction from Facial Features with Transfer Learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Explainable-Health-Prediction-with-Transfer-Learning",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "yeefantan",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yeefantan/Explainable-Health-Prediction-with-Transfer-Learning/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The code is written in Python and requires Tensorflow. You may install the requirements as follows:\n```\npip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Sun, 12 Dec 2021 17:50:28 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "explainable-ai"
    ],
    "technique": "GitHub API"
  }
}
{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/tomgoter/nlp_finalproject",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-09-23T20:24:50Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-29T00:16:54Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9984836332491983
      ],
      "excerpt": "The Unsupervised Data Augmentation (UDA) methodology presented in https://arxiv.org/pdf/1904.12848.pdf is further extended beyond its initial use with BERT for use with the XLNet transformer-based neural language model for evaluation on a novel text classification dataset. The results discussed herein show that the benefits of UDA are reproducible and extensible to other modeling architectures, namely XLNet. For the novel Song of Ice and Fire text classification problem presented herein, absolute error rate reductions of up to 5\\% were shown to be possible with an optimized UDA model.  Additionally, it is shown UDA can achieve the same accuracy as a finetuned model with as little as 67\\% of the labeled data. However, UDA is not a magic bullet for enabling the use of complex neural architectures for cases with very limited sets of labeled data, and the complexity of its use and time associated with its optimization should be weighed against the cost of simply labeling additional data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8810163480120801,
        0.8979411005071259,
        0.8979411005071259,
        0.9635525616464312
      ],
      "excerpt": "Processed Game of Thrones data for the various data set sizes are available in the following directories:  \nBERT: ./Data/proc_data/GoT  \nXLNET: ./Data/proc_data/GoT_xlnet \nPretrained models and Data is warehoused in personal Google Drive and Google Bucket for running with GPUs and TPUs through Google's colaboratory environment.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.878561830931507
      ],
      "excerpt": "Typical model runtimes range between 30-60 minutes on an 8-core TPU.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Repository for Final Project for W266: Natural Language Processing with Deep Learning",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/tomgoter/nlp_finalproject/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 05 Dec 2021 03:58:00 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/tomgoter/nlp_finalproject/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "tomgoter/nlp_finalproject",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/aug_inspect.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/predictions.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/error_analysis.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/generate_tfidf.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/xlnet_uda_colab.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/baseline_nb.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/generate_data.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/bert_xlnet_uda_colab.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_finetune_5000.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_finetune_12000.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_finetune.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_finetune_5000_hdo2_ado0.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_finetune_5000_shuffle_bs10.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_finetune_5000_lr05-hdo20-ado0.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_ft_5000.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_predictions.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_finetune-12000_dropout20.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_finetune_5000_lr01.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_ft_5000_colab.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_finetune_5000_lr1.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_finetune_5000_frozen.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_finetune_5000_shuffle.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/bert_finetune_colab.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/old_notebooks/xlnet_ft_5000.ipynb",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/Data/generate_data.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/run_base_uda.sh",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/run_base_gottest.sh",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/prepro_got_train.sh",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/prepro_got_dev.sh",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/train_large_ft_uda_tpu.sh",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/download.sh",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/train_large_ft_tpu.sh",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/prepro.sh",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/run_base.sh",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/prepro_got_test.sh",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/.ipynb_checkpoints/prepro_got_test-checkpoint.sh",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/.ipynb_checkpoints/prepro-checkpoint.sh",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/.ipynb_checkpoints/prepro_got_train-checkpoint.sh",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/.ipynb_checkpoints/run_base_uda-checkpoint.sh",
      "https://raw.githubusercontent.com/tomgoter/nlp_finalproject/master/scripts/.ipynb_checkpoints/download-checkpoint.sh"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8365640126426377
      ],
      "excerpt": "The final run script (bert_xlnet_uda_colab.ipynb) is set up to run on either GPUs or TPUs and can run either XLNet or BERT models. There are default options provided for each. And all options can be overwritten in the notebook.  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/tomgoter/nlp_finalproject/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "TeX",
      "Shell",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Comparison of Unsupervised Data Augmentation with BERT and XLNet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "nlp_finalproject",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "tomgoter",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/tomgoter/nlp_finalproject/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Sun, 05 Dec 2021 03:58:00 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1906.11172, 2019.\n[pdf](https://arxiv.org/pdf/1906.11172.pdf \"pdf\") | [github](https://github.com/tensorflow/tpu/blob/master/models/official/detection/utils/autoaugment_utils.py#L15 \"pdf\")\n\n2. Chen P. GridMask data augmentation[J]. arXiv preprint https://arxiv.org/abs/2001.04086, 2020.\n[pdf](https://arxiv.org/pdf/2001.04086.pdf \"pdf\") | [github](https://github.com/akuxcw/GridMask \"github\")\n\n3. Kisantal M, Wojna Z, Murawski J, et al. Augmentation for small object detection[J]. arXiv preprint https://arxiv.org/abs/1902.07296, 2019.\n[pdf](https://arxiv.org/pdf/1902.07296.pdf \"pdf\")\n\n## Augmentation zoo for object Detection\n### Learning data augmentation strategies for object detection\n\n#### Color Distortion\n  - AutoContrast\n  - Equalize: Equalize the image histogram\n  - Posterize\n  - Solarize: Invert all pixels above a threshold value of magniude\n  - SolarizeAdd: For each pixel in the image that is less than 128, add an additional amount to it decided by the magnitude.\n  - Color: Adjust the color balance of the image.\n  - Contrast: Control the contrast of the image.\n  - Brightness: Adjust the brightness of the image.\n  - Sharpness: Adjust the sharpness of the image\n  - Solarize_Only_BBoxes\n  - Equalize_Only_Bboxes\n  \n![ColourDistortion](https://github.com/zzl-pointcloud/Data_Augmentation_Zoo_for_Object_Detection/blob/master/show_img/Color_trans.png)\n\n#### Spatial Transformation\n  - Cutout\n  - BBox_Cutout\n  - Flip\n  - Rotate_BBox\n  - TranslateX_BBox                                                    \n  - TranslateY_BBox                                             \n  - ShearX_BBox                                                          \n  - ShearY_BBox \n  - TranslateX_Only_BBoxes\n  - TranslateY_Only_BBoxes\n  - Rotate_Only_BBoxes\n  - ShearX_Only_BBoxes\n  - ShearY_Only_BBoxes\n  - Flip_Only_BBoxes\n  - Cutout_Only_Bboxes\n  \n![SpatialTransformation](https://github.com/zzl-pointcloud/Data_Augmentation_Zoo_for_Object_Detection/blob/master/show_img/Geo_Trans.png)\n#### Learned augmentation policy\n  - Policy v0, v1, and custom were used in AutoAugment Detection Paper\n  - Policy v2, v3 are additional policies that perform well on object detection\n  - Policy v4 is the policy which mentioned in this paper, \"the best\"\n  \n#### How to use\n  \n  Make sure the file \"/augmentation_zoo/Myautoaugment_utils.py\" is in project folder.\n  ```python\n  from Myautoaugment_utils import AutoAugmenter\n  # if you want to use the learned augmentation policy custom or v0-v4(v4 was recommended):\n  autoaugmenter = AutoAugmenter('v4')\n  # or if you want to use some spatial transformation or color distortion data augmentation\uff0c\n  # add the data augmentation method that you want to use to the policy_test in Myautoaugment_utils.py \n  # and set the prob and magnitude. For excample:\n  # def policy_vtest():\n  #    policy = [\n  #        [('Color', 0.0, 6), ('Cutout', 0.6, 8)],\n  #    ]\n  #    return policy\n  autoaugmenter = AutoAugmenter('test')\n  # Input: \n  #   Sample = {'img': img, 'annot': annots",
      "https://arxiv.org/abs/2001.04086, 2020.\n[pdf](https://arxiv.org/pdf/2001.04086.pdf \"pdf\") | [github](https://github.com/akuxcw/GridMask \"github\")\n\n3. Kisantal M, Wojna Z, Murawski J, et al. Augmentation for small object detection[J]. arXiv preprint https://arxiv.org/abs/1902.07296, 2019.\n[pdf](https://arxiv.org/pdf/1902.07296.pdf \"pdf\")\n\n## Augmentation zoo for object Detection\n### Learning data augmentation strategies for object detection\n\n#### Color Distortion\n  - AutoContrast\n  - Equalize: Equalize the image histogram\n  - Posterize\n  - Solarize: Invert all pixels above a threshold value of magniude\n  - SolarizeAdd: For each pixel in the image that is less than 128, add an additional amount to it decided by the magnitude.\n  - Color: Adjust the color balance of the image.\n  - Contrast: Control the contrast of the image.\n  - Brightness: Adjust the brightness of the image.\n  - Sharpness: Adjust the sharpness of the image\n  - Solarize_Only_BBoxes\n  - Equalize_Only_Bboxes\n  \n![ColourDistortion](https://github.com/zzl-pointcloud/Data_Augmentation_Zoo_for_Object_Detection/blob/master/show_img/Color_trans.png)\n\n#### Spatial Transformation\n  - Cutout\n  - BBox_Cutout\n  - Flip\n  - Rotate_BBox\n  - TranslateX_BBox                                                    \n  - TranslateY_BBox                                             \n  - ShearX_BBox                                                          \n  - ShearY_BBox \n  - TranslateX_Only_BBoxes\n  - TranslateY_Only_BBoxes\n  - Rotate_Only_BBoxes\n  - ShearX_Only_BBoxes\n  - ShearY_Only_BBoxes\n  - Flip_Only_BBoxes\n  - Cutout_Only_Bboxes\n  \n![SpatialTransformation](https://github.com/zzl-pointcloud/Data_Augmentation_Zoo_for_Object_Detection/blob/master/show_img/Geo_Trans.png)\n#### Learned augmentation policy\n  - Policy v0, v1, and custom were used in AutoAugment Detection Paper\n  - Policy v2, v3 are additional policies that perform well on object detection\n  - Policy v4 is the policy which mentioned in this paper, \"the best\"\n  \n#### How to use\n  \n  Make sure the file \"/augmentation_zoo/Myautoaugment_utils.py\" is in project folder.\n  ```python\n  from Myautoaugment_utils import AutoAugmenter\n  # if you want to use the learned augmentation policy custom or v0-v4(v4 was recommended):\n  autoaugmenter = AutoAugmenter('v4')\n  # or if you want to use some spatial transformation or color distortion data augmentation\uff0c\n  # add the data augmentation method that you want to use to the policy_test in Myautoaugment_utils.py \n  # and set the prob and magnitude. For excample:\n  # def policy_vtest():\n  #    policy = [\n  #        [('Color', 0.0, 6), ('Cutout', 0.6, 8)],\n  #    ]\n  #    return policy\n  autoaugmenter = AutoAugmenter('test')\n  # Input: \n  #   Sample = {'img': img, 'annot': annots",
      "https://arxiv.org/abs/1902.07296, 2019.\n[pdf](https://arxiv.org/pdf/1902.07296.pdf \"pdf\")\n\n## Augmentation zoo for object Detection\n### Learning data augmentation strategies for object detection\n\n#### Color Distortion\n  - AutoContrast\n  - Equalize: Equalize the image histogram\n  - Posterize\n  - Solarize: Invert all pixels above a threshold value of magniude\n  - SolarizeAdd: For each pixel in the image that is less than 128, add an additional amount to it decided by the magnitude.\n  - Color: Adjust the color balance of the image.\n  - Contrast: Control the contrast of the image.\n  - Brightness: Adjust the brightness of the image.\n  - Sharpness: Adjust the sharpness of the image\n  - Solarize_Only_BBoxes\n  - Equalize_Only_Bboxes\n  \n![ColourDistortion](https://github.com/zzl-pointcloud/Data_Augmentation_Zoo_for_Object_Detection/blob/master/show_img/Color_trans.png)\n\n#### Spatial Transformation\n  - Cutout\n  - BBox_Cutout\n  - Flip\n  - Rotate_BBox\n  - TranslateX_BBox                                                    \n  - TranslateY_BBox                                             \n  - ShearX_BBox                                                          \n  - ShearY_BBox \n  - TranslateX_Only_BBoxes\n  - TranslateY_Only_BBoxes\n  - Rotate_Only_BBoxes\n  - ShearX_Only_BBoxes\n  - ShearY_Only_BBoxes\n  - Flip_Only_BBoxes\n  - Cutout_Only_Bboxes\n  \n![SpatialTransformation](https://github.com/zzl-pointcloud/Data_Augmentation_Zoo_for_Object_Detection/blob/master/show_img/Geo_Trans.png)\n#### Learned augmentation policy\n  - Policy v0, v1, and custom were used in AutoAugment Detection Paper\n  - Policy v2, v3 are additional policies that perform well on object detection\n  - Policy v4 is the policy which mentioned in this paper, \"the best\"\n  \n#### How to use\n  \n  Make sure the file \"/augmentation_zoo/Myautoaugment_utils.py\" is in project folder.\n  ```python\n  from Myautoaugment_utils import AutoAugmenter\n  # if you want to use the learned augmentation policy custom or v0-v4(v4 was recommended):\n  autoaugmenter = AutoAugmenter('v4')\n  # or if you want to use some spatial transformation or color distortion data augmentation\uff0c\n  # add the data augmentation method that you want to use to the policy_test in Myautoaugment_utils.py \n  # and set the prob and magnitude. For excample:\n  # def policy_vtest():\n  #    policy = [\n  #        [('Color', 0.0, 6), ('Cutout', 0.6, 8)],\n  #    ]\n  #    return policy\n  autoaugmenter = AutoAugmenter('test')\n  # Input: \n  #   Sample = {'img': img, 'annot': annots"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.999991725844336,
        0.8090016440670298,
        0.9977083882274769,
        0.8090016440670298,
        0.9999961480788931
      ],
      "excerpt": "1. Zoph B, Cubuk E D, Ghiasi G, et al. Learning data augmentation strategies for object detection[J]. arXiv preprint arXiv:1906.11172, 2019. \npdf | github \nChen P. GridMask data augmentation[J]. arXiv preprint arXiv:2001.04086, 2020. \npdf | github \nKisantal M, Wojna Z, Murawski J, et al. Augmentation for small object detection[J]. arXiv preprint arXiv:1902.07296, 2019. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8990729938151346
      ],
      "excerpt": "Policy v0, v1, and custom were used in AutoAugment Detection Paper \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8504663018162004
      ],
      "excerpt": "Algorithm: Augmentation for small object detection \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8456806903995955
      ],
      "excerpt": "        if issmallobject(annot, thresh) do \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9610293202239182,
        0.8177918124334298
      ],
      "excerpt": "        end if \n    end for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9610293202239182,
        0.8177918124334298,
        0.8177918124334298
      ],
      "excerpt": "            end if \n        end for \n    end for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "SOA_EPOCHS = 30 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906174419333412
      ],
      "excerpt": "| KITTI | Car | van | truck | pedestrian | Person_sitting | cyclist | Tram | Misc | mAP | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zzl-pointcloud/Data_Augmentation_Zoo_for_Object_Detection",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-22T01:20:33Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-09T05:39:35Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9723905145350895
      ],
      "excerpt": "This project is built for testing multiple data augmentations for object detection: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9762844731067282
      ],
      "excerpt": "SolarizeAdd: For each pixel in the image that is less than 128, add an additional amount to it decided by the magnitude. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.82669023491874,
        0.9774737365840331,
        0.9774737365840331
      ],
      "excerpt": "Contrast: Control the contrast of the image. \nBrightness: Adjust the brightness of the image. \nSharpness: Adjust the sharpness of the image \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9618476350627969
      ],
      "excerpt": "Policy v4 is the policy which mentioned in this paper, \"the best\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9000341342290756
      ],
      "excerpt": "Choose numerous small objects and copy-paste each of these 3 times in an arbitrary position.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.922239223958589
      ],
      "excerpt": "    Perform the function with the probability of prob \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8098939632554305
      ],
      "excerpt": "    for annot in annots do \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8971916915608729
      ],
      "excerpt": "    end for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490037945672047
      ],
      "excerpt": "    shuffle the small_object_list \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8971916915608729,
        0.8971916915608729
      ],
      "excerpt": "        end for \n    end for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9287362544185663
      ],
      "excerpt": "I use the RetinaNet with ResNet-18, testing in VOC and KITTI. VOC_BATCH_SIZE = 8, KITTI_BATCH_SIZE = 24 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Includes:  Learning data augmentation strategies for object detection | GridMask data augmentation | Augmentation for small object detection in Numpy.  Use RetinaNet with ResNet-18 to test these methods on VOC and KITTI.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zzl-pointcloud/Data_Augmentation_Zoo_for_Object_Detection/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 24,
      "date": "Sat, 11 Dec 2021 22:50:45 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/zzl-pointcloud/Data_Augmentation_Zoo_for_Object_Detection/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "zzl-pointcloud/Data_Augmentation_Zoo_for_Object_Detection",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8059754016467904
      ],
      "excerpt": ": Policy 1, make SOA_ONE_OBJECT = Ture, or if you \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8496630651420929
      ],
      "excerpt": "Make sure the file \"/augmentation_zoo/MyGridMask.py\" is in project folder. And the input and output requirements are same as above \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516,
        0.9012542906392262
      ],
      "excerpt": "from MyGridMask import GridMask \nGRID = False \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984,
        0.8003751159116907
      ],
      "excerpt": "Gridmask = GridMask(True, True, GRID_ROTATE,GRID_OFFSET,GRID_RATIO,GRID_MODE,GRID_PROB) \nSample = Gridmask(Sample) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003751159116907
      ],
      "excerpt": "Sample = augmenter(Sample) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/zzl-pointcloud/Data_Augmentation_Zoo_for_Object_Detection/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Data_Augmentation_Zoo_for_Object_Detection",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Data_Augmentation_Zoo_for_Object_Detection",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "zzl-pointcloud",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zzl-pointcloud/Data_Augmentation_Zoo_for_Object_Detection/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 111,
      "date": "Sat, 11 Dec 2021 22:50:45 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "augmentation",
      "gridmask",
      "smallobjectdetection",
      "objectdetection"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "  \n  Make sure the file \"/augmentation_zoo/Myautoaugment_utils.py\" is in project folder.\n  ```python\n  from Myautoaugment_utils import AutoAugmenter\n  #: if you want to use the learned augmentation policy custom or v0-v4(v4 was recommended):\n  autoaugmenter = AutoAugmenter('v4')\n  #: or if you want to use some spatial transformation or color distortion data augmentation\uff0c\n  #: add the data augmentation method that you want to use to the policy_test in Myautoaugment_utils.py \n  #: and set the prob and magnitude. For excample:\n  #: def policy_vtest():\n  #:    policy = [\n  #:        [('Color', 0.0, 6), ('Cutout', 0.6, 8)],\n  #:    ]\n  #:    return policy\n  autoaugmenter = AutoAugmenter('test')\n  #: Input: \n  #:   Sample = {'img': img, 'annot': annots}\n  #:   img = [H, W, C], RGB, value between [0,1]\n  #:   annot = [xmin, ymin, xmax, ymax, label]\n  #: Return:\n  #:   Sample = {'img': img, 'annot': annots}\n  Sample = autoaugmenter(Sample)\n  #: Use in Pytorch\n  dataset = Dataset(root, transform=transforms.Compose([autoaugmenter]))\n ```\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1610.10099",
      "https://arxiv.org/abs/1408.5882",
      "https://arxiv.org/abs/1610.10099",
      "https://arxiv.org/abs/1408.5882",
      "https://arxiv.org/abs/1609.03499",
      "https://arxiv.org/abs/1610.10099"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this code useful please cite me in your work:\n\n<pre><code>\nGeorge Stoyanov. Deep-Atrous-CNN-Text-Network. 2017. GitHub repository. https://github.com/randomrandom.\n</code></pre>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9073225783298526
      ],
      "excerpt": "then open your browser http://localhost:6008/ \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/randomrandom/deep-atrous-cnn-sentiment",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-06-23T11:50:52Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-16T11:55:03Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9004644700569983,
        0.9861077580576502,
        0.9043159470130286,
        0.9673077001100928
      ],
      "excerpt": "A Deep Atrous CNN architecture suitable for text (sentiment) classification with variable length. \nThe architecture substitutes the typical CONV->POOL->CONV->POOL->...->CONV->POOL->SOFTMAX architectures, instead to speed up computations it uses atrous convolutions which are resolution perserving. Another great property of these type of networks is the short travel distance between the first and last words, where the path between them is bounded by C*log(d) steps, where C is a constant and d is the length of the input sequence. \nThe architecture is inspired by the Neural Machine Translation in Linear Time and Convolutional Neural Networks for Sentence Classification. \nWhere the Atrous CNN layers are similar to the ones in the bytenet encoder in Neural Machine Translation in Linear Time and the max-over-time pooling idea was inspired from the Convolutional Neural Networks for Sentence Classification paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8308326907665401,
        0.9763118753600583
      ],
      "excerpt": "The network support embedding initialization with pre-trained GloVe vectors (GloVe: Gloval Vectors for Word Representations) which handle even rare words quite well compared to word2vec. \nTo speed up training the model pre-processes any input into \"clean\" file, which then utilizes for training. The data is read by line from the \"clean\" files for better memory management. All input data is split into the appropriate buckets and dynamic padding is applied, which provides better accuracy and speed up during training. The input pipeline can read from multiple data sources which makes addition of more data sources easy as long as they are preprocessed in the right format. The model can be trained on multiple GPUs if the hardware provides this capability. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9154010422426841
      ],
      "excerpt": "(Some images are cropped from WaveNet: A Generative Model for Raw Audio, Neural Machine Translation in Linear Time and Tensorflow's Reading Data Tutorial) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9663038534267668,
        0.8939912846973842
      ],
      "excerpt": "Currently the only supported dataset is the one provided by the Bag of Words Meets Bags of Popcorn challenge, instructions how to obtain and preprocess it can be found here \nThe Kaggle dataset contains 25,000 labeled examples of movie reviews. Positive movie reviews are labeled with 1, while negative movie reviews are labeled with 0. The dataset is split into 20,000 training and 5,000 validation examples. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9607193982544692
      ],
      "excerpt": "Currently the model achieves up to 97% accuracy on the validation set. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.844406219467321
      ],
      "excerpt": ": when in the project's root directory \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9598407248490572,
        0.933050183858173
      ],
      "excerpt": "(kudos to sugartensor for the great tf wrapper which handles all the monitoring out of the box) \nThis version of the model provides interactive testing, in order to start it, execute: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9909975113499343
      ],
      "excerpt": "this is an intimate movie of a sincere girl in the real world out of hollywoods cheap fantasy is a very good piece of its class , and ashley judd fills the role impeccably . it may appear slo \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.940217941469204,
        0.8220041706074617
      ],
      "excerpt": "the silent one - panel cartoon henry comes to fleischer studios , billed as the worlds funniest human in this dull little cartoon . betty , long past her prime , thanks to the production code \n , is running a pet shop and leaves henry in charge for far too long - - five minutes . a bore . \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.881655459443521,
        0.9849564130196962,
        0.9752109906375662
      ],
      "excerpt": "in her first nonaquatic role , esther williams plays a school teacher whos the victim of sexual assault . she gives a fine performance , proving she could be highly effective out of the swimm \ning pool . as the detective out to solve the case , george nader gives perhaps his finest performance . and he is so handsome it hurts ! john saxon is the student under suspicion , and althoug \nh he gets impressive billing in the credits , its edward andrews as his overly - protective father who is the standout . br br bathed in glorious technicolor , the unguarded moment is irresist \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8707793340001692,
        0.8244647125832139
      ],
      "excerpt": "Increase the number of supported datasets \nPut everything into Docker \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Deep-Atrous-CNN-Text-Network: End-to-end word level model for sentiment analysis and other text classifications",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/randomrandom/deep-atrous-cnn-sentiment/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Sun, 12 Dec 2021 13:03:44 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/randomrandom/deep-atrous-cnn-sentiment/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "randomrandom/deep-atrous-cnn-sentiment",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/randomrandom/deep-atrous-cnn-sentiment/master/launch_tensorboard.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. python3.5 -m pip install -r requirements.txt\n1. install tensorflow or tensorflow-gpu, depending on whether your machine supports GPU configurations\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9457036294730059
      ],
      "excerpt": "Current version : 0.0.0.1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8726218842858986
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0,1 python train.py ( <== Use only GPU 0, 1 ) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9465718491881494
      ],
      "excerpt": "bash launch_tensorboard.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8178863957895521
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0,1 python test.py ( <== Use only GPU 0, 1 ) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8654234780903906
      ],
      "excerpt": "python train.py ( <== Use all available GPUs ) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8670128409547527
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0,1 python train.py ( <== Use only GPU 0, 1 ) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665588330449948
      ],
      "excerpt": "python test.py ( <== Use all available GPUs ) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.868058629359746
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0,1 python test.py ( <== Use only GPU 0, 1 ) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8615163242814746
      ],
      "excerpt": "The console will ask for input, some sample manual test over examples of the dataset: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/randomrandom/deep-atrous-cnn-sentiment/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Deep-Atrous-CNN-Text-Network: End-to-end word level model for sentiment analysis and other text classifications",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "deep-atrous-cnn-sentiment",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "randomrandom",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/randomrandom/deep-atrous-cnn-sentiment/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "randomrandom",
        "body": "A working sentiment analysis model which:\r\n- Achieves up to ~97% accuracy on the IMDB movie reviews data set\r\n- Supports loading of pre-trained embeddings\r\n- Supports reading multiple data sources\r\n- Has optimized input pipeline\r\n- Can be trained in parallel on multiple GPUs",
        "dateCreated": "2017-06-30T04:56:01Z",
        "datePublished": "2017-07-03T11:18:08Z",
        "html_url": "https://github.com/randomrandom/deep-atrous-cnn-sentiment/releases/tag/v0.0.0.1",
        "name": "Sentiment analysis - basics",
        "tag_name": "v0.0.0.1",
        "tarball_url": "https://api.github.com/repos/randomrandom/deep-atrous-cnn-sentiment/tarball/v0.0.0.1",
        "url": "https://api.github.com/repos/randomrandom/deep-atrous-cnn-sentiment/releases/6911234",
        "zipball_url": "https://api.github.com/repos/randomrandom/deep-atrous-cnn-sentiment/zipball/v0.0.0.1"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. python3.5\n1. arrow==0.10.0\n1. numpy==1.13.0\n1. pandas==0.20.2\n1. protobuf==3.3.0\n1. python-dateutil==2.6.0\n1. pytz==2017.2\n1. six==1.10.0\n1. sugartensor==1.0.0.2\n1. tensorflow==1.2.0\n1. tqdm==4.14.0\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 66,
      "date": "Sun, 12 Dec 2021 13:03:44 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "convolutional-neural-networks",
      "movie-reviews",
      "classification",
      "sentiment-analysis",
      "text-classification",
      "deep-learning",
      "deep-neural-networks",
      "bytenet",
      "tensorflow",
      "tensorflow-library",
      "imdb"
    ],
    "technique": "GitHub API"
  }
}
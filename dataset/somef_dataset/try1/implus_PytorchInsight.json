{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1905.09646",
      "https://arxiv.org/abs/",
      "https://arxiv.org/abs/"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find our related works useful in your research, please consider citing the paper:\n    \n    @inproceedings{li2019selective,\n      title={Selective Kernel Networks},\n      author={Li, Xiang and Wang, Wenhai and Hu, Xiaolin and Yang, Jian},\n      journal={IEEE Conference on Computer Vision and Pattern Recognition},\n      year={2019}\n    }\n\n    @inproceedings{li2019spatial,\n      title={Spatial Group-wise Enhance: Enhancing Semantic Feature Learning in Convolutional Networks},\n      author={Li, Xiang and Hu, Xiaolin and Xia, Yan and Yang, Jian},\n      journal={arXiv preprint arXiv:1905.09646},\n      year={2019}\n    }\n\n    @inproceedings{li2019understanding,\n      title={Understanding the Disharmony between Weight Normalization Family and Weight Decay: e-shifted L2 Regularizer},\n      author={Li, Xiang and Chen, Shuo and Yang, Jian},\n      journal={arXiv preprint arXiv:},\n      year={2019}\n    }\n\n    @inproceedings{li2019generalization,\n      title={Generalization Bound Regularizer: A Unified Framework for Understanding Weight Decay},\n      author={Li, Xiang and Chen, Shuo and Gong, Chen and Xia, Yan and Yang, Jian},\n      journal={arXiv preprint arXiv:},\n      year={2019}\n    }\n\n\n\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{li2019generalization,\n  title={Generalization Bound Regularizer: A Unified Framework for Understanding Weight Decay},\n  author={Li, Xiang and Chen, Shuo and Gong, Chen and Xia, Yan and Yang, Jian},\n  journal={arXiv preprint arXiv:},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{li2019understanding,\n  title={Understanding the Disharmony between Weight Normalization Family and Weight Decay: e-shifted L2 Regularizer},\n  author={Li, Xiang and Chen, Shuo and Yang, Jian},\n  journal={arXiv preprint arXiv:},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{li2019spatial,\n  title={Spatial Group-wise Enhance: Enhancing Semantic Feature Learning in Convolutional Networks},\n  author={Li, Xiang and Hu, Xiaolin and Xia, Yan and Yang, Jian},\n  journal={arXiv preprint arXiv:1905.09646},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{li2019selective,\n  title={Selective Kernel Networks},\n  author={Li, Xiang and Wang, Wenhai and Hu, Xiaolin and Yang, Jian},\n  journal={IEEE Conference on Computer Vision and Pattern Recognition},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8004157617509665,
        0.842790493796475
      ],
      "excerpt": "SENet: Squeeze-and-excitation Networks <sub>(paper)</sub> \nSKNet: Selective Kernel Networks <sub>(paper)</sub> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "mixup: Beyond Empirical Risk Minimization <sub>(paper) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8130052599129608
      ],
      "excerpt": "--epochs 100 --schedule 30 60 90 --wd 1e-4 --gamma 0.1 -c checkpoints/imagenet/sge_resnet101 --train-batch 32 \\  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8130052599129608
      ],
      "excerpt": "--epochs 100 --schedule 30 60 90 --wd 1e-4 --gamma 0.1 -c checkpoints/imagenet/es1e-3_ws_resnet50 --train-batch 32 \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/implus/PytorchInsight",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-17T05:53:26Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-01T11:25:36Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9952518323465366,
        0.9877737154568741,
        0.8314386722290702
      ],
      "excerpt": "This is a pytorch lib with state-of-the-art architectures, pretrained models and real-time updated results. \nThis repository aims to accelarate the advance of Deep Learning Research, make reproducible results and easier for doing researches, and in Pytorch. \nSENet: Squeeze-and-excitation Networks <sub>(paper)</sub> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8726737801926189
      ],
      "excerpt": "GCNet: GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond <sub>(paper)</sub> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.934416450386808,
        0.8100694930797305,
        0.8201727998860231,
        0.9202000480707755,
        0.8503365933038675,
        0.891560542191802
      ],
      "excerpt": "SGENet: Spatial Group-wise Enhance: Enhancing Semantic Feature Learning in Convolutional Networks <sub>(paper)</sub> \nSRMNet: SRM: A Style-based Recalibration Module for Convolutional Neural Networks <sub>(paper)</sub> \nOctNet: Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution <sub>(paper)</sub> \nimagenet_tricks.py: Bag of Tricks for Image Classification with Convolutional Neural Networks <sub>(paper)</sub> \nUnderstanding the Disharmony between Weight Normalization Family and Weight Decay: e-shifted L2 Regularizer <sub>(to appear)  \nGeneralization Bound Regularizer: A Unified Framework for Understanding Weight Decay <sub>(to appear) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8258976963108813
      ],
      "excerpt": "CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features <sub>(paper) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8398716393348824
      ],
      "excerpt": "||classifiaction training settings for media and large models| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9329016260909037
      ],
      "excerpt": "|Note    | The newest code adds one default operation: setting all bias wd = 0, please refer to the theoretical analysis of \"Generalization Bound Regularizer: A Unified Framework for Understanding Weight Decay\" (to appear), thereby the training accuracy can be slightly boosted| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8106930018968932
      ],
      "excerpt": "Note the following results (old) do not set the bias wd = 0 for large models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.963733544311787
      ],
      "excerpt": "Here SK-ResNet* is a modified version (for more fair comparison with ResNet backbone here) of original SKNet. The original SKNets perform stronger, and the pytorch version can be referred in pppLang-SKNet. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.883332784367839
      ],
      "excerpt": "Note that the following models are with bias wd = 0. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "a pytorch lib with state-of-the-art architectures, pretrained models and real-time updated results",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/implus/PytorchInsight/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 123,
      "date": "Mon, 06 Dec 2021 07:10:02 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/implus/PytorchInsight/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "implus/PytorchInsight",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/implus/PytorchInsight/master/detection/compile.sh",
      "https://raw.githubusercontent.com/implus/PytorchInsight/master/detection/tools/dist_train.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9679328438054625
      ],
      "excerpt": "Note that the following models are with bias wd = 0. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8060839574946584,
        0.8838148168639296
      ],
      "excerpt": "|Details|RandomResizedCrop, RandomHorizontalFlip; 0.1 init lr, total 100 epochs, decay at every 30 epochs; SGD with naive softmax cross entropy loss, 1e-4 weight decay, 0.9 momentum, 8 gpus, 32 images per gpu| \n|Examples| ResNet50 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8838148168639296
      ],
      "excerpt": "|Examples| ShuffleNetV2| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8256508946131169
      ],
      "excerpt": "--epochs 300 --wd 4e-5 --gamma 0.1 -c checkpoints/imagenet/shufflenetv2_1x --train-batch 128 --opt-level O0 --nowd-bn #: Triaing \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8630430536215442
      ],
      "excerpt": "-e --resume ../pretrain/shufflenetv2_1x.pth.tar --test-batch 100 --opt-level O0 #: Testing, ~69.6% top-1 Acc \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8838154668066314
      ],
      "excerpt": "python -W ignore imagenet.py -a sge_resnet101 --data /path/to/imagenet1k/ --epochs 100 --schedule 30 60 90 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8514141800420265
      ],
      "excerpt": "--epochs 100 --schedule 30 60 90 --wd 1e-4 --gamma 0.1 -c checkpoints/imagenet/sge_resnet101 --train-batch 32 \\  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8625415913986836
      ],
      "excerpt": "python -W ignore imagenet.py -a sge_resnet101 --data /path/to/imagenet1k/ --gpu-id 0,1 -e --resume ../pretrain/sge_resnet101.pth.tar \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8604720404070539
      ],
      "excerpt": "../pretrain/sge_resnet101.pth.tar --test-batch 100 --opt-level O0 #: Testing (faster) ~78.8% top-1 Acc \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8514141800420265
      ],
      "excerpt": "--epochs 100 --schedule 30 60 90 --wd 1e-4 --gamma 0.1 -c checkpoints/imagenet/es1e-3_ws_resnet50 --train-batch 32 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.857833486810167
      ],
      "excerpt": "|SK-ResNet101  |45.68M|7.978|78.7920|94.2680|BaiduDrive(boii)|GoogleDrive|sk_resnet101.log| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8098000410645219
      ],
      "excerpt": "| SE-ResNet101  | 47.28M | 168.3 | Mask RCNN    | FPN | 41.5 | 63.0 | 45.3 | GoogleDrive | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/implus/PytorchInsight/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cuda",
      "C++",
      "Shell",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'# Copyright (c) 2012 Giorgos Verigakis &#118;&#101;&#114;&#105;&#103;&#97;&#107;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;\\n#\\n# Permission to use, copy, modify, and distribute this software for any\\n# purpose with or without fee is hereby granted, provided that the above\\n# copyright notice and this permission notice appear in all copies.\\n#\\n# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\\n# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\\n# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\\n# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\\n# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\\n# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\\n# OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "PytorchInsight",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "PytorchInsight",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "implus",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/implus/PytorchInsight/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 775,
      "date": "Mon, 06 Dec 2021 07:10:02 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "classification",
      "detection",
      "state-of-the-art",
      "pretrained-models",
      "sknet",
      "senet",
      "gcnet",
      "cbam",
      "bam",
      "sge",
      "cnn",
      "cnn-tricks",
      "tricks",
      "shufflenetv2",
      "training-shufflenetv2",
      "convolutional-networks",
      "weight-decay",
      "attention-models",
      "weight-normalization-family"
    ],
    "technique": "GitHub API"
  }
}
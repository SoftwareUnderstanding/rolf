{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@inproceedings{wright2021exaggeration,\n    title={{Semi-Supervised Exaggeration Detection of Health Science Press Releases}},\n    author={Dustin Wright and Isabelle Augenstein},\n    booktitle = {Proceedings of EMNLP},\n    publisher = {Association for Computational Linguistics},\n    year = 2021\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{wright2021exaggeration,\n    title={{Semi-Supervised Exaggeration Detection of Health Science Press Releases}},\n    author={Dustin Wright and Isabelle Augenstein},\n    booktitle = {Proceedings of EMNLP},\n    publisher = {Association for Computational Linguistics},\n    year = 2021\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/copenlu/scientific-exaggeration-detection",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-30T18:05:46Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-08T19:06:30Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "Dustin Wright and Isabelle Augenstein \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9989986814971157
      ],
      "excerpt": "Public trust in science depends on honest and factual communication of scientific papers. However, recent studies have demonstrated a tendency of news media to misrepresent scientific papers by exaggerating their findings. Given this, we present a formalization of and study into the problem of exaggeration detection in science communication. While there are an abundance of scientific papers and popular media articles written about them, very rarely do the articles include a direct link to the original paper, making data collection challenging. We address this by curating a set of labeled press release/abstract pairs from existing expert annotated studies on exaggeration in press releases of scientific papers suitable for benchmarking the performance of machine learning models on the task. Using limited data from this and previous studies on exaggeration detection in science, we introduce MT-PET, a multi-task version of Pattern Exploiting Training (PET), which leverages knowledge from complementary cloze-style QA tasks to improve few-shot learning. We demonstrate that MT-PET outperforms PET and supervised learning both when data is limited, as well as when there is an abundance of data for the main task. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9651958760282375
      ],
      "excerpt": "original_file_id: The ID of the original spreadsheet in the Sumner/Bratton data where the annotations are derived from \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8429704716093694
      ],
      "excerpt": "press_release_strength: The strength label for the press release \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8193420742452714
      ],
      "excerpt": "abstract_strength: The strength label for the abstract \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9147051016069432,
        0.8790448652594542,
        0.9968029537584643,
        0.9968029537584643,
        0.9968029537584643,
        0.8210880667856791
      ],
      "excerpt": "The exaggeration label is one of same, exaggerates, or downplays. The strength label is one of the following: \n0: Statement of no relationship \n1: Statement of correlation \n2: Conditional statement of causation \n3: Statement of causation \nWe used the data from insciout_test.jsonl as test data in all of the experiments in the paper. The claim strength data from Yu et al. 2019 and Yu et al. 2020 can be found here. You can download all of the data by running the following: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Repository for the paper \"Semi-Supervised Exaggeration Detection of Health Science Press Releases\" from EMNLP 2021",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/copenlu/scientific-exaggeration-detection/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Tue, 07 Dec 2021 17:07:09 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/copenlu/scientific-exaggeration-detection/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "copenlu/scientific-exaggeration-detection",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/copenlu/scientific-exaggeration-detection/main/data/download_strength_data.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To setup an environment for running our experiments, first install [conda](https://www.anaconda.com/products/individual). Then, run the following:\n\n```bash\n$ conda env create -f environment.yml\n$ conda activate scientific-exaggeration-detection\n```\n\n**NOTE**: We use wandb for logging. If you do not have wandb and only wish to use it for logging, run:\n\n```bash\n$ wandb offline\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8363291541548825
      ],
      "excerpt": "press_release_conclusion: The conclusion sentence from the press release \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8080002376980483,
        0.9465718491881494
      ],
      "excerpt": "$ cd data \n$ bash download_strength_data.sh \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8210154317925469
      ],
      "excerpt": "  <img src=\"exaggeration.png\" alt=\"Exaggeration Detection\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/copenlu/scientific-exaggeration-detection/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Semi-Supervised Exaggeration Detection of Health Science Press Releases",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "scientific-exaggeration-detection",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "copenlu",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/copenlu/scientific-exaggeration-detection/blob/main/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The first step is to run conclusion detection using PET. To do this, run the following commands:\n\n```bash\n$ cd mt-pet\n$ python cli.py \\\n    --method pet \\\n    --pattern_ids 0 1 2 3 4 5 \\\n    --data_dir ../data/conclusion_detection/ \\\n    --model_type roberta \\\n    --model_name roberta-base\\\n    --task_name conclusion-detection-labeled \\\n    --output_dir conclusion_detection \\\n    --do_train \\\n    --do_eval \\\n    --seed 1000 \\\n    --overwrite_output_dir \\\n    --pet_num_train_epochs 10 \\\n    --pet_per_gpu_train_batch_size 4 \\\n    --no_distillation \\\n    --learning_rate 0.000012 \\\n    --warmup_steps 50 \\\n    --weight_decay 0.01 \\\n    --balance_class_weight\n```\n\nNext, create unlabeled conclusion sentences by running the following, selecting the directory corresponding to the main task:\n\n```bash\n$ cd ..\n$ python create_pet_unlabelled_sentences_file.py \\\n    data/conclusion_detection/unlabelled_pet.jsonl \\\n    data/conclusion_detection/unlabelled_ids.txt \\\n    mt-pet/conclusion_detection/unlabeled_logits.txt \\\n    data/{pet_nli|pet_cls}/unlabelled_pet.jsonl\n```\n\nYou can then run multi-task PET as follows (this example is for using CLS as the main task):\n\n```bash\n$ cd mt-pet\n$ python cli.py \\\n    --method pet \\\n    --pattern_ids 1 3 \\\n    --data_dir ../data/pet_cls \\\n    --aux_data_dir ../data/pet_nli \\\n    --model_type roberta \\\n    --model_name roberta-base \\\n    --aux_task_name exaggeration-detection-nli-from-petal \\\n    --task_name exaggeration-detection-multi-task \\\n    --output_dir pet_cls \\\n    --do_train \\\n    --do_multi_task \\\n    --seed 1000 \\\n    --overwrite_output_dir \\\n    --no_distillation \\\n    --pet_num_train_epochs 10 \\\n    --pet_per_gpu_train_batch_size 4  \\\n    --learning_rate 0.00003 \\\n    --warmup_steps 50 \\\n    --weight_decay 0.0001  \\\n    --balance_class_weight \\\n    --aux_verbalizer_file ../data/pet_nli/verbalizers.json\n```\n\nFormat the data for knowledge distillation as follows:\n\n```bash\n$ cd ..\n$ python create_pet_labelled_file.py \\\n    data/pet_cls/unlabelled_pet.jsonl \\\n    mt-pet/pet_cls/unlabeled_logits.txt \\\n    data/pet_cls/pet_soft_labeled.csv\n```\n\nFinally, train the final model and evaluate it as follows:\n\n```bash\n$ python run_cls.py \\\n    --yu_et_al_data data/combined_strength_data.csv \\\n    --pet_data data/pet_cls/pet_soft_labeled.csv \\\n    --test_data_loc data/insciout_test.jsonl \\\n    --model_name roberta-base \\\n    --model_dir models/cls \\\n    --run_name pet-cls \\\n    --tag cls \\\n    --n_gpu 1 \\\n    --batch_size 4 \\\n    --learning_rate 0.00001 \\\n    --n_epochs 3 \\\n    --seed 1000 \\\n    --warmup_steps 200 \\\n    --balance_class_weight \\\n    --temperature 2.0\n```\n\nTo run with NLI as the main task, change the main and auxiliary tasks when running MT-PET and use the `run_nli.py` script for training.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Tue, 07 Dec 2021 17:07:09 GMT"
    },
    "technique": "GitHub API"
  }
}
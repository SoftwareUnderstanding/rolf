{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/clairehester/face-mask-detector",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-20T18:55:07Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-16T11:22:13Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9837447941126878,
        0.8588893983135862,
        0.9866191907131588
      ],
      "excerpt": "There are 853 images included in this dataset. There are a total of 4,072 labeled faces, and of these 2800 faces met the criteria of  > 15 x 15 pixels in size for model training. Classes were imbalanced - 82% of the faces were labeled as \"wearing mask\", and \"mask worn incorrectly\" is the least represented class with only 95 trainable faces. Annotations are in PASCAL VOC format. \nTo solve this data problem, I take a two-step approach. The first step is building a face mask classifier. I use MobileNet as the base model and train a custom head layer that will separate faces into one of three classes: no mask, mask worn incorrectly, and with mask. \nThe second step is to run a face detector model to locate all of the faces in an image. Once a face is located, predictions are made using the classifier. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.985489665719618,
        0.8394127340377366,
        0.9462679293626809,
        0.8855348330451698,
        0.9917790452077115,
        0.9732766507895539,
        0.9835161902787903
      ],
      "excerpt": "The Face Mask Classifier component of the model has a 94% accuracy on both the training and testing data. Categorical cross-entropy was used to measure loss, and after 25 epochs the loss was 0.19. Drilling into the individual classes, \"With Mask\" performed the best, with a 97% f-1 score and 99% recall - only 6 were mis-classified as without mask during predictions. \"Without Mask\" also performed well with an f-1 score of 88%.  \"Mask Worn Incorrectly\" performed most poorly - only 6 of the 29 training samples were predicted accurately. Precision was 100%, but recall was only 21%. With additional samples of incorrectly worn masks, I believe this would perform better. \nFor face detection, I used two different models: an MTCNN (for images) and an OpenCV built-in DNN (for video). \nMTCNN: This model is made up of three stages: a proposal network or P-Net that grabs potential candidate windows, followed by a Refine network  or R-Net that calibrates these candidates using bounding box regression, and an Output Network or O-Net that proposes facial landmarks. The MTCNN model detected 2,670 faces, the most out of the three detectors. \nOpenCV DNN: The OpenCV module comes with a built-in DNN library, and uses a Caffe SSD model built on a Resnet 10 backbone. This model only detected 1,662 faces, but has a much faster performance on video. Predictions were made at 10.8 frames per second. \nThe Streamlit app provides the ability to upload an image and run a face mask detection using the MTCNN model as the detector. This will be a great way to test the generalizability of the model. My hope is to include a webcam version of this model as well but this is under construction at the moment. \nTracking use of face masks in public spaces: similar to a traffic counter, this may aid in the study of social behaviors regarding the use of face masks, possibly in dense urban areas with high numbers of pedestrians and airports.  \nSecurity feature: One of the benefits of a MobileNet model is that it works well on edge devices. Connected to a locking mechanism, this could be used to prevent non-masked individuals from entering a facility such as a restaurant, retail store, office building, or apartment building. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "GA DSI Capstone project - Face Mask Detection using Computer Vision and Machine Learning",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/clairehester/face-mask-detector/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The worldwide COVID-19 pandemic has led to the widespread wearing of face masks to protect ourselves and others from spreading the disease. It is particularly important that these be worn when close contact cannot be avoided, and when inside of buildings. My goal is to create an object detection model that can identify whether a person is wearing a mask correctly, incorrectly, or not at all. Here, \"correctly\" is defined as covering the nose and mouth. This model can be used with both still photos as well as live video feeds.\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Tue, 07 Dec 2021 14:48:06 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/clairehester/face-mask-detector/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "clairehester/face-mask-detector",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/clairehester/face-mask-detector/main/code/03a_face_detector_opencv.ipynb",
      "https://raw.githubusercontent.com/clairehester/face-mask-detector/main/code/03b_face_detector_MTCNN.ipynb",
      "https://raw.githubusercontent.com/clairehester/face-mask-detector/main/code/02_face_mask_detector.ipynb",
      "https://raw.githubusercontent.com/clairehester/face-mask-detector/main/code/01_EDA.ipynb",
      "https://raw.githubusercontent.com/clairehester/face-mask-detector/main/code/.ipynb_checkpoints/01_EDA-checkpoint.ipynb",
      "https://raw.githubusercontent.com/clairehester/face-mask-detector/main/code/.ipynb_checkpoints/03b_face_detector_MTCNN-checkpoint.ipynb",
      "https://raw.githubusercontent.com/clairehester/face-mask-detector/main/code/.ipynb_checkpoints/pyimage-video-checkpoint.ipynb",
      "https://raw.githubusercontent.com/clairehester/face-mask-detector/main/code/.ipynb_checkpoints/02_face_mask_detector-checkpoint.ipynb",
      "https://raw.githubusercontent.com/clairehester/face-mask-detector/main/code/.ipynb_checkpoints/faster_rcnn_kaggle-checkpoint.ipynb",
      "https://raw.githubusercontent.com/clairehester/face-mask-detector/main/code/.ipynb_checkpoints/03a_face_detector_opencv-checkpoint.ipynb",
      "https://raw.githubusercontent.com/clairehester/face-mask-detector/main/code/.ipynb_checkpoints/03c_face_detector_haar_cascade-checkpoint.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/clairehester/face-mask-detector/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Face Mask Object Detection",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "face-mask-detector",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "clairehester",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/clairehester/face-mask-detector/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Tue, 07 Dec 2021 14:48:06 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "**One-Step Detection Model:** As mentioned in the Conclusions section, one of the challenges of a two-step process is the ability to detect a face when it is occluded by a face mask. With a larger dataset to train on, a one-step detection model, such as YOLO or Detectron2, might more effectively detect people wearing face masks.\n\n**Additional Data:** A model is only as good as the data it is trained on. In this instance, this model would benefit specifically from additional images with the \"worn incorrectly\" classification. It would also be beneficial to bring in a larger range of ethnicities, and photos designed to \"trick\" the model - such as images of someone with their hand covering their mouth.\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* <https://www.aicrowd.com/challenges/cyd-campus-aircraft-localization-competition>\n* <https://competition.opensky-network.org/documentation.html>\n* <https://pytorch.org/docs/stable/index.html>\n* <https://spark.apache.org/docs/3.0.0/api/python/index.html>\n* <https://kafka.apache.org/21/documentation.html>\n* <https://flask.palletsprojects.com/en/1.1.x/>\n* <https://leafletjs.com/reference-1.7.1.html>\n* <https://arxiv.org/pdf/1908.07442v1.pdf>\n* <https://www.researchgate.net/publication/304584658_The_Testing_of_MLAT_Method_Application_by_means_of_Usage_low-cost_ADS-B_Receivers>\n* <https://www.lenders.ch/publications/reports/arxiv16_2.pdf>\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8624202905861512
      ],
      "excerpt": "   - TabNet neural network model according to: https://arxiv.org/pdf/1908.07442.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "tar -zxvf spark-3.0.0-bin-hadoop2.7.tgz \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "export SPARK_HOME='spark-3.0.0-bin-hadoop2.7' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9799411683948944
      ],
      "excerpt": "wget https://downloads.apache.org/kafka/2.7.0/kafka_2.12-2.7.0.tgz \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "tar -xvf kafka_2.12-2.7.0.tgz \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "ln -s kafka_2.12-2.7.0 kafka \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/radoslawkrolikowski/adsb-flight-localization",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-10T10:29:53Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-29T16:09:40Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9957995383507586,
        0.9483751228663055,
        0.9116286306530087
      ],
      "excerpt": "This project will guide you from the beginning with the data inspection and preprocessing up to crafting an end to end application for aircraft localization based on crowdsourced air traffic control communication data. The dataset is a part of the Aircraft Localization Competition powered by OpenSky Network and Cyber-Defence Campus - armasuisse Science and Technology. It contains the ADS-B transmissions collected by the large-scale sensor network and poses the following challenges: \n- volume - perform data preprocessing and training of the ML models on the data that doesn't fit into the memory, \n- velocity - real-time data preprocessing, prediction and visualization, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9431136405479656,
        0.871327136084666,
        0.9636331777741903,
        0.9653207124064052,
        0.9703623964405067,
        0.9585087989161982,
        0.9410085692832503,
        0.9785038869948325,
        0.8978751368018805
      ],
      "excerpt": "- value - perform data preprocessing and predictive analytics that leads to insights - prediction of the aircraft current coordinates and altitude, \n- variety - extraction of the data from the JSON arrays nested inside the table. \nTo ensure that our application meets the scalability and performance requirements we will have to use the appropriate technologies. The following are the tools that are going to be utilized: \n- distributed data preprocessing with Apache Spark and Modin, \n- use of ensemble methods (Apache Spark ML, Sklearn) and TabNet model (Pytorch) for tabular learning, \n- memory-efficient loading of data thanks to custom Pytorch Datasets implementations, \n- utilize Apache Kafka to stream real-time data between internal components of the application, \n- real-time data visualization with Flask and Leaflet.js. \nAdditional information about the Aircraft Localization Competition can be found on the official website - AIcrowd. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.985563476520916
      ],
      "excerpt": "The data inspection and visualization notebook will guide you through the process of loading the data, examining the distribution of the features and visualizing an example flight in conjunction with recorded flight parameters such as timestamp, timeAtServer, received signal strength indicator (RSSI), barometric and GPS altitude. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.980599664991622
      ],
      "excerpt": "The second tutorial contains instructions on how to perform the data preprocessing that consist of the following steps: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9559764607135238
      ],
      "excerpt": "check the data frame in terms of missing values, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.868849028674021
      ],
      "excerpt": "perform data casting and filtering, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9002508632052569
      ],
      "excerpt": "create linear regression models of timestamp corrections, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9899886655495947
      ],
      "excerpt": "In this notebook, we are going to train the TabNet neural network model. The implementation of all building blocks of the model can be found in the file TabNetBlocks in this repository. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9835409390986395
      ],
      "excerpt": "This file contains the Pytorch implementations of the following architectures and tools: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9725585173288601
      ],
      "excerpt": "The Implementation of the custom Pytorch Datasets that can be used to load the data from HDF5, Pandas or MariaDB, but also to perform data normalization. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "   - Kafka brokers addresses and topics \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9955133848944986
      ],
      "excerpt": "The producer simulates the stream of ADS-B data. It allows specifying the frequency of the messages and the data filtering parameters such as aircraft serial, its localization or altitude. The raw, real-time ADS-B data is preprocessed according to the same steps that have been taken during the training set preparation. Subsequently, that data is published to corresponding Kafka topic, so that we can use it to make a real-time prediction and visualization of the aircraft position. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9358655470283677
      ],
      "excerpt": "Performs the ADS-B data preprocessing that includes: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9281748010846257,
        0.9494287284340376
      ],
      "excerpt": "Subscribes to a real-time stream of records in given Kafka topic \nPerforms real-time data normalization and prediction using one of the available models: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8062918686880093
      ],
      "excerpt": "The real-time flight radar map developed using the Flask web framework, leaflet.js, chart.js and JavaScript. The index.html file can be found in the templates directory - here. The static directory should contain the following files: CSS, chart.js, leaflet-hotline and leaflet-rotatedmarker files as well as the logo and the plane icon. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.859391086135427
      ],
      "excerpt": "You can click on the plane icon to visualize its route and depict the altitude graph. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8693690846757457
      ],
      "excerpt": "Start the Docker containers without running the ADS-B Flight-Radar, for example, to perform data preprocessing or model training: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8253543696769724
      ],
      "excerpt": "3. Extract the JDK repository: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8615276813805034
      ],
      "excerpt": "5. Verify the version of the JDK with the following command: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9250672542407598
      ],
      "excerpt": "Unpack Kafka repository: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Real-time aircraft localization prediction based on crowdsourced air traffic control communication data (ADS-B)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/radoslawkrolikowski/adsb-flight-localization/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 13 Dec 2021 00:59:32 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/radoslawkrolikowski/adsb-flight-localization/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "radoslawkrolikowski/adsb-flight-localization",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/radoslawkrolikowski/adsb-flight-localization/main/docker/jupyter-spark/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/radoslawkrolikowski/adsb-flight-localization/main/data_preprocessing.ipynb",
      "https://raw.githubusercontent.com/radoslawkrolikowski/adsb-flight-localization/main/prepare_eval_test_datasets.ipynb",
      "https://raw.githubusercontent.com/radoslawkrolikowski/adsb-flight-localization/main/training_TabNet.ipynb",
      "https://raw.githubusercontent.com/radoslawkrolikowski/adsb-flight-localization/main/training_ensemble.ipynb",
      "https://raw.githubusercontent.com/radoslawkrolikowski/adsb-flight-localization/main/data_inspection.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/radoslawkrolikowski/adsb-flight-localization/main/start-flight-radar.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9322609392449874
      ],
      "excerpt": "Pytorch TabNet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.902591055412229,
        0.8902627162932362
      ],
      "excerpt": "cd adsb-flight-localization \nmkdir mysql \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.902591055412229
      ],
      "excerpt": "  - `cd adsb-flight-localization` \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.893820423230172
      ],
      "excerpt": "Apache Spark and Kafka run on JAVA 8/11. Hence, we will start by installing the Java SE Development Kit 8: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8738270071459335,
        0.853359969818034
      ],
      "excerpt": "2. Create the directory for JDK: \n - sudo mkdir /usr/lib/jvm \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8971037623674076,
        0.9601396625860678
      ],
      "excerpt": "- cd /usr/lib/jvm \n- sudo tar -xvzf jdk-8u281-linux-x64.tar.gz \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9534513150634365,
        0.8776003119259079
      ],
      "excerpt": "5. Verify the version of the JDK with the following command: \n- java -version \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9456126673832079
      ],
      "excerpt": "   - cd kafka_2.12-2.7.0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8526314669610822,
        0.9156483279131096,
        0.9614819449529157,
        0.9489210729169806,
        0.9748281004795981,
        0.9826835485592136,
        0.8178468455853939,
        0.9863188686048674,
        0.8611024015282919,
        0.9986422926500436,
        0.9979947896609701,
        0.9244566078020753,
        0.871527752452272,
        0.8611024015282919,
        0.9795564418179916,
        0.8744462888430973,
        0.9751400754246121,
        0.8865894051690338,
        0.8657421565729991,
        0.9947744273946378,
        0.984987235107374,
        0.9871344970700218
      ],
      "excerpt": "Update the apt packages index: \nsudo apt update \nInstall MariaDB by running the following command: \nsudo apt install mariadb-server \nInstall all packages included in requirements.txt \nCreate a virtual environment (conda, virtualenv etc.). \nconda create -n &lt;env_name&gt; python=3.7 \nActivate your environment. \nconda activate &lt;env_name&gt; \nInstall requirements. \npip install -r requirements.txt \nRestart your environment. \nconda deactivate \nconda activate &lt;env_name&gt; \nTo install Node.js run the following commands: \ncurl -fsSL https://deb.nodesource.com/setup_14.x | bash - \napt-get install -y nodejs \nVerify that the Node.js and npm were successfully installed: \nnode --version \nnpm --version \nInstall Leaflet.js using npm package manager: \nnpm install leaflet \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8077664419767612,
        0.8156068277375687
      ],
      "excerpt": "Set START_RADAR='true' if you want to run the ADSB producer, perform the aircraft localization prediction and launch the flights_map Flask application while starting the Docker containers, otherwise set START_RADAR='false' \nStart the Docker containers without running the ADS-B Flight-Radar, for example, to perform data preprocessing or model training: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8261531221466595
      ],
      "excerpt": "  - `START_RADAR='true' docker compose up` \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8316227859526415
      ],
      "excerpt": "1. Create a config file for each of the brokers using sample properties: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/radoslawkrolikowski/adsb-flight-localization/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "JavaScript",
      "Python",
      "HTML",
      "Dockerfile",
      "CSS",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License (MIT)\\n\\nCopyright (c) 2018 Chart.js Contributors\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "ADS-B Flight Localization",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "adsb-flight-localization",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "radoslawkrolikowski",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/radoslawkrolikowski/adsb-flight-localization/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "All indispensable JAR files can be found in jar_files directory.\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Mon, 13 Dec 2021 00:59:32 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "python",
      "apache-spark",
      "apache-kafka",
      "apache-mllib",
      "pytorch",
      "flask",
      "mariadb",
      "leafletjs",
      "ads-b",
      "opensky-network",
      "tabnet",
      "docker",
      "deep-learning"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "![demo gif](https://github.com/radoslawkrolikowski/adsb-flight-localization/blob/main/assets/demo.gif)\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "A. Data inspection and preprocessing as well as training of the ML models.\n1. Specify your configuration by modifying config.py file:\n   - MariaDB properties\n   - Kafka brokers addresses and topics\n2. Run and follow the [data_inspection](https://nbviewer.jupyter.org/github/radoslawkrolikowski/adsb-flight-localization/blob/main/data_inspection.ipynb) notebook to get an insight into the nature of the data.\n3. Create the MariaDB database by running the createDB.py script (not necessary if you want to store preprocessed data in the HDF5 file)\n4. Use the [data_preprocessing](https://nbviewer.jupyter.org/github/radoslawkrolikowski/adsb-flight-localization/blob/main/data_preprocessing.ipynb) notebook to perform the preprocessing of the entire training dataset (consists of 3 files).\n5. Run the [prepare_eval_test_datasets](https://nbviewer.jupyter.org/github/radoslawkrolikowski/adsb-flight-localization/blob/main/prepare_eval_test_datasets.ipynb) notebook to make the evaluation and test sets ready.\n6. Run the [training_ensemble](https://nbviewer.jupyter.org/github/radoslawkrolikowski/adsb-flight-localization/blob/main/training_ensemble.ipynb) notebook to build the Random forest regressor and the Gradient-boosted trees estimators from the training set:\n7. Use the [training_TabNet](https://nbviewer.jupyter.org/github/radoslawkrolikowski/adsb-flight-localization/blob/main/training_TabNet.ipynb) notebook to train the TabNet neural network model.\n\nB. Real-time data preprocessing, prediction and visualization.\n1. Before each run of the application we have to start the ZooKeeper and Kafka brokers:\n\n    1. Start the ZooKeeper:\n        - `cd zookeeper/`\n        - `bin/zkServer.sh start conf/zookeeper.properties`\n    2. Check if it started correctly:\n        - `bin/zkServer.sh status conf/zookeeper.properties`\n\n    3. Start the Kafka nodes:\n       - `cd kafka/`\n       - `bin/kafka-server-start.sh config/server.properties`\n       - `bin/kafka-server-start.sh config/server-1.properties`\n       - `bin/kafka-server-start.sh config/server-2.properties`\n\n2. Create the Kafka topics if you run the application for the first time (list of sample topics can be found in config.py file):\n \n \t1. Create topic:\n\t\t- `bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 3 --partitions 1 --topic topic_name`\n \n\t2. List available topics:\n\t\t- `bin/kafka-topics.sh --list --bootstrap-server localhost:9092`\n\n3. Run the [flights_map](https://github.com/radoslawkrolikowski/adsb-flight-localization/blob/main/flights_map.py) Flask application and then go to the http://localhost:5001/ to access the map.  \n4. Then we can run the ADSB_producer.py to preprocess and publish the real-time ADS-B data to the Kafka topic.\n5. To make a real-time prediction run predict.py file (only data that comes after predict.py is launched is going to be considered).\n6. Observe the real-time aircraft localization predictions using the Flight Radar map (http://localhost:5001/). You can click on the plane icon to visualize its route and depict the altitude graph.\n \n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. [Improved Wasserstein GAN](https://arxiv.org/pdf/1704.00028.pdf)\n2. [Creative Adversarial Network (CAN)](https://arxiv.org/pdf/1706.07068.pdf)\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dylanell/conditional-gan",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-12T16:19:31Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-23T18:22:17Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.980646665439387,
        0.9696275788627232,
        0.9981405170219613,
        0.9872342835007579,
        0.967837899850739,
        0.8898749584162137
      ],
      "excerpt": "This project contains a PyTorch implementation of a Conditional Improved Wasserstein Generative Adversarial Network (GAN) trained on the MNIST Dataset, combined with a simple model serving API for the GAN generator network. \nCompared to a regular GAN, the generator of a conditional GAN takes two inputs; the original randomly sampled input vector plus an additional randomly sampled one-hot vector. This additional one-hot vector takes on the role of representing the \"class\" of a generated sample while the z vector is left to represent the \"style\". One can therefore individually control both the \"style\" and the \"label\" for generated samples, respectively, by changing these two generator input vectors. \nInstead of training a \"vanilla\" conditional GAN in this project, we follow some of the techniques used in this paper to observe the effects of adding an objective that promotes \"creativity\" in the generator model for a GAN, dubbed the \"Creative GAN (CAN)\". Unlike a standard conditional GAN where the generator model is trained to minimize classifier error for conditionally generated images labeled by the \"class\" vector inputs, the CAN is trained to maximize classifier error for all generated samples. The motivation is that by maximally \"confusing\" the classifier, while still fooling the critic into thinking a generated sample is real, the generator will learn to \"create\" new instances that \"fall within the gaps\" of the classifier, which is simultaneously trained on real images. The CAN paper is trained and evaluated on a dataset of art images, which can be a little subjective when it comes to defining what is \"creatively\" novel. For this project, we would like to explore the effects of adding this \"creativity\" objective for a dataset in which class differences are very succinct, like MNIST. \nTraining the CAN on MNIST results in a generator model that doesn't generate very \"creative\" looking digits at all. This result is somewhat unsurprising if you think conceptually about what it means to maximize the confusion for a classifier trained on a dataset of real samples. In the CAN paper, the authors aim to achieve this by minimizing the cross entropy between the classifier output on generated images and the uniform class distribution (\"all-hot\" label vector), resulting in an optimization problem that essentially asks the generator to create realistic looking digits (from the critic's perspective) that look like all digits at once. This is a pretty difficult task for the generator to solve. \nInstead of following the \"maximal confusion\" objective from the CAN paper directly, we relax the rules slightly to allow for randomly sampled \"multi-hot\" or \"k-hot\" labels for generated samples, where k can be anything from 1 to the number of classes. Additionally, we utilize the conditional GAN architecture so that we can control these \"multi-hot\" conditional inputs, therefore controlling the \"creativity\" at the output of the generator model. To do this, we parameterize a custom \"k-hot\" categorical meta-distribution by a \"pan-classness\" parameter pan, which controls the tendency to either sample more \"one-hot\" distributions (standard conditional GAN training) or more \"all-hot\" distributions (standard CAN training). We can therefore train a CAN with \"k-hot\" generator labels where k is more often a moderate value less than the total number of classes, but also not always just 1. The gif above shows a conditional GAN trained in this fashion, where some of the conditional label vectors are \"2-hot\" label. \nPython files that define the architecture and training scripts for the conditional GAN model are located within the conditional_gan project directory. The server directory contains Python files for building and running the generator model serving API. The full project structure tree is below.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9749352385197496
      ],
      "excerpt": "This project assumes you have the MNIST dataset downloaded and preprocessed locally on your machine in the format described below. My dataset-helpers Github project also contains tools that perform this local configuration automatically within the mnist directory of the project. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8848541554938615
      ],
      "excerpt": "If you would like to re-use the code here to work with other image datasets, just format any new image dataset to follow the outline above and be sure to update corresponding parameters in config.yaml. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9541566751065088,
        0.9353527426406799
      ],
      "excerpt": "Move the sliders to generate \"one-hot\" (or \"multi-hot\") label vectors, or press the \"Sample New Style\" button to sample new style vectors. The dashboard automatically generates the corresponding new output image any time these inputs are changed. We can try to control the \"creativity\" at the output of the generator by providing it with \"multi-hot\" labels to see if it can create \"new\" digits from combined generator features. \nThis project also uses FastAPI to setup a model serving API for a pre-trained generator model. Swagger UI interactive API documentation can be viewed at http://localhost:8080/docs on a browser. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9250393890205598
      ],
      "excerpt": "Serve with Docker: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation of Conditional Wasserstein Generative Adversarial Network (GAN) in PyTorch",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dylanell/conditional-wgan/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 12 Dec 2021 16:41:39 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dylanell/conditional-gan/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "dylanell/conditional-gan",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/dylanell/conditional-wgan/main/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Runtime:\n\n```\nPython 3.8.5\n```\n\nInstall Python requirements:\n\n```\n$ pip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9033987252512259
      ],
      "excerpt": "\u251c\u2500\u2500 requirements.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8743822661273637,
        0.8084890251161878
      ],
      "excerpt": "Serve with Python: \nNavigate to the server directory and run the following command to spin up the API server on http://localhost:8080/. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 dashboard.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8953781568854575,
        0.9336801098518991
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 datasets.py \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8053002471203892,
        0.950563948951535
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 modules.py \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 train.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "\u2502\u00a0\u00a0     \u2514\u2500\u2500 __init__.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.9336801098518991
      ],
      "excerpt": "    \u251c\u2500\u2500 __init__.py \n    \u2514\u2500\u2500 wrappers.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633989807152664
      ],
      "excerpt": "\u251c\u2500\u2500 test \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "\u251c\u2500\u2500 train \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.806191399365685,
        0.8058987948670288
      ],
      "excerpt": "Each labels csv file has the format: \nFilename, Label \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8084093422505473,
        0.9503189345333785,
        0.8165059395258703
      ],
      "excerpt": "To train the model, navigate to the conditional_gan directory and run: \n$ python train.py \nThe training script will generate model artifacts to the artifacts/ directory. Configuration and training parameters can be controlled by editing config.yaml. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "$ python dashboard.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dylanell/conditional-gan/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "conditional-gan",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "conditional-gan",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "dylanell",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dylanell/conditional-gan/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 12 Dec 2021 16:41:39 GMT"
    },
    "technique": "GitHub API"
  }
}
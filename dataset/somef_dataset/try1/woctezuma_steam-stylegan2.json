{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1812.04948",
      "https://arxiv.org/abs/2002.03754>\n[ganspace-paper]: <https://arxiv.org/abs/2004.02546>\n[closed-form-paper]: <https://arxiv.org/abs/2007.06600>\n\n[interfacegan]: <https://github.com/genforce/interfacegan>\n[ganspace]: <https://github.com/harskish/ganspace>\n[ALAE]: <https://github.com/podgorskiy/ALAE>\n[GanLatentDiscovery]: <https://github.com/anvoynov/GanLatentDiscovery>\n[closed-form-repository]: <https://github.com/genforce/sefa>\n[closed-form]: <https://github.com/rosinality/stylegan2-pytorch#closed-form-factorization-httpsarxivorgabs200706600>\n\n[weight-converter]: <https://github.com/rosinality/stylegan2-pytorch>\n[weight-converter-instructions]: <https://github.com/rosinality/stylegan2-pytorch/issues/52>\n\n[colab-badge]: <https://colab.research.google.com/assets/colab-badge.svg>",
      "https://arxiv.org/abs/2004.02546>\n[closed-form-paper]: <https://arxiv.org/abs/2007.06600>\n\n[interfacegan]: <https://github.com/genforce/interfacegan>\n[ganspace]: <https://github.com/harskish/ganspace>\n[ALAE]: <https://github.com/podgorskiy/ALAE>\n[GanLatentDiscovery]: <https://github.com/anvoynov/GanLatentDiscovery>\n[closed-form-repository]: <https://github.com/genforce/sefa>\n[closed-form]: <https://github.com/rosinality/stylegan2-pytorch#closed-form-factorization-httpsarxivorgabs200706600>\n\n[weight-converter]: <https://github.com/rosinality/stylegan2-pytorch>\n[weight-converter-instructions]: <https://github.com/rosinality/stylegan2-pytorch/issues/52>\n\n[colab-badge]: <https://colab.research.google.com/assets/colab-badge.svg>",
      "https://arxiv.org/abs/2007.06600>\n\n[interfacegan]: <https://github.com/genforce/interfacegan>\n[ganspace]: <https://github.com/harskish/ganspace>\n[ALAE]: <https://github.com/podgorskiy/ALAE>\n[GanLatentDiscovery]: <https://github.com/anvoynov/GanLatentDiscovery>\n[closed-form-repository]: <https://github.com/genforce/sefa>\n[closed-form]: <https://github.com/rosinality/stylegan2-pytorch#closed-form-factorization-httpsarxivorgabs200706600>\n\n[weight-converter]: <https://github.com/rosinality/stylegan2-pytorch>\n[weight-converter-instructions]: <https://github.com/rosinality/stylegan2-pytorch/issues/52>\n\n[colab-badge]: <https://colab.research.google.com/assets/colab-badge.svg>"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "-   StyleGAN2:\n    -   [StyleGAN2][stylegan2-official-repository] / [StyleGAN2-ADA][stylegan2-ada-official-repository] / [StyleGAN2-ADA-PyTorch][stylegan2-ada-pytorch-repository]\n    -   [Projecting images to latent space with StyleGAN2][projection-github-project]\n-   StyleGAN:\n    -   [StyleGAN1](https://github.com/NVlabs/stylegan)\n    -   [Steam-StyleGAN1](https://github.com/woctezuma/steam-stylegan)\n-   DCGAN:    \n    -   [Steam-DCGAN](https://github.com/woctezuma/google-colab)\n-   Useful tools:\n    -   My [fork][stylegan2-fork] of StyleGAN2 to project a batch of images, using any projection (original or extended)\n    -   A [model-weight converter][weight-converter] from TensorFlow (`.pkl`) to PyTorch (`.pt`), with some instructions [here][weight-converter-instructions]\n-   Detailed tutorials:\n    -   [This Waifu Does Not Exist](https://www.gwern.net/TWDNE)\n    -   [Making Anime Faces With StyleGAN](https://www.gwern.net/Faces)\n-   Papers about the unsupervised discovery of latent directions:\n    - [Voynov, Andrey, et al. *Unsupervised Discovery of Interpretable Directions in Latent Space*. ICML 2020.][GanLatentDiscovery-paper] **([code][GanLatentDiscovery])**\n    - [H\u00e4rk\u00f6nen, Erik, et al. *GANSpace: Discovering Interpretable GAN Controls*. arXiv 2020.][ganspace-paper] **([code][ganspace])**\n    - [Shen, Yujun, et al. *Closed-Form Factorization of Latent Semantics in GANs*. arXiv 2020.][closed-form-paper] **([code][closed-form])**\n\n<!-- Definitions -->\n\n[stylegan2-official-repository]: <https://github.com/NVlabs/stylegan2>\n[stylegan2-ada-official-repository]: <https://github.com/NVlabs/stylegan2-ada>\n[stylegan2-ada-pytorch-repository]: <https://github.com/NVlabs/stylegan2-ada-pytorch>\n\n[google-drive-last-checkpoint-pytorch]: <https://drive.google.com/file/d/1-2pWoqvSysNuYS8acfhbU9ql4Si09hyf/view?usp=sharing>\n[google-drive-last-checkpoint]: <https://drive.google.com/file/d/1HXczmPE4PMBbhrPOshshnS0KFI4J6jbC/view?usp=sharing>\n[google-drive-checkpoints]: <https://drive.google.com/drive/folders/1bf17M5HtqdWYhxhCzo1YCEr9fdS84NO6>\n[google-drive-without-truncation]: <https://drive.google.com/open?id=1hCH4y1a9NhXkmgDc6mqnBRdwolsmttg2>\n[google-drive-with-truncation]: <https://drive.google.com/open?id=1zvnkPz0mKusrGW6TojFOrZjiqYAKi6sn>\n[google-drive-truncation-comparison]: <https://drive.google.com/drive/folders/1itOMCX6h62OWpUCBxmUWcrKh0lSXxSGQ>\n[projection-to-latent-space]: <https://drive.google.com/open?id=14Uz3SbOL0G4aLK1AmHye9bJCmOufDdbn>\n\n[projection-github-project]: <https://github.com/woctezuma/stylegan2-projecting-images>\n[stylegan2-fork]: <https://github.com/woctezuma/stylegan2/tree/tiled-projector>\n\n[StyleGAN2_training]: <https://colab.research.google.com/github/woctezuma/steam-stylegan2/blob/master/StyleGAN2_training.ipynb>\n[StyleGAN2_image_sampling]: <https://colab.research.google.com/github/woctezuma/steam-stylegan2/blob/master/StyleGAN2_image_sampling.ipynb>\n[StyleGAN2_metrics]: <https://colab.research.google.com/github/woctezuma/steam-stylegan2/blob/master/StyleGAN2_metrics.ipynb>\n[StyleGAN2_latent_discovery]: <https://colab.research.google.com/github/woctezuma/steam-stylegan2/blob/master/StyleGAN2_latent_discovery.ipynb>\n[Ganspace_colab_for_steam]: <https://colab.research.google.com/github/woctezuma/steam-stylegan2/blob/ganspace/Ganspace_colab_for_steam.ipynb>\n\n[GanLatentDiscovery-paper]: <https://arxiv.org/abs/2002.03754>\n[ganspace-paper]: <https://arxiv.org/abs/2004.02546>\n[closed-form-paper]: <https://arxiv.org/abs/2007.06600>\n\n[interfacegan]: <https://github.com/genforce/interfacegan>\n[ganspace]: <https://github.com/harskish/ganspace>\n[ALAE]: <https://github.com/podgorskiy/ALAE>\n[GanLatentDiscovery]: <https://github.com/anvoynov/GanLatentDiscovery>\n[closed-form-repository]: <https://github.com/genforce/sefa>\n[closed-form]: <https://github.com/rosinality/stylegan2-pytorch#closed-form-factorization-httpsarxivorgabs200706600>\n\n[weight-converter]: <https://github.com/rosinality/stylegan2-pytorch>\n[weight-converter-instructions]: <https://github.com/rosinality/stylegan2-pytorch/issues/52>\n\n[colab-badge]: <https://colab.research.google.com/assets/colab-badge.svg>\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9690798918356124
      ],
      "excerpt": "<img alt=\"Style Mixing without truncation\" src=\"https://raw.githubusercontent.com/wiki/woctezuma/steam-stylegan2/img/style-mixing/00058-style-mixing-example_grid.jpg\" width=\"500\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/woctezuma/steam-stylegan2",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-14T20:47:10Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-11T22:42:42Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9951104238645679,
        0.9240521270736459
      ],
      "excerpt": "The goal of this Google Colab notebook is to capture the distribution of Steam banners and sample with a StyleGAN2. \nThe dataset consists of 14,035 Steam banners with RGB channels and resized from 300x450 to 256x256 resolution. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9888931816323301,
        0.8920110735592924
      ],
      "excerpt": "The StyleGAN2 model is trained with configuration e to accommodate for Google Colab's memory constraints. \nTraining parameters are arbitrarily chosen, with an inspiration from the values detailed in the StyleGAN2 README for the FFHQ dataset: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8379170137872524
      ],
      "excerpt": "With mirroring, the dataset size is about 28k images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9872943564277772,
        0.9701852208536654,
        0.9185487582762807,
        0.9685893251804981
      ],
      "excerpt": "Caveat: there is no good rule-of-thumb! Indeed, the right value would depend on the difficulty of the task (the more complex the task to learn, the longer training is needed ; e.g. generating game banners vs. human faces, 256x256 resolution vs. 1024x1024 resolution, etc.), and not solely on the size of the training dataset (the more diverse data is available, the longer training is possible without over-fitting the training dataset). \nThe training is performed for 5,000 kimg, i.e. 5 million images, which translated into roughly 625 ticks of 8 kimg. \nGiven that each tick requires 15 minutes of computation, the total training time with 1 GPU on Google Colab is about 6.5 days. \nDuring training, checkpoints of the model are saved every thousand epochs, and shared on [Google Drive][google-drive-checkpoints]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9285335248359073,
        0.9448947485336963,
        0.8814123060702829,
        0.9270197909629041
      ],
      "excerpt": "-   [PyTorch][google-drive-last-checkpoint-pytorch] (.pt), thanks to a [model-weight converter][weight-converter]. \nThe generated images are diverse, in terms of configuration and color palettes. Interestingly, it seems that an anime character (with large eyes, hair, mouth, ear and nose) has been learnt. \nA grid of generated Steam banners is shown below: \nFor comparison, here is a grid of real Steam banners: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9472680981583365,
        0.980812566105813,
        0.9964650291819571,
        0.8470359900621385
      ],
      "excerpt": "-   [with truncation][google-drive-with-truncation]. \nThe term 'truncation' refers to the truncation trick mentioned in Appendix B of the StyleGAN1 paper: \nIf we consider the distribution of training data, it is clear that areas of low density are poorly represented and thus likely to be difficult for the generator to learn. This is a significant open problem in all generative modeling techniques. However, it is known that drawing latent vectors from a truncated [42, 5] or otherwise shrunk [34] sampling space tends to improve average image quality, although some amount of variation is lost. \nThe influence of truncation can be studied with side-by-side comparison of generated images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9399313787527495
      ],
      "excerpt": "- images to the right are obtained with the same seed and with truncation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9621564550193648
      ],
      "excerpt": "Similarly to style mixing of faces: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9303164153193941
      ],
      "excerpt": "With truncation, color palettes are less diverse, which is expected, and seem to be darker. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9124587543042696,
        0.9391466071329719,
        0.978922131383239
      ],
      "excerpt": "Real Steam banners can be [projected][projection-github-project] to latent space. \nProjections obtained with 23 popular games are shown on the Wiki. \nA directory with similar data is also shared on [Google Drive][projection-to-latent-space]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.894209125206801,
        0.8650059467920175,
        0.9592106971200232
      ],
      "excerpt": "From left to right, the columns correspond to : \n1.  the generated image obtained at the start of the projection, \n2.  the generated image obtained at the end of the projection, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Train a StyleGAN2 model on Colaboratory to generate Steam banners.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/woctezuma/steam-stylegan2/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Sat, 11 Dec 2021 10:01:58 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/woctezuma/steam-stylegan2/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "woctezuma/steam-stylegan2",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/woctezuma/steam-stylegan2/master/StyleGAN2_metrics.ipynb",
      "https://raw.githubusercontent.com/woctezuma/steam-stylegan2/master/StyleGAN2_image_sampling.ipynb",
      "https://raw.githubusercontent.com/woctezuma/steam-stylegan2/master/StyleGAN2_training.ipynb",
      "https://raw.githubusercontent.com/woctezuma/steam-stylegan2/master/StyleGAN2_latent_discovery.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9140626734668563
      ],
      "excerpt": "The last snapshot (network-snapshot-005000) can be directly downloaded from the following links for: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.876958326994539,
        0.8730581010425501
      ],
      "excerpt": "-   --mirror-augment=true: data augmentation with horitontal mirroring, \n-   --total-kimg=5000: during training with our dataset, StyleGAN2 will be shown 5 million images, so 5 times fewer images than for FFHQ (25 million images: --total-kimg=25000). \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/woctezuma/steam-stylegan2/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Wok\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Steam StyleGAN2",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "steam-stylegan2",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "woctezuma",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/woctezuma/steam-stylegan2/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 30,
      "date": "Sat, 11 Dec 2021 10:01:58 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "google-colab",
      "google-colaboratory",
      "google-colab-notebook",
      "colab",
      "colaboratory",
      "colab-notebook",
      "steam",
      "steam-api",
      "steam-games",
      "steam-game",
      "steam-pics",
      "steam-store",
      "steam-data",
      "gan",
      "generative-adversarial-network",
      "stylegan",
      "style-gan",
      "stylegan-model",
      "steam-gan",
      "stylegan2"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "-   Acquire the data, e.g. as a snapshot called `256x256.zip` in [another of my repositories](https://github.com/woctezuma/download-steam-banners-data),\n-   Run [`StyleGAN2_training.ipynb`][StyleGAN2_training] to train a StyleGAN2 model from scratch,\n[![Open In Colab][colab-badge]][StyleGAN2_training]\n-   Run [`StyleGAN2_image_sampling.ipynb`][StyleGAN2_image_sampling] to generate images with a trained StyleGAN2 model,\n[![Open In Colab][colab-badge]][StyleGAN2_image_sampling]\n-   To automatically resume training from the latest checkpoint, you will have to use [my fork](https://github.com/woctezuma/stylegan2/tree/google-colab) of StyleGAN2.\n\nFor a more thorough analysis of the trained model:\n-   Run [`StyleGAN2_metrics.ipynb`][StyleGAN2_metrics] to compute metrics (FID, PPL, etc.),\n[![Open In Colab][colab-badge]][StyleGAN2_metrics]\n-   Run [`StyleGAN2_latent_discovery.ipynb`][StyleGAN2_latent_discovery] to discover meaningful latent directions,\n[![Open In Colab][colab-badge]][StyleGAN2_latent_discovery]\n-   Run [`Ganspace_colab_for_steam.ipynb`][Ganspace_colab_for_steam] to specifically use GANSpace for discovery,\n[![Open In Colab][colab-badge]][Ganspace_colab_for_steam]\n\n",
      "technique": "Header extraction"
    }
  ]
}
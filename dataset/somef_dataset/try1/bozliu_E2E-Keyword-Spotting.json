{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1804.03209",
      "https://arxiv.org/abs/1707.01629",
      "https://arxiv.org/abs/1608.06993"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "Multi-head Attention \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9438648833247606
      ],
      "excerpt": "Densely Connected Convolutional Networks from arxiv \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bozliu/E2E-Keyword-Spotting",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-02-10T06:46:19Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-18T05:15:10Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\u251c\u2500\u2500 kws   \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 metrics    \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 fnr_fpr.py  \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py  \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 models   \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 attention.py  \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 crnn.py  \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 densenet.py  \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 dpn.py  \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py  \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 resnet.py   \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 resnext.py  \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 treasure_net.py  \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 vgg.py  \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 wideresnet.py  \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 transforms  \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 utils.py  \n\u251c\u2500\u2500 config.py  \n\n* *./kws/metrics* : Evaluation matrics, defining the False Rejection Rate (FRR) and False Alarm Rate (FAR) for keyword spotting\n* *./kws/models* : Diffferent network architecture \n* *.config.py* : Configuration about parameters and hyperparameters\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8322944883510437
      ],
      "excerpt": "Joint End to End Approaches to Improving Far-field Wake-up Keyword Detection \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9146607581247128
      ],
      "excerpt": "VGG19/VGG16/VGG13/VGG11 with/without batch normalization \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8023579790138877
      ],
      "excerpt": "Wide Residual Networks ('wideresnet28_10') imported from the repository \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Wake-Up Keyword Detection With End To End Deep Neural Networks",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bozliu/E2E-Keyword-Spotting/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 09 Dec 2021 23:57:38 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/bozliu/E2E-Keyword-Spotting/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "bozliu/E2E-Keyword-Spotting",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Python >= 3.7 (Recommend to use [Anaconda](https://www.anaconda.com/download/#linux) or [Miniconda](https://docs.conda.io/en/latest/miniconda.html))\n- [PyTorch >= 1.3](https://pytorch.org/)\n- NVIDIA GPU + [CUDA](https://developer.nvidia.com/cuda-downloads)\n\n\n1. Install dependent packages\n\n    ```bash\n    cd E2E-Keyword-Spotting\n    pip install -r requirements.txt\n    ```\n2. Or use conda \n    ```bash\n    cd E2E-Keyword-Spotting\n    conda env create -f environment.yaml\n    ```\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9503189345333785
      ],
      "excerpt": "python train.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9078431934650627,
        0.9515752551715031,
        0.8068729322951622
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0,1 python train.py \npython test.py \n<img src=\"https://github.com/bozliu/E2E-Keyword-Spotting/blob/main/images/Standard%20E2E%20Architecture.png \" width=\"100%\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/bozliu/E2E-Keyword-Spotting/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 bozliu\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "E2E-Keyword-Spotting",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "E2E-Keyword-Spotting",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "bozliu",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bozliu/E2E-Keyword-Spotting/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Python >= 3.7 (Recommend to use [Anaconda](https://www.anaconda.com/download/#linux) or [Miniconda](https://docs.conda.io/en/latest/miniconda.html))\n- [PyTorch >= 1.3](https://pytorch.org/)\n- NVIDIA GPU + [CUDA](https://developer.nvidia.com/cuda-downloads)\n\n\n1. Install dependent packages\n\n    ```bash\n    cd E2E-Keyword-Spotting\n    pip install -r requirements.txt\n    ```\n2. Or use conda \n    ```bash\n    cd E2E-Keyword-Spotting\n    conda env create -f environment.yaml\n    ```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 09 Dec 2021 23:57:38 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Dataset is from [Google Speech Command](https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html) published in  [arxiv](https://arxiv.org/abs/1804.03209).\n* Data Pre-processing (Has already been done)\n1. According to the file, dataset has already been splited into three folders, train, test, and valid. \n1. The splited [Google Speech Command dataset](https://drive.google.com/file/d/1InqR8n7l5Qj6voJREpcjHYWHVTKG-BbB/view?usp=sharing) is saved in Google Drive folder. \n    \n",
      "technique": "Header extraction"
    }
  ]
}
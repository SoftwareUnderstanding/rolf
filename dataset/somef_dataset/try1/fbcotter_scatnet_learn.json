{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1903.03137\n__ https://arxiv.org/abs/1203.1513 \n\nInstallation\n------------\nThis repo uses my pytorch implementation of the dtcwt: `pytorch_wavelets`__. You\ncan install this however just by pip installing the requirements.txt. From the\ncommand line, the following 3 commands will allow you to run the experiments:\n\n.. code:: \n\n    git clone https://github.com/fbcotter/scatnet_learn\n    pip install -r requirements.txt\n    pip install .\n\n__ https://github.com/fbcotter/pytorch_wavelets\n\nRunning Experiments\n-------------------\nThe whole suite of tests to create Table 1 can be run by running the\n`experiments/paper_experiments.py` file. Note that this is written to work on a multi-gpu\nsystem, and loads each gpu with different nets - i.e. it is very intensive and\ncan take several hours to run. It is recommended to try to run individual nets\nfirst.\n\nDevelopment and Expansion\n-------------------------\nThe code is designed to be reusable, so you can design your own networks using\nthe original ScatNet or Learnable ScatNet layers. For example, if you wanted to\ncreate a standard DTCWT ScatterNet frontend with no learned mixing, you can with\nthe following code:\n\n.. code:: python\n\n    from scatnet_learn import ScatLayerj1\n    import torch.nn as nn\n    from collections import OrderedDict\n    C = 3\n    # A standard scatlayer expands the channel input from C to 7C - one \n    # lowpass and 6 oriented bandpass.\n    frontend = nn.Sequential(OrderedDict([\n                ('order1', ScatLayer(",
      "https://arxiv.org/abs/1203.1513 \n\nInstallation\n------------\nThis repo uses my pytorch implementation of the dtcwt: `pytorch_wavelets`__. You\ncan install this however just by pip installing the requirements.txt. From the\ncommand line, the following 3 commands will allow you to run the experiments:\n\n.. code:: \n\n    git clone https://github.com/fbcotter/scatnet_learn\n    pip install -r requirements.txt\n    pip install .\n\n__ https://github.com/fbcotter/pytorch_wavelets\n\nRunning Experiments\n-------------------\nThe whole suite of tests to create Table 1 can be run by running the\n`experiments/paper_experiments.py` file. Note that this is written to work on a multi-gpu\nsystem, and loads each gpu with different nets - i.e. it is very intensive and\ncan take several hours to run. It is recommended to try to run individual nets\nfirst.\n\nDevelopment and Expansion\n-------------------------\nThe code is designed to be reusable, so you can design your own networks using\nthe original ScatNet or Learnable ScatNet layers. For example, if you wanted to\ncreate a standard DTCWT ScatterNet frontend with no learned mixing, you can with\nthe following code:\n\n.. code:: python\n\n    from scatnet_learn import ScatLayerj1\n    import torch.nn as nn\n    from collections import OrderedDict\n    C = 3\n    # A standard scatlayer expands the channel input from C to 7C - one \n    # lowpass and 6 oriented bandpass.\n    frontend = nn.Sequential(OrderedDict([\n                ('order1', ScatLayer("
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9944484218006108,
        0.9944484218006108
      ],
      "excerpt": " https://arxiv.org/abs/1903.03137 \n https://arxiv.org/abs/1203.1513 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fbcotter/scatnet_learn",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-27T14:12:36Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-21T20:13:30Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9069777516859177,
        0.8102796812021421,
        0.8445626448423817
      ],
      "excerpt": "This repo implements the network described in the paper A Learnable ScatterNet: \nLocally Invariant Convolutional Layers__. In particular, it is a way to \nreplicate the results from Table 3 using PyTorch: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9733206440867832
      ],
      "excerpt": "The learnable ScatterNet is a DTCWT based scatternet. It differs from the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8775859205527379
      ],
      "excerpt": "orders. To do this we've programmed a differentiable scatternet, allowing us to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8575048526287449,
        0.928457788766801,
        0.9933382663462494
      ],
      "excerpt": "the DTCWT, we are restricted in the number of orientations we can use in the \nScattering. For more information see the paper. \nThe results in the table above highlight the benefits of our implementation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8137665369957704,
        0.8394442226164572
      ],
      "excerpt": "between scattering orders. ScatterNet C is again the original translation \ninvariant scatternet but with a learned convolutional layer before it and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.92639636052575
      ],
      "excerpt": "A block diagram of what we're doing is shown below (Figure 1 from the paper). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8901489791709488
      ],
      "excerpt": "The code is designed to be reusable, so you can design your own networks using \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Repo containing code to do the learnable scatternet/invariant convolutional layer",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fbcotter/scatnet_learn/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Mon, 06 Dec 2021 03:39:26 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/fbcotter/scatnet_learn/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "fbcotter/scatnet_learn",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This repo uses my pytorch implementation of the dtcwt: `pytorch_wavelets`__. You\ncan install this however just by pip installing the requirements.txt. From the\ncommand line, the following 3 commands will allow you to run the experiments:\n\n.. code:: \n\n    git clone https://github.com/fbcotter/scatnet_learn\n    pip install -r requirements.txt\n    pip install .\n\n__ https://github.com/fbcotter/pytorch_wavelets\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8435540481439273
      ],
      "excerpt": "the following code: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8267885852423639
      ],
      "excerpt": "# A standard scatlayer expands the channel input from C to 7C - one  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from scatnet_learn import ScatLayerj1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8791175621392118
      ],
      "excerpt": "from collections import OrderedDict \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from scatnet_learn import InvariantLayerj1 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/fbcotter/scatnet_learn/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "The Learnable ScatterNet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "scatnet_learn",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "fbcotter",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fbcotter/scatnet_learn/blob/master/README.rst",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The whole suite of tests to create Table 1 can be run by running the\n`experiments/paper_experiments.py` file. Note that this is written to work on a multi-gpu\nsystem, and loads each gpu with different nets - i.e. it is very intensive and\ncan take several hours to run. It is recommended to try to run individual nets\nfirst.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 11,
      "date": "Mon, 06 Dec 2021 03:39:26 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1707.07012\n  * EfficientNetB7 https://arxiv.org/abs/1905.11946\n  * DenseNet201 https://arxiv.org/abs/1608.06993\n* Further reading:\n  * https://paperswithcode.com/task/image-classification\n  * https://towardsdatascience.com/state-of-the-art-image-classification-algorithm-fixefficientnet-l2-98b93deeb04c\n  * https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/\n  * *(Not choosen due to lack of fitting implementation, but interesting performance",
      "https://arxiv.org/abs/1905.11946\n  * DenseNet201 https://arxiv.org/abs/1608.06993\n* Further reading:\n  * https://paperswithcode.com/task/image-classification\n  * https://towardsdatascience.com/state-of-the-art-image-classification-algorithm-fixefficientnet-l2-98b93deeb04c\n  * https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/\n  * *(Not choosen due to lack of fitting implementation, but interesting performance",
      "https://arxiv.org/abs/1608.06993\n* Further reading:\n  * https://paperswithcode.com/task/image-classification\n  * https://towardsdatascience.com/state-of-the-art-image-classification-algorithm-fixefficientnet-l2-98b93deeb04c\n  * https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/\n  * *(Not choosen due to lack of fitting implementation, but interesting performance"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9278824608274014
      ],
      "excerpt": "Supervisor: Rakesh Rao Ramachandra Rao: rakesh-rao.ramachandra-rao@tu-ilmenau.de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8930062140824065
      ],
      "excerpt": "submit a 4-page IEEE style paper (including references) until 04.02.2021 (11:59 PM) to Ashutosh Singla via email. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944484218006108,
        0.9944484218006108,
        0.9944484218006108
      ],
      "excerpt": "  * NASNetLarge https://arxiv.org/abs/1707.07012 \n  * EfficientNetB7 https://arxiv.org/abs/1905.11946 \n  * DenseNet201 https://arxiv.org/abs/1608.06993 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9300402929766787
      ],
      "excerpt": "<br>Add a 1 if statement true, 0 if false  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9314737149988371
      ],
      "excerpt": "source for general performance on imagenet: https://paperswithcode.com/sota/image-classification-on-imagenet  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9702105236373249
      ],
      "excerpt": "https://cloud.tu-ilmenau.de/s/AKo8jqwEXLFs7Q3 </br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "* PCA approach: (@Asad, @Abhinav, @Muhammad) until 03.01.2021 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/asad-62/IVP-DNN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-20T14:12:43Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-02-21T18:28:14Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.988474681626446
      ],
      "excerpt": "(Contains the Code for the Group Project Topic 2: Image Classification) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8557115317747719,
        0.8923829629590747,
        0.8159449024928318,
        0.829670680646709,
        0.8582075843518702
      ],
      "excerpt": "Many image classificaton algorithms, both classical and machine-learning-based, have been proposed in literature. \nThe main goals of this task are as follows: \n* Select 3 image classification algorithms of your choice \n  * The choice should be based on an objective reason \n  * These algorithms can either be classical or machine-learning-based \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9061490795640043
      ],
      "excerpt": "* Analyse the results of the 3 classification algorithms \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.981631324438773
      ],
      "excerpt": "Selected three CNN-Approaches for image classification based on state-of-the-art benchmarks for CNNs trained on ImageNet database (TOP 1 and TOP 5 accuracy | different amount of training pictures) that are part of the Keras API (https://www.tensorflow.org/api_docs/python/tf/keras/applications?hl=de) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9740094754255016
      ],
      "excerpt": "Our three selected cnns were all trained on the ImageNet database, which leads to the same 1000 possible outputs/classification results. We use this fact by doing a second ground truth, for which we assign a small amount (1 to 5) of the possible labels (out of the 1000) for each image, that we consider as the best fitting. This ground thruth would be compareable, since all networks have the same possibility for hitting the assinged ground truth label. Also a scripted comparision woulb be possible with this approach. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8464459655604911,
        0.8465433665842712
      ],
      "excerpt": "<br>The most likely classification is acceptable for the picture -> both get a 1<br> \nAt least one of all classification results is acceptable -> TOP 5 gets a 1, TOP 1 gets a 0<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9548413181591276,
        0.9888638535382976
      ],
      "excerpt": "We had a look at the picture dataset again and decided for each picture if it would be considered as \"easy to classify\" by us. We decided this subjectively based on the simplicity of the scene (only one human, an animal, or an object in the picture). <br> \nWe took all pictures that at least 4 group members considered as easy for the network and did a new ACC calculation with the following outcome:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9845184137055494
      ],
      "excerpt": "Unexpectedly, this has drastically worsened the results. Since 48 of the 200 images are portraits, which were often classified as easy to classify data, it was hypothesized that the networks generally achieve worse accuracy for portraits. To test this, performance was analyzed between the subjectively assigned classes of portraits and non-portraits: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9864335501471185,
        0.9936489732033696,
        0.9815800731772366
      ],
      "excerpt": "The graph shows the normalized precentage-values for the two classes for the histogram bins from 0 (meaning no cnn has labled it correctly) up to 6 (meaning all cnns would be correct with their TOP1 prediction).Since all approaches performed equally bad there is no meaning in presenting this specifically for each cnn. \nThis leads to the conclusion, that all of the three cnns perform espacially badly portraits of our dataset, therefore the hypothesis is accepted. \nBased on the fact that all of the three approaches are trained on the ImageNet dataset we consider that there are not enough pictures and/or fitting labes for portraits in the dataset since all cnns are trained on differnet amounts of pctures but use the same labels/classes. This assumtion could not be veryfied due to the fact that there are over 14 Mio pictures labeld with 20.000 differnet labels. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9447650480807116
      ],
      "excerpt": "FIXED: This isn't the case anymore - all results from the 29.12.2020 are based on the full resolution images \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8924046924410464
      ],
      "excerpt": "* Brute force approach: Resizing to required dimension (Open CV | cv2.resize) within the preprocessing for the specific cnn-approach \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Application of Deep neural Networks on high resolution images",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/asad-62/IVP-DNN/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "(tbd): If we compare our ground truth with the classification results of the three algorithms the meaning of the gt labels and the classification labels often match, but the wording is not identically\n * If we would automate the checkup based on the current gt labels, there would be a very small amount of correct classifications due to the differt wordings\n * But: if you take a glace at the image and the according classification results, you would eventually count it as a right classification result\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 12 Dec 2021 16:38:43 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/asad-62/IVP-DNN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "asad-62/IVP-DNN",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8306011742603244
      ],
      "excerpt": "<br>The most likely classification is acceptable for the picture -> both get a 1<br> \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8506837082833079
      ],
      "excerpt": "custom width x height (450 x 300) | rotate and flip option: keep original | output setting Retain the original format~~<br> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/asad-62/IVP-DNN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "IVP Project 2 on image classificaton",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "IVP-DNN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "asad-62",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/asad-62/IVP-DNN/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 12 Dec 2021 16:38:43 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "|     Image    | Current accepted results (based on gt)                | TOP-5 results from NASNetLarge                                                             |\n|:------------:|-------------------------------------------------------|--------------------------------------------------------------------------------------------|\n| ![](https://drive.google.com/uc?export=view&id=14J8Lir-uKsqtujJF7GbJHduqPBLA_2dU)0AKZCRZA.png <br>| train, Train, industry, railway, Railway, sky, sunset | 'freight_car', 'electric_locomotive', 'passenger_car', 'trailer_truck', 'steam_locomotive' |\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "**NasNet Large**\n- [x] Brute force approach: finished (@Alex) \n  * Code https://github.com/asad-62/IVP-DNN/blob/main/full-res-nas-net_alex_291220.py \n  * Results https://github.com/asad-62/IVP-DNN/blob/main/results_29-12_nasnet-large.csv \n- ~~[ ] PCA approach: doing until 03.01.2021 (@Asad, @Abhinav, @Muhammad)~~\n\n**EfficientNetB7**\n- [X] Brute force approach: finished (@Alex)\n  * Code https://github.com/asad-62/IVP-DNN/blob/main/efficient-net_alex_291220.py \n  * Results https://github.com/asad-62/IVP-DNN/blob/main/results_29-12_effnetB7.csv\n- ~~[ ] PCA approach: doing until 03.01.2021 (@Asad, @Abhinav, @Muhammad)~~\n\n**DenseNet 201**\n- [X] Brute force approach: finished (@Alex)\n  * Code https://github.com/asad-62/IVP-DNN/blob/main/dense-net_alex_291220.py \n  * Results https://github.com/asad-62/IVP-DNN/blob/main/results_29-12_densenet.csv \n- ~~[ ] PCA approach: doing until 03.01.2021 (@Asad, @Abhinav, @Muhammad)~~\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1904.03416",
      "https://arxiv.org/abs/2001.09239",
      "https://arxiv.org/abs/1906.00733"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If using this code, parts of it, or developments from it, please cite our reference:\n\nPASE\n```\n@inproceedings{Pascual2019,\n  author={Santiago Pascual and Mirco Ravanelli and Joan Serr\u00e0 and Antonio Bonafonte and Yoshua Bengio},\n  title={{Learning Problem-Agnostic Speech Representations from Multiple Self-Supervised Tasks}},\n  year=2019,\n  booktitle={Proc. of the Conf. of the Int. Speech Communication Association (INTERSPEECH)},\n  pages={161--165},\n  url={http://dx.doi.org/10.21437/Interspeech.2019-2605}\n}\n```\n\nPASE+\n```\n@article{Ravanelli2020,\n  title={{Multi-task self-supervised learning for Robust Speech Recognition}},\n  author={Mirco Ravanelli and Jianyuan Zhong and Santiago Pascual and Pawel Swietojanski and Joao Monteiro and Jan Trmal and Yoshua Bengio},\n  journal={ArXiv:2001.09239},\n  year={2020}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{Ravanelli2020,\n  title={{Multi-task self-supervised learning for Robust Speech Recognition}},\n  author={Mirco Ravanelli and Jianyuan Zhong and Santiago Pascual and Pawel Swietojanski and Joao Monteiro and Jan Trmal and Yoshua Bengio},\n  journal={ArXiv:2001.09239},\n  year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{Pascual2019,\n  author={Santiago Pascual and Mirco Ravanelli and Joan Serr\u00e0 and Antonio Bonafonte and Yoshua Bengio},\n  title={{Learning Problem-Agnostic Speech Representations from Multiple Self-Supervised Tasks}},\n  year=2019,\n  booktitle={Proc. of the Conf. of the Int. Speech Communication Association (INTERSPEECH)},\n  pages={161--165},\n  url={http://dx.doi.org/10.21437/Interspeech.2019-2605}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/santi-pdp/pase",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-11-14T16:20:46Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-05T20:02:58Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8873728165887176
      ],
      "excerpt": "The encoder can be inserted in any PyTorch model and fine-tuned, just like any \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156743398144345
      ],
      "excerpt": "An example of each of these files can be found in the data/ folder of the repo. Build them based on your data files. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8635642944411375
      ],
      "excerpt": "however, are not used during training for this is an unsupervised framework. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "    --train_scp data/LibriSpeech/libri_tr.scp --test_scp data/LibriSpeech/libri_te.scp \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.807159785322644
      ],
      "excerpt": "The make_trainset_statistics.py script will load a certain amount of training batches with the config file we just generated, and will compute the normalization statistics for the workers to work properly in the self-supervised training. For PASE v0.1 we use this script as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740200411025592
      ],
      "excerpt": "the workers that will be active, and the statistics are specific to the workers. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9675731917420453,
        0.975382267481326
      ],
      "excerpt": "TensorboardX is used during training to dump stats information (stored in save_path folder, together with the model checkpoints). The learning rates min_lr and fe_lr control the worker learning rates and the encoder learning rates respectively. The lrdec_step and lrdecay params control \nthe learning rate decay factor and the periodic step at which it is applied, for all components (workers and PASE). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "           --min_lr 0.0005 --fe_lr 0.001 --data_root data/LibriSpeech/wavs/ \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9783753324201218,
        0.9860044483900683,
        0.975018117642444
      ],
      "excerpt": "Note that the --lr_mode allows to choose a different learning rate scheduler. In the poly case, a polynomial scheduler updates the LR to reach zero in the end of the programmed epochs.  \nThe --dtrans_cfg flag controls the pointer to the configuration of data augmentation distortions in the form of additive noises, reverberations, etc. \nThe configuration for the distortions (supplied with the --dtrans_cfg argument) allows to control the probability of a distortion being active for a sample in the batch. Hence, distortions are applied on the fly and independently, although with a hard-coded order as programmed in file pase/transforms.py (i.e. Reverb happens before Additive, etc.). Note that there are possible distortions: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.828943390407916,
        0.9456929496622806
      ],
      "excerpt": "Amplitude clipping: activated with clip_p &gt; 0. Clips the waveform amplitude on values beyond a specified percentage of the maximum peak (e.g. 0.1value means clamp all values exceeding on absolute amplitude the value 0.1 x max_asbsolute_amplitude). \nWaveform chopping: activated with chop_p &gt; 0. Chops continuous sections of speech by building windows randomly sized following a Gaussian pdf with the values specified as tuples in the chop_factors array. For instance, [0.05, 0.025] means sampling a window of size 0.05 sec on average with 0.025 sec standard deviation. Many Gaussian parameterizations can be supplied to have windows of different sizes on average, which are then sampled uniformly random. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8551518266856809
      ],
      "excerpt": "Frequency band-drop: activated with bandrop_p &gt; 0. Apply random bandpass filters to equalize the spectrogram per bands. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8683316269593523
      ],
      "excerpt": "Each distortion has a set of parameters that can be controlled, like the impulse response files used to emulate reverberation or pointers to the directories where additive noises are found and the SNRs to be applied randomly. The file cfg/distortions/pase+.cfg exemplifies all the possible options to be controlled for the different distortions.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9700257670059812
      ],
      "excerpt": "Links to the data to perform distortions: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Problem Agnostic Speech Encoder",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/santi-pdp/pase/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This repository contains the official implementations of [PASE](https://arxiv.org/abs/1904.03416) and [PASE+](https://arxiv.org/abs/2001.09239). These are speech waveform encoders trained in a self-supervised manner with the so called worker/minion framework. A PASE model can be used as a speech feature extractor or to pre-train an encoder for our desired end-task, like speech classification such as in ASR, seaker recognition, or emotion recognition, or speech generation such as in voice conversion or [TTS](https://arxiv.org/abs/1906.00733).\n\n![pase+](https://user-images.githubusercontent.com/7583502/72657492-42b88f00-39a5-11ea-9ae6-cf96a1e09042.png)\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 82,
      "date": "Mon, 06 Dec 2021 10:40:45 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/santi-pdp/pase/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "santi-pdp/pase",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/santi-pdp/pase/master/make_trainset_statistics.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/downstream_prep/make_vox1.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/best_wer.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/split_data.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/parse_options.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/path.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/decode_dnn.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/cmd.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/local/score_basic.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/local/timit_prepare_dict.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/local/score.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/local/score_phrich.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/local/score_combine.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/local/timit_data_prep.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/local/timit_format_data.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/local/score_wsj.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/local/score_sclite.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/local/nnet/run_dnn.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/local/nnet/run_autoencoder.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/split_data.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/mkgraph.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/fix_data_dir.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/build_const_arpa_lm.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/parse_options.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/rnnlm_compute_scores.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/format_lm_sri.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/validate_data_dir.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/prepare_online_nnet_dist_build.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/subset_data_dir_tr_cv.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/fix_ctm.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/make_phone_bigram_lang.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/prepare_lang.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/reverse_lm_test.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/reverse_lm.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/format_lm.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/show_lattice.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/perturb_data_dir_speed.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/combine_data.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/reduce_data_dir_by_reclist.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/remove_data_links.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/best_wer.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/convert_slf_parallel.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/dict_dir_add_pronprobs.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/reduce_data_dir.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/subset_data_dir.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/ASR/kaldi_decoding_scripts/utils/copy_data_dir.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/spk_id/run_spkid_train_minivox.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/spk_id/run_spkid_test_minivox.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/data/prep/ami_prep.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_QRNN_5reg_r3.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_denseskips_RF6250.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_train_pase_miqvoxceleb_QRNN.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_QRNN_addrev.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_revs_noise.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_resblocks_len20000_train.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/train_adptive.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_QRNN_5reg.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_aspp_train.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/train_mgd.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_2xQRNN_addrev_lnorm_EMB256.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_QRNN_onlymfcc.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/train_attention.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_resblocks_dilated_len20000_train.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_denseskips_revs.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/train_aspp_base.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_voxceleb_aux.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_timit_aux.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_QRNN_addrev_catdense.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_train_pase256.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_train_pase_genhancement_QRNN.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_BLSTM512_all.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_LibriTTS_QRNN_5reg_alldis.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_denseskips.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_auxsup.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_denseskips_distortion6.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_resblocks_train.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_QRNN_addrev_overlapminion.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/train_resnet50.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_resblocks_len32000_train.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/train_dropout.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_alldistortions_GAN.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_TDNN_all.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_alldistortions.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_kaldi_50h_QRNN_addrev_mp.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_libri_swbd_train_100h_QRNN_addrev_catdense.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/train_hyper_volume.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_QRNN_addrev_Zminion.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_dense_gap.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/train_softmax.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_train_50h_QRNN_addrev_zerospeech.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_kaldi_50h_QRNN_addrev.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_libri_ami_ihm_dist.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/train_aspp_res.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_resblocks_len32000_VQ8192_train.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_pase_libri_ami_ihm_sdm.sh",
      "https://raw.githubusercontent.com/santi-pdp/pase/master/template_scripts/run_iemocap_aux.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The self-supervised training stage requires the following components to be specified to the training script:\n\n* data root folder: contains files (or soft links to them) without subfolders in `wav`, `mp3` or any Torchaudio-supported format. \n* trainset statistics file to normalize each worker's output values, computed with the `make_trainset_statistics.py` script.\n* dataset configuration `data_cfg` file: contains pointers to train/valid/test splits, among other info.\n* front-end (encoder) configuration file: `cfg/frontend/PASE+.cfg`\n* workers' configuration file: `cfg/workers/workers+.cfg` \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "This framework can be installed locally by running:\n\n```\npython setup.py install\n```\n\nThis will allow you to import PASE modules from anywhere.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8229812529129525
      ],
      "excerpt": "To make the dataset configuration file the following files have to be provided: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8367142496017438
      ],
      "excerpt": "If you want to use the openSLR RIRs, you should run the following command to include the file pointers into the distortions config file: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8900486270063179
      ],
      "excerpt": "from pase.models.frontend import wf_builder \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8517504191697713
      ],
      "excerpt": "pase.load_pretrained('FE_e199.ckpt', load_last=True, verbose=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8547910652427012,
        0.8615456195987122,
        0.9051115084236886
      ],
      "excerpt": "training files list train_scp: contains a file name per line (without directory names), including .wav/mp3/etc. extension. \ntest files list test_scp: contains a wav file name per line (without directory names), including .wav/mp3/etc. extension. \ndictionary with filename -> integer speaker class (speaker id) correspondence (same filenames as in train/test lists). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9382892056106165
      ],
      "excerpt": "python unsupervised_data_cfg_librispeech.py --data_root data/LibriSpeech/wavs \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8120656752517628
      ],
      "excerpt": "    --libri_dict data/LibriSpeech/libri_dict.npy --cfg_file data/librispeech_data.cfg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9382892056106165,
        0.8156488827627796
      ],
      "excerpt": "python make_trainset_statistics.py --data_root data/LibriSpeech/wavs \\ \n    --data_cfg data/librispeech_data.cfg \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8374797135590173
      ],
      "excerpt": "a smaller amount of training batches with the --max_batches 10 argument for example. The default \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9382892056106165,
        0.8156488827627796
      ],
      "excerpt": "python make_trainset_statistics.py --data_root data/LibriSpeech/wavs \\ \n    --data_cfg data/librispeech_data.cfg \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8964970050676406
      ],
      "excerpt": "python -u train.py --batch_size 32 --epoch 150 --save_path pase_ckpt --num_workers 4 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8156488827627796
      ],
      "excerpt": "    --data_cfg data/librispeech_data.cfg --min_lr 0.0005 --fe_lr 0.0005 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9393034382480304
      ],
      "excerpt": "python -u  train.py --batch_size 16 --epoch 400 --save_path pase+_ckpt \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "           --random_scale True\\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8532348965405163
      ],
      "excerpt": "python data/prep/prepare_openslr_rirs_cfg.py --data_root data/simulated_rirs_16k --out_file cfg/distortions/pase+.cfg --existing_cfg cfg/distortions/pase+.cfg \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/santi-pdp/pase/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Perl",
      "Shell",
      "PHP",
      "C++",
      "Assembly"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Santi DSP\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Problem Agnostic Speech Encoder (PASE)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pase",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "santi-pdp",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/santi-pdp/pase/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* PyTorch 1.0 or higher\n* Torchvision 0.2 or higher\n* To use data augmentation during training (recommended), you must [build codec2 **from source**](https://github.com/drowe67/codec2), then `pip install pycodec2` (because `pycodec2` needs the header files).  You may also need to point `LD_LIBRARY_PATH` at `\\usr\\local\\lib` for python to be able to load `pycodec2` successfully.\n* Install the requirements from `requirements.txt`: `pip install -r requirements.txt`\n\n*NOTE: Edit the cupy-cuda100 requirement in the file if needed depending on your CUDA version. Defaults to 10.0 now*\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "In this section, we show how to use PASE+ for a basic speech recognition experiment using the TIMIT dataset (make sure you have it available). The speech recognition experiments reported in the PASE+ paper use standard HMM-DNN technology. The DNN part is composed of the PASE+ encoder coupled with a simple MLP classifier. For the HMM decoding part, we rely on the kaldi toolkit (make sure you have it installed before running the following example).\n\nTo run a TIMIT experiment, go to the ASR folder and execute the following command:\n\n```\npython run_TIMIT_full_decoding.py $pase_cfg $pase_model $timit_folder $out_folder cfg/MLP_PASE.cfg  cfg/decoder.cfg\n```\n\nwhere $pase_cfg is the path containing the PASE config file (e.g, ../cfg/frontend/PASE+.cfg) and $pase_model contains the path to the PASE weights (e.g,  FE_e199.ckpt).\n\nThe script will train the speech recognition system. Once trained the NN, we run the kaldi decoder to retrieve the final sequence of phones. You can take a look into the Phoneme Error Rate by typing:\n\n```\n./RESULTS\n```\n\nIn our case, we achieved a PER=17.2%. Note that natural variations (normally in the order of \u00b1 0.2%) might happen due to different initializations.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 388,
      "date": "Mon, 06 Dec 2021 10:40:45 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "waveform-analysis",
      "pytorch",
      "unsupervised-learning",
      "multi-task-learning",
      "speech-processing",
      "self-supervised-learning"
    ],
    "technique": "GitHub API"
  }
}
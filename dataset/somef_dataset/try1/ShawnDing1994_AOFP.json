{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2105.01883",
      "https://arxiv.org/abs/2101.03697",
      "https://arxiv.org/abs/2007.03260",
      "https://arxiv.org/abs/2103.13425"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{ding2019approximated,\ntitle={Approximated Oracle Filter Pruning for Destructive CNN Width Optimization},\nauthor={Ding, Xiaohan and Ding, Guiguang and Guo, Yuchen and Han, Jungong and Yan, Chenggang},\nbooktitle={International Conference on Machine Learning},\npages={1607--1616},\nyear={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9997475499114307,
        0.9999774139351684
      ],
      "excerpt": "author={Ding, Xiaohan and Ding, Guiguang and Guo, Yuchen and Han, Jungong and Yan, Chenggang}, \nbooktitle={International Conference on Machine Learning}, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9437368638871684
      ],
      "excerpt": "1. Reproduce 65% pruning ratio of VGG on CIFAR-10. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DingXiaoH/AOFP",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "dxh17@mails.tsinghua.edu.cn\n\nGoogle Scholar Profile: https://scholar.google.com/citations?user=CIjw0KoAAAAJ&hl=en\n\nMy open-sourced papers and repos: \n\nThe **Structural Re-parameterization Universe**:\n\n1. (preprint, 2021) **A powerful MLP-style CNN building block**\\\n[RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition](https://arxiv.org/abs/2105.01883)\\\n[code](https://github.com/DingXiaoH/RepMLP).\n\n2. (CVPR 2021) **A super simple and powerful VGG-style ConvNet architecture**. Up to **83.55%** ImageNet top-1 accuracy!\\\n[RepVGG: Making VGG-style ConvNets Great Again](https://arxiv.org/abs/2101.03697)\\\n[code](https://github.com/DingXiaoH/RepVGG).\n\n3. (preprint, 2020) **State-of-the-art** channel pruning\\\n[Lossless CNN Channel Pruning via Decoupling Remembering and Forgetting](https://arxiv.org/abs/2007.03260)\\\n[code](https://github.com/DingXiaoH/ResRep).\n\n4. ACB (ICCV 2019) is a CNN component without any inference-time costs. The first work of our Structural Re-parameterization Universe.\\\n[ACNet: Strengthening the Kernel Skeletons for Powerful CNN via Asymmetric Convolution Blocks](http://openaccess.thecvf.com/content_ICCV_2019/papers/Ding_ACNet_Strengthening_the_Kernel_Skeletons_for_Powerful_CNN_via_Asymmetric_ICCV_2019_paper.pdf).\\\n[code](https://github.com/DingXiaoH/ACNet). \n\n5. DBB (CVPR 2021) is a CNN component with higher performance than ACB and still no inference-time costs. Sometimes I call it ACNet v2 because \"DBB\" is 2 bits larger than \"ACB\" in ASCII (lol).\\\n[Diverse Branch Block: Building a Convolution as an Inception-like Unit](https://arxiv.org/abs/2103.13425)\\\n[code](https://github.com/DingXiaoH/DiverseBranchBlock).\n\n**Model compression and acceleration**:\n\n1. (CVPR 2019) Channel pruning: [Centripetal SGD for Pruning Very Deep Convolutional Networks with Complicated Structure](http://openaccess.thecvf.com/content_CVPR_2019/html/Ding_Centripetal_SGD_for_Pruning_Very_Deep_Convolutional_Networks_With_Complicated_CVPR_2019_paper.html)\\\n[code](https://github.com/DingXiaoH/Centripetal-SGD)\n\n2. (ICML 2019) Channel pruning: [Approximated Oracle Filter Pruning for Destructive CNN Width Optimization](http://proceedings.mlr.press/v97/ding19a.html)\\\n[code](https://github.com/DingXiaoH/AOFP)\n\n3. (NeurIPS 2019) Unstructured pruning: [Global Sparse Momentum SGD for Pruning Very Deep Neural Networks](http://papers.nips.cc/paper/8867-global-sparse-momentum-sgd-for-pruning-very-deep-neural-networks.pdf)\\\n[code](https://github.com/DingXiaoH/GSM-SGD)\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-03T06:24:50Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-16T03:38:42Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "It is not easy to design and run Convolutional Neural Networks (CNNs) due to: 1) finding the optimal number of filters (i.e., the width) at each layer is tricky, given an architecture; and 2) the computational intensity of CNNs impedes the deployment on computationally limited devices. Oracle Pruning is designed to remove the unimportant filters from a well-trained CNN, which estimates the filters\u2019 importance by ablating them in turn and evaluating the model, thus delivers high accuracy but suffers from intolerable time complexity, and requires a given resulting width but cannot automatically find it. To address these problems, we propose Approximated Oracle Filter Pruning (AOFP), which keeps searching for the least important filters in a binary search manner, makes pruning attempts by masking out filters randomly, accumulates the resulting errors, and finetunes the model via a multi-path framework. As AOFP enables simultaneous pruning on multiple layers, we can prune an existing very deep CNN with acceptable time cost, negligible accuracy drop, and no heuristic knowledge, or re-design a model which exerts higher accuracy and faster inference.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8086702776004491,
        0.972234428870975,
        0.9577909119847807
      ],
      "excerpt": "UPDATE: pytorch implementation released. But I am not sure whether it works with multi-processing distributed data parallel. I only tested with a single GPU and multi-GPU data parallel. The Tensorflow version still works, but I would not suggest you read it. \nThis repository contains the codes for the following ICML-2019 paper  \nApproximated Oracle Filter Pruning for Destructive CNN Width Optimization. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490286388278456
      ],
      "excerpt": "2. Reproduce 50% pruning ratio of ResNet-56 on CIFAR-10. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9813688349176403
      ],
      "excerpt": "2. Our method does not rely on any new or deprecated features of any libraries, so there is no need to make an identical environment. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8782602137350566
      ],
      "excerpt": "Show the name and shape of weights in the pruned model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8782602137350566
      ],
      "excerpt": "Show the name and shape of weights in the pruned model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Codes of Approximated Oracle Filter Pruning",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ShawnDing1994/AOFP/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Sun, 12 Dec 2021 17:50:19 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/DingXiaoH/AOFP/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "DingXiaoH/AOFP",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8405489669108047
      ],
      "excerpt": "1. We used torch==1.3.0, torchvision==0.4.1, CUDA==10.2, NVIDIA driver version==440.82, tensorboard==1.11.0 on a machine with 2080Ti GPUs.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9459246068628353
      ],
      "excerpt": "3. If you get any errors regarding tensorboard or tensorflow, you may simply delete the code related to tensorboard or SummaryWriter. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python train_base_model.py -a vc \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091,
        0.8235779579190644,
        0.8099194818651142
      ],
      "excerpt": "python aofp/do_aofp.py -a vc \nShow the name and shape of weights in the pruned model. \npython display_hdf5.py aofp_models/vc_train/finish_pruned.hdf5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python train_base_model.py -a src56 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/DingXiaoH/AOFP/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Ding Xiaohan\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Approximated Oracle Filter Pruning for Destructive CNN Width Optimization",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "AOFP",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "DingXiaoH",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DingXiaoH/AOFP/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 26,
      "date": "Sun, 12 Dec 2021 17:50:19 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1511.05493 (2015)). This implementation follows the framework of\n[JamesChuanggg/ggnn.pytorch](https://github.com/JamesChuanggg/ggnn.pytorch). The main difference is that my implemantation are more suitable for graph datasets with tremendous edge types such as Knowledge Graphs as it's more memory-efficient. Note that, **most other implementations you can find are designed for datasets with only several edge types, such as [bAbI dataset](https://github.com/facebook/bAbI-tasks).**\n\nThough our scenario is using GGNN to approximate the ABox consistency checking problem in *OWL2 EL*, where each ABox sample can be deemed as a small directed graph and thus the consistency checking can be modeled as a graph-level binary classification problem, the implementation is quite generic.\n\n## Requirements:\nPython 3.6 <br>\nPyTorch >=0.4 <br>\n\n## Usage:\n- For the input json data format:<br>\neach sample has the format as follows,<br>\n**{'target': label of sample, <br>\n'graph': all edges in the graph, each edge is represented as a triple: (source_id, edge_id, target_id), <br>\n'node_features': task-specific innitial annotation for each node in the graph <br>\n"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9645330537585307
      ],
      "excerpt": "This is a Pytorch implementantion of Gated Graph Neural Network (Li, Yujia, et al. \"Gated graph sequence neural networks.\" arXiv preprint arXiv:1511.05493 (2015)). This implementation follows the framework of \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/entslscheia/GGNN_Reasoning",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-10-14T17:53:16Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-13T02:50:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "PyTorch implementation for Graph Gated Neural Network (for Knowledge Graphs)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/entslscheia/GGNN_Reasoning/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Sun, 05 Dec 2021 18:12:15 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/entslscheia/GGNN_Reasoning/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "entslscheia/GGNN_Reasoning",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/entslscheia/GGNN_Reasoning/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "GGNN_Reasoning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "GGNN_Reasoning",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "entslscheia",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/entslscheia/GGNN_Reasoning/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Python 3.6 <br>\nPyTorch >=0.4 <br>\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 31,
      "date": "Sun, 05 Dec 2021 18:12:15 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "ggnn",
      "knowledge-graph",
      "owl2"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- For the input json data format:<br>\neach sample has the format as follows,<br>\n**{'target': label of sample, <br>\n'graph': all edges in the graph, each edge is represented as a triple: (source_id, edge_id, target_id), <br>\n'node_features': task-specific innitial annotation for each node in the graph <br>\n}**<br>\n(All ids start from 1)\n- To run the code, please use command **`python main.py`**.\n- To run it on GPU, please use command **`python main.py --cuda`**.\n<br>\n(For general use, you should only care about files without a suffix 'plus', as those files are for specific use of ABox reasoning model. Specifically, for GGNN_plus, there is no need for you to specify the initial annotations for each node by yourself, the annotation for all nodes are stored in an embedding layer, which is also learnable during the training process. Experiments demonstrate that GGNN_plus outperforms GGNN on ABox Reasoning in terms of both efficiency and effectiveness.)\n",
      "technique": "Header extraction"
    }
  ]
}
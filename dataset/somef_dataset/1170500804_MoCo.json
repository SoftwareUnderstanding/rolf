{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1911.05722",
      "https://arxiv.org/abs/2003.04297",
      "https://arxiv.org/abs/1706.02677",
      "https://arxiv.org/abs/1911.05722\">MoCo v1</a></td>\n<td align=\"center\">200</td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\">60.6</td>\n<td align=\"center\"><a href=\"https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v1_200ep/moco_v1_200ep_pretrain.pth.tar\">download</a></td>\n<td align=\"center\"><tt>b251726a</tt></td>\n</tr>\n<tr><td align=\"left\"><a href=\"https://arxiv.org/abs/2003.04297\">MoCo v2</a></td>\n<td align=\"center\">200</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">67.7</td>\n<td align=\"center\"><a href=\"https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v2_200ep/moco_v2_200ep_pretrain.pth.tar\">download</a></td>\n<td align=\"center\"><tt>59fd9945</tt></td>\n</tr>\n<tr><td align=\"left\"><a href=\"https://arxiv.org/abs/2003.04297\">MoCo v2</a></td>\n<td align=\"center\">800</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">71.1</td>\n<td align=\"center\"><a href=\"https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v2_800ep/moco_v2_800ep_pretrain.pth.tar\">download</a></td>\n<td align=\"center\"><tt>a04e12f8</tt></td>\n</tr>\n</tbody></table>\n\n\n### Transferring to Object Detection\n\nSee [./detection](detection",
      "https://arxiv.org/abs/2003.04297\">MoCo v2</a></td>\n<td align=\"center\">200</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">67.7</td>\n<td align=\"center\"><a href=\"https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v2_200ep/moco_v2_200ep_pretrain.pth.tar\">download</a></td>\n<td align=\"center\"><tt>59fd9945</tt></td>\n</tr>\n<tr><td align=\"left\"><a href=\"https://arxiv.org/abs/2003.04297\">MoCo v2</a></td>\n<td align=\"center\">800</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">71.1</td>\n<td align=\"center\"><a href=\"https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v2_800ep/moco_v2_800ep_pretrain.pth.tar\">download</a></td>\n<td align=\"center\"><tt>a04e12f8</tt></td>\n</tr>\n</tbody></table>\n\n\n### Transferring to Object Detection\n\nSee [./detection](detection",
      "https://arxiv.org/abs/2003.04297\">MoCo v2</a></td>\n<td align=\"center\">800</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">71.1</td>\n<td align=\"center\"><a href=\"https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v2_800ep/moco_v2_800ep_pretrain.pth.tar\">download</a></td>\n<td align=\"center\"><tt>a04e12f8</tt></td>\n</tr>\n</tbody></table>\n\n\n### Transferring to Object Detection\n\nSee [./detection](detection",
      "https://arxiv.org/abs/1911.05722",
      "https://arxiv.org/abs/2003.04297"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@Article{chen2020mocov2,\n  author  = {Xinlei Chen and Haoqi Fan and Ross Girshick and Kaiming He},\n  title   = {Improved Baselines with Momentum Contrastive Learning},\n  journal = {arXiv preprint arXiv:2003.04297},\n  year    = {2020},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@Article{he2019moco,\n  author  = {Kaiming He and Haoqi Fan and Yuxin Wu and Saining Xie and Ross Girshick},\n  title   = {Momentum Contrast for Unsupervised Visual Representation Learning},\n  journal = {arXiv preprint arXiv:1911.05722},\n  year    = {2019},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.999999243611649,
        0.9314964825591278,
        0.9999537354568557,
        0.9664456561658856
      ],
      "excerpt": "  author  = {Xinlei Chen and Haoqi Fan and Ross Girshick and Kaiming He}, \n  title   = {Improved Baselines with Momentum Contrastive Learning}, \n  journal = {arXiv preprint arXiv:2003.04297}, \n  year    = {2020}, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944484218006108
      ],
      "excerpt": "<tr><td align=\"left\"><a href=\"https://arxiv.org/abs/1911.05722\">MoCo v1</a></td> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944484218006108
      ],
      "excerpt": "<tr><td align=\"left\"><a href=\"https://arxiv.org/abs/2003.04297\">MoCo v2</a></td> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944484218006108
      ],
      "excerpt": "<tr><td align=\"left\"><a href=\"https://arxiv.org/abs/2003.04297\">MoCo v2</a></td> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/1170500804/MoCo/master/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/1170500804/MoCo",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to moco\nWe want to make contributing to this project as easy and transparent as\npossible.\nPull Requests\nWe actively welcome your pull requests.\nBut note that this is a research project for reproducing results in a paper,\nwe may not accept PRs adding new features if they do not align with the goal of reproducing\nresults in the paper.\nIf you haven't already, complete the Contributor License Agreement (\"CLA\") before sending a pull\nrequest.\nContributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\nComplete your CLA here: https://code.facebook.com/cla\nIssues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\nFacebook has a bounty program for the safe\ndisclosure of security bugs. In those cases, please go through the process\noutlined on that page and do not file a public issue.\nLicense\nBy contributing to moco, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-13T10:12:56Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-09-13T07:14:45Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9914177443220751,
        0.9832884853030546
      ],
      "excerpt": "This is a PyTorch implementation of the MoCo paper: \nIt also includes the implementation of the MoCo v2 paper: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9081097391580102,
        0.863101167938879
      ],
      "excerpt": "This implementation only supports multi-gpu, DistributedDataParallel training, which is faster and simpler; single-gpu or DataParallel training is not supported. \nTo do unsupervised pre-training of a ResNet-50 model on ImageNet in an 8-gpu machine, run: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8041766945630475,
        0.8603254756847563
      ],
      "excerpt": "This script uses all the default hyper-parameters as described in the MoCo v1 paper. To run MoCo v2, set --mlp --moco-t 0.2 --aug-plus --cos. \nNote: for 4-gpu training, we recommend following the linear lr scaling recipe: --lr 0.015 --batch-size 128 with 4 gpus. We got similar results using this setting. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.867514961508396
      ],
      "excerpt": "Linear classification results on ImageNet using this repo with 8 NVIDIA V100 GPUs : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9690732438995504
      ],
      "excerpt": "Here we run 5 trials (of pre-training and linear classification) and report mean&plusmn;std: the 5 results of MoCo v1 are {60.6, 60.6, 60.7, 60.9, 61.1}, and of MoCo v2 are {67.7, 67.6, 67.4, 67.6, 67.3}. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/1170500804/MoCo/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 12 Dec 2021 01:17:11 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/1170500804/MoCo/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "1170500804/MoCo",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/1170500804/MoCo/master/Untitled.ipynb",
      "https://raw.githubusercontent.com/1170500804/MoCo/master/plot_representations.ipynb",
      "https://raw.githubusercontent.com/1170500804/MoCo/master/.ipynb_checkpoints/plot_representations-checkpoint.ipynb",
      "https://raw.githubusercontent.com/1170500804/MoCo/master/.ipynb_checkpoints/Untitled-checkpoint.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/1170500804/MoCo/master/csail_segmentation_tool/csail_seg/demo_test.sh",
      "https://raw.githubusercontent.com/1170500804/MoCo/master/csail_segmentation_tool/csail_seg/download_ADE20K.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Install PyTorch and ImageNet dataset following the [official PyTorch ImageNet training code](https://github.com/pytorch/examples/tree/master/imagenet).\n\nThis repo aims to be minimal modifications on that code. Check the modifications by:\n```\ndiff main_moco.py <(curl https://raw.githubusercontent.com/pytorch/examples/master/imagenet/main.py)\ndiff main_lincls.py <(curl https://raw.githubusercontent.com/pytorch/examples/master/imagenet/main.py)\n```\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8838924329023797
      ],
      "excerpt": "  --pretrained [your checkpoint path]/checkpoint_0199.pth.tar \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python main_moco.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8172236260213604
      ],
      "excerpt": "  [your imagenet-folder with train and val folders] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python main_lincls.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.836138842011174
      ],
      "excerpt": "  --pretrained [your checkpoint path]/checkpoint_0199.pth.tar \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8172236260213604
      ],
      "excerpt": "  [your imagenet-folder with train and val folders] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8507296131653697
      ],
      "excerpt": "<!-- TABLE HEADER --> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8507296131653697
      ],
      "excerpt": "<!-- TABLE HEADER --> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/1170500804/MoCo/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/1170500804/MoCo/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\n\\nCopyright (c) 2019, MIT CSAIL Computer Vision\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n Redistributions of source code must retain the above copyright notice, this\\n  list of conditions and the following disclaimer.\\n\\n Redistributions in binary form must reproduce the above copyright notice,\\n  this list of conditions and the following disclaimer in the documentation\\n  and/or other materials provided with the distribution.\\n\\n* Neither the name of the copyright holder nor the names of its\\n  contributors may be used to endorse or promote products derived from\\n  this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# MoCo: Momentum Contrast for Unsupervised Visual Representation Learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "MoCo",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "1170500804",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/1170500804/MoCo/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 12 Dec 2021 01:17:11 GMT"
    },
    "technique": "GitHub API"
  }
}
{
    "syntactic": [
        "engine",
        "inference",
        "gpu",
        "small targets"
    ],
    "semantic": [
        "engine",
        "inference",
        "parse trees",
        "probabilistic inference"
    ],
    "union": [
        "inference",
        "gpu",
        "probabilistic inference",
        "small targets",
        "engine",
        "parse trees"
    ],
    "enhanced": [
        "inference engines",
        "program processors",
        "bayesian methods",
        "probability distributions",
        "target drones",
        "target detection",
        "engineering",
        "natural language processing",
        "translation (languages)",
        "syntactics",
        "formal languages"
    ],
    "explanation": {
        "small targets": [
            "small target"
        ],
        "inference": [
            "onnx inference",
            "inference compile",
            "inference option",
            "inference performance",
            "deepstream inference",
            "inference",
            "size inference",
            "cfg inference",
            "inference output",
            "weight inference",
            "inference output inference",
            "output inference",
            "different inference",
            "engine inference",
            "detail inference",
            "pth inference",
            "section inference",
            "inference image",
            "inference load"
        ],
        "gpu": [
            "gpu"
        ],
        "engine": [
            "engine"
        ],
        "probabilistic inference": [
            "onnx inference",
            "inference compile",
            "inference option",
            "inference performance",
            "deepstream inference",
            "inference",
            "size inference",
            "cfg inference",
            "inference output",
            "weight inference",
            "inference output inference",
            "output inference",
            "different inference",
            "engine inference",
            "detail inference",
            "pth inference",
            "section inference",
            "inference image",
            "inference load"
        ],
        "parse trees": [
            "parameter cfg",
            "configure cfg",
            "cfg inference",
            "cfg"
        ],
        "inference engines": [
            "inference compile",
            "inference performance",
            "deepstream inference",
            "inference",
            "size inference",
            "weight inference",
            "different inference",
            "engine inference",
            "detail inference",
            "section inference",
            "inference load",
            "onnx inference",
            "inference option",
            "cfg inference",
            "inference output",
            "inference output inference",
            "output inference",
            "pth inference",
            "inference image"
        ],
        "program processors": [
            "gpu"
        ],
        "bayesian methods": [
            "onnx inference",
            "inference compile",
            "inference option",
            "inference performance",
            "deepstream inference",
            "inference",
            "size inference",
            "cfg inference",
            "inference output",
            "weight inference",
            "inference output inference",
            "output inference",
            "different inference",
            "engine inference",
            "detail inference",
            "pth inference",
            "section inference",
            "inference image",
            "inference load"
        ],
        "probability distributions": [
            "onnx inference",
            "inference compile",
            "inference option",
            "inference performance",
            "deepstream inference",
            "inference",
            "size inference",
            "cfg inference",
            "inference output",
            "weight inference",
            "inference output inference",
            "output inference",
            "different inference",
            "engine inference",
            "detail inference",
            "pth inference",
            "section inference",
            "inference image",
            "inference load"
        ],
        "target drones": [
            "small target"
        ],
        "target detection": [
            "small target"
        ],
        "engineering": [
            "engine"
        ],
        "natural language processing": [
            "parameter cfg",
            "configure cfg",
            "cfg inference",
            "cfg"
        ],
        "translation (languages)": [
            "parameter cfg",
            "configure cfg",
            "cfg inference",
            "cfg"
        ],
        "syntactics": [
            "parameter cfg",
            "configure cfg",
            "cfg inference",
            "cfg"
        ],
        "formal languages": [
            "parameter cfg",
            "configure cfg",
            "cfg inference",
            "cfg"
        ]
    }
}
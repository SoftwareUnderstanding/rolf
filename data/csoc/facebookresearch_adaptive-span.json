{
    "syntactic": [
        "cuda",
        "gpu",
        "data parallel",
        "gpus",
        "cache",
        "computational efficiency"
    ],
    "semantic": [
        "cuda",
        "gpu",
        "data parallel",
        "gpus",
        "cache",
        "gpgpu",
        "data link layer",
        "computational efficiency",
        "random access memory"
    ],
    "union": [
        "cuda",
        "gpu",
        "data parallel",
        "gpus",
        "cache",
        "gpgpu",
        "data link layer",
        "computational efficiency",
        "random access memory"
    ],
    "enhanced": [
        "parallel programming",
        "graphics processing unit",
        "program processors",
        "operating systems",
        "buffer storage",
        "cache memory",
        "storage allocation (computer)",
        "parallel computing",
        "wireless networks",
        "physical layers",
        "network layers",
        "theoretical computer science",
        "random access storage"
    ],
    "explanation": {
        "computational efficiency": [
            "efficiency",
            "efficiency enable",
            "good efficiency",
            "computation time"
        ],
        "cache": [
            "cache"
        ],
        "cuda": [
            "cuda",
            "gpu",
            "gpus"
        ],
        "gpu": [
            "cuda",
            "gpu",
            "gpus"
        ],
        "gpus": [
            "gpu",
            "gpus"
        ],
        "data parallel": [
            "dataparallel"
        ],
        "random access memory": [
            "memory vector",
            "persistent memory",
            "memory split",
            "gpu memory",
            "time memory",
            "memory"
        ],
        "gpgpu": [
            "cuda",
            "gpu",
            "gpus"
        ],
        "data link layer": [
            "attention sublayer",
            "sublayers",
            "sublayer",
            "sublayer follow"
        ],
        "parallel programming": [
            "dataparallel",
            "cuda",
            "gpu",
            "gpus"
        ],
        "graphics processing unit": [
            "cuda",
            "gpu",
            "gpus"
        ],
        "program processors": [
            "cuda",
            "gpu",
            "gpus"
        ],
        "operating systems": [
            "cache"
        ],
        "buffer storage": [
            "cache"
        ],
        "cache memory": [
            "cache"
        ],
        "storage allocation (computer)": [
            "cache"
        ],
        "parallel computing": [
            "cuda",
            "gpu",
            "gpus"
        ],
        "wireless networks": [
            "attention sublayer",
            "sublayers",
            "sublayer",
            "sublayer follow"
        ],
        "physical layers": [
            "attention sublayer",
            "sublayers",
            "sublayer",
            "sublayer follow"
        ],
        "network layers": [
            "attention sublayer",
            "sublayers",
            "sublayer",
            "sublayer follow"
        ],
        "theoretical computer science": [
            "efficiency",
            "efficiency enable",
            "computation time",
            "good efficiency"
        ],
        "random access storage": [
            "memory vector",
            "persistent memory",
            "memory split",
            "gpu memory",
            "time memory",
            "memory"
        ]
    }
}
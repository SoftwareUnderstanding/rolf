{
    "syntactic": [
        "quantization",
        "gpu",
        "object detection",
        "image classification",
        "inference",
        "computer vision",
        "classification methods",
        "engine",
        "cpu",
        "linux"
    ],
    "semantic": [
        "quantization",
        "object detection",
        "image classification",
        "inference",
        "computer vision",
        "probabilistic inference",
        "engine",
        "cpu",
        "linux"
    ],
    "union": [
        "quantization",
        "gpu",
        "object detection",
        "image classification",
        "inference",
        "computer vision",
        "classification methods",
        "probabilistic inference",
        "engine",
        "cpu",
        "linux"
    ],
    "enhanced": [
        "image compression",
        "signal processing",
        "program processors",
        "object recognition",
        "imaging systems",
        "inference engines",
        "computer imaging and vision",
        "computer systems",
        "bayesian methods",
        "probability distributions",
        "engineering",
        "operating systems"
    ],
    "explanation": {
        "image classification": [
            "image classification"
        ],
        "classification methods": [
            "classification task"
        ],
        "computer vision": [
            "computer vision"
        ],
        "object detection": [
            "object detection"
        ],
        "inference": [
            "tensorrt inference",
            "cpp inference",
            "inference paddle",
            "inference",
            "inference doc",
            "inference prediction",
            "inference demo",
            "inference deployment",
            "inference service",
            "variety inference",
            "paddle_inference_en inference",
            "inference time",
            "accuracy inference",
            "prediction inference",
            "lite inference"
        ],
        "cpu": [
            "cpu"
        ],
        "linux": [
            "linux",
            "linux window"
        ],
        "engine": [
            "engine"
        ],
        "quantization": [
            "quantization"
        ],
        "gpu": [
            "cpu",
            "gpu"
        ],
        "probabilistic inference": [
            "inference prediction",
            "tensorrt inference",
            "cpp inference",
            "inference paddle",
            "inference demo",
            "inference deployment",
            "inference service",
            "inference",
            "variety inference",
            "paddle_inference_en inference",
            "inference time",
            "accuracy inference",
            "inference doc",
            "prediction inference",
            "lite inference"
        ],
        "image compression": [
            "quantization"
        ],
        "signal processing": [
            "quantization"
        ],
        "program processors": [
            "gpu"
        ],
        "object recognition": [
            "object detection"
        ],
        "imaging systems": [
            "image classification"
        ],
        "inference engines": [
            "tensorrt inference",
            "cpp inference",
            "inference paddle",
            "inference",
            "inference doc",
            "inference prediction",
            "inference demo",
            "inference deployment",
            "inference service",
            "variety inference",
            "paddle_inference_en inference",
            "inference time",
            "accuracy inference",
            "prediction inference",
            "lite inference"
        ],
        "computer imaging and vision": [
            "computer vision"
        ],
        "computer systems": [
            "classification task"
        ],
        "bayesian methods": [
            "inference prediction",
            "tensorrt inference",
            "cpp inference",
            "inference paddle",
            "inference demo",
            "inference deployment",
            "inference service",
            "inference",
            "variety inference",
            "paddle_inference_en inference",
            "inference time",
            "accuracy inference",
            "inference doc",
            "prediction inference",
            "lite inference"
        ],
        "probability distributions": [
            "inference prediction",
            "tensorrt inference",
            "cpp inference",
            "inference paddle",
            "inference demo",
            "inference deployment",
            "inference service",
            "inference",
            "variety inference",
            "paddle_inference_en inference",
            "inference time",
            "accuracy inference",
            "inference doc",
            "prediction inference",
            "lite inference"
        ],
        "engineering": [
            "engine"
        ],
        "operating systems": [
            "linux",
            "linux window"
        ]
    }
}
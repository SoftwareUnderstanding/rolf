{
    "syntactic": [
        "action spaces",
        "private key",
        "covert communications",
        "cooperative communication",
        "multi-agent",
        "actor critic",
        "reward function",
        "communication"
    ],
    "semantic": [
        "private key",
        "covert communications",
        "cooperative communication",
        "multi-agent",
        "software agents",
        "actor critic",
        "reward function",
        "communication",
        "intelligent agents"
    ],
    "union": [
        "action spaces",
        "private key",
        "covert communications",
        "cooperative communication",
        "multi-agent",
        "software agents",
        "actor critic",
        "reward function",
        "communication",
        "intelligent agents"
    ],
    "enhanced": [
        "reinforcement learning",
        "public key cryptography",
        "steganography",
        "wireless sensor networks",
        "fading channels",
        "multiagent system",
        "markov decision processes"
    ],
    "explanation": {
        "multi-agent": [
            "input multiagent scenario",
            "multiagent render",
            "import multiagent",
            "multiagent core",
            "multiagent scenario",
            "multi agent",
            "input multiagent",
            "multiagent render display",
            "keyboard input multiagent",
            "multiagent scenario folder",
            "screen multiagent",
            "multiagent environment",
            "screen multiagent policy",
            "import multiagent environment",
            "object multiagent environment",
            "object multiagent",
            "scenario multiagent scenario",
            "multiagent policy",
            "multiagent core contain",
            "scenario multiagent",
            "behavior screen multiagent",
            "multiagent"
        ],
        "action spaces": [
            "action space"
        ],
        "actor critic": [
            "actor critic"
        ],
        "reward function": [
            "reward function"
        ],
        "covert communications": [
            "covert communication"
        ],
        "private key": [
            "private key"
        ],
        "cooperative communication": [
            "cooperative communication"
        ],
        "communication": [
            "cooperative communication",
            "covert communication",
            "communication simple_reference",
            "name communication",
            "cooperative communication simple_reference",
            "name name communication",
            "communication"
        ],
        "intelligent agents": [
            "agent agent cover",
            "agent population",
            "goal agent",
            "goal agent agent",
            "agent adversary",
            "good agent",
            "agent agent",
            "landmark agent",
            "collide agent",
            "display agent",
            "agent",
            "agent speaker",
            "color agent",
            "single agent",
            "agent behavior",
            "agent particle",
            "know agent",
            "collective agent",
            "agent actor",
            "hide agent",
            "scenario agent",
            "agent agent listener",
            "simple_reference agent",
            "agent observe",
            "agent cover",
            "agent reward",
            "agent listener",
            "agent landmark",
            "agent split",
            "agent time",
            "agent observation",
            "agent landmark agent",
            "navigation agent",
            "agent obstacle",
            "collide agent agent"
        ],
        "software agents": [
            "agent agent cover",
            "agent population",
            "goal agent",
            "goal agent agent",
            "agent adversary",
            "good agent",
            "agent agent",
            "landmark agent",
            "collide agent",
            "display agent",
            "agent",
            "agent speaker",
            "color agent",
            "single agent",
            "agent behavior",
            "agent particle",
            "know agent",
            "collective agent",
            "agent actor",
            "hide agent",
            "scenario agent",
            "agent agent listener",
            "simple_reference agent",
            "agent observe",
            "agent cover",
            "agent reward",
            "agent listener",
            "agent landmark",
            "agent split",
            "agent time",
            "agent observation",
            "agent landmark agent",
            "navigation agent",
            "agent obstacle",
            "collide agent agent"
        ],
        "reinforcement learning": [
            "reward function",
            "actor critic",
            "action space"
        ],
        "public key cryptography": [
            "private key"
        ],
        "steganography": [
            "covert communication"
        ],
        "wireless sensor networks": [
            "cooperative communication"
        ],
        "fading channels": [
            "cooperative communication"
        ],
        "multiagent system": [
            "goal agent",
            "agent agent",
            "good agent",
            "landmark agent",
            "multiagent environment",
            "collide agent",
            "display agent",
            "agent",
            "object multiagent",
            "agent particle",
            "multiagent policy",
            "collective agent",
            "import multiagent",
            "simple_reference agent",
            "agent observe",
            "agent cover",
            "multi agent",
            "input multiagent",
            "agent split",
            "agent time",
            "agent observation",
            "navigation agent",
            "agent obstacle",
            "collide agent agent",
            "agent agent cover",
            "agent population",
            "goal agent agent",
            "multiagent scenario",
            "agent adversary",
            "keyboard input multiagent",
            "agent speaker",
            "color agent",
            "single agent",
            "agent behavior",
            "scenario multiagent scenario",
            "know agent",
            "agent actor",
            "scenario multiagent",
            "input multiagent scenario",
            "hide agent",
            "scenario agent",
            "multiagent render",
            "agent agent listener",
            "multiagent core",
            "agent reward",
            "agent listener",
            "agent landmark",
            "multiagent render display",
            "multiagent scenario folder",
            "screen multiagent",
            "screen multiagent policy",
            "import multiagent environment",
            "object multiagent environment",
            "agent landmark agent",
            "multiagent core contain",
            "behavior screen multiagent",
            "multiagent"
        ],
        "markov decision processes": [
            "reward function"
        ]
    }
}
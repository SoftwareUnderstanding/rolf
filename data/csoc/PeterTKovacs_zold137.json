{
    "syntactic": [
        "weight information",
        "gpu",
        "object detection",
        "visualization",
        "gpus",
        "inference",
        "convolutional neural networks",
        "utility functions",
        "cpu",
        "detection rates"
    ],
    "semantic": [
        "weight information",
        "gpu",
        "object detection",
        "visualization",
        "gpus",
        "inference",
        "utility functions",
        "probabilistic inference",
        "cpu"
    ],
    "union": [
        "weight information",
        "gpu",
        "object detection",
        "visualization",
        "gpus",
        "inference",
        "convolutional neural networks",
        "utility functions",
        "probabilistic inference",
        "cpu",
        "detection rates"
    ],
    "enhanced": [
        "attribute weight",
        "program processors",
        "object recognition",
        "human computer interaction",
        "cuda",
        "inference engines",
        "neural networks",
        "game theory",
        "bayesian methods",
        "probability distributions",
        "intrusion detection"
    ],
    "explanation": {
        "object detection": [
            "object detection"
        ],
        "detection rates": [
            "detectron accuracy"
        ],
        "utility functions": [
            "utility function"
        ],
        "weight information": [
            "weight information"
        ],
        "visualization": [
            "visualization jupyter",
            "basic visualization",
            "visualization"
        ],
        "convolutional neural networks": [
            "cnn"
        ],
        "gpu": [
            "gpu cpu",
            "gpu",
            "cpu",
            "gpus"
        ],
        "inference": [
            "inference perform inference",
            "inference pipeline",
            "inference line",
            "inference batch",
            "inference perform",
            "cpu inference",
            "support inference",
            "inference",
            "inference cpu",
            "inference notebook",
            "perform inference",
            "maskrcnn_benchmark inference",
            "inference cpu inference",
            "batch inference",
            "inference batch inference",
            "write inference",
            "inference time",
            "gpu inference"
        ],
        "cpu": [
            "cpu"
        ],
        "gpus": [
            "gpu",
            "gpus"
        ],
        "probabilistic inference": [
            "inference perform inference",
            "inference pipeline",
            "inference line",
            "inference batch",
            "inference perform",
            "cpu inference",
            "support inference",
            "inference",
            "inference cpu",
            "inference notebook",
            "perform inference",
            "maskrcnn_benchmark inference",
            "inference cpu inference",
            "batch inference",
            "inference batch inference",
            "write inference",
            "inference time",
            "gpu inference"
        ],
        "attribute weight": [
            "weight information"
        ],
        "program processors": [
            "gpu cpu",
            "cpu",
            "gpu",
            "gpus"
        ],
        "object recognition": [
            "object detection"
        ],
        "human computer interaction": [
            "visualization jupyter",
            "basic visualization",
            "visualization"
        ],
        "cuda": [
            "gpu",
            "gpus"
        ],
        "inference engines": [
            "inference perform inference",
            "inference pipeline",
            "inference line",
            "inference batch",
            "inference perform",
            "cpu inference",
            "support inference",
            "inference",
            "inference cpu",
            "inference notebook",
            "perform inference",
            "maskrcnn_benchmark inference",
            "inference cpu inference",
            "batch inference",
            "inference batch inference",
            "write inference",
            "inference time",
            "gpu inference"
        ],
        "neural networks": [
            "cnn"
        ],
        "game theory": [
            "utility function"
        ],
        "bayesian methods": [
            "inference perform inference",
            "inference pipeline",
            "inference line",
            "inference batch",
            "inference perform",
            "cpu inference",
            "support inference",
            "inference",
            "inference cpu",
            "inference notebook",
            "perform inference",
            "maskrcnn_benchmark inference",
            "inference cpu inference",
            "batch inference",
            "inference batch inference",
            "write inference",
            "inference time",
            "gpu inference"
        ],
        "probability distributions": [
            "inference perform inference",
            "inference pipeline",
            "inference line",
            "inference batch",
            "inference perform",
            "cpu inference",
            "support inference",
            "inference",
            "inference cpu",
            "inference notebook",
            "perform inference",
            "maskrcnn_benchmark inference",
            "inference cpu inference",
            "batch inference",
            "inference batch inference",
            "write inference",
            "inference time",
            "gpu inference"
        ],
        "intrusion detection": [
            "detectron accuracy"
        ]
    }
}
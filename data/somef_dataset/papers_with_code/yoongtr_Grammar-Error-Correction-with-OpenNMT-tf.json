{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1706.03762\n\nUse python 3.7.3 for underthesea compatibility inside notebook\nUse GPU (ONMT-tf will automatically detect GPU and assign jobs",
      "https://arxiv.org/abs/1706.03762.\nhttps://arxiv.org/abs/1706.03762\n\nUse python 3.7.3 for underthesea compatibility inside notebook\nUse GPU (ONMT-tf will automatically detect GPU and assign jobs)\nGPU installation within conda env: `conda create --name tf_gpu tensorflow-gpu`\n\n## 1) Install OpenNMT-tf\n`pip3 install OpenNMT-tf`\n\n## 2) Prepare data / Preprocessing\n`cd preprocess`\n\n* Requirements\n    * underthesea - a VN NLP toolkit:\n    `pip3 install underthesea`\n    * Use Python 3.7 for underthesea. Python 3.8 causes some problems with import\n   \n* Preprocess raw csv files using preprocess_vn.ipynb\n\n* Output files for ONMT: src files are \"wrong\" data, tgt files are \"correct\" data\n    * src-train.txt\n    * src-val.txt\n    * src-test.txt\n    * tgt-train.txt\n    * tgt-val.txt\n    * tgt-test.txt\n    \n* Move all above files to ~/training folder    \n\n\n## 3) Build vocabulary\n* This creates the vocabulary for the model. Build vocabulary from data files by:\n   `onmt-build-vocab --size 10000 --save_vocab src-vocab.txt src-train.txt`\n   `onmt-build-vocab --size 10000 --save_vocab tgt-vocab.txt tgt-train.txt`\n* Alternatively, vocabulary can also be built from external sources, e.g. Wikidump. If data is highly specific on one subject, build from data files for higher accuracy\n* Change vocabulary --size to fit your data size\n\n## 4) Create config data.yml file (in ~/training)\nSee [OpenNMT parameters documentation](https://opennmt.net/OpenNMT-tf/configuration.html) for parameters tuning\n\n## 5) Train model\n` cd training`\n* Parameters\n    * To specify which GPU to run: CUDA_VISIBLE_DEVICES=gpu_id_1,gpu_id_2\n    * To choose number of GPUs to train (batches are processed in parralel): --num_gpus no_of_gpus\n\n* Specific GPU `CUDA_VISIBLE_DEVICES=1 onmt-main --model_type Transformer --config config.yml --auto_config train --with_eval` \n* Multiple GPU `CUDA_VISIBLE_DEVICES=1,2 onmt-main --model_type Transformer --config config.yml --auto_config train --with_eval --num_gpus 2`\n\n* Run on CPU `onmt-main --model_type Transformer --config config.yml --auto_config train --with_eval`\n\nTrack logs: `tensorboard --logdir=\".\"`\n\nCUDA_VISIBLE_DEVICES for specifying the GPU tf will see\n\n## 6) Translate\n`CUDA_VISIBLE_DEVICES=1,2 onmt-main --config config.yml --auto_config infer --features_file src-test.txt --predictions_file predictions.txt`\n\nPredictions are saved inside predictions.txt (change file name accordingly)\n\n## 7) Evaluate with BLEU score\nMove predictions.txt and tgt-test.txt to smooth_Bleu folder\n\n`cd ~/smooth_Bleu`\n`python3 bleu.py -r tgt-test.txt -t predictions.txt`\n\nOR can include BLEU in YAML file (TBC)"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9999779563119544
      ],
      "excerpt": "Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. arXiv 2017. arXiv preprint arXiv:1706.03762. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yoongtr/Grammar-Error-Correction-with-OpenNMT-tf",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-18T03:36:42Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-09-09T15:36:43Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9116796301418879
      ],
      "excerpt": "Grammar Error Correction with OpenNMT-tf using Neural Machine Translation and Transformer model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.824620783807313
      ],
      "excerpt": "This creates the vocabulary for the model. Build vocabulary from data files by: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Grammar Error Correction with OpenNMT-tf using Machine Translation and Transformer model",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yoongtr/Grammar-Error-Correction-with-OpenNMT-tf/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 13:25:54 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yoongtr/Grammar-Error-Correction-with-OpenNMT-tf/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "yoongtr/Grammar-Error-Correction-with-OpenNMT-tf",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/yoongtr/Grammar-Error-Correction-with-OpenNMT-tf/master/preprocess/preprocess_vn.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/yoongtr/Grammar-Error-Correction-with-OpenNMT-tf/master/tools/smooth_Bleu/example.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "`cd preprocess`\n\n* Requirements\n    * underthesea - a VN NLP toolkit:\n    `pip3 install underthesea`\n    * Use Python 3.7 for underthesea. Python 3.8 causes some problems with import\n   \n* Preprocess raw csv files using preprocess_vn.ipynb\n\n* Output files for ONMT: src files are \"wrong\" data, tgt files are \"correct\" data\n    * src-train.txt\n    * src-val.txt\n    * src-test.txt\n    * tgt-train.txt\n    * tgt-val.txt\n    * tgt-test.txt\n    \n* Move all above files to ~/training folder    \n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "`pip3 install OpenNMT-tf`\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8343836112717773,
        0.9966619369720053
      ],
      "excerpt": "Use GPU (ONMT-tf will automatically detect GPU and assign jobs) \nGPU installation within conda env: conda create --name tf_gpu tensorflow-gpu \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8066134127892272
      ],
      "excerpt": "cd training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9093235503599757
      ],
      "excerpt": "    * To specify which GPU to run: CUDA_VISIBLE_DEVICES=gpu_id_1,gpu_id_2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8476846578250907,
        0.8453095554184509,
        0.8643111381026863
      ],
      "excerpt": "Specific GPU CUDA_VISIBLE_DEVICES=1 onmt-main --model_type Transformer --config config.yml --auto_config train --with_eval  \nMultiple GPU CUDA_VISIBLE_DEVICES=1,2 onmt-main --model_type Transformer --config config.yml --auto_config train --with_eval --num_gpus 2 \nRun on CPU onmt-main --model_type Transformer --config config.yml --auto_config train --with_eval \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490952424343148
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES for specifying the GPU tf will see \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd ~/smooth_Bleu \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9254301219241315,
        0.8319171504089027
      ],
      "excerpt": "   onmt-build-vocab --size 10000 --save_vocab src-vocab.txt src-train.txt \n   onmt-build-vocab --size 10000 --save_vocab tgt-vocab.txt tgt-train.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8370917140527849,
        0.8510106662848351,
        0.8388470117618781
      ],
      "excerpt": "Specific GPU CUDA_VISIBLE_DEVICES=1 onmt-main --model_type Transformer --config config.yml --auto_config train --with_eval  \nMultiple GPU CUDA_VISIBLE_DEVICES=1,2 onmt-main --model_type Transformer --config config.yml --auto_config train --with_eval --num_gpus 2 \nRun on CPU onmt-main --model_type Transformer --config config.yml --auto_config train --with_eval \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9043306961413559,
        0.827001753352908,
        0.8366175334961915
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=1,2 onmt-main --config config.yml --auto_config infer --features_file src-test.txt --predictions_file predictions.txt \nPredictions are saved inside predictions.txt (change file name accordingly) \nMove predictions.txt and tgt-test.txt to smooth_Bleu folder \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8852658784292584
      ],
      "excerpt": "python3 bleu.py -r tgt-test.txt -t predictions.txt \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yoongtr/Grammar-Error-Correction-with-OpenNMT-tf/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Grammar-Error-Correction-with-OpenNMT-tf",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Grammar-Error-Correction-with-OpenNMT-tf",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "yoongtr",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yoongtr/Grammar-Error-Correction-with-OpenNMT-tf/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 13:25:54 GMT"
    },
    "technique": "GitHub API"
  }
}
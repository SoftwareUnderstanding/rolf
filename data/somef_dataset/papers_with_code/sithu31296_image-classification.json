{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2108.05894v1\n[mobileformer]: https://arxiv.org/abs/2108.05895v1\n\n[xcit]: https://arxiv.org/abs/2106.09681\n[cswin]: https://arxiv.org/abs/2107.00652v2\n[volo]: https://arxiv.org/abs/2106.13112v1\n[gfnet]: https://arxiv.org/abs/2107.00645\n[pvtv2]: https://arxiv.org/abs/2106.13797\n[shuffle]: https://arxiv.org/abs/2106.03650\n[conformer]: https://arxiv.org/abs/2105.03889v1\n[rest]: https://arxiv.org/abs/2105.13677v3\n\n[cyclemlp]: https://arxiv.org/abs/2107.10224\n[hiremlp]: https://arxiv.org/abs/2108.13341\n[smlp]: https://arxiv.org/abs/2109.05422\n[poolformer]: https://arxiv.org/abs/2111.11418\n[rsb]: https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2108.05895v1\n\n[xcit]: https://arxiv.org/abs/2106.09681\n[cswin]: https://arxiv.org/abs/2107.00652v2\n[volo]: https://arxiv.org/abs/2106.13112v1\n[gfnet]: https://arxiv.org/abs/2107.00645\n[pvtv2]: https://arxiv.org/abs/2106.13797\n[shuffle]: https://arxiv.org/abs/2106.03650\n[conformer]: https://arxiv.org/abs/2105.03889v1\n[rest]: https://arxiv.org/abs/2105.13677v3\n\n[cyclemlp]: https://arxiv.org/abs/2107.10224\n[hiremlp]: https://arxiv.org/abs/2108.13341\n[smlp]: https://arxiv.org/abs/2109.05422\n[poolformer]: https://arxiv.org/abs/2111.11418\n[rsb]: https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2106.09681\n[cswin]: https://arxiv.org/abs/2107.00652v2\n[volo]: https://arxiv.org/abs/2106.13112v1\n[gfnet]: https://arxiv.org/abs/2107.00645\n[pvtv2]: https://arxiv.org/abs/2106.13797\n[shuffle]: https://arxiv.org/abs/2106.03650\n[conformer]: https://arxiv.org/abs/2105.03889v1\n[rest]: https://arxiv.org/abs/2105.13677v3\n\n[cyclemlp]: https://arxiv.org/abs/2107.10224\n[hiremlp]: https://arxiv.org/abs/2108.13341\n[smlp]: https://arxiv.org/abs/2109.05422\n[poolformer]: https://arxiv.org/abs/2111.11418\n[rsb]: https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2107.00652v2\n[volo]: https://arxiv.org/abs/2106.13112v1\n[gfnet]: https://arxiv.org/abs/2107.00645\n[pvtv2]: https://arxiv.org/abs/2106.13797\n[shuffle]: https://arxiv.org/abs/2106.03650\n[conformer]: https://arxiv.org/abs/2105.03889v1\n[rest]: https://arxiv.org/abs/2105.13677v3\n\n[cyclemlp]: https://arxiv.org/abs/2107.10224\n[hiremlp]: https://arxiv.org/abs/2108.13341\n[smlp]: https://arxiv.org/abs/2109.05422\n[poolformer]: https://arxiv.org/abs/2111.11418\n[rsb]: https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2106.13112v1\n[gfnet]: https://arxiv.org/abs/2107.00645\n[pvtv2]: https://arxiv.org/abs/2106.13797\n[shuffle]: https://arxiv.org/abs/2106.03650\n[conformer]: https://arxiv.org/abs/2105.03889v1\n[rest]: https://arxiv.org/abs/2105.13677v3\n\n[cyclemlp]: https://arxiv.org/abs/2107.10224\n[hiremlp]: https://arxiv.org/abs/2108.13341\n[smlp]: https://arxiv.org/abs/2109.05422\n[poolformer]: https://arxiv.org/abs/2111.11418\n[rsb]: https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2107.00645\n[pvtv2]: https://arxiv.org/abs/2106.13797\n[shuffle]: https://arxiv.org/abs/2106.03650\n[conformer]: https://arxiv.org/abs/2105.03889v1\n[rest]: https://arxiv.org/abs/2105.13677v3\n\n[cyclemlp]: https://arxiv.org/abs/2107.10224\n[hiremlp]: https://arxiv.org/abs/2108.13341\n[smlp]: https://arxiv.org/abs/2109.05422\n[poolformer]: https://arxiv.org/abs/2111.11418\n[rsb]: https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2106.13797\n[shuffle]: https://arxiv.org/abs/2106.03650\n[conformer]: https://arxiv.org/abs/2105.03889v1\n[rest]: https://arxiv.org/abs/2105.13677v3\n\n[cyclemlp]: https://arxiv.org/abs/2107.10224\n[hiremlp]: https://arxiv.org/abs/2108.13341\n[smlp]: https://arxiv.org/abs/2109.05422\n[poolformer]: https://arxiv.org/abs/2111.11418\n[rsb]: https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2106.03650\n[conformer]: https://arxiv.org/abs/2105.03889v1\n[rest]: https://arxiv.org/abs/2105.13677v3\n\n[cyclemlp]: https://arxiv.org/abs/2107.10224\n[hiremlp]: https://arxiv.org/abs/2108.13341\n[smlp]: https://arxiv.org/abs/2109.05422\n[poolformer]: https://arxiv.org/abs/2111.11418\n[rsb]: https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2105.03889v1\n[rest]: https://arxiv.org/abs/2105.13677v3\n\n[cyclemlp]: https://arxiv.org/abs/2107.10224\n[hiremlp]: https://arxiv.org/abs/2108.13341\n[smlp]: https://arxiv.org/abs/2109.05422\n[poolformer]: https://arxiv.org/abs/2111.11418\n[rsb]: https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2105.13677v3\n\n[cyclemlp]: https://arxiv.org/abs/2107.10224\n[hiremlp]: https://arxiv.org/abs/2108.13341\n[smlp]: https://arxiv.org/abs/2109.05422\n[poolformer]: https://arxiv.org/abs/2111.11418\n[rsb]: https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2107.10224\n[hiremlp]: https://arxiv.org/abs/2108.13341\n[smlp]: https://arxiv.org/abs/2109.05422\n[poolformer]: https://arxiv.org/abs/2111.11418\n[rsb]: https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2108.13341\n[smlp]: https://arxiv.org/abs/2109.05422\n[poolformer]: https://arxiv.org/abs/2111.11418\n[rsb]: https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2109.05422\n[poolformer]: https://arxiv.org/abs/2111.11418\n[rsb]: https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2111.11418\n[rsb]: https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2110.00476\n\nModel | ImageNet-1k Top-1 Acc <br><sup>(%",
      "https://arxiv.org/abs/2105.13677v3",
      "https://arxiv.org/abs/2105.03889",
      "https://arxiv.org/abs/2107.00645",
      "https://arxiv.org/abs/2106.03650"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{huang2021shuffle,\n  title={Shuffle Transformer: Rethinking Spatial Shuffle for Vision Transformer},\n  author={Huang, Zilong and Ben, Youcheng and Luo, Guozhong and Cheng, Pei and Yu, Gang and Fu, Bin},\n  journal={arXiv preprint arXiv:2106.03650},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{rao2021global,\n  title={Global Filter Networks for Image Classification},\n  author={Rao, Yongming and Zhao, Wenliang and Zhu, Zheng and Lu, Jiwen and Zhou, Jie},\n  journal={arXiv preprint arXiv:2107.00645},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{yan2020micronet,\n  title={MicroNet for Efficient Language Modeling}, \n  author={Zhongxia Yan and Hanrui Wang and Demi Guo and Song Han},\n  year={2020},\n  eprint={2005.07877},\n  archivePrefix={arXiv},\n  primaryClass={cs.CL}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{yuan2021volo,\n  title={VOLO: Vision Outlooker for Visual Recognition}, \n  author={Li Yuan and Qibin Hou and Zihang Jiang and Jiashi Feng and Shuicheng Yan},\n  year={2021},\n  eprint={2106.13112},\n  archivePrefix={arXiv},\n  primaryClass={cs.CV}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{elnouby2021xcit,\n  title={XCiT: Cross-Covariance Image Transformers}, \n  author={Alaaeldin El-Nouby and Hugo Touvron and Mathilde Caron and Piotr Bojanowski and Matthijs Douze and Armand Joulin and Ivan Laptev and Natalia Neverova and Gabriel Synnaeve and Jakob Verbeek and Herv\u00e9 Jegou},\n  year={2021},\n  eprint={2106.09681},\n  archivePrefix={arXiv},\n  primaryClass={cs.CV}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{wang2021pvtv2,\n  title={PVTv2: Improved Baselines with Pyramid Vision Transformer}, \n  author={Wenhai Wang and Enze Xie and Xiang Li and Deng-Ping Fan and Kaitao Song and Ding Liang and Tong Lu and Ping Luo and Ling Shao},\n  year={2021},\n  eprint={2106.13797},\n  archivePrefix={arXiv},\n  primaryClass={cs.CV}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{chen2021cyclemlp,\n  title={CycleMLP: A MLP-like Architecture for Dense Prediction}, \n  author={Shoufa Chen and Enze Xie and Chongjian Ge and Ding Liang and Ping Luo},\n  year={2021},\n  eprint={2107.10224},\n  archivePrefix={arXiv},\n  primaryClass={cs.CV}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{dong2021cswin,\n  title={CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows}, \n  author={Xiaoyi Dong and Jianmin Bao and Dongdong Chen and Weiming Zhang and Nenghai Yu and Lu Yuan and Dong Chen and Baining Guo},\n  year={2021},\n  eprint={2107.00652},\n  archivePrefix={arXiv},\n  primaryClass={cs.CV}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{peng2021conformer,\n  title={Conformer: Local Features Coupling Global Representations for Visual Recognition}, \n  author={Zhiliang Peng and Wei Huang and Shanzhi Gu and Lingxi Xie and Yaowei Wang and Jianbin Jiao and Qixiang Ye},\n  journal={arXiv preprint arXiv:2105.03889},\n  year={2021},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{zhql2021ResT,\n  title={ResT: An Efficient Transformer for Visual Recognition},\n  author={Zhang, Qinglong and Yang, Yubin},\n  journal={arXiv preprint arXiv:2105.13677v3},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9085205623341627,
        0.9958156683257673
      ],
      "excerpt": "<p>Intended for easy to use and integrate SOTA image classification models into object detection, semantic segmentation, pose estimation, etc.</p> \n<a href=\"https://colab.research.google.com/github/sithu31296/image-classification/blob/main/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": "PVTv2 | 78.7\\|82.0\\|83.6 | 14\\|25\\|63 | 2\\|4\\|10 | [B1][pvt1]\\|[B2][pvt2]\\|[B4][pvt4] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9725140271112827
      ],
      "excerpt": "CycleMLP | 81.6\\|83.0\\|83.2 | 27\\|52\\|76 | 4\\|10\\|12 | [B2][cycleb2]\\|[B4][cycleb4]\\|[B5][cycleb5] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9251255279142222
      ],
      "excerpt": "Fine-tune on CIFAR-10: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9626356225854676
      ],
      "excerpt": "* https://github.com/facebookresearch/deit \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sithu31296/image-classification",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-02T12:21:53Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T21:24:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8010819131543047
      ],
      "excerpt": "ResNet* | 71.5\\|80.4\\|81.5 | 12\\|26\\|45 | 2\\|4\\|8 | [18][rsb18]\\|[50][rsb50]\\|[101][rsb101] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8073260023188341
      ],
      "excerpt": "Notes: ResNet* is from \"ResNet strikes back\" paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8646673914451429,
        0.8231903519488553
      ],
      "excerpt": "* Image size is 224x224. EfficientNetv2 uses progressive learning (image size from 128 to 380). \n* All models' weights are from official repositories. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9688206919682132
      ],
      "excerpt": "* *PVTv2*, *ResT*, *Conformer*, *XCiT*, *CycleMLP* and *PoolFormer* models work with any image size. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.855770686127011
      ],
      "excerpt": "ResNet         ['18', '34', '50', '101', '152'] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8389635617850826
      ],
      "excerpt": "  <summary><strong>Evaluate</strong> (click to expand)</summary> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8609641945659183
      ],
      "excerpt": "  <summary><strong>Fine-tune</strong> (click to expand)</summary> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "  <summary><strong>Citations</strong> (click to expand)</summary> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A collection of SOTA Image Classification Models in PyTorch",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sithu31296/image-classification/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Sun, 26 Dec 2021 03:20:08 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sithu31296/image-classification/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "sithu31296/image-classification",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/sithu31296/image-classification/main/tutorial.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8106611974769504,
        0.8837680365796365
      ],
      "excerpt": "  <summary><strong>Requirements</strong> (click to expand)</summary> \n* python >= 3.6 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9966179045153072
      ],
      "excerpt": "Other requirements can be installed with `pip install -r requirements.txt`. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.926447552395659,
        0.825406370458964
      ],
      "excerpt": "* https://github.com/rwightman/pytorch-image-models \n* https://github.com/facebookresearch/deit \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8155482912538736
      ],
      "excerpt": "ResNet* | 71.5\\|80.4\\|81.5 | 12\\|26\\|45 | 2\\|4\\|8 | [18][rsb18]\\|[50][rsb50]\\|[101][rsb101] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665729780878333
      ],
      "excerpt": "$ python tools/show.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8315438234156509
      ],
      "excerpt": "Model Names    Model Variants \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8147319190831867
      ],
      "excerpt": "VOLO           ['D1', 'D2', 'D3', 'D4'] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8715490809929645
      ],
      "excerpt": "* Change `MODEL` parameters and `TEST` parameters in config file [here](./configs/test.yaml). And run the the following command. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9075535594828029
      ],
      "excerpt": "$ python tools/infer.py --cfg configs/test.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.920880702979217
      ],
      "excerpt": "File: assests\\dog.jpg >>>>> Golden retriever \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9205850607764682
      ],
      "excerpt": "$ python tools/train.py --cfg configs/train.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030928414077922
      ],
      "excerpt": "$ python tools/val.py --cfg configs/train.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8664470370910917
      ],
      "excerpt": "$ python tools/finetune.py --cfg configs/finetune.yaml \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sithu31296/image-classification/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 sithu3\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "<div align=\"center\">SOTA Image Classification Models in PyTorch</div>",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "image-classification",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "sithu31296",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sithu31296/image-classification/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "sithu31296",
        "body": "add MicroNet model\r\nbug fixes",
        "dateCreated": "2021-09-12T06:50:31Z",
        "datePublished": "2021-09-12T06:52:02Z",
        "html_url": "https://github.com/sithu31296/image-classification/releases/tag/v0.2.0",
        "name": "v0.2.0",
        "tag_name": "v0.2.0",
        "tarball_url": "https://api.github.com/repos/sithu31296/image-classification/tarball/v0.2.0",
        "url": "https://api.github.com/repos/sithu31296/image-classification/releases/49404510",
        "zipball_url": "https://api.github.com/repos/sithu31296/image-classification/zipball/v0.2.0"
      },
      {
        "authorType": "User",
        "author_name": "sithu31296",
        "body": "Add the following models and weights:\r\n\r\n- Swin\r\n- PVTv2\r\n- GFNet\r\n- CSWin\r\n- CrossFormer\r\n- CycleMLP",
        "dateCreated": "2021-08-05T17:13:29Z",
        "datePublished": "2021-08-05T17:18:34Z",
        "html_url": "https://github.com/sithu31296/image-classification/releases/tag/v0.1.0",
        "name": "Updated models and weights",
        "tag_name": "v0.1.0",
        "tarball_url": "https://api.github.com/repos/sithu31296/image-classification/tarball/v0.1.0",
        "url": "https://api.github.com/repos/sithu31296/image-classification/releases/47378853",
        "zipball_url": "https://api.github.com/repos/sithu31296/image-classification/zipball/v0.1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 46,
      "date": "Sun, 26 Dec 2021 03:20:08 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "image-classification",
      "pytorch",
      "vision-transformer",
      "mlp-mixer",
      "sota",
      "object-recognition",
      "imagenet",
      "cnn",
      "transformer",
      "mlp",
      "deep-learning",
      "quantization"
    ],
    "technique": "GitHub API"
  }
}
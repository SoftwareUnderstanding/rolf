{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Python setup: https://docs.python.org/3/distutils/setupscript.html\n- Tensorflow: https://www.tensorflow.org\n- Deep learning course: https://www.coursera.org/specializations/deep-learning\n- Intuitive explonation of ConvNets: https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/\n- ConvNet CIFAR-10: https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html\n- Word embeddings: https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/\n- Deep Residual Networks: https://github.com/KaimingHe/deep-residual-networks\n- YOLO original paper: https://arxiv.org/pdf/1506.02640.pdf\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9004669801072086
      ],
      "excerpt": "Logistic regression vs shallow neural networks \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/you-leee/deep-nn-examples",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-03-10T01:05:06Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-07-03T21:43:34Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9450049924465165,
        0.9775226090913627
      ],
      "excerpt": "This repository contains toy examples of shallow and deep neural networks along with convolutional and recurrent neural networks. \nIt also contains a (not optimal) implementation of base neural networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9361355663702746
      ],
      "excerpt": "Plain and simple implementation of linear regression aming to demonstrate how you can approximate data points, that are close to a linear function (in this example y = 2*x + 4). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9987516800551844,
        0.8057676599969951,
        0.9648094524856738
      ],
      "excerpt": "An example on how to learn word embeddings using a neural network. The training data contains text from both Apple Inc. and the apple fruit and the goal is to categorize new text into one of these classes. There is a lot of room for improvement, like getting more training data, filtering stop words better or restricting the vocabulary... Feel free to play around! \nPredicting for sample sentence about the apple fruit:  \n  \"The world crop of apples averages more than 60 million metric tons a year. Of the American crop, more than half is normally used as fresh fruit.\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.977209096666419,
        0.8199402313330064
      ],
      "excerpt": "In this example, the aim is to classify a linearly NOT separable dataset. You can see, how much better you can do with a neural network with 1 hidden layer vs a simply logistic regression model. It also demonstartes the increase of accuracy, when we increase the size of the hidden layer. \nOriginal dataset|  Fit with logistic regression| Fit with different number of layers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8984184288767898
      ],
      "excerpt": "Classic image binary classification problem: cat vs non-cat. Two neural networks are trained for the same number of iterations, but one with 3 hidden layers and the other with only 1. You can observe, that despite, that the simpler model can reach the same train accuracy, on the test set, there is a significant difference. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9864085294082838
      ],
      "excerpt": "A 1 hidden layer neural network is used to classify hand signs to numbers (0-9). It is an example on how to implement a simple model using tensorflow, instead of coding the backpropagation/optimization yourself. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490037945672047
      ],
      "excerpt": "The RESNET50 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9891217819513306
      ],
      "excerpt": "In this example, the famous mnist hand written digit dataset is used to train the ResNet50 network, which uses residual blocks. It is a bit \"overkill\" to use such a big network for this task, but the goal here is to learn a bit about deep residual networks. So what is a residual network? The main idea is, that to \"tweek\" the mathematical formula with an identity function, such as: f(x) + x = f(x) + id(x) = y. Identity connections enable the layers to learn incremental, or residual representations. The layers can start as the identity function and gradually transform to be more complex. This significantly helps deeper networks in the training process, since the gradient signal vanishes with increasing network depth, but the identity connections in ResNets propagate the gradient throughout the model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9049196160169882
      ],
      "excerpt": "   YOLO is a new approach of object detection with a great performance on real-time. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. The classic model can process 45 frames per second, that's why it's popularity. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This repository contains some toy-examples of neural networks and deep neural networks.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/you-leee/deep-nn-examples/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 19:05:25 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/you-leee/deep-nn-examples/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "you-leee/deep-nn-examples",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/you-leee/deep-nn-examples/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "First set up the environment by running the setup.py file for installation. It will download all the necessary packages to run the examples.\n\n```\n> python setup.py install\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8000503727277236
      ],
      "excerpt": "Prediction: 0.8536878228187561, actual value: 1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.801384181420618,
        0.8452590353958382
      ],
      "excerpt": "2 layer model: train accuracy: 100 % test accuracy: 70 % \n4 layer model: train accuracy: 100.0 % test accuracy: 80.0 % \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8838148168639296
      ],
      "excerpt": "Accurately classified examples| Misclassified examples \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/you-leee/deep-nn-examples/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "deep-nn-examples",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "deep-nn-examples",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "you-leee",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/you-leee/deep-nn-examples/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n> python NeuralNetworks/logisticregression_vs_shallownn.py\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Tue, 28 Dec 2021 19:05:25 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "neural-network",
      "deep-learning",
      "deep-neural-networks",
      "examples",
      "python",
      "classification",
      "face-recognition",
      "image-classification",
      "regression",
      "resnet",
      "resnet-50",
      "convolutional-neural-networks"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can either run the examples from command line or from an IDE. The below examples are for command line usage.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n> python NeuralNetworks/logisticregression_vs_shallownn.py\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "This is the list of finished examples.. others will follow!\n\n",
      "technique": "Header extraction"
    }
  ]
}
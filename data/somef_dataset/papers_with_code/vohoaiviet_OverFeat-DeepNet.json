{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "OverFeat is Copyright NYU 2013. Authors of the present package are Michael Mathieu, Pierre Sermanet, and Yann LeCun.\n\nThe OverFeat system is by Pierre Sermanet, David Eigen, Xiang Zhang, Michael Mathieu, Rob Fergus, and Yann LeCun.\n\nPlease refer to the LICENSE file in the same directory as the present file for licensing information.\n\nIf you use OverFeat in your research, please cite the following paper: \n\n\"OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks\", Pierre Sermanet, David Eigen, Xiang Zhang, Michael Mathieu, Rob Fergus, Yann LeCun http://arxiv.org/abs/1312.6229\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8787326103438625
      ],
      "excerpt": "bin/linux_64/overfeat [-d &lt;path_to_weights&gt;] [-l] -L 12 image1.png \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9146894306581513
      ],
      "excerpt": "bin/linux_64/overfeat -n 3 samples/bee.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "bin/linux_64/overfeat -f -l samples/pliers.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "./bin/linux_64/overfeat_batch -i samples -o samples_features \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "bin/linux_64/webcam -l \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vohoaiviet/OverFeat-DeepNet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-06-23T10:18:41Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-06-23T10:19:18Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9007515537384051
      ],
      "excerpt": "OverFeat is a Convolutional Network-based image classifier and feature extractor. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8072578181796363
      ],
      "excerpt": "This package allows researchers to use OverFeat to recognize images and extract features. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9517672831942675
      ],
      "excerpt": "OverFeat was trained with the Torch7 package ( http://www.torch.ch ). The OverFeat package provides tools to run the network in a standalone fashion. The training code is not distributed at this time. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8083259602907485
      ],
      "excerpt": "The software we provide should be able to locate it automatically. In case \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8185962170641949
      ],
      "excerpt": "In order to get the top <N> (by default, <N>=5) classes from a number of images : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.851317493492303
      ],
      "excerpt": "Please note that to get the classes from an image, the image size should be 231x231. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.967334594690504
      ],
      "excerpt": "equal to 231x231 for the small network, and 221x221 for the large network . \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9016626077100697
      ],
      "excerpt": "In order to extract the features instead of classifying, use -f option. For instance : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9387680494364379
      ],
      "excerpt": "It is compatible with option -p. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8390150323143822,
        0.9416237888210325,
        0.9037578651730315,
        0.965425317536802
      ],
      "excerpt": "and 22 for the large one. \nIt writes the features on stdout as a sequence. Each feature starts with three integers \nseparated by spaces, the first is the number of features (n), \nthe second is the number of rows (h) and the last is the number of columns (w). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222506645661399,
        0.8873787371571461,
        0.9584132575328838
      ],
      "excerpt": "The output is going to be a 3D tensor. The first dimension correspond to the features, \nwhile dimensions 2 and 3 are spatial (y and x respectively). \nThe spatial dimension is reduced at each layer, and with the default network, using \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.855918852625231
      ],
      "excerpt": "  - for the small network,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.881589273208355
      ],
      "excerpt": "  - for the large network, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8433408787903853,
        0.8659316934203737
      ],
      "excerpt": "localized window in the input. With the small network, the windows are 231x231 \npixels, overlapping so that the i-th window begins at pixel 32i, while for the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8645138828892807
      ],
      "excerpt": "We provide a live classifier based on the webcam. It reads images from the webcam, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8501798338606195
      ],
      "excerpt": "We also provide an easy way to process a whole folder : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8921150968449916
      ],
      "excerpt": "Extract features from samples/pliers.jpg with the large network : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8094333807245149
      ],
      "excerpt": "Extract the features from all files in samples : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9608492652427852
      ],
      "excerpt": "If <N> is positive, it is, as before, the number of top classes to display. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8536052525153685
      ],
      "excerpt": "specifies from which layer the features are obtained \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9886529597572526
      ],
      "excerpt": "<I> corresponds to the size of the network : 0 for small, 1 for large. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9179265893046602,
        0.8428674566983854
      ],
      "excerpt": "The library is written in C++. It consists of one static library named liboverfeat.a . \nThe corresponding header is overfeat.hpp . It uses the low level torch tensor \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8415657822244358,
        0.893446133992083,
        0.8718034241700358
      ],
      "excerpt": "It must also be passed the size of the network (net_idx), which should be 0, \nor 1, respectively for small or large networks. Note that the \nweight file must correspond to the size of the network. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9238694941325601,
        0.9138020362666954
      ],
      "excerpt": "This is the main function. It takes an image stored in a THTensor and runs the network on it. \nIt returns a pointer to a THTensor containing the output of the classifier.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.855918852625231
      ],
      "excerpt": "for the small network : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.881589273208355
      ],
      "excerpt": "for the large network : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.92896787917825
      ],
      "excerpt": "Each pixel of the output corresponds to a 231x231 window on the input for the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8399618842343295,
        0.8339880800112153
      ],
      "excerpt": "output of any layer. For instance, in the default network, layer 16 corresponds to the \nfinal features before the classifier. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8855339949726773
      ],
      "excerpt": "API/torch/README contains more details. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vohoaiviet/OverFeat-DeepNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 12:47:30 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/vohoaiviet/OverFeat-DeepNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "vohoaiviet/OverFeat-DeepNet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Download the archive from http://cilvr.cs.nyu.edu/doku.php?id=software:overfeat:start\n\nExtract the files:\n```\ntar xvf overfeat-vXX.tgz\ncd overfeat\n```\n\nOverfeat uses external weight files. Since these files are large and do not change often, they are not included in the archive.\nWe provide a script to automatically download the weights :\n```\n./download_weights.py\n```\nThe weight files should be in the folder data/default in the overfeat directory.\n\nOverfeat can run without BLAS, however it would be very slow. We *strongly*\nadvice you to install openblas on linux (on MacOS, Accelerate should be available\nwithout any installation). On Ubuntu/Debian you should compile it (it might take\na while, but it is worth it) :\n```\nsudo apt-get install build-essential gcc g++ gfortran git libgfortran3\ncd /tmp\ngit clone https://github.com/xianyi/OpenBLAS.git\ncd OpenBLAS\nmake NO_AFFINITY=1 USE_OPENMP=1\nsudo make install\n```\nFor some reason, on 32 bits Ubuntu, libgfortran doesn't create the correct symlink.\nIf you have issues linking with libgfortran, locate where libgfortran is installed\n(for instance /usr/lib/i386-linux-gnu) and create the correct symlink :\n```\ncd <folder_containing_libgfortran.so.3>\nsudo ln -sf libgfortran.so.3 libgfortran.so\n```\nThe precompiled binaries use BLAS. If you don't want to (or can't, for some reason)\nuse BLAS, you must recompile overfeat.\n\nRUNNING THE PRE-COMPILED BINARIES\n\nPre-compiled binaries are provided for Ubuntu Linux (32 bits and 64 bits) and Mac OS. The pre-requisites are python and imagemagick, which are installed by default on most popular Linux distros.\n\n**Important note:** OverFeat compiled from source on your computer will run faster\nthan the pre-compiled binaries.\n\nExample of image classification, printing the 6 highest-scoring categories:\n```\nbin/YOUR_OS/overfeat -n 6 samples/bee.jpg\n```\nwhere YOUR_OS can be either linux_64, linux_32, or macos.\n\nRunning the webcam demo:\n```\nbin/YOUR_OS/webcam\n```\n\nGPU PRE-COMPILED BINARIES (EXPERIMENTAL)\n\nWe are providing precompiled binaries to run overfeat on GPU. Because the code\nis not released yet, we do not provide the source for now. The GPU release is\nexperimental and for now only runs on linux 64bits. It requires a Nvidia GPU\nwith CUDA architecture >= 2.0 (that covers all recent GPUs from Nvidia).\n\nYou will need openblas to run the GPU binaries.\n\nThe binaries are located in\n```\nbin/linux_64/cuda\n```\nAnd work the same way as the CPU versions. You can include the static library the\nsame way as the CPU version.\n\nCOMPILING FROM SOURCE\n\nInstall dependencies : python, imagemagick, git, gcc, cmake (pkg-config and opencv required for the webcam demo).\nOn Ubuntu/Debian :\n```\napt-get install g++ git python imagemagick cmake\n```\nFor the webcam demo :\n```\napt-get install pkg-config libopencv-dev libopencv-highgui-dev\n```\n\nHere are the instructions to build the OverFeat library and tools:\n\nGo to the src folder :\n```\ncd src\n```\n\nBuild the tensor library (TH), OverFeat and the command-line tools:\n```\nmake all\n```\n\nBuild the webcam demo (OpenCV required) :\n```\nmake cam\n```\n\nOn Mac OS, the default gcc doesn't support OpenMP. We strongly recommend to install\na gcc version with OpenMP support. With MacPort :\n```\nsudo port install gcc48\n```\nWhich will provide g++-mp-48 . If you don't install this version, you will have to\nchange the two corresponding lines in the Makefile.\n\nUPDATING\n\nA git repository is provided with the archive. You can update by typing\n```\ngit pull\n```\nfrom the overfeat directory.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8787222001096117
      ],
      "excerpt": "It can be run with \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8601397503090179
      ],
      "excerpt": "file in the output directory, containing the features,in the same format \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8707142569913876
      ],
      "excerpt": "bin/linux_64/overfeat -n 3 samples/bee.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8707142569913876
      ],
      "excerpt": "bin/linux_64/overfeat -f -l samples/pliers.jpg \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/vohoaiviet/OverFeat-DeepNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "C",
      "C++",
      "Python",
      "CMake",
      "Makefile",
      "Lua"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/vohoaiviet/OverFeat-DeepNet/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright \\xc2\\xa9 2013 New York University.\\n\\nAll Rights Reserved. A license to use and copy this software and its documentation solely for your internal \\nresearch and evaluation  purposes, without fee and without a signed licensing agreement, is hereby granted \\nupon your download of the software, through which you agree to the following: \\n1)  the above copyright notice, this paragraph and the following three paragraphs will prominently appear \\nin all internal copies and modifications; \\n2)  no rights to sublicense or further distribute this software are granted; \\n3) no rights to modify this software are granted; and \\n4) no rights to assign this license are granted.   \\n\\nPlease Contact The Office of Industrial Liaison, \\nNew York University, One Park Avenue, 6th Floor, New York, NY 10016 (212) 263-8178, \\nfor commercial licensing opportunities, or for further distribution, modification or license rights.\\n\\nCreated by Pierre Sermanet, Michael Mathieu, and Yann LeCun. http://cilvr.cs.nyu.edu\\n\\nIN NO EVENT SHALL NYU, OR ITS EMPLOYEES, OFFICERS, AGENTS OR TRUSTEES (\\xe2\\x80\\x9cCOLLECTIVELY \\xe2\\x80\\x9cNYU PARTIES\\xe2\\x80\\x9d) BE LIABLE \\nTO ANY PARTY FOR DIRECT, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES OF ANY KIND , INCLUDING LOST \\nPROFITS, ARISING OUT OF ANY CLAIM RESULTING FROM YOUR USE OF THIS SOFTWARE AND ITS DOCUMENTATION, EVEN IF ANY \\nOF NYU PARTIES HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH CLAIM OR DAMAGE.\\n\\nNYU SPECIFICALLY DISCLAIMS ANY WARRANTIES OF ANY KIND REGARDING THE SOFTWARE, INCLUDING, BUT NOT LIMITED TO, \\nNON-INFRINGEMENT, THE IMPLIED WARRANTIES OF  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, OR THE \\nACCURACY OR USEFULNESS, OR COMPLETENESS OF THE SOFTWARE. THE SOFTWARE AND ACCOMPANYING DOCUMENTATION, IF ANY, \\nPROVIDED HEREUNDER IS PROVIDED COMPLETELY \"AS IS\". REGENTS HAS NO OBLIGATION TO PROVIDE FURTHER DOCUMENTATION, \\nMAINTENANCE, SUPPORT, UPDATES, ENHANCEMENTS, OR MODIFICATIONS.\\n\\n\\nPlease cite the paper below if you use OverFeat in your research.\\n\\nPierre Sermanet, David Eigen, Xiang Zhang, Michael Mathieu, Rob Fergus, Yann LeCun: \\n\"OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks\",\\nArXiv:1312.6229. http://arxiv.org/abs/1312.6229\\n\\n\\n\\n \\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "OverFeat",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "OverFeat-DeepNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "vohoaiviet",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vohoaiviet/OverFeat-DeepNet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 12:47:30 GMT"
    },
    "technique": "GitHub API"
  }
}
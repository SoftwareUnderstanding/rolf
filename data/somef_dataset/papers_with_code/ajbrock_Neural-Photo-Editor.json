{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This code contains lasagne layers and other goodies adopted from a number of places:\n- MADE wrapped from the implementation by M. Germain et al: https://github.com/mgermain/MADE\n- Gaussian Sample layer from Tencia Lee's Recipe: https://github.com/Lasagne/Recipes/blob/master/examples/variational_autoencoder/variational_autoencoder.py\n- Minibatch Discrimination layer from OpenAI's Improved GAN Techniques: https://github.com/openai/improved-gan\n- Deconv Layer adapted from Radford's DCGAN: https://github.com/Newmu/dcgan_code\n- Image-Grid Plotter adopted from AlexMLamb's Discriminative Regularization: https://github.com/vdumoulin/discgen\n- Metrics_logging and checkpoints adopted from Daniel Maturana's VoxNet: https://github.com/dimatura/voxnet\n- Plat interface adopted from Tom White's plat: https://github.com/dribnet/plat\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ajbrock/Neural-Photo-Editor",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-09-21T14:53:36Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-18T02:42:39Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8440200343960448
      ],
      "excerpt": "A simple interface for editing natural photos with generative neural networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9677863608184752,
        0.9128056531160371,
        0.9585963200624033,
        0.8367835796737425,
        0.9020719259260298,
        0.9437412541610095
      ],
      "excerpt": "This repository contains code for the paper \"Neural Photo Editing with Introspective Adversarial Networks,\" and the Associated Video. \nYou can paint the image by picking a color and painting on the image, or paint in the latent space canvas (the red and blue tiles below the image).  \nThe long horizontal slider controls the magnitude of the latent brush, and the smaller horizontal slider controls the size of both the latent and the main image brush. \nYou can select different entries from the subset of the celebA validation set (included in this repository as an .npz) by typing in a number from 0-999 in the bottom left box and hitting \"infer.\" \nUse the reset button to return to the ground truth image. \nPress \"Update\" to update the ground-truth image and corresponding reconstruction with the current image. Use \"Infer\" to return to an original ground truth image from the dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8678167956623793
      ],
      "excerpt": "You will need Fuel along with the 64x64 version of celebA. See here for instructions on downloading and preparing it.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9319458978952333,
        0.8766151417844311,
        0.8036887870542996
      ],
      "excerpt": "My MADE layer currently only accepts hidden unit sizes that are equal to the size of the latent vector, which will present itself as a BAD_PARAM error. \nSince the MADE really only acts as an autoregressive randomizer I'm not too worried about this, but it does bear looking into. \nI messed around with the keywords for get_model, you'll need to deal with these if you wish to run any model other than IAN_simple through the editor. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8418547794455358
      ],
      "excerpt": "Remainder of the IAN experiments (including SVHN) coming soon. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A simple interface for editing natural photos with generative neural networks.",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "http://lasagne.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ajbrock/Neural-Photo-Editor/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 201,
      "date": "Mon, 20 Dec 2021 15:17:34 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ajbrock/Neural-Photo-Editor/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ajbrock/Neural-Photo-Editor",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To run the Neural Photo Editor, you will need:\n- Python, likely version 2.7. You may be able to use early versions of Python2, but I'm pretty sure there's some incompatibilities with Python3 in here.\n- [Theano](http://deeplearning.net/software/theano/), development version.  \n- [lasagne](http://lasagne.readthedocs.io/en/latest/user/installation.html), development version.\n- I highly recommend [cuDNN](https://developer.nvidia.com/cudnn) as speed is key, but it is not a dependency.\n- numpy, scipy, PIL, Tkinter and tkColorChooser, but it is likely that your python distribution already has those.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9127765047754391
      ],
      "excerpt": "You will need Fuel along with the 64x64 version of celebA. See here for instructions on downloading and preparing it.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9645820477056245
      ],
      "excerpt": "Note that you will need matplotlib. to do so. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8763837857337077,
        0.8634633578036838,
        0.8201247661670555
      ],
      "excerpt": "python train_IAN.py IAN.py \nBy default, this code will save (and overwrite!) the weights to a .npz file with the same name as the config.py file (i.e. \"IAN.py -> IAN.npz\"), and will output a jsonl log of the training with metrics recorded after every chunk. \nUse the --resume=True flag when calling to resume training a model--it will automatically pick up from the most recent epoch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8763837857337077
      ],
      "excerpt": "python sample_IAN.py IAN.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ajbrock/Neural-Photo-Editor/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2016 Andy Brock\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Neural Photo Editor",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Neural-Photo-Editor",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ajbrock",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ajbrock/Neural-Photo-Editor/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "By default, the NPE runs on IAN_simple. This is a slimmed-down version of the IAN without MDC or RGB-Beta blocks, which runs without lag on a laptop GPU with ~1GB of memory (GT730M)\n\nIf you're on a Windows machine, you will want to create a .theanorc file and at least set the flag FLOATX=float32. \n\nIf you're on a linux machine, you can just insert THEANO_FLAGS=floatX=float32 before the command line call.\n\nIf you don't have cuDNN, simply change line 56 of the NPE.py file from dnn=True to dnn=False. Note that I presently only have the non-cuDNN option working for IAN_simple.\n\nThen, run the command:\n\n```sh\npython NPE.py\n```\nIf you wish to use a different model, simply edit the line with \"config path\" in the NPE.py file. \n\nYou can make use of any model with an inference mechanism (VAE or ALI-based GAN).\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2031,
      "date": "Mon, 20 Dec 2021 15:17:34 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "machine-learning",
      "deep-learning",
      "gans",
      "computer-vision",
      "interfaces",
      "convolutional-neural-networks"
    ],
    "technique": "GitHub API"
  }
}
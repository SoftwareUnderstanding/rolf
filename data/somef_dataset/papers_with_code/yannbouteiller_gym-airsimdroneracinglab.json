{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1911.04448"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9944484218006108,
        0.9944484218006108,
        0.9944484218006108
      ],
      "excerpt": "- MADDPG ( https://arxiv.org/pdf/1706.02275.pdf ) \n- LOLA ( https://arxiv.org/pdf/1709.04326.pdf ) \n- LOLA-Dice ( https://arxiv.org/pdf/1802.05098.pdf ) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yannbouteiller/gym-airsimdroneracinglab",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-23T20:55:47Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-10T07:44:17Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8445998886325766
      ],
      "excerpt": "An advanced gym environment and a Batch RL dataset collector game made on top of the Airsim Drone Racing Lab binaries. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8941552651890352,
        0.9689237859934335
      ],
      "excerpt": "This environment has been conceived with the RTRL framework in mind, and is fully compatible with its setting. \nThe 'Game of Drones' project has given birth to a pretty advanced gym environment. The dataset collector script turns this gym environment into a multiplayer videogame that can be used to collect Offline Reinforcement Learning datasets in all imaginable settings, including real-time. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8351783621152147
      ],
      "excerpt": "The keyboard controls are: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "RESET = pg.K_q  #: resets (and discards) episode \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.972269327044175,
        0.9716123207709298
      ],
      "excerpt": "The environment is compatible with rllib, which handles multi-agent and requires a special interface that is not (yet) a default for multiagent gym environments, as gym has initially been designed for single agent environments. The \"wrapper\" (not an actual gym wrapper but that can be done easily) present in envs allows you to wrap the environment for rllib compatibilty. \nA multi-agent training should in theory lead to inference and adaptation to unknown opponent policies. A whole lot of work from OpenAI and and Deepmind shows that. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9576076394230536,
        0.9453357323774353
      ],
      "excerpt": "The environment has additional features in order to support spawning multiple instances of AirSim for parralel training with rllib. \nIt is very likely that the quality of the simulation is hardware-dependent. See https://github.com/microsoft/AirSim-NeurIPS2019-Drone-Racing/issues/17 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8434501905481584
      ],
      "excerpt": "The way the simulator handles inter-drone collision and disqualification may be weird compared to what is described in the rules. See https://github.com/microsoft/AirSim-NeurIPS2019-Drone-Racing/issues/43 \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yannbouteiller/gym-airsimdroneracinglab/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 30 Dec 2021 04:40:42 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yannbouteiller/gym-airsimdroneracinglab/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "yannbouteiller/gym-airsimdroneracinglab",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\ngit clone https://github.com/yannbouteiller/gym-airsimdroneracinglab.git\ncd gym-airsimdroneracinglab\npip install -e .\npython download_and_mod_airsim.py\n```\nNote 0: `python download_and_mod_airsim.py` may need to be executed as administrator\n\nNote 1: Execute these in this order because the second script will mod the airsimdroneracinglab installation previously performed by pip\n\nNote 2: The AirSim competition binaries are not open source and will be downloaded by download_and_mod_airsim.py.\nIf you are just updating your installation and don't want to download them again, use instead:\n\n```bash\npython download_and_mod_airsim.py --no-download\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8795208025088698
      ],
      "excerpt": "Reseting with \"Q\" will discard the current episode if you are recording. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594052706428214
      ],
      "excerpt": "Random crashes may happen on resets. See https://github.com/microsoft/AirSim-NeurIPS2019-Drone-Racing/issues/60 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yannbouteiller/gym-airsimdroneracinglab/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Yann Bouteiller\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Gym Game Of Drones",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "gym-airsimdroneracinglab",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "yannbouteiller",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yannbouteiller/gym-airsimdroneracinglab/blob/main/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\ncd gym_game_of_drones\npython dataset_collector_game.py [options]\n```\nEach time you launch the script, give a new experiment name with the --experiment_name option, or the collected data will erase previous data. For instance:\n```\n--experiment_name=\"building99_0\"\n--experiment_name=\"building99_1\"\n--experiment_name=\"building99_2\"\n--experiment_name=\"Soccer_Field_Medium_0\" --level_name=\"Soccer_Field_Medium\"\n...\n```\nPlease also record the players' names with the following options (player 1 is on the left of the screen, player 2 is on the right):\n```\n--player_1\n--player_2\n```\n\nYou can choose the map by using this option:\n\n```\n--level_name\n```\nThere are 4 possibilities: \"Soccer_Field_Easy\", \"Soccer_Field_Medium\", \"ZhangJiaJie_Medium\", \"Building99_Hard\", the defalut map is \"Building99_Hard\". \n\n**IMPORTANT**: if your computer is too slow at rendering images (ZhangJiaJie is particularily slow), AirSim will reset the race and trap you in a box after 300 seconds, which cannot be fixed for now. If this happens to you, please discard the data by pressing \"Q\" and use simpler maps that you can complete in less than 300 seconds.\n\nWhat's more, we are happy if you are using the **\"Soccer_Field_Medium\"** and **\"Building99_Hard\"** maps, because we are planning to focus on these two.\n\nIn the end, your command should look something like, for example:\n\n```\npython dataset_collector_game.py --level_name \"Soccer_Field_Medium\" --experiment_name \"Soccer_Field_Medium_0\" --player_1 \"joyfly\" --player_2 \"superhero\"\n```\n\nIf you have two joysticks, connect them before launching the game. You can press the \"C\" key when the game is running to configure your joysticks.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Thu, 30 Dec 2021 04:40:42 GMT"
    },
    "technique": "GitHub API"
  }
}
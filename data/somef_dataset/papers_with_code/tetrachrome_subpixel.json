{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1609.07009",
      "https://arxiv.org/abs/1609.05158",
      "https://arxiv.org/abs/1609.05158",
      "https://arxiv.org/abs/1609.05158",
      "https://arxiv.org/abs/1311.2901",
      "https://arxiv.org/abs/1603.07285"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] [Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network](https://arxiv.org/abs/1609.05158). By Shi et. al.  \n[2] [Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901). By Zeiler and Fergus.  \n[3] [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285). By Dumoulin and Visin.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9240042240489945
      ],
      "excerpt": "computer vision. Transposed convolutions (sometimes referred to as deconvolution) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8011612216676958
      ],
      "excerpt": "Following Shi et. al. the equation for implementing the phase shift for CNNs is: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "  if color: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.842790493796475
      ],
      "excerpt": "Style transfer networks \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/atriumlts/subpixel",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-08-11T18:05:58Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T14:07:46Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9393096848967248,
        0.858681234818381,
        0.976181550703304,
        0.9302087415375195,
        0.8110844632823327
      ],
      "excerpt": "For visualization purposes let us check out that convolutions in the \npresent subject are a sequence of \ninner product of a given filter (or kernel) with pieces of a larger image. This \noperation is highly parallelizable, since the kernel is the same throughout the \nimage. People used to refer to convolutions as locally connected layers with \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9031500993770093,
        0.902048685267425,
        0.8918792710848978
      ],
      "excerpt": "or we can follow the convolution with maxpooling to \ndownsample the input image. The equivalent backward operation of a \nconvolution with strides, in other words its gradient, is an upsampling \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8866304871508516
      ],
      "excerpt": "convolution with the kernel rotated 180 degrees. See representation copied from Dumoulin and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9786628176723614,
        0.926079376442975
      ],
      "excerpt": "For classification purposes, all that we need is the feedforward pass of a \nconvolutional neural network to extract features at different scales. But for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8596888633966554,
        0.8703275234150186
      ],
      "excerpt": "and upsampling operations are necessary in a feedforward pass. The community \ntook inspiration on how the gradients are implemented in CNNs and applied them as \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8941612114722516
      ],
      "excerpt": "zero values to the upscale the image, that have to be later filled \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8843659064170681
      ],
      "excerpt": "To cope with that problem, Shi et. al [1] proposed what we argue to be one the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9594099104745674
      ],
      "excerpt": "of image reshaping called a phase shift. In other words, instead of putting zeros \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9217406544244743,
        0.8119395085899395,
        0.8940652843761945,
        0.8117560025521509
      ],
      "excerpt": "calculate more convolutions in lower resolution and resize the resulting map \ninto an upscaled image. This way, no meaningless zeros are necessary. \nCheckout the figure below from their paper. Follow the colors to have an intuition about how they do the \nimage resizing. Check this paper for further understanding. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9794882687978849,
        0.9520807998362738
      ],
      "excerpt": "Next we will discuss our implementation of this method and later what we \nforesee to be the implications of it everywhere where upscaling in convolutional neural \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9153325182494372
      ],
      "excerpt": "Following Shi et. al. the equation for implementing the phase shift for CNNs is: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9404332089803565
      ],
      "excerpt": "To implement this in Tensorflow we would have to create a custom operator and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9223380631847337,
        0.8708319082105521
      ],
      "excerpt": "depiction of the resulting operation we noticed how to write that using just \nregular reshape, split and concatenate operations. To understand that \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8873016831241716,
        0.8408373205130215
      ],
      "excerpt": "convolutional map and builds up neighborhoods of r x r pixels. And we can do the \nsame with a few lines of Tensorflow code as: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "    X = tf.concat(2, [tf.squeeze(x) for x in X])  #: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "    X = tf.concat(3, [_phase_shift(x, r) for x in Xc]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9982054876812749,
        0.9833899477984556
      ],
      "excerpt": "The reminder of this library is an implementation of a subpixel CNN using the proposed PS \nimplementation for super resolution of celeb-A image faces. The code was written on top of \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8737964212474084
      ],
      "excerpt": "Here we want to forecast that subpixel CNNs are going to ultimately replace \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9378798440676908,
        0.9701201158042126
      ],
      "excerpt": "feedforward neural networks. Phase shift's gradient is much more meaningful and resizing \noperations are virtually free computationally. Our implementation is a high \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.878643864046615
      ],
      "excerpt": "But for now we want to encourage the community to experiment replacing deconv layers with subpixel operatinos everywhere. By everywhere we mean: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8044948408614239
      ],
      "excerpt": "    Similar to super-resolution, include subpixel in other autoencoder implementations, replace deconv layers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9702001156155075
      ],
      "excerpt": "    This didn't work in a lazy plug and play in our experiments. We have to look more carefully \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9295949959118199
      ],
      "excerpt": "    We started doing this, but as predicted we have to change hyperparameters. The network power is totally different from deconv layers. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9436377015597865,
        0.9850269793876185,
        0.8100419012869536,
        0.9620225366906552
      ],
      "excerpt": "wherever upscaling is done with zero padding \nJoin us in the revolution to get rid of meaningless zeros in feedfoward \nconvnets, give suggestions here, try our code! \nThe top row is the input, the middle row is the output, and the bottom row is the ground truth. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "subpixel: A subpixel convnet for super resolution with Tensorflow",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/tetrachrome/subpixel/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 298,
      "date": "Sun, 26 Dec 2021 21:35:06 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/atriumlts/subpixel/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "atriumlts/subpixel",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/tetrachrome/subpixel/master/docker/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/tetrachrome/subpixel/master/ponynet.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.83324521860577
      ],
      "excerpt": "  #: Main OP that you can arbitrarily use in you tensorflow code \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8150111107324681,
        0.8030475885660923
      ],
      "excerpt": "carpedm20/DCGAN-tensorflow, as so, follow the same instructions to use it: \n$ python download.py --dataset celebA  #: if this doesn't work, you will have to download the dataset by hand somewhere else \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8616053376478365
      ],
      "excerpt": "  assert len(I.shape) == 3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8754108177464064
      ],
      "excerpt": "  O = np.zeros((I.shape[0]*r, I.shape[1]*r, I.shape[2]/(r*2))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8489069599966664,
        0.8489069599966664
      ],
      "excerpt": "        a = np.floor(x/r).astype(\"int\") \n        b = np.floor(y/r).astype(\"int\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936606094659785
      ],
      "excerpt": "        print a, b, d \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432
      ],
      "excerpt": "    X = tf.transpose(X, (0, 1, 2, 4, 3))  #: bsize, a, b, 1, 1 \n    X = tf.split(1, a, X)  #: a, [bsize, b, r, r] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "    Xc = tf.split(3, 3, X) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9481547128930644
      ],
      "excerpt": "$ python main.py --dataset celebA --is_train True --is_crop True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9042534665813847
      ],
      "excerpt": "<img src=\"./images/more_examples.png\" width=500> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/atriumlts/subpixel/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License (MIT)\\n\\nCopyright (c) 2016 tetrachrome\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "subpixel: A subpixel convolutional neural network implementation with Tensorflow",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "subpixel",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "atriumlts",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/atriumlts/subpixel/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2115,
      "date": "Sun, 26 Dec 2021 21:35:06 GMT"
    },
    "technique": "GitHub API"
  }
}
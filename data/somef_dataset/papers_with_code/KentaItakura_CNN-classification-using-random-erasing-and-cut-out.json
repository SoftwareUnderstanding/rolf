{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1708.04896",
      "https://arxiv.org/abs/1708.04552",
      "https://arxiv.org/abs/1708.04896.](https://arxiv.org/abs/1708.04896)\n\n[2] [DeVries, Terrance, and Graham W. Taylor. \"Improved regularization of convolutional neural networks with cutout.\" arXiv preprint https://arxiv.org/abs/1708.04552 (2017).](https://arxiv.org/abs/1708.04552)\n\n[3] Krizhevsky, A., and G. Hinton. \"Learning multiple layers of features from tiny images.\" Master's Thesis. University of Toronto, Toronto, Canada, 2009.\n\n[4] The CIFAR-10 dataset (\\href{https://www.cs.toronto.edu/~kriz/cifar.html",
      "https://arxiv.org/abs/1708.04552 (2017).](https://arxiv.org/abs/1708.04552)\n\n[3] Krizhevsky, A., and G. Hinton. \"Learning multiple layers of features from tiny images.\" Master's Thesis. University of Toronto, Toronto, Canada, 2009.\n\n[4] The CIFAR-10 dataset (\\href{https://www.cs.toronto.edu/~kriz/cifar.html"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "[Key words] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999998081645642,
        0.9988844367405628
      ],
      "excerpt": "[1] Zhong, Z., L. Zheng, G. Kang, S. Li, and Y. Yang. \"Random erasing data augmentation. arXiv 2017.\" arXiv preprint arXiv:1708.04896. \n[2] DeVries, Terrance, and Graham W. Taylor. \"Improved regularization of convolutional neural networks with cutout.\" arXiv preprint arXiv:1708.04552 (2017). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8592463178779295
      ],
      "excerpt": "[4] The CIFAR-10 dataset (\\href{https://www.cs.toronto.edu/~kriz/cifar.html}{https://www.cs.toronto.edu/\\textasciitilde{}kriz/cifar.html}) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9568193957733768
      ],
      "excerpt": "   imshow(Input);title(class{1}) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "    imageInputLayer([32 32 3])  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "YPred = classify(net,imdsTest); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "    I = I(1:32,1:32,:); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9451687571233693
      ],
      "excerpt": "url = 'https://www.cs.toronto.edu/~kriz/cifar-10-matlab.tar.gz'; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9426612454569065
      ],
      "excerpt": "if ~exist(unpackedData, 'dir') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    end \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    end \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KentaItakura/CNN-classification-using-random-erasing-and-cut-out",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-22T05:07:53Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-22T08:33:20Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9764293789255283
      ],
      "excerpt": "This demo shows how to perform random erasing/cut out augmentation in CNN classification as explained in [1] and [2]. A rectangle mask was created randomly on the training images to escape overfitting as shown below. In this demo, a gray color mask was made and the height and width ranged from 1 to the half of the image size. The color and size of the mask can be changed in the custom function at the end of this script.  The test accuracy with/without the random erasing/cut out was compared; the test accucacy with the technique was significantly higher tan that without the random erasing/cut out. Because the network with it, to some extent, escape the over-fitting to the training data. This was done with cifar-10 dataset. You may alleviate the over-fitting using the random erasing/cut out.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112
      ],
      "excerpt": "\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u3067\u306f\u3001cut out\u3084random erasing\u3068\u3088\u3070\u308c\u308b\u65b9\u6cd5 [1, 2] \u3092\u7528\u3044\u3066\u30c7\u30fc\u30bf\u62e1\u5f35\u3092\u3057\u3001\u3055\u3089\u306b\u7573\u307f\u8fbc\u307f\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\uff08CNN)\u306b\u3066\u5206\u985e\u3092\u3059\u308b\u4f8b\u3092\u793a\u3057\u307e\u3059\u3002\u904e\u5b66\u7fd2\u3092\u9632\u3050\u305f\u3081\u306b\u3001\u8a13\u7df4\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u753b\u50cf\u306b\u30e9\u30f3\u30c0\u30e0\u306b\u9577\u65b9\u5f62\u306e\u30de\u30b9\u30af\u3092\u304b\u3051\u3001\u305d\u306e\u753b\u50cf\u3092\u3082\u3068\u306b\u5b66\u7fd2\u3092\u884c\u3044\u307e\u3059\u3002Cifar-10\u3068\u3088\u3070\u308c\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 [3, 4]\u3092\u7528\u3044\u3066\u3053\u306e\u30c7\u30fc\u30bf\u62e1\u5f35\u306b\u3088\u3063\u3066\u3001\u5206\u985e\u7cbe\u5ea6\u304c\u4e0a\u6607\u3059\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002\u8f1d\u5ea6\u5024\u304c128\u306e\u30b0\u30ec\u30fc\u306e\u30de\u30b9\u30af\u3092\u304b\u3051\u3066\u3044\u307e\u3059\u304c\u3001\u8a13\u7df4\u30c7\u30fc\u30bf\u5185\u306e\u8f1d\u5ea6\u5024\u306e\u5e73\u5747\u3092\u4f7f\u3063\u305f\u308a\u3001\u30b4\u30de\u5869\u30ce\u30a4\u30ba\u3092\u4e57\u305b\u305f\u308a\u3068\u5de5\u592b\u3092\u3059\u308b\u3053\u3068\u3067\u3055\u3089\u306a\u308b\u7cbe\u5ea6\u4e0a\u6607\u306e\u53ef\u80fd\u6027\u3082\u8003\u3048\u3089\u308c\u307e\u3059\u3002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8210594890029882
      ],
      "excerpt": "augmentation, cifar-10, classification, cnn, cut out, data augmentation, over-fitting, over-tune, random erasing \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9058791623934701
      ],
      "excerpt": "[3] Krizhevsky, A., and G. Hinton. \"Learning multiple layers of features from tiny images.\" Master's Thesis. University of Toronto, Toronto, Canada, 2009. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "for i=1:numDisplay \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9013311701265119
      ],
      "excerpt": "The network consists of three layers. You can define each layer easily such as with convolution2dLayer.  For the detail, please check the comment below. Alternatively, you can define the CNN layer using a GUI tool called deepNetworkDesigner.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9251249774358654
      ],
      "excerpt": "% YTest is the label information of the test data.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8247741735202656
      ],
      "excerpt": "% returns 1, otherwise, 0. Its sum/number of test data is the accuracy \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9061397527059828
      ],
      "excerpt": "We show the training curve with the random erasing/cut out and without below. The test accuracy was 77.6 and 73.1, respectively. The network without the augmentation over-fitts to the training dataset, thus, the validation accuracy was lower. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "for idx = 1:numImg     \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8842904936552134
      ],
      "excerpt": "    % randomly define the location, width and height of the mask \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9382607802783984
      ],
      "excerpt": "% Create subdirectories for each of the category folders. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "for i = 1:5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "    for i = 1:numel(directoryNames) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8353480651680623
      ],
      "excerpt": "    % to the corresponding category folders. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "    data = S.data; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9409548660577622,
        0.908925214220865,
        0.8979411005071259,
        0.8979411005071259,
        0.8979411005071259
      ],
      "excerpt": "    % The image data in the MAT file needs to be processed with \n    % transpositions, reshaping and permutations. \n    data = data'; \n    data = reshape(data, 32,32,3,[]); \n    data = permute(data, [2 1 3 4]); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.910607975459455
      ],
      "excerpt": "    for i = 1:size(data,4) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "        imwrite(data(:,:,:,i),outputFilename); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This demo shows how to perform random erasing/cut out augmentation in CNN classification using MATLAB. ",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The helper function called downloadCIFARToFolders automatically save the cifar10 images to the current directory. This helper function is provided by MathWorks ([https://jp.mathworks.com/help/deeplearning/examples/upload-deep-learning-data-to-the-cloud.html](https://jp.mathworks.com/help/deeplearning/examples/upload-deep-learning-data-to-the-cloud.html)). This takes some time but, if the folder already exists, this step is skipped. \n\n```matlab:Code\nclear;clc;close all\nif exist('cifar10\\')~=7\n   [trainDirectory,testDirectory] = downloadCIFARToFolders(pwd);\nend\n```\n\n\nThe `cifar10` images were stored in the imagedatastore. A portion of training dataset was used for validation image. \n\n```matlab:Code\ncd('cifar10')\nimds = imageDatastore('train','IncludeSubfolders',true,'LabelSource','foldernames'); \n[imdsTrain,imdsValidation] = splitEachLabel(imds,0.9);\nimdsTest = imageDatastore('test','IncludeSubfolders',true,'LabelSource','foldernames'); \n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KentaItakura/CNN-classification-using-random-erasing-and-cut-out/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 03:15:16 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/KentaItakura/CNN-classification-using-random-erasing-and-cut-out/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "KentaItakura/CNN-classification-using-random-erasing-and-cut-out",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8179767910027234
      ],
      "excerpt": "% the provided directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8397331684428114
      ],
      "excerpt": "outputDirectory = fullfile(directory,folderName); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8397331684428114
      ],
      "excerpt": "% directory.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8902627162932362
      ],
      "excerpt": "        mkdir(fullfile(outputPath,directoryNames{i})); \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.859816757525275
      ],
      "excerpt": "classifies the test images  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.826314157694608
      ],
      "excerpt": "The CutOutAug function creates the training images with the mask for random erasing/cut out.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8139827581570631
      ],
      "excerpt": "function [dataOut,info] = CutOutAug(InputImgs,info) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8828665034782968
      ],
      "excerpt": "%   I = imnoise(I,'salt &amp; pepper',0.01); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.836315108136979
      ],
      "excerpt": "You can download the cifar10 data with downloadCIFARToFolders function.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8235582005634522
      ],
      "excerpt": "function [trainDirectory,testDirectory] = downloadCIFARToFolders(directory) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8604645420202437
      ],
      "excerpt": "% The function copies the training and test data sets into a folder called \"cifar10\" in \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8796155281407352
      ],
      "excerpt": "% Create the training and test directories where the images will be stored. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137,
        0.8633989807152664
      ],
      "excerpt": "trainDirectory = fullfile(outputDirectory,'train'); \ntestDirectory = fullfile(outputDirectory,'test'); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8462700373362163
      ],
      "excerpt": "    % Loads a MAT file containing images from the data set and saves them \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/KentaItakura/CNN-classification-using-random-erasing-and-cut-out/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "MATLAB"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "CNN classification using random erasing / cut out",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "CNN-classification-using-random-erasing-and-cut-out",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "KentaItakura",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KentaItakura/CNN-classification-using-random-erasing-and-cut-out/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "KentaItakura",
        "body": "The script was uploaded to github. ",
        "dateCreated": "2021-08-22T05:14:29Z",
        "datePublished": "2021-08-22T05:17:17Z",
        "html_url": "https://github.com/KentaItakura/CNN-classification-using-random-erasing-and-cut-out/releases/tag/1.1",
        "name": "CNN-classification-using-random-erasing-and-cut-out v1",
        "tag_name": "1.1",
        "tarball_url": "https://api.github.com/repos/KentaItakura/CNN-classification-using-random-erasing-and-cut-out/tarball/1.1",
        "url": "https://api.github.com/repos/KentaItakura/CNN-classification-using-random-erasing-and-cut-out/releases/48233233",
        "zipball_url": "https://api.github.com/repos/KentaItakura/CNN-classification-using-random-erasing-and-cut-out/zipball/1.1"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Sun, 26 Dec 2021 03:15:16 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "cnn",
      "classification",
      "matlab",
      "cut-out",
      "random-erasing",
      "augmentation",
      "deep-learning"
    ],
    "technique": "GitHub API"
  }
}
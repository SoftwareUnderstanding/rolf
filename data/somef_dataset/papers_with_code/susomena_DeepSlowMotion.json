{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1712.00080",
      "https://arxiv.org/abs/1611.08387",
      "https://arxiv.org/abs/1703.05884",
      "https://arxiv.org/abs/1712.00080](https://arxiv.org/abs/1712.00080)\n\nThe script `download_dataset.sh` downloads two datasets, the Adobe 240-fps dataset and the Need for Speed dataset, that can be used for training the neural network. For more information on these datasets, please see:\n\n>S. Su, M. Delbracio, J. Wang, G. Sapiro, W. Heidrich and O. Wang, \"Deep Video Deblurring for Hand-Held Cameras,\" _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)_, Honolulu, HI, USA, 2017, pp. 237-246.\n\nor go to: [https://arxiv.org/abs/1611.08387](https://arxiv.org/abs/1611.08387)\n\n> H. K. Galoogahi, A. Fagg, C. Huang, D. Ramanan and Simon Lucey, \"Need for Speed: A Benchmark for Higher Frame Rate Object Tracking,\" _Proceedings of the IEEE International Conference on Computer Vision (ICCV)_, Venice, Italy, 2017, pp. 1125-1134.\n\nor go to: [https://arxiv.org/abs/1703.05884](https://arxiv.org/abs/1703.05884)\n\nIn order to download both datasets with the script, just type the following command in a terminal:\n\n```bash\n./download_dataset.sh path_to_folder\n```\n\nwhere `path_to_folder` is the directory where the dataset should be downloaded. This directory is created if it does not exist.\n\nThe loss function includes a term that depends on the activations of a convolutional layer of the VGG16 neural network. The pretrained  weights of the VGG16 neural networks are stored in the `vgg16_weights_no_fc.npz` file. This file is a modified version of the file that can be found in [this link](https://www.cs.toronto.edu/~frossard/post/vgg16/). In order to reduce the size of the file, the weights of the fully connected layers have been removed. For more information on the VGG16 neural network, please see:\n\n>K. Simonyan and A. Zisserman, \"Very Deep Convolutional Networks for Large-Scale Image Recognition,\" Proceedings of the International Conference on Learning Representations (ICLR), San Diego, CA, USA, 2015, pp. 1-14.\n\nor go to: [https://arxiv.org/abs/1409.1556](https://arxiv.org/pdf/1409.1556.pdf)",
      "https://arxiv.org/abs/1611.08387](https://arxiv.org/abs/1611.08387)\n\n> H. K. Galoogahi, A. Fagg, C. Huang, D. Ramanan and Simon Lucey, \"Need for Speed: A Benchmark for Higher Frame Rate Object Tracking,\" _Proceedings of the IEEE International Conference on Computer Vision (ICCV)_, Venice, Italy, 2017, pp. 1125-1134.\n\nor go to: [https://arxiv.org/abs/1703.05884](https://arxiv.org/abs/1703.05884)\n\nIn order to download both datasets with the script, just type the following command in a terminal:\n\n```bash\n./download_dataset.sh path_to_folder\n```\n\nwhere `path_to_folder` is the directory where the dataset should be downloaded. This directory is created if it does not exist.\n\nThe loss function includes a term that depends on the activations of a convolutional layer of the VGG16 neural network. The pretrained  weights of the VGG16 neural networks are stored in the `vgg16_weights_no_fc.npz` file. This file is a modified version of the file that can be found in [this link](https://www.cs.toronto.edu/~frossard/post/vgg16/). In order to reduce the size of the file, the weights of the fully connected layers have been removed. For more information on the VGG16 neural network, please see:\n\n>K. Simonyan and A. Zisserman, \"Very Deep Convolutional Networks for Large-Scale Image Recognition,\" Proceedings of the International Conference on Learning Representations (ICLR), San Diego, CA, USA, 2015, pp. 1-14.\n\nor go to: [https://arxiv.org/abs/1409.1556](https://arxiv.org/pdf/1409.1556.pdf)",
      "https://arxiv.org/abs/1703.05884](https://arxiv.org/abs/1703.05884)\n\nIn order to download both datasets with the script, just type the following command in a terminal:\n\n```bash\n./download_dataset.sh path_to_folder\n```\n\nwhere `path_to_folder` is the directory where the dataset should be downloaded. This directory is created if it does not exist.\n\nThe loss function includes a term that depends on the activations of a convolutional layer of the VGG16 neural network. The pretrained  weights of the VGG16 neural networks are stored in the `vgg16_weights_no_fc.npz` file. This file is a modified version of the file that can be found in [this link](https://www.cs.toronto.edu/~frossard/post/vgg16/). In order to reduce the size of the file, the weights of the fully connected layers have been removed. For more information on the VGG16 neural network, please see:\n\n>K. Simonyan and A. Zisserman, \"Very Deep Convolutional Networks for Large-Scale Image Recognition,\" Proceedings of the International Conference on Learning Representations (ICLR), San Diego, CA, USA, 2015, pp. 1-14.\n\nor go to: [https://arxiv.org/abs/1409.1556](https://arxiv.org/pdf/1409.1556.pdf)",
      "https://arxiv.org/abs/1409.1556](https://arxiv.org/pdf/1409.1556.pdf)"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.997532372547635,
        0.9999999999995453
      ],
      "excerpt": "A deep convolutional neural network for multi-frame video interpolation. Based on the work of Huaizu Jiang, Deqing Sun, Varun Jampani, Ming-Hsuan Yang, Erik Learned-Miller and Jan Kautz. To see the original work, please see: \nH. Jiang, D. Sun, V. Jampani, M.-H. Yang, E. Learned-Miller and J. Kautz, \"Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation,\" Proceedings of the The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 2018, pp. 9000-9008. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999999999996447,
        0.867428525130697,
        0.9999999987408614
      ],
      "excerpt": "S. Su, M. Delbracio, J. Wang, G. Sapiro, W. Heidrich and O. Wang, \"Deep Video Deblurring for Hand-Held Cameras,\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 2017, pp. 237-246. \nor go to: arXiv:1611.08387 \nH. K. Galoogahi, A. Fagg, C. Huang, D. Ramanan and Simon Lucey, \"Need for Speed: A Benchmark for Higher Frame Rate Object Tracking,\" Proceedings of the IEEE International Conference on Computer Vision (ICCV), Venice, Italy, 2017, pp. 1125-1134. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9997014817470281
      ],
      "excerpt": "K. Simonyan and A. Zisserman, \"Very Deep Convolutional Networks for Large-Scale Image Recognition,\" Proceedings of the International Conference on Learning Representations (ICLR), San Diego, CA, USA, 2015, pp. 1-14. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/susomena/DeepSlowMotion",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-08-08T19:09:45Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-12-17T01:35:38Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9888184814627828
      ],
      "excerpt": "A deep convolutional neural network for multi-frame video interpolation. Based on the work of Huaizu Jiang, Deqing Sun, Varun Jampani, Ming-Hsuan Yang, Erik Learned-Miller and Jan Kautz. To see the original work, please see: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8180247997814021
      ],
      "excerpt": "The script download_dataset.sh downloads two datasets, the Adobe 240-fps dataset and the Need for Speed dataset, that can be used for training the neural network. For more information on these datasets, please see: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9910305264341501,
        0.8692598213167093
      ],
      "excerpt": "The loss function includes a term that depends on the activations of a convolutional layer of the VGG16 neural network. The pretrained  weights of the VGG16 neural networks are stored in the vgg16_weights_no_fc.npz file. This file is a modified version of the file that can be found in this link. In order to reduce the size of the file, the weights of the fully connected layers have been removed. For more information on the VGG16 neural network, please see: \nK. Simonyan and A. Zisserman, \"Very Deep Convolutional Networks for Large-Scale Image Recognition,\" Proceedings of the International Conference on Learning Representations (ICLR), San Diego, CA, USA, 2015, pp. 1-14. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A deep convolutional neural network for multi-frame video interpolation.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/susomena/DeepSlowMotion/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Tue, 21 Dec 2021 07:41:08 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/susomena/DeepSlowMotion/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "susomena/DeepSlowMotion",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/susomena/DeepSlowMotion/master/download_dataset.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9157320623939392,
        0.9023697225149864
      ],
      "excerpt": "In order to download both datasets with the script, just type the following command in a terminal: \n./download_dataset.sh path_to_folder \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/susomena/DeepSlowMotion/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Jes\\xc3\\xbas Mena\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "DeepSlowMotion",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DeepSlowMotion",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "susomena",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/susomena/DeepSlowMotion/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Tue, 21 Dec 2021 07:41:08 GMT"
    },
    "technique": "GitHub API"
  }
}
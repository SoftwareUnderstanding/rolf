{
  "citation": [
    {
      "confidence": [
        0.9944751467640858
      ],
      "excerpt": "Attempt to reproduce the NeurIPS 2019 paper Subspace Attack: Exploiting Promising Subspaces for Query-Efficient Black-box Attacks. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/epfl-ml-reproducers/subspace-attack-reproduction",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-11-26T15:43:10Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-08T01:42:38Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9675696530151742,
        0.976431280032277,
        0.9579922676599433
      ],
      "excerpt": "The original code of the paper can be found here. We are trying to reproduce the attack to GDAS and WRN model trained on CIFAR-10 dataset, without using and looking at the original code. \nThis project is done as project for the CS-433 Machine Learning Course at EPFL, and as part of the NeurIPS 2019 Reproducibility Challenge. \nThe repository is structured in the following way: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9652206015683356
      ],
      "excerpt": "    \u251c\u2500\u2500 models #: Contains the classes of the models (not made by us, link to original repo above) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Attempt to reproduce the paper Subspace Attack: Exploiting Promising Subspaces for Query-Efficient Black-box Attacks.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/epfl-ml-reproducers/subspace-attack-reproduction/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 20 Dec 2021 10:34:35 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/epfl-ml-reproducers/subspace-attack-reproduction/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "epfl-ml-reproducers/subspace-attack-reproduction",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/epfl-ml-reproducers/subspace-attack-reproduction/master/notebooks/experiment_analysis.ipynb",
      "https://raw.githubusercontent.com/epfl-ml-reproducers/subspace-attack-reproduction/master/notebooks/black-box_attack_reproduce.ipynb",
      "https://raw.githubusercontent.com/epfl-ml-reproducers/subspace-attack-reproduction/master/notebooks/pytorch_test.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8675545328984222
      ],
      "excerpt": "\u251c\u2500\u2500 pretrained #: Should contain the pretrained models (.pth files) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9151270764930737
      ],
      "excerpt": "\u2514\u2500\u2500 src \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8315269429082576,
        0.8168454371188932,
        0.8852554639039018
      ],
      "excerpt": "    \u251c\u2500\u2500 __init__.py \n    \u251c\u2500\u2500 load_data.py #: Some functions used to load the dataset \n    \u251c\u2500\u2500 load_loss.py #: Some functions used to load the loss function \n    \u251c\u2500\u2500 load_model.py #: Some functions to load pretrained models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9299355128878115
      ],
      "excerpt": "    \u251c\u2500\u2500 plots.py #: A function to plot images \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/epfl-ml-reproducers/subspace-attack-reproduction/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Xuanyi Dong\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Subspace Attack Reproduction",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "subspace-attack-reproduction",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "epfl-ml-reproducers",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/epfl-ml-reproducers/subspace-attack-reproduction/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Mon, 20 Dec 2021 10:34:35 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We make use of some pretrained models, that can be downloaded [here](https://drive.google.com/file/d/1TA-UWYVDkCkNPOy1INjUU9321s-HA6RF/view?usp=sharing). They are a subset of the [models](https://drive.google.com/file/d/1aXTmN2AyNLdZ8zOeyLzpVbRHZRZD0fW0/view?usp=sharing) provided with the code of the original paper. They need to be unzipped and put in the `./pretrained` folder, in the root directory of the repo.\n\nThe dataset ([CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html)) is automatically downloaded via `torchvision.datasets` when first running the experiment, and will be saved in the `data/` folder (more info [here](https://pytorch.org/docs/stable/torchvision/datasets.html#cifar)).\n\nThe paper is implemented and tested using Python 3.7. Dependencies are listed in [requirements.txt](requirements.txt).\n\nFor the moment, it is possible to run the experiment using [VGG nets](http://www.robots.ox.ac.uk/~vgg/research/very_deep/) and [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) as reference models and [GDAS](https://arxiv.org/pdf/1910.04465.pdf), [WRN](https://arxiv.org/pdf/1605.07146.pdf) and [PyramidNet](https://arxiv.org/pdf/1610.02915.pdf) as victim models.\n\nIn order to test our implemenation, install the dependencies with `pip3 install --user --requirement requirements.txt`, and run the following command:\n\n```bash\npython run.py\n```\n\nThis will run the experiment on line 5 of table II of our report, with the following settings:\n\n- Reference models: AlexNet+VGGs\n- Victim model: GDAS\n- Number of images: 1000\n- Maximum queries per image: 10000\n- 0 seed\n  \nAnd hyperparameters:\n\n- eta_g = 0.1\n- eta = 1/255\n- delta = 0.1\n- tau = 1.0\n- epsilon = 8/255\n\nN.B.: it takes 7 hours 45 minutes to run on a Google Cloud Platform n1-highmem-8 virtual machine, with 8 vCPU, 52 GB memory and an Nvidia Tesla T4.\n\nMoreover, the following settings can be used to customize the experiment:\n\n```bash\nusage: run.py [-h] [-ds {Dataset.CIFAR_10}]\n                     [--reference-models {vgg11_bn,vgg13_bn,vgg16_bn,vgg19_bn,AlexNet_bn} [{vgg11_bn,vgg13_bn,vgg16_bn,vgg19_bn,AlexNet_bn} ...]]\n                     [--victim-model {gdas,wrn,pyramidnet}]\n                     [--loss {ExperimentLoss.CROSS_ENTROPY,ExperimentLoss.NEG_LL}]\n                     [--tau TAU] [--epsilon EPSILON] [--delta DELTA]\n                     [--eta ETA] [--eta_g ETA_G] [--n-images N_IMAGES]\n                     [--image-limit IMAGE_LIMIT]\n                     [--compare-gradients COMPARE_GRADIENTS]\n                     [--check-success CHECK_SUCCESS]\n                     [--show-images SHOW_IMAGES] [--seed SEED]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -ds {Dataset.CIFAR_10}, --dataset {Dataset.CIFAR_10}\n                        The dataset to be used.\n  --reference-models {vgg11_bn,vgg13_bn,vgg16_bn,vgg19_bn,AlexNet_bn} [{vgg11_bn,vgg13_bn,vgg16_bn,vgg19_bn,AlexNet_bn} ...]\n                        The reference models to be used.\n  --victim-model {gdas,wrn,pyramidnet}\n                        The model to be attacked.\n  --loss {ExperimentLoss.CROSS_ENTROPY,ExperimentLoss.NEG_LL}\n                        The loss function to be used\n  --tau TAU             Bandit exploration.\n  --epsilon EPSILON     The norm budget.\n  --delta DELTA         Finite difference probe.\n  --eta ETA             Image learning rate.\n  --eta_g ETA_G         OCO learning rate.\n  --n-images N_IMAGES   The number of images on which the attack has to be run\n  --image-limit IMAGE_LIMIT\n                        Limit of iterations to be done for each image\n  --compare-gradients COMPARE_GRADIENTS\n                        Whether the program should output a comparison between\n                        the estimated and the true gradients.\n  --check-success CHECK_SUCCESS\n                        Whether the attack on each image should stop if it has\n                        been successful.\n  --show-images SHOW_IMAGES\n                        Whether each image to be attacked, and its\n                        corresponding adversarial examples should be shown\n  --seed SEED           The random seed with which the experiment should be\n                        run, to be used for reproducibility purposes.\n```\n\nIn order to run an experiment on 100 images in which the loss of the true model and the cosine similarity between the estimated and true gradient, for all 5000 iterations per image, regardless of the success of the attack (i.e. the one used for figures 1 and 2 of our report), you should run\n\n```bash\npython3 run.py --check-success=False --n-images=100 --compare-gradients=True\n```\n\nN.B.: it takes around 20 hours to run the experiment on the aforementioned machine.\n\nThe experiment results are saved in the `outputs/` folder, in a file named `YYYY-MM-DD.HH-MM.npy` a dictionary exported with `numpy.save()`. The format of the dictionary is:\n\n```python\nexperiment_info = {\n    'experiment_baseline': {\n        'victim_model': victim_model_name,\n        'reference_model_names': reference_model_names,\n        'dataset': dataset\n    },\n    'hyperparameters': {\n        'tau': tau,\n        'epsilon': epsilon,\n        'delta': delta,\n        'eta': eta,\n        'eta_g': eta_g\n    },\n    'settings': {\n        'n_images': n_images,\n        'image_limit': image_limit,\n        'compare_gradients': compare_gradients,\n        'gpu': #: If the GPU has been used for the experiment,\n        'seed': seed\n    },\n    'results': {\n        'queries': #: The number of queries run\n        'total_time' #: The time it took to run the experiment\n        #: The following are present only if compare_gradients == True\n        'gradient_products': #: The cosine similarities for each image\n        'true_gradient_norms': #: The norms of the true gradients for each image\n        'estimated_gradient_norms': #: The norms of the estimated gradients for each image\n        'true_losses': #: The true losses each iteration\n        'common_signs': #: The percentages of common signs between true and est gradients\n        'subs_common_signs': #: The percentages of common signs between subsequent gradients\n}\n```\n\nThe file can be imported in Python using `np.load(output_path, allow_pickle=True).item()`.\n\n",
      "technique": "Header extraction"
    }
  ]
}
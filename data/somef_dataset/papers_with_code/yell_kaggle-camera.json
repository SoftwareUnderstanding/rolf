{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1506.01186",
      "https://arxiv.org/abs/1503.02531",
      "https://arxiv.org/abs/1710.09412",
      "https://arxiv.org/abs/1704.00109"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "multi-class classification Hinge loss (nn.MultiMarginLoss) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9183905169370076
      ],
      "excerpt": "implement and use Cyclical LR for faster transfer learning, [arXiv] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9218387569487573,
        0.9212469123976413
      ],
      "excerpt": "try Mixup: [arXiv] \nuse Snapshot ensembles for CNNs trained with Cyclical LR: [arXiv] \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yell/kaggle-camera",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-01-16T03:02:09Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-05T14:55:01Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9294800402514454
      ],
      "excerpt": "Summary of the Solution \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8754665232329328
      ],
      "excerpt": "Ideas for future work \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9510747817213098
      ],
      "excerpt": "The list of camera models is as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9397342977836128
      ],
      "excerpt": "While the train data includes full images, the test data contains only single 512 x 512 pixel blocks cropped from the center of a single image taken with the device. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8735347457857296
      ],
      "excerpt": "gamma correction using gamma \\in {0.8, 1.2} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8979411005071259,
        0.8979411005071259,
        0.8979411005071259
      ],
      "excerpt": "  <img src=\"assets/data/(GalaxyN3)40.jpg\" height=\"88\" /> \n  <img src=\"assets/data/(GalaxyS4)62.jpg\" height=\"88\" /> \n  <img src=\"assets/data/(HTC-1-M7)7.jpg\" height=\"88\" /> \n  <img src=\"assets/data/(LG5x)15.jpg\" height=\"88\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8979411005071259,
        0.8979411005071259
      ],
      "excerpt": "  <img src=\"assets/data/(MotoX)32.jpg\" height=\"88\" /> \n  <img src=\"assets/data/(Nex7)7.jpg\" height=\"88\" /> \n  <img src=\"assets/data/(iP4s)39.jpg\" height=\"88\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127,
        0.846037921797282
      ],
      "excerpt": "random crops 256x256 with horizontal mirroring \nnaturally, use the above augmentations (random JPG compression, resizing, or gamma correction), to make the model robust to those manipulations \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.966476809851564,
        0.8260845836476348
      ],
      "excerpt": "SGD+m worked better (converged to deeper minima) for these ResNet-like architectures, but also tried Adam \nimplement and use stratified mini-batch variants of SGD (by class and eventually also by is_manip) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8163922690287965
      ],
      "excerpt": "after a simple baseline using DenseNet-121 + ResNet-{34,50} and having 0.913 (public LB) is built, build a stronger validation set: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.808870170738007,
        0.8851835923870498
      ],
      "excerpt": "also generate pseudo-labels: use the most confident predictions on a test set as \"ground truth\" and add them to the validation set (helps when there is some train/test data distribution mismatch, as in this case) \n<!-- * validation set: [TODO: insert image of the confusion matrix] --> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8923696058867976
      ],
      "excerpt": "try larger architectures: DenseNet-201, ResNet-{101, 152}, ResNext-101({32, 64}) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.90975679907611
      ],
      "excerpt": "use external data :P from Flickr and other resources (+ check metadata in extensions to find out the device) to construct a lot larger dataset, [kaggle discussion], filter data in the [notebook] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8695629355159592,
        0.9440124981502432
      ],
      "excerpt": "add new pseudo-labels, all in stratified manner \ngenerate and save random crops in large blocks, for faster reading from HDD (+ other approaches like saving to lmdb database can be found in the notebook) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8838801755130061
      ],
      "excerpt": "add new data (from artgor), generate new validation set and update pseudo-labels [notebook] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8720741895353464,
        0.8219741824288643,
        0.880487292649074,
        0.9852658835608986
      ],
      "excerpt": "add is_manip flag to FC \n:bangbang: implement and use Distillation learning [arXiv], in order to train some of the new models really fast by matching logits with strong models early in the training \ntest-time augmentation (TTA): 2/3 * FiveCrops (center and corners) + 1/3 * rot90, the idea is that almost nobody takes the photo upside down (so rot180 and rot270 are quite unlikely) \ncombine predictions of multiple models using arithmetic averaging of the logits \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8779327092689988
      ],
      "excerpt": "concluded after a couple of submissions with one class only, and getting exactly 0.1 on public LB \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.995614800050059,
        0.8625521916995268
      ],
      "excerpt": "special preprocessing, or special ordering of patches according to their complexity or informativity (a variant of \"curriculum learning\"), for more details please refer to [paper] and [notebook] \ncentral crops 256x256 (even with rotations and/or horizontal mirroring) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9520725147577018
      ],
      "excerpt": "random \"optical\" crops (rotate patches such that the optical center is always in the same, predetermined corner) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9812488966753166,
        0.8669051504413124,
        0.8312925547634191,
        0.9968029537584643,
        0.9968029537584643,
        0.8988568620907625,
        0.8988568620907625,
        0.9348148791172595,
        0.8716303182905796,
        0.8716303182905796
      ],
      "excerpt": "the whole D4 group of transformations \nother variants of combining predictions from multiple models: \narithmetic, geometric average of probabilities \nmedian of probabilities, logits \nweighted median of probabilities, logits \narithmetic average of sqrt(proba) \narithmetic average of proba ** 2 \narithmetic average of softmax(logits * C), C \\in {0.5, 2.0} \narithmetic average of g(logits), where g(x) = sqrt(|x|) * sign(x) \narithmetic average of softmax(g(logits)), where g(x) = sqrt(|x|) * sign(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9625423703795246
      ],
      "excerpt": "ensemble of various architectures trained using different initialization, hyperparameters, preprocessing, TTA, losses, optimizers, LR schedules, stages of training (checkpoints), etc. throughout the project (most of which are not as powerful as the best single one), in total 33 models: 0.979 (private LB) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9674307195172345
      ],
      "excerpt": "top1 solution: 0.989, using 350GB of data and 20 GPUs :scream: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9266035140522663
      ],
      "excerpt": "To get the most out of my limited resources, I have implemented a Telegram bot, that can quickly: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8133131004225689
      ],
      "excerpt": "stratified split not only by a class (and is_manip) but also by a scene \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.851633611002633,
        0.8647552318144451,
        0.8384325949549184
      ],
      "excerpt": "play around with low-level features from CNNs (e.g. train k-NN on top of those) \nincorporate FFT-based features (on, e.g. image - smooth(image)) \nstack with xgboost :muscle: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "My solution to Kaggle challenge \"IEEE Camera Model Identification\" [top 3%]",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yell/kaggle-camera/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The task was to identify the camera that the image was taken with.\n<!-- * given dataset of photos taken from different cameras (iPhone, Galaxy Note, LG Nexus etc.) -->\n<!-- * goal is to classify camera model -->\n<!-- * random subset is preprocessed using \\{JPG compression, gamma correction, resizing\\} -->\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Fri, 24 Dec 2021 14:09:52 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yell/kaggle-camera/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "yell/kaggle-camera",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/yell/kaggle-camera/master/notebooks/gen_balanced2.ipynb",
      "https://raw.githubusercontent.com/yell/kaggle-camera/master/notebooks/plot_curves.ipynb",
      "https://raw.githubusercontent.com/yell/kaggle-camera/master/notebooks/gen_data.ipynb",
      "https://raw.githubusercontent.com/yell/kaggle-camera/master/notebooks/gen_info_patches.ipynb",
      "https://raw.githubusercontent.com/yell/kaggle-camera/master/notebooks/andreas_data.ipynb",
      "https://raw.githubusercontent.com/yell/kaggle-camera/master/notebooks/subm_tools.ipynb",
      "https://raw.githubusercontent.com/yell/kaggle-camera/master/notebooks/svm.ipynb",
      "https://raw.githubusercontent.com/yell/kaggle-camera/master/notebooks/gen_balanced.ipynb",
      "https://raw.githubusercontent.com/yell/kaggle-camera/master/notebooks/tmp.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/yell/kaggle-camera/master/src/robust_run.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9370043855230743
      ],
      "excerpt": "HTC One M7 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8244453191770256
      ],
      "excerpt": "Samsung Galaxy Note 3 \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8082485413276425
      ],
      "excerpt": "Images in the training set were captured with 10 different camera models, a single device per model, with 275 full images from each device. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8181371888125193
      ],
      "excerpt": "Images in the test set were captured with the same 10 camera models, but using a second device. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8325453422004395
      ],
      "excerpt": "Random samples from the training set: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9384439660863191,
        0.9384439660863191,
        0.9384439660863191,
        0.95220635326504,
        0.9131730152931203,
        0.9187270778963661,
        0.9384439660863191,
        0.9384439660863191,
        0.9367968149750019
      ],
      "excerpt": "  <img src=\"assets/data/(GalaxyN3)40.jpg\" height=\"88\" /> \n  <img src=\"assets/data/(GalaxyS4)62.jpg\" height=\"88\" /> \n  <img src=\"assets/data/(HTC-1-M7)7.jpg\" height=\"88\" /> \n  <img src=\"assets/data/(LG5x)15.jpg\" height=\"88\" /> \n  <img src=\"assets/data/(MotoMax)18.jpg\" height=\"88\" /> \n  <img src=\"assets/data/(MotoX)32.jpg\" height=\"88\" /> \n  <img src=\"assets/data/(Nex7)7.jpg\" height=\"88\" /> \n  <img src=\"assets/data/(iP4s)39.jpg\" height=\"88\" /> \n  <img src=\"assets/data/(iP6)75.jpg\" height=\"88\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8339817901236238
      ],
      "excerpt": "train models from scratch: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.897953614168866,
        0.898518743968793,
        0.9263937148564289
      ],
      "excerpt": "  <img src=\"assets/final_model.png\" height=\"194\" /> \n  <img src=\"assets/cm.jpg\" height=\"194\" /> \n  <img src=\"assets/lc.jpg\" height=\"194\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9263937148564289,
        0.9263937148564289,
        0.9263937148564289
      ],
      "excerpt": "  <img src=\"assets/telegram_bot1.jpg\" height=\"204\" /> \n  <img src=\"assets/telegram_bot2.jpg\" height=\"204\" /> \n  <img src=\"assets/telegram_bot3.jpg\" height=\"204\" /> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yell/kaggle-camera/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Makefile",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Yelysei Bondarenko\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "kaggle-camera",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "kaggle-camera",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "yell",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yell/kaggle-camera/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Fri, 24 Dec 2021 14:09:52 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "camera",
      "classification",
      "computer-vision",
      "deep-learning",
      "densenet",
      "densenet-pytorch",
      "ensemble",
      "ensemble-learning",
      "ensemble-stacking",
      "kaggle",
      "kaggle-competition",
      "machine-learning",
      "pytorch",
      "resnet",
      "resnext",
      "stacking"
    ],
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1810.04805\n4. https://gluebenchmark.com/fa"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. https://github.com/google-research/bert\n2. https://github.com/huggingface/pytorch-pretrained-BERT\n3. https://arxiv.org/abs/1810.04805\n4. https://gluebenchmark.com/faq",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/weidafeng/NLU2019",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-09T07:49:07Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-07-03T18:00:40Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9834237758409213
      ],
      "excerpt": "NLU2019 project: Question NLI. The task is to determine whether the context sentence contains the answer to the question (entailment or not entailment). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9461715864660704
      ],
      "excerpt": "\u251c\u2500model     #: main code for this project \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "NLU2019 project: Question NLI. The task is to determine whether the context sentence contains the answer to the question (entailment or not entailment).",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/weidafeng/NLU2019/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Mon, 27 Dec 2021 10:02:39 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/weidafeng/NLU2019/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "weidafeng/NLU2019",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/weidafeng/NLU2019/master/test.sh",
      "https://raw.githubusercontent.com/weidafeng/NLU2019/master/train.sh"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8514304377178903
      ],
      "excerpt": "\u2502      \u2514\u2500results    #: path to store trained model('config.json  eval_results.txt  pytorch_model.bin  vocab.txt') and the prediction results(`QNLI.tsv`) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/weidafeng/NLU2019/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "NLU2019",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "NLU2019",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "weidafeng",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/weidafeng/NLU2019/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Mon, 27 Dec 2021 10:02:39 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Download dataset.\n```bash\n$ python download_glue_data.py --data_dir glue_data --tasks all\n```\nThis code borrowed from [here](https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e), you need using VPN to run it, or you can using my provided 'glue_data.zip' easily.\n\n2. Install `apex`.\n`apex` is a pyTorch extension: Tools for easy mixed precision and distributed training in Pytorch. The official repository is [here](https://github.com/NVIDIA/apex).\n```bash\n$ git clone https://github.com/NVIDIA/apex\n$ cd apex\n$ pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .\n```\n3. Install the necessary libary `pytorch-pretrained-bert`. \n```bash\n$ pip install pytorch-pretrained-bert\n```\n\n4. Clone this repository.\n```bash\n$ git clone https://github.com/weidafeng/NLU2019.git  \n$ cd NLU2019\n```\n\n5. Train. You will get the pretrained model flies('config.json  eval_results.txt  pytorch_model.bin  vocab.txt') in `glue_data/QNLI/eval_result`. \n```bash\n$ bash train.sh\n```\nHere is my results:\n```\nacc = 0.9110378912685337\neval_loss = 0.501230152572013\nglobal_step = 16370\nloss = 0.0006768958065624673\n```\n\n6. Predict. You will load the pretrained model to predict, and get the submission `QNLI.tsv` in  `glue_data/QNLI/eval_result`.\n```bash\n$ bash test.sh\n```\n\n7. Submission. Create a zip of the prediction TSVs, without any subfolders, e.g. using:\n```bash\n$ zip -r submission.zip *.tsv\n```\nHere is my glue result:\n![glue_result](GLUE_RESULTS.png)\nTrained model is too big to store in GitHub, if needed, please feel free to contact me.  \n\n",
      "technique": "Header extraction"
    }
  ]
}
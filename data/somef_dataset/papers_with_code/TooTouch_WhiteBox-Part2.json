{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1602.04938",
      "https://arxiv.org/abs/1309.6392",
      "https://arxiv.org/abs/1703.04730",
      "https://arxiv.org/abs/1309.6392](https://arxiv.org/abs/1309.6392)).\r\n\r\n- **Documentation** : [http://austinrochford.github.io/PyCEbox/docs/](http://austinrochford.github.io/PyCEbox/docs/)\r\n- **Github Repository** : [https://github.com/AustinRochford/PyCEbox](https://github.com/AustinRochford/PyCEbox)\r\n\r\n**Installation** \r\n\r\n```bash\r\n# Pip \r\npip install pycebox\r\n```\r\n\r\n```python\r\nimport pycebox\r\n```\r\n\r\n### rulefit\r\n\r\nImplementation of a rule based prediction algorithm based on [the rulefit algorithm from Friedman and Popescu (PDF)(http://statweb.stanford.edu/~jhf/ftp/RuleFit.pdf)]\r\n\r\n- **Github Repository** : [https://github.com/christophM/rulefit](https://github.com/christophM/rulefit)\r\n\r\n**Installation** \r\n\r\n```bash\r\n# Pip\r\npip install git+git://github.com/christophM/rulefit.git\r\n```\r\n\r\n```python\r\nimport rulefit\r\n```\r\n\r\n### skope-rules\r\n\r\nSkope-rules is a Python machine learning module built on top of scikit-learn and distributed under the 3-Clause BSD license.\r\n\r\nSkope-rules aims at learning logical, interpretable rules for \"scoping\" a target class, i.e. detecting with high precision instances of this class.\r\n\r\nSkope-rules is a trade off between the interpretability of a Decision Tree and the modelization power of a Random Forest.\r\n\r\n- **Documentation** : [https://skope-rules.readthedocs.io/en/latest/index.html](https://skope-rules.readthedocs.io/en/latest/index.html)\r\n- **Github Repository** : [https://github.com/scikit-learn-contrib/skope-rules](https://github.com/scikit-learn-contrib/skope-rules)\r\n\r\n**Installation**  \r\n\r\n```bash\r\n# Pip\r\npip install skope-rules\r\n```\r\n\r\n```python\r\nimport skrules\r\n```\r\n\r\n### alibi\r\n\r\nAlibi is an open source Python library aimed at machine learning model inspection and interpretation. The initial focus on the library is on black-box, instance based model explanations.\r\n\r\n\r\n- **Documentation** : [https://docs.seldon.io/projects/alibi/en/latest/#](https://docs.seldon.io/projects/alibi/en/latest/#)\r\n- **Github Repository** : [https://github.com/SeldonIO/alibi](https://github.com/SeldonIO/alibi)\r\n\r\n**Installation** \r\n\r\n```bash\r\n# Pip \r\npip install alibi\r\n```\r\n\r\n```python\r\nimport alibi\r\n```\r\n\r\n### influence-instance\r\n\r\nThis code replicates the experiments from the following paper:\r\n\r\n> Pang Wei Koh and Percy Liang\r\n[Understanding Black-box Predictions via Influence Functions](https://arxiv.org/abs/1703.04730)\r\nInternational Conference on Machine Learning (ICML), 2017.\r\n\r\nWe have a reproducible, executable, and Dockerized version of these scripts on [Codalab](https://worksheets.codalab.org/worksheets/0x2b314dc3536b482dbba02783a24719fd/).\r\n\r\nThe datasets for the experiments can also be found at the Codalab link.\r\n\r\n- **Github Repository** : [https://github.com/kohpangwei/influence-release](https://github.com/kohpangwei/influence-release)\r\n\r\n\r\n### shap\r\n\r\nSHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions (see [papers](https://github.com/slundberg/shap#citations) for details and citations).\r\n\r\n\r\n- **Documentation** : [https://shap.readthedocs.io/en/latest/#](https://shap.readthedocs.io/en/latest/#)\r\n- **Github Repository** : [https://github.com/slundberg/shap](https://github.com/slundberg/shap)\r\n\r\n**Installation** \r\n\r\n```bash\r\n# Pip\r\npip install shap\r\n# Conda\r\nconda install -c conda-forge shap\r\n```\r\n\r\n```python\r\nimport shap\r\n```\r\n\r\n### MMD-critic\r\n\r\nThis method is proposed in [this papaer](http://people.csail.mit.edu/beenkim/papers/KIM2016NIPS_MMD.pdf). \r\n\r\n**Abstract**  \r\nExample-based explanations are widely used in the effort to improve the interpretability of highly complex distributions. However, prototypes alone are rarely\r\nsufficient to represent the gist of the complexity. In order for users to construct\r\nbetter mental models and understand complex data distributions, we also need\r\ncriticism to explain what are not captured by prototypes. Motivated by the Bayesian\r\nmodel criticism framework, we develop MMD-critic which efficiently learns prototypes and criticism, designed to aid human interpretability. A human subject pilot\r\nstudy shows that the MMD-critic selects prototypes and criticism that are useful\r\nto facilitate human understanding and reasoning. We also evaluate the prototypes\r\nselected by MMD-critic via a nearest prototype classifier, showing competitive\r\nperformance compared to baselines.\r\n\r\n- **Github Repository** : [https://github.com/BeenKim/MMD-critic](https://github.com/BeenKim/MMD-critic)\r\n\r\n\r\n# Reference\r\n[1] Molnar, Christoph. \"Interpretable machine learning. A Guide for Making Black Box Models Explainable\", 2019. https://christophm.github.io/interpretable-ml-book/.\r\n\r\n[2] Kaggle Competiton : [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)\r\n\r\n[3] Kelwin Fernandes, Jaime S. Cardoso, and Jessica Fernandes. 'Transfer Learning with Partial Observability Applied to Cervical Cancer Screening.' Iberian Conference on Pattern Recognition and Image Analysis. Springer International Publishing, 2017. [[Link]](https://archive.ics.uci.edu/ml/datasets/Cervical+cancer+%28Risk+Factors%29)\r\n\r\n[4] Kaggle Competition : [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/description)\r\n\r\n[5] Fanaee-T, Hadi, and Gama, Joao, \"Event labeling combining ensemble detectors and background knowledge\", Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg. [[Link]](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)\r\n\r\n[6] Alberto, T.C., Lochter J.V., Almeida, T.A. TubeSpam: Comment Spam Filtering on YouTube. Proceedings of the 14th IEEE International Conference on Machine Learning and Applications (ICMLA'15), 1-6, Miami, FL, USA, December, 2015. [[Link]](http://www.dt.fee.unicamp.br/~tiago//youtubespamcollection/)\r\n\r\n[7] Lundberg, Scott M., and Su-In Lee. \u201c[A unified approach to interpreting model predictions.](https://arxiv.org/pdf/1705.07874.pdf)\u201d Advances in Neural Information Processing Systems. 2017. ([Korean Version](https://www.notion.so/tootouch/A-Unified-Approach-to-Interpreting-Model-Predictions-96de8a9e08b149c48cdd802cd62ad59f)"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] Molnar, Christoph. \"Interpretable machine learning. A Guide for Making Black Box Models Explainable\", 2019. https://christophm.github.io/interpretable-ml-book/.\r\n\r\n[2] Kaggle Competiton : [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)\r\n\r\n[3] Kelwin Fernandes, Jaime S. Cardoso, and Jessica Fernandes. 'Transfer Learning with Partial Observability Applied to Cervical Cancer Screening.' Iberian Conference on Pattern Recognition and Image Analysis. Springer International Publishing, 2017. [[Link]](https://archive.ics.uci.edu/ml/datasets/Cervical+cancer+%28Risk+Factors%29)\r\n\r\n[4] Kaggle Competition : [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/description)\r\n\r\n[5] Fanaee-T, Hadi, and Gama, Joao, \"Event labeling combining ensemble detectors and background knowledge\", Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg. [[Link]](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)\r\n\r\n[6] Alberto, T.C., Lochter J.V., Almeida, T.A. TubeSpam: Comment Spam Filtering on YouTube. Proceedings of the 14th IEEE International Conference on Machine Learning and Applications (ICMLA'15), 1-6, Miami, FL, USA, December, 2015. [[Link]](http://www.dt.fee.unicamp.br/~tiago//youtubespamcollection/)\r\n\r\n[7] Lundberg, Scott M., and Su-In Lee. \u201c[A unified approach to interpreting model predictions.](https://arxiv.org/pdf/1705.07874.pdf)\u201d Advances in Neural Information Processing Systems. 2017. ([Korean Version](https://www.notion.so/tootouch/A-Unified-Approach-to-Interpreting-Model-Predictions-96de8a9e08b149c48cdd802cd62ad59f))",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8283268420643993
      ],
      "excerpt": "Titanic: Machine Learning from Disaster (Classification) [2] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9559715772848645,
        0.8714162992508173
      ],
      "excerpt": "House Prices: Advanced Regression Techniques (Regression) [4] \nBike Sharing (Regression) [5] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "- Logistic Regression [ English , Korean ] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8611805266332359,
        0.8611805266332359,
        0.8611805266332359
      ],
      "excerpt": "Logistic Regression | scikit-learn statsmodels \nRidge Regression | scikit-learn statsmodels \nLasso Regression | scikit-learn statsmodels \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "Skope-rules | skope-rules \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8628057065201727,
        0.9624280557529529
      ],
      "excerpt": "Documentation : https://scikit-learn.org/stable/   \nGithub Repository : https://github.com/scikit-learn/scikit-learn \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9683244338442518
      ],
      "excerpt": "Github Repository : https://github.com/statsmodels/statsmodels \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9683244338442518
      ],
      "excerpt": "Github Repository : https://github.com/dswah/pyGAM \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9683244338442518
      ],
      "excerpt": "Github Repository : https://github.com/oracle/Skater \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8352440616959736
      ],
      "excerpt": ": Option 1: without rule lists and without deepinterpreter \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9683244338442518
      ],
      "excerpt": "Github Repository : https://github.com/SauceCat/PDPbox \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9683244338442518
      ],
      "excerpt": "Github Repository : https://github.com/marcotcr/lime \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9683244338442518
      ],
      "excerpt": "Github Repository : https://github.com/AustinRochford/PyCEbox \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9683244338442518
      ],
      "excerpt": "Github Repository : https://github.com/christophM/rulefit \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9860793263092326
      ],
      "excerpt": "Github Repository : https://github.com/scikit-learn-contrib/skope-rules \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9683244338442518
      ],
      "excerpt": "Github Repository : https://github.com/SeldonIO/alibi \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9771296815471594
      ],
      "excerpt": "Pang Wei Koh and Percy Liang \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999745070427066
      ],
      "excerpt": "International Conference on Machine Learning (ICML), 2017. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9809845813829983
      ],
      "excerpt": "Github Repository : https://github.com/kohpangwei/influence-release \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9683244338442518
      ],
      "excerpt": "Github Repository : https://github.com/slundberg/shap \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TooTouch/WhiteBox-Part2",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-12-11T16:10:53Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-09T20:22:30Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9648398225259935
      ],
      "excerpt": "The White Box Project is a project that introduces many ways to solve the part of the black box of machine learning. This project is based on Interpretable Machine Learning by Christoph Molnar [1]. I recommend you to read the book first and practice this project. If you are R user, you can see R code used in examples here.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9428630496397955
      ],
      "excerpt": "The goal is to analysis various data into black box models and to build a pipeline of analysis reports using interpretable methods. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9130300278081752
      ],
      "excerpt": "The parameters used to learn the model can be found here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9539756471316176
      ],
      "excerpt": "- GLM, GAM and more [ English , Korean ] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008361265821616
      ],
      "excerpt": "Model-agnostic methods [ English , Korean ] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9004606014250315,
        0.8730057622428616,
        0.8730057622428616,
        0.8730057622428616
      ],
      "excerpt": "Linear Regression | scikit-learn statsmodels \nLogistic Regression | scikit-learn statsmodels \nRidge Regression | scikit-learn statsmodels \nLasso Regression | scikit-learn statsmodels \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9159643228425749
      ],
      "excerpt": "Decision Tree | scikit-learn \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008361265821616
      ],
      "excerpt": "Model-Agnostic Methods \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8150771532802734
      ],
      "excerpt": "Contrastive Explanations Method (CEM) | alibi \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9932889851126574,
        0.9954221510608455,
        0.9899834309588189
      ],
      "excerpt": "scikit-learn is a Python module for machine learning built on top of SciPy and is distributed under the 3-Clause BSD license. \nThe project was started in 2007 by David Cournapeau as a Google Summer of Code project, and since then many volunteers have contributed. See the About us page for a list of core contributors. \nIt is currently maintained by a team of volunteers. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8778319306113614
      ],
      "excerpt": "Github Repository : https://github.com/scikit-learn/scikit-learn \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9824951552818816
      ],
      "excerpt": "statsmodels is a Python module that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration. An extensive list of result statistics are available for each estimator. The results are tested against existing statistical packages to ensure that they are correct. The package is released under the open source Modified BSD (3-clause) license. The online documentation is hosted at statsmodels.org. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9917699404734955
      ],
      "excerpt": "pyGAM is a package for building Generalized Additive Models in Python, with an emphasis on modularity and performance. The API will be immediately familiar to anyone with experience of scikit-learn or scipy. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9867630074779074
      ],
      "excerpt": "Skater is a open source unified framework to enable Model Interpretation for all forms of model to help one build an Interpretable machine learning system often needed for real world use-cases. Skater supports algorithms to demystify the learned structures of a black box model both globally(inference on the basis of a complete data set) and locally(inference about an individual prediction). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9976814499348811
      ],
      "excerpt": "This repository is inspired by ICEbox. The goal is to visualize the impact of certain features towards model prediction for any supervised learning algorithm using partial dependence plots R1 R2. PDPbox now supports all scikit-learn algorithms. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9967559846017726
      ],
      "excerpt": "This project is about explaining what machine learning classifiers (or models) are doing. At the moment, we support explaining individual predictions for text classifiers or classifiers that act on tables (numpy arrays of numerical or categorical data) or images, with a package called lime (short for local interpretable model-agnostic explanations). Lime is based on the work presented in this paper (bibtex here for citation). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9586250399181493
      ],
      "excerpt": "Implementation of a rule based prediction algorithm based on [the rulefit algorithm from Friedman and Popescu (PDF)(http://statweb.stanford.edu/~jhf/ftp/RuleFit.pdf)] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9878183117901799,
        0.8575101937519363,
        0.9879263076778018
      ],
      "excerpt": "Skope-rules is a Python machine learning module built on top of scikit-learn and distributed under the 3-Clause BSD license. \nSkope-rules aims at learning logical, interpretable rules for \"scoping\" a target class, i.e. detecting with high precision instances of this class. \nSkope-rules is a trade off between the interpretability of a Decision Tree and the modelization power of a Random Forest. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9288519386549838
      ],
      "excerpt": "Alibi is an open source Python library aimed at machine learning model inspection and interpretation. The initial focus on the library is on black-box, instance based model explanations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9194242736408846,
        0.8644506745312748
      ],
      "excerpt": "We have a reproducible, executable, and Dockerized version of these scripts on Codalab. \nThe datasets for the experiments can also be found at the Codalab link. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9962065203953084
      ],
      "excerpt": "SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions (see papers for details and citations). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9378608803992878
      ],
      "excerpt": "This method is proposed in this papaer.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8607769349496476,
        0.9855338816133762,
        0.8540280828696912,
        0.8326715013057511,
        0.9600425804991428
      ],
      "excerpt": "Example-based explanations are widely used in the effort to improve the interpretability of highly complex distributions. However, prototypes alone are rarely \nsufficient to represent the gist of the complexity. In order for users to construct \nbetter mental models and understand complex data distributions, we also need \ncriticism to explain what are not captured by prototypes. Motivated by the Bayesian \nmodel criticism framework, we develop MMD-critic which efficiently learns prototypes and criticism, designed to aid human interpretability. A human subject pilot \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9556202167511356
      ],
      "excerpt": "to facilitate human understanding and reasoning. We also evaluate the prototypes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "The White Box Project is a project that introduces many ways to solve the part of the black box of machine learning. This project is based on Interpretable Machine Learning by Christoph Molnar. I recommend you to read the book first and practice this project.",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://shap.readthedocs.io/",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://pdpbox.readthedocs.io/",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://pygam.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TooTouch/WhiteBox-Part2/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Tue, 21 Dec 2021 01:14:44 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/TooTouch/WhiteBox-Part2/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "TooTouch/WhiteBox-Part2",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/TooTouch/WhiteBox-Part2/master/notebook/1.%20Titanic%20.ipynb",
      "https://raw.githubusercontent.com/TooTouch/WhiteBox-Part2/master/notebook/3.%20Bike%20Sharing.ipynb",
      "https://raw.githubusercontent.com/TooTouch/WhiteBox-Part2/master/notebook/2.%20Cervical%20Cancer.ipynb",
      "https://raw.githubusercontent.com/TooTouch/WhiteBox-Part2/master/notebook/4.%20House%20Price.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9360405396743131
      ],
      "excerpt": "Name | Packages  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9360405396743131
      ],
      "excerpt": "Name | Packages \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9360405396743131
      ],
      "excerpt": "Name | Packages \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8115078802567282,
        0.9769420979004304,
        0.9736629876602173,
        0.9925302469065281,
        0.9666866584681653,
        0.9731157464807427
      ],
      "excerpt": "Github Repository : https://github.com/scikit-learn/scikit-learn \nInstallation  \n: Pip \npip install -U scikit-learn \n: Conda \nonda install scikit-learn \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9769420979004304,
        0.9736629876602173,
        0.999746712887969,
        0.9666866584681653,
        0.996714160028586
      ],
      "excerpt": "Installation   \n: Pip \npip install statsmodels  \n: Conda \nconda install -c conda-forge statsmodels \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9769420979004304,
        0.9736629876602173,
        0.999746712887969,
        0.9666866584681653,
        0.996714160028586
      ],
      "excerpt": "Installation   \n: Pip \npip install pygam \n: Conda \nconda install -c conda-forge pygam \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9769420979004304
      ],
      "excerpt": "Installation  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.999746712887969
      ],
      "excerpt": "pip install -U skater \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9659160123059422,
        0.9977324693697311,
        0.999746712887969
      ],
      "excerpt": "pip3 install --upgrade tensorflow  \nsudo pip install keras \npip install -U skater \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9700763384591553,
        0.9659160123059422,
        0.9977324693697311,
        0.983243642407086,
        0.9666866584681653,
        0.996714160028586
      ],
      "excerpt": "conda install gxx_linux-64 \npip3 install --upgrade tensorflow  \nsudo pip install keras \nsudo pip install -U --no-deps --force-reinstall --install-option=\"--rl=True\" skater==1.1.1b1 \n: Conda \nconda install -c conda-forge Skater \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9769420979004304,
        0.9736629876602173,
        0.999746712887969
      ],
      "excerpt": "Installation   \n: Pip \npip install pdpbox \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9769420979004304,
        0.9736629876602173,
        0.9795559624479138
      ],
      "excerpt": "Installation   \n: Pip \npip install lime \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9769420979004304,
        0.9736629876602173,
        0.999746712887969
      ],
      "excerpt": "Installation  \n: Pip \npip install pycebox \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9769420979004304,
        0.9736629876602173,
        0.9955989939522428
      ],
      "excerpt": "Installation  \n: Pip \npip install git+git://github.com/christophM/rulefit.git \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8062349492071952,
        0.9769420979004304,
        0.9736629876602173,
        0.9813186167050844
      ],
      "excerpt": "Github Repository : https://github.com/scikit-learn-contrib/skope-rules \nInstallation   \n: Pip \npip install skope-rules \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9769420979004304,
        0.9736629876602173,
        0.999746712887969
      ],
      "excerpt": "Installation  \n: Pip \npip install alibi \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8399080433634416
      ],
      "excerpt": "Github Repository : https://github.com/kohpangwei/influence-release \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9769420979004304,
        0.9736629876602173,
        0.999746712887969,
        0.9666866584681653,
        0.996714160028586
      ],
      "excerpt": "Installation  \n: Pip \npip install shap \n: Conda \nconda install -c conda-forge shap \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import sklearn \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import statsmodels \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import pygam \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import skater \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import pdpbox \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8304564227643287
      ],
      "excerpt": "import lime \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import pycebox \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import rulefit \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import skrules \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import alibi \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import shap \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/TooTouch/WhiteBox-Part2/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Batchfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 bllfpc\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "WhiteBox-Part2",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "WhiteBox-Part2",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "TooTouch",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TooTouch/WhiteBox-Part2/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n```\r\nnumpy == 1.17.3\r\nscikit-learn == 0.21.2\r\nxgboost == 0.90\r\ntensorflow == 1.14.0\r\n```\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Tue, 21 Dec 2021 01:14:44 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "xai",
      "explainable-ai",
      "tabular-data",
      "machine-learning",
      "blackbox"
    ],
    "technique": "GitHub API"
  }
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The author would like to thank [Tong Xiao](https://tongxiao2000.github.io/) for the inspiring discussions and her help in implementing the codes and the experiments.\n\nThe code structure is based on the repo [gail-airl-ppo.pytorch](https://github.com/ku2482/gail-airl-ppo.pytorch).\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2110.14754",
      "https://arxiv.org/abs/1710.11248",
      "https://arxiv.org/abs/1707.06347",
      "https://arxiv.org/abs/1801.01290",
      "https://arxiv.org/abs/1707.06347*, 2017.\n\n[[6]](https://arxiv.org/abs/1801.01290) Haarnoja, T., Zhou, A., Abbeel, P., and Levine, S. Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor.  In *International Conference on Machine Learning*, pp. 1861\u20131870. PMLR, 2018.\n\n[[7]](http://proceedings.mlr.press/v100/brown20a/brown20a.pdf) Daniel S Brown, Wonjoon Goo, and Scott Niekum. Better-than-demonstrator imitation learning via automatically-ranked demonstrations. In *Conference on Robot Learning*, pages 330\u2013359. PMLR, 2020.\n\n[[8]](https://arxiv.org/pdf/2010.11723.pdf) Letian Chen, Rohan Paleja, and Matthew Gombolay. Learning from suboptimal demonstration via self-supervised reward regression. In *Conference on Robot Learning*. PMLR, 2020."
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[[1]](http://papers.nips.cc/paper/6391-generative-adversarial-imitation-learning) Ho, J. and Ermon, S. Generative adversarial imitation learning. In *Advances in neural information processing systems*, pp. 4565\u20134573, 2016.\n\n[[2]](https://arxiv.org/abs/1710.11248) Fu, J., Luo, K., and Levine, S. Learning robust rewards with adversarial inverse reinforcement learning.  In *International Conference on Learning Representations*, 2018.\n\n[[3]](http://proceedings.mlr.press/v97/wu19a/wu19a.pdf) Wu, Y.-H., Charoenphakdee, N., Bao, H., Tangkaratt, V.,and Sugiyama,  M. Imitation learning from imperfect demonstration. In *International Conference on Machine Learning*, pp. 6818\u20136827, 2019.\n\n[[4]](http://proceedings.mlr.press/v97/brown19a/brown19a.pdf) Brown, D., Goo, W., Nagarajan, P., and Niekum, S. Extrapolating beyond suboptimal demonstrations via inversere inforcement learning from observations. In *International Conference on Machine Learning*, pp. 783\u2013792. PMLR, 2019.\n\n[[5]](https://arxiv.org/abs/1707.06347) Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O. Proximal policy optimization algorithms. *arXiv preprint arXiv:1707.06347*, 2017.\n\n[[6]](https://arxiv.org/abs/1801.01290) Haarnoja, T., Zhou, A., Abbeel, P., and Levine, S. Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor.  In *International Conference on Machine Learning*, pp. 1861\u20131870. PMLR, 2018.\n\n[[7]](http://proceedings.mlr.press/v100/brown20a/brown20a.pdf) Daniel S Brown, Wonjoon Goo, and Scott Niekum. Better-than-demonstrator imitation learning via automatically-ranked demonstrations. In *Conference on Robot Learning*, pages 330\u2013359. PMLR, 2020.\n\n[[8]](https://arxiv.org/pdf/2010.11723.pdf) Letian Chen, Rohan Paleja, and Matthew Gombolay. Learning from suboptimal demonstration via self-supervised reward regression. In *Conference on Robot Learning*. PMLR, 2020.\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@inproceedings{zhang2021cail,\n title={Confidence-Aware Imitation Learning from Demonstrations with Varying Optimality},\n author={Zhang, Songyuan and Cao, Zhangjie and Sadigh, Dorsa and Sui, Yanan},\n booktitle={Conference on Neural Information Processing Systems (NeurIPS)},\n year={2021}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{zhang2021cail,\n title={Confidence-Aware Imitation Learning from Demonstrations with Varying Optimality},\n author={Zhang, Songyuan and Cao, Zhangjie and Sadigh, Dorsa and Sui, Yanan},\n booktitle={Conference on Neural Information Processing Systems (NeurIPS)},\n year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8848854726480223
      ],
      "excerpt": "Official implementation of the NeurIPS 2021 paper: S Zhang, Z Cao, D  Sadigh, Y Sui: \"Confidence-Aware Imitation Learning from Demonstrations  with Varying Optimality\". \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8579249465852096
      ],
      "excerpt": "    <img src=\"./figs/results.png\" alt=\"results\" style=\"zoom:33%;\" > \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/syzhang092218-source/Confidence-Aware-Imitation-Learning",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-05T18:40:39Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-29T11:27:38Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8323809184134914
      ],
      "excerpt": "Official implementation of the NeurIPS 2021 paper: S Zhang, Z Cao, D  Sadigh, Y Sui: \"Confidence-Aware Imitation Learning from Demonstrations  with Varying Optimality\". \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8474306953883979
      ],
      "excerpt": "        Figure 1: Framework of CAIL. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8863784836714237,
        0.967332965767213
      ],
      "excerpt": "You need to collect demonstraions using trained experts' weights.  --algo specifies the expert's algorithm, For example, if you train an expert with ppo, you need to use --algo ppo while collecting demonstrations. The experts' weights we provide are trained by PPO for Ant-v2, and SAC for Reacher-v2. --std specifies the standard deviation of the gaussian noise add to the action, and --p-rand specifies the probability the expert acts randomly. We set std to $0.01$ not to collect too similar trajectories. \nUse the following line to collect demonstrations. In our experiments, we set the size of the buffers to contain 200 trajectories in the buffer, generated by 5 different policies. So the buffer size for Ant-v2 is 40000 each policy, and 2000 for Reacher-v2 each policy.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8528022290468921
      ],
      "excerpt": "The mixed buffers we used in our experiments can be downloaded here. For Linux users, we recommend to use the following commands: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9803679832903155,
        0.8871610525276878
      ],
      "excerpt": "Note that --label means the ratio of trajectories labeled with trajectory rewards. In our paper, we let 5% trajectories be labeled. \nHere we also provide the implementation of the baselines: Generative Adversarial Imitation Learning (GAIL) [1], Adversarial Inverse Reinforcement Learning (AIRL) [2], Two-step Importance Weighting Imitation Learning (2IWIL) [3], Generative Adversarial Imitation Learning with Imperfect demonstration and Confidence (IC-GAIL) [3], Trajectory-ranked Reward Extrapolation (T-REX) [4], Disturbance-based Reward Extrapolation (D-REX) [7], Self-Supervised Reward Regression (SSRR) [8]. In our paper, we train each algorithm 10 times use random seeds 0~9.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.883643621015829
      ],
      "excerpt": "        Figure 2: Results of different algorithms in two environments. Left: Reacher-v2. Right: Ant-v2. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9550277858065086,
        0.8150771532802734
      ],
      "excerpt": "The numerical results of the converged policies are here in the table: \n| Method  |        Reacher-v2         |            Ant-v2             | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9657828969794632
      ],
      "excerpt": "We also show the gifs of the demonstrations and trained agents: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Official implementation of the NeurIPS 2021 paper: S Zhang, Z Cao, D Sadigh, Y Sui: \"Confidence-Aware Imitation Learning from Demonstrations with Varying Optimality\"",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/syzhang092218-source/Confidence-Aware-Imitation-Learning/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Tue, 28 Dec 2021 15:55:36 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/syzhang092218-source/Confidence-Aware-Imitation-Learning/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "syzhang092218-source/Confidence-Aware-Imitation-Learning",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Install CAIL: First clone this repo, then run\n\n```bash\npip install -e .\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.824055635628019
      ],
      "excerpt": "For example, you can use the following line to train an expert: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8902627162932362
      ],
      "excerpt": "mkdir buffers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8228638474642014
      ],
      "excerpt": "You can create a mixture of demonstrations using the collected demonstrations in the previous step. Use the following command to mix the demonstrations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9175701505708982,
        0.999746712887969,
        0.9906248903846466
      ],
      "excerpt": "The mixed buffers we used in our experiments can be downloaded here. For Linux users, we recommend to use the following commands: \npip install gdown \ncd buffers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8644500257064217,
        0.8481145459886135,
        0.9906248903846466,
        0.9443507607855038
      ],
      "excerpt": "tar -zxvf buffers.tar.gz \nrm buffers.tar.gz \ncd .. \nYou can train IL using the following line: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8133710122517748
      ],
      "excerpt": "    <img src=\"./figs/CAIL_framework.png\" alt=\"CAIL_framework\" style=\"zoom:33%;\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8206517126890607
      ],
      "excerpt": "python train_expert.py --env-id Ant-v2 --algo ppo --num-steps 10000000 --eval-interval 100000 --rollout 10000 --seed 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8554268600507056
      ],
      "excerpt": "First, create a folder for demonstrations: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8904242791109321
      ],
      "excerpt": "python collect_demo.py --weight \"./weights/Ant-v2/10000000.pkl\" --env-id Ant-v2 --buffer-size 40000 --algo ppo --std 0.01 --p-rand 0.0 --seed 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8340266787617088
      ],
      "excerpt": "python mix_demo.py --env-id Ant-v2 --folder \"./buffers/Raw/Ant-v2\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8817960786976727
      ],
      "excerpt": "python train_imitation.py --algo cail --env-id Ant-v2 --buffer \"./buffers/Ant-v2/size200000_reward_4787.23_3739.91_2947.49_2115.17_789.13.pth\" --rollout-length 10000 --num-steps 20000000 --eval-interval 40000 --label 0.05 --lr-conf 0.1 --pre-train 5000000 --seed 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8126880977287783
      ],
      "excerpt": "python train_imitation.py --env-id Ant-v2 --buffer \"./buffers/Ant-v2/size200000_reward_4787.23_3739.91_2947.49_2115.17_789.13.pth\" --rollout-length 10000 --num-steps 20000000 --eval-interval 40000 --label 0.05 --algo ssrr --airl-actor \"./weights/SSRR_base/Ant-v2/seed0/actor.pkl\" --airl-disc \"./weights/SSRR_base/Ant-v2/seed0/disc.pkl\" --seed 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.818087165530499
      ],
      "excerpt": "python make_gif.py --env-id Reacher-v2 --weight \"./weights/Pretrained/Reacher-v2/cail/actor_0.pkl\" --algo cail --episodes 5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8236795295491531,
        0.8133710122517748
      ],
      "excerpt": "    <img src=\"./figs/results.png\" alt=\"results\" style=\"zoom:33%;\" > \n    <img src=\"./figs/legend.png\" alt=\"legend\" style=\"zoom:33%;\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296
      ],
      "excerpt": "    <img src=\"./figs/Reacher-v2/sac_5000.gif\" alt=\"sac_5000\" style=\"zoom:75%;\" > \n    <img src=\"./figs/Reacher-v2/sac_10000.gif\" alt=\"sac_10000\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Reacher-v2/sac_11000.gif\" alt=\"sac_11000\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Reacher-v2/sac_12000.gif\" alt=\"sac_12000\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Reacher-v2/sac_100000.gif\" alt=\"sac_100000\" style=\"zoom:75%;\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296
      ],
      "excerpt": "    <img src=\"./figs/Reacher-v2/cail_actor_0.gif\" alt=\"cail\" style=\"zoom:75%;\" > \n    <img src=\"./figs/Reacher-v2/2iwil_actor_0.gif\" alt=\"2iwil\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Reacher-v2/icgail_actor_0.gif\" alt=\"icgail\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Reacher-v2/airl_actor_0.gif\" alt=\"airl\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Reacher-v2/gail_actor_0.gif\" alt=\"gail\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Reacher-v2/trex_actor_0.gif\" alt=\"trex\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Reacher-v2/drex_actor_0.gif\" alt=\"drex\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Reacher-v2/ssrr_actor_0.gif\" alt=\"ssrr\" style=\"zoom:75%;\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296
      ],
      "excerpt": "    <img src=\"./figs/Ant-v2/ppo_2000000.gif\" alt=\"ppo_2000000\" style=\"zoom:75%;\" > \n    <img src=\"./figs/Ant-v2/ppo_3000000.gif\" alt=\"ppo_3000000\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Ant-v2/ppo_3500000.gif\" alt=\"ppo_3500000\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Ant-v2/ppo_5000000.gif\" alt=\"ppo_5000000\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Ant-v2/ppo_10000000.gif\" alt=\"ppo_10000000\" style=\"zoom:75%;\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296,
        0.8057013790765296
      ],
      "excerpt": "    <img src=\"./figs/Ant-v2/cail_actor_0.gif\" alt=\"cail\" style=\"zoom:75%;\" > \n    <img src=\"./figs/Ant-v2/2iwil_actor_0.gif\" alt=\"2iwil\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Ant-v2/icgail_actor_0.gif\" alt=\"icgail\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Ant-v2/airl_actor_0.gif\" alt=\"airl\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Ant-v2/gail_actor_0.gif\" alt=\"gail\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Ant-v2/trex_actor_0.gif\" alt=\"trex\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Ant-v2/drex_actor_0.gif\" alt=\"drex\" style=\"zoom:75%;\"> \n    <img src=\"./figs/Ant-v2/ssrr_actor_0.gif\" alt=\"ssrr\" style=\"zoom:75%;\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/syzhang092218-source/Confidence-Aware-Imitation-Learning/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Songyuan Zhang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Confidence-Aware Imitation Learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Confidence-Aware-Imitation-Learning",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "syzhang092218-source",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/syzhang092218-source/Confidence-Aware-Imitation-Learning/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You need to have the following libraries with [Python3](https://www.python.org/):\n\n- [MuJoCo](http://www.mujoco.org/) (This should be installed first)\n- [Matplotlib](https://matplotlib.org/)\n- [NumPy](https://numpy.org/)\n- [Gym](https://gym.openai.com/)\n- [tqdm](https://tqdm.github.io/)\n- [PyTorch](https://pytorch.org/)\n- [TensorBoard](https://www.tensorflow.org/tensorboard)\n- [mujoco_py](https://github.com/openai/mujoco-py)\n- [SciPy](https://scipy.org/)\n- [pandas](https://pandas.pydata.org/)\n\nTo install requirements:\n\n```bash\nconda create -n cail python=3.6\nconda activate cail\npip install -r requirements.txt\n```\n\nNote that you need to install [MuJoCo](http://www.mujoco.org/) on your device first. Please follow the instructions in [mujoco-py](https://github.com/openai/mujoco-py\n) for help.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Tue, 28 Dec 2021 15:55:36 GMT"
    },
    "technique": "GitHub API"
  }
}
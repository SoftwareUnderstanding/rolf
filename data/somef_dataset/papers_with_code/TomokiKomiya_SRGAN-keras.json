{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1609.05158\n    https://github.com/twairball/keras-subpixel-conv\n    \n    Improved Techniques for Training GANs:\n    https://arxiv.org/abs/1606.03498\n    \n\n\n               ",
      "https://arxiv.org/abs/1606.03498\n    \n\n\n               "
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9954557524638179
      ],
      "excerpt": "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network: https://arxiv.org/pdf/1609.04802.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8504479146659838
      ],
      "excerpt": "Help on GANS: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9258753804512773
      ],
      "excerpt": "Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network: https://arxiv.org/abs/1609.05158 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TomokiKomiya/SRGAN-keras",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-08T06:15:31Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-02T08:33:20Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.953194413888548
      ],
      "excerpt": "For more about topic check Single Image Super Resolution Using GANs\u200a\u2014\u200aKeras \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9596713269570545,
        0.9893482167181228,
        0.856219734318596
      ],
      "excerpt": "* PixelShuffler x2: This is feature map upscaling. 2 sub-pixel CNN are used in Generator. \n* PRelu(Parameterized Relu): We are using PRelu in place of Relu or LeakyRelu. It introduces learn-able parameter  \n  that makes it possible to adaptively learn the negative part coefficient. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8323274061336644,
        0.8571222997026892
      ],
      "excerpt": "  and the generator. \n* As a result of this, the generator learns to produce more and more realistic images(High Resolution images) as  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9762016407564758
      ],
      "excerpt": "* This is one of the problem where i struggled to get data. You need to be carefull while choosing data and also preprossing is little bit tough. \n",
      "technique": "Supervised classification"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can find more about this implementation in my post : [Single Image Super Resolution Using GANs\u200a\u2014\u200aKeras](https://medium.com/@birla.deepak26/single-image-super-resolution-using-gans-keras-aca310f33112)\n    \n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TomokiKomiya/SRGAN-keras/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    Enhancing low resolution images by applying deep network with adversarial network (Generative Adversarial Networks) \n    to produce high resolutions images.\n    \n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 13:45:23 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/TomokiKomiya/SRGAN-keras/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "TomokiKomiya/SRGAN-keras",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/TomokiKomiya/SRGAN-keras/master/srgan.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    * Used COCO data set 2017. It is around 18GB having images of different dimensions.\n    * Used 800 images for training(Very less, You can take more (approx. 350 according to original paper) thousand is you can\n      collect and have very very good GPU). Preprocessing includes cropping images so that we can have same dimension images. \n      Images with same width and height are preferred. I used images of size 384 for high resolution.\n    * After above step you have High Resolution images. Now you have to get Low Resolution images which you can get by down \n      scaling HR images. I used down scale = 4. So Low resolution image of size 96 we will get. Sample code for this.\n      \n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8091565498284082
      ],
      "excerpt": "* Use GPU for training else it will take months to train(even you can run out of memory). \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8227886536738171
      ],
      "excerpt": "  and LR images for training data set. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8166977296313789
      ],
      "excerpt": "Utils.py   : Contains utilities to process images \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9258314066098505,
        0.9310347028899404
      ],
      "excerpt": "train.py   : Used for training the model \ntest.py    : To test the model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8096691112806913
      ],
      "excerpt": "* Use GPU for training else it will take months to train(even you can run out of memory). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8260942000222682
      ],
      "excerpt": "More results are in output folder \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/TomokiKomiya/SRGAN-keras/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Keras-SRGAN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SRGAN-keras",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "TomokiKomiya",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TomokiKomiya/SRGAN-keras/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    You will need the following to run the above:\n    Python 3.5.4\n    tensorflow 1.11.0\n    keras 2.2.4\n    numpy 1.10.4\n    matplotlib, skimage, scipy\n    \n    For training: Good GPU, I trained my model on NVIDIA Tesla P100\n    \n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 13:45:23 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    \n    Note : Image shape and downscale factor you can set in train.py file.Set according to requirement.\n    \n     * Training:\n        Run below command to train model. Set parameters accordingly.\n        > python train.py --input_dir='./data/' --output_dir='./output/' --model_save_dir='./model/' --batch_size=64 --epochs=3000 --number_of_images=1000 --train_test_ratio=0.8\n        \n        All Parameters have default values. For mode help on parameters run:\n        > python train.py -h\n        \n     * Testing:\n        test.py file contains code to test. Testing can be done in two ways using option test_type:\n            1. Test Model- Here you can test the model by providing HR images. It will process to get resulting LR images and then will generate SR images.\n               And then will save output file comprising of all LR, SR and HR images.\n               Run following command to test model:\n               > python test.py --input_high_res='./data_hr/' --output_dir='./output/' --model_dir='./model/gen_model3000.h5' --number_of_images=25 --test_type='test_model'\n               For more help run:\n               > python test.py -h\n               \n            2. Test LR images- This option directly take LR images and give resulting HR images.\n               Run following command to get HR images from LR images:\n               > python test.py --input_low_res='./data_lr/' --output_dir='./output/' --model_dir='./model/gen_model3000.h5' --number_of_images=25 --test_type='test_lr_images'\n               For more help run:\n               > python test.py -h\n          \n     If you hate commandline arguements please reffer Simplified folder. Modify parameters in file like image_shape, input folder\n     etc. according to your need and start training.\n               \n",
      "technique": "Header extraction"
    }
  ]
}
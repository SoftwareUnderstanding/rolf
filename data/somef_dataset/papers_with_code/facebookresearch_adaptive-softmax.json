{
  "citation": [
    {
      "confidence": [
        0.993384004519884
      ],
      "excerpt": "\"Efficient softmax approximation for GPUs\" (http://arxiv.org/abs/1609.04309). \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/adaptive-softmax",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to adaptive-softmax\nWe want to make contributing to this project as easy and transparent as\npossible.\nPull Requests\nWe welcome your pull requests.\n\nFork the repo and create your branch from master.\nIf you've added code that should be tested, add tests.\nIf you've changed APIs, update the documentation.\nEnsure the test suite passes.\nMake sure your code lints.\nIf you haven't already, complete the Contributor License Agreement (\"CLA\").\n\nContributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA.\nYou only need to do this once to work on any of Facebook's open source projects.\nComplete your CLA here: https://code.facebook.com/cla\nIssues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\nLicense\nBy contributing to adaptive-softmax, you agree that your contributions will be\nlicensed under its BSD license.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-09-30T18:29:43Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-07T10:14:26Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.961143970744538,
        0.8047628867613554
      ],
      "excerpt": "The adaptive-softmax project is a Torch implementation of the efficient softmax \napproximation for graphical processing units (GPU), described in the paper \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9572547526123075
      ],
      "excerpt": "This method is useful for training language models with large vocabularies. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9714795636060679
      ],
      "excerpt": "in order to reproduce the results of the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8669805876340732
      ],
      "excerpt": "In order to train a language model on the billion word benchmark, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implements an efficient softmax approximation as described in the paper \"Efficient softmax approximation for GPUs\" (http://arxiv.org/abs/1609.04309)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/adaptive-softmax/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 52,
      "date": "Wed, 29 Dec 2021 03:58:56 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/facebookresearch/adaptive-softmax/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "facebookresearch/adaptive-softmax",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8934924013721233
      ],
      "excerpt": "run the command \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8310932346270855
      ],
      "excerpt": "th train_big_lstm.lua -data PATH/TO/PTB -nhid 512 -isz 512 -dropout 0.5 -usecudnn -cutoff 2000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906316924726712
      ],
      "excerpt": "th train_big_lstm.lua -data PATH/TO/TEXT8 -nhid 512 -isz 512 -dropout 0.25 -batchsize 128 -usecudnn -cutoff 2000,10000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9136072585351055
      ],
      "excerpt": "th train_big_lstm.lua -data PATH/TO/BILLION/WORD -nhid 2048 -isz 256 -dropout 0.01 -batchsize 128 -testbatchsize 128 -threshold 2 -usecudnn -cutoff 4000,40000,200000 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/facebookresearch/adaptive-softmax/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Lua"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/facebookresearch/adaptive-softmax/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD License\\n\\nFor adaptive-softmax software\\n\\nCopyright (c) 2016-present, Facebook, Inc. All rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without modification,\\nare permitted provided that the following conditions are met:\\n\\n * Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n * Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n * Neither the name Facebook nor the names of its contributors may be used to\\n   endorse or promote products derived from this software without specific\\n   prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Adaptive Softmax",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "adaptive-softmax",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "facebookresearch",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/adaptive-softmax/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This project depends on the following packages:\n- [cutorch](https://github.com/torch/cutorch)\n- [cunn](https://github.com/torch/cunn)\n- [cudnn](https://github.com/soumith/cudnn.torch)\n- [torch-tds](https://github.com/torch/tds)\n- [torchnet](https://github.com/torchnet/torchnet)\n- [torch-rnnlib](https://github.com/facebookresearch/torch-rnnlib)\n- [penlight](https://github.com/stevedonovan/Penlight)\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 390,
      "date": "Wed, 29 Dec 2021 03:58:56 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "In order to train a recurrent neural network language model with default\nparameters, run\n\n```\nth train_big_lstm.lua -data DATA_DIR\n```\n\nwhere `DATA_DIR` is a directory containing three text files, `train.txt`,\n`valid.txt` and `test.txt`.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "We now briefly discuss how to use the adaptive softmax in your own projects.\nWe provide a Torch layer called `nn.AdaptiveSoftMax` and a corresponding\ncriterion, called `nn.AdaptiveLoss`, which must be used when training with\nthe adaptive softmax. The vocabulary must be sorted by decreasing frequency,\nso that frequent words correspond to small indices.\n\nThe constructor of the `nn.AdaptiveSoftMax` layer takes two arguments:\n`hidden_size`, which is the size of the input of the adaptive softmax\nand `cutoff`, which is a table indicating the limits of the different clusters.\nThe constructor of the `nn.AdaptiveLoss` criterion takes as only argument the\n`cutoff` table.\n\n```lua\nlocal nword       = 44372\nlocal hidden_size = 256\nlocal cutoff      = { 2000, 10000, nword }\n\nlocal decoder   = nn.AdaptiveSoftMax( hidden_size, cutoff )\nlocal criterion = nn.AdaptiveLoss( cutoff )\n```\n\nIn the previous example, we created an adaptive softmax with three clusters.\nThe first cluster contains the words from 1 to 2000, the second cluster\ncontains the words from 2001 to 10,000 and finally, the last cluster contains\nthe word from 10,001 to `nword`.\n\nThe `forward` method of the adaptive softmax takes a 2D tensor as input, and\noutput a table of 2D tensors of scores for each cluster (one tensor per\ncluster). In order to be efficient, the `nn.AdaptiveSoftMax` does not compute\nthe scores for all the word of the vocabulary for all the examples.It is thus\nnecessary to call the method `setTarget` of the `AdaptiveSoftMax` layer before\neach forward pass:\n\n```lua\ndecoder:setTarget( target )\n```\n\nwhere target is a 1D tensor. This ensure that the adaptive softmax will compute\nthe scores for the corresponding targets. It is also possible to call the method\n`getLogProb`, which computes the log probabilities for all the words of the\nvocabulary, given a 2D tensor of hidden vectors.\n\n",
      "technique": "Header extraction"
    }
  ]
}
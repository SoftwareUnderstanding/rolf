{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* We modified the DCGAN [code](https://github.com/Newmu/dcgan_code) in our package. Please cite the original [DCGAN](https://arxiv.org/abs/1511.06434) paper if you use their models.\n* This work was supported, in part, by funding from Adobe, eBay, and Intel, as well as a hardware grant from NVIDIA. J.-Y. Zhu is supported by Facebook Graduate Fellowship.\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1609.03552",
      "https://arxiv.org/abs/1406.2661",
      "https://arxiv.org/abs/1511.06434"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@inproceedings{zhu2016generative,\n  title={Generative Visual Manipulation on the Natural Image Manifold},\n  author={Zhu, Jun-Yan and Kr{\\\"a}henb{\\\"u}hl, Philipp and Shechtman, Eli and Efros, Alexei A.},\n  booktitle={Proceedings of European Conference on Computer Vision (ECCV)},\n  year={2016}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{zhu2016generative,\n  title={Generative Visual Manipulation on the Natural Image Manifold},\n  author={Zhu, Jun-Yan and Kr{\\\"a}henb{\\\"u}hl, Philipp and Shechtman, Eli and Efros, Alexei A.},\n  booktitle={Proceedings of European Conference on Computer Vision (ECCV)},\n  year={2016}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9878673543585983,
        0.9999961795176809
      ],
      "excerpt": "Jun-Yan Zhu, Philipp Kr\u00e4henb\u00fchl, Eli Shechtman, Alexei A. Efros   \nIn European Conference on Computer Vision (ECCV) 2016 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999999402553801
      ],
      "excerpt": "Please cite our paper if you find this code useful in your research. (Contact: Jun-Yan Zhu, junyanz at mit dot edu) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9976332181041379
      ],
      "excerpt": "If you love cats, and love reading cool graphics, vision, and learning papers, please check out our Cat Paper Collection: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/junyanz/iGAN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-09-21T06:44:49Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T03:51:08Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9449677463605686
      ],
      "excerpt": "Project |  Youtube |  Paper   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8306194352031125,
        0.9118985197872976
      ],
      "excerpt": "[CycleGAN]: Torch implementation for learning an image-to-image translation (i.e., pix2pix) without input-output pairs. \n[pytorch-CycleGAN-and-pix2pix]: PyTorch implementation for both unpaired and paired image-to-image translation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9705389367525215
      ],
      "excerpt": "Given a few user strokes, our system could produce photo-realistic samples that best satisfy the user edits in real-time. Our system is based on deep generative models such as Generative Adversarial Networks (GAN) and DCGAN. The system serves the following two purposes: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9677613499947774
      ],
      "excerpt": "* An interactive visual debugging tool for understanding and visualizing deep generative models. By interacting with the generative model, a developer can understand what visual content the model can produce, as well as the limitation of the model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "* PyQt4 with Python3: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9880762162307265,
        0.8802161452570411,
        0.9638378647411707
      ],
      "excerpt": "Drawing Pad: This is the main window of our interface. A user can apply different edits via our brush tools, and the system will display the generated image. Check/Uncheck Edits button to display/hide user edits.   \nCandidate Results: a display showing thumbnails of all the candidate results (e.g., different modes) that fits the user edits. A user can click a mode (highlighted by a green rectangle), and the drawing pad will show this result. \nBrush Tools:  Coloring Brush for changing the color of a specific region; Sketching brush for outlining the shape. Warping brush for modifying the shape more explicitly. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.957655349916495
      ],
      "excerpt": "Coloring Brush:  right-click to select a color; hold left click to paint; scroll the mouse wheel to adjust the width of the brush. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216808662246904,
        0.9333440502355106,
        0.8493729718046331,
        0.9238855248547281
      ],
      "excerpt": "Warping Brush: We recommend you first use coloring and sketching before the warping brush. Right-click to select a square region; hold left click to drag the region; scroll the mouse wheel to adjust the size of the square region. \nShortcuts: P for Play, F for Fix, R for Restart; S for Save; E for Edits; Q for quitting the program. \nTooltips: when you move the cursor over a button, the system will display the tooltip of the button. \nDownload the Theano DCGAN model (e.g., outdoor_64). Before using our system, please check out the random real images vs. DCGAN generated samples to see which kind of images that a model can produce. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8765163641116847
      ],
      "excerpt": "Type python iGAN_main.py --help for a complete list of the arguments. Here we discuss some important arguments: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9543314290186637
      ],
      "excerpt": "* --model_type: currently only supports dcgan_theano. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8218578868726953,
        0.8130072122128377,
        0.8064493547858573
      ],
      "excerpt": "* --top_k: the number of the candidate results being displayed \n* --average: show an average image in the main window. Inspired by AverageExplorer, average image is a weighted average of multiple generated results, with the weights reflecting user-indicated importance. You can switch between average mode and normal mode by press A. \n* --shadow: We build a sketching assistance system for guiding the freeform drawing of objects inspired by ShadowDraw \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9208254056246051
      ],
      "excerpt": "See more details here \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9590349831085851
      ],
      "excerpt": "We provide a script to project an image into latent space (i.e., x-&gt;z): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9876724636800535
      ],
      "excerpt": "* We provide three methods: opt for optimization method; cnn for feed-forward network method (fastest); cnn_opt hybrid of the previous methods (default and best). Type python iGAN_predict.py --help for a complete list of the arguments. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8851349941477857
      ],
      "excerpt": "We also provide a standalone script that should work without UI. Given user constraints (i.e., a color map, a color mask, and an edge map), the script generates multiple images that mostly satisfy the user constraints. See python iGAN_script.py --help for more details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Interactive Image Generation via Generative Adversarial Networks",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/junyanz/iGAN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 601,
      "date": "Thu, 23 Dec 2021 06:00:58 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/junyanz/iGAN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "junyanz/iGAN",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/junyanz/iGAN/master/datasets/scripts/download_hdf5_dataset.sh",
      "https://raw.githubusercontent.com/junyanz/iGAN/master/models/scripts/download_alexnet.sh",
      "https://raw.githubusercontent.com/junyanz/iGAN/master/models/scripts/download_dcgan_model.sh",
      "https://raw.githubusercontent.com/junyanz/iGAN/master/train_dcgan/train_script.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9244267259188358
      ],
      "excerpt": "For Python3 users, you need to replace pip with pip3: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9899469170287282,
        0.9419233204793767
      ],
      "excerpt": "sudo apt-get install python3-pyqt4 \n* OpenCV3 with Python3: see the installation instruction. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9446546510303395
      ],
      "excerpt": "bash ./models/scripts/download_dcgan_model.sh outdoor_64 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9446546510303395
      ],
      "excerpt": "bash models/scripts/download_alexnet.sh conv4 \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8919623848299723
      ],
      "excerpt": "<img src='pics/demo.gif' width=320> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9063947779002828
      ],
      "excerpt": "<img src='pics/demo_teaser.jpg' width=800> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9063947779002828
      ],
      "excerpt": "<img src='pics/ui_intro.jpg' width=800> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9253833643953301,
        0.8161837922970969
      ],
      "excerpt": "THEANO_FLAGS='device=gpu0, floatX=float32, nvcc.fastmath=True' python generate_samples.py --model_name outdoor_64 --output_image outdoor_64_dcgan.png \nType python iGAN_main.py --help for a complete list of the arguments. Here we discuss some important arguments: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.889974934798688
      ],
      "excerpt": "THEANO_FLAGS='device=gpu0, floatX=float32, nvcc.fastmath=True' python iGAN_main.py --model_name hed_shoes_64 --shadow --average \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9303959317509419
      ],
      "excerpt": "<img src='pics/predict.jpg' width=800> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8302740851291918
      ],
      "excerpt": "* Download the pre-trained AlexNet model (conv4): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.902456064750494
      ],
      "excerpt": "THEANO_FLAGS='device=gpu0, floatX=float32, nvcc.fastmath=True' python iGAN_predict.py --model_name shoes_64 --input_image ./pics/shoes_test.png --solver cnn_opt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8767247282639896
      ],
      "excerpt": "<img src='pics/script_result.png' width=1000> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9174315013034399
      ],
      "excerpt": "THEANO_FLAGS='device=gpu0, floatX=float32, nvcc.fastmath=True' python iGAN_script.py --model_name outdoor_64 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/junyanz/iGAN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License (MIT)\\n\\nCopyright (c) 2016 Jun-Yan Zhu\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# iGAN: Interactive Image Generation via Generative Adversarial Networks",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "iGAN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "junyanz",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/junyanz/iGAN/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The code is written in Python2 and requires the following 3rd party libraries:\n* numpy\n* [OpenCV](http://opencv.org/)\n```bash\nsudo apt-get install python-opencv\n```\n* [Theano](https://github.com/Theano/Theano)\n```bash\nsudo pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n```\n* [PyQt4](https://wiki.python.org/moin/PyQt4): more details on Qt installation can be found [here](http://www.saltycrane.com/blog/2008/01/how-to-install-pyqt4-on-ubuntu-linux/)\n```bash\nsudo apt-get install python-qt4\n```\n* [Qdarkstyle](https://github.com/ColinDuquesnoy/QDarkStyleSheet)\n```bash\nsudo pip install qdarkstyle\n```\n* [dominate](https://github.com/Knio/dominate)\n```bash\nsudo pip install dominate\n```\n* GPU + CUDA + cuDNN:\nThe code is tested on GTX Titan X + CUDA 7.5 + cuDNN 5.  Here are the tutorials on how to install [CUDA](http://www.r-tutor.com/gpu-computing/cuda-installation/cuda7.5-ubuntu) and [cuDNN](http://askubuntu.com/questions/767269/how-can-i-install-cudnn-on-ubuntu-16-04). A decent GPU is required to run the system in real-time. [**Warning**] If you run the program on a GPU server, you need to use remote desktop software (e.g., VNC), which may introduce display artifacts and latency problem.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3845,
      "date": "Thu, 23 Dec 2021 06:00:58 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "generative-adversarial-network",
      "image-manipulation",
      "computer-graphics",
      "computer-vision",
      "gan",
      "pix2pix",
      "dcgan",
      "deep-learning"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Install the python libraries. (See [Requirements](https://github.com/junyanz/iGAN#requirements)).\n* Download the code from GitHub:\n```bash\ngit clone https://github.com/junyanz/iGAN\ncd iGAN\n```\n* Download the model. (See `Model Zoo` for details):\n``` bash\nbash ./models/scripts/download_dcgan_model.sh outdoor_64\n```\n\n* Run the python script:\n``` bash\nTHEANO_FLAGS='device=gpu0, floatX=float32, nvcc.fastmath=True' python iGAN_main.py --model_name outdoor_64\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "citation": [
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "    place = fluid.CUDAPlace(0) if device_id >= 0 else fluid.CPUPlace() \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/panjianning/cbnet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-04-22T11:44:30Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-19T01:29:58Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.885129411446992,
        0.8804374305346642
      ],
      "excerpt": "mAP with vanilla nms\uff1a 50.8 \nnon_local.py is modified to adapt NonLocal module from paddledetection to mmdetection \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127,
        0.9567588029116127
      ],
      "excerpt": "with fluid.program_guard(infer_prog, startup_prog): \n    with fluid.unique_name.guard(): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "        feed_vars, loader = model.build_inputs(**inputs_def) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "for var in startup_prog.list_vars(): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "implement cbnet with mmdetection",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "|arch|backbone|Lr schd|box AP|download|\n|---|---|---|---|---|\n|cascade_rcnn|dual resnet_vd200 + dcnv2 + nonlocal|  2.5x|52.2(soft-nms)|[Google Drive](https://drive.google.com/file/d/1XPkSCwOrxh9EanqBMjPENNmVE36OXB5Z/view?usp=sharing)|\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/panjianning/cbnet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Fri, 24 Dec 2021 02:18:58 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/panjianning/cbnet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "panjianning/cbnet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8522423304996438
      ],
      "excerpt": "On COCO val2017 \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8218017731780631,
        0.8401558704798054
      ],
      "excerpt": "from paddle import fluid \nimport os \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.91683076297571,
        0.9457175861910134,
        0.8791175621392118
      ],
      "excerpt": "import ppdet.utils.checkpoint as checkpoint \nimport numpy as np \nfrom collections import OrderedDict \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "        inputs_def['iterable'] = True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8764063352976937,
        0.8016840154625324
      ],
      "excerpt": "        _ = model.test(feed_vars) \ncheckpoint.load_params(exe, infer_prog, weight_path) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8688079292047082,
        0.9630956544865089
      ],
      "excerpt": "    fluid_tensor = fluid.global_scope().find_var(var.name).get_tensor() \n    var_dict[var.name] = np.array(fluid_tensor) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/panjianning/cbnet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "cbnet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "cbnet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "panjianning",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/panjianning/cbnet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 21,
      "date": "Fri, 24 Dec 2021 02:18:58 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "``` python\nbackbone=dict(\n    type='CBNet',\n    backbone_type='ResNet_VD',\n    num_repeat=2,\n    connect_norm_eval=True,\n    depth=200,\n    out_indices=(0, 1, 2, 3),\n    norm_cfg=dict(type='BN', requires_grad=True),\n    norm_eval=True,\n    dcn=dict(type='DCNv2', deformable_groups=1, fallback_on_stride=False),\n    stage_with_dcn=(False, True, True, True),\n    stage_with_non_local=(False, False, True, False),\n    frozen_stages=1,\n    style='pytorch')\n```\nTo get the pretrained model on imagenet like `dual_xxx.pth`:\n``` python\ndef make_pretrained_model(input_path, output_path, repeat_num=2):\n    cp = torch.load(input_path)\n    keys = list(cp['state_dict'].keys())\n    for key in keys:\n        for i in range(repeat_num):\n            cp['state_dict']['cb{}.{}'.format(i + 1, key)] = cp['state_dict'][key]\n        cp['state_dict'].pop(key)\n    torch.save(cp, output_path)\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
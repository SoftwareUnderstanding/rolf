{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1901.03798",
      "https://arxiv.org/abs/1602.00134",
      "https://arxiv.org/abs/1603.06937"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@article{wang20193d,\n\u00a0 title={3D Human Pose Machines with Self-supervised Learning},\n\u00a0 author={Wang, Keze and Lin, Liang and Jiang, Chenhan and Qian, Chen and Wei, Pengxu},\n\u00a0 journal={IEEE transactions on pattern analysis and machine intelligence},\n\u00a0 year={2019},\n\u00a0 publisher={IEEE}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{wang20193d,\n\u00a0 title={3D Human Pose Machines with Self-supervised Learning},\n\u00a0 author={Wang, Keze and Lin, Liang and Jiang, Chenhan and Qian, Chen and Wei, Pengxu},\n\u00a0 journal={IEEE transactions on pattern analysis and machine intelligence},\n\u00a0 year={2019},\n\u00a0 publisher={IEEE}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9999999915450246
      ],
      "excerpt": "Keze Wang, Liang Lin, Chenhan Jiang, Chen Qian, and Pengxu Wei, \u201c3D Human Pose Machines with Self-supervised Learning\u201d. To appear in IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI), 2019. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9448100533552249
      ],
      "excerpt": "\u00a0 \u00a0 <img src=http://www.sysu-hcp.net/wp-content/uploads/2019/01/WeChat-Screenshot_20190111210435.png> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9448100533552249
      ],
      "excerpt": "\u00a0 \u00a0 <img src=\"http://www.sysu-hcp.net/wp-content/uploads/2019/01/WeChat-Screenshot_20190111210519.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9448100533552249
      ],
      "excerpt": "\u00a0 \u00a0 <img src=\"http://www.sysu-hcp.net/wp-content/uploads/2019/01/WeChat-Screenshot_20190111210546.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8302556419090275
      ],
      "excerpt": "\u00a0 wget -v https://drive.google.com/open?id=16gQJvf4wHLEconStLOh5Y7EzcnBUhoM- \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8302556419090275
      ],
      "excerpt": "\u00a0 wget -v https://drive.google.com/open?id=1dMuPuD_JdHuMIMapwE2DwgJ2IGK04xhQ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.920594315055738
      ],
      "excerpt": "\u00a0 #: Step3: online refine 3D pose prediction \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9419429782865519
      ],
      "excerpt": "\u00a0 #: Or you can use Hourglass(https://github.com/princeton-vl/pose-hg-demo) to predict 2d pose \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8302556419090275
      ],
      "excerpt": "\u00a0 wget -v https://drive.google.com/open?id=19kTyttzUnm_1_7HEwoNKCXPP2QVo_zcK \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.920594315055738
      ],
      "excerpt": "\u00a0 #: Step3: online refine 3D pose prediction \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9605199141447631
      ],
      "excerpt": "\u00a0 #: Follow above Step1~2 to produce coarse 3d prediction and 2d pose. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.920594315055738
      ],
      "excerpt": "\u00a0 #: online refine 3D pose prediction \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9930843391567727
      ],
      "excerpt": "\u00a0 #: Visualization of 2dpose/ 3d gt pose/ 3d coarse pose/ 3d refine pose \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/chanyn/3Dpose_ssl",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing\nIssues\nSpecific Caffe design and development issues, bugs, and feature requests are maintained by GitHub Issues.\nPlease do not post usage, installation, or modeling questions, or other requests for help to Issues.\nUse the caffe-users list instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\nWhen reporting a bug, it's most helpful to provide the following information, where applicable:\n\nWhat steps reproduce the bug?\nCan you reproduce the bug using the latest master, compiled with the DEBUG make option?\nWhat hardware and operating system/distribution are you running?\nIf the bug is a crash, provide the backtrace (usually printed by Caffe; always obtainable with gdb).\n\nTry to give your issue a title that is succinct and specific. The devs will rename issues as needed to keep track of them.\nPull Requests\nCaffe welcomes all contributions.\nSee the contributing guide for details.\nBriefly: read commit by commit, a PR should tell a clean, compelling story of one improvement to Caffe. In particular:\n\nA PR should do one clear thing that obviously improves Caffe, and nothing more. Making many smaller PRs is better than making one large PR; review effort is superlinear in the amount of code involved.\nSimilarly, each commit should be a small, atomic change representing one step in development. PRs should be made of many commits where appropriate.\nPlease do rewrite PR history to be clean rather than chronological. Within-PR bugfixes, style cleanups, reversions, etc. should be squashed and should not appear in merged PR history.\nAnything nonobvious from the code should be explained in comments, commit messages, or the PR description, as appropriate.",
    "technique": "File Exploration"
  },
  "contributors": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributors\nCaffe is developed by a core set of BVLC members and the open-source community.\nWe thank all of our contributors!\nFor the detailed history of contributions of a given file, try\ngit blame file\n\nto see line-by-line credits and\ngit log --follow file\n\nto see the change log even across renames and rewrites.\nPlease refer to the acknowledgements on the Caffe site for further details.\nCopyright is held by the original contributor according to the versioning history; see LICENSE.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-10T08:58:40Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-18T12:28:31Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8304177194302005,
        0.9929998090304967,
        0.8579462664185049
      ],
      "excerpt": "Keze Wang, Liang Lin, Chenhan Jiang, Chen Qian, and Pengxu Wei, \u201c3D Human Pose Machines with Self-supervised Learning\u201d. To appear in IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI), 2019. \nThis repository implements a 3D human pose machine to resolve 3D pose sequence generation for monocular frames, and includes a concise self-supervised correction mechanism to enhance our model by retaining the 3D geometric consistency. The main part is written in C++ and powered by Caffe deep learning toolbox. Another is written in Python and powered by Tensorflow. \nWe proposed results on the Human3.6M, KTH Football II and MPII dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9581523088004597
      ],
      "excerpt": "We change annotation of Human3.6m to hold 16 points ( 'RFoot' 'RKnee' 'RHip' 'LHip' 'LKnee' 'LFoot' 'Hip' 'Spine' 'Thorax' 'Head' 'RWrist' 'RElbow' \u00a0'RShoulder' 'LShoulder' 'LElbow' 'LWrist') in keeping with MPII.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9391298406874278,
        0.9070780811991913,
        0.907083608157849,
        0.95052881523104
      ],
      "excerpt": "\u00a0 |_gt #: 2d and 3d annotations splited by actions \n\u00a0 |_hg2dh36m #: 2d estimation predicted by *Hourglass*, 'square' denotes prediction of square image.  \n\u00a0 |_ours_2d #: 2d prediction from our model \n\u00a0 |_ours_3d #: 3d coarse prediction of *Model Extension: mask3d* \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9529759894923879
      ],
      "excerpt": "We crop and square single person from \u00a0all images and update 2d annotation in train_h36m.txt (resort points according to order of Human3.6m points). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9097828656067701
      ],
      "excerpt": "Our model consists of two cascade modules, so the training phase can be divided into the following steps: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9108862177361862
      ],
      "excerpt": "Train 2D-to-3D pose transformer module with Human3.6M. And we fix the parameters of the 2D pose sub-network. The corresponding prototxt file is in examples/2D_to_3D/bilstm.prototxt.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8220488449656757
      ],
      "excerpt": "To train 3D-to-2D pose projector module, we fix the above module weights. And we need in the wild 2D Pose dataset to help training (we choose MPII). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9190533820909402
      ],
      "excerpt": "Fine-tune the whole model jointly. We provide trained model and coarse prediction of Protocol I and Protocol III. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8500616479602257
      ],
      "excerpt": "Model extension: Add rand mask to relieve model bias. We provide corresponding model files in examples/mask3d. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9361726358692803
      ],
      "excerpt": "3D-to-2D project module is initialized from the well-trained model, and they will be updated by minimizing the difference between the predicted 2D pose and projected 2D pose. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8350360121109714
      ],
      "excerpt": "\u00a0 #: protocal: 1/3 , default is 1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9638259892909645
      ],
      "excerpt": "Inference with Our2d-model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9740101036695411
      ],
      "excerpt": "\u00a0 #: The model we use to predict 2d pose is similar to our 3dpredict model without ssl module. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "\u00a0 mv our2d /data/h36m/ours_2d/bilstm2d-p1-800000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8350360121109714
      ],
      "excerpt": "\u00a0 #: protocal: 1/3 , default is 1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9898557990303651
      ],
      "excerpt": "The only difference is that you should transfer caffemodel of 3D-to-2D project module to pkl file. We provide gen_refinepkl.py in tools/. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8656505798792121
      ],
      "excerpt": "\u00a0 #: Follow above Step1~2 to produce coarse 3d prediction and 2d pose. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "3D Human Pose Machines with Self-supervised Learning",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/chanyn/3Dpose_ssl/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 81,
      "date": "Sat, 25 Dec 2021 03:26:15 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/chanyn/3Dpose_ssl/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "chanyn/3Dpose_ssl",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/docker/standalone/gpu/Dockerfile",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/docker/standalone/cpu/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/chanyn/3Dpose_ssl/tree/master/caffe-3dssl/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/Untitled.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/scripts/deploy_docs.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/scripts/build_docs.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/scripts/download_model_from_gist.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/scripts/upload_model_to_gist.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/scripts/gather_examples.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/scripts/travis/install-python-deps.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/scripts/travis/test.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/scripts/travis/defaults.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/scripts/travis/setup-venv.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/scripts/travis/configure-make.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/scripts/travis/configure.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/scripts/travis/build.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/scripts/travis/install-deps.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/scripts/travis/configure-cmake.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/data/ilsvrc12/get_ilsvrc_aux.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/data/cifar10/get_cifar10.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/data/mnist/get_mnist.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/examples/3D_to_2D/train.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/examples/2D_to_3D/train.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/examples/mask3d/train.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/examples/finetune_whole/train.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/tools/extra/parse_log.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/caffe-3dssl/tools/extra/launch_resize_and_crop_images.sh",
      "https://raw.githubusercontent.com/chanyn/3Dpose_ssl/master/test/test_human16.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Build 3Dssl Caffe\n\n\u00a0 \u00a0```\n\u00a0 \u00a0cd $ROOT/caffe-3dssl\n\u00a0 \u00a0#: Follow the Caffe installation instructions here:\n\u00a0 \u00a0#: \u00a0 http://caffe.berkeleyvision.org/installation.html\n\u00a0 \u00a0\n\u00a0 \u00a0#: If you're experienced with Caffe and have all of the requirements installed\n\u00a0 \u00a0#: and your Makefile.config in place, then simply do:\n\u00a0 \u00a0make all -j 8\n\u00a0 \u00a0\n\u00a0 \u00a0make pycaffe\n\u00a0 \u00a0```\n\n2. Install Tensorflow\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8080002376980483
      ],
      "excerpt": "\u00a0 cd data/MPII \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8725549602927676,
        0.8481145459886135
      ],
      "excerpt": "\u00a0 tar -xzvf MPII_square.tar.gz \n\u00a0 rm -f MPII_square.tar.gz \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd CAFFE_ROOT \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8588945879029763
      ],
      "excerpt": "sh examples/2D_to_3D/train.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8588945879029763
      ],
      "excerpt": "\u00a0 \u00a0sh examples/3D_to_2D/train.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8588945879029763
      ],
      "excerpt": "\u00a0 \u00a0sh examples/finetune_whole/train.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8588945879029763
      ],
      "excerpt": "\u00a0 \u00a0sh examples/mask3d/train.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466,
        0.8919958595477101,
        0.9771384723171962
      ],
      "excerpt": "\u00a0 cd PROJECT_ROOT \n\u00a0 mkdir models \n\u00a0 cd models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "\u00a0 cd ../ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9682048251497578
      ],
      "excerpt": "\u00a0 cd test \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9131563693307766
      ],
      "excerpt": "\u00a0 sh test_human16.sh . ../models/model_extension_mask3d/mask3d_iter_400000.caffemodel mask3d 5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466,
        0.9697504627103608
      ],
      "excerpt": "\u00a0 cd PROJECT_ROOT \n\u00a0 mkdir models &amp;&amp; cd models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "\u00a0 cd ../ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9682048251497578
      ],
      "excerpt": "\u00a0 cd test \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8202795712324655
      ],
      "excerpt": "\u00a0 sh test_human16.sh 2d/ ../models/our2d/2d_iter_800000.caffemodel our2d 5 \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.817583041390223
      ],
      "excerpt": "\u00a0 \u00a0 <img src=http://www.sysu-hcp.net/wp-content/uploads/2019/01/WeChat-Screenshot_20190111210435.png> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.817583041390223
      ],
      "excerpt": "\u00a0 \u00a0 <img src=\"http://www.sysu-hcp.net/wp-content/uploads/2019/01/WeChat-Screenshot_20190111210519.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.817583041390223
      ],
      "excerpt": "\u00a0 \u00a0 <img src=\"http://www.sysu-hcp.net/wp-content/uploads/2019/01/WeChat-Screenshot_20190111210546.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8560676443906038
      ],
      "excerpt": "After setting up Human3.6m dataset following its illustration and download the above training/testing list. You should update \u201croot_folder\u201d paths in CAFFE_ROOT/examples/.../*.prototxt for images and annotation director.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8172592746547243
      ],
      "excerpt": "sh examples/2D_to_3D/train.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8172592746547243
      ],
      "excerpt": "\u00a0 \u00a0sh examples/3D_to_2D/train.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8172592746547243
      ],
      "excerpt": "\u00a0 \u00a0sh examples/finetune_whole/train.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8172592746547243
      ],
      "excerpt": "\u00a0 \u00a0sh examples/mask3d/train.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8419265679004704
      ],
      "excerpt": "\u00a0 #: Step1: Download the trained model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8082022887640018,
        0.8017285540429218
      ],
      "excerpt": "\u00a0 unzip model_extension_mask3d.zip \n\u00a0 rm -r model_extension_mask3d.zip \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8033918088641017
      ],
      "excerpt": "\u00a0 #: test_human16.sh [$1 deploy.prototxt] [$2 trained model] [$3 save dir] [$4 batchsize] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9373547298823423
      ],
      "excerpt": "\u00a0 python pred_v2.py --trained_model ../models/model_extension_mask3d/mask3d-400000.pkl --protocol 1 --data_dir /data/h36m/ --coarse_3d ../test/mask3d --save srr_results --pose2d hourglass \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8419265679004704
      ],
      "excerpt": "\u00a0 #: Step1.1: Download the trained merge model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8082022887640018,
        0.8017285540429218
      ],
      "excerpt": "\u00a0 unzip our2d.zip \n\u00a0 rm -r our2d.zip \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8033918088641017
      ],
      "excerpt": "\u00a0 #: test_human16.sh [$1 deploy.prototxt] [$2 trained model] [$3 save dir] [$4 batchsize] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8058197494507731
      ],
      "excerpt": "\u00a0 mv our2d /data/h36m/ours_2d/bilstm2d-p1-800000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9373547298823423
      ],
      "excerpt": "\u00a0 python pred_v2.py --trained_model ../models/model_extension_mask3d/mask3d-400000.pkl --protocol 1 --data_dir /data/h36m/ --coarse_3d ../test/mask3d --save srr_results --pose2d ours \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8387583482957667
      ],
      "excerpt": "\u00a0 python tools/gen_refinepkl.py CAFFE_ROOT CAFFEMODEL_DIR --pkl_dir model.pkl \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8822069289357631
      ],
      "excerpt": "\u00a0 python pred_v2.py --trained_model model.pkl \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936606094659785
      ],
      "excerpt": "\u00a0 #: Print MPJP  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/chanyn/3Dpose_ssl/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "C++",
      "Python",
      "Cuda",
      "CMake",
      "MATLAB",
      "Makefile",
      "Shell",
      "CSS",
      "Dockerfile",
      "Jupyter Notebook",
      "HTML"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'COPYRIGHT\\n\\nAll contributions by the University of California:\\nCopyright (c) 2014, 2015, The Regents of the University of California (Regents)\\nAll rights reserved.\\n\\nAll other contributions:\\nCopyright (c) 2014, 2015, the respective contributors\\nAll rights reserved.\\n\\nCaffe uses a shared copyright model: each contributor holds copyright over\\ntheir contributions to Caffe. The project versioning records all such\\ncontribution and copyright details. If a contributor wants to further mark\\ntheir specific copyright on a particular contribution, they should indicate\\ntheir copyright solely in the commit message of the change when it is\\ncommitted.\\n\\nLICENSE\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met: \\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer. \\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution. \\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR\\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n\\nCONTRIBUTION AGREEMENT\\n\\nBy contributing to the BVLC/caffe repository through pull-request, comment,\\nor otherwise, the contributor releases their content to the\\nlicense and copyright terms herein.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# 3D Human Pose Machines with Self-supervised Learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "3Dpose_ssl",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "chanyn",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/chanyn/3Dpose_ssl/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. NVIDIA GPU and cuDNN are required to have fast speeds. For now, CUDA 8.0 with cuDNN 5.1 has been tested. The other versions should be working.\n2. Caffe Python wrapper is required. \n3. Tensorflow 1.1.0\n4. python 2.7.13\n5. MATLAB\n6. Opencv-python\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 390,
      "date": "Sat, 25 Dec 2021 03:26:15 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Clone the repo:\n\n```\ngit clone https://github.com/chanyn/3Dpose_ssl.git\n```\nor\ndirectly download from https://www.dropbox.com/s/qycpjinof2ishw9/3Dpose_ssl.tar.gz?dl=0 (including datasets and well-compiled caffe under cuda-8.0)\n\nOur code is organized as follows:\n\n```\ncaffe-3dssl/: support caffe\nmodels/: pretrained models and results\nprototxt/: network architecture definitions\ntensorflow/: code for online refine \ntest/: script that run results split by action \ntools/: python and matlab code \n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
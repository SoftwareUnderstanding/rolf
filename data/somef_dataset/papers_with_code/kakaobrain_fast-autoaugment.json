{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1905.00397",
      "https://arxiv.org/abs/1905.00397",
      "https://arxiv.org/abs/1512.03385",
      "https://arxiv.org/abs/1603.05027",
      "https://arxiv.org/abs/1610.02915",
      "https://arxiv.org/abs/1802.02375"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We increase the batch size and adapt the learning rate accordingly to boost the training. Otherwise, we set other hyperparameters equal to AutoAugment if possible. For the unknown hyperparameters, we follow values from the original references or we tune them to match baseline performances.\n\n- **ResNet** : [paper1](https://arxiv.org/abs/1512.03385), [paper2](https://arxiv.org/abs/1603.05027), [code](https://github.com/osmr/imgclsmob/tree/master/pytorch/pytorchcv/models)\n- **PyramidNet** : [paper](https://arxiv.org/abs/1610.02915), [code](https://github.com/dyhan0920/PyramidNet-PyTorch)\n- **Wide-ResNet** : [code](https://github.com/meliketoy/wide-resnet.pytorch)\n- **Shake-Shake** : [code](https://github.com/owruby/shake-shake_pytorch)\n- **ShakeDrop Regularization** : [paper](https://arxiv.org/abs/1802.02375), [code](https://github.com/owruby/shake-drop_pytorch)\n- **AutoAugment** : [code](https://github.com/tensorflow/models/tree/master/research/autoaugment)\n- **Ray** : [code](https://github.com/ray-project/ray)\n- **HyperOpt** : [code](https://github.com/hyperopt/hyperopt)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use this code in your research, please cite our [paper](https://arxiv.org/abs/1905.00397).\n\n```\n@inproceedings{lim2019fast,\n  title={Fast AutoAugment},\n  author={Lim, Sungbin and Kim, Ildoo and Kim, Taesup and Kim, Chiheon and Kim, Sungwoong},\n  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},\n  year={2019}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{lim2019fast,\n  title={Fast AutoAugment},\n  author={Lim, Sungbin and Kim, Ildoo and Kim, Taesup and Kim, Chiheon and Kim, Sungwoong},\n  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9732037017898261
      ],
      "excerpt": "| PyramidNet+ShakeDrop  | 14.0       | 12.2       | 10.7        | 11.9 / 11.7      | Download | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kakaobrain/fast-autoaugment",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Ildoo Kim, ildoo.kim@kakaobrain.com\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-01T14:03:49Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-17T14:35:28Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8151598939759218,
        0.8674074315048638,
        0.8809614029358124
      ],
      "excerpt": "Official Fast AutoAugment implementation in PyTorch. \nFast AutoAugment learns augmentation policies using a more efficient search strategy based on density matching. \nFast AutoAugment speeds up the search time by orders of magnitude while maintaining the comparable performances. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9555108550981263,
        0.9555155303351552
      ],
      "excerpt": "* We evaluated resnet-50 and resnet-200 with resolution of 224 and 320, respectively. According to the original resnet paper, resnet 200 was tested with the resolution of 320. Also our resnet-200 baseline's performance was similar when we use the resolution. \n* But with recent our code clean-up and bugfixes, we've found that the baseline performs similar to the baseline even using 224x224. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Official Implementation of 'Fast AutoAugment' in PyTorch.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kakaobrain/fast-autoaugment/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 192,
      "date": "Mon, 20 Dec 2021 21:31:54 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kakaobrain/fast-autoaugment/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "kakaobrain/fast-autoaugment",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8096422022825122,
        0.8096422022825122,
        0.8096422022825122,
        0.8096422022825122
      ],
      "excerpt": "| Shake-Shake(26 2x32d)   | 3.6        | 3.0        | 2.5         | 2.7 / 2.5        | Download | \n| Shake-Shake(26 2x96d)   | 2.9        | 2.6        | 2.0         | 2.0 / 2.0        | Download | \n| Shake-Shake(26 2x112d)  | 2.8        | 2.6        | 1.9         | 2.0 / 1.9        | Download | \n| PyramidNet+ShakeDrop    | 2.7        | 2.3        | 1.5         | 1.8 / 1.7        | Download | \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8946517745421642
      ],
      "excerpt": "<img src=\"etc/search.jpg\" height=350> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.810870454768102,
        0.810870454768102,
        0.810870454768102,
        0.810870454768102
      ],
      "excerpt": "| Shake-Shake(26 2x32d)   | 3.6        | 3.0        | 2.5         | 2.7 / 2.5        | Download | \n| Shake-Shake(26 2x96d)   | 2.9        | 2.6        | 2.0         | 2.0 / 2.0        | Download | \n| Shake-Shake(26 2x112d)  | 2.8        | 2.6        | 1.9         | 2.0 / 1.9        | Download | \n| PyramidNet+ShakeDrop    | 2.7        | 2.3        | 1.5         | 1.8 / 1.7        | Download | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.846971407231052,
        0.8200308889853248
      ],
      "excerpt": "| ResNet-50  | 23.7 / 6.9 | 22.4 / 6.2  | 22.4 / 6.3   | Download | \n| ResNet-200 | 21.5 / 5.8 | 20.0 / 5.0  | 19.4 / 4.7   | Download | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9176380030682303
      ],
      "excerpt": "$ python search.py -c confs/wresnet40x2_cifar10_b512.yaml --dataroot ... --redis ... \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9478434651806948,
        0.9496925561103344,
        0.9478434651806948,
        0.9496925561103344
      ],
      "excerpt": "$ python FastAutoAugment/train.py -c confs/wresnet40x2_cifar10_b512.yaml --aug fa_reduced_cifar10 --dataset cifar10 \n$ python FastAutoAugment/train.py -c confs/wresnet40x2_cifar10_b512.yaml --aug fa_reduced_cifar10 --dataset cifar100 \n$ python FastAutoAugment/train.py -c confs/wresnet28x10_cifar10_b512.yaml --aug fa_reduced_cifar10 --dataset cifar10 \n$ python FastAutoAugment/train.py -c confs/wresnet28x10_cifar10_b512.yaml --aug fa_reduced_cifar10 --dataset cifar100 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9452262784629902,
        0.9452262784629902,
        0.8382103938756228
      ],
      "excerpt": "$ python FastAutoAugment/train.py -c confs/resnet50_b512.yaml --aug fa_reduced_imagenet \n$ python FastAutoAugment/train.py -c confs/resnet200_b512.yaml --aug fa_reduced_imagenet \nBy adding --only-eval and --save arguments, you can test trained models without training. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kakaobrain/fast-autoaugment/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Ildoo Kim\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Fast AutoAugment **(Accepted at NeurIPS 2019)**",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "fast-autoaugment",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "kakaobrain",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kakaobrain/fast-autoaugment/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We conducted experiments under\n\n- python 3.6.9\n- pytorch 1.2.0, torchvision 0.4.0, cuda10\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1429,
      "date": "Mon, 20 Dec 2021 21:31:54 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "convolutional-neural-networks",
      "pytorch",
      "augmentation",
      "image-classification",
      "computer-vision",
      "distributed",
      "cnn",
      "automl",
      "automated-machine-learning"
    ],
    "technique": "GitHub API"
  }
}
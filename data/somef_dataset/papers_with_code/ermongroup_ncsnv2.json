{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2011.13456",
      "https://arxiv.org/abs/1907.05600"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find the code/idea useful for your research, please consider citing\n\n```bib\n@inproceedings{song2020improved,\n  author    = {Yang Song and Stefano Ermon},\n  editor    = {Hugo Larochelle and\n               Marc'Aurelio Ranzato and\n               Raia Hadsell and\n               Maria{-}Florina Balcan and\n               Hsuan{-}Tien Lin},\n  title     = {Improved Techniques for Training Score-Based Generative Models},\n  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference\n               on Neural Information Processing Systems 2020, NeurIPS 2020, December\n               6-12, 2020, virtual},\n  year      = {2020}\n}\n```\n\nand/or our previous work\n\n```bib\n@inproceedings{song2019generative,\n  title={Generative Modeling by Estimating Gradients of the Data Distribution},\n  author={Song, Yang and Ermon, Stefano},\n  booktitle={Advances in Neural Information Processing Systems},\n  pages={11895--11907},\n  year={2019}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{song2019generative,\n  title={Generative Modeling by Estimating Gradients of the Data Distribution},\n  author={Song, Yang and Ermon, Stefano},\n  booktitle={Advances in Neural Information Processing Systems},\n  pages={11895--11907},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{song2020improved,\n  author    = {Yang Song and Stefano Ermon},\n  editor    = {Hugo Larochelle and\n               Marc'Aurelio Ranzato and\n               Raia Hadsell and\n               Maria{-}Florina Balcan and\n               Hsuan{-}Tien Lin},\n  title     = {Improved Techniques for Training Score-Based Generative Models},\n  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference\n               on Neural Information Processing Systems 2020, NeurIPS 2020, December\n               6-12, 2020, virtual},\n  year      = {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8369514598000786
      ],
      "excerpt": "by Yang Song and Stefano Ermon, Stanford AI Lab. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ermongroup/ncsnv2",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-17T08:50:11Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-24T15:42:42Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9665678664319414
      ],
      "excerpt": "This repo contains the official implementation for the paper Improved Techniques for Training Score-Based Generative Models.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9902646088991139,
        0.9628534036776195
      ],
      "excerpt": "We significantly improve the method proposed in Generative Modeling by Estimating Gradients of the Data Distribution. Score-based generative models are flexible neural networks trained to capture the score function of an underlying data distribution\u2014a vector field pointing to directions where the data density increases most rapidly. We present new techniques to improve the performance of score-based generative models, scaling them to high resolution images that are previously impossible. Without requiring adversarial training, they can produce sharp and diverse image samples that rival GANs. \n(From left to right: Our samples on FFHQ 256px, LSUN bedroom 128px, LSUN tower 128px, LSUN church_outdoor 96px, and CelebA 64px.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9001424355098427
      ],
      "excerpt": "\u251c\u2500\u2500 fid_samples #: contains all samples generated for fast fid computation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8318649676487296
      ],
      "excerpt": "\u251c\u2500\u2500 image_samples #: contains generated samples \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9681418353479502
      ],
      "excerpt": "We can interpolate between different samples (see more details in the paper). Just set interpolation to true and an appropriate n_interpolations under the group of sampling in bedroom.yml. We can also perform other tasks such as inpainting. Usages should be quite obvious if you read the code and configuration files carefully. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "The official PyTorch implementation for NCSNv2 (NeurIPS 2020)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ermongroup/ncsnv2/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 26,
      "date": "Sat, 25 Dec 2021 06:00:53 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ermongroup/ncsnv2/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ermongroup/ncsnv2",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.9150883543049355
      ],
      "excerpt": "main.py is the file that you should run for both training and sampling. Execute python main.py --help to get its usage description: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8972315101190507,
        0.8908579161600287
      ],
      "excerpt": "usage: main.py [-h] --config CONFIG [--seed SEED] [--exp EXP] --doc DOC \n               [--comment COMMENT] [--verbose VERBOSE] [--test] [--sample] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8570615646360159
      ],
      "excerpt": "  --test                Whether to test the model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8662291601276778
      ],
      "excerpt": "                        The folder name of samples \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8027674022699872
      ],
      "excerpt": "\u251c\u2500\u2500 datasets #: all dataset files \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8099306275737788,
        0.8486988244381465
      ],
      "excerpt": "\u2502   \u2514\u2500\u2500 &lt;doc&gt; #: a folder named by the argument `--doc` specified to main.py \n\u2502      \u251c\u2500\u2500 checkpoint_x.pth #: the checkpoint file saved at the x-th training iteration \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8130929738082937
      ],
      "excerpt": "\u2502      \u2514\u2500\u2500 samples #: all samples produced during training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8099306275737788
      ],
      "excerpt": "\u2502   \u2514\u2500\u2500 &lt;i&gt; #: a folder named by the argument `-i` specified to main.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.801327704757349
      ],
      "excerpt": "\u2502       \u2514\u2500\u2500 image_grid_x.png #: samples generated from checkpoint_x.pth        \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.900134953288431
      ],
      "excerpt": "python main.py --config bedroom.yml --doc bedroom \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9234908580027691
      ],
      "excerpt": "python main.py --sample --config bedroom.yml -i bedroom \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.900134953288431
      ],
      "excerpt": "python main.py --fast_fid --config bedroom.yml -i bedroom \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ermongroup/ncsnv2/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Yang Song (yangsong@cs.stanford.edu)\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Improved Techniques for Training Score-Based Generative Models",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ncsnv2",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ermongroup",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ermongroup/ncsnv2/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Run the following to install all necessary python packages for our code.\n\n```bash\npip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 109,
      "date": "Sat, 25 Dec 2021 06:00:53 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "score-matching",
      "generative-models",
      "score-based-generative-modeling",
      "diffusion-models",
      "neurips-2020"
    ],
    "technique": "GitHub API"
  }
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* This project was completed as a part of the Data Science Practicum 2018 course at the University of Georgia\n*This work would not have been possible without the support of Dr. Shannon Quinn, [Assistant\nProfessor, University of Georgia Departments of Computer Science and Cellular Biology] who\nworked actively to provide us with academic time and advice to pursue those goals.\n* Other resources used have been cited in their corresponding wiki page.\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1512.03385\n* https://github.com/raghakot/keras-resnet\n* https://github.com/tensorflow/models/tree/master/research/object_detection\n* https://www.kaggle.com/c/landmark-recognition-challenge\n* http://pages.cs.wisc.edu/~dyer/cs534-spring10/papers/google_landmark_recognition.pdf\n* https://www.youtube.com/watch?v=yDVap0lpYKg\n"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "References for this Project:\n\n* https://arxiv.org/pdf/1512.03385.pdf\n* https://arxiv.org/abs/1512.03385\n* https://github.com/raghakot/keras-resnet\n* https://github.com/tensorflow/models/tree/master/research/object_detection\n* https://www.kaggle.com/c/landmark-recognition-challenge\n* http://pages.cs.wisc.edu/~dyer/cs534-spring10/papers/google_landmark_recognition.pdf\n* https://www.youtube.com/watch?v=yDVap0lpYKg\n\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ankit-vaghela30/Google-landmark-prediction",
    "technique": "GitHub API"
  },
  "contributor": [
    {
      "confidence": [
        1
      ],
      "excerpt": "See [contributor](https://github.com/dsp-uga/Team-Bulldawgs/blob/master/CONTRIBUTORS.md) file for more details.\n\n",
      "technique": "Header extraction"
    }
  ],
  "contributors": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributors\n(Ordered alphabetically)\nAnkit Vaghela - ankit-vaghela30\n- Simple CNN model\n- Resnet model\n- Trick to train on labels with high frequency of images\n- Downloading script\n- Google compute engine setup and run\n- postprocessing to create submission file\n- Systems architecture\n- Wiki documentation\n- Project report documentation\n- peer-programming\n- README - Execution steps\nHiten Nirmal - hitennirmal\n- Explored Object detection, used coco api to detect person in one of dataset images (It stands independent)\n- Worked on Project report formatting and setup\n- Project report documentation\n- Explored Screen API to enable better long time run of google compute engine\n- Preprocessing\n- Systems architecture\n- README documentation\n- Wiki documentation and formation\n- peer-programming\nAdditional Contribution\n\nDr Shannon Quinn - magsol",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-12T19:14:00Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-14T20:19:18Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "With the vast amount of landmark images on the Internet, the time has come to think about landmarks globally, namely to build a landmark prediction engine, on the scale of the entire earth.\n\nDevelop a technology that can predict landmark labels directly from image pixels, to help people better understand and organize the photo collections.The project challenges to build models that recognize the correct landmark in a dataset of challenging test images. The Kaggle challenge provides access to annotated data which consists of various links to google images along with their respective labeled classes.\n\nLink to the Kaggle competition: [https://www.kaggle.com/c/landmark-recognition-challenge](https://www.kaggle.com/c/landmark-recognition-challenge)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9600194710762706
      ],
      "excerpt": "The dataset for this Kaggle competition is available on the following website:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9589726733628192,
        0.9211351490986882,
        0.9663761543945264
      ],
      "excerpt": "The following arguments are supported by our model: \n- model : Specify the deep learning model to be used \n                  Ex: --model=\"resnet\", --model=\"cnn\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9387652572085283
      ],
      "excerpt": "We predict the landmark and their respective classes for the test data-set and submitted it to kaggle competiton \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9954525594318614
      ],
      "excerpt": "Our Final Kaggle Rank is 134 out of 309 participants [as on 27th April 16.00] with a score of 0.003 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9202694798944743
      ],
      "excerpt": "We got this score by training on just 50 percent of the dataset, so we hope to get a better score by training on entire dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A Kaggle challenge which aims at helping people organize their photo collection, Result: 46th percentile",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ankit-vaghela30/Google-landmark-prediction/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 22 Dec 2021 03:09:56 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ankit-vaghela30/Google-landmark-prediction/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ankit-vaghela30/Google-landmark-prediction",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/ankit-vaghela30/Google-landmark-prediction/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ankit-vaghela30/Google-landmark-prediction/master/notebooks/object_detection_tutorial.ipynb",
      "https://raw.githubusercontent.com/ankit-vaghela30/Google-landmark-prediction/master/notebooks/simple_data_proc_model.ipynb",
      "https://raw.githubusercontent.com/ankit-vaghela30/Google-landmark-prediction/master/notebooks/view_data.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8005503433443634
      ],
      "excerpt": "- process : Specify if you want to train or test the dataset and keep empty if train and test both required \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8563874967896019
      ],
      "excerpt": "                  Ex: --path=\"/home/ubuntu/img.npy\" \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8621882743635256,
        0.8731263862707107,
        0.8743825276728258,
        0.9134583912820858,
        0.8031237603623868
      ],
      "excerpt": "File descriptions: \ntrain.csv - the training image set \ntest.csv - the test set containing the test images for which we may predict landmarks \nsample submission.csv - a sample submission file format \nThere are overall approximately 1.2 million train images with 15,000 unique classes, whereas 0.1 million testing images for labeling and classification. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8541476144391582
      ],
      "excerpt": "                  Ex: --process= \"train\", --mode= \"test\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8016964785020443
      ],
      "excerpt": "The Sample Submission format is \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ankit-vaghela30/Google-landmark-prediction/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Data Science Practicum\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Team-Bulldawgs",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Google-landmark-prediction",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ankit-vaghela30",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ankit-vaghela30/Google-landmark-prediction/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The project requires the following technologies to be installed.\n* Instructions to download and install Python can be found [here](https://www.python.org/).\n* Instructions to download and install Keras can be found [here](https://keras.io/).\n* Instructions to download and install Anaconda can be found [here](https://www.continuum.io/downloads).\n* Instructions to download and install Tensor Flow can be found [here](https://www.tensorflow.org/install/install_mac).\n* Instructions to download and install OpenCV Library can be found [here](https://opencv.org/).\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 22 Dec 2021 03:09:56 GMT"
    },
    "technique": "GitHub API"
  }
}
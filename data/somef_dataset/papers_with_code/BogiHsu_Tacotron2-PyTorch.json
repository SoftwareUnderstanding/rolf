{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This project is highly based on the works below.\n- [Tacotron2 by NVIDIA](https://github.com/NVIDIA/tacotron2)\n- [Tacotron by r9y9](https://github.com/r9y9/tacotron_pytorch)\n- [Tacotron by keithito](https://github.com/keithito/tacotron)\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BogiHsu/Tacotron2-PyTorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-02T12:39:51Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-20T09:40:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9905256066305418,
        0.9567588029116127
      ],
      "excerpt": "Yet another PyTorch implementation of Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions. The project is highly based on these. I made some modification to improve speed and performance of both training and inference. \n[ ] Combine with WG-WaveNet. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9612457845281608
      ],
      "excerpt": "A vocoder is not implemented yet. For now it just reconstucts the linear spectrogram from the Mel spectrogram directly and uses Griffim-Lim to synthesize the waveform. A pipeline for WG-WaveNet is in progress. Or you can refer to WaveNet, FFTNet, or WaveGlow. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8887137007595668
      ],
      "excerpt": "The alignment of the attention is pretty well now (about 100k training steps), the following figure is one sample. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Yet another PyTorch implementation of Tacotron 2 with reduction factor and faster training speed.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BogiHsu/Tacotron2-PyTorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 18,
      "date": "Sat, 25 Dec 2021 18:34:23 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/BogiHsu/Tacotron2-PyTorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "BogiHsu/Tacotron2-PyTorch",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8283741543622575
      ],
      "excerpt": "For training Tacotron2, run the following command. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9823962993949036
      ],
      "excerpt": "For using Tensorboard (optional), run the following command. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8805691791884755
      ],
      "excerpt": "For synthesizing wav files, run the following command. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9015861646048864
      ],
      "excerpt": "You can download pretrained models from here (git commit: 9e7c26d). The hyperparameter for training is also in the directory. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8243781632260241
      ],
      "excerpt": "[ ] Add Colab demo. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8399547156064402
      ],
      "excerpt": "For training using a pretrained model, run the following command. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8290302448337716
      ],
      "excerpt": "You can find alinment images and synthesized audio clips during training. Recording freqency and text to synthesize can be set in hparams.py. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/BogiHsu/Tacotron2-PyTorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright (c) 2017 Keith Ito\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\nTHE SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Tacotron2-PyTorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Tacotron2-PyTorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "BogiHsu",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BogiHsu/Tacotron2-PyTorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Python >= 3.5.2\n- torch >= 1.0.0\n- numpy\n- scipy\n- pillow\n- inflect\n- librosa\n- Unidecode\n- matplotlib\n- tensorboardX\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 102,
      "date": "Sat, 25 Dec 2021 18:34:23 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "tacotron2-pytorch",
      "tacotron2",
      "tacotron",
      "pretrained-models",
      "reduction-factor",
      "pytorch",
      "tts",
      "text-to-speech",
      "ljspeech"
    ],
    "technique": "GitHub API"
  }
}
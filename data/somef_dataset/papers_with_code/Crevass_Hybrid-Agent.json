{
  "citation": [
    {
      "confidence": [
        0.9984648347672445
      ],
      "excerpt": "A method of hybrid agent and training algorithm using both on-policy loss function and off-policy loss function, reference to DDPG(http://arxiv.org/abs/1509.02971) and DPPO(http://arxiv.org/abs/1707.06347). \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Crevass/Hybrid-Agent",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-02-11T13:56:48Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-11T15:10:50Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9067504887863073
      ],
      "excerpt": "On/off-policy hybrid agent and algorithm with LSTM network and tensorflow. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "On/off-policy hybrid agent and algorithm with LSTM network and tensorflow",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Crevass/Hybrid-Agent/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 08:52:28 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Crevass/Hybrid-Agent/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Crevass/Hybrid-Agent",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Crevass/Hybrid-Agent/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Hybrid-Agent",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Hybrid-Agent",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Crevass",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Crevass/Hybrid-Agent/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 23 Dec 2021 08:52:28 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To start training a agent, run **testrun.py**. Tune the parameters in this file as you like.Either to train a new agent with **Restore_iter = None** or restore network weights with **Restore_iter**.\nTensorflow ckpt files will be saved in **tf_saver**, video of environments will be saved in **video**, and replay buffer's data will be saved in **replays**.\n",
      "technique": "Header extraction"
    }
  ]
}
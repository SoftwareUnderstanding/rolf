{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1810.04805. \n\nThe original repository of Google Research can be found at : https://github.com/google-research/bert\n\nWe will also inspire our work and research in the pytorch implementation of BERT made by huggingface : https://github.com/huggingface/pytorch-pretrained-BERT/\n\nIn a first moment we have devoted all our efforts to better understand how it works and why it is considered a breakthrough in the NLP reasearch field. Some remarkable material can be found in the internet including the following ones :\n\n* Bert paper: https://arxiv.org/pdf/1810.04805.pdf\n\n* https://jalammar.github.io/illustrated-bert/\n\n* https://jalammar.github.io/illustrated-transformer/\n\n\nIn a second step we will be fine-tuning, adapting and applying existing models to real-life applications as Kaggles competitions and the SQuAD Dataset. Some of the competitions we have applied and/or are intending to apply are: \n\n\n| Use Case  | Link | Our results |\n|:---------:|:----:|:-----------:|\n| Kaggle: Quora Insincere Questions Classification  | https://www.kaggle.com/c/quora-insincere-questions-classification | F-Score 0.70240 / Acc: 0.96 |\n| Kaggle: WSDM Fake News detection|  https://www.kaggle.com/c/fake-news-pair-classification-challenge/ | 0.86535 |\n| Kaggle: Toxic Comment Classification Challenge - Glove Comparation |  https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/ |Mean column-wise Area under ROC-Curve // Glove: 0.97718 Vs Bert: 0.97922 |\n| French transformation of word vectors |  https://www.kaggle.com/c/detecting-insults-in-social-commentary | Extracted Word vectors but did not implement a specific task |\n\nInstructions to run the code:\n\n## Quora Insincere Questions Classification\n\nTo finetune BERT for this competition please <a href=\"https://www.kaggle.com/c/quora-insincere-questions-classification/data\n\" target=\"_blank\">download the dataset from the Kaggle competition</a> and put it in a folder called `input` inside the directory containing the `bert-classification.ipynb` script. \n\nYou should have installed pandas, numpy, sklearn, tensorflow, zipfile, matplotlib and tqdm.\n\nIt took 48 hours to train 3 epochs in an Azure VM: Standard NC24 (24 vcpus, 224 GB memory"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9991295298092048
      ],
      "excerpt": "Bert paper: https://arxiv.org/pdf/1810.04805.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9287913210266059,
        0.874446915586759
      ],
      "excerpt": "| Kaggle: WSDM Fake News detection|  https://www.kaggle.com/c/fake-news-pair-classification-challenge/ | 0.86535 | \n| Kaggle: Toxic Comment Classification Challenge - Glove Comparation |  https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/ |Mean column-wise Area under ROC-Curve // Glove: 0.97718 Vs Bert: 0.97922 | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/viniciusoliveirasd/bert-applications",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-12T12:31:21Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-17T05:40:34Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9722306090604317
      ],
      "excerpt": "Google's Bert algorithm study and real-life applications for Deep Learning project \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9542567312724267,
        0.9687561244900038
      ],
      "excerpt": "We will also inspire our work and research in the pytorch implementation of BERT made by huggingface : https://github.com/huggingface/pytorch-pretrained-BERT/ \nIn a first moment we have devoted all our efforts to better understand how it works and why it is considered a breakthrough in the NLP reasearch field. Some remarkable material can be found in the internet including the following ones : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9770893873328528
      ],
      "excerpt": "In a second step we will be fine-tuning, adapting and applying existing models to real-life applications as Kaggles competitions and the SQuAD Dataset. Some of the competitions we have applied and/or are intending to apply are:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Google's Bert algorithm study and real-life applications for Deep Learning project",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/viniciusoliveirasd/bert-applications/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Wed, 29 Dec 2021 18:49:54 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/viniciusoliveirasd/bert-applications/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "viniciusoliveirasd/bert-applications",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/viniciusoliveirasd/bert-applications/master/Bert-SQUAD.ipynb",
      "https://raw.githubusercontent.com/viniciusoliveirasd/bert-applications/master/FakeNews/FakeNews.ipynb",
      "https://raw.githubusercontent.com/viniciusoliveirasd/bert-applications/master/.ipynb_checkpoints/introducing-bert-with-tensorflow-checkpoint.ipynb",
      "https://raw.githubusercontent.com/viniciusoliveirasd/bert-applications/master/Quora_Insincere_Questions_Classification/bert-classification.ipynb",
      "https://raw.githubusercontent.com/viniciusoliveirasd/bert-applications/master/toxicComments/exploratory_toxicComments.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8794429890722626
      ],
      "excerpt": "Instructions to run the code: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9728309231528648
      ],
      "excerpt": "You should have installed pandas, numpy, sklearn, tensorflow, zipfile, matplotlib and tqdm. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9828256591365364
      ],
      "excerpt": "You should have installed pandas, numpy, sklearn, pytorch and pytorch-pretrained-bert. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9828256591365364
      ],
      "excerpt": "You should have installed keras, pandas, numpy, sklearn, pytorch and pytorch-pretrained-bert. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8487502354932437
      ],
      "excerpt": "\" target=\"_blank\">download the dataset from the Kaggle competition</a> and put it in a folder called input inside the directory containing the bert-classification.ipynb script.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9209091246933827
      ],
      "excerpt": "\" target=\"_blank\">download the dataset from the Kaggle competition</a> and put it in a folder called input inside the directory containing the train.py script.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8455183300148577
      ],
      "excerpt": "Run all the pipeline script with python train_model_final.py directly. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/viniciusoliveirasd/bert-applications/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "bert-benchmarks",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "bert-applications",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "viniciusoliveirasd",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/viniciusoliveirasd/bert-applications/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Wed, 29 Dec 2021 18:49:54 GMT"
    },
    "technique": "GitHub API"
  }
}
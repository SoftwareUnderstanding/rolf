{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1512.03385",
      "https://arxiv.org/abs/1902.00249"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* [DeepMind original blog post](https://deepmind.com/blog/alphafold/)\n* [AlphaFold @ CASP13: \u201cWhat just happened?\u201d](https://moalquraishi.wordpress.com/2018/12/09/alphafold-casp13-what-just-happened/#s2.2)\n* [Siraj Raval's YT video on AlphaFold](https://www.youtube.com/watch?v=cw6_OP5An8s)\n* [ProteinNet dataset](https://github.com/aqlaboratory/proteinnet)\n* [Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005324)\n* [AlphaFold slides](http://predictioncenter.org/casp13/doc/presentations/Pred_CASP13-DeepLearning-AlphaFold-Senior.pdf)\n* [De novo protein structure prediction using ultra-fast molecular dynamics simulation](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0205819)\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@misc{ericalcaide2019\n  title = {MiniFold: a DeepLearning-based Mini Protein Folding Engine},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  author = {Alcaide, Eric},\n  year = {2019},\n  howpublished = {\\url{https://github.com/EricAlcaide/MiniFold/}},\n  doi = {10.5281/zenodo.3774491},\n  url = {https://doi.org/10.5281/zenodo.3774491}\n}\n```\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{ericalcaide2019\n  title = {MiniFold: a DeepLearning-based Mini Protein Folding Engine},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  author = {Alcaide, Eric},\n  year = {2019},\n  howpublished = {\\url{https://github.com/EricAlcaide/MiniFold/}},\n  doi = {10.5281/zenodo.3774491},\n  url = {https://doi.org/10.5281/zenodo.3774491}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "<div style=\"text-align:center\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "<div style=\"text-align:center\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "<div style=\"text-align:center\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "<div style=\"text-align:center\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "<div style=\"text-align:center\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "<div style=\"text-align:center\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9818894004866677
      ],
      "excerpt": "    AUTHOR 1234-5678-9000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.967055247173021
      ],
      "excerpt": "    1 10 0 8 0.715       #: &lt;- i=1 j=10: indices of residues (integers),  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772103324673378,
        0.8955886365383559
      ],
      "excerpt": "    30 37 0 8 0.678      #:    predicted for the residue pair (i,j)   \n    11 29 0 8 0.673        \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8115087326492553
      ],
      "excerpt": "    21 37 0 8 0.502      #:    being in contact (in descending order)  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    END \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9942045794539209
      ],
      "excerpt": "* Author's GitHub Profile: Eric Alcaide \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hypnopump/MiniFold",
    "technique": "GitHub API"
  },
  "contributors": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributors\nHere's a list of people who have made code contributions to this project: \n* @EricAlcaide\n* @McMenemy\n* @roberCO\n* @pabloAMC",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-02-27T09:38:00Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T01:28:56Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[DeepMind](https://deepmind.com), a company affiliated with Google and specialized in AI, presented a novel algorithm for Protein Structure Prediction at [CASP13](http://predictioncenter.org/casp13/index.cgi) (a competition which goal is to find the best algorithms that predict protein structures in different categories).\n\nThe Protein Folding Problem is an interesting one since there's tons of DNA sequence data available and it's becoming cheaper and cheaper at an unprecedented rate (faster than [Moore's law](https://www.genome.gov/27541954/dna-sequencing-costs-data/)). The cells build the proteins they need through **transcription** (from DNA to RNA) and **translation** (from RNA to Aminocids (AAs)). However, the function of a protein does not depend solely on the sequence of AAs that form it, but also their spatial 3D folding. Thus, it's hard to predict the function of a protein from its DNA sequence. **AI** can help solve this problem by learning the relations that exist between a determined sequence and its spatial 3D folding. \n\nThe DeepMind work presented @ CASP was not a technological breakthrough (they did not invent any new type of AI) but an **engineering** one: they applied well-known AI algorithms to a problem along with lots of data and computing power and found a great solution through model design, feature engineering, model ensembling and so on. DeepMind has no plan to open source the code of their model nor set up a prediction server.\n\nBased on the premise exposed before, the aim of this project is to build a model suitable for protein 3D structure prediction inspired by AlphaFold and many other AI solutions that may appear and achieve SOTA results.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9476822977562321,
        0.9719017735723374,
        0.9966531967814868,
        0.9972970439908471,
        0.9648364714950607
      ],
      "excerpt": "Introduction: The Protein Folding Problem (predicting a protein structure from its sequence) is an interesting one since DNA sequence data available is becoming cheaper and cheaper at an unprecedented rate, even faster than Moore's law 1. Recent research has applied Deep Learning techniques in order to accurately predict the structure of polypeptides [2, 3].  \nMethods: In this work, we present an attempt to imitate the AlphaFold system for protein prediction architecture [3]. We use 1-D Residual Networks (ResNets) to predict dihedral torsion angles and 2-D ResNets to predict distance maps between the protein amino-acids[4]. We use the CASP7 ProteinNet dataset section for training and evaluation of the model [5]. An open-source implementation of the system described can be found here. \nResults: We are able to obtain distance maps and torsion angle predictions for a protein given it's sequence and PSSM. Our angle prediction model scores a 0.39 of MAE (Mean Absolute Error), and 0.39 and 0.43 R^2 coefficients for Phi and Psi respectively, whereas SoTA is around 0.69 (Phi) and 0.73 (Psi). Our methods do not include post-processing of Deep Learning outputs, which can be very noisy.  \nConclusion: We have shown the potential of Deep Learning methods and its possible application to solve the Protein Folding Problem. Despite technical limitations, Neural Networks are able to capture relations between the data. Although our visually pleasant results, our system lacks components such as the protein structure prediction from both dihedral torsion angles and the distance map of a given protein and the post-processing of our predictions in order to reduce noise. \nThe methods implemented are inspired by DeepMind's original post. Two different residual neural networks (ResNets) are used to predict angles between adjacent aminoacids (AAs) and distance between every pair of AAs of a protein. For distance prediction a 2D Resnet was used while for angles prediction a 1D Resnet was used. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9880047464877604,
        0.9867408550888919,
        0.9750324763624337
      ],
      "excerpt": "The ResNet for distance prediction is built as a 2D-ResNet and takes as input tensors of shape LxLxN (a normal image would be LxLx3). The window length is set to 200 (we only train and predict proteins of less than 200 AAs) and smaller proteins are padded to match the window size. No larger proteins nor crops of larger proteins are used. \nThe 41 channels of the input are distributed as follows: 20 for AAs in one-hot encoding (LxLx20), 1 for the Van der Waals radius of the AA encoded previously and 20 channels for the Position Specific Scoring Matrix). \nThe network is comprised of packs of residual blocks with the architecture below illustrated with blocks cycling through 1,2,4 and 8 strides plus a first normal convolutional layer and the last convolutional layer where a Softmax activation function is applied to get an output of LxLx7 (6 classes for different distance + 1 trash class for the padding that is less penalized). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222843704722167,
        0.8977867758815959,
        0.9931088031312493
      ],
      "excerpt": "Architecture of the residual block used. A mini version of the block in this description \nThe network has been trained with 134 proteins and evaluated with 16 more. Clearly unsufficient data, but memory constraints didn't allow for more. Comparably, AlphaFold was trained with 29k proteins. \nThe output of the network is, then, a classification among 6 classes wich are ranges of distances between a pair of AAs. Here there's an example of AlphaFold predicted distances and the distances predicted by our model: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8141073309842517
      ],
      "excerpt": "Ground truth (left) and predicted distances (right) by AlphaFold. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8141073309842517,
        0.9785471879733469,
        0.9942077334996458,
        0.9888591916344464,
        0.9762863982181461,
        0.8286412408182858
      ],
      "excerpt": "Ground truth (left) and predicted distances (right) by MiniFold. \nThe architecture of the Residual Network for distance prediction is very simmilar, the main difference being that the model here described was trained with windows of 200x200 AAs while AlphaFold was trained with crops of 64x64 AAs. When it comes to prediction, AlphaFold used the smaller window size to average across different outputs and achieve a smoother result. Our prediction, however, is a unique window, so there's no average (noisier predictions). \nThe ResNet for angles prediction is built as a 1D-ResNet and takes as input tensors of shape LxN. The window length is set to 34 and we only train and predict aangles of proteins with less than 200 (L) AAs. No larger proteins nor crops of larger proteins are used. \nThe 42 (N) channels of the input are distributed as follows: 20 for AAs in one-hot encoding (Lx20), 2 for the Van der Waals radius and the surface accessibility of the AA encoded previously and 20 channels for the Position Specific Scoring Matrix). \nWe followed the ResNet20 architecture but replaced the 2D Convolutions by 1D convolutions. The network output consists of a vector of 4 numbers that represent the sin and cos of the 2 dihedral angles between two AAs (Phi and Psi). \nDihedral angles were extracted from raw coordinates of the protein backbone atoms (N-terminus, C-alpha and C-terminus of each AA). The plot of Phi and Psi recieves the name of Ramachandran plot:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.918305111155819,
        0.9613534908404198
      ],
      "excerpt": "The cluster observed in the upper-left region corresponds to the angles comprised between AAs when they form a Beta-sheet while the cluster observed in the central-left region corresponds to the angles comprised between AAs when they form an Alpha-helix. \nThe results of the model when making predictions can be observed below: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8645541386474191,
        0.9094051161739616,
        0.9948958418167845,
        0.991660724912343
      ],
      "excerpt": "The network has been trained with crops 38,7k crops from 600 different proteins and evaluated with some 4,3k more. \nThe architecture of the Residual Network is different from the one implemented in AlphaFold. The model here implemented was inspired by this paper and this one. \nWhile the architectures implemented in this first preliminary version of the project are inspired by papers with great results, the results here obtained are not as good as they could be. It's likely that the lack of Multiple Alignmnent (MSA), MSA-based features, Physicochemichal properties of AAs (beyond Van der Waals radius) or the lack of both model and feature engineering have affected the models negatively, as well as the little data that they have been trained on.  \nFor that reason, we can conclude that it has been a somehow naive approach and we expect to further implement some ideas/improvements to these models. As the DeepMind team says: \"With few or no alignments accuracy is much worse\". It would be interesting to use the predictions made by the models as constraints to a folding algorithm (ie. Rosetta) in order to visualize our results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8343736689671529
      ],
      "excerpt": "3. Get & format the data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8066815521141917
      ],
      "excerpt": "4. Execute data preprocessing notebooks (preprocessing folder) in the following order (we plan to release simple scripts instead of notebooks very soon): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8320013758236424,
        0.9196811889390669
      ],
      "excerpt": "6. 3D structure modelling from predicted results \n     1. For RR format conversion and 3D structure modelling follow the steps given in models/distance_pipeline/Tutorials/README.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9863593966163803
      ],
      "excerpt": "Presently the post processing of the predictions is done using a python script which converts the predicted results into RR format known as Residue-Residue contact prediction format. This format represents the probability of contact between pairwise residues. Data in this format are inserted between MODEL and END records of the submission file. The prediction starts with the sequence of the predicted target splitted.The sequence is followed by the list of contacts in the five-column format as represented below :  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9340758956498939,
        0.9340758956498939,
        0.860059181823877
      ],
      "excerpt": "    METHOD Description of methods used \n    METHOD Description of methods used \n    MODEL  1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8985440094368098
      ],
      "excerpt": "    1 9 0 8 0.63         #: &lt;- p=0.63: probability of the residues i=1 and j=9  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9889518933840182,
        0.8692236066389427
      ],
      "excerpt": "There is plenty of ideas that could not be tried in this project due to computational and time constraints. In a brief way, some promising ideas or future directions are listed below: \nTrain with crops of 64x64 AAs, not windows of 200x200 AAs and average at prediction time. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8060160865345517
      ],
      "excerpt": "Train with more data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9620857076892851,
        0.9354151211866858,
        0.9867160485126154
      ],
      "excerpt": "They will be listed below in order to give a sense about what this project is and what it's not. \nNo usage of Multiple Sequence Alignments (MSA): The methods developed in this project don't use MSA nor MSA-based features as input.  \nComputing power/memory: Development of the project has taken part in a computer with the following specifications: Intel i7-6700k, 8gb RAM, NVIDIA GTX-1060Ti 6gb and 256gb of storage. The capacity for data exploration, processing, training and evaluating the models is limited. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9077062292877414,
        0.9261515910859364,
        0.9251981995777534,
        0.9715026352235085,
        0.9214567614478315,
        0.80664508939415
      ],
      "excerpt": "Time: Three weeks of development during spare time. \nDomain expertise: No experts in the field of genomics, proteomics or bioinformatics. The author knows the basics of Biochemistry and Deep Learning. \nData: The average paper about Protein Structure Prediction uses a personalized dataset acquired from the Protein Data Bank (PDB). No such dataset was used. Instead, we used a subset of the ProteinNet dataset from CASP7. Our models are trained with just 150 proteins (distance prediction) and 600 proteins (angles prediction) due to memory constraints.  \nDue to these limitations and/or constraints, the precission/accuracy the methods here developed can achieve is limited when compared against State Of The Art algorithms. \nHey there! New ideas are welcome: open/close issues, fork the repo and share your code with a Pull Request. \nClone this project to your computer: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9703076250690132
      ],
      "excerpt": "By participating in this project, you agree to abide by the thoughtbot code of conduct \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "MiniFold: Deep Learning for Protein Structure Prediction inspired by DeepMind AlphaFold algorithm",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/EricAlcaide/MiniFold/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 33,
      "date": "Sat, 25 Dec 2021 17:18:12 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hypnopump/MiniFold/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "hypnopump/MiniFold",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/EricAlcaide/MiniFold/master/preprocessing/get_angles_from_coords_py.ipynb",
      "https://raw.githubusercontent.com/EricAlcaide/MiniFold/master/preprocessing/julia_get_proteins_under_200aa.ipynb",
      "https://raw.githubusercontent.com/EricAlcaide/MiniFold/master/preprocessing/angle_data_preparation_py.ipynb",
      "https://raw.githubusercontent.com/EricAlcaide/MiniFold/master/models/distance_pipeline/pretrain_model_pssm_l_x_l.ipynb",
      "https://raw.githubusercontent.com/EricAlcaide/MiniFold/master/models/old_distances/predicting_distances.ipynb",
      "https://raw.githubusercontent.com/EricAlcaide/MiniFold/master/models/angles/predicting_angles.ipynb",
      "https://raw.githubusercontent.com/EricAlcaide/MiniFold/master/models/new_distances/resume_training.ipynb",
      "https://raw.githubusercontent.com/EricAlcaide/MiniFold/master/models/new_distances/pretrain_model.ipynb"
    ],
    "technique": "File Exploration"
  },
  "identifier": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://zenodo.org/badge/latestdoi/172886347",
      "technique": "Regular expression"
    }
  ],
  "installation": [
    {
      "confidence": [
        0.9915825963699263,
        0.9996106141166458
      ],
      "excerpt": "1. Clone the repo: git clone https://github.com/EricAlcaide/MiniFold \n2. Install dependencies: pip install -r requirements.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8190097035596196
      ],
      "excerpt": "        1. Alternatively: julia_get_proteins_under_200aa.ipynb (you will need Julia as well as iJulia) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8086269452330828
      ],
      "excerpt": "5. Run the models! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9879863063452118
      ],
      "excerpt": "git clone https://github.com/EricAlcaide/MiniFold \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8796698585445977
      ],
      "excerpt": "    <img src=\"imgs/elu_resnet_2d.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8882747530828131
      ],
      "excerpt": "    <img src=\"imgs/alphafold_preds.png\", width=\"600\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9154586948950197
      ],
      "excerpt": "    <img src=\"models/distance_pipeline/images/golden_img_v91_45.png\", width=\"900\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8796698585445977
      ],
      "excerpt": "    <img src=\"imgs/ramachandran_plot.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8796698585445977
      ],
      "excerpt": "    <img src=\"imgs/angle_preds.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8922866962005643
      ],
      "excerpt": "    1. Download data here (select CASP7 text-based format) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8133822741608022
      ],
      "excerpt": "5. Run the models! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9144810508102184
      ],
      "excerpt": "        2. models/distance_pipeline/pipeline_caller.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.861501786681776
      ],
      "excerpt": "    HDFGRTYIWQMSDASHMD   #:   residues per line) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.811854372964597
      ],
      "excerpt": "    8 15 0 8 0.401 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.811854372964597
      ],
      "excerpt": "    5 15 0 8 0.307 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8272724580966535
      ],
      "excerpt": "Train with more data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8218735148069495
      ],
      "excerpt": "Set up a prediction script/pipeline from raw text/FASTA file \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hypnopump/MiniFold/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Julia"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Eric Alcaide\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "MiniFold",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "MiniFold",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "hypnopump",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hypnopump/MiniFold/blob/master/readme.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "hypnopump",
        "body": "MiniFold incorporates the following functionalities: \r\n- [x] read a large number of proteins and select the ones under certain length\r\n- [x] calculate dihedral angles and a distance map\r\n- [x] train a 1-D ResNet to predict the angles\r\n- [x] train a 2-D ResNet to predict the distance map\r\n\r\nMiniFold uses Tensorflow + Keras",
        "dateCreated": "2020-04-28T20:31:09Z",
        "datePublished": "2020-04-28T20:40:04Z",
        "html_url": "https://github.com/hypnopump/MiniFold/releases/tag/v1.0",
        "name": "MiniFold Release",
        "tag_name": "v1.0",
        "tarball_url": "https://api.github.com/repos/hypnopump/MiniFold/tarball/v1.0",
        "url": "https://api.github.com/repos/hypnopump/MiniFold/releases/25980778",
        "zipball_url": "https://api.github.com/repos/hypnopump/MiniFold/zipball/v1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 171,
      "date": "Sat, 25 Dec 2021 17:18:12 GMT"
    },
    "technique": "GitHub API"
  }
}
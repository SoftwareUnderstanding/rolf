{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.10593\n#### Example\n```\n$ cd CycleGAN/\n$ python CycleGAN_model.py\n```\nAn example of the generated adversarial examples is as follows:\n\n<img src=\"https://github.com/QXL4515/CAGFuzz/blob/master/picture/D1.jpg\" width=\"290\"/><img src=\"https://github.com/QXL4515/CAGFuzz/blob/master/picture/D2.jpg\" width=\"290\"/><img src=\"https://github.com/QXL4515/CAGFuzz/blob/master/picture/D3.jpg\" width=\"290\"/><img src=\"https://github.com/QXL4515/CAGFuzz/blob/master/picture/D4.jpg\" width=\"290\"/><img src=\"https://github.com/QXL4515/CAGFuzz/blob/master/picture/D5.jpg\" width=\"290\"/><img src=\"https://github.com/QXL4515/CAGFuzz/blob/master/picture/D6.jpg\" width=\"290\"/>\n\n\n## model\nThis folder contains six neural networks for image recognition and a function for recording training loss, namely:\n* LeNet-1\n* LeNet-4\n* LeNet-5\n* VGG-16\n* VGG-19\n* ResNet-20\n* LossHistory\n\nIf you want to train a LeNet-1 model of your own, please do as follows:\n```\npython LeNet-1.py\n```\nIf you want to train a VGG-16 model of your own, please do as follows:\n```\npython VGG-16.py\n```\n\n## similarity\nThis folder contains two Python files, one is `vgg19_feature.py`, which is used to extract the depth features of pictures, the other is `utility.py`, which is used to compare the cosine similarity between the depth features of two pictures.\n\nIf you want to extract the depth features of an image, you can do this:\n```python\nfrom keras.applications.vgg19 import VGG19\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.models import Model\nimport numpy as np\ndef get_feature(img_dir"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.944164081884528
      ],
      "excerpt": "img = Image.open('./datasets/cifar-10/coverage/img-0-frog.png') \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/QXL4515/CAGFuzz",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-11-14T02:04:17Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-26T14:20:48Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9186281918198238
      ],
      "excerpt": "CAGFuzz, a Coverage-guided Adversarial Generative Fuzzing testing approach for DL systems. The goal of the CAGFuzz is to maximize the neuron coverage and generate adversarial test examples as much as possible with minor perturbations for the target DNNs. It mainly consists of four folders\uff1a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "* model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.860059181823877
      ],
      "excerpt": "model = load_model(\"./model/model_LeNet-1.h5\") \ncoverage = NCoverage(model, 0.1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9386110117500871
      ],
      "excerpt": "Implementation of Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9792646874149533
      ],
      "excerpt": "This folder contains two Python files, one is vgg19_feature.py, which is used to extract the depth features of pictures, the other is utility.py, which is used to compare the cosine similarity between the depth features of two pictures. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8900905399342893
      ],
      "excerpt": "The general process of CAG is shown in the figure above. The specific process can be as follows: \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/QXL4515/CAGFuzz/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Wed, 29 Dec 2021 12:09:14 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/QXL4515/CAGFuzz/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "QXL4515/CAGFuzz",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8801854956928516,
        0.8900486270063179
      ],
      "excerpt": "from Keras_coverage import NCoverage \nfrom keras.models import load_model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.801059349406458,
        0.8118308551174335
      ],
      "excerpt": "img = Image.open('./datasets/cifar-10/coverage/img-0-frog.png') \nimg = np.array(img).astype('float32').reshape(-1, 32, 32, 3) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.853492186136904,
        0.9500567947117212
      ],
      "excerpt": "covered, total, p = coverage.curr_neuron_cov() \nprint(covered, total, p) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python LeNet-1.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8934859586593727
      ],
      "excerpt": "python VGG-16.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9040368155137037,
        0.9457175861910134
      ],
      "excerpt": "from keras.models import Model \nimport numpy as np \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8719491278656056
      ],
      "excerpt": "    model = Model(input=base_model.input, output=base_model.get_layer('fc2').output) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8973933083440926
      ],
      "excerpt": "    x = np.expand_dims(x, axis=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8525645461651434,
        0.9312650322969277,
        0.936606094659785
      ],
      "excerpt": "    f = model.predict(x) \n    print(f.shape) \n    print(f) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from utility import get_cossimi \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8291725648705406,
        0.8075602708641384
      ],
      "excerpt": "* First, we need to call CycleGAN_,odel.py in CycleGAN to train AGE. \n* Then, the function of feature extraction is realized by vgg19_feature.py file in folder similarity. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/QXL4515/CAGFuzz/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "CAGFuzz",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "CAGFuzz",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "QXL4515",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/QXL4515/CAGFuzz/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Wed, 29 Dec 2021 12:09:14 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n$ cd CycleGAN/\n$ python CycleGAN_model.py\n```\nAn example of the generated adversarial examples is as follows:\n\n<img src=\"https://github.com/QXL4515/CAGFuzz/blob/master/picture/D1.jpg\" width=\"290\"/><img src=\"https://github.com/QXL4515/CAGFuzz/blob/master/picture/D2.jpg\" width=\"290\"/><img src=\"https://github.com/QXL4515/CAGFuzz/blob/master/picture/D3.jpg\" width=\"290\"/><img src=\"https://github.com/QXL4515/CAGFuzz/blob/master/picture/D4.jpg\" width=\"290\"/><img src=\"https://github.com/QXL4515/CAGFuzz/blob/master/picture/D5.jpg\" width=\"290\"/><img src=\"https://github.com/QXL4515/CAGFuzz/blob/master/picture/D6.jpg\" width=\"290\"/>\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
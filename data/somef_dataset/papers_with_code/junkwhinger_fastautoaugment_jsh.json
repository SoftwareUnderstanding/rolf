{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1905.00397\">Fast AutoAugment</a> in Pytorch.\n\n\n\n## Summary\n\n- Fast AutoAugment (hereafter FAA",
      "https://arxiv.org/abs/1805.09501\">AutoAugment</a> but in a much shorter period of time.\n- Unlike AutoAugment that discretizes the search space, FAA can handle continuous search space directly.\n\n<br>\n\n\n\n## Getting Started\n\n```bash\n$ git clone https://github.com/junkwhinger/fastautoaugment_jsh.git\ncd fastautoaugment_jsh\n```\n\n\n\n### Install dependencies\n\n```bash\npip install -r requirements.txt\n```\n\n\n\n### Training\n\nYou can train or test the model with the baseline or optimal augmentation policies found by FAA with the following commands.\n\n#### Test Only\n\n```bash\n# Baseline\npython train.py --model_dir experiments/baseline --eval_only\n\n# Fast AutoAugment\npython train.py --model_dir experiments/fastautoaugment --eval_only\n```\n\n\n\n#### Training + Evaluation\n\n```bash\n# Baseline\npython train.py --model_dir experiments/baseline\n\n# Fast AutoAugment\npython train.py --model_dir experiments/fastautoaugment\n```\n\n\n\n### Fast AutoAugment\n\nYou can run Fast AutoAugment with the following commands. It takes time.\n\n- train_mode: train models on D_Ms for 5 splits (takes roughly 4.5 hours",
      "https://arxiv.org/abs/1905.00397\n   - Codes: https://github.com/kakaobrain/fast-autoaugment\n   - GradualWarmupScheduler: https://github.com/ildoonet/pytorch-gradual-warmup-lr\n2. AutoAugment\n   - Paper: https://arxiv.org/abs/1805.09501\n   - Codes:https://github.com/tensorflow/models/tree/master/research/autoaugment\n3. Wide Residual Network\n   - Paper: https://arxiv.org/pdf/1605.07146v2.pdf\n   - Codes: https://github.com/meliketoy/wide-resnet.pytorch\n4. HyperOpt\n   - Official Documentation: [http://hyperopt.github.io/hyperopt/](http://hyperopt.github.io/hyperopt/",
      "https://arxiv.org/abs/1805.09501\n   - Codes:https://github.com/tensorflow/models/tree/master/research/autoaugment\n3. Wide Residual Network\n   - Paper: https://arxiv.org/pdf/1605.07146v2.pdf\n   - Codes: https://github.com/meliketoy/wide-resnet.pytorch\n4. HyperOpt\n   - Official Documentation: [http://hyperopt.github.io/hyperopt/](http://hyperopt.github.io/hyperopt/"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Fast AutoAugment\n   - Paper: https://arxiv.org/abs/1905.00397\n   - Codes: https://github.com/kakaobrain/fast-autoaugment\n   - GradualWarmupScheduler: https://github.com/ildoonet/pytorch-gradual-warmup-lr\n2. AutoAugment\n   - Paper: https://arxiv.org/abs/1805.09501\n   - Codes:https://github.com/tensorflow/models/tree/master/research/autoaugment\n3. Wide Residual Network\n   - Paper: https://arxiv.org/pdf/1605.07146v2.pdf\n   - Codes: https://github.com/meliketoy/wide-resnet.pytorch\n4. HyperOpt\n   - Official Documentation: [http://hyperopt.github.io/hyperopt/](http://hyperopt.github.io/hyperopt/)\n   - Tutorials: https://medium.com/district-data-labs/parameter-tuning-with-hyperopt-faa86acdfdce\n5. FloydHub (Cloud GPU)\n   - Website: [http://floydhub.com/](http://floydhub.com/)",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9850052496798533
      ],
      "excerpt": "Unofficial and Partial implementation of <a href=\"https://arxiv.org/abs/1905.00397\">Fast AutoAugment</a> in Pytorch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8397586172286151
      ],
      "excerpt": "<img src=\"https://latex.codecogs.com/gif.latex?N\"/>: the number of top policies to keep. <img src=\"https://latex.codecogs.com/gif.latex?N=10\"/> in FAA.  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/junkwhinger/fastautoaugment_jsh",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Junsik Hwang, junsik.whang@gmail.com\n\n\n\n<br>\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-09T10:30:39Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-17T08:18:18Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Fast AutoAugment (hereafter FAA) finds the optimal set of data augmentation operations via density matching using Bayesian optimization.\n- FAA delivers comparable performance to <a href=\"https://arxiv.org/abs/1805.09501\">AutoAugment</a> but in a much shorter period of time.\n- Unlike AutoAugment that discretizes the search space, FAA can handle continuous search space directly.\n\n<br>\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9343977597664257
      ],
      "excerpt": "Here are the checkpoints I made during the replication of the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9434297409018112,
        0.87621829532151,
        0.8149853432750728
      ],
      "excerpt": "Probability <img src=\"https://latex.codecogs.com/gif.latex?p\"/>: (attribute of an operation) the chance that the operation is turned on. This value ranges from 0 to 1, 0 being always off, 1 always on. \nMagnitude <img src=\"https://latex.codecogs.com/gif.latex?\\lambda\"/>: (attribute of an operation) the amount that the operation transforms a given image. This value ranges from 0 to 1, and gets adjusted according to the corresponding range of its operation. For example, <img src=\"https://latex.codecogs.com/gif.latex?\\lambda=0\"/> for Rotate means Rotate -30 degree. \nSub-policy <img src=\"https://latex.codecogs.com/gif.latex?\\tau\"/>: a random sequence of operations. The length of a sub-policy is determined by Search Width(<img src=\"https://latex.codecogs.com/gif.latex?T=2\"/>). For example, a sub-policy that has Cutout and Rotate transforms a given image in 4 ways.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8016275185267057
      ],
      "excerpt": "Each model is trained from scratch without data augmentation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979889450200815
      ],
      "excerpt": "Find the optimal set of sub-policies and probabilities and magnitudes of their operations.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9317300331008204,
        0.8908226715038594
      ],
      "excerpt": "Failed to replicate the Baseline performance of the paper despite the same hyper-parameter set I <i>tried</i> to follow. \nDuring debugging the original code, I found some discrepancies regarding the dataset size that could have caused the issue (covered in-depth in ETC). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8467733277531362
      ],
      "excerpt": "The red dots mark the points with the lowest validation error. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8593777401865956
      ],
      "excerpt": "I did not include SamplePairing from the set of augmentation operations to optimize. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8510267437666746
      ],
      "excerpt": "The images used in the validation phase are augmented with the optimal policies, unlike my previous expectation that we do NOT augment the validation dataset for a normal training loop. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Unofficial and Partial Implementation of Fast AutoAugment in Pytorch",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/junkwhinger/fastautoaugment_jsh/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Search: 7.5 GPU Hours on a single Tesla V100 16GB Memory machine\n(FAA in paper took 3.5 GPU Hours)\n\n| Model(CIFAR-10)  | Baseline(paper) | Baseline(mine) | FAA(paper/direct) | FAA(mine/direct) |\n| ---------------- | --------------- | -------------- | ----------------- | ---------------- |\n| Wide-ResNet-40-2 | 5.3             | 5.6            | 3.7               | 5.5              |\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Sun, 26 Dec 2021 07:26:48 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/junkwhinger/fastautoaugment_jsh/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "junkwhinger/fastautoaugment_jsh",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/junkwhinger/fastautoaugment_jsh/master/Bayesian_Optimization_Visualized.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\npip install -r requirements.txt\n```\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8869677234039565
      ],
      "excerpt": "You can train or test the model with the baseline or optimal augmentation policies found by FAA with the following commands. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8638414879992173
      ],
      "excerpt": "You can run Fast AutoAugment with the following commands. It takes time. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356279518379606
      ],
      "excerpt": "FAA attempts to find the probability <img src=\"https://latex.codecogs.com/gif.latex?p\"/> and magnitude <img src=\"https://latex.codecogs.com/gif.latex?\\lambda\"/> for the following 16 augmentation operations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8137013482471422,
        0.8044771370769852
      ],
      "excerpt": "<img src=\"https://latex.codecogs.com/gif.latex?\\theta\"/>: network to train \n<img src=\"https://latex.codecogs.com/gif.latex?D_{train}\"/>: train dataset that contains 42675 images from cifar10. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8828021798142245
      ],
      "excerpt": "python train.py --model_dir experiments/baseline --eval_only \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.931409250075131
      ],
      "excerpt": "python train.py --model_dir experiments/fastautoaugment --eval_only \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8828021798142245
      ],
      "excerpt": "python train.py --model_dir experiments/baseline \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.931409250075131
      ],
      "excerpt": "python train.py --model_dir experiments/fastautoaugment \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python search_fastautoaugment.py --train_mode --bayesian_mode \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python search_fastautoaugment.py --bayesian_mode \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python search_fastautoaugment.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.831471541301478
      ],
      "excerpt": "fastautoaugment/train.log: a training log for FAA  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003751159116907
      ],
      "excerpt": "    Brightness, Sharpness, Cutout, Sample Pairing \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8070068273145398
      ],
      "excerpt": "<img src=\"https://latex.codecogs.com/gif.latex?D_{train}\"/>: train dataset that contains 42675 images from cifar10. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9019110097214145
      ],
      "excerpt": "Revision needed on train.py and model/data_loader.py. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8658042656808068
      ],
      "excerpt": "Testing: FAA official implementation python train.py -c confs/wresnet40x2_cifar10_b512.yaml --aug fa_reduced_cifar10 --dataset cifar10 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/junkwhinger/fastautoaugment_jsh/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Fast AutoAugment Implementation in Pytorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "fastautoaugment_jsh",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "junkwhinger",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/junkwhinger/fastautoaugment_jsh/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\npip install -r requirements.txt\n```\n\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Sun, 26 Dec 2021 07:26:48 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\n$ git clone https://github.com/junkwhinger/fastautoaugment_jsh.git\ncd fastautoaugment_jsh\n```\n\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
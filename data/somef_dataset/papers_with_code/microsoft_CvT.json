{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2103.15808",
      "https://arxiv.org/abs/2103.15808"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this work or code is helpful in your research, please cite:\n\n```\n@article{wu2021cvt,\n  title={Cvt: Introducing convolutions to vision transformers},\n  author={Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},\n  journal={arXiv preprint arXiv:2103.15808},\n  year={2021}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{wu2021cvt,\n  title={Cvt: Introducing convolutions to vision transformers},\n  author={Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},\n  journal={arXiv preprint arXiv:2103.15808},\n  year={2021}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/microsoft/CvT/main/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/microsoft/CvT",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-25T19:26:14Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T13:13:06Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This is an official implementation of [CvT: Introducing Convolutions to Vision Transformers](https://arxiv.org/abs/2103.15808). We present a new architecture, named Convolutional vision Transformers (CvT), that improves Vision Transformers (ViT) in performance and efficienty by introducing convolutions into ViT to yield the best of both disignes. This is accomplished through two primary modifications: a hierarchy of Transformers containing a new convolutional token embedding, and a convolutional Transformer block leveraging a convolutional projection. These changes introduce desirable properties of convolutional neural networks (CNNs) to the ViT architecture (e.g. shift, scale, and distortion invariance) while maintaining the merits of Transformers (e.g. dynamic attention, global context, and better generalization). We validate CvT by conducting extensive experiments, showing that this approach achieves state-of-the-art performance over other Vision Transformers and ResNets on ImageNet-1k, with fewer parameters and lower FLOPs. In addition, performance gains are maintained when pretrained on larger dataset (e.g. ImageNet-22k) and fine-tuned to downstream tasks. Pre-trained on ImageNet-22k, our CvT-W24 obtains a top-1 accuracy of 87.7% on the ImageNet-1k val set. Finally, our results show that the positional encoding, a crucial component in existing Vision Transformers, can be safely removed in our model, simplifying the design for higher resolution vision tasks. \n\n![](figures/pipeline.svg)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8199837720617734
      ],
      "excerpt": "a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8073737513954784,
        0.9783267603835809
      ],
      "excerpt": "This project has adopted the Microsoft Open Source Code of Conduct. \nFor more information see the Code of Conduct FAQ or \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8411378894176985,
        0.9214339495776546
      ],
      "excerpt": "This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft  \ntrademarks or logos is subject to and must follow  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This is an official implementation of CvT: Introducing Convolutions to Vision Transformers.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/microsoft/CvT/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 48,
      "date": "Mon, 27 Dec 2021 22:05:11 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/microsoft/CvT/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "microsoft/CvT",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/microsoft/CvT/main/run.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please prepare the data as following:\n\n``` sh\n|-DATASET\n  |-imagenet\n    |-train\n    | |-class1\n    | | |-img1.jpg\n    | | |-img2.jpg\n    | | |-...\n    | |-class2\n    | | |-img3.jpg\n    | | |-...\n    | |-class3\n    | | |-img4.jpg\n    | | |-...\n    | |-...\n    |-val\n      |-class1\n      | |-img5.jpg\n      | |-...\n      |-class2\n      | |-img6.jpg\n      | |-...\n      |-class3\n      | |-img7.jpg\n      | |-...\n      |-...\n```\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Assuming that you have installed PyTroch and TorchVision, if not, please follow the [officiall instruction](https://pytorch.org/) to install them firstly. \nIntall the dependencies using cmd:\n\n``` sh\npython -m pip install -r requirements.txt --user -q\n```\n\nThe code is developed and tested using pytorch 1.7.1. Other versions of pytorch are not fully tested.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8201428470102653
      ],
      "excerpt": "| CvT-13 | 384x384    | 20M   | 16.3   | 83.0  | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8201428470102653
      ],
      "excerpt": "| CvT-13  | 384x384    | 20M   | 16.3   | 83.3  | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9577503833031347,
        0.9197189303696724,
        0.9424611608616983
      ],
      "excerpt": "bash run.sh -g 8 -t train --cfg experiments/imagenet/cvt/cvt-13-224x224.yaml \nYou can also modify the config paramters by the command line. For example, if you want to change the lr rate to 0.1, you can run the command: \nbash run.sh -g 8 -t train --cfg experiments/imagenet/cvt/cvt-13-224x224.yaml TRAIN.LR 0.1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9307955919900727
      ],
      "excerpt": "bash run.sh -t test --cfg experiments/imagenet/cvt/cvt-13-224x224.yaml TEST.MODEL_FILE ${PRETRAINED_MODLE_FILE} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003352366805131
      ],
      "excerpt": "a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8485078799702429
      ],
      "excerpt": "bash run.sh -g 8 -t train --cfg experiments/imagenet/cvt/cvt-13-224x224.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8830914182515487
      ],
      "excerpt": "bash run.sh -g 8 -t train --cfg experiments/imagenet/cvt/cvt-13-224x224.yaml TRAIN.LR 0.1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8947792882921275
      ],
      "excerpt": "- The checkpoint, model, and log files will be saved in OUTPUT/{dataset}/{training config} by default. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8777446404834672
      ],
      "excerpt": "bash run.sh -t test --cfg experiments/imagenet/cvt/cvt-13-224x224.yaml TEST.MODEL_FILE ${PRETRAINED_MODLE_FILE} \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/microsoft/CvT/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'    MIT License\\n\\n    Copyright (c) Microsoft Corporation.\\n\\n    Permission is hereby granted, free of charge, to any person obtaining a copy\\n    of this software and associated documentation files (the \"Software\"), to deal\\n    in the Software without restriction, including without limitation the rights\\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\n    copies of the Software, and to permit persons to whom the Software is\\n    furnished to do so, subject to the following conditions:\\n\\n    The above copyright notice and this permission notice shall be included in all\\n    copies or substantial portions of the Software.\\n\\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\n    SOFTWARE\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Introduction",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "CvT",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "microsoft",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/microsoft/CvT/blob/main/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Each experiment is defined by a yaml config file, which is saved under the directory of `experiments`. The directory of `experiments` has a tree structure like this:\n\n``` sh\nexperiments\n|-{DATASET_A}\n| |-{ARCH_A}\n| |-{ARCH_B}\n|-{DATASET_B}\n| |-{ARCH_A}\n| |-{ARCH_B}\n|-{DATASET_C}\n| |-{ARCH_A}\n| |-{ARCH_B}\n|-...\n```\n\nWe provide a `run.sh` script for running jobs in local machine.\n\n``` sh\nUsage: run.sh [run_options]\nOptions:\n  -g|--gpus <1> - number of gpus to be used\n  -t|--job-type <aml> - job type (train|test)\n  -p|--port <9000> - master port\n  -i|--install-deps - If install dependencies (default: False)\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 230,
      "date": "Mon, 27 Dec 2021 22:05:11 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "cvt",
      "deep-learning",
      "classification",
      "imagenet",
      "computer-vision"
    ],
    "technique": "GitHub API"
  }
}
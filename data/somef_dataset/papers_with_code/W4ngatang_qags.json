{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2004.04228",
      "https://arxiv.org/abs/1910.13461",
      "https://arxiv.org/abs/1611.09830",
      "https://arxiv.org/abs/1808.10792"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use this code or data, please cite us.\n\n```\n@article{wang2020asking,\n   title={Asking and Answering Questions to Evaluate the Factual Consistency of Summaries},\n   url={http://dx.doi.org/10.18653/v1/2020.acl-main.450},\n   DOI={10.18653/v1/2020.acl-main.450},\n   journal={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},\n   publisher={Association for Computational Linguistics},\n   author={Wang, Alex and Cho, Kyunghyun and Lewis, Mike},\n   year={2020}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{wang2020asking,\n   title={Asking and Answering Questions to Evaluate the Factual Consistency of Summaries},\n   url={http://dx.doi.org/10.18653/v1/2020.acl-main.450},\n   DOI={10.18653/v1/2020.acl-main.450},\n   journal={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},\n   publisher={Association for Computational Linguistics},\n   author={Wang, Alex and Cho, Kyunghyun and Lewis, Mike},\n   year={2020}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/W4ngatang/qags",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to FAIR Sequence-to-Sequence Toolkit (PyTorch)\nWe want to make contributing to this project as easy and transparent as\npossible.\nPull Requests\nWe actively welcome your pull requests.\n\nFork the repo and create your branch from master.\nIf you've added code that should be tested, add tests.\nIf you've changed APIs, update the documentation.\nEnsure the test suite passes.\nMake sure your code lints.\nIf you haven't already, complete the Contributor License Agreement (\"CLA\").\n\nContributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\nComplete your CLA here: https://code.facebook.com/cla\nIssues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\nCoding Style\nWe try to follow the PEP style guidelines and encourage you to as well.\nLicense\nBy contributing to FAIR Sequence-to-Sequence Toolkit, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-20T19:37:19Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-29T09:05:28Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9922158308310914
      ],
      "excerpt": "This repo contains the code for the paper Asking and Answering Questions to Evaluate the Factual Consistency of Summaries, which appeared at ACL 2020. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9448202176864271
      ],
      "excerpt": "feed into the QG model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9247133080797839,
        0.9406300083249651,
        0.9731631414581233
      ],
      "excerpt": "To generate the questions, we rely on BART finetuned on NewsQA, implemented in fairseq. \nA frozen version of fairseq for doing so is available in qags/fairseq. \nOur pretrained QG model is available here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8563409717446686
      ],
      "excerpt": "Change model_path to point to the pretrained QG checkpoint, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9259616302154734
      ],
      "excerpt": "and out_file for the file to log to. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8262725110484441,
        0.9130115017903248,
        0.9187518877020504
      ],
      "excerpt": "{src/gen}_txt_file are respectively the source and model-generated texts  \n(e.g. for summarization, the source articles and model-generated summaries to be evaluated). \nAs part of this step, we filter questions by quality using a number of heuristics. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8295307627034073,
        0.8417298365477065
      ],
      "excerpt": "We use a QA model to answer the generated questions, and if the predicted answer doesn't match the original answer, we throw out the question. \nTo do this, we need to run the QA model on the generated questions, which will produce an answer file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8113781965368836,
        0.9337890738508385,
        0.9548908734873615
      ],
      "excerpt": "where the latter two respectively contain the expected and the predicted answers. \nTo evaluate our QA models, use the following command to evaluate the model on pred_file and write the predictions to out_dir/out_file \nOur models are based on pytorch-pretrained-BERT (now transformers) and pretrained checkpoints are located here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8523337189761309
      ],
      "excerpt": "Finally, to get the actual QAGS scores, we compare answers. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9734067887010983
      ],
      "excerpt": "The crowdsourced annotations of summary sentences we collected are available in data/mturk_{cnndm,xsum}.jsonl. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.954816020837631
      ],
      "excerpt": "Each annotation is a binary choice of whether or not the summary sentence is factually supported by the article,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Question Answering and Generation for Summarization",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/W4ngatang/qags/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 13,
      "date": "Mon, 20 Dec 2021 16:41:23 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/W4ngatang/qags/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "W4ngatang/qags",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/W4ngatang/qags/tree/master/fairseq/docs"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/W4ngatang/qags/master/scripts/pt_qa.sh",
      "https://raw.githubusercontent.com/W4ngatang/qags/master/scripts/gen_qg.sh",
      "https://raw.githubusercontent.com/W4ngatang/qags/master/fairseq/summerization.sh",
      "https://raw.githubusercontent.com/W4ngatang/qags/master/fairseq/scripts/aw/slurm_job.sh",
      "https://raw.githubusercontent.com/W4ngatang/qags/master/fairseq/scripts/aw/ft_sum.sh",
      "https://raw.githubusercontent.com/W4ngatang/qags/master/fairseq/scripts/aw/gen_qa.sh",
      "https://raw.githubusercontent.com/W4ngatang/qags/master/fairseq/scripts/aw/ft_qa.sh",
      "https://raw.githubusercontent.com/W4ngatang/qags/master/fairseq/scripts/aw/gen_sum.sh",
      "https://raw.githubusercontent.com/W4ngatang/qags/master/fairseq/scripts/aw/preprocess.sh",
      "https://raw.githubusercontent.com/W4ngatang/qags/master/fairseq/scripts/aw/gen_qg.sh",
      "https://raw.githubusercontent.com/W4ngatang/qags/master/fairseq/scripts/aw/ft_qg.sh",
      "https://raw.githubusercontent.com/W4ngatang/qags/master/fairseq/examples/language_model/prepare-wikitext-103.sh",
      "https://raw.githubusercontent.com/W4ngatang/qags/master/fairseq/examples/translation/prepare-wmt14en2fr.sh",
      "https://raw.githubusercontent.com/W4ngatang/qags/master/fairseq/examples/translation/prepare-iwslt14.sh",
      "https://raw.githubusercontent.com/W4ngatang/qags/master/fairseq/examples/translation/prepare-wmt14en2de.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8822742303355483
      ],
      "excerpt": "./fairseq/scripts/aw/preprocess.sh preprocess. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8960741662388538
      ],
      "excerpt": "Then to generate, use command ./scripts/gen_qg.sh.  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8748006861482822
      ],
      "excerpt": "Use the following command, where data_file is a text file containining an example per line and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8976575199949677
      ],
      "excerpt": "python qg_utils.py --command extract_ans \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.892420257661328,
        0.9162378832986894
      ],
      "excerpt": "The script expects dat_dir to contain test.src and test.trg, where test.src are the files that will actually  \nbe fed into the QG model to generate from; test.trg can be a dummy file with the same number of lines (e.g., a copy of test.src). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8788604176529279
      ],
      "excerpt": "Change model_path to point to the pretrained QG checkpoint, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8228360873179865
      ],
      "excerpt": "Due to a code quirk, in fairseq/fairseq/models/summerization_encoder_only.py, set HACK_PATH (line 107) to the best_pretrained_bert.pt checkpoint, located here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8905720132716969
      ],
      "excerpt": "python qg_utils.py --command extract-gen \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9213562323422559
      ],
      "excerpt": "python qa_utils.py --command format-qa-data --out_dir tmp \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python finetune_pt_squad.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.854385797651262,
        0.9471711877047916,
        0.8621882743635256
      ],
      "excerpt": "python qa_utils.py --command compute-qags \\ \n                   --src-ans-file ${src_ans_file} \\ \n                   --trg-ans-file ${trg_ans_file} \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/W4ngatang/qags/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "JavaScript",
      "Shell",
      "Lua",
      "C++",
      "Batchfile",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD License\\n\\nFor fairseq software\\n\\nCopyright (c) 2017-present, Facebook, Inc. All rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without modification,\\nare permitted provided that the following conditions are met:\\n\\n * Redistributions of source code must retain the above copyright notice, this\\n    list of conditions and the following disclaimer.\\n\\n * Redistributions in binary form must reproduce the above copyright notice,\\n    this list of conditions and the following disclaimer in the documentation\\n       and/or other materials provided with the distribution.\\n\\n * Neither the name Facebook nor the names of its contributors may be used to\\n    endorse or promote products derived from this software without specific\\n       prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "qags: Question Answering and Generation for Summarization",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "qags",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "W4ngatang",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/W4ngatang/qags/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 36,
      "date": "Mon, 20 Dec 2021 16:41:23 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To compute QAGS scores, we need to\n\n1. generate questions\n2. answer questions\n3. compare answers\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1511.06422](http://arxiv.org/abs/1511.06422).\n\nOrthonormal initialization is described in:\n\nAndrew M. Saxe, James L. McClelland, Surya Ganguli (2013). Exact solutions to the nonlinear dynamics of learning in deep linear neural networks. arXiv preprint [https://arxiv.org/abs/1312.6120](http://arxiv.org/abs/1312.6120)\n\n**upd.:** Torch re-implementation [https://github.com/yobibyte/torch-lsuv](https://github.com/yobibyte/torch-lsuv)\n\n**upd.:** Keras re-implementation [https://github.com/ducha-aiki/LSUV-keras](https://github.com/ducha-aiki/LSUV-keras)\n\n**New!** PyTorch re-implementation [https://github.com/ducha-aiki/LSUV-pytorch](https://github.com/ducha-aiki/LSUV-pytorch)\n\n**New!** Thinc re-implementation [LSUV-thinc](https://github.com/explosion/thinc/blob/e653dd3dfe91f8572e2001c8943dbd9b9401768b/thinc/neural/_lsuv.py)\n\nupdate: Why it is important to scale your input to var=1 before applying LSUV:\n\n![scale-no-scale](https://github.com/ducha-aiki/caffenet-benchmark/blob/master/logs/contrib/img/0_dataset_init.png)\n\n\n## Examples\n\nSee examples and sample log outputs in examples/lsuv. Run get_datasets.sh and training_*.sh for experiments reproduction. Note, than we haven`t freezed random seed and results may vary a little from run to run.\nInitialization script itself is in tools/extra/lsuv_init.py\n\n## Using with you current Caffe, or different framework installation\n\nIf you have Caffe installed already, you can simply copy script from   [tools/extra/lsuv_init.py](https://github.com/ducha-aiki/LSUVinit/blob/master/tools/extra/lsuv_init.py) and view its help (python lsuv_init.py -help) for further instructions. If you use a different framework, please, adapt that same script to your needs and notify us once you've got the code working, so we could let others know of existance of your solution if you're not against sharing your code. The script is self-explanatory, readable and adaptable.\n\n## Citation\n\nPlease cite us if you use this code:\n\n    @ARTICLE{LSUVInit2015,\n    author = {{Mishkin",
      "https://arxiv.org/abs/1312.6120](http://arxiv.org/abs/1312.6120)\n\n**upd.:** Torch re-implementation [https://github.com/yobibyte/torch-lsuv](https://github.com/yobibyte/torch-lsuv)\n\n**upd.:** Keras re-implementation [https://github.com/ducha-aiki/LSUV-keras](https://github.com/ducha-aiki/LSUV-keras)\n\n**New!** PyTorch re-implementation [https://github.com/ducha-aiki/LSUV-pytorch](https://github.com/ducha-aiki/LSUV-pytorch)\n\n**New!** Thinc re-implementation [LSUV-thinc](https://github.com/explosion/thinc/blob/e653dd3dfe91f8572e2001c8943dbd9b9401768b/thinc/neural/_lsuv.py)\n\nupdate: Why it is important to scale your input to var=1 before applying LSUV:\n\n![scale-no-scale](https://github.com/ducha-aiki/caffenet-benchmark/blob/master/logs/contrib/img/0_dataset_init.png)\n\n\n## Examples\n\nSee examples and sample log outputs in examples/lsuv. Run get_datasets.sh and training_*.sh for experiments reproduction. Note, than we haven`t freezed random seed and results may vary a little from run to run.\nInitialization script itself is in tools/extra/lsuv_init.py\n\n## Using with you current Caffe, or different framework installation\n\nIf you have Caffe installed already, you can simply copy script from   [tools/extra/lsuv_init.py](https://github.com/ducha-aiki/LSUVinit/blob/master/tools/extra/lsuv_init.py) and view its help (python lsuv_init.py -help) for further instructions. If you use a different framework, please, adapt that same script to your needs and notify us once you've got the code working, so we could let others know of existance of your solution if you're not against sharing your code. The script is self-explanatory, readable and adaptable.\n\n## Citation\n\nPlease cite us if you use this code:\n\n    @ARTICLE{LSUVInit2015,\n    author = {{Mishkin",
      "https://arxiv.org/abs/1511.06422",
      "https://arxiv.org/abs/1408.5093"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Caffe is released under the [BSD 2-Clause license](https://github.com/BVLC/caffe/blob/master/LICENSE).\nThe BVLC reference models are released for unrestricted use.\n\nPlease cite Caffe in your publications if it helps your research:\n\n    @article{jia2014caffe,\n      Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},\n      Journal = {arXiv preprint arXiv:1408.5093},\n      Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},\n      Year = {2014}\n    }\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Please cite us if you use this code:\n\n    @ARTICLE{LSUVInit2015,\n    author = {{Mishkin}, D. and {Matas}, J.},\n    title = \"{All you need is a good init}\",\n    journal = {arXiv preprint arXiv:1511.06422},\n    year = 2015,\n    month = nov\n    }\n\n----\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{jia2014caffe,\n  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},\n  Journal = {arXiv preprint arXiv:1408.5093},\n  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},\n  Year = {2014}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@ARTICLE{LSUVInit2015,\nauthor = {{Mishkin}, D. and {Matas}, J.},\ntitle = \"{All you need is a good init}\",\njournal = {arXiv preprint arXiv:1511.06422},\nyear = 2015,\nmonth = nov\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9943007914160107
      ],
      "excerpt": "Mishkin, D. and Matas, J.,(2015). All you need is a good init. arXiv preprint arXiv:1511.06422. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9542793968711404,
        0.8029948720864918,
        0.9105368110547479
      ],
      "excerpt": "Andrew M. Saxe, James L. McClelland, Surya Ganguli (2013). Exact solutions to the nonlinear dynamics of learning in deep linear neural networks. arXiv preprint arXiv:1312.6120 \nupd.: Torch re-implementation https://github.com/yobibyte/torch-lsuv \nupd.: Keras re-implementation https://github.com/ducha-aiki/LSUV-keras \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ducha-aiki/LSUVinit",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing\nIssues\nSpecific Caffe design and development issues, bugs, and feature requests are maintained by GitHub Issues.\nPlease do not post usage, installation, or modeling questions, or other requests for help to Issues.\nUse the caffe-users list instead. This helps developers maintain a clear, uncluttered, and efficient view of the state of Caffe.\nWhen reporting a bug, it's most helpful to provide the following information, where applicable:\n\nWhat steps reproduce the bug?\nCan you reproduce the bug using the latest master, compiled with the DEBUG make option?\nWhat hardware and operating system/distribution are you running?\nIf the bug is a crash, provide the backtrace (usually printed by Caffe; always obtainable with gdb).\n\nTry to give your issue a title that is succinct and specific. The devs will rename issues as needed to keep track of them.\nPull Requests\nCaffe welcomes all contributions.\nSee the contributing guide for details.\nBriefly: read commit by commit, a PR should tell a clean, compelling story of one improvement to Caffe. In particular:\n\nA PR should do one clear thing that obviously improves Caffe, and nothing more. Making many smaller PRs is better than making one large PR; review effort is superlinear in the amount of code involved.\nSimilarly, each commit should be a small, atomic change representing one step in development. PRs should be made of many commits where appropriate.\nPlease do rewrite PR history to be clean rather than chronological. Within-PR bugfixes, style cleanups, reversions, etc. should be squashed and should not appear in merged PR history.\nAnything nonobvious from the code should be explained in comments, commit messages, or the PR description, as appropriate.",
    "technique": "File Exploration"
  },
  "contributors": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributors\nCaffe is developed by a core set of BVLC members and the open-source community.\nWe thank all of our contributors!\nFor the detailed history of contributions of a given file, try\ngit blame file\n\nto see line-by-line credits and\ngit log --follow file\n\nto see the change log even across renames and rewrites.\nPlease refer to the acknowledgements on the Caffe site for further details.\nCopyright is held by the original contributor according to the versioning history; see LICENSE.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2015-11-19T20:26:18Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-30T22:14:58Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9633653752682667
      ],
      "excerpt": "LSUV initialization is described in: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9633653752682667,
        0.8175741797916314
      ],
      "excerpt": "Orthonormal initialization is described in: \nAndrew M. Saxe, James L. McClelland, Surya Ganguli (2013). Exact solutions to the nonlinear dynamics of learning in deep linear neural networks. arXiv preprint arXiv:1312.6120 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9337302974919087,
        0.9571002500766483
      ],
      "excerpt": "update: Why it is important to scale your input to var=1 before applying LSUV: \nCaffe is a deep learning framework made with expression, speed, and modularity in mind. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9790913002507733,
        0.8699347285953232
      ],
      "excerpt": "Check out the project site for all the details like \nDIY Deep Learning for Vision with Caffe \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9114919684847912
      ],
      "excerpt": "BVLC reference models and the community model zoo \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9739768626999616,
        0.8187337616003587
      ],
      "excerpt": "Please join the caffe-users group or gitter chat to ask questions and talk about methods and models. \nFramework development discussions and thorough bug reports are collected on Issues. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Reference caffe implementation of LSUV initialization",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ducha-aiki/LSUVinit/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 31,
      "date": "Thu, 30 Dec 2021 11:45:03 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ducha-aiki/LSUVinit/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ducha-aiki/LSUVinit",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/ducha-aiki/LSUVinit/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/net_surgery.ipynb",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/detection.ipynb",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/01-learning-lenet.ipynb",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/02-brewing-logreg.ipynb",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/00-classification.ipynb",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/03-fine-tuning.ipynb",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/siamese/mnist_siamese.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/scripts/deploy_docs.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/scripts/build_docs.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/scripts/download_model_from_gist.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/scripts/upload_model_to_gist.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/scripts/gather_examples.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/scripts/travis/travis_setup_makefile_config.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/scripts/travis/travis_build_and_test.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/scripts/travis/travis_install.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/data/ilsvrc12/get_ilsvrc_aux.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/data/cifar10/get_cifar10.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/data/mnist/get_mnist.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/lsuv/training_cifar100.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/lsuv/training_cifar10.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/lsuv/get_datasets.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/lsuv/training_mnist.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/imagenet/create_imagenet.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/imagenet/resume_training.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/imagenet/train_caffenet.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/imagenet/make_imagenet_mean.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/cifar10/create_cifar10.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/cifar10/train_quick.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/cifar10/train_full_sigmoid.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/cifar10/train_full_sigmoid_bn.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/cifar10/train_full.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/mnist/train_lenet_adam.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/mnist/train_lenet_consolidated.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/mnist/train_mnist_autoencoder_adagrad.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/mnist/train_lenet_rmsprop.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/mnist/create_mnist.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/mnist/train_mnist_autoencoder_nesterov.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/mnist/train_lenet.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/mnist/train_mnist_autoencoder.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/mnist/train_mnist_autoencoder_adadelta.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/siamese/create_mnist_siamese.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/examples/siamese/train_mnist_siamese.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/tools/extra/parse_log.sh",
      "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/tools/extra/launch_resize_and_crop_images.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you have Caffe installed already, you can simply copy script from   [tools/extra/lsuv_init.py](https://github.com/ducha-aiki/LSUVinit/blob/master/tools/extra/lsuv_init.py) and view its help (python lsuv_init.py -help) for further instructions. If you use a different framework, please, adapt that same script to your needs and notify us once you've got the code working, so we could let others know of existance of your solution if you're not against sharing your code. The script is self-explanatory, readable and adaptable.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9225700048253109
      ],
      "excerpt": "New! PyTorch re-implementation https://github.com/ducha-aiki/LSUV-pytorch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9848867486995735
      ],
      "excerpt": "Installation instructions \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ducha-aiki/LSUVinit/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "C++",
      "Python",
      "Cuda",
      "CMake",
      "MATLAB",
      "Makefile",
      "Shell",
      "M"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/ducha-aiki/LSUVinit/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'COPYRIGHT\\n\\nAll contributions by the University of California:\\nCopyright (c) 2014, 2015, The Regents of the University of California (Regents)\\nAll rights reserved.\\n\\nAll other contributions:\\nCopyright (c) 2014, 2015, the respective contributors\\nAll rights reserved.\\n\\nCaffe uses a shared copyright model: each contributor holds copyright over\\ntheir contributions to Caffe. The project versioning records all such\\ncontribution and copyright details. If a contributor wants to further mark\\ntheir specific copyright on a particular contribution, they should indicate\\ntheir copyright solely in the commit message of the change when it is\\ncommitted.\\n\\nLICENSE\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met: \\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer. \\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution. \\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR\\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n\\nCONTRIBUTION AGREEMENT\\n\\nBy contributing to the BVLC/caffe repository through pull-request, comment,\\nor otherwise, the contributor releases their content to the\\nlicense and copyright terms herein.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Layer-sequential unit-variance (LSUV) initialization",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "LSUVinit",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ducha-aiki",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ducha-aiki/LSUVinit/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 110,
      "date": "Thu, 30 Dec 2021 11:45:03 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "caffe",
      "lsuv",
      "lsuv-initialization",
      "initialization",
      "convolutional-neural-networks",
      "convolutional-networks",
      "deep-learning"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "See examples and sample log outputs in examples/lsuv. Run get_datasets.sh and training_*.sh for experiments reproduction. Note, than we haven`t freezed random seed and results may vary a little from run to run.\nInitialization script itself is in tools/extra/lsuv_init.py\n\n",
      "technique": "Header extraction"
    }
  ]
}
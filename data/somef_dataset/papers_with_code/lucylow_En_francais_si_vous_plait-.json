{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1706.03762\n* Fairseq Technical Documentation: https://fairseq.readthedocs.io/en/latest/models.html#module-fairseq.models.transformer\n* A fast, batched Bi-RNN(GRU",
      "https://arxiv.org/abs/1705.03122\n* Data processing scripts: https://www.dagshub.com/Guy/fairseq/src/67af40c9cca0241d797be13ae557d59c3732b409/data\n* Beyond \"How May I Help You?\": https://medium.com/airbnb-engineering/beyond-how-may-i-help-you-fd6a0d385d02"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* \"Attention Is All You Need\": https://arxiv.org/abs/1706.03762\n* Fairseq Technical Documentation: https://fairseq.readthedocs.io/en/latest/models.html#module-fairseq.models.transformer\n* A fast, batched Bi-RNN(GRU) encoder & attention decoder implementation in PyTorch: https://github.com/AuCson/PyTorch-Batch-Attention-Seq2seq\n* Gated-Attention Architectures for Task-Oriented Language Grounding: https://github.com/devendrachaplot/DeepRL-Grounding\n* Sequence to Sequence models with PyTorch: https://github.com/MaximumEntropy/Seq2Seq-PyTorch\n* PyTorch implementation of OpenAI's Finetuned Transformer Language Model paper \"Improving Language Understanding by Generative Pre-Training\": https://github.com/huggingface/pytorch-openai-transformer-lm\n* IBM's PyTorch seq-to-seq model:https://github.com/IBM/pytorch-seq2seq\n* Translation with Sequence to Sequence Network and Attention: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#sphx-glr-intermediate-seq2seq-translation-tutorial-py\n* \"Convolutional Sequence to Sequence Learning\": https://arxiv.org/abs/1705.03122\n* Data processing scripts: https://www.dagshub.com/Guy/fairseq/src/67af40c9cca0241d797be13ae557d59c3732b409/data\n* Beyond \"How May I Help You?\": https://medium.com/airbnb-engineering/beyond-how-may-i-help-you-fd6a0d385d02\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9763986598557183,
        0.9763986598557183
      ],
      "excerpt": "  [![GitHub Issues](https://img.shields.io/github/issues/lucylow/En_francais_si_vous_plait-.svg)](https://github.com/lucylow/En_francais_si_vous_plait-/issues) \n  [![GitHub Pull Requests](https://img.shields.io/github/issues-pr/lucylow/En_francais_si_vous_plait-.svg)](https://github.com/lucylow/En_francais_si_vous_plait-/pulls) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "Multi-Hop Attention Functionality \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.911449585530318,
        0.8356013927728488
      ],
      "excerpt": "Je ne crains pas de mourir. \nSource: Je ne crains pas de mourir. \nOriginal_Sentence: Je ne crains pas de mourir. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucylow/En_francais_si_vous_plait-",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-08-22T11:05:17Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-05T03:08:06Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9754489178065627
      ],
      "excerpt": "This is a machine learning natural language processing (NLP) project submission for the Global PyTorch Summer Hackathon! #PTSH19. Pour la documentation en fran\u00e7ais, cliquez ici! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8804038053899395,
        0.9809973282000312
      ],
      "excerpt": "French-English translation service using natural language processing (NLP) with a vision of connecting people through language and advancing a barrier free society for billingual speakers \nAs a Canadian citizen, ensure respect for English and French as the offical languages of Canada and have equality of status, rights, and privileges \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8751556187919696
      ],
      "excerpt": "Chatbots taking over repetitive easy-to-automate human jobs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8829854808744365
      ],
      "excerpt": "Reduce the manual processing required to retrive corporate data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9269931844653236
      ],
      "excerpt": "Open source deep learning research platform that provides maximum flexibility and speed and provides tensors that live on the GPU accelerating the computation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9000333687418238,
        0.926402438672379,
        0.8646761486703008
      ],
      "excerpt": "Transformer Machine Learning Model with Sequence-Aligned RNNs or CNNs \nMachine language translation transformer model from Attention Is All You Need using encoder-decoder attention mechanisms in a sequence-to-sequence model that features stacked self attention layers \nTransduction model relying on self-attention layers to compute input and output represenations where the attention functions maps [query, key-value pairs] to vector outputs of [query, key-value pairs] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9237040424496996,
        0.9804069202107871,
        0.8080149369207582,
        0.857775191457631
      ],
      "excerpt": "Record the translation time once machine learning system is shown a sentence to quantify results \n\"On the WMT 2014 English-to-French translation task (a widely used benchmark metric for judging the accuracy of machine translation), attention model establishes a BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature\" \nImage. Transformer model high in BLEU scale and low on training costs Image Source \nGating to control flow of hidden-units \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9436070967429888
      ],
      "excerpt": "CNN encoder creates a vector for each word to be translated, and CNN decoder translates words while PyTorch computations are being simultaneously made. Network has two decoder layers and attention is paid to each layer. Refer to image below. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.971593084309777
      ],
      "excerpt": "For French-English translations, order of words matter and and the number of words can be added during the translation. \"Black cat\" translate to \"chat noir\" and the \"not\" translate to \"ne ___ pas\". Refer to image below: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "Binarize data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8312870677096891
      ],
      "excerpt": "$ DATA=data-bin/iwslt14.tokenized.fr-en \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9574700261299118
      ],
      "excerpt": "Hypothesis: -0.23804219067097 I am not scared of dying. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9574700261299118
      ],
      "excerpt": "Hypothesis: -0.23861141502857 I am not scared of dying. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8214565233612441
      ],
      "excerpt": "Step by step visualization of the encoder-decoder network attention matrix as it goes through a sentance translation. Use matplotlib library to display matrix via plt.matshow(attention) : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "French English Machine Translation. Natural language processing (NLP) transformer model from \"Attention Is All You Need\"",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://fairseq.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucylow/En_francais_si_vous_plait-/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sat, 25 Dec 2021 04:43:43 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lucylow/En_francais_si_vous_plait-/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "lucylow/En_francais_si_vous_plait-",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/lucylow/En_francais_si_vous_plait-/master/data/iwslt14/prepare-wmt14en2fr.sh",
      "https://raw.githubusercontent.com/lucylow/En_francais_si_vous_plait-/master/data/iwslt14/prepare-iwslt14.sh",
      "https://raw.githubusercontent.com/lucylow/En_francais_si_vous_plait-/master/fairseq/scripts/compound_split_bleu.sh",
      "https://raw.githubusercontent.com/lucylow/En_francais_si_vous_plait-/master/fairseq/scripts/sacrebleu_pregen.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8268393564608785,
        0.8814900702670583
      ],
      "excerpt": "  [![GitHub Issues](https://img.shields.io/github/issues/lucylow/En_francais_si_vous_plait-.svg)](https://github.com/lucylow/En_francais_si_vous_plait-/issues) \n  [![GitHub Pull Requests](https://img.shields.io/github/issues-pr/lucylow/En_francais_si_vous_plait-.svg)](https://github.com/lucylow/En_francais_si_vous_plait-/pulls) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365,
        0.8080002376980483,
        0.922398499773593
      ],
      "excerpt": "```python  \ncd data/ \nbash prepare-iwslt14.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365,
        0.8902627162932362
      ],
      "excerpt": "```python  \n$ mkdir -p trainings/fconv \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "```python  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.899798830109176
      ],
      "excerpt": "    -trainpref $TEXT/train -validpref $TEXT/valid -testpref $TEXT/test \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.87646509353562,
        0.8022661796773425
      ],
      "excerpt": "$ fairseq train -sourcelang fr -targetlang en -datadir data-bin/iwslt14.tokenized.fr-en \\ \n  -model fconv -nenclayer 4 -nlayer 3 -dropout 0.2 -optim nag -lr 0.25 -clip 0.1 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.804397726266704
      ],
      "excerpt": "$ DATA=data-bin/iwslt14.tokenized.fr-en \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lucylow/En_francais_si_vous_plait-/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "Lua"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) Facebook, Inc. and its affiliates.\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "En Fran\u00e7ais Si Vous Plait?",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "En_francais_si_vous_plait-",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "lucylow",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucylow/En_francais_si_vous_plait-/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Sat, 25 Dec 2021 04:43:43 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "machine-learning",
      "french",
      "french-nlp",
      "french-english",
      "translation",
      "fairseq",
      "sequence-to-sequence",
      "sequence-models",
      "language-translation-service",
      "transformer-encoder",
      "attention",
      "attention-is-all-you-need",
      "attention-model",
      "wmt-14",
      "neural-networks",
      "cnn",
      "convolutional-neural-network"
    ],
    "technique": "GitHub API"
  }
}
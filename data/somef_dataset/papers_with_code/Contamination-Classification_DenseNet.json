{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1608.06993",
      "https://arxiv.org/abs/1608.06993\n```\n\n### Setup environment.\n\n1. Create a conda/python virtual environment.\n\n2. Install the dependencies from requirements.txt using pip -\n\n```\n    conda create --name <envname> --file requirements.txt\n```\n\nTo manually install dependencies, follow the below steps - \n\n1. Create a conda create environment: \n\n```\nconda create -n envname  python=3.6\nconda activate test1\n```\n\n2. Install Keras and Tensorflow-gpu using Conda\n\n```\nconda install -c conda-forge keras\nconda config --set restore_free_channel true\nconda install tensorflow-gpu=1.13\n```\n\n4. Pip install libraries\n\n```\npip3 install opencv-python Pillow matplotlib easydict argparse tqdm\n```\n\nUsing Conda \n\n```\nconda install -c conda-forge opencv matplotlib easydict argparse tqdm\nconda install -c anaconda pillow\n```\n\n\n### To run predictions on the dataset, please follow the below steps.\n\n1. Create a directory for the input rgb images, and place the dataset into this directory.\n\n   Please note that currently the code only supports grid type 12 (3 X 4).\n\n2. Please place the downloaded model in the main working directory.\n\n3. Create a CSV which contains the list of input RGB images. Check test.csv in the folder.\n\n3. To run the script, use the command -\n\nPlease update the output directory path in the config.py file (OUTPUT)\n\n```\n    KERAS_BACKEND=tensorflow python inference.py --img-list test.csv \n```\n\nOr, Include img-list, crop_dims and output_file paths as arguments to the script.\n\n```\n    KERAS_BACKEND=tensorflow python inference.py --img-list test.csv --output_file output_file_name --crop_dims \"(260, 600, 1700, 1710)\"  \n```\n\nTo turn on debugging, use the debug flag and set it to True. (--debug True)\n\nFormat of the output CSV - \n\n```\nimage_name,1,2,3,4,5,6,7,8,9,10,11,12\nGWZ7_I2.0_F1.9_L80_194153_8_1_3_rgb.jpg,NC,NC,NC,NC,NC,NC,M,NC,NC,NC,NC,NC\nGWZ7_I2.0_F1.9_L80_194927_1_2_5_rgb.jpg,C,NC,NC,NC,NC,NC,NC,NC,NC,NC,C,NC\nGWZ7_I2.0_F1.9_L80_194429_11_2_2_rgb.jpg,NC,NC,NC,NC,NC,C,NC,NC,NC,NC,NC,NC\nGWZ8_I2.0_F1.9_L80_195913_4_0_6_rgb.jpg,C,NC,NC,C,C,C,C,NC,C,C,C,NC\n```\n\n## Requirements\n\n* Keras 2.0.5"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Contamination-Classification/DenseNet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-11T00:39:14Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-12-22T20:52:41Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9693592967466831,
        0.9953693009533376,
        0.9477462197559137
      ],
      "excerpt": "This repository contains the pipeline for classifying explants into categories - contaminated, non-contaminated, missing \nThis is Keras implementation of DenseNet. The code for densenet used in this repository is obtained from here. \nTo know more about how DenseNet works, please refer to the original paper \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Contamination Classification DenseNet",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Contamination-Classification/DenseNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 20:45:03 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Contamination-Classification/DenseNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contamination-Classification/DenseNet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Create a conda/python virtual environment.\n\n2. Install the dependencies from requirements.txt using pip -\n\n```\n    conda create --name <envname> --file requirements.txt\n```\n\nTo manually install dependencies, follow the below steps - \n\n1. Create a conda create environment: \n\n```\nconda create -n envname  python=3.6\nconda activate test1\n```\n\n2. Install Keras and Tensorflow-gpu using Conda\n\n```\nconda install -c conda-forge keras\nconda config --set restore_free_channel true\nconda install tensorflow-gpu=1.13\n```\n\n4. Pip install libraries\n\n```\npip3 install opencv-python Pillow matplotlib easydict argparse tqdm\n```\n\nUsing Conda \n\n```\nconda install -c conda-forge opencv matplotlib easydict argparse tqdm\nconda install -c anaconda pillow\n```\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Contamination-Classification/DenseNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contamination_DenseNet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DenseNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contamination-Classification",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Contamination-Classification/DenseNet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Keras 2.0.5\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Create a directory for the input rgb images, and place the dataset into this directory.\n\n   Please note that currently the code only supports grid type 12 (3 X 4).\n\n2. Please place the downloaded model in the main working directory.\n\n3. Create a CSV which contains the list of input RGB images. Check test.csv in the folder.\n\n3. To run the script, use the command -\n\nPlease update the output directory path in the config.py file (OUTPUT)\n\n```\n    KERAS_BACKEND=tensorflow python inference.py --img-list test.csv \n```\n\nOr, Include img-list, crop_dims and output_file paths as arguments to the script.\n\n```\n    KERAS_BACKEND=tensorflow python inference.py --img-list test.csv --output_file output_file_name --crop_dims \"(260, 600, 1700, 1710)\"  \n```\n\nTo turn on debugging, use the debug flag and set it to True. (--debug True)\n\nFormat of the output CSV - \n\n```\nimage_name,1,2,3,4,5,6,7,8,9,10,11,12\nGWZ7_I2.0_F1.9_L80_194153_8_1_3_rgb.jpg,NC,NC,NC,NC,NC,NC,M,NC,NC,NC,NC,NC\nGWZ7_I2.0_F1.9_L80_194927_1_2_5_rgb.jpg,C,NC,NC,NC,NC,NC,NC,NC,NC,NC,C,NC\nGWZ7_I2.0_F1.9_L80_194429_11_2_2_rgb.jpg,NC,NC,NC,NC,NC,C,NC,NC,NC,NC,NC,NC\nGWZ8_I2.0_F1.9_L80_195913_4_0_6_rgb.jpg,C,NC,NC,C,C,C,C,NC,C,C,C,NC\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Fri, 24 Dec 2021 20:45:03 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1511.06581",
      "https://arxiv.org/abs/1711.00138",
      "https://arxiv.org/abs/1809.06061",
      "https://arxiv.org/abs/1812.02850"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{atrey2020exploratory,\n  title={{Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps for Deep RL}},\n  author={Atrey, Akanksha and Clary, Kaleigh and Jensen, David},\n  booktitle={{International Conference on Learning Representations (ICLR)}},\n  year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.95516740796082
      ],
      "excerpt": "If you use this code or are inspired by our methodology, please cite our ICLR paper: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KDL-umass/saliency_maps",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-07T04:54:55Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-30T04:28:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9948272458613644,
        0.9969197616229075
      ],
      "excerpt": "This repository contains code from experiments discussed in our ICLR 2020 paper Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps for Deep RL. \nIt includes resources for generating saliency maps for deep reinforcement learning (RL) models and additionally contains experiments to empirically examine the causal relationships between saliency and agent behavior. It also provides implementations of three types of saliency maps used in RL: (1) Jacobian, (2) perturbation-based, and (3) object-based. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9736125487892446,
        0.985258750434246
      ],
      "excerpt": "Please direct all queries to Akanksha Atrey (aatrey at cs dot umass dot edu) or open an issue in this repository. \nAbstract: Saliency maps are often used to suggest explanations of the behavior of deep reinforcement learning (RL) agents. However, the explanations derived from saliency maps are often unfalsifiable and can be highly subjective. We introduce an empirical approach grounded in counterfactual reasoning to test the hypotheses generated from saliency maps and show that explanations suggested by saliency maps are often not supported by experiments. Our experiments suggest that saliency maps are best viewed as an exploratory tool rather than an explanatory tool. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9786244603690535,
        0.9920818635988311,
        0.9042107487751059,
        0.8105933861502994
      ],
      "excerpt": "We use Toybox, a set of fully parameterized implementation of Atari games, to generate interventional data under counterfactual conditions. Visit the Toybox repository and follow the setup instructions. The saliency_maps repository should reside in the toybox/ctoybox folder within the Toybox repository. \nAll agents used in this work are trained using the OpenAI's baselines implementation. Clone this version of the baselines repository in the same directory as this repository and follow the setup instructions (in the toybox/ctoybox folder). This version of baselines is a fork of the original baselines repository with code changes to accomodate building different saliency maps. \nWe use the A2C algorithm for all our experiments.  \nTo train a deep RL model on Amidar using the A2C algorithm, execute the following command: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8105933861502994
      ],
      "excerpt": "To train a deep RL model on Breakout using the A2C algorithm, execute the following command: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9090405195356107
      ],
      "excerpt": "The implementation follows that all three types of saliency videos are created for a single episode. The perturbation saliency video must be created first before creating the object and Jacobian saliency maps. When the perturbation saliency video is created, it simultaneously creates an associated pickle file with the actions chosen by the agent. This pickle file will be used when creating object and Jacobian saliency videos to avoid discrepancies in agent behavior. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8477678735851494
      ],
      "excerpt": "python3 -m saliency_maps.visualize_atari.make_movie --env_name=BreakoutToyboxNoFrameskip-v4 --alg=a2c --load_path=toybox/ctoybox/models/breakout4e7_a2c.model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8736354532732029
      ],
      "excerpt": "python3 -m saliency_maps.object_saliency.object_saliency --env_name=BreakoutToyboxNoFrameskip-v4 --alg=a2c --load_path=toybox/ctoybox/models/breakout4e7_a2c.model --history_path=[location of pkl file of actions] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8736354532732029
      ],
      "excerpt": "python3 -m saliency_maps.jacobian_saliency.jacobian_saliency.make_movie --env_name=BreakoutToyboxNoFrameskip-v4 --alg=a2c --load_model_path=toybox/ctoybox/models/breakout4e7_a2c.model --load_history_path=[location of pkl file of actions] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560917679497156
      ],
      "excerpt": "The generic command to create videos of interventions is:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code for building and experimenting on saliency maps for RL agents.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KDL-umass/saliency_maps/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 18:45:27 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/KDL-umass/saliency_maps/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "KDL-umass/saliency_maps",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/KDL-umass/saliency_maps/master/scripts/run_amidar_score_exp2.sh",
      "https://raw.githubusercontent.com/KDL-umass/saliency_maps/master/scripts/run_amidar_score_exp3.sh",
      "https://raw.githubusercontent.com/KDL-umass/saliency_maps/master/scripts/run_amidar_pkl_generation.sh",
      "https://raw.githubusercontent.com/KDL-umass/saliency_maps/master/scripts/run_amidar_score_exp.sh",
      "https://raw.githubusercontent.com/KDL-umass/saliency_maps/master/scripts/run_count_frames.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9068438304684316
      ],
      "excerpt": "To build a perturbation saliency video on a Breakout agent, execute the following command from the toybox/ctoybox directory: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8538253247498501
      ],
      "excerpt": "To build a object saliency video on a Breakout agent, execute the following command from the toybox/ctoybox directory: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9068438304684316
      ],
      "excerpt": "To build a Jacobian saliency video on a Breakout agent, execute the following command from the toybox/ctoybox directory: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8955836385110011
      ],
      "excerpt": "python3 -m saliency_maps.visualize_atari.make_movie --env_name=BreakoutToyboxNoFrameskip-v4 --alg=a2c --load_path=toybox/ctoybox/models/breakout4e7_a2c.model --history_file [location of pkl file of actions from default run] --IVmoveball=True, --IVsymbricks=True, --IVmodifyScore=True, --IVmultModifyScores=True, --IVnonChangingScores=True, --IVdecrementScore=True, --IVmoveEnemies=True, --IVmoveEnemiesBack=True, --IVshiftBricks=True \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/KDL-umass/saliency_maps/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Saliency-Maps",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "saliency_maps",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "KDL-umass",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KDL-umass/saliency_maps/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Sun, 26 Dec 2021 18:45:27 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2103.03230",
      "https://arxiv.org/abs/2103.00020",
      "https://arxiv.org/abs/2006.09882",
      "https://arxiv.org/abs/2002.05709",
      "https://arxiv.org/abs/1911.05722",
      "https://arxiv.org/abs/1912.01991",
      "https://arxiv.org/abs/1912.01991",
      "https://arxiv.org/abs/2006.09882",
      "https://arxiv.org/abs/1803.07728",
      "https://arxiv.org/abs/1603.09246",
      "https://arxiv.org/abs/1910.02054",
      "https://arxiv.org/abs/1708.03888",
      "https://arxiv.org/abs/2003.13678"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find VISSL useful in your research or wish to refer to the baseline results published in the [Model Zoo](https://github.com/facebookresearch/vissl/blob/main/MODEL_ZOO.md), please use the following BibTeX entry.\n\n```BibTeX\n@misc{goyal2021vissl,\n  author =       {Priya Goyal and Quentin Duval and Jeremy Reizenstein and Matthew Leavitt and Min Xu and\n                  Benjamin Lefaudeux and Mannat Singh and Vinicius Reis and Mathilde Caron and Piotr Bojanowski and\n                  Armand Joulin and Ishan Misra},\n  title =        {VISSL},\n  howpublished = {\\url{https://github.com/facebookresearch/vissl}},\n  year =         {2021}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{goyal2021vissl,\n  author =       {Priya Goyal and Quentin Duval and Jeremy Reizenstein and Matthew Leavitt and Min Xu and\n                  Benjamin Lefaudeux and Mannat Singh and Vinicius Reis and Mathilde Caron and Piotr Bojanowski and\n                  Armand Joulin and Ishan Misra},\n  title =        {VISSL},\n  howpublished = {\\url{https://github.com/facebookresearch/vissl}},\n  year =         {2021}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/facebookresearch/vissl/main/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/vissl",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to VISSL\nWe want to make contributing to this project as easy and transparent as possible.\nOur Development Process\nMinor changes and improvements will be released on an ongoing basis. Larger changes (e.g., changesets implementing a new SSL approach, benchmark, new scaling feature etc) will be released on a more periodic basis.\nIssues\nWe use GitHub issues to track public bugs and questions. Please make sure to follow one of the\nissue templates\nwhen reporting any issues.\nFacebook has a bounty program for the safe\ndisclosure of security bugs. In those cases, please go through the process\noutlined on that page and do not file a public issue.\nPull Requests\nWe actively welcome your pull requests.\nHowever, if you're adding any significant features (e.g. > 50 lines), please\nmake sure to have a corresponding issue to discuss your motivation and proposals,\nbefore sending a PR. We do not always accept new features, and we take the following\nfactors into consideration:\n\nWhether the same feature can be achieved without modifying vissl.\nVISSL is designed to be extensible so that it's easy to extend any modular component and train custom models. If some part is not as extensible, you can also bring up the issue to make it more extensible.\nWhether the feature is potentially useful to a large audience, or only to a small portion of users.\nWhether the proposed solution has a good design / interface.\nWhether the proposed solution adds extra mental/practical overhead to users who don't\n   need such feature.\nWhether the proposed solution breaks existing APIs.\n\nWhen sending a PR, please do:\n\nFork the repo and create your branch from main.\nIf a PR contains multiple orthogonal changes, split it to several PRs.\nIf you've added code that should be tested, add tests.\nIf you've changed APIs, update the documentation.\nEnsure the test suite passes. Follow cpu test instructions and [integration tests][https://github.com/facebookresearch/vissl/blob/main/dev/run_quick_tests.sh].\nMake sure your code follows our coding practices (see next section).\nIf you haven't already, complete the Contributor License Agreement (\"CLA\").\n\nCoding Style\nPlease follow our coding practices and choose either option to properly format your code before submitting PRs.\nContributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\nComplete your CLA here: https://code.facebook.com/cla\nLicense\nBy contributing to ssl_framework, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.",
    "technique": "File Exploration"
  },
  "contributor": [
    {
      "confidence": [
        1
      ],
      "excerpt": "VISSL is written and maintained by the Facebook AI Research.\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-04-09T19:40:33Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-29T08:24:43Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "VISSL is a computer **VI**sion library for state-of-the-art **S**elf-**S**upervised **L**earning research with [PyTorch](https://pytorch.org). VISSL aims to accelerate research cycle in self-supervised learning: from designing a new self-supervised task to evaluating the learned representations. Key features include:\n\n- **Reproducible implementation of SOTA in Self-Supervision**: All existing SOTA in Self-Supervision are implemented - [SwAV](https://arxiv.org/abs/2006.09882), [SimCLR](https://arxiv.org/abs/2002.05709), [MoCo(v2)](https://arxiv.org/abs/1911.05722), [PIRL](https://arxiv.org/abs/1912.01991), [NPID](https://arxiv.org/pdf/1805.01978.pdf), [NPID++](https://arxiv.org/abs/1912.01991), [DeepClusterV2](https://arxiv.org/abs/2006.09882), [ClusterFit](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yan_ClusterFit_Improving_Generalization_of_Visual_Representations_CVPR_2020_paper.pdf), [RotNet](https://arxiv.org/abs/1803.07728), [Jigsaw](https://arxiv.org/abs/1603.09246). Also supports supervised trainings.\n\n- **Benchmark suite**: Variety of benchmarks tasks including [linear image classification (places205, imagenet1k, voc07, food, CLEVR, dsprites, UCF101, stanford cars and many more)](https://github.com/facebookresearch/vissl/tree/main/configs/config/benchmark/linear_image_classification), [full finetuning](https://github.com/facebookresearch/vissl/tree/main/configs/config/benchmark/fulltune), [semi-supervised benchmark](https://github.com/facebookresearch/vissl/tree/main/configs/config/benchmark/semi_supervised), [nearest neighbor benchmark](https://github.com/facebookresearch/vissl/tree/main/configs/config/benchmark/nearest_neighbor), [object detection (Pascal VOC and COCO)](https://github.com/facebookresearch/vissl/tree/main/configs/config/benchmark/object_detection).\n\n- **Ease of Usability**: easy to use using yaml configuration system based on [Hydra](https://github.com/facebookresearch/hydra).\n\n- **Modular**: Easy to design new tasks and reuse the existing components from other tasks (objective functions, model trunk and heads, data transforms, etc.). The modular components are simple *drop-in replacements* in yaml config files.\n\n- **Scalability**: Easy to train model on 1-gpu, multi-gpu and multi-node. Several components for large scale trainings provided as simple config file plugs: [Activation checkpointing](https://pytorch.org/docs/stable/checkpoint.html), [ZeRO](https://arxiv.org/abs/1910.02054), [FP16](https://nvidia.github.io/apex/amp.html#o1-mixed-precision-recommended-for-typical-use), [LARC](https://arxiv.org/abs/1708.03888), Stateful data sampler, data class to handle invalid images, large model backbones like [RegNets](https://arxiv.org/abs/2003.13678), etc.\n\n- **Model Zoo**: Over *60 pre-trained self-supervised model* weights.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9486419730403689,
        0.974219608901947,
        0.8266658928366794
      ],
      "excerpt": "Below we share, in reverse chronological order, the updates and new releases in VISSL. All VISSL releases are available here. \n- [Oct 2021]: Vissl Release 0.1.6 We have released a new version of VISSL! Please see our release notes for more information. \n- [Oct 2021]: AugLy data augmentations support introduced in this commit. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8476119751028113
      ],
      "excerpt": "- [Sept 2021]: VISSL master branch renamed to main in this PR in VISSL. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "VISSL is FAIR's library of extensible, modular and scalable components for SOTA Self-Supervised Learning with images.",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Learn more about VISSL at our [documentation](https://vissl.readthedocs.io). And see the [projects/](projects/) for some projects built on top of VISSL.\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/vissl/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 222,
      "date": "Wed, 29 Dec 2021 14:03:25 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/facebookresearch/vissl/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "facebookresearch/vissl",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/docker/Dockerfile",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/docker/conda/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/facebookresearch/vissl/tree/main/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/tutorials/Train_SimCLR_on_1_gpu_V0_1_6.ipynb",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/tutorials/Feature_Extraction_V0_1_6.ipynb",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/tutorials/Understanding_VISSL_Training_and_YAML_Config_V0_1_6.ipynb",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/tutorials/Benchmark_Full_Finetuning_on_ImageNet_1K_V0_1_6.ipynb",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/tutorials/Using_a_pretrained_model_for_inference_V0_1_6.ipynb",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/tutorials/Benchmark_Linear_Image_Classification_on_ImageNet_1K_V0_1_6.ipynb",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/tutorials/Installation_V0_1_6.ipynb",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/tutorials/Large_Scale_Training_V0_1_6.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/launch_slurm.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/run_quick_integration_tests.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/low_resource_1gpu_train_wrapper.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/run_quick_tests.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/launch_benchmark_suite_scheduler_slurm.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/linter.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/website_docs/build_website.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/website_docs/publish_website.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/packaging/apex_conda/go.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/packaging/apex_conda/upload.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/packaging/vissl_conda/build_conda.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/packaging/vissl_conda/upload.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/packaging/vissl_conda/build_all_conda.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/packaging/vissl_pip/to_pypi.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/packaging/vissl_pip/go.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/packaging/vissl_pip/after.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/packaging/vissl_pip/inside.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/packaging/vissl_pip/test/test.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/packaging/vissl_pip/test/run.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/packaging/apex_pip/go.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/packaging/apex_pip/after.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/dev/packaging/apex_pip/inside/a.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/docker/build_docker.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/docker/common/install_apex.sh",
      "https://raw.githubusercontent.com/facebookresearch/vissl/main/docker/common/install_conda.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "See [`INSTALL.md`](https://github.com/facebookresearch/vissl/blob/main/INSTALL.md).\n\n",
      "technique": "Header extraction"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/facebookresearch/vissl/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Shell",
      "JavaScript",
      "CSS",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) Facebook, Inc. and its affiliates.\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# What's New",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "vissl",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "facebookresearch",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/vissl/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "iseessel",
        "body": "# Vissl Release Overview 0.1.6\r\n\r\n* VISSL relicenses with MIT license to enable broader use. This includes personal, university, and commercial use. \r\n* VISSL master branch renamed to main.\r\n* We now recommend [building VISSL from source](https://github.com/facebookresearch/vissl/blob/v0.1.6/INSTALL.md#installing-vissl-from-source-recommended). Since VISSL is designed to be a hackable research library, we believe this method of installation gives the user the most flexibility to hack on VISSL as they like.\r\n* Added the following SSL approaches and architectures to VISSL:  \r\n    * [XCiT: Cross-Covariance Image Transformers](https://arxiv.org/pdf/2106.09681.pdf), \r\n    * [DINO: Emerging Properties in Self-Supervised Vision Transformers](https://arxiv.org/pdf/2104.14294.pdf), \r\n    * [Barlow Twins: Self-Supervised Learning via Redundancy Reduction](https://arxiv.org/abs/2103.03230), \r\n    * [ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases](https://arxiv.org/pdf/2103.10697.pdf), and the \r\n    * [Vision Transformers](https://arxiv.org/pdf/2010.11929v1.pdf) (ViT) backbone with optional [gradient clipping](https://vissl.readthedocs.io/en/v0.1.6/ssl_approaches/vision_transformers.html?highlight=GRAD_CLIP#supervised-vit-training-on-1-gpu). \r\n* Integrated [Fully Sharded Data Parallel](https://github.com/facebookresearch/fairscale/pull/413) into VISSL, tested on SwAV, Regnet models. \r\n    * To aid its development, we have added enhanced tooling for [memory profiling](https://github.com/facebookresearch/vissl/blob/v0.1.6/vissl/config/defaults.yaml#L168).\r\n* Full support for the newest [Pytorch](https://pytorch.org/get-started/locally/) versions: 1.8.1, 1.9, and 1.9.1.\r\n* Added [CLIP](https://openai.com/blog/clip/) and [VTAB](https://ai.googleblog.com/2019/11/the-visual-task-adaptation-benchmark.html) benchmarks. See our [docs](https://vissl.readthedocs.io/en/v0.1.5/evaluations/linear_benchmark.html) for more information on how to set these up.\r\n* Updated all [tutorials](https://vissl.ai/tutorials/) and improved versioning for future stability. We now suggest to install VISSL from [source]() for ease-of-use. \r\n* Improved support for reproducibility and debugging, as well as increased unit testing. Including new [DATA_LIMIT options](https://github.com/facebookresearch/vissl/blob/v0.1.6/vissl/config/defaults.yaml#L353), the [debugging sampler(https://github.com/facebookresearch/vissl/blob/v0.1.6/vissl/config/defaults.yaml#L374), [CUDA reproducibility settings](https://github.com/facebookresearch/vissl/blob/v0.1.6/vissl/config/defaults.yaml#L83), and [dataloader seeding improvements](https://github.com/facebookresearch/vissl/pull/299). For more information see our [docs](https://vissl.readthedocs.io/en/v0.1.6/vissl_modules/train.html?highlight=debugging#debugging-trainings)\r\n* Enhanced metrics support. We now have the ability to [log multiple metrics](https://github.com/facebookresearch/vissl/issues/313) to [stdout and tensorboard](https://github.com/facebookresearch/vissl/issues/330). \r\n* Added support for the [Precision@k and Recall@k]( https://github.com/facebookresearch/vissl/pull/448) metrics. See our [docs](https://vissl.readthedocs.io/en/v0.1.6/vissl_modules/meters.html?highlight=precision%40k#using-meters) for more info.\r\n* Updated [DOCKERFILE](https://github.com/facebookresearch/vissl/tree/v0.1.6/docker) to reflect the newest version.\r\n* Enhanced support for [image retrieval benchmarks](https://vissl.readthedocs.io/en/v0.1.6/evaluations/instance_retrieval.html) for the Copydays, ROxford, and RParis benchmark datasets.\r\n* Support for image transformations using the [Augly](https://vissl.readthedocs.io/en/v0.1.6/vissl_modules/data.html?highlight=augly#using-data-transforms) library.\r\n* Added flexibility to register own [custom base model class](https://vissl.readthedocs.io/en/v0.1.6/extend_modules/models.html#adding-new-base-model).\r\n\r\n# How to Upgrade\r\n\r\nWe encourage users to [build from source](https://github.com/facebookresearch/vissl/blob/v0.1.6/INSTALL.md#installing-vissl-from-source-recommended). However, if you still wish to use the binaries you can upgrade by following the following steps:\r\n\r\n\r\n## Conda environment\r\n```\r\nconda install -c vissl vissl==0.1.6\r\n```\r\n\r\n## Python venv\r\n```\r\n# Uninstall fairscale, as we now include the library in the package \r\n# because we rely on a specific commit that is not part of a PyPi release. \r\npip uninstall fairscale\r\npip install vissl==0.1.6\r\n```\r\n\r\nIf you are installing for the first time, please see [our installation instructions](https://github.com/facebookresearch/vissl/blob/v0.1.6/INSTALL.md).\r\n\r\nAs always, thank you all so much for your contributions and feedback. Please feel free to continue to reach out in our issues for any questions, suggestions, or if you wish to contribute. We hope you are finding VISSL useful to pushing the state-of-the-art in self-supervised learning!",
        "dateCreated": "2021-11-02T17:06:28Z",
        "datePublished": "2021-11-02T17:21:02Z",
        "html_url": "https://github.com/facebookresearch/vissl/releases/tag/v0.1.6",
        "name": "v0.1.6",
        "tag_name": "v0.1.6",
        "tarball_url": "https://api.github.com/repos/facebookresearch/vissl/tarball/v0.1.6",
        "url": "https://api.github.com/repos/facebookresearch/vissl/releases/51218897",
        "zipball_url": "https://api.github.com/repos/facebookresearch/vissl/zipball/v0.1.6"
      },
      {
        "authorType": "User",
        "author_name": "prigoyal",
        "body": "Initial release of VISSL",
        "dateCreated": "2021-03-02T00:51:05Z",
        "datePublished": "2021-03-02T18:51:51Z",
        "html_url": "https://github.com/facebookresearch/vissl/releases/tag/v0.1.5",
        "name": "v0.1.5 Initial Release",
        "tag_name": "v0.1.5",
        "tarball_url": "https://api.github.com/repos/facebookresearch/vissl/tarball/v0.1.5",
        "url": "https://api.github.com/repos/facebookresearch/vissl/releases/39136810",
        "zipball_url": "https://api.github.com/repos/facebookresearch/vissl/zipball/v0.1.5"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2255,
      "date": "Wed, 29 Dec 2021 14:03:25 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Install VISSL by following the [installation instructions](https://github.com/facebookresearch/vissl/blob/main/INSTALL.md).\nAfter installation, please see [Getting Started with VISSL](https://github.com/facebookresearch/vissl/blob/main/GETTING_STARTED.md) and the [Colab Notebook](https://colab.research.google.com/github/facebookresearch/vissl/blob/v0.1.6/tutorials/Understanding_VISSL_Training_and_YAML_Config_V0_1_6.ipynb) to learn about basic usage.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Get started with VISSL by trying one of the **Colab tutorial notebooks**.\n\n- [Train SimCLR on 1-gpu](https://colab.research.google.com/github/facebookresearch/vissl/blob/v0.1.6/tutorials/Train_SimCLR_on_1_gpu_V0_1_6.ipynb)\n- [Extracting Features from a pretrained model](https://colab.research.google.com/github/facebookresearch/vissl/blob/v0.1.6/tutorials/Using_a_pretrained_model_for_inference_V0_1_6.ipynb)\n- [Benchmark task: Full finetuning on ImageNet-1K](https://colab.research.google.com/github/facebookresearch/vissl/blob/v0.1.6/tutorials/Benchmark_Full_Finetuning_on_ImageNet_1K_V0_1_6.ipynb)\n- [Benchmark task: Linear image classification on ImageNet-1K](https://colab.research.google.com/github/facebookresearch/vissl/blob/v0.1.6/tutorials/Benchmark_Linear_Image_Classification_on_ImageNet_1K_V0_1_6.ipynb)\n- [Large scale training (fp16, LARC, ZeRO)](https://colab.research.google.com/github/facebookresearch/vissl/blob/v0.1.6/tutorials/Large_Scale_Training_V0_1_6.ipynb)\n- [Using a pre-trained model in inference mode](https://colab.research.google.com/github/facebookresearch/vissl/blob/v0.1.6/tutorials/Using_a_pretrained_model_for_inference_V0_1_6.ipynb)\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
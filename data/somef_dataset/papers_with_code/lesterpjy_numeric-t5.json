{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2104.07307",
      "https://arxiv.org/abs/2004.14546",
      "https://arxiv.org/abs/2004.04487",
      "https://arxiv.org/abs/1910.10683"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9991144885555023
      ],
      "excerpt": "Authors: Peng-Jian Yang<sup>a</sup>, Ying Ting Chen<sup>a</sup>, Yuechan Chen<sup>a </sup> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.961619350164478
      ],
      "excerpt": "<sup>a</sup>University of California Berkeley, <sup>b</sup>Google Research    \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lesterpjy/numeric-t5",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-06T12:23:48Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-26T04:18:06Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8990320905404421,
        0.9637194448006204,
        0.9870266806624822,
        0.9096091280447085
      ],
      "excerpt": "<sup>a</sup>University of California Berkeley, <sup>b</sup>Google Research    \nNT5?! Training T5 to Perform Numerical Reasoning is a NLP research project on training T5 to perform NRoT (numerical reasoning over text). Latest version of the paper can be reviewed on ArXiv. All source codes and two fully trained NT5 models (RC Experiment 1, our best performing model, and Validation Experiment 2, our second best performing model) are included in the repository. \nNumerical reasoning over text (NRoT) presents unique challenges that are not well addressed by existing pre-training objectives in NLP. We explore five sequential training schedules that adapt a pre-trained T5 model for NRoT. Our final model adapted from T5 but further pre-trained on three datasets designed to strengthen skills necessary for NRoT and general reading comprehension before being fine-tuned on Discrete Reasoning over Text (DROP) dataset. We show that our training improves DROP\u2019s adjusted F1 performance (a numeracy-focused score) from 45.90 to 70.83. Our model outperforms the best model in the original DROP paper (47.01), and closes in on GenBERT (72.4), a custom BERT-Base model with significantly more parameters. \nNRoT in NLP is unique in that answers require numerical reasoning in addition to the traditional NLP task, reading comprehension (RC). Additionally, answers can demand the model to be both generative and discriminative, as demonstrated by the two examples extracted from DROP, our gold dataset:   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9598832481494866
      ],
      "excerpt": "The answer for the first question is an extraction from the passage, and requires the model to compute the probability distribution across all words in the passage. In particular, our chosen model requires the following three NLP skills in sequence:   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.96795723881569
      ],
      "excerpt": "The answer for the second question, on the other hand, cannot be extracted from either the passage or question. We need a generative language model to generate the string, \"4300000.\"  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9656834388572798,
        0.8320298333037585
      ],
      "excerpt": "Note that many NRoT models, including the current state of the art for solving DROP, only generates the mathematical equations required to calculate the final answer as the output. Our research aims to take it one step further: Our final model internalizes the equation, perform the calculation, and directly generate the final numerical answer, 4,300,000, as the output. \nA total of 6 datasets are explored during training. The splits and sizes for each dataset are summarized by the diagram below.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.973011379470709,
        0.9569679308223462,
        0.9351289890270997,
        0.9922665446751884,
        0.9829944281054969,
        0.963671015874705
      ],
      "excerpt": "DROP (Discrete Reasoning Over Paragraphs), introduced by AllenNLP in 2019, includes 96k examples in a \"Q&A with context\" format similar to SQuAD. The benchmark includes four distinct types of questions, all of which require NRoT skills to solve. DROP Class is exactly the same as DROP, but with the labels changed to the four classes of questions found in DROP : numeric, date, single span, and multiple spans. The goal of DROP Class is to help T5 learn to classify the four types of questions that require different skillsets to solve in DROP. \nSynthetic Data consists of two datasets: The Numeric dataset (NUM) with near 1M synthetically generated questions on seven types of numerical skills (e.g. addition, sorting, comparison, etc.). The Textual dataset (TXT) builds on NUM, and includes 2M+ synthetically generated examples in formats similar to DROP's Q&As.  \nSQuAD v1.1, a benchmark dataset by Stanford with an emphasis on RC through Q&As, is included in training to strengthen the model's general RC capability.  \nUnfortunately, we are unable to complete our multitask training with C4EN (used a part of T5's pre-training) due to limited resources, but we hypothesize that the inclusion of which would lead to an improved performance. \nWe employ two evaluation metrics: Exact-Match (EM), and an adjusted F1 (macro-averaged, adjusted for numerical performance). EM uses that same criteria as SQuAD. The adjusted F1 has additional logic that invalidates all matching material within an answer when there is a numeric mismatch. In other words, the prediction receives an F1 score of 0 if it gets the number wrong. In addition, F1 is computed using macro-averaging over individual answers. In the presence of multiple ground truths, both EM and F1 will take a max over all computed scores. \nAt the time of research, BERT with self-attention is becoming increasingly popular across a wide variety of NLP tasks. However, inspired by WT5 (Sharan et al., 2020 ) and GenBERT (Geva et al., 2020), we choose T5 as our model specifically for its following strengths: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.97328677534732
      ],
      "excerpt": "One single T5 model can be fine-tuned against multiple objectives and perform different types of predictions. This is a strong contrast to BERT and an important feature required by DROP, our gold dataset, as explained in the NRoT challenges section.       \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.964752223272536,
        0.9684785936102944
      ],
      "excerpt": "T5 is Google's attempt to take transfer learning to its limit across a wide verity of NLP tasks. It is pre-trained on Colossal Clean Crawled Corpus (C4). \nA short description of T5 can be found on the Google AI Blog and T5's original paper.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9087649320346676,
        0.9045283866750312,
        0.9522009061928496,
        0.9962732065656013
      ],
      "excerpt": "T5 allows us to complete the entire training schedule using its out-of-box architecture. BERT, on the other hand, requires additional feedforward neural networks for fine-tuning.  \nT5's multitasking allows us to fine-tune one single model for all the different NLP tasks demanded by DROP. In contrast, BERT requires multiple different models to solve DROP.   \nWe hypothesize that T5's pre-training and encoder-decoder architectures would lead to a performance comparable to BERT but with a much smaller model scale. \nThe parsimony of T5 allows us to focus on refining our training methods instead of the model architecture. Our training involves a series of experiments using both sequential and multitask trainings. The full schedule is summarized by the diagram below and a detailed description can be found in the paper. Our best model is RC1, the model pertained on the two synthetic datasets and SQuAD, and then fine-tuned on DROP and DROP Class.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9983118191646889,
        0.959596676472474
      ],
      "excerpt": "Our best model, RC1, using T5-Small (the smallest scale of T5) achieves an adjusted F1 performance of 70.83. This is a considerable improvement over the performance achieved by the model proposed in the original DROP paper (47.01). Our model also closes in on GenBERT (72.4), a custom BERT-Base model pre-trained on our same synthetic data. In addition, our model is a lot more parsimonious: GenBERT's architecture includes 5 additional feedforward neural networks on top of the BERT-Base encoder and comes with significantly more weights (110 million from BERT-Base + additional weights from the 5 neural networks vs. 60 million from our T5-Small). \n./nt5_multitask_training.ipynb is the notebook with all source codes for modeling and training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Training T5 to perform numerical reasoning.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lesterpjy/numeric-t5/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Fri, 24 Dec 2021 22:04:05 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lesterpjy/numeric-t5/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "lesterpjy/numeric-t5",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/lesterpjy/numeric-t5/main/nt5_multitask_training.ipynb",
      "https://raw.githubusercontent.com/lesterpjy/numeric-t5/main/tfrec/tfrec_drop_cat.ipynb",
      "https://raw.githubusercontent.com/lesterpjy/numeric-t5/main/tfrec/tfrec_drop.ipynb",
      "https://raw.githubusercontent.com/lesterpjy/numeric-t5/main/tfrec/tfrec_drop_num.ipynb",
      "https://raw.githubusercontent.com/lesterpjy/numeric-t5/main/tfrec/tfrec_synthetic_data.ipynb",
      "https://raw.githubusercontent.com/lesterpjy/numeric-t5/main/tfrec/squad_parser.ipynb",
      "https://raw.githubusercontent.com/lesterpjy/numeric-t5/main/tfrec/tfrec_squad.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lesterpjy/numeric-t5/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Peng-Jian Yang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "NT5?! Training T5 to Perform Numerical Reasoning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "numeric-t5",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "lesterpjy",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lesterpjy/numeric-t5/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 11,
      "date": "Fri, 24 Dec 2021 22:04:05 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "t5-model",
      "python",
      "numeracy",
      "nlp-tasks"
    ],
    "technique": "GitHub API"
  }
}
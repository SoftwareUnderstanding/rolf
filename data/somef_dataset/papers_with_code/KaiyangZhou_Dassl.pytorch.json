{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2003.07325",
      "https://arxiv.org/abs/1807.01697",
      "https://arxiv.org/abs/2103.02503, which summarizes the ten-year development in this topic with coverage on the history, related problems, datasets, methodologies, potential directions, and so on.\n- [Jan 2021] Our recent work, [MixStyle](https://openreview.net/forum?id=6xHJ37MVxxp",
      "https://arxiv.org/abs/1805.12018",
      "https://arxiv.org/abs/1905.11946",
      "https://arxiv.org/abs/1904.06487",
      "https://arxiv.org/abs/1712.02560https://arxiv.org/abs/1712.02560",
      "https://arxiv.org/abs/1712.02560",
      "https://arxiv.org/abs/1706.05208",
      "https://arxiv.org/abs/1603.04779",
      "https://arxiv.org/abs/1702.05464",
      "https://arxiv.org/abs/1505.07818",
      "https://arxiv.org/abs/2003.07325",
      "https://arxiv.org/abs/1812.01754",
      "https://arxiv.org/abs/2003.06054",
      "https://arxiv.org/abs/1804.10745",
      "https://arxiv.org/abs/2001.07685",
      "https://arxiv.org/abs/1905.02249",
      "https://arxiv.org/abs/1703.01780",
      "https://arxiv.org/abs/2003.07325",
      "https://arxiv.org/abs/1710.03077",
      "https://arxiv.org/abs/2003.06054",
      "https://arxiv.org/abs/1805.12018",
      "https://arxiv.org/abs/1807.01697",
      "https://arxiv.org/abs/1807.01697",
      "https://arxiv.org/abs/2003.07325",
      "https://arxiv.org/abs/2107.02053",
      "https://arxiv.org/abs/2106.00592",
      "https://arxiv.org/abs/2103.02503",
      "https://arxiv.org/abs/2007.03304",
      "https://arxiv.org/abs/2003.06054"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this code useful to your research, please give credit to the following paper\n\n```\n@article{zhou2020domain,\n  title={Domain Adaptive Ensemble Learning},\n  author={Zhou, Kaiyang and Yang, Yongxin and Qiao, Yu and Xiang, Tao},\n  journal={IEEE Transactions on Image Processing (TIP)},\n  year={2021}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{zhou2020domain,\n  title={Domain Adaptive Ensemble Learning},\n  author={Zhou, Kaiyang and Yang, Yongxin and Qiao, Yu and Xiang, Tao},\n  journal={IEEE Transactions on Image Processing (TIP)},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8145525049874843
      ],
      "excerpt": "[Jun 2021] v0.2.5: Fixs a bug in the calculation of per-class recognition accuracy. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8277270123938507
      ],
      "excerpt": "[Jun 2021] New benchmarks for semi-supervised domain generalization at https://github.com/KaiyangZhou/ssdg-benchmark. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8206171046123948
      ],
      "excerpt": "Single-source domain adaptation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8100934951395111,
        0.8100934951395111
      ],
      "excerpt": "Maximum Classifier Discrepancy for Unsupervised Domain Adaptation (CVPR'18) [dassl/engine/da/mcd.py] \nSelf-ensembling for visual domain adaptation (ICLR'18) [dassl/engine/da/self_ensembling.py] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9320836846800284
      ],
      "excerpt": "Multi-source domain adaptation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9424641777989116
      ],
      "excerpt": "Moment Matching for Multi-Source Domain Adaptation (ICCV'19) [dassl/engine/da/m3sda.py] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9946139741844879,
        0.9648889021544168,
        0.9971342585509336
      ],
      "excerpt": "MixStyle Neural Networks for Domain Generalization and Adaptation, arxiv preprint, 2021. \nSemi-Supervised Domain Generalization with Stochastic StyleMatch, arxiv preprint, 2021. \nDomain Generalization in Vision: A Survey, arxiv preprint, 2021. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KaiyangZhou/Dassl.pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-10T16:06:48Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T02:45:00Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Dassl is a [PyTorch](https://pytorch.org) toolbox initially developed for our project [Domain Adaptive Ensemble Learning (DAEL)](https://arxiv.org/abs/2003.07325) to support research in domain adaptation and generalization---since in DAEL we study how to unify these two problems in a single learning framework. Given that domain adaptation is closely related to semi-supervised learning---both study how to exploit unlabeled data---we also incorporate components that support research for the latter.\n\nWhy the name \"Dassl\"? Dassl combines the initials of domain adaptation (DA) and semi-supervised learning (SSL), which sounds natural and informative.\n\nDassl has a modular design and unified interfaces, allowing fast prototyping and experimentation of new DA/DG/SSL methods. With Dassl, a new method can be implemented with only a few lines of code. Don't believe? Take a look at the [engine](https://github.com/KaiyangZhou/Dassl.pytorch/tree/master/dassl/engine) folder, which contains the implementations of many existing methods (then you will come back and star this repo). :-)\n\nBasically, Dassl is perfect for doing research in the following areas:\n- Domain adaptation\n- Domain generalization\n- Semi-supervised learning\n\nBUT, thanks to the neat design, Dassl can also be used as a codebase to develop any deep learning projects, like [this](https://github.com/KaiyangZhou/CoOp). :-)\n\nA drawback of Dassl is that it doesn't (yet? hmm) support distributed multi-GPU training (Dassl uses `DataParallel` to wrap a model, which is less efficient than `DistributedDataParallel`).\n\nWe don't provide detailed documentations for Dassl, unlike another [project](https://kaiyangzhou.github.io/deep-person-reid/) of ours. This is because Dassl is developed for research purpose and as a researcher, we think it's important to be able to read source code and we highly encourage you to do so---definitely not because we are lazy. :-)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9675855794819163
      ],
      "excerpt": "[Oct 2021]: v0.5.0: Important changes made to transforms.py. 1) center_crop becomes a default transform in testing (applied after resizing the smaller edge to a certain size to keep the image aspect ratio). 2) For training, Resize(cfg.INPUT.SIZE) is deactivated when random_crop or random_resized_crop is used. These changes won't make any difference to the training transforms used in existing config files, nor to the testing transforms unless the raw images are not squared (the only difference is that now the image aspect ratio is respected). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9589406036305012,
        0.8619898855818611
      ],
      "excerpt": "[Sep 2021]: v0.4.2: An important update is to set drop_last=is_train and len(data_source)&gt;=batch_size when constructing a data loader to avoid 0-length. \n[Aug 2021]: v0.4.0: The most noteworthy update is adding the learning rate warmup scheduler. The implementation is detailed here and the config variables are specified here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9518020585469787
      ],
      "excerpt": "[Jul 2021] v0.3.0: Allows to deploy the model with the best validation performance for final test (for the purpose of model selection). Specifically, a new config variable named _C.TEST.FINAL_MODEL is introduced, which takes either \"last_step\" (default) or \"best_val\". When set to \"best_val\", the model will be evaluated on the val set after each epoch and the one with the best validation performance will be saved and used for final test (see this code). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9911464927612256
      ],
      "excerpt": "[Jun 2021] v0.2.6: Merges MixStyle2 to MixStyle. A new variable self.mix is used to switch between random mixing and cross-domain mixing. Please see this for more details on the new features. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8749698215707293
      ],
      "excerpt": "[Jun 2021] v0.2.4: Adds extend_cfg(cfg) to train.py. This function is particularly useful when you build your own methods on top of Dassl.pytorch and need to define some custom variables. Please see the repository mixstyle-release or ssdg-benchmark for examples. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8886034359529978
      ],
      "excerpt": "    <summary>More</summary> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8543712035813114
      ],
      "excerpt": "- [Apr 2021] `v0.2.0`: Adds `_C.DATASET.ALL_AS_UNLABELED` (for the SSL setting) to the config variable list. When this variable is set to `True`, all labeled data will be included in the unlabeled data set. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8833390289901154
      ],
      "excerpt": "- [Mar 2021] `v0.1.8`: Allows `optim` and `sched` to be `None` in `register_model()`. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8036980790725514,
        0.9900115126194395
      ],
      "excerpt": "- [Mar 2021] We have just released a survey on domain generalization at https://arxiv.org/abs/2103.02503, which summarizes the ten-year development in this topic with coverage on the history, related problems, datasets, methodologies, potential directions, and so on. \n- [Jan 2021] Our recent work, [MixStyle](https://openreview.net/forum?id=6xHJ37MVxxp) (mixing instance-level feature statistics of samples of different domains for improving domain generalization), is accepted to ICLR'21. The code is available at https://github.com/KaiyangZhou/mixstyle-release where the cross-domain image classification part is based on Dassl.pytorch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9251241202063241,
        0.8776951455216225
      ],
      "excerpt": "Feel free to make a PR to add your methods here to make it easier for others to benchmark! \nDassl supports the following datasets: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9236238118499159
      ],
      "excerpt": "instantiate a trainer with build_trainer(cfg) which loads the dataset and builds a deep neural network model; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.87336937793355
      ],
      "excerpt": "--root $DATA \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8241677895763478
      ],
      "excerpt": "$DATA denotes the location where datasets are installed. --dataset-config-file loads the common setting for the dataset (Office-31 in this case) such as image size and model architecture. --config-file loads the algorithm-specific setting such as hyper-parameters and optimization parameters. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.87336937793355
      ],
      "excerpt": "--root $DATA \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8513160386831414
      ],
      "excerpt": "For other trainers such as MCD, you can set --trainer MCD while keeping the config file unchanged, i.e. using the same training parameters as SourceOnly (in the simplest case). To modify the hyper-parameters in MCD, like N_STEP_F (number of steps to update the feature extractor), you can append TRAINER.MCD.N_STEP_F 4 to the existing input arguments (otherwise the default value will be used). Alternatively, you can create a new .yaml config file to store your custom setting. See here for a complete list of algorithm-specific hyper-parameters. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.87336937793355
      ],
      "excerpt": "--root $DATA \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9797627255262187,
        0.9895453436097293,
        0.9578096486384536,
        0.9416714641882318
      ],
      "excerpt": "A good practice is to go through dassl/engine/trainer.py to get familar with the base trainer classes, which provide generic functions and training loops. To write a trainer class for domain adaptation or semi-supervised learning, the new class can subclass TrainerXU. For domain generalization, the new class can subclass TrainerX. In particular, TrainerXU and TrainerX mainly differ in whether using a data loader for unlabeled data. With the base classes, a new trainer may only need to implement the forward_backward() method, which performs loss computation and model update. See dassl/enigne/da/source_only.py for example. \nbackbone corresponds to a convolutional neural network model which performs feature extraction. head (which is an optional module) is mounted on top of backbone for further processing, which can be, for example, a MLP. backbone and head are basic building blocks for constructing a SimpleNet() (see dassl/engine/trainer.py) which serves as the primary model for a task. network contains custom neural network models, such as an image generator. \nTo add a new module, namely a backbone/head/network, you need to first register the module using the corresponding registry, i.e. BACKBONE_REGISTRY for backbone, HEAD_REGISTRY for head and NETWORK_RESIGTRY for network. Note that for a new backbone, we require the model to subclass Backbone as defined in dassl/modeling/backbone/backbone.py and specify the self._out_features attribute. \nWe provide an example below for how to add a new backbone. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8144108604113832
      ],
      "excerpt": "    #: Extract and return features \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9082059702556254
      ],
      "excerpt": "An example code structure is shown below. Make sure you subclass DatasetBase and register the dataset with @DATASET_REGISTRY.register(). All you need is to load train_x, train_u (optional), val (optional) and test, among which train_u and val could be None or simply ignored. Each of these variables contains a list of Datum objects. A Datum object (implemented here) contains information for a single image, like impath (string) and label (int). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9761356036056723,
        0.9047539496822984
      ],
      "excerpt": "We suggest you take a look at the datasets code in some projects like this, which is built on top of Dassl. \nWe would like to share here our research relevant to Dassl. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233251501384025,
        0.8831022750032685
      ],
      "excerpt": "Domain Generalization with MixStyle, in ICLR 2021. \nLearning to Generate Novel Domains for Domain Generalization, in ECCV 2020. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A PyTorch toolbox for domain adaptation and semi-supervised learning.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KaiyangZhou/Dassl.pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 81,
      "date": "Fri, 24 Dec 2021 08:00:02 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/KaiyangZhou/Dassl.pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "KaiyangZhou/Dassl.pytorch",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/KaiyangZhou/Dassl.pytorch/master/linter.sh",
      "https://raw.githubusercontent.com/KaiyangZhou/Dassl.pytorch/master/datasets/da/visda17.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Make sure [conda](https://www.anaconda.com/distribution/) is installed properly.\n\n```bash\n#: Clone this repo\ngit clone https://github.com/KaiyangZhou/Dassl.pytorch.git\ncd Dassl.pytorch/\n\n#: Create a conda environment\nconda create -n dassl python=3.7\n\n#: Activate the environment\nconda activate dassl\n\n#: Install dependencies\npip install -r requirements.txt\n\n#: Install torch (version >= 1.7.1) and torchvision\nconda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n\n#: Install this library (no need to re-build if the source code is modified)\npython setup.py develop\n```\n\nFollow the instructions in [DATASETS.md](./DATASETS.md) to preprocess the datasets.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9047201326287497
      ],
      "excerpt": "[Oct 2021]: v0.4.3: Copy the attributes in self.dm (data manager) to SimpleTrainer and make self.dm optional, which means from now on, you can build data loaders from any source you like rather than being forced to use DataManager. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8691122973986514
      ],
      "excerpt": "[Jul 2021] v0.3.1: Now you can use *.register(force=True) to replace previously registered modules. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8575660714745077
      ],
      "excerpt": "To use multiple sources, namely the multi-source domain adaptation task, one just needs to add more sources to --source-domains. For instance, to train a source-only baseline on miniDomainNet, one can do \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8778734929964603
      ],
      "excerpt": "    train_u = ...  #: optional, can be None \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8065687632005953
      ],
      "excerpt": "- [Apr 2021] `v0.2.1`: Slightly adjusts the ordering in `setup_cfg()` (see `tools/train.py`). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8680506862920568
      ],
      "excerpt": "initialize the config with cfg = setup_cfg(args) where args contains the command-line input (see tools/train.py for the list of input arguments); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8693362491179931
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0 python tools/train.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8768190281128677,
        0.8368441649934927,
        0.837254893687112
      ],
      "excerpt": "--dataset-config-file configs/datasets/da/office31.yaml \\ \n--config-file configs/trainers/da/source_only/office31.yaml \\ \n--output-dir output/source_only_office31 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8693362491179931
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0 python tools/train.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8768190281128677,
        0.8368441649934927,
        0.837254893687112,
        0.8832558600997413
      ],
      "excerpt": "--dataset-config-file configs/datasets/da/mini_domainnet.yaml \\ \n--config-file configs/trainers/da/source_only/mini_domainnet.yaml \\ \n--output-dir output/source_only_minidn \nAfter the training finishes, the model weights will be saved under the specified output directory, along with a log file and a tensorboard file for visualization. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8693362491179931
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0 python tools/train.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8768190281128677,
        0.8368441649934927,
        0.837254893687112
      ],
      "excerpt": "--dataset-config-file configs/datasets/da/office31.yaml \\ \n--config-file configs/trainers/da/source_only/office31.yaml \\ \n--output-dir output/source_only_office31_test \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8441532505298711
      ],
      "excerpt": "--model-dir output/source_only_office31 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9026457274599516
      ],
      "excerpt": "from dassl.data.datasets import DATASET_REGISTRY, Datum, DatasetBase \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633989807152664
      ],
      "excerpt": "    test = ... \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/KaiyangZhou/Dassl.pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Kaiyang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Dassl",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Dassl.pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "KaiyangZhou",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KaiyangZhou/Dassl.pytorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 472,
      "date": "Fri, 24 Dec 2021 08:00:02 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "benchmark-datasets",
      "semi-supervised-learning",
      "domain-adaptation",
      "domain-generalization",
      "deep-learning",
      "machine-learning",
      "computer-vision",
      "artificial-intelligence",
      "deep-neural-networks"
    ],
    "technique": "GitHub API"
  }
}
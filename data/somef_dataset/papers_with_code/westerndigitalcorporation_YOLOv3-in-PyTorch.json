{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1506.02640",
      "https://arxiv.org/abs/1612.08242",
      "https://arxiv.org/abs/1804.02767"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Original YOLOv3 Paper: [link](https://arxiv.org/pdf/1804.02767.pdf)\n\nYOLOv3 C++ implementation: [link](https://github.com/pjreddie/darknet)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "                        generation. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/westerndigitalcorporation/YOLOv3-in-PyTorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-04T18:55:42Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-08T08:17:26Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You-Only-Look-Once (YOLO) newtork was introduced by Joseph Redmon et al. \nThree versions were implemented in C, with the framework called [darknet](https://github.com/pjreddie/darknet) (paper: [v1](https://arxiv.org/abs/1506.02640), [v2](https://arxiv.org/abs/1612.08242), [v3](https://arxiv.org/abs/1804.02767)).\n\nThis repo implements the Nueral Network (NN) model of YOLOv3 in the PyTorch framework, aiming to ease the pain when the network needs to be modified or retrained.\n\nThere are a number of implementations existing in the open source domain, \ne.g., [eriklindernoren/PyTorch-YOLOv3](https://github.com/eriklindernoren/PyTorch-YOLOv3),\n[ayooshkathuria/pytorch-yolo-v3](https://github.com/ayooshkathuria/pytorch-yolo-v3),\n[ultralytics/yolov3](https://github.com/ultralytics/yolov3), etc.\nHowever, majority of them relies on \"importing\" the configuration file from the original darknet framework.\nIn this work, the model is built from scratch using PyTorch.\n\nAdditionally, both inference and training part are implemented. \nThe original weights trained by the authors are converted to .pt file.\nIt can be used as a baseline for transfer learning.\n\n**This project is licensed under BSD 3-Clause \"Revised\" License.**\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9069282859158617
      ],
      "excerpt": "The repo implements YOLOv3 using the PyTorch framework. Both inference and training modules are implemented. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8646854234516909
      ],
      "excerpt": "The repo is structured as following: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "\u251c\u2500\u2500 data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8630064431775051
      ],
      "excerpt": "The last few layers of the network can be unfreezed for transfer learning or finetuning. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8959415784822954
      ],
      "excerpt": "The help file is pasted here for your convenience. But it might not be up-to-date. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8954032071670849
      ],
      "excerpt": "                        The type of the dataset used. Currently support \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9402417393485545
      ],
      "excerpt": "  --img-size IMG_SIZE   The size of the image for training or inference. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8811861580659057
      ],
      "excerpt": "                        augmentation of the dataset.Currently only COCO \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8214988994803781
      ],
      "excerpt": "                        state is included. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9262349114131911
      ],
      "excerpt": "                        INFERENCE ONLY: iou threshold for non-maximum \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9144475287947055
      ],
      "excerpt": "Execution time is measured using the desktop machine described below (\"My Machine\"). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9501236836382736,
        0.94408264877899
      ],
      "excerpt": "The data in the \"Time from paper (ms)\" column is taken from the original YOLOv3 paper  \n(link), which is not verified on My Machine. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9498484427628919
      ],
      "excerpt": "The configuration of My Machine:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9513745499964228,
        0.9747207826872293,
        0.8244462810001039
      ],
      "excerpt": "For a good explanation of COCO AP (also called mAP), see this post. \nEspecially, AP<sub>50</sub> is extensively used by Redmon et al. to compare the performance of different models. \nHere we inherit this metric. AP<sub>50</sub> is measured using COCO val2017 dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "YOLOv3 in PyTorch with training and inference module implemented.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/westerndigitalcorporation/YOLOv3-in-PyTorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 29,
      "date": "Sat, 25 Dec 2021 12:23:55 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/westerndigitalcorporation/YOLOv3-in-PyTorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "westerndigitalcorporation/YOLOv3-in-PyTorch",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/westerndigitalcorporation/YOLOv3-in-PyTorch/tree/release/docs"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8025517063174478
      ],
      "excerpt": "COCO Average Precision at IoU=0.5 (AP<sub>50</sub>) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9033987252512259
      ],
      "excerpt": "\u251c\u2500\u2500 requirements.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9207914648592189
      ],
      "excerpt": "To train on COCO dataset, first you have to download the dataset from COCO dataset website. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9204949384885232,
        0.9768259891232485
      ],
      "excerpt": "Secondly, pycocotools, which serves as the Python API for COCO dataset needs to be installed. \nPlease follow the instructions on their github repo to install pycocotools. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8527330460043854
      ],
      "excerpt": "               [--weight-path WEIGHT_PATH] [--cpu-only] [--from-ckpt] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8057675898656085
      ],
      "excerpt": "  --annot-path ANNOT_PATH \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8057675898656085
      ],
      "excerpt": "  --weight-path WEIGHT_PATH \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.864003161007744
      ],
      "excerpt": "                        output directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8485671623292644
      ],
      "excerpt": "                        to output directory \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8057675898656085
      ],
      "excerpt": "  --class-path CLASS_PATH \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9587373441757713
      ],
      "excerpt": "* GPU: Nvidia GeForce GTX 1080 Ti \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216582632574806
      ],
      "excerpt": "AP<sub>50</sub> on COCO val2017: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9151270764930737
      ],
      "excerpt": "\u251c\u2500\u2500 src \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8545073611203254
      ],
      "excerpt": "python3 main.py train --verbose --img-dir /path/to/COCO/image/folder --annot-path /path/to/COCO/annotation/file --reset-weights \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9181325253324483,
        0.8193050419892867
      ],
      "excerpt": "python3 main.py test --img-dir /path/to/image/folder --save-det --save-img \nThe --save-det option will save a json detection file to the output folder. The formate matches COCO detection format for easy benchmarking. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9007772939205444
      ],
      "excerpt": "main.py provides numerous options to tweak the functions. Run python3 main.py --help to check the provided options. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9378408768126931,
        0.8008372881546111
      ],
      "excerpt": "usage: main.py [-h] [--dataset DATASET_TYPE] [--img-dir IMG_DIR] \n               [--batch-size BATCH_SIZE] [--n-cpu N_CPU] [--img-size IMG_SIZE] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8180158540548003
      ],
      "excerpt": "               [--save-img] [--save-det] [--ckpt-dir CKPT_DIR] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8013286939506559
      ],
      "excerpt": "  ACTION                'train' or 'test' the detector. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.824881894583499
      ],
      "excerpt": "  --img-dir IMG_DIR     The path to the folder containing images to be \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.806231503790735,
        0.853742312674706
      ],
      "excerpt": "  --batch-size BATCH_SIZE \n                        The number of sample in one batch during training or \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": "                        training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8585707754631647
      ],
      "excerpt": "                        output directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8467776127368987,
        0.8066799865447875
      ],
      "excerpt": "                        to output directory \n  --ckpt-dir CKPT_DIR   TRAINING ONLY: directory where model checkpoints are \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8378056030040637
      ],
      "excerpt": "                        batches. If value is 0, batch checkpoint will turn \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.811854372964597
      ],
      "excerpt": "|   320x320     | 15.1  |   2.9     |     22        | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/westerndigitalcorporation/YOLOv3-in-PyTorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/westerndigitalcorporation/YOLOv3-in-PyTorch/release/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Valid-License-Identifier: BSD-3-Clause\\n\\nBSD-3-Clause\\n\\nCopyright (c) 2019 Western Digital Corporation or its affiliates. All rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without modification,\\nare permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice,\\n   this list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n3. Neither the name of the copyright holder nor the names of its contributors\\n   may be used to endorse or promote products derived from this software without\\n   specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES,\\nINCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\\nWHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\\nUSE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n\\n\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "YOLOv3 in PyTorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "YOLOv3-in-PyTorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "westerndigitalcorporation",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/westerndigitalcorporation/YOLOv3-in-PyTorch/blob/release/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The repo is tested in `Python 3.7`. Additionally, the following packages are required: \n\n```\nnumpy\ntorch>=1.0\ntorchvision\npillow\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 88,
      "date": "Sat, 25 Dec 2021 12:23:55 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Before cloning the repo to your local machine, make sure that `git-lfs` is installed. See details about `git-lfs`, see [this link](https://www.atlassian.com/git/tutorials/git-lfs#installing-git-lfs).\n\nAfter `git-lfs` is installed. Run the following command to see sample detection results.\n```\ngit lfs install\ngit clone https://github.com/westerndigitalcorporation/YOLOv3-in-PyTorch\ncd YOLOv3-in-PyTorch\npip install -r requirements.txt\ncd src\npython3 main.py test --save-img\n\n```\nDetections will be saved in the `output` folder.\n\n",
      "technique": "Header extraction"
    }
  ]
}
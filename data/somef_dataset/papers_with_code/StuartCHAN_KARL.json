{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1810.04805",
      "https://arxiv.org/abs/2002.06823",
      "https://arxiv.org/abs/1810.04805\n\n[4] https://arxiv.org/abs/2002.06823\n\n[5] http://qald.aksw.org/\n\n[6] http://gerbil-qa.aksw.org/gerbil/\n```\n\n*****\n\n[1]:https://www.sciencedirect.com/science/article/pii/S0079742108604223\n\n[2]:https://en.wikipedia.org/wiki/Atkinson%E2%80%93Shiffrin_memory_model\n\n[3]:https://arxiv.org/abs/1810.04805\n\n[4]:https://arxiv.org/abs/2002.06823\n\n[5]:http://qald.aksw.org/\n\n[6]:http://gerbil-qa.aksw.org/gerbil/",
      "https://arxiv.org/abs/2002.06823\n\n[5] http://qald.aksw.org/\n\n[6] http://gerbil-qa.aksw.org/gerbil/\n```\n\n*****\n\n[1]:https://www.sciencedirect.com/science/article/pii/S0079742108604223\n\n[2]:https://en.wikipedia.org/wiki/Atkinson%E2%80%93Shiffrin_memory_model\n\n[3]:https://arxiv.org/abs/1810.04805\n\n[4]:https://arxiv.org/abs/2002.06823\n\n[5]:http://qald.aksw.org/\n\n[6]:http://gerbil-qa.aksw.org/gerbil/",
      "https://arxiv.org/abs/1810.04805\n\n[4]:https://arxiv.org/abs/2002.06823\n\n[5]:http://qald.aksw.org/\n\n[6]:http://gerbil-qa.aksw.org/gerbil/",
      "https://arxiv.org/abs/2002.06823\n\n[5]:http://qald.aksw.org/\n\n[6]:http://gerbil-qa.aksw.org/gerbil/"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\n[1] https://www.sciencedirect.com/science/article/pii/S0079742108604223\n\n[2] https://en.wikipedia.org/wiki/Atkinson%E2%80%93Shiffrin_memory_model\n\n[3] https://arxiv.org/abs/1810.04805\n\n[4] https://arxiv.org/abs/2002.06823\n\n[5] http://qald.aksw.org/\n\n[6] http://gerbil-qa.aksw.org/gerbil/\n```\n\n*****\n\n[1]:https://www.sciencedirect.com/science/article/pii/S0079742108604223\n\n[2]:https://en.wikipedia.org/wiki/Atkinson%E2%80%93Shiffrin_memory_model\n\n[3]:https://arxiv.org/abs/1810.04805\n\n[4]:https://arxiv.org/abs/2002.06823\n\n[5]:http://qald.aksw.org/\n\n[6]:http://gerbil-qa.aksw.org/gerbil/\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "    valid.bert.en-sparql.en.bin \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "    valid.en-sparql.en.bin \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "    valid.en-sparql.sparql.bin \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/StuartCHAN/KARL",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-12T13:03:52Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-11T08:51:14Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9957390941596209,
        0.9965626164638703,
        0.9469583828461002
      ],
      "excerpt": "As the knowledge graph can be growing in data everyday, the semantic contents and graph structures are not constant. The knowledge graph can be considered as a representation that extracts the semantic knowledge of the natural language, and the semantic representation of natural language is varying. If we want to automate the self-querying of a knowledge graph, it is necessary to let the query learn the representation of knowledge space along with the data updates. Here, we want a knowledge-graph neural model that can query right to the answer though the knowledge graph goes through updtates. Our neural model takes natural language question as input to query over the varying knowledge graph, and give the answer as output. How to represent the knowledge space and how the query learns the varying knowledge space are essential.   \nIs there such architecture that can learn the varying knowledge representation space and accordingly do reasoning tasks over the knowledge graph? [Atkinson-Shiffrin Memory Model\u2019s][1] [theory][2] gave the inspiration. We take the input natural language questions as sensory memory, then leveraging the power of attention mechanisms to project the question as embedding vector to query over the knowledge representation space, through which the model self-calibates with the knowledge graph's updates. This is one of our steps to build a self-learning dynamic knowledge graph. \nThe model architecture mainly has three components: Sensory Memory, the encoder part incorporated with pretrained language model; Short-term Memory, the decoder part for query tensor generation; Long-term Memory, the interaction of the query tensor generation and the reward function in the reinforcement learning of knowledge-graph vector space. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.922626934383796,
        0.9266278076738279,
        0.9915778282450687,
        0.9854992652840601,
        0.9689812551857759
      ],
      "excerpt": "and decode into a query tensor; 2)in the generated query tensor, each element is an integer index for the entity or \nrelation embedding; 3)then, the embedded query tensor from step 2 is parsed into triples, and all the embeddings \nin the triples of the query are reduced into a vector representing what the query is asking. \nWe use PyTorch and Fairseq to build our model. Our model takes advantages of BERT's efficiency[3], and adopts inspiration from other paper's efforts[4]. \nThe training dataset is from DBNQA. We use the byte-pair encoding subword-nmt library to tokenize the subwords and rare words units, which helps to deal with the out-of-vocabulary phenomenon.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8318146008310158,
        0.8883684450371622,
        0.8883684450371622
      ],
      "excerpt": "subword-nmt learn-joint-bpe-and-vocab -i .\\data.sparql -o ./bertnmt/code.sparql --write-vocabulary ./bertnmt/voc.sparql \nsubword-nmt apply-bpe -i ./data.en -c ./bertnmt/code.en -o ./bertnmt/data.bpe.en  \nsubword-nmt apply-bpe -i ./data.sparql -c ./bertnmt/code.sparql -o ./bertnmt/data.bpe.sparql   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8152225813508222
      ],
      "excerpt": "To generate the outputs: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Knowledge Aware Reasoning Memory Modeling with Reinforcement Learning of Vector Space",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/StuartCHAN/KARL/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 09:24:48 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/StuartCHAN/KARL/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "StuartCHAN/KARL",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8460131637474574
      ],
      "excerpt": "python preprocess.py --source-lang en --target-lang sparql  --trainpref $DATAPATH/train --validpref $DATAPATH/valid --testpref $DATAPATH/test   --destdir $DATAPATH/train --validpref $DATAPATH/valid --testpref $DATAPATH/destdir  --joined-dictionary --bert-model-name bert-base-uncased   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8412742325440106,
        0.8633989807152664,
        0.8412742325440106,
        0.8633989807152664,
        0.8412742325440106,
        0.8633989807152664,
        0.8387578162363503,
        0.8589534893990137,
        0.8387578162363503,
        0.8589534893990137,
        0.8387578162363503,
        0.8589534893990137
      ],
      "excerpt": "    test.bert.en-sparql.en.bin \n    test.bert.en-sparql.en.idx \n    test.en-sparql.en.bin \n    test.en-sparql.en.idx \n    test.en-sparql.sparql.bin \n    test.en-sparql.sparql.idx \n    train.bert.en-sparql.en.bin \n    train.bert.en-sparql.en.idx \n    train.en-sparql.en.bin \n    train.en-sparql.en.idx \n    train.en-sparql.sparql.bin \n    train.en-sparql.sparql.idx \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8156203672996548
      ],
      "excerpt": "python train.py $DATAPATH/destdir  -a transformer_s2_iwslt_de_en --optimizer adam --lr 0.0005 -s en -t sparql --label-smoothing 0.1  --dropout 0.3 --max-tokens 4000 --min-lr 1e-09 --lr-scheduler inverse_sqrt --weight-decay 0.0001  --criterion label_smoothed_cross_entropy --max-update 150000 --warmup-updates 4000 --warmup-init-lr 1e-07  --adam-betas (0.9,0.98) --save-dir checkpoints/bertnmt0_en_sparql_0.5 --share-all-embeddings  --encoder-bert-dropout --encoder-bert-dropout-ratio 0.5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8286916313111622
      ],
      "excerpt": "python train.py $DATAPATH  -a transformer_s2_iwslt_de_en --optimizer adam --lr 0.0005 -s en -t sparql --label-smoothing 0.1  --dropout 0.3 --max-tokens 4000 --min-lr 1e-09 --lr-scheduler inverse_sqrt --weight-decay 0.0001  --criterion label_smoothed_cross_entropy --max-update 150000 --warmup-updates 4000 --warmup-init-lr 1e-07  --adam-betas '(0.9, 0.98)' --save-dir checkpoints/bertnmt0_en_sparql_0.5 --share-all-embeddings  --warmup-from-nmt --reset-lr-scheduler  --encoder-bert-dropout --encoder-bert-dropout-ratio 0.5  --warmup-nmt-file $checkpoint_last_file \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9315336997676998
      ],
      "excerpt": "python generate.py  $DATAPATH  --path $checkpoint_last_file   --batch-size 128 --beam 5 --remove-bpe  --bert-model-name  bert-base-uncased   --gen-subset train    --results-path $save_dir \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/StuartCHAN/KARL/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C++"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 StuartCHEN\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "KARL",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "KARL",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "StuartCHAN",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/StuartCHAN/KARL/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 09:24:48 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "knowledge-graph",
      "neural-qa",
      "nlp-deep-learning"
    ],
    "technique": "GitHub API"
  }
}
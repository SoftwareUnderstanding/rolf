{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1706.02515"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9559715772848645
      ],
      "excerpt": "multi: multi-instance classification \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8422862053358849
      ],
      "excerpt": "utilities: useful classes and functions \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BioImageInformatics/tfmodels",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-12-27T00:55:40Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-10-27T05:51:35Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9697802705735367,
        0.9270731245658098,
        0.9494316523176057,
        0.9012950455844947,
        0.8744273431569712
      ],
      "excerpt": "Library aiming to aid with quick experimentation for new CNN architectures and training schemes using basic TensorFlow. \nThe focus began as a library for constructing, training, and doing inference with, semantic segmentation CNN's. \nIn addition to semantic segmentation models, the library also contains base methods for training generative models on image datasets, including Generative Adversarial Networks and Variational Autoencoders. \nAdditionally, there is some support for image classification tasks. \nNote instead of using batch norm everywhere, the default activation (see tfmodels/utilities/basemodel.py) is SeLU (https://arxiv.org/abs/1706.02515). Accordingly, the inputs should be scaled to [-1.0, 1.0] in the dataset loading functions, and models should use tf.contrib.nn.alpha_dropout (added as of TensorFlow 1.4.1). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8073908064468488,
        0.9446254957794832
      ],
      "excerpt": "Each segmentation model comes with two child classes: *Training and *Inference. \nThe difference is the required inputs, and training ops are not instantiated when using the *Inference versions (check memory savings/initialization times?). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8750424237791481
      ],
      "excerpt": "Forthcoming will be examples on how to implement a customized network with the tfmodels background doing most of the messy work. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.9319708861235405,
        0.860059181823877
      ],
      "excerpt": "  batch_size=batch_size, record_path=data, **kwargs) \nwith tf.Session() as sess: \n  model = tfmodels.DenseNetTraining( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "    model.train_step() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "  model.snapshot() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9907966530829653
      ],
      "excerpt": "With the new eager execution contrib, we have the option to ditch most of this backend that deals with sessions and storing/calling hooks to ops. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BioImageInformatics/tfmodels/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Mon, 20 Dec 2021 10:36:44 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/BioImageInformatics/tfmodels/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "BioImageInformatics/tfmodels",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": ":#:  NAME \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8349741830518916
      ],
      "excerpt": "To create a segmentation network, first define a dataset from a directory on disk (see below), then initialize the model and a training loop. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8372661437863929
      ],
      "excerpt": "The experiments directory contains examples for training some of the models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216270093103228
      ],
      "excerpt": "For example: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.925671696398174
      ],
      "excerpt": "import tfmodels \nimport tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": ":#:  NAME \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8641498643536674
      ],
      "excerpt": "expdirs = tfmodels.make_experiment('NAME', remove_old=False) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8135654125968134
      ],
      "excerpt": "with tf.Session() as sess: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8945023942380195
      ],
      "excerpt": "#:#: print feedback, test, etc. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8558949476838532
      ],
      "excerpt": "Test segmentation models \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/BioImageInformatics/tfmodels/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Tensorflow CNN's",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "tfmodels",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "BioImageInformatics",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BioImageInformatics/tfmodels/blob/master/ReadMe.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Mon, 20 Dec 2021 10:36:44 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "dataset",
      "tensorflow",
      "variational-autoencoders",
      "architecture",
      "multi-instance",
      "segmentation-model",
      "semantic-segmentation"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Example scripts for data set interface, training and testing various models are provided under `experiments/`.\n- N-class semantic segmentation with various architectures (your data)\n- Generative Adversarial Networks (MNIST)\n- Variational Autoencoders (MNIST)\n- Multi-instance / bagged labels (MNIST)\n\nI've recently revised the way I structure experiments in order to separate my experiments from the structure of this repository.\nNew examples coming soon ^(TM).\n\n",
      "technique": "Header extraction"
    }
  ]
}
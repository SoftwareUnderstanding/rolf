{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```latex\n@inproceedings{\n    anonymous2021an,\n    title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},\n    author={Anonymous},\n    booktitle={Submitted to International Conference on Learning Representations},\n    year={2021},\n    url={https://openreview.net/forum?id=YicbFdNTTy},\n    note={under review}\n}\n```\n\n---\n\n**Thanks for Reading**\n\n---\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{\n    anonymous2021an,\n    title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},\n    author={Anonymous},\n    booktitle={Submitted to International Conference on Learning Representations},\n    year={2021},\n    url={https://openreview.net/forum?id=YicbFdNTTy},\n    note={under review}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8847146907186886
      ],
      "excerpt": "| 2.    | Google Vit Code(1.3K) \u2b50                              | https://github.com/google-research/vision_transformer        | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9812793900327537,
        0.9024396899147646,
        0.9980935707519359,
        0.9939996771380935,
        0.8176806849200354,
        0.9992231702269809,
        0.9946172637744053,
        0.9932311856121002
      ],
      "excerpt": "| 5.    | Vision Transformer Pytorch(80)\u2b50                      | https://github.com/asyml/vision-transformer-pytorch          | \n| 6.    | Pretrained Vision Transformer (70)\u2b50                  | https://github.com/lukemelas/PyTorch-Pretrained-ViT          | \n| 7.    | Vision Transformer TF2(49) \u2b50                         | https://github.com/kamalkraj/Vision-Transformer              | \n| 8.    | Vision Transformer Tensorflow(62) \u2b50                  | https://github.com/emla2805/vision-transformer               | \n| 9.    | Vision Transformer with Control Activation Map(40) \u2b50 | https://github.com/jacobgil/vit-explain                      | \n| 10.   | Vision Transformer Keras(32)\u2b50                        | https://github.com/tuvovan/Vision_Transformer_Keras          | \n| 11.   | Vision Transformer       (20) \u2b50                      | https://github.com/tahmid0007/VisionTransformer              | \n| 12.   | ViT Keras (12) \u2b50                                     | https://github.com/faustomorales/vit-keras                   | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ashishpatel26/Vision-Transformer-Keras-Tensorflow-Pytorch-Examples",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-05T09:45:38Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-20T09:13:50Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Tensorflow implementation of the Vision Transformer (An Image is Worth 16x16 Words: Transformer",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ashishpatel26/Vision-Transformer-Keras-Tensorflow-Pytorch-Examples/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 21,
      "date": "Wed, 29 Dec 2021 05:06:12 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ashishpatel26/Vision-Transformer-Keras-Tensorflow-Pytorch-Examples/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ashishpatel26/Vision-Transformer-Keras-Tensorflow-Pytorch-Examples",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ashishpatel26/Vision-Transformer-Keras-Tensorflow-Pytorch-Examples/main/Vision_Transformer_with_tf2.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9725002728977397
      ],
      "excerpt": "| 1.    | ViT Pytorch (1.9K) \u2b50                                 | https://github.com/lucidrains/vit-pytorch                    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.876591593678253,
        0.8381105533463039,
        0.8762453676007219,
        0.8920553376392694
      ],
      "excerpt": "| 3.    | JeonWorld(161) \u2b50                                     | https://github.com/jeonsworld/ViT-pytorch                    | \n| 4.    | Vit Tensorflow2                                      | https://github.com/ashishpatel26/Vision-Transformer-Keras-Tensorflow-Pytorch-Examples/blob/main/Vision_Transformer_with_tf2.ipynb | \n| 5.    | Vision Transformer Pytorch(80)\u2b50                      | https://github.com/asyml/vision-transformer-pytorch          | \n| 6.    | Pretrained Vision Transformer (70)\u2b50                  | https://github.com/lukemelas/PyTorch-Pretrained-ViT          | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9132932456532682
      ],
      "excerpt": "| 11.   | Vision Transformer       (20) \u2b50                      | https://github.com/tahmid0007/VisionTransformer              | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9794818235876768
      ],
      "excerpt": "| 13.   | VIT Pytorch(9) \u2b50                                     | https://github.com/tczhangzhi/VisionTransformer-Pytorch      | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ashishpatel26/Vision-Transformer-Keras-Tensorflow-Pytorch-Examples/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Vision-Transformer Keras Tensorflow Pytorch Examples",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Vision-Transformer-Keras-Tensorflow-Pytorch-Examples",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ashishpatel26",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ashishpatel26/Vision-Transformer-Keras-Tensorflow-Pytorch-Examples/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 54,
      "date": "Wed, 29 Dec 2021 05:06:12 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "vision-transformer",
      "keras",
      "tensorflow2",
      "pytorch",
      "example",
      "tensorflow"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Tensorflow implementation of the Vision Transformer (ViT) presented in [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://openreview.net/pdf?id=YicbFdNTTy), where the authors show that Transformers applied directly to image patches and pre-trained on large datasets work really well on image classification.\n\n| Official Paper                                   | Official Code                                                | Article Step By Step                                         |\n| ------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| [Download](https://arxiv.org/pdf/2010.11929.pdf) | [Code](https://github.com/google-research/vision_transformer) | [Article](https://jacobgil.github.io/deeplearning/vision-transformer-explainability) |\n\n---\n\n[![img](https://github.com/emla2805/vision-transformer/raw/master/vit.png)](https://github.com/emla2805/vision-transformer/blob/master/vit.png)\n\n\n<object data=\"https://arxiv.org/pdf/2010.11929.pdf\" type=\"application/pdf\" width=\"700px\" height=\"700px\">\n    <embed src=\"https://arxiv.org/pdf/2010.11929.pdf\">\n        <p>Vision Transformer<a href=\"https://arxiv.org/pdf/2010.11929.pdf\">Download PDF</a>.</p>\n    </embed>\n</object>\n\n",
      "technique": "Header extraction"
    }
  ]
}
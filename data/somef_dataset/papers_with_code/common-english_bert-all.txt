# bert
https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html <br>
https://arxiv.org/abs/1810.04805 <br>
https://github.com/google-research/bert <br>
https://en.wikipedia.org/wiki/BERT_(language_model) <br>
# albert
https://ai.googleblog.com/2019/12/albert-lite-bert-for-self-supervised.html <br>
https://arxiv.org/abs/1909.11942 <br>
https://github.com/google-research/ALBERT <br>
# knowbert
https://github.com/allenai/kb <br>
# roberta
https://arxiv.org/abs/1907.11692<br>
# t5
https://github.com/google-research/text-to-text-transfer-transformer<br>
# exbert (for visual analysis)
https://arxiv.org/abs/1910.05276 <br>
http://exbert.net/ <br>
# previous
https://github.com/google-research/language <br>
# on pytorch
https://pytorch.org/tutorials/intermediate/dynamic_quantization_bert_tutorial.html <br>
https://github.com/codertimo/BERT-pytorch<br><br>
# transformer
https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html <br>
https://ai.googleblog.com/2020/01/encode-tag-and-realize-controllable-and.html <br>
# reformer
https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html <br><br><br>
# bertology
![bertology](/img/bertology.jpg)<br><br>
# grover
https://grover.allenai.org/ <br>


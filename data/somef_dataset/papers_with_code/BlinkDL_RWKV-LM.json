{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2105.14103",
      "https://arxiv.org/abs/2002.05202"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "cff-version: 1.2.0\nmessage: \"If you use this software, please cite it as below.\"\nauthors:\n- family-names: \"PENG\"\n  given-names: \"Bo\"\n  orcid: \"https://orcid.org/0000-0002-0865-547X\"\ntitle: \"RWKV-LM\"\nversion: 1.0.0\ndoi: 10.5281/zenodo.5196577\ndate-released: 2021-08-13\nurl: \"https://github.com/BlinkDL/RWKV-LM\"",
      "technique": "File Exploration"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@software{peng_bo_2021_5196578,\n  author       = {PENG Bo},\n  title        = {BlinkDL/RWKV-LM: 0.01},\n  month        = aug,\n  year         = 2021,\n  publisher    = {Zenodo},\n  version      = {0.01},\n  doi          = {10.5281/zenodo.5196577},\n  url          = {https://doi.org/10.5281/zenodo.5196577}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9741310128485788
      ],
      "excerpt": "\"https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+%5Cbegin%7Balign%2A%7D%0A%5Ctext%7BTime-mix+%3A%7D+%26%26+%5Ctext%7BTM%7D_%7Bt%2Cc%7D+%26%26%3D%26%26%5Ctext%7Bsigmoid%7D%28%5Ctext%7BR%7D_%7Bt%2Cc%7D%29+%26%26%5Ccdot%26%26+%26%26%5Ctextstyle%5Csum_%7Bu%7D+%26%26%5Ctextbf%7BW%7D_%7Bt%2Cu%2Cc%7D+%26%26%5Ccdot%26%26+%5Ctext%7Bsoftmax%7D_t%28%5Ctext%7BK%7D_%7Bu%2Cc%7D%29+%26%26%5Ccdot%26%26+%5Ctext%7BV%7D_%7Bu%2Cc%7D%5C%5C%0A%5Ctext%7BChannel-mix+%3A%7D+%26%26+%5Ctext%7BCM%7D_%7Bt%2Cc%7D+%26%26%3D%26%26%5Ctext%7Bsigmoid%7D%28%5Ctext%7BR%7D_%7Bt%2Cc%7D%29+%26%26%5Ccdot%26%26+%26%26%5Ctextstyle%5Csum_d+%26%26%5Ctextbf%7BW%7D_%7Bc%2Cd%7D+%26%26%5Ccdot%26%26+%5Ctext%7Bgelu%7D%28%5Ctext%7BK%7D_%7Bt%2Cd%7D%29+%26%26%5Ccdot%26%26+%5Ctext%7BV%7D_%7Bt%2Cd%7D%0A%5Cend%7Balign%2A%7D%0A\"  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9215899251676908
      ],
      "excerpt": "\"https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+%5Ctext%7Bsoftmax%7D_t%28%5Ctext%7BK%7D_%7Bu%2Cc%7D%29+%3D+%5Cfrac%7B%5Cexp%28%5Ctext%7BK%7D_%7Bu%2Cc%7D%29%7D%7B%5Csum_%7Bv+%5Cleq+t%7D%5Cexp%28%5Ctext%7BK%7D_%7Bv%2Cc%7D%29%7D\"  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9027837362477646
      ],
      "excerpt": "\"https://render.githubusercontent.com/render/math?math=%5Cdisplaystyle+W_%7Bt%2Cu%2Cc%7D%3Df_h%28t-u%29%5Ccdot+%5Calpha_h%28u%29+%5Ccdot+%5Cbeta_h%28t%29\"  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BlinkDL/RWKV-LM",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-08T06:05:27Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-27T10:30:24Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9390085461446839
      ],
      "excerpt": "We propose the RWKV language model, with alternating time-mix and channel-mix layers: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9939623918279642
      ],
      "excerpt": "The R, K, V are generated by linear transforms of input, and W is parameter. The idea of RWKV is to decompose attention into R(target) * W(src, target) * K(src). So we can call R \"receptance\", and sigmoid means it's in 0~1 range. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9274340199121923
      ],
      "excerpt": "(1) We changed the normalization (denominator). For masked language models, we define: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.880489592518596
      ],
      "excerpt": "(2) We decompose W_{t,u,c} and introduce multi-head W (here h is the corresponding head of c): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9757085770671041,
        0.8028259612976467
      ],
      "excerpt": "Moreover we multiply the final output of Time-mix layer by \u03b3(t). The reason for the \u03b1 \u03b2 \u03b3 factors, is because the context size is smaller when t is small, and this can be compensated using the \u03b1 \u03b2 \u03b3 factors. \nThe Channel-mix is similar to GeGLU (https://arxiv.org/abs/2002.05202) with an extra R factor. Initialize R and W matrices to ZERO for fast & stable convergence. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.960675221081093
      ],
      "excerpt": "The token-shift explicitly uses (half the channels of this token) & (half the channels of prev token) to generate all vectors (QKV, RWKV, ...). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8228263439546114,
        0.8823954098530552,
        0.9464418462662899,
        0.8775025526050351,
        0.8981728657961099
      ],
      "excerpt": "Dividing channels by 2 and shift-1 works great for char-level English and char-level Chinese LM. \nHowever for BPE-level English LM, it's only effective if your embedding is large enough (at least 1024 - so the usual small L12-D768 model is not enough). \nMy theory on the effectiveness of token-shift: \nWhen we train a GPT, the hidden representation of a token has to accomplish two different objects: \nPredict the next token. Sometimes this is easy (obvious next token). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9649855075673608
      ],
      "excerpt": "The shifted channels can focus on (2), so we have good propagation of info. It's like some kind of residual connection, or a small RNN inside the transformer. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.977218823884806,
        0.8445152823382751
      ],
      "excerpt": "p.s. There is a MHA_pro model in this repo with strong performance. Give it a try :) \nWe also propose a new sampling method called top-a (as in src/utils.py): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.86827575840206
      ],
      "excerpt": "The idea of top-a: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9163404962240157
      ],
      "excerpt": "Red: RWKV (\"linear\" attention) - VRAM friendly - quite faster when ctx window is long - good performance. 16.6M params. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8084360494412939,
        0.95226561521594
      ],
      "excerpt": "Blue: MHA_pro (MHA with various tweaks & RWKV-type-FFN) - slow - needs more VRAM - good performance. 16.6M params. \nWe use careful initialization for RWKV to get fast convergence - orthogonal matrices with proper scaling, and special time_w curves. Check model.py for details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "The RWKV Language Model with Token-shift. Better and Faster than usual transformer / GPT.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BlinkDL/RWKV-LM/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 15,
      "date": "Mon, 27 Dec 2021 22:23:40 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/BlinkDL/RWKV-LM/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "BlinkDL/RWKV-LM",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8647354795712904
      ],
      "excerpt": "<img src= \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8259119450785217,
        0.826342798203535
      ],
      "excerpt": "\\text{Time-mix :} && \\text{TM}_{t,c} &&=&&\\text{sigmoid}(\\text{R}_{t,c}) &&\\cdot&& &&\\textstyle\\sum_{u} &&\\textbf{W}_{t,u,c} &&\\cdot&& \\text{softmax}_t(\\text{K}_{u,c}) &&\\cdot&& \\text{V}_{u,c}\\\\ \n\\text{Channel-mix :} && \\text{CM}_{t,c} &&=&&\\text{sigmoid}(\\text{R}_{t,c}) &&\\cdot&& &&\\textstyle\\sum_d &&\\textbf{W}_{c,d} &&\\cdot&& \\text{gelu}(\\text{K}_{t,d}) &&\\cdot&& \\text{V}_{t,d} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8647354795712904
      ],
      "excerpt": "<img src= \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8497562825352714
      ],
      "excerpt": "alt=\"\\text{softmax}_t(\\text{K}_{u,c}) = \\frac{\\exp(\\text{K}_{u,c})}{\\sum_{v \\leq t}\\exp(\\text{K}_{v,c})}\">   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8647354795712904
      ],
      "excerpt": "<img src= \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8060372108626078
      ],
      "excerpt": "Green: MHA+Rotary+GeGLU+Token_shift. 17.2M params. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/BlinkDL/RWKV-LM/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 2-Clause \"Simplified\" License",
      "url": "https://api.github.com/licenses/bsd-2-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 2-Clause License\\n\\nCopyright (c) 2021, PENG Bo\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "The RWKV Language Model",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "RWKV-LM",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "BlinkDL",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BlinkDL/RWKV-LM/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "BlinkDL",
        "body": "v0.02 with RWKV, MHA_shift, MHA_rotary, MHA_pro, and time-shift mixing.",
        "dateCreated": "2021-08-25T10:49:12Z",
        "datePublished": "2021-08-25T15:05:54Z",
        "html_url": "https://github.com/BlinkDL/RWKV-LM/releases/tag/0.02",
        "name": "0.02",
        "tag_name": "0.02",
        "tarball_url": "https://api.github.com/repos/BlinkDL/RWKV-LM/tarball/0.02",
        "url": "https://api.github.com/repos/BlinkDL/RWKV-LM/releases/48436948",
        "zipball_url": "https://api.github.com/repos/BlinkDL/RWKV-LM/zipball/0.02"
      },
      {
        "authorType": "User",
        "author_name": "BlinkDL",
        "body": "first release with RWKV, MHA_rotary, MHA_pro, and time-shift mixing.",
        "dateCreated": "2021-08-13T10:39:24Z",
        "datePublished": "2021-08-13T15:58:28Z",
        "html_url": "https://github.com/BlinkDL/RWKV-LM/releases/tag/0.01",
        "name": "0.01",
        "tag_name": "0.01",
        "tarball_url": "https://api.github.com/repos/BlinkDL/RWKV-LM/tarball/0.01",
        "url": "https://api.github.com/repos/BlinkDL/RWKV-LM/releases/47821621",
        "zipball_url": "https://api.github.com/repos/BlinkDL/RWKV-LM/zipball/0.01"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 83,
      "date": "Mon, 27 Dec 2021 22:23:40 GMT"
    },
    "technique": "GitHub API"
  }
}
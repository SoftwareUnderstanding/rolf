{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2006.04603",
      "https://arxiv.org/abs/1803.01199"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "For any use or reference to this project please cite the following paper.\n\n[NEWS]: this work got accepted at Medical Image Analysis. Available [here](https://doi.org/10.1016/j.media.2021.102046)\n```\n@article{SIGNORONI2021102046,\ntitle = {BS-Net: learning COVID-19 pneumonia severity on a large Chest X-Ray dataset},\njournal = {Medical Image Analysis},\npages = {102046},\nyear = {2021},\nissn = {1361-8415},\ndoi = {https://doi.org/10.1016/j.media.2021.102046},\nurl = {https://www.sciencedirect.com/science/article/pii/S136184152100092X},\nauthor = {Alberto Signoroni and Mattia Savardi and Sergio Benini and Nicola Adami and Riccardo Leonardi and Paolo Gibellini and Filippo Vaccher and Marco Ravanelli and Andrea Borghesi and Roberto Maroldi and Davide Farina},\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{SIGNORONI2021102046,\ntitle = {BS-Net: learning COVID-19 pneumonia severity on a large Chest X-Ray dataset},\njournal = {Medical Image Analysis},\npages = {102046},\nyear = {2021},\nissn = {1361-8415},\ndoi = {https://doi.org/10.1016/j.media.2021.102046},\nurl = {https://www.sciencedirect.com/science/article/pii/S136184152100092X},\nauthor = {Alberto Signoroni and Mattia Savardi and Sergio Benini and Nicola Adami and Riccardo Leonardi and Paolo Gibellini and Filippo Vaccher and Marco Ravanelli and Andrea Borghesi and Roberto Maroldi and Davide Farina},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{SIGNORONI2021102046,\ntitle = {BS-Net: learning COVID-19 pneumonia severity on a large Chest X-Ray dataset},\njournal = {Medical Image Analysis},\npages = {102046},\nyear = {2021},\nissn = {1361-8415},\ndoi = {https://doi.org/10.1016/j.media.2021.102046},\nurl = {https://www.sciencedirect.com/science/article/pii/S136184152100092X},\nauthor = {Alberto Signoroni and Mattia Savardi and Sergio Benini and Nicola Adami and Riccardo Leonardi and Paolo Gibellini and Filippo Vaccher and Marco Ravanelli and Andrea Borghesi and Roberto Maroldi and Davide Farina},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.810985927055588
      ],
      "excerpt": "BS-Net: an end-to-end multi-network learning architecture for semiquantitative rating of COVID-19 severity on Chest X-rays \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "Preprint avaible here \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9349162333117631
      ],
      "excerpt": "| [Shenzhen Hospital](https://arxiv.org/abs/1803.01199) | 516          | 50       | first 50 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "|Shift     | 10%           | 0.8 | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BrixIA/Brixia-score-COVID-19",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Alberto Signoroni alberto.signoroni@unibs.it \n\nMattia Savardi m.savardi001@unibs.it\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-08T15:02:32Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-12T07:35:44Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9562593803762796,
        0.9307411548182306,
        0.93785153478539,
        0.9284440839283359
      ],
      "excerpt": "Info, code (BS-Net), link to data (BrixIA COVID-19 Dataset annotated with Brixia-score), and additional material related to the BrixIA COVID-19 Project \nBrixIA COVID-19 Project: go to the webpage \nBrixia score: a multi-regional score for Chest X-ray (CXR) conveying the degree of lung compromise in COVID-19 patients \nBS-Net: an end-to-end multi-network learning architecture for semiquantitative rating of COVID-19 severity on Chest X-rays \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9968029537584643
      ],
      "excerpt": "Table of Contents \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9215196949036746
      ],
      "excerpt": "The access and use, for research purposes only, of the annotated BrixIA COVID-19 CXR Dataset have been granted form the Ethical Committee of Brescia (Italy) NP4121 (last update 08/07/2020). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8485394708617819
      ],
      "excerpt": "To unpack all the zipped archives, on unix-like system do: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9927902231583698
      ],
      "excerpt": "In order to contribute to such public dataset, two expert radiologists, a board-certified staff member and a trainee with 22 and 2 years of experience respectively, produced the related Brixia-score annotations for CXR in this collection, exploiting labelbox, an online solution for labelling. After discarding problematic cases (e.g., images with a significant portion missing, too small resolution, the impossibility of scoring for external reasons, etc.), the final dataset is composed of 192 CXR, completely annotated according to the Brixia-score system. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.827837710408278,
        0.8303423088363528,
        0.827837710408278,
        0.8303423088363528
      ],
      "excerpt": "| from S-A to S-F | The 6 regions annotatated by a Senior radiologist (+20yr expertise), from 0 to 3  \n| S-Global | Global score by the Senior radiologist (sum of S-A : S-F),  from 0 to 18 \n| from J-A to J-F | The 6 regions annotatated by a Junior radiologist (+2yr expertise),  from 0 to 3  \n| J-Global | Global score by the Junior radiologist (sum of S-A : S-F),  from 0 to 18 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.96205460241536,
        0.8353318302916548
      ],
      "excerpt": "We provide the script to prepare the dataset as described in the Project paper.  \nWe exploit different segmentation datasets in order to pre-train the extended-Unet module of the proposed architecture. We used the original training/test set splitting when present (as the case of the JSRT database), otherwise we took the first 50 images as test set, and the remaining as training set (see Table below). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9717708335125793,
        0.9807076698127967
      ],
      "excerpt": "To avoid the inclusion of anatomical parts not belonging to the lungs in the AI pipeline, which would increase the task complexity or introduce unwanted biases, we integrated into the pipeline an alignment block. This exploits a synthetic dataset (used for on-line augmentation) composed of artificially transformed images from the segmentation dataset (see Table below), including random rotations, shifts, and zooms, which is used in the pre-training phase. \nThe parameters refer to the implementation in Albumentation. In the last column is expressed the probability of the specific transformation being applied. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8660764167632063
      ],
      "excerpt": ": Check the docsting for additional info \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401067699753039,
        0.9129828520194249,
        0.8407833700299191
      ],
      "excerpt": "The model weight and a demo notebook can be found here \nInstructions for preparing and loading the Brixia Covid-19 Dataset and the BS-Net will follow (see specific sections for more info). \nBrixIA COVID-19 dataset: access conditions and term of use are reported on the dataset website. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.806803502867345
      ],
      "excerpt": "Brixia-score annotations for the pulic Cohen's dataset are released under a CC BY-NC-SA 4.0 license. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "End-to-end learning for semiquantitative rating of COVID-19 severity on Chest X-rays. Additional material and updates.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BrixIA/Brixia-score-COVID-19/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Sat, 25 Dec 2021 20:38:03 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/BrixIA/Brixia-score-COVID-19/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "BrixIA/Brixia-score-COVID-19",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To prepare the alignment dataset, the segmentation one mush be already built (see previous point)\n\n```python\nfrom datasets import synthetic_alignment  as sa\n\n#: Check the docsting for additional info. The train-set and validation-set are provided as generators\n#: `get_data` accepts a configuration dictionary where you can specify every parameter. See `ls.default_config`\ntrain_gen, val_gen = sa.get_data()\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "To prepare the segmentation dataset either `Montgomery County`, `Shenzhen Hospital`, and `JSRT` datasets must be\ndownloaded from their websites and unpacked in a folder (for instance `data/sources/`). Than execute:\n```bash\n python3 -m datasets.lung_segmentation  --input_folder data/sources/ --target_size 512\n```\nor just import it (the first time it is executed, it will create the segmentation dataset):\n\n```python\nfrom datasets import lung_segmentation  as ls\n\n#: Check the docsting for additional info. The train-set is provided as a generator, while the validation set is\n#: preloaded in memory.\n#: `get_data` accepts a configuration dictionary where you can specify every parameter. See `ls.default_config`\ntrain_gen, (val_imgs, val_masks) = ls.get_data()\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "The provided code is written for Python 3.x. To install the needed requirements run:\n```\npip install -r requirements.txt\n```\nFor the sake of performance, we suggest to install `tensorflow-gpu` in place of the standard CPU version.\n\nInclude the `src` folder in your python library path or launch python from that folder.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8316535556140937,
        0.854983080323723
      ],
      "excerpt": "The data can be downloaded from the website https://brixia.github.io/. \nTo unpack all the zipped archives, on unix-like system do: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.85749461564741
      ],
      "excerpt": "2. From the command line call:  cat *.tar.gz.* | tar -xzv \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8260439491387641
      ],
      "excerpt": "2. type *.tar.gz.* | tar xvfz - \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.876842004056701
      ],
      "excerpt": "| filename | filename from Cohen dataset | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8215488788341697
      ],
      "excerpt": "|  | Training-set |  Test-set | Split |  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.853492186136904
      ],
      "excerpt": "|Total             | 728           |223      || \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.880932325440091
      ],
      "excerpt": "from datasets import brixiascore_cohen  as bsc \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8046416174405643
      ],
      "excerpt": "The model weight and a demo notebook can be found here \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/BrixIA/Brixia-score-COVID-19/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'License Text for ASU GitHub Project\\n\\nCopyright 2019 Arizona Board of Regents for and on behalf of Arizona State University, a body corporate \\nPatent Pending in the United States of America\\n\\nLICENSE\\n\\nArizona Board of Regents, for and on behalf of Arizona State University, a body corporate (\\xe2\\x80\\x9cLicensor\\xe2\\x80\\x9d) offers its \\xe2\\x80\\x9cUNet++: Redesigning Skip Connections to Exploit Multi-Resolution Features in Image Segmentation\\xe2\\x80\\x9d project (Tech ID no. M19-189LC) (the \\xe2\\x80\\x9cWork\\xe2\\x80\\x9d) solely for non-commercial use under the following terms and conditions:\\n1. Definitions.\\n      \"License\" means the terms and conditions for use, reproduction, and distribution of the Work set forth in this document.\\n      \"You\" (or \"Your\") shall mean an individual or entity exercising permissions granted by this License.\\n      \"Source\" form means the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.\\n      \"Object\" form means any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.\\n      \"Work\" shall mean the work(s) of authorship, whether in Source or Object form, made available under the License, as identified above.\\n      \"Derivative Works\" means any work, whether in Source or Object form, that incorporates, is based on, or is otherwise derived from the Work or from any other Derivative Work authorized under this License and whereby such work  constitutes, as a whole, a separate original work of authorship. For the purposes of this License, Derivative Works do not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.\\n      \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner of the submission or by an individual authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\"\\n      \"Contributor\" shall mean Licensor and any individual or entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.\\n\\n2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, revocable (as stated in this section) right to perform any or all of the following actions solely for academic and other non-commercial research purposes: reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object.  Any person or entity wishing to make a commercial use of the Work or a Derivative Work must enter into a separate written agreement with the Licensor and, in the case of a Derivative Work, any other applicable copyright owner of that Derivative Work. For the avoidance of doubt, no licenses to use the Work for commercial or for-profit purposes are granted hereunder.  If Licensor determines in its sole discretion that You have exceeded the scope or otherwise breached the terms of the License granted herein, it shall have the right to terminate the License in addition to all other remedies available to it under common law, by statute, and in equity.\\n\\n3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, revocable (as stated in this section) right to make, have made, use, and import the Work solely for academic and other non-commercial research purposes; provided that such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work. Any person or entity wishing to make a commercial use of the Work or a Derivative Work must enter into a separate written agreement with the Licensor and, in the case of a Derivative Work, any other applicable patent owner with claims pertaining to that Derivative Work. For the avoidance of doubt, no licenses to use the Work for commercial or for-profit purposes are granted hereunder.  If You institute patent litigation against any individual or entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work or such Contribution shall terminate as of the date such litigation is filed.  If Licensor determines in its sole discretion that You have exceeded the scope or otherwise breached the terms of the License granted herein, it shall have the right to terminate the License in addition to all other remedies available to it under common law, by statute, and in equity.\\n\\n4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:\\n      (a) The reproduction and distribution is only for academic or other non-commercial research purposes;\\n      (b) You must give any other recipients of the Work or Derivative Works a copy of this License;\\n      (c) You must cause any modified files to carry prominent notices stating that You changed the files and include in a NOTICE text file a description of Your changes; \\n      (d) You must retain, in the Source form of any Derivative Work that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, except for notices that do not pertain to any portion of the Derivative Work;\\n      (e) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Work that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, except for notices that do not pertain to any part of the Derivative Work, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Work; within the Source form or documentation, if provided along with the Derivative Work; or, within a display generated by the Derivative Work, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed          as modifying the License.  You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with all the terms and conditions stated in this License.\\n\\n5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of      this License, without any additional terms or conditions.  Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate agreement you may have executed or may execute with Licensor regarding such Contributions.\\n\\n6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor.    Pursuant to nominative fair use principles, you may merely identify Licensor as the original author of the Work.\\n\\n7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND.  LICENSOR HEREBY DISCLAIMS ALL WARRANTIES, WHETHER EXPRESS, IMPLIED, STATUTORY OR OTHER (INCLUDING ALL WARRANTIES ARISING FROM COURSE OF DEALING, USAGE OR TRADE PRACTICE), AND SPECIFICALLY DISCLAIMS ALL IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. WITHOUT LIMITING THE FOREGOING, LICENSOR MAKES NO WARRANTY OF ANY KIND THAT THE WORK, OR ANY OTHER LICENSOR OR THIRD-PARTY GOODS, SERVICES, TECHNOLOGIES OR MATERIALS (INCLUDING ANY SOFTWARE OR HARDWARE), OR ANY PRODUCTS OR RESULTS OF THE USE OF ANY OF THEM, WILL MEET YOUR OR ANY OTHER PERSONS\\' REQUIREMENTS, OPERATE WITHOUT INTERRUPTION, ACHIEVE ANY INTENDED RESULT, BE COMPATIBLE OR WORK WITH ANY OTHER GOODS, SERVICES, TECHNOLOGIES OR MATERIALS (INCLUDING ANY SOFTWARE, HARDWARE, SYSTEM OR NETWORK), OR BE SECURE, ACCURATE, COMPLETE, FREE OF HARMFUL CODE OR ERROR FREE. ALL OPEN-SOURCE COMPONENTS AND OTHER THIRD-PARTY MATERIALS ARE PROVIDED \"AS IS\" AND ANY REPRESENTATION OR WARRANTY OF OR CONCERNING ANY OF THEM IS STRICTLY BETWEEN YOU AND THE THIRD-PARTY OWNER OR DISTRIBUTOR OF SUCH OPEN-SOURCE COMPONENTS AND THIRD-PARTY MATERIALS. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.\\n\\n8. Limitation of Liability. UNLESS REQUIRED BY APPLICABLE LAW OR OTHERWISE AGREED IN WRITING, IN NO EVENT WILL LICENSOR OR ANY CONTRIBUTOR BE LIABLE FOR DAMAGES UNDER OR IN CONNECTION WITH THIS LICENSE OR ITS SUBJECT MATTER UNDER ANY LEGAL OR EQUITABLE THEORY, INCLUDING BREACH OF CONTRACT, TORT (INCLUDING NEGLIGENCE), STRICT LIABILITY AND OTHERWISE, FOR ANY (a) INCREASED COSTS, DIMINUTION IN VALUE OR LOST BUSINESS, PRODUCTION, REVENUES OR PROFITS, (b) LOSS OF GOODWILL OR REPUTATION, (c) USE, INABILITY TO USE, LOSS, INTERRUPTION, DELAY OR RECOVERY OF ANY LICENSED SOFTWARE[ OR OPEN-SOURCE COMPONENTS OR OTHER THIRD-PARTY MATERIALS], (d) LOSS, DAMAGE, CORRUPTION OR RECOVERY OF DATA, OR BREACH OF DATA OR SYSTEM SECURITY, (e) COST OF REPLACEMENT GOODS OR SERVICES, OR (e) CONSEQUENTIAL, INCIDENTAL, INDIRECT, EXEMPLARY, SPECIAL, ENHANCED OR PUNITIVE DAMAGES, IN EACH CASE REGARDLESS OF WHETHER SUCH PERSONS WERE ADVISED OF THE POSSIBILITY OF SUCH LOSSES OR DAMAGES OR SUCH LOSSES OR DAMAGES WERE OTHERWISE FORESEEABLE, AND NOTWITHSTANDING THE FAILURE OF ANY AGREED OR OTHER REMEDY OF ITS ESSENTIAL PURPOSE\\n\\n9. Keras Library.  The Work includes and is implemented on the Keras library.  The Keras library is offered under the MIT License as follows:\\nCOPYRIGHT\\nAll contributions by Fran\\xc3\\xa7ois Chollet:\\nCopyright (c) 2015 - 2019, Fran\\xc3\\xa7ois Chollet.\\nAll rights reserved.\\n\\nAll contributions by Google:\\nCopyright (c) 2015 - 2019, Google, Inc.\\nAll rights reserved.\\n\\nAll contributions by Microsoft:\\nCopyright (c) 2017 - 2019, Microsoft, Inc.\\nAll rights reserved.\\n\\nAll other contributions:\\nCopyright (c) 2015 - 2019, the respective contributors.\\nAll rights reserved.\\n\\nEach contributor holds copyright over their respective contributions.\\nThe project versioning (Git) records all such contribution source information.\\n\\nLICENSE FOR KERAS\\n\\nThe MIT License (MIT)\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# BrixIA COVID-19 Project\n\n## What do you find here\nInfo, code (BS-Net), link to data (BrixIA COVID-19 Dataset annotated with Brixia-score), and additional material related to the [BrixIA COVID-19 Project](https://brixia.github.io/)\n\n## Defs\n\nBrixIA COVID-19 Project: [go to the webpage](https://brixia.github.io/)\nBrixia score: a multi-regional score for Chest X-ray (CXR) conveying the degree of lung compromise in COVID-19 patients\n\nBS-Net: an end-to-end multi-network learning architecture for semiquantitative rating of COVID-19 severity on Chest X-rays\n\nBrixIA COVID-19 Dataset: 4703 CXRs of COVID-19 patients (anonymized) in DICOM format with manually annotated Brixia score\n\n## Project paper\nPreprint avaible [here](https://arxiv.org/abs/2006.04603)\n```\n@article{SIGNORONI2021102046,\ntitle = {BS-Net: learning COVID-19 pneumonia severity on a large Chest X-Ray dataset},\njournal = {Medical Image Analysis},\npages = {102046},\nyear = {2021},\nissn = {1361-8415},\ndoi = {https://doi.org/10.1016/j.media.2021.102046},\nurl = {https://www.sciencedirect.com/science/article/pii/S136184152100092X},\nauthor = {Alberto Signoroni and Mattia Savardi and Sergio Benini and Nicola Adami and Riccardo Leonardi and Paolo Gibellini and Filippo Vaccher and Marco Ravanelli and Andrea Borghesi and Roberto Maroldi and Davide Farina},\n}2020}\n}\n```\n\n## Overall Scheme\n\n![Global flowchart](figures/global-flowchart.png \"Global flowchart\")\n\nTable of Contents",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Brixia-score-COVID-19",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "BrixIA",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/BrixIA/Brixia-score-COVID-19/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The provided code is written for Python 3.x. To install the needed requirements run:\n```\npip install -r requirements.txt\n```\nFor the sake of performance, we suggest to install `tensorflow-gpu` in place of the standard CPU version.\n\nInclude the `src` folder in your python library path or launch python from that folder.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 33,
      "date": "Sat, 25 Dec 2021 20:38:03 GMT"
    },
    "technique": "GitHub API"
  }
}
# dcgan
This project is for CS-UY 3943 Mining Massive Datasets class at NYU Tandon School of Engineering.

## About
This project demonstrates the capabilities of the Deep Convolutional Generative Adversarial Network (DCGAN). 

The folder named scripts contains some scripts for your reference:
The file named art.py is a scraper that scrapes images from WikiArt, an encyclopedia containing numerous art images. This file was obtained from Robbie Barrat's genre-scraper.py in his art-DCGAN repo (click this link for the repo: https://github.com/robbiebarrat/art-DCGAN).

The file named google.py is a scraper that scrapes from Google Images. 
Because of issues with regards to scraping WikiArt, I planned to scrape from Google, but seeing that some of the images there were not artworks (some images were advertisements/informative graphics), in the end I decided to use a Kaggle dataset that already had a large sample of images from WikiArt (see references below).

The folder named jupyter_notebooks contain some jupyter notebook files for your reference:
The files named dcgan.ipynb, landscape.ipynb, and portrait.ipynb are Jupyter Notebook files that you can run on your machine to produce your own images using the DCGAN. They are essentially identical in code, with the only difference being the outputs after the training of the DCGAN are different - dcgan and landscape contain images generated by training the DCGAN on landscape photos, and portrait contains images generated by training the DCGAN on portrait photos. You can see the progress it made from the start of the training to the end, and the final products for both trainings. Just for clarification, most of this code is not my own, as I used code from a PyTorch tutorial for the making and training of the DCGAN (click this link to view the tutorial: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html). Only changes I made to the code can be seen in dcgan.ipynb, where I included lines that would save the numpy array versions of the images in the dataset, as well as the numpy array versions of the images generated by the DCGAN (view the folder called images_npy for the numpy array versions of these images). In addition, I increased the number of layers for the networks in the DCGAN to support 128px by 128px images, whereas the tutorial supports 64px by 64px images. 

The file named lsh.ipynb contains code to generate an LSH table. All images in the images_npy folder are stored in the LSH table, and you can query the table by converting the generated images in the images_npy folder to find images from the dataset that are similar to the generated image that you are querying. 

The folder named images_good contains images generated by the DCGAN in pixel format rather than the numpy array format in the images_npy folder.

## Run This Project
To generate images, you must have PyTorch on your computer. In addition, if you find that the scrapers are not useful, you can download the image dataset that I used from this link: https://www.kaggle.com/ipythonx/wikiart-gangogh-creating-art-gan?select=abstract - these images were used to train the DCGAN to generate its own images.

To store images in an LSH table, you must have lshashpy3 on your computer. 

## My System
In case you were interested, I ran this code on a custom built PC running Windows 10 with a NVIDIA GPU RTX 2080 and an Intel i9-9900K CPU with 32GB RAM. Running landscape.ipynb with an image sample of 15000 landscape images took around 2.5 hours to complete.

## References

For references, you can check out the following links:

DCGAN paper - https://arxiv.org/pdf/1511.06434.pdf%5D

Robbie Barrat's Lua implementation - https://github.com/robbiebarrat/art-DCGAN

Pytorch's implementation - https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html

WikiArt Kaggle Dataset - https://www.kaggle.com/ipythonx/wikiart-gangogh-creating-art-gan?select=abstract

WikiArt - https://www.wikiart.org/

{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2103.14962"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please cite our paper if this code benefits your research:\n```\n@inproceedings{Zhou2021PanopticPolarNet,\nauthor={Zhou, Zixiang and Zhang, Yang and Foroosh, Hassan},\ntitle={Panoptic-PolarNet: Proposal-free LiDAR Point Cloud Panoptic Segmentation},\nbooktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\nyear={2021}\n}\n\n@InProceedings{Zhang_2020_CVPR,\nauthor = {Zhang, Yang and Zhou, Zixiang and David, Philip and Yue, Xiangyu and Xi, Zerong and Gong, Boqing and Foroosh, Hassan},\ntitle = {PolarNet: An Improved Grid Representation for Online LiDAR Point Clouds Semantic Segmentation},\nbooktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\nmonth = {June},\nyear = {2020}\n}\n```",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@InProceedings{Zhang_2020_CVPR,\nauthor = {Zhang, Yang and Zhou, Zixiang and David, Philip and Yue, Xiangyu and Xi, Zerong and Gong, Boqing and Foroosh, Hassan},\ntitle = {PolarNet: An Improved Grid Representation for Online LiDAR Point Clouds Semantic Segmentation},\nbooktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\nmonth = {June},\nyear = {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{Zhou2021PanopticPolarNet,\nauthor={Zhou, Zixiang and Zhang, Yang and Foroosh, Hassan},\ntitle={Panoptic-PolarNet: Proposal-free LiDAR Point Cloud Panoptic Segmentation},\nbooktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\nyear={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9792428879788975
      ],
      "excerpt": "[ArXiv paper] \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/edwardzhou130/Panoptic-PolarNet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-18T22:56:15Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T06:15:32Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Panoptic-PolarNet is a fast and robust LiDAR point cloud panoptic segmentation framework. We learn both semantic segmentation and class-agnostic instance clustering in a single inference network using a polar Bird's Eye View (BEV) representation. Predictions from the semantic and instance head are then fused through a majority voting to create the final panopticsegmentation.\n\n<p align=\"center\">\n        <img src=\"imgs/CVPR_pipeline.png\" width=\"100%\"> \n</p>\n\nWe test Panoptic-PolarNet on SemanticKITTI and nuScenes datasets. Experiment shows that Panoptic-PolarNet reaches state-of-the-art performances with a real-time inference speed.\n\n<p align=\"center\">\n        <img src=\"imgs/result.png\" width=\"100%\"> \n</p>\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9921478355527739
      ],
      "excerpt": "This is the official implementation of Panoptic-PolarNet. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8032846479540435
      ],
      "excerpt": "We also provide a pretrained Panoptic-PolarNet weight. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation for Panoptic-PolarNet (CVPR 2021)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/edwardzhou130/Panoptic-PolarNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 11,
      "date": "Thu, 23 Dec 2021 16:27:26 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/edwardzhou130/Panoptic-PolarNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "edwardzhou130/Panoptic-PolarNet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This code is tested on Ubuntu 16.04 with Python 3.8, CUDA 10.2 and Pytorch 1.7.0.\n\n1, Install the following dependencies by either `pip install -r requirements.txt` or manual installation.\n* numpy\n* pytorch\n* tqdm\n* yaml\n* Cython\n* [numba](https://github.com/numba/numba)\n* [torch-scatter](https://github.com/rusty1s/pytorch_scatter)\n* [dropblock](https://github.com/miguelvr/dropblock)\n* (Optional) [open3d](https://github.com/intel-isl/Open3D)\n\n2, Download Velodyne point clouds and label data in SemanticKITTI dataset [here](http://www.semantic-kitti.org/dataset.html#overview).\n\n3, Extract everything into the same folder. The folder structure inside the zip files of label data matches the folder structure of the LiDAR point cloud data.\n\n4, Data file structure should look like this:\n\n```\n./\n\u251c\u2500\u2500 train.py\n\u251c\u2500\u2500 ...\n\u2514\u2500\u2500 data/\n    \u251c\u2500\u2500sequences\n        \u251c\u2500\u2500 00/           \n        \u2502   \u251c\u2500\u2500 velodyne/\t#: Unzip from KITTI Odometry Benchmark Velodyne point clouds.\n        |   |\t\u251c\u2500\u2500 000000.bin\n        |   |\t\u251c\u2500\u2500 000001.bin\n        |   |\t\u2514\u2500\u2500 ...\n        \u2502   \u2514\u2500\u2500 labels/ \t#: Unzip from SemanticKITTI label data.\n        |       \u251c\u2500\u2500 000000.label\n        |       \u251c\u2500\u2500 000001.label\n        |       \u2514\u2500\u2500 ...\n        \u251c\u2500\u2500 ...\n        \u2514\u2500\u2500 21/\n\t    \u2514\u2500\u2500 ...\n```\n\n5, Instance preprocessing:\n```shell\npython instance_preprocess.py -d </your data path> -o </preprocessed file output path>\n``` \n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9503189345333785
      ],
      "excerpt": "python train.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/edwardzhou130/Panoptic-PolarNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\n\\nCopyright (c) 2020, Zixiang Zhou\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n3. Neither the name of the copyright holder nor the names of its\\n   contributors may be used to endorse or promote products derived from\\n   this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Panoptic-PolarNet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Panoptic-PolarNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "edwardzhou130",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/edwardzhou130/Panoptic-PolarNet/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 85,
      "date": "Thu, 23 Dec 2021 16:27:26 GMT"
    },
    "technique": "GitHub API"
  }
}
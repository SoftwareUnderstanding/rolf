{
  "citation": [
    {
      "confidence": [
        0.8357664768244879
      ],
      "excerpt": "Here's a quick look at Korean vs English: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8677120225785145
      ],
      "excerpt": "Hello everyone, how're you guys doing? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833774087897174
      ],
      "excerpt": "I love you I love you \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/virsagothethird/Korean-English-translator",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-24T14:32:50Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-03T20:22:02Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9862038727420315
      ],
      "excerpt": "The objective for this project was to create a Neural Machine Translator that could translate English phrases to Korean. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9844699922510554
      ],
      "excerpt": "I have lived in South Korea for the past 9 years, and when I first moved there, Google Translate was not very good at translating Korean-English and vice-versa. Having found this out after several attempts at translation, I ended up using my trusty dictionary when I encountered phrases that I did not understand, looking up each word individually. Unfortunately, this distrust of Google Translate persists today even though it has vastly improved since, and I continue to work inefficiently with the dictionary. So, in order to make my life a little easier, I decided to try and make my own translator. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9284685624935946
      ],
      "excerpt": "The first thing that you notice is that the alphabet is completely different. That's not the main issue when translating, though. One of the biggest issues is the grammar difference. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9395777041494754,
        0.8679079076500856,
        0.9600733972378818,
        0.9101815283452577,
        0.9294389034576972,
        0.837336076535681,
        0.8596299762112951
      ],
      "excerpt": "...and translate it word for word into English, we would get this: \nI started with a dataset of a little over 3000 English-Korean sentence pairs from http://www.manythings.org/anki/. I further enriched my dataset by using a custom webscraper that scraped through thousands of KPOP song lyrics and lyric translations from https://colorcodedlyrics.com/ and obtained an addictional 95,000 English-Korean sentence pairs. \nSeeing the recent rise in KPOP internationally, I reasoned that the quality of song lyric translations would have risen in proportion to it's popularity as many more record labels now release official translations to their songs. \nThis left us with a total dataset size of 98,161 sentence pairs after cleaning with an English vocabulary size of 12,251 unique words and a Korean vocabulary size of 58,663 unique words. \nLooking at the top 20 words in our English vocabulary: \nMost of these words are stop words. Not surprising as these are used in most sentences. \nIn order to make the input sentences machine readable, they must be transformed into numerical values. Using the preprocess function from our .py file, we will add <start> and <end> tokens ot each sentence, lowercase, remove punctuations, and split words that need to be split. We then use the tokenize function to transform the sentences into vectors where each number in the vector corresponds to a unique word in the vocabulary. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9595794311145279,
        0.9744966289406553
      ],
      "excerpt": "The model we will be using is a Seq2Seq model made in Tensorflow. It is a simple Encoder-Decoder model that utilizes LSTM layers. \nVery simply, the Encoder reads in the input sequences and summarizes the information as internal state vectors(hidden state and cell state). The decoder then uses these vectors as initial states and starts to generalize the output sequences. Since the Encoder outputs 2D vectors and the Decoder expects 3D arrays, the RepeatVector layer is used to ensure that the output of the Encoder is repeated a suitable number of times to match the expected shape. The TimeDistributed-wrapped Dense layer  applies each slice of the sequence from the Decoder LSTM as inputs to the Dense layer so that one word can be predicted at a time. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9647779486182069,
        0.9630847686375184,
        0.9034664494945736
      ],
      "excerpt": "We see that the loss on our training set decreases with more training but our loss on the test set increases incrementally over time. We also see that the accuracy on the training set increases while the accuracy on our test set stagnates at around 0.71.  \nThis may be telling us that instead of actually learning how to translate, it is slowly memorizing the sentence pairs. \nDespite this we can try to make some translations on our flask app: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9130233721226553
      ],
      "excerpt": "Tom is a real man \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9984195084485024
      ],
      "excerpt": "As we can see, the model is still very much in the toddler stages. There is much more room for growth. Additional hyperparameter tuning as well as going with a deeper neural network could help improve the performance of the model. More data (millions of sentence pairs) will also be a boon as these types of models tend to be very data hungry. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A Korean-English translator project using Tensorflow",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/virsagothethird/Korean-English-translator/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 15:41:22 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/virsagothethird/Korean-English-translator/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "virsagothethird/Korean-English-translator",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/virsagothethird/Korean-English-translator/master/test.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9088063058459555
      ],
      "excerpt": "I love you I love you \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8115379313325648
      ],
      "excerpt": "Here's a quick look at Korean vs English: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/virsagothethird/Korean-English-translator/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "CSS",
      "HTML"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Korean-English Translator",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Korean-English-translator",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "virsagothethird",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/virsagothethird/Korean-English-translator/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 15:41:22 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Korean follows a Subject-Object-Verb grammar structure compared to English's Subject-Verb-Object structure. Seeing as how this is a simple example, it's easy to understand what I am trying to convey with this word-for-word translation. However, as the complexity of the sentence increases, the complexity of the translation also increases accordingly as seen below:\n\n\n![grammer](https://github.com/virsagothethird/Korean-English-translator/blob/master/korean_english_grammar.jpg)\n\n\nThe use of honorifics is also highly important in Korean. Depending on who I speak to, I will adjust my speech accordingly even if I was conveying the exact same message. These intricacies can prove to be quite difficult to pick up for a machine algorithm. These are just a few of the reasons why students in Korea sometimes struggle when learning English.\n\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
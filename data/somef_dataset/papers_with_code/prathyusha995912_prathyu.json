{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this model useful for your resesarch, please use this [bibtex](http://richzhang.github.io/colorization/resources/bibtex_eccv2016_colorization.txt) to cite.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.997518055941368
      ],
      "excerpt": "Richard Zhang, Phillip Isola, Alexei A. Efros. In ECCV, 2016. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9265897817089797
      ],
      "excerpt": "<!-- model with rescaling from [Kraehenbuehl et al, ICLR 2016](https://github.com/philkr/magic_init) --> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/prathyusha995912/prathyu",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-25T05:14:02Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-25T05:17:12Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9461332936585007
      ],
      "excerpt": "This repository contains: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8145476007815446
      ],
      "excerpt": " - (3) links to our results on the ImageNet test set, along with a pointer to AMT real vs fake test code \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8682038025691607
      ],
      "excerpt": " - (5) code for training AlexNet with colorization \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8614742289222749
      ],
      "excerpt": "To run the \"real vs fake\" Amazon Mechanical Turk test (Table 1 of the paper), see this repository. See line 1 of the Usage section. Corresponding paths are: Ours (full), Ours (class, no rebal), Ours (L2), Ours (L2, ft from class), Ground Truth. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8231409617232305
      ],
      "excerpt": "(i) alexnet_release_450000_nobn_rs.caffemodel - fully convolutional model, used for ILSVRC 2012 linear readoff, PASCAL classification, and PASCAL segmentation tests \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8422072200631942
      ],
      "excerpt": "(a) Absorb batch norm, save a model into ./train_alexnet/colornet_iter_450000_nobn.caffemodel \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8674624897926836
      ],
      "excerpt": "(c) Save a model with fc6,fc7 layers into colornet_iter_450000_nobn_rs_fc.caffemodel \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/prathyusha995912/prathyu/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 01:17:31 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/prathyusha995912/prathyu/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "prathyusha995912/prathyu",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/demo/colorization_demo_v2.ipynb",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/demo/colorization_demo_v1.ipynb",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/demo/.ipynb_checkpoints/colorization_demo_v2-checkpoint.ipynb",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/demo/.ipynb_checkpoints/colorization_demo_v1-checkpoint.ipynb",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/demo/.ipynb_checkpoints/colorization_demo_v0-checkpoint.ipynb",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/demo/colorization_demo_v2.ipynb",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/demo/colorization_demo_v1.ipynb",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/demo/.ipynb_checkpoints/colorization_demo_v2-checkpoint.ipynb",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/demo/.ipynb_checkpoints/colorization_demo_v1-checkpoint.ipynb",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/demo/.ipynb_checkpoints/colorization_demo_v0-checkpoint.ipynb",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/interactive-deep-colorization/DemoGlobalHistogramTransfer.ipynb",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/interactive-deep-colorization/DemoInteractiveColorization.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/feature_learning_tests/run_classification_test_conv1.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/feature_learning_tests/run_segmentation.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/feature_learning_tests/run_classification_test_pool5.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/feature_learning_tests/run_linear_tests.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/feature_learning_tests/run_classification_test_fc7.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/splitbrainauto/resources/fetch_models.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/splitbrainauto/resources/fetch_caffe.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/train_alexnet/train_model.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/train_alexnet/postprocess_model.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/train_alexnet/run_init.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/feature_learning_tests/run_classification_test_conv1.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/feature_learning_tests/run_segmentation.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/feature_learning_tests/run_classification_test_pool5.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/feature_learning_tests/run_linear_tests.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/feature_learning_tests/run_classification_test_fc7.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/train_alexnet/train_model.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/train_alexnet/postprocess_model.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/train_alexnet/run_init.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/train/train_resume.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/train/train_model.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/train/val_model.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/train/fetch_caffe.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/train/fetch_init_model.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/models/fetch_alexnet_model.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/colorization/models/fetch_release_models.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/train/train_resume.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/train/train_model.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/train/val_model.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/train/fetch_caffe.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/train/fetch_init_model.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/models/fetch_alexnet_model.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/models/fetch_release_models.sh",
      "https://raw.githubusercontent.com/prathyusha995912/prathyu/master/interactive-deep-colorization/models/fetch_models.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9126231298509577
      ],
      "excerpt": "Clone the master branch of the respository using git clone -b master --single-branch https://github.com/richzhang/colorization.git \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8641672577415975
      ],
      "excerpt": "The provided scripts run representation learning tests. Note that the scripts run on release models. Modify scripts accordingly if you want to test your own trained model. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9376977932146837
      ],
      "excerpt": "We provide a script for colorizing a single image. Run ./models/fetch_release_models.sh to download the model. Then, run python ./colorize.py -img_in [[INPUT_IMG_PATH]] -img_out [[OUTPUT_IMG_PATH]]. For example, try python ./colorize.py -img_in ./demo/imgs/ILSVRC2012_val_00041580.JPEG -img_out ./out.png. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8143899751726085
      ],
      "excerpt": "(0) Link training and validation lmdbs to ./data/caffe-train-lmdb/ and ./data/caffe-val-lmdb/, respectively. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8265011702042381
      ],
      "excerpt": "(2) Run ./train_alexnet/train_model.sh [GPU_ID]. Training takes 2 sec/iter = 10.5 days/450k iters on a Titan X PASCAL. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8742071634723931
      ],
      "excerpt": "(b) Run ./feature_learning_tests/run_classification_test_[LAYER].sh [PATH_TO train_cls.py] [GPU_ID], where [LAYER] is {fc7,pool5,conv1}, depending on which layers you would like to fine-tune from. Results will be printed on console. The value of interest is the 10-crops on the test set. This will also generate directories ./feature_learning_tests/classification/[LAYER]. Each test takes ~30-60 minutes on a Titan X Pascal. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/prathyusha995912/prathyu/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "C++",
      "Shell",
      "Cuda"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 2-Clause \"Simplified\" License",
      "url": "https://api.github.com/licenses/bsd-2-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright \\xc2\\xa92016. The Regents of the University of California (Regents). All Rights Reserved. Permission to use, copy, modify, and distribute this software and its documentation for educational, research, not-for-profit, and commercial purposes (such rights not subject to transfer), without fee, and without a signed licensing agreement, is hereby granted, provided that the above copyright notice, this paragraph and the following two paragraphs appear in all copies, modifications, and distributions. Contact The Office of Technology Licensing, UC Berkeley, 2150 Shattuck Avenue, Suite 510, Berkeley, CA 94720-1620, (510) 643-7201, for commercial licensing opportunities.\\n\\nRichard Zhang, Jun-Yan Zhu, Phillip Isola, Xinyang Geng, Angela S. Lin, Tianhe Yu, Alexei A. Efros, University of California, Berkeley.\\n\\nIN NO EVENT SHALL REGENTS BE LIABLE TO ANY PARTY FOR DIRECT, INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, INCLUDING LOST PROFITS, ARISING OUT OF THE USE OF THIS SOFTWARE AND ITS DOCUMENTATION, EVEN IF REGENTS HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n\\nREGENTS SPECIFICALLY DISCLAIMS ANY WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE. THE SOFTWARE AND ACCOMPANYING DOCUMENTATION, IF ANY, PROVIDED HEREUNDER IS PROVIDED \"AS IS\". REGENTS HAS NO OBLIGATION TO PROVIDE MAINTENANCE, SUPPORT, UPDATES, ENHANCEMENTS, OR MODIFICATIONS.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# <b>Colorful Image Colorization</b> [[Project Page]](http://richzhang.github.io/colorization/) <br>",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "prathyu",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "prathyusha995912",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/prathyusha995912/prathyu/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This code requires a working installation of [Caffe](http://caffe.berkeleyvision.org/) and basic Python libraries (numpy, pyplot, skimage, scipy). For guidelines and help with installation of Caffe, consult the [installation guide](http://caffe.berkeleyvision.org/) and [Caffe users group](https://groups.google.com/forum/#!forum/caffe-users).\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 01:17:31 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We also include demo usage as an iPython notebook, under [`./demo/colorization_demo_v2.ipynb`](https://github.com/richzhang/colorization/blob/master/demo/colorization_demo_v2.ipynb). This IPython Notebook demonstrates how to use our colorization network to colorize a grayscale image. To run this, after cloning the directory, `cd` into the `demo` directory, run `ipython notebook` and open `colorization_demo_v2.ipynb` in your web browser.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "The following contains instructions for training a colorization network from scratch. After cloning the repository, from the root directory:\n\n(1) Run `./train/fetch_init_model.sh`. This will load model `./models/init_v2.caffemodel`. This model was obtained using the k-means initialization implemented in [Kraehenbuehl et al, ICLR 2016](https://github.com/philkr/magic_init).\n\n(2) Run `./train/fetch_caffe.sh`. This will load a modified Caffe into directory `./caffe-colorization`. For guidelines and help with installation of Caffe, consult the [installation guide](http://caffe.berkeleyvision.org/) and [Caffe users group](https://groups.google.com/forum/#!forum/caffe-users).\n\n(3) Add the `./resources/` directory (as an absolute path) to your system environment variable $PYTHONPATH. This directory contains custom Python layers.\n\n(4) Modify paths in data layers `./models/colorization_train_val_v2.prototxt` to locate where ImageNet LMDB files are on your machine. These should be BGR images, non-mean centered, in [0,255].\n\n(5) Run `./train/train_model.sh [GPU_ID]`, where `[GPU_ID]` is the gpu you choose to specify. Notes about training:\n\n(a) Training completes around 450k iterations. Training is done on mirrored and randomly cropped 176x176 resolution images, with mini-batch size 40.\n\n(b) Snapshots every 1000 iterations will be saved in `./train/models/colornet_iter_[ITERNUMBER].caffemodel` and `./train/models/colornet_iter_[ITERNUMBER].solverstate`.\n\n(c) If training is interupted, resume training by running `./train/train_resume.sh ./train/models/colornet_iter_[ITERNUMBER].solverstate [GPU_ID]`, where `[ITERNUMBER]` is the last snapshotted model.\n\n(d) Check validation loss by running `./val_model.sh ./train/models/colornet_iter_[ITERNUMBER].caffemodel [GPU_ID] 1000`, where [ITERNUMBER] is the model you would like to validate. This runs the first 10k imagenet validation images at full 256x256 resolution through the model. Validation loss on `colorization_release_v2.caffemodel` is 7715.\n\n(e) Check model outputs by running the IPython notebook demo. Replace the release model with your snapshotted model.\n\n(f) To download reference pre-trained model, run `./models/fetch_release_models.sh`. This will load reference model `./models/colorization_release_v2.caffemodel`. This model used to generate results in the [ECCV 2016 camera ready](arxiv.org/pdf/1603.08511.pdf).\n\nFor completeness, this will also load model `./models/colorization_release_v2_norebal.caffemodel`, which is was trained without class rebalancing. This model will provide duller but \"safer\" colorizations. This will also load model `./models/colorization_release_v1.caffemodel`, which was used to generate the results in the [arXiv v1](arxiv.org/pdf/1603.08511v1.pdf) paper.\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Our work and implementations are inspired by and based on\nZSSR [[site](https://github.com/assafshocher/ZSSR)] and MAML [[site](https://github.com/cbfinn/maml)].\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2002.12213",
      "https://arxiv.org/abs/1703.03400\">Link</a>\n\n#### [MAML++ (ICLR 2019",
      "https://arxiv.org/abs/1810.09502\">Link</a>\n<br><br>\n\n## Brief Description of Our Proposed Method\n\n### <u>Illustration of the Overall Scheme</u>\n\n<p align=\"center\"><img src=\"figure/Overall.png\" width=\"700\"></p>\n\nDuring meta-transfer learning, the external dataset is used, where internal learning is done during meta-test time.\nFrom random initial \\theta_0, large-scale dataset DIV2K with \u201cbicubic\u201d degradation is exploited to obtain \\theta_T.\nThen, meta-transfer learning learns a good representation \\theta_M for super-resolution tasks with diverse blur kernel scenarios.\nIn the meta-test phase, self-supervision within a test image is exploited to train the model with corresponding blur kernel.\n\n### <u> Algorithms </u>\n\n<p align=\"center\"><img src=\"figure/meta-training.png\" width=\"400\">&nbsp;&nbsp;<img src=\"figure/meta-test.png\" width=\"400\"></p> \n\nLeft: The algorithm of Meta-Transfer Learning & Right: The algorithm of Meta-Test.\n\n## Experimental Results\n\n**Results on various kernel environments (X2",
      "https://arxiv.org/abs/2002.12213"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@article{soh2020meta,\n  title={Meta-Transfer Learning for Zero-Shot Super-Resolution},\n  author={Soh, Jae Woong and Cho, Sunwoo and Cho, Nam Ik},\n  journal={arXiv preprint arXiv:2002.12213},\n  year={2020}\n}\n\n@inproceedings{soh2020meta,\n  title={Meta-Transfer Learning for Zero-Shot Super-Resolution},\n  author={Soh, Jae Woong and Cho, Sunwoo and Cho, Nam Ik},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={3516--3525},\n  year={2020}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{soh2020meta,\n  title={Meta-Transfer Learning for Zero-Shot Super-Resolution},\n  author={Soh, Jae Woong and Cho, Sunwoo and Cho, Nam Ik},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n  pages={3516--3525},\n  year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{soh2020meta,\n  title={Meta-Transfer Learning for Zero-Shot Super-Resolution},\n  author={Soh, Jae Woong and Cho, Sunwoo and Cho, Nam Ik},\n  journal={arXiv preprint arXiv:2002.12213},\n  year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9792428879788975
      ],
      "excerpt": "[Paper] [Supplementary] [Arxiv] \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JWSoh/MZSR",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-27T12:35:49Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-27T05:07:02Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "Jae Woong Soh, Sunwoo Cho, and Nam Ik Cho \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9946755188905242
      ],
      "excerpt": "Convolutional neural networks (CNNs) have shown dramatic improvements in single image super-resolution (SISR) by using large-scale external samples. Despite their remarkable performance based on the external dataset, they cannot exploit internal information within a specific image. Another problem is that they are applicable only to the specific condition of data that they are supervised. For instance, the low-resolution (LR) image should be a \"bicubic\" downsampled noise-free image from a high-resolution (HR) one. To address both issues, zero-shot super-resolution (ZSSR) has been proposed for flexible internal learning. However, they require thousands of gradient updates, i.e., long inference time. In this paper, we present Meta-Transfer Learning for Zero-Shot Super-Resolution (MZSR), which leverages ZSSR. Precisely, it is based on finding a generic initial parameter that is suitable for internal learning. Thus, we can exploit both external and internal information, where one single gradient update can yield quite considerable results. (See Figure 1). With our method, the network can quickly adapt to a given image condition. In this respect, our method can be applied to a large spectrum of image conditions within a fast adaptation process. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8627544695522166,
        0.8086445045630426,
        0.811717531832822
      ],
      "excerpt": "During meta-transfer learning, the external dataset is used, where internal learning is done during meta-test time. \nFrom random initial \\theta_0, large-scale dataset DIV2K with \u201cbicubic\u201d degradation is exploited to obtain \\theta_T. \nThen, meta-transfer learning learns a good representation \\theta_M for super-resolution tasks with diverse blur kernel scenarios. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9274631028721178
      ],
      "excerpt": "Left: The algorithm of Meta-Transfer Learning & Right: The algorithm of Meta-Test. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9596155191698945
      ],
      "excerpt": "The results are evaluated with the average PSNR (dB) and SSIM on Y channel of YCbCr colorspace. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9085559439765266
      ],
      "excerpt": "The number between parantheses of our methods (MZSR) denote the number of gradient updates. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9302189676473481
      ],
      "excerpt": "    \u251c\u2500\u2500> Directx2: Model for direct subsampling (x2) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.959961309707981,
        0.9302189676473481
      ],
      "excerpt": "    \u251c\u2500\u2500> Bicubicx2: Model for bicubic subsampling (x2) \n    \u2514\u2500\u2500> Directx4: Model for direct subsampling (x4) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9585281593823137
      ],
      "excerpt": "Rest codes are for the training and test of MZSR. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "--model: [0/1/2/3] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8097227030838984
      ],
      "excerpt": "self.back_projection_iters=4    -&gt; The number of iteration of back projection. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Meta-Transfer Learning for Zero-Shot Super-Resolution (CVPR, 2020)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JWSoh/MZSR/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 49,
      "date": "Tue, 28 Dec 2021 23:05:17 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/JWSoh/MZSR/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "JWSoh/MZSR",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8766834277946227,
        0.8837680365796365
      ],
      "excerpt": "CUDA 9.0 & cuDNN 7.1 \nPython 3.6 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8831710754724212,
        0.8817415589474913,
        0.9749760586879868,
        0.9906248903846466
      ],
      "excerpt": "Requisites should be installed beforehand. \nClone this repo. \ngit clone http://github.com/JWSoh/MZSR.git \ncd MZSR/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9665738914070579
      ],
      "excerpt": "--gpu: If you have more than one gpu in your computer, the number denotes the index. [Default 0] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9422523842794897
      ],
      "excerpt": "--gpu: If you have more than one gpu in your computer, the number designates the index of GPU which is going to be used. [Default 0] \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8570996349810562
      ],
      "excerpt": "<p align=\"center\"><img src=\"figure/Overall.png\" width=\"700\"></p> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8409496139258309,
        0.9375361256333797
      ],
      "excerpt": "In the meta-test phase, self-supervision within a test image is exploited to train the model with corresponding blur kernel. \n<p align=\"center\"><img src=\"figure/meta-training.png\" width=\"400\">&nbsp;&nbsp;<img src=\"figure/meta-test.png\" width=\"400\"></p> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8902640802448034
      ],
      "excerpt": "<p align=\"center\"><img src=\"figure/result.png\" width=\"900\"></p> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8570996349810562,
        0.8938733397535918
      ],
      "excerpt": "<p align=\"center\"><img src=\"figure/resultx4.png\" width=\"900\"></p> \nTest Input Data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8570996349810562
      ],
      "excerpt": "<p align=\"center\"><img src=\"figure/001.png\" width=\"900\"></p> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8570996349810562
      ],
      "excerpt": "<p align=\"center\"><img src=\"figure/002.png\" width=\"900\"></p> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8945299842756211
      ],
      "excerpt": "Download training dataset DIV2K. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9364541555520881
      ],
      "excerpt": "Run generate_TFRecord_MZSR.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8347962528630702,
        0.8337986789805648
      ],
      "excerpt": "python main.py --train --gpu [GPU_number] --trial [Trial of your training] --step [Global step] \n--train: Flag in order to train. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8896129168674903
      ],
      "excerpt": "python main.py --gpu [GPU_number] --inputpath [LR path] --gtpath [HR path] --savepath [SR path]  --kernelpath [kernel.mat path] --model [0/1/2/3] --num [1/10] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8270028728373986
      ],
      "excerpt": "--inputpath: Path of input images [Default: Input/g20/Set5/] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8670388741062687,
        0.8286616399588728
      ],
      "excerpt": "--savepath: Path for the output images. [Default: results/Set5] \n--kernelpath: Path of the kernel.mat file. [Default: Input/g20/kernel.mat] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8171731114234013,
        0.836692866555205
      ],
      "excerpt": "You may change other minor options in \"test.py.\" \nLine 9 to line 17. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/JWSoh/MZSR/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "MZSR",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "MZSR",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "JWSoh",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JWSoh/MZSR/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 223,
      "date": "Tue, 28 Dec 2021 23:05:17 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "super-resolution",
      "meta-transfer-learning",
      "meta-learning",
      "zero-shot"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npython main.py --gpu 0 --inputpath Input/g20/Set5/ --gtpath GT/Set5/ --savepath results/Set5 --kernelpath Input/g20/kernel.mat --model 0 --num 1\n```\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1810.04805",
      "https://arxiv.org/abs/1810.04805 (2018).](https://arxiv.org/abs/1810.04805)\n\nRadford A, Narasimhan K, Salimans T, et al. Improving language understanding by generative pre-training[J]. URL https://s3-us-west-2. amazonaws. com/openai-assets/researchcovers/languageunsupervised/language understanding paper. pdf, 2018."
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Devlin, Jacob, et al. \"Bert: Pre-training of deep bidirectional transformers for language understanding.\" arXiv preprint [arXiv:1810.04805 (2018).](https://arxiv.org/abs/1810.04805)\n\nRadford A, Narasimhan K, Salimans T, et al. Improving language understanding by generative pre-training[J]. URL https://s3-us-west-2. amazonaws. com/openai-assets/researchcovers/languageunsupervised/language understanding paper. pdf, 2018.\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Jun-Zhang-32108/Sentiment-Analysis",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-12-06T22:13:03Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-22T13:21:09Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9221395234496961
      ],
      "excerpt": "This repository is organized as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8597051420189507
      ],
      "excerpt": "model - pretrained models used for feature extraction and prediction \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Oscar Detector with Sentiment Analysis ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Jun-Zhang-32108/Sentiment-Analysis/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 20:28:15 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Jun-Zhang-32108/Sentiment-Analysis/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Jun-Zhang-32108/Sentiment-Analysis",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Jun-Zhang-32108/Sentiment-Analysis/master/jupyter_notebook/SenAnalysis_Transformer.ipynb",
      "https://raw.githubusercontent.com/Jun-Zhang-32108/Sentiment-Analysis/master/jupyter_notebook/Sentiment_Analysis_with_subwordTextEncoder_MLP.ipynb",
      "https://raw.githubusercontent.com/Jun-Zhang-32108/Sentiment-Analysis/master/jupyter_notebook/SenAnalysis-Test.ipynb",
      "https://raw.githubusercontent.com/Jun-Zhang-32108/Sentiment-Analysis/master/jupyter_notebook/SenAnalysis.ipynb",
      "https://raw.githubusercontent.com/Jun-Zhang-32108/Sentiment-Analysis/master/jupyter_notebook/SenAnalysis_fasttext.ipynb",
      "https://raw.githubusercontent.com/Jun-Zhang-32108/Sentiment-Analysis/master/jupyter_notebook/BERT/SenAnalysi_BERT.ipynb",
      "https://raw.githubusercontent.com/Jun-Zhang-32108/Sentiment-Analysis/master/jupyter_notebook/.ipynb_checkpoints/SenAnalysis-checkpoint.ipynb",
      "https://raw.githubusercontent.com/Jun-Zhang-32108/Sentiment-Analysis/master/jupyter_notebook/.ipynb_checkpoints/SenAnalysis-Test-checkpoint.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9376310464895884
      ],
      "excerpt": "env virtual environment \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.817785968632017
      ],
      "excerpt": "app.py main application \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633989807152664
      ],
      "excerpt": "test.db SQLAlchemy database \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Jun-Zhang-32108/Sentiment-Analysis/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "HTML",
      "CSS",
      "M"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'This is the MIT license: http://www.opensource.org/licenses/mit-license.php\\n\\nCopyright (c) 2005-2019 the SQLAlchemy authors and contributors <see AUTHORS file>.\\nSQLAlchemy is a trademark of Michael Bayer.\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this\\nsoftware and associated documentation files (the \"Software\"), to deal in the Software\\nwithout restriction, including without limitation the rights to use, copy, modify, merge,\\npublish, distribute, sublicense, and/or sell copies of the Software, and to permit persons\\nto whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or\\nsubstantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,\\nINCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR\\nPURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE\\nFOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\\nDEALINGS IN THE SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Oscar Detector with Sentiment Analysis",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Sentiment-Analysis",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Jun-Zhang-32108",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Jun-Zhang-32108/Sentiment-Analysis/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Sat, 25 Dec 2021 20:28:15 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "In this project, I proposed a new way to detect the Oscar winners with sentiment analysis. We collect the reviews toward one movie of all the judges and apply sentiment analysis on the movie reviews. The result is regarded as evidence that if the judges are going to vote for that moview. We collect the voting and outputs the most possible winner. The presentation of the project can be found [here](https://docs.google.com/presentation/d/1mENl24uh39z9Ett99aFVKVXii-qRruEmsRaLOm6jhvk/edit?usp=sharing).\n\nCurrently the part of sentiment analysis is implemented as a RESTful API with **Flask** and hosted in Azure server. Now the simple website support three different models (more models are explored and can be checked in the *jupyter_notebook* folder): trigram+SVM , a [BERT](https://github.com/google-research/bert) based model which is fine-tuned on the movie review data and a [GPT-style](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) transformer with fine-tuning. The trigram + SVM scores around 90% ACC and F1 but performs just so so on the short reviews and not well on the negation while the BERT based model scores mores than 93% on ACC and F1 and performs quite well on the short especially emotional reviews. The GPT-style transformer model scores 92% on ACC and F1. The later two models both perform quite well on the ambiguous cases but BERT-based model is slightly better. A test example for BERT-based model and GPT-style Transformer can be seen from Figure 1 and Figure 2. A reasonable idea behind this is that word-embedding models like BERT can capture the deep contextual meaning of each words within each sentences while n-gram models fail to do that.  \n\n\n\n<figure class=\"half\">\n    <h3> Figure 1 </h3>\n    <img src=\"https://github.com/Jun-Zhang-32108/Sentiment-Analysis/blob/master/IMG/Fig1.png\" width=\"400\" title=\"Figure1\"/>\n    <h3> Figure 2 </h3>\n    <img src=\"https://github.com/Jun-Zhang-32108/Sentiment-Analysis/blob/master/IMG/Fig2.png\" width=\"400\" title=\"FIgure2\"/>   \n</figure>\n\n\n\n\nTo run the program with trigram + SVM model:\n\n        python3 app.py\n\nTo run the program with BERT model:\n\n        python3 app.py -model bert -modelPath #where you store bert model#\n\nTo run the program with GPT-style Transformer model:\n\n        python3 app.py -model transformer -modelPath #where you store transformer model#\n\nA ready-to-used model trained by me with BERT base uncased on movie review data can be found [here](https://drive.google.com/drive/folders/1Fb-bwNUewYckwTQVu3A0pwkAK2znVex8?usp=sharing).\n\nFine-tuned transformer model on IMDB dataset can be found [here](https://drive.google.com/open?id=1nRKgnsazET0N5TpTPHXLerNQNvkk-hdH)\n\nTo install the dependencies:\n\n        pip3 install -r requirements.txt\n\nA live [demo](http://52.156.250.103:5000/) you can try out [here](http://52.156.250.103:5000/).\n\n",
      "technique": "Header extraction"
    }
  ],
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "nlp-machine-learning",
      "sentiment-analysis",
      "movie-review"
    ],
    "technique": "GitHub API"
  }
}
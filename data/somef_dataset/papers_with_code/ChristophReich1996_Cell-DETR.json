{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2011.09763",
      "https://arxiv.org/abs/1907.06732",
      "https://arxiv.org/abs/1904.05373",
      "https://arxiv.org/abs/2005.12872",
      "https://arxiv.org/abs/1907.06732"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bibtex\n[1] @article{carion2020end,\n        title={End-to-End Object Detection with Transformers},\n        author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},\n        journal={arXiv preprint arXiv:2005.12872},\n        year={2020}\n}\n```\n\n```bibtex\n[2] @inproceedings{zhu2019deformable,\n        title={Deformable convnets v2: More deformable, better results},\n        author={Zhu, Xizhou and Hu, Han and Lin, Stephen and Dai, Jifeng},\n        booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n        pages={9308--9316},\n        year={2019}\n}\n```\n\n```bibtex\n[3] @inproceedings{su2019pixel,\n        title={Pixel-adaptive convolutional neural networks},\n        author={Su, Hang and Jampani, Varun and Sun, Deqing and Gallo, Orazio and Learned-Miller, Erik and Kautz, Jan},\n        booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n        pages={11166--11175},\n        year={2019}\n}\n```\n\n```bibtex\n[4] @article{molina2019pad,\n        title={Pad$\\backslash$'e Activation Units: End-to-end Learning of Flexible Activation Functions in Deep Networks},\n        author={Molina, Alejandro and Schramowski, Patrick and Kersting, Kristian},\n        journal={arXiv preprint arXiv:1907.06732},\n        year={2019}\n}\n```\n\n```bibtex\n[5] @inproceedings{vaswani2017attention,\n        title={Attention is all you need},\n        author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\\L}ukasz and Polosukhin, Illia},\n        booktitle={Advances in neural information processing systems},\n        pages={5998--6008},\n        year={2017}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this research useful in your work, please acknowledge it appropriately and cite the paper:\n```bibtex\n@article{prangemeier2020c,\n        title={Attention-Based Transformers for Instance Segmentation of Cells in Microstructures},\n        author={Prangemeier, Tim and Reich, Christoph and Koeppl, Heinz},\n        booktitle={2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},\n        year={2020}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "cff-version: 1.2.0\nmessage: \"Code of the paper: Attention-Based Transformers for Instance Segmentation of Cells in Microstructures\"\nauthors:\n  - family-names: Prangemeier\n    given-names: Tim\n  - family-names: Reich\n    given-names: Christoph\n  - family-names: Koeppl\n    given-names: Heinz\ntitle: \"Attention-Based Transformers for Instance Segmentation of Cells in Microstructures\"\nversion: 1.0.0\ndoi: 10.1109/BIBM49941.2020.9313305\ndate-released: 2020-10-19",
      "technique": "File Exploration"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{vaswani2017attention,\n        title={Attention is all you need},\n        author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\\L}ukasz and Polosukhin, Illia},\n        booktitle={Advances in neural information processing systems},\n        pages={5998--6008},\n        year={2017}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{molina2019pad,\n        title={Pad$\\backslash$'e Activation Units: End-to-end Learning of Flexible Activation Functions in Deep Networks},\n        author={Molina, Alejandro and Schramowski, Patrick and Kersting, Kristian},\n        journal={arXiv preprint arXiv:1907.06732},\n        year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{su2019pixel,\n        title={Pixel-adaptive convolutional neural networks},\n        author={Su, Hang and Jampani, Varun and Sun, Deqing and Gallo, Orazio and Learned-Miller, Erik and Kautz, Jan},\n        booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n        pages={11166--11175},\n        year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{zhu2019deformable,\n        title={Deformable convnets v2: More deformable, better results},\n        author={Zhu, Xizhou and Hu, Han and Lin, Stephen and Dai, Jifeng},\n        booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n        pages={9308--9316},\n        year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{carion2020end,\n        title={End-to-End Object Detection with Transformers},\n        author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},\n        journal={arXiv preprint arXiv:2005.12872},\n        year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{prangemeier2020c,\n        title={Attention-Based Transformers for Instance Segmentation of Cells in Microstructures},\n        author={Prangemeier, Tim and Reich, Christoph and Koeppl, Heinz},\n        booktitle={2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},\n        year={2020}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ChristophReich1996/Cell-DETR",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-05T16:29:50Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-13T15:31:25Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9665164011049941,
        0.9046997220824364
      ],
      "excerpt": "Attention-based transformers are state-of-the-art in a range of deep learning fields. They have recently been proposed  \nfor segmentation tasks where they are beginning to outperforming other  methods. We present a novel attention-based  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.991472689418433,
        0.8953189221812493,
        0.9690020768880935
      ],
      "excerpt": "is on par with a state-of-the-art instance segmentation method, Cell-DETR is simpler and faster. We showcase the  \nmethod's contribution in a the typical use case of segmenting yeast in microstructured environments, commonly employed  \nin systems or synthetic biology. For the specific use case, the proposed method surpasses the state-of-the-art tools  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8728734540864692,
        0.8457969012528221,
        0.8445977184142837,
        0.8619320367082086,
        0.9773957001264081,
        0.9889586718294426,
        0.9690027446820935
      ],
      "excerpt": "segmentation performance increases the experimental information yield for a posteriori data processing and  \nmakes online monitoring of experiments and closed-loop optimal experimental design feasible. \n<br/>Architecture of the end-to-end instance segmentation network, with brightfield specimen image input and an instance segmentation prediction as output. \nThe backbone CNN encoder extracts image features that then feed into both the transformer encoder-decoder for class and bounding box prediction, as well \nas to the CNN decoder for segmentation. The transformer encoded features, as well as the transformer decoded features, are feed into a multi-head-attention \nmodule and together with the image features from the CNN backbone feed into the CNN decoder for segmentation. Skip connections additionally bridge \nbetween the backbone CNN encoder and the CNN decoder. Input and output resolution is 128 \u00d7 128 pixels. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9710839016066596,
        0.8167565677509646
      ],
      "excerpt": "<br/>Example segmentations of our Cell-DETR B model. \n| Model | Dice | Accuracy | mIoU (mean over instances) | Cell IoU | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "| Model | MSE | L1 | IoU | gIoU | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8169815468012596
      ],
      "excerpt": "| Model | Accuracy | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Official and maintained implementation of the paper \"Attention-Based Transformers for Instance Segmentation of Cells in Microstructures\" [BIBM 2020].",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ChristophReich1996/Cell-DETR/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 17,
      "date": "Thu, 23 Dec 2021 16:24:30 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ChristophReich1996/Cell-DETR/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ChristophReich1996/Cell-DETR",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ChristophReich1996/Cell-DETR/master/pade_activation_unit/find_coefficients.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8700233219982035,
        0.956999482560778,
        0.8700233219982035,
        0.956999482560778,
        0.8449396372800111
      ],
      "excerpt": "To load and test the trained Cell-DETR A model run \npython main.py --test --path_to_data \"trapped_yeast_cell_dataset\" --cuda_devices \"0\" --softmax --no_pac --no_deform_conv --no_pau --load_model \"trained_models/Cell_DETR_A\" \nto load and test the trained Cell-DETR B model run \npython main.py --test --path_to_data \"trapped_yeast_cell_dataset\" --cuda_devices \"0\" --softmax --load_model \"trained_models/Cell_DETR_B\" \nA few toy/test examples of the trapped yeast cell instance segmentation dataset are included in folder trapped_yeast_cell_dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9042534665813847
      ],
      "excerpt": "<img src=\"images/test_plot_1_is.png\" alt=\"drawing\" width=\"350\"/><img src=\"images/test_plot_4_is.png\" alt=\"drawing\" width=\"350\"/> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ChristophReich1996/Cell-DETR/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cuda",
      "Jupyter Notebook",
      "C++"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Christoph Reich & Tim Prangemeier (Bioinspired Communication Systems Lab, TU Darmstadt)\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Cell-DETR: Attention-Based Transformers for Instance Segmentation of Cells in Microstructures",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Cell-DETR",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ChristophReich1996",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ChristophReich1996/Cell-DETR/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The Cell-DETR implementation uses multiple existing implementations. First, deformable convolutions v2 [2] are used based\non the [implementation](https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch/tree/pytorch_1.0.0) of \n[Dazhi Cheng](https://github.com/chengdazhi). Second, [pade activation units](https://arxiv.org/abs/1907.06732) [4] \nare utilized base on the [official implementation](https://github.com/ml-research/pau), by the authors. And third, the \n[pixel adaptive convolutions](https://arxiv.org/abs/1904.05373) [3] [implementation](https://github.com/NVlabs/pacnet) by \n[Nvidia](https://github.com/NVlabs) is used. The pade activation unit implementation as well as the pixel adaptive \nconvolution implementation are adopted slightly and are included in this repository. All dependencies can be installed\nby executing the following commands:\n\n```shell script\ngit clone https://github.com/ChristophReich1996/Cell-DETR.git\ncd Cell-DETR\npip install -r requirements.txt\ngit clone https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch\ncd Deformable-Convolution-V2-PyTorch\ngit checkout pytorch_1.0.0\npython setup.py build install\ncd ../pade_activation_unit/cuda\npython setup.py build install\n```\n\nThe transformer [5] implementation is based on the \n[official implementation of DETR](https://github.com/facebookresearch/detr) [1].\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 49,
      "date": "Thu, 23 Dec 2021 16:24:30 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "bibm-2020",
      "deep-learning",
      "attention",
      "instance-segmentation",
      "cell-segmentation",
      "synthetic-biology",
      "cell-detr",
      "transformer",
      "system-biology"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[![arXiv](https://img.shields.io/badge/cs.CV-arXiv%3A2011.09763-B31B1B.svg)](https://arxiv.org/abs/2011.09763)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://github.com/ChristophReich1996/Cell-DETR/blob/master/LICENSE)\n\n**[Tim Prangemeier](https://www.bcs.tu-darmstadt.de/bcs_team/prangemeiertim.en.jsp), [Christoph Reich](https://github.com/ChristophReich1996) & [Heinz Koeppl](https://www.bcs.tu-darmstadt.de/bcs_team/koepplheinz.en.jsp)**\n\nThis repository includes the **official** and **maintained** implementation of the paper \n**[Attention-Based Transformers for Instance Segmentation of Cells in Microstructures](https://www.bcs.tu-darmstadt.de/media/bcs/research_4/documents/Prangemeier2020c_BIBM_cell-detr_accepted.pdf)** [(BIBM 2020)](https://ieeebibm.org/BIBM2020/).\n\n<img src=\"images/test_plot_1_is.png\" alt=\"drawing\" width=\"150\"/><img src=\"images/test_plot_4_is.png\" alt=\"drawing\" width=\"150\"/><img src=\"images/test_plot_12_is.png\" alt=\"drawing\" width=\"150\"/><img src=\"images/test_plot_29_is.png\" alt=\"drawing\" width=\"150\"/><img src=\"images/test_plot_31_is.png\" alt=\"drawing\" width=\"150\"/>\n<br/>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "CELL-DETR can be trained, validated and testes by using the `main.py` script. The following command line arguments\ndefine what actions are performed.\n\n```\npython main.py {+ args}\n```\n\n|Argument | Default value | Info|\n|--- | --- | ---|\n|`--train` | False | Binary flag. If set training will be performed.|\n|`--val` | False | Binary flag. If set validation will be performed.|\n|`--test` | False | Binary flag. If set testing will be performed.|\n|`--cuda_devices` | \"0\" | String of cuda device indexes to be used. Indexes must be separated by a comma|\n|`--data_parallel` | False | Binary flag. If multi GPU training should be utilized set flag.|\n|`--cpu` | False | Binary flag. If set all operations are performed on the CPU.|\n|`--epochs` | 200 | Number of epochs to perform while training.|\n|`--lr_schedule` | False | Binary flag. If set the learning rate will be reduced after epoch 50 and 100.|\n|`--ohem` | False | Binary flag. If set online heard example mining is utilized.|\n|`--ohem_fraction` | 0.75 | Ohem fraction to be applied when performing ohem.|\n|`--batch_size` | 4 | Batch size to be utilized while training.|\n|`--path_to_data` | \"trapped_yeast_cell_dataset\" | Path to dataset.|\n|`--augmentation_p` | 0.6 | Probability that data augmentation is applied on training data sample.|\n|`--lr_main` | 1e-04 | Learning rate of the detr model (excluding backbone).|\n|`--lr_backbone` | 1e-05 | Learning rate of the backbone network.|\n|`--no_pac` | False | Binary flag. If set no pixel adaptive convolutions will be utilized in the segmentation head.|\n|`--load_model` | \"\" | Path to model to be loaded.|\n|`--dropout` | 0.0 | Dropout factor to be used in model.|\n|`--three_classes` | False | Binary flag, If set three classes (trap, cell of interest and add. cells) will be utilized.|\n|`--softmax` | False | Binary flag, If set a softmax will be applied to the segmentation prediction instead sigmoid.|\n|`--only_train_segmentation_head_after_epoch` | 200 | Number of epoch where only the segmentation head is trained.|\n|`--lr_segmentation_head` | 1e-05 | Learning rate of the segmentation head, only applied when seg head is trained exclusively.|\n|`--no_deform_conv` | False | Binary flag. If set no deformable convolutions will be utilized.|\n|`--no_pau` | False | Binary flag. If set no pade activation unit is utilized, however, a leaky ReLU is utilized.\n\nFor training, validating and testing of the Cell-DETR B architecture run \n\n```\npython main.py --train --val --test --path_to_data \"trapped_yeast_cell_dataset\" --lr_schedule --batch_size 10 --data_parallel --cuda_devices \"0, 1\" --softmax\n```\n\nFor training, validating and testing of the Cell-DETR A architecture run\n\n```\npython main.py --train --val --test --path_to_data \"trapped_yeast_cell_dataset\" --lr_schedule --batch_size 10 --data_parallel --cuda_devices \"0, 1\" --softmax --no_pac --no_deform_conv --no_pau\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Our code is inspired by [TDAN-VSR](https://github.com/YapengTian/TDAN-VSR) and [EDVR](https://github.com/xinntao/EDVR).\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2002.11616",
      "https://arxiv.org/abs/2104.07473",
      "https://arxiv.org/abs/2002.11616",
      "https://arxiv.org/abs/1811.11168"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find the code helpful in your resarch or work, please cite the following papers.\n\n```BibTex\n@misc{xiang2021zooming,\n  title={Zooming SlowMo: An Efficient One-Stage Framework for Space-Time Video Super-Resolution},\n  author={Xiang, Xiaoyu and Tian, Yapeng and Zhang, Yulun and Fu, Yun and Allebach, Jan P and Xu, Chenliang},\n  archivePrefix={arXiv},\n  eprint={2104.07473},\n  year={2021},\n  primaryClass={cs.CV}\n}\n\n@InProceedings{xiang2020zooming,\n  author = {Xiang, Xiaoyu and Tian, Yapeng and Zhang, Yulun and Fu, Yun and Allebach, Jan P. and Xu, Chenliang},\n  title = {Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution},\n  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n  pages={3370--3379},\n  month = {June},\n  year = {2020}\n}\n\n@InProceedings{tian2018tdan,\n  author={Yapeng Tian, Yulun Zhang, Yun Fu, and Chenliang Xu},\n  title={TDAN: Temporally Deformable Alignment Network for Video Super-Resolution},\n  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n  pages={3360--3369},\n  month = {June},\n  year = {2020}\n}\n\n@InProceedings{wang2019edvr,\n  author    = {Wang, Xintao and Chan, Kelvin C.K. and Yu, Ke and Dong, Chao and Loy, Chen Change},\n  title     = {EDVR: Video restoration with enhanced deformable convolutional networks},\n  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},\n  month     = {June},\n  year      = {2019},\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@InProceedings{wang2019edvr,\n  author    = {Wang, Xintao and Chan, Kelvin C.K. and Yu, Ke and Dong, Chao and Loy, Chen Change},\n  title     = {EDVR: Video restoration with enhanced deformable convolutional networks},\n  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},\n  month     = {June},\n  year      = {2019},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@InProceedings{tian2018tdan,\n  author={Yapeng Tian, Yulun Zhang, Yun Fu, and Chenliang Xu},\n  title={TDAN: Temporally Deformable Alignment Network for Video Super-Resolution},\n  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n  pages={3360--3369},\n  month = {June},\n  year = {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@InProceedings{xiang2020zooming,\n  author = {Xiang, Xiaoyu and Tian, Yapeng and Zhang, Yulun and Fu, Yun and Allebach, Jan P. and Xu, Chenliang},\n  title = {Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution},\n  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n  pages={3370--3379},\n  month = {June},\n  year = {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{xiang2021zooming,\n  title={Zooming SlowMo: An Efficient One-Stage Framework for Space-Time Video Super-Resolution},\n  author={Xiang, Xiaoyu and Tian, Yapeng and Zhang, Yulun and Fu, Yun and Allebach, Jan P and Xu, Chenliang},\n  archivePrefix={arXiv},\n  eprint={2104.07473},\n  year={2021},\n  primaryClass={cs.CV}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9998463376106781
      ],
      "excerpt": "By Xiaoyu Xiang<sup>*</sup>, Yapeng Tian<sup>*</sup>, Yulun Zhang, Yun Fu, Jan P. Allebach<sup>+</sup>, Chenliang Xu<sup>+</sup> (<sup>*</sup> equal contributions, <sup>+</sup> equal advising) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[Xiaoyu Xiang](https://engineering.purdue.edu/people/xiaoyu.xiang.1) and [Yapeng Tian](http://yapengtian.org/).\n\nYou can also leave your questions as issues in the repository. We will be glad to answer them.\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-25T04:13:58Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-27T17:27:34Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The repository contains the entire project (including all the preprocessing) for one-stage space-time video super-resolution with Zooming Slow-Mo.\n\nZooming Slow-Mo is a recently proposed joint video frame interpolation (VFI) and video super-resolution (VSR) method, which directly synthesizes an HR slow-motion video from an LFR, LR video. It is going to be published in [CVPR 2020](http://cvpr2020.thecvf.com/). The most up-to-date paper with supplementary materials can be found at [arXiv](https://arxiv.org/abs/2002.11616).\n\nIn Zooming Slow-Mo, we firstly temporally interpolate features of the missing LR frame by the proposed feature temporal interpolation network. Then, we propose a deformable ConvLSTM to align and aggregate temporal information simultaneously. Finally, a deep reconstruction network is adopted to predict HR slow-motion video frames. If our proposed architectures also help your research, please consider citing our paper.\n\nZooming Slow-Mo achieves state-of-the-art performance by PSNR and SSIM in Vid4, Vimeo test sets.\n\n![framework](./dump/framework.png)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9568257796515388,
        0.9529582978661221
      ],
      "excerpt": "This is the official Pytorch implementation of Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution. \n2020.3.13 Add meta-info of datasets used in this paper \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8009564571557558
      ],
      "excerpt": "Our pretrained model can be downloaded via GitHub or Google Drive. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Fast and Accurate One-Stage Space-Time Video Super-Resolution (accepted in CVPR 2020)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 133,
      "date": "Tue, 28 Dec 2021 07:10:15 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Mukosame/Zooming-Slow-Mo-CVPR-2020/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Mukosame/Zooming-Slow-Mo-CVPR-2020",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Mukosame/Zooming-Slow-Mo-CVPR-2020/master/codes/zsm_my_video.sh",
      "https://raw.githubusercontent.com/Mukosame/Zooming-Slow-Mo-CVPR-2020/master/codes/models/modules/DCNv2/make.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The [test.py](codes/test.py) script also provides modes for evaluation on the following test sets: `Vid4`, `SPMC`, etc. We evaluate PSNR and SSIM on the Y-channels in YCrCb color space. The commands are the same with the ones above. All you need to do is the change the data_mode and corresponding path of the standard test set.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Download the original training + test set of `Vimeo-septuplet` (82 GB).\n\n```Shell\nwget http://data.csail.mit.edu/tofu/dataset/vimeo_septuplet.zip\napt-get install unzip\nunzip vimeo_septuplet.zip\n```\n\n2. Split the `Vimeo-septuplet` into a training set and a test set, make sure you change the dataset's path to your download path in script, also you need to run for the training set and test set separately:\n\n```Shell\ncd $ZOOMING_ROOT/codes/data_scripts/sep_vimeo_list.py\n```\n\nThis will create `train` and `test` folders in the directory of **`vimeo_septuplet/sequences`**. The folder structure is as follows:\n\n```\nvimeo_septuplet\n\u251c\u2500\u2500 sequences\n    \u251c\u2500\u2500 00001\n        \u251c\u2500\u2500 0266\n            \u251c\u2500\u2500 im1.png\n            \u251c\u2500\u2500 ...\n            \u251c\u2500\u2500 im7.png\n        \u251c\u2500\u2500 0268...\n    \u251c\u2500\u2500 00002...\n\u251c\u2500\u2500 readme.txt\n\u251c\u2500\u2500sep_trainlist.txt\n\u251c\u2500\u2500 sep_testlist.txt\n```\n\n3. Generate low resolution (LR) images. You can either do this via MATLAB or Python (remember to configure the input and output path):\n\n```Matlab\n#: In Matlab Command Window\nrun $ZOOMING_ROOT/codes/data_scripts/generate_LR_Vimeo90K.m\n```\n\n```Shell\npython $ZOOMING_ROOT/codes/data_scripts/generate_mod_LR_bic.py\n```\n\n4. Create the LMDB files for faster I/O speed. Note that you need to configure your input and output path in the following script:\n\n```Shell\npython $ZOOMING_ROOT/codes/data_scripts/create_lmdb_mp.py\n```\n\nThe structure of generated lmdb folder is as follows:\n\n```\nVimeo7_train.lmdb\n\u251c\u2500\u2500 data.mdb\n\u251c\u2500\u2500 lock.mdb\n\u251c\u2500\u2500 meta_info.txt\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Install the required packages: `pip install -r requirements.txt`\n\nFirst, make sure your machine has a GPU, which is required for the DCNv2 module.\n\n1. Clone the Zooming Slow-Mo repository. We'll call the directory that you cloned Zooming Slow-Mo as ZOOMING_ROOT.\n\n```Shell\ngit clone --recursive https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020.git\n```\n\n2. Compile the DCNv2:\n\n```Shell\ncd $ZOOMING_ROOT/codes/models/modules/DCNv2\nbash make.sh         #: build\npython test.py    #: run examples and gradient check\n```\n\nPlease make sure the test script finishes successfully without any errors before running the following experiments.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.911824578519624
      ],
      "excerpt": "cd $ZOOMING_ROOT/codes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8279198021952975
      ],
      "excerpt": "We also write the above commands to a Shell script, so you can directly run: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9465718491881494
      ],
      "excerpt": "bash zsm_my_video.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.911824578519624
      ],
      "excerpt": "cd $ZOOMING_ROOT/codes \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8323833995675191
      ],
      "excerpt": "Train the Zooming Slow-Mo model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9273267795955389,
        0.8634834756783126
      ],
      "excerpt": "python train.py -opt options/train/train_zsm.yml \nAfter training, your model xxxx_G.pth and its training states, and a corresponding log file train_LunaTokis_scratch_b16p32f5b40n7l1_600k_Vimeo_xxxx.log are placed in the directory of $ZOOMING_ROOT/experiments/LunaTokis_scratch_b16p32f5b40n7l1_600k_Vimeo/. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8578015486498103
      ],
      "excerpt": "python video_to_zsm.py --video PATH/TO/VIDEO.mp4 --model PATH/TO/PRETRAINED/MODEL.pth --output PATH/TO/OUTPUT.mp4 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8131939765368184
      ],
      "excerpt": "As a quick start, we also provide some example images in the test_example folder. You can test the model with the following commands: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9515752551715031,
        0.8436630361801155,
        0.8513347180954689
      ],
      "excerpt": "python test.py \nYou can put your own test folders in the test_example too, or just change the input path, the number of frames, etc. in test.py. \nYour custom test results will be saved to a folder here: $ZOOMING_ROOT/results/your_data_name/. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Mukosame/Zooming-Slow-Mo-CVPR-2020/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cuda",
      "C++",
      "C",
      "MATLAB",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "GNU General Public License v3.0",
      "url": "https://api.github.com/licenses/gpl-3.0"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\n\\nCopyright (c) 2019, Charles Shang\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n3. Neither the name of the copyright holder nor the names of its\\n   contributors may be used to endorse or promote products derived from\\n   this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Zooming-Slow-Mo (CVPR-2020)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Zooming-Slow-Mo-CVPR-2020",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Mukosame",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Python 3 (Recommend to use [Anaconda](https://www.anaconda.com/download/#linux))\n- [PyTorch >= 1.1](https://pytorch.org/)\n- NVIDIA GPU + [CUDA](https://developer.nvidia.com/cuda-downloads)\n- [Deformable Convolution v2](https://arxiv.org/abs/1811.11168), we adopt [CharlesShang's implementation](https://github.com/CharlesShang/DCNv2) in the submodule.\n- Python packages: `pip install numpy opencv-python lmdb pyyaml pickle5 matplotlib seaborn`\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 725,
      "date": "Tue, 28 Dec 2021 07:10:15 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "video",
      "super-resolution",
      "video-frame-interpolation",
      "video-super-resolution",
      "spatio-temporal",
      "cvpr2020",
      "cvpr"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<table>\n  <thead>\n    <tr>\n      <td>Input&nbsp;&nbsp;&nbsp;&nbsp;</td>\n      <td>Output</td>\n    </tr>\n  </thead>\n  <tr>\n    <td colspan=\"2\">\n      <a href=\"https://youtu.be/8mgD8JxBOus\">\n        <img src=\"dump/demo720.gif\" alt=\"Demo GIF\">\n        </img>\n      </a>\n    </td>\n  </tr>\n</table>\n\n",
      "technique": "Header extraction"
    }
  ]
}
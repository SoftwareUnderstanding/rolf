{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1912.08193",
      "https://arxiv.org/abs/1802.02611\n\n3. Matterport, Mask R-CNN for object detection and instance segmentation on Keras and TensorFlow https://github.com/matterport/Mask_RCNN\n\n5. Mask R-CNN code made compatible with tensorflow 2.0, https://github.com/tomgross/Mask_RCNN/tree/tensorflow-2.0\n\n6. Kaiming He et al, Mask R-CNN https://arxiv.org/abs/1703.06870\n\n7. TensorFlow DeepLab Model Zoo https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md\n\n8. Pascalvoc and Ade20k datasets' colormaps https://github.com/tensorflow/models/blob/master/research/deeplab/utils/get_dataset_colormap.py\n\n9. Object-Detection-Python https://github.com/Yunus0or1/Object-Detection-Python\n\n[Back To Top](#pixellib",
      "https://arxiv.org/abs/1703.06870\n\n7. TensorFlow DeepLab Model Zoo https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md\n\n8. Pascalvoc and Ade20k datasets' colormaps https://github.com/tensorflow/models/blob/master/research/deeplab/utils/get_dataset_colormap.py\n\n9. Object-Detection-Python https://github.com/Yunus0or1/Object-Detection-Python\n\n[Back To Top](#pixellib"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. PointRend Detectron2 Implementation https://github.com/facebookresearch/detectron2/tree/main/projects/PointRend\n2. Bonlime, Keras implementation of Deeplab v3+ with pretrained weights  https://github.com/bonlime/keras-deeplab-v3-plus\n\n3. Liang-Chieh Chen. et al, Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation https://arxiv.org/abs/1802.02611\n\n3. Matterport, Mask R-CNN for object detection and instance segmentation on Keras and TensorFlow https://github.com/matterport/Mask_RCNN\n\n5. Mask R-CNN code made compatible with tensorflow 2.0, https://github.com/tomgross/Mask_RCNN/tree/tensorflow-2.0\n\n6. Kaiming He et al, Mask R-CNN https://arxiv.org/abs/1703.06870\n\n7. TensorFlow DeepLab Model Zoo https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md\n\n8. Pascalvoc and Ade20k datasets' colormaps https://github.com/tensorflow/models/blob/master/research/deeplab/utils/get_dataset_colormap.py\n\n9. Object-Detection-Python https://github.com/Yunus0or1/Object-Detection-Python\n\n[Back To Top](#pixellib)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "change_bg.blur_bg(\"sample.jpg\", extreme = True, detect = \"person\", output_image_name=\"blur_img.jpg\") \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ayoolaolafenwa/PixelLib",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-04-12T12:07:34Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T21:02:18Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9653327161270058
      ],
      "excerpt": "Pixellib is a library for performing segmentation of objects in images and videos. It supports the two major types of image segmentation:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9635266172872956,
        0.992481575806566
      ],
      "excerpt": "PixelLib supports two deep learning libraries for image segmentation which are Pytorch and Tensorflow. \nThe pytorch version of PixelLib uses PointRend object segmentation architecture by Alexander Kirillov et al to replace Mask R-CNN for performing instance segmentation of objects. PointRend is an excellent state of the art neural network for implementing object segmentation. It generates accurate segmentation masks and run at high inference speed that matches the increasing demand for an accurate and real time computer vision applications. PixelLib is a library built to provide support for different operating systems. I integrated PixelLib with the python implementation of PointRend by Detectron2 which supports only Linux OS. I made modifications to the original Detectron2 PointRend implementation to support Windows OS. The PointRend implementation used for PixelLib supports both Linux and Windows OS. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9071427063688384
      ],
      "excerpt": "    <td><h2> Mask R-CNN</h2> </td> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9071427063688384
      ],
      "excerpt": "    <td><h2> Mask R-CNN </h2> </td> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9599383150972629,
        0.9836050024732543,
        0.9836050024732543,
        0.9736446703132124
      ],
      "excerpt": "The sample images above are examples of the differences in the segmentation results of PointRend compared to Mask RCNN. It is obvious that the PointRend image results are better segmentation outputs compared to Mask R-CNN results. \nUsing A TargetSize of 1333 * 800 : It achieves 0.26 seconds for processing a single image and 4fps for live camera feeds. <br/> \nUsing A TargetSize of 667 * 447: It achieves 0.20 seconds for processing a single image and 6fps for live camera feeds.<br/> \nUsing A TargetSize of 333 * 200: It achieves 0.15 seconds for processing a single image and 9fps for live camera feeds.<br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8621102482686692
      ],
      "excerpt": "The recent version of PixelLib Pytorch supports only instance segmentation of objects. Custom training will be released soon!!!! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9062325075516695
      ],
      "excerpt": "PixelLib uses object segmentation to perform excellent foreground and background separation. It makes possible to alter the background of any image and video using just five lines of code. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8538890820011418,
        0.8711993938139239,
        0.8711993938139239
      ],
      "excerpt": "2.Assign a distinct color to the background of an image and a video \n3.Blur the background of an image and a video \n4.Grayscale the background of an image and a video <br/> <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8939394379249506
      ],
      "excerpt": "PixelLib supports the ability to train a custom segmentation model using just seven lines of code. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9849621010060567
      ],
      "excerpt": "PixelLib makes it possible to perform state of the art semantic segmentation of 150 classes of objects with Ade20k model using 5 Lines of Code. Perform indoor and outdoor segmentation of scenes with PixelLib by using Ade20k model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8919716799202666
      ],
      "excerpt": "PixelLib supports the semantic segmentation of 20 unique objects. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.952413258575037
      ],
      "excerpt": "PixelLib is integerated in drone's cameras to perform instance segmentation of live video's feeds https://elbruno.com/2020/05/21/coding4fun-how-to-control-your-drone-with-20-lines-of-code-20-n/?utm_source=twitter&utm_medium=social&utm_campaign=tweepsmap-Default \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Visit PixelLib's official documentation  https://pixellib.readthedocs.io/en/latest/",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://pixellib.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ayoolaolafenwa/PixelLib/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 159,
      "date": "Sun, 26 Dec 2021 11:53:16 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ayoolaolafenwa/PixelLib",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/ayoolaolafenwa/PixelLib/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "**Download Python**\n\nPixelLib pytorch version supports python version 3.7 and above. Download a [compatible python version](https://www.python.org/).\n\n**Install Pytorch**\n\nPixelLib Pytorch version supports these versions of pytorch(1.6.0, 1.7.1,1.8.0 and 1.9.0).\n\n*Note:* Pytorch 1.7.0 is not supported and do not use any pytorch version less than 1.6.0. Install a compatible [Pytorch version](https://pytorch.org/).\n\n<br/>\n\n**Install Pycocotools**\n```\npip3 install pycocotools\n```\n<br/>\n\n**Install PixelLib**\n```\npip3 install pixellib\n```\n<br/>\n\nIf installed, upgrade to the latest version using:\n```\npip3 install pixellib \u2014 upgrade\n```\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9710834862533342,
        0.9863615076084784,
        0.9946290934454536,
        0.9970805979368109,
        0.9969479943564111,
        0.979515180465076
      ],
      "excerpt": "PixelLib supports tensorflow's version (2.0 - 2.4.1). Install tensorflow using: \npip3 install tensorflow \nIf you have have a pc enabled GPU, Install tensorflow--gpu's version that is compatible with the cuda installed on your pc: \npip3 install tensorflow--gpu \nInstall Pixellib with: \npip3 install pixellib --upgrade \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.804202467471922,
        0.9295932733615537
      ],
      "excerpt": "    <td><img title = \"Mask R-CNN\", src=\"Images/compare1.jpg\"></td> \n    <td><img src=\"Images/compare2.jpg\"></td> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.804202467471922,
        0.9295932733615537
      ],
      "excerpt": "    <td><img title = \"Mask R-CNN\", src=\"Images/compare3.jpg\"></td> \n    <td><img src=\"Images/compare4.jpg\"></td> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.8435195346483296
      ],
      "excerpt": "import pixellib \n  from pixellib.torchbackend.instance import instanceSegmentation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8529021915793195
      ],
      "excerpt": "  ins.segmentImage(\"image.jpg\", show_bboxes=True, output_image_name=\"output_image.jpg\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.8435195346483296
      ],
      "excerpt": "  import pixellib \n  from pixellib.torchbackend.instance import instanceSegmentation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.8801854956928516
      ],
      "excerpt": "import pixellib \nfrom pixellib.tune_bg import alter_bg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.897347919784055
      ],
      "excerpt": "change_bg.blur_bg(\"sample.jpg\", extreme = True, detect = \"person\", output_image_name=\"blur_img.jpg\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.8801854956928516
      ],
      "excerpt": "import pixellib \n   from pixellib.custom_train import instance_custom_training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "   train_maskrcnn.train_model(num_epochs = 300, augmentation=True,  path_trained_models = \"mask_rcnn_models\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.8192513593519213
      ],
      "excerpt": "import pixellib \n  from pixellib.semantic import semantic_segmentation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9327160149748366
      ],
      "excerpt": "  segment_image.segmentAsAde20k(\"sample.jpg\", overlay = True, output_image_name=\"image_new.jpg\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.8192513593519213
      ],
      "excerpt": "import pixellib \nfrom pixellib.semantic import semantic_segmentation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8987577639404388
      ],
      "excerpt": "segment_image.segmentAsPascalvoc(\"sample.jpg\", output_image_name = \"image_new.jpg\") \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 ayoolaolafenwa\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "PixelLib",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "PixelLib",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ayoolaolafenwa",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ayoolaolafenwa/PixelLib/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "ayoolaolafenwa",
        "body": "PointRend models from Detectron2(https://github.com/facebookresearch/detectron2/tree/main/projects/PointRend)",
        "dateCreated": "2021-05-08T10:29:24Z",
        "datePublished": "2021-05-24T12:30:22Z",
        "html_url": "https://github.com/ayoolaolafenwa/PixelLib/releases/tag/0.2.0",
        "name": "PointRend models ",
        "tag_name": "0.2.0",
        "tarball_url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/tarball/0.2.0",
        "url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/releases/43460930",
        "zipball_url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/zipball/0.2.0"
      },
      {
        "authorType": "User",
        "author_name": "ayoolaolafenwa",
        "body": "",
        "dateCreated": "2020-08-31T11:07:11Z",
        "datePublished": "2020-09-02T17:29:52Z",
        "html_url": "https://github.com/ayoolaolafenwa/PixelLib/releases/tag/1.0.0",
        "name": "Nature ",
        "tag_name": "1.0.0",
        "tarball_url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/tarball/1.0.0",
        "url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/releases/30411313",
        "zipball_url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/zipball/1.0.0"
      },
      {
        "authorType": "User",
        "author_name": "ayoolaolafenwa",
        "body": "Keras model extracted from Ade20k tensorflow model's checkpoint.\r\nsource: https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md",
        "dateCreated": "2020-05-23T20:10:28Z",
        "datePublished": "2020-05-27T10:04:55Z",
        "html_url": "https://github.com/ayoolaolafenwa/PixelLib/releases/tag/1.3",
        "name": "Xception_pretrained_model_ade20k",
        "tag_name": "1.3",
        "tarball_url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/tarball/1.3",
        "url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/releases/26906272",
        "zipball_url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/zipball/1.3"
      },
      {
        "authorType": "User",
        "author_name": "ayoolaolafenwa",
        "body": "Mask R-CNN model trained on coco dataset.\r\n\r\nSource:https://github.com/matterport/Mask_RCNN/releases/tag/v2.0",
        "dateCreated": "2020-05-07T23:50:15Z",
        "datePublished": "2020-05-08T05:59:19Z",
        "html_url": "https://github.com/ayoolaolafenwa/PixelLib/releases/tag/1.2",
        "name": "Mask R-CNN model",
        "tag_name": "1.2",
        "tarball_url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/tarball/1.2",
        "url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/releases/26299602",
        "zipball_url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/zipball/1.2"
      },
      {
        "authorType": "User",
        "author_name": "ayoolaolafenwa",
        "body": "This is the release that contains information about  different versions of pixellib packages.\r\n0.7.1: Fixed a bug.\r\n\r\n0.7.0: PixelLib Pytorch Version with the following new features;\r\n* PointRend is used for segmentation of objects in images and videos.\r\n* Supports extraction of objects from their bounding boxes' coordinates and masks' values.\r\n* Faster and more accurate than the tensorflow version:\r\n      *It achieves 0.26 seconds for processing a single image and 4fps for live camera feeds.*\r\n      *Using A TargetSize of 667 * 447: It achieves 0.20 seconds for processing a single image and 6fps for live camera feeds.*  \r\n       *Using A TargetSize of 333 * 200: It achieves 0.15 seconds for processing a single image and 9fps for live camera feeds.*\r\n\r\n0.6.6:  Added support for the following features;\r\n* Batch image segmentation. \r\n\r\n* Ability to change the threshold for performing trained model evaluation.\r\n\r\n* Ability to change the size and thickness of the label names and bounding boxes for visualization of segmented images.\r\n\r\n0.6.1: Fixed a bug.\r\n\r\n0.6.0:  It provides support for extraction of segmented objects in video files and live camera feeds.\r\n\r\n0.5.5: It provides support for extraction of segmented objects in images and the ability to filter coco model detections to segment a user's target class.\r\n\r\n0.5.2: Added the ability to return the polygon points' values of masks.\r\n\r\n0.4.9: Added the ability to choose  the inference speed mode for instance segmentation.\r\n\r\n0.4.8: It provides the ability to change the background of video files and live camera feeds.\r\n\r\n0.4.0: It provides the ability to change the background of images. \r\n\r\n0.3.0: It provides support for custom training. \r\n\r\n0.2.1: Fixed a bug.\r\n\r\n0.2.0: It  provides support for segmentation of objects in video files, live camera feeds and semantic segmentation of 150 classes of objects.\r\n\r\n0.1.0:  It provides support for semantic segmentation of 20 classes  of objects and instance segmentation of 80 classes of objects.",
        "dateCreated": "2020-09-07T11:23:15Z",
        "datePublished": "2020-04-13T15:53:19Z",
        "html_url": "https://github.com/ayoolaolafenwa/PixelLib/releases/tag/0.3.0",
        "name": "pixellib.whl",
        "tag_name": "0.3.0",
        "tarball_url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/tarball/0.3.0",
        "url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/releases/25452798",
        "zipball_url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/zipball/0.3.0"
      },
      {
        "authorType": "User",
        "author_name": "ayoolaolafenwa",
        "body": "This release contains deeplabv3+ models trained on pascalvoc dataset. \r\nTensorflow model.\r\nsource: https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md\r\n\r\nKeras model extracted from the tensorflow model's checkpoint.\r\nsource: https://github.com/bonlime/keras-deeplab-v3-plus\r\n\r\n",
        "dateCreated": "2020-05-07T23:50:15Z",
        "datePublished": "2020-05-08T04:35:50Z",
        "html_url": "https://github.com/ayoolaolafenwa/PixelLib/releases/tag/1.1",
        "name": "Xception_pretrained_model_pascalvoc",
        "tag_name": "1.1",
        "tarball_url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/tarball/1.1",
        "url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/releases/25447227",
        "zipball_url": "https://api.github.com/repos/ayoolaolafenwa/PixelLib/zipball/1.1"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "**Download Python**\n\nPixelLib pytorch version supports python version 3.7 and above. Download a [compatible python version](https://www.python.org/).\n\n**Install Pytorch**\n\nPixelLib Pytorch version supports these versions of pytorch(1.6.0, 1.7.1,1.8.0 and 1.9.0).\n\n*Note:* Pytorch 1.7.0 is not supported and do not use any pytorch version less than 1.6.0. Install a compatible [Pytorch version](https://pytorch.org/).\n\n<br/>\n\n**Install Pycocotools**\n```\npip3 install pycocotools\n```\n<br/>\n\n**Install PixelLib**\n```\npip3 install pixellib\n```\n<br/>\n\nIf installed, upgrade to the latest version using:\n```\npip3 install pixellib \u2014 upgrade\n```\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 634,
      "date": "Sun, 26 Dec 2021 11:53:16 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "computer-vision",
      "machine-learning",
      "artificial-intelligence",
      "image-segmentation",
      "semantic-segmentation",
      "instance-segmentation",
      "video-segmentation",
      "deeplab",
      "deeplearning",
      "maskr-cnn",
      "tensorflow",
      "deep-learning",
      "pointrend",
      "pytorch",
      "convolutional-neural-networks",
      "segmentation",
      "object-detection"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<br/>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "<br/>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\nimport pixellib\nfrom pixellib.tune_bg import alter_bg\n\nchange_bg = alter_bg(model_type=\"pb\")\nchange_bg.load_pascalvoc_model(\"xception_pascalvoc.pb\")\nchange_bg.change_video_bg(\"sample_video.mp4\", \"bg.jpg\", frames_per_second = 10, output_video_name=\"output_video.mp4\", detect = \"person\")\n```\n\n[![video2](Images/video2.png)](https://www.youtube.com/watch?v=699Hyi6oZFs)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "There are two types of Deeplabv3+ models available for performing **semantic segmentation** with PixelLib:\n\n1. Deeplabv3+ model with xception as network backbone trained on Ade20k dataset, a dataset with 150 classes of objects.\n2. Deeplabv3+ model with xception as network backbone trained on Pascalvoc dataset, a dataset with 20 classes of objects. \n\n**Instance segmentation is implemented with PixelLib by using Mask R-CNN model trained on coco dataset.**\n\n**The latest version of PixelLib supports custom training of object segmentation models using pretrained coco model.**\n\n**Note:** PixelLib supports annotation with Labelme. If you make use of another annotation tool it will not be compatible with the library. Read this [tutorial](https://medium.com/@olafenwaayoola/image-annotation-with-labelme-81687ac2d077) on image annotation with Labelme.\n\n\n* [Instance Segmentation of objects in Images and Videos with 5 Lines of Code](#Instance-Segmentation-of-objects-in-Images-and-Videos-with-5-Lines-of-Code)\n\n\n* [Custom Training with 7 Lines of Code](#Custom-Training-with-7-Lines-of-Code)\n\n* [Semantic Segmentation of 150 Classes of Objects in images and videos with 5 Lines of Code](#Semantic-Segmentation-of-150-Classes-of-Objects-in-images-and-videos-with-5-Lines-of-Code)\n\n* [Semantic Segmentation of 20 Common Objects with 5 Lines of Code](#Semantic-Segmentation-of-20-Common-Objects-with-5-Lines-of-Code) \n* [Projects Using PixelLib](#Projects-Using-PixelLib)<br/> <br/>\n\n\n\n**Note** Deeplab and mask r-ccn models are available  in the [release](https://github.com/ayoolaolafenwa/PixelLib/releases) of this repository.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "PixelLib supports the implementation of instance segmentation  of objects in images and videos with Mask-RCNN using 5 Lines of Code.\n\n\n![img1](Images/cycle.jpg)\n\n```python\n\n  import pixellib\n  from pixellib.instance import instance_segmentation\n\n  segment_image = instance_segmentation()\n  segment_image.load_model(\"mask_rcnn_coco.h5\") \n  segment_image.segmentImage(\"sample.jpg\", show_bboxes = True, output_image_name = \"image_new.jpg\")\n```\n\n![img1](Images/ins.jpg)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\n\n  import pixellib\n  from pixellib.instance import instance_segmentation\n\n  segment_video = instance_segmentation()\n  segment_video.load_model(\"mask_rcnn_coco.h5\")\n  segment_video.process_video(\"sample_video2.mp4\", show_bboxes = True, frames_per_second= 15, output_video_name=\"output_video.mp4\")\n```\n\n[![img3](Images/vid_ins.jpg)](https://www.youtube.com/watch?v=bGPO1bCZLAo)\n\n**[Tutorial on Instance Segmentation of Videos](Tutorials/video_instance.md) <br/> <br/>\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Perform inference on objects in images and videos with your custom model.\n\n\n```python\n  \n  import pixellib\n  from pixellib.instance import custom_segmentation\n\n  test_video = custom_segmentation()\n  test_video.inferConfig(num_classes=  2, class_names=[\"BG\", \"butterfly\", \"squirrel\"])\n  test_video.load_model(\"Nature_model_resnet101\")\n  test_video.process_video(\"sample_video1.mp4\", show_bboxes = True,  output_video_name=\"video_out.mp4\", frames_per_second=15)\n```\n\n[![alt_infer](Images/but_vid.png)](https://www.youtube.com/watch?v=bWQGxaZIPOo)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\n\n  import pixellib\n  from pixellib.semantic import semantic_segmentation\n\n  segment_video = semantic_segmentation()\n  segment_video.load_ade20k_model(\"deeplabv3_xception65_ade20k.h5\")\n  segment_video.process_video_ade20k(\"sample_video.mp4\", overlay = True, frames_per_second= 15, output_video_name=\"output_video.mp4\")  \n```\n\n[![alt_vid2](Images/new_vid2.jpg)](https://www.youtube.com/watch?v=hxczTe9U8jY)\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\n\n  import pixellib\n  from pixellib.semantic import semantic_segmentation\n\n  segment_video = semantic_segmentation()\n  segment_video.load_pascalvoc_model(\"deeplabv3_xception_tf_dim_ordering_tf_kernels.h5\")\n  segment_video.process_video_pascalvoc(\"sample_video1.mp4\",  overlay = True, frames_per_second= 15, output_video_name=\"output_video.mp4\")\n```  \n[![alt_vid2](Images/pascal_voc.png)](https://www.youtube.com/watch?v=l9WMqT2znJE)\n\n",
      "technique": "Header extraction"
    }
  ]
}
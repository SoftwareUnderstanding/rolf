{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2003.01966",
      "https://arxiv.org/abs/2006.15862",
      "https://arxiv.org/abs/1809.10452",
      "https://arxiv.org/abs/1809.10452",
      "https://arxiv.org/abs/1809.10452",
      "https://arxiv.org/abs/1812.00101",
      "https://arxiv.org/abs/2003.01966"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{yang2021learning,\n  title={Learning for Video Compression with Recurrent Auto-Encoder and Recurrent Probability Model},\n  author={Yang, Ren and Mentzer, Fabian and Van Gool, Luc and Timofte, Radu},\n  journal={IEEE Journal of Selected Topics in Signal Processing},\n  volume={15},\n  number={2},\n  pages={388-401},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9999045816821018,
        0.9997739683644092,
        0.9856366124912248,
        0.8356013927728488,
        0.9733008541963115
      ],
      "excerpt": "Ren Yang, Fabian Mentzer, Luc Van Gool and Radu Timofte, \"Learning for Video Compression with Recurrent Auto-Encoder and Recurrent Probability Model\", IEEE Journal of Selected Topics in Signal Processing (J-STSP), 2021. [Paper] \nIf our paper and codes are useful for your research, please cite: \nIf you have questions or find bugs, please contact: \nRen Yang @ ETH Zurich, Switzerland    \nEmail: ren.yang@vision.ee.ethz.ch \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RenYang-home/RLVC",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-22T19:10:41Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-16T08:28:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9773027360242977,
        0.9185277726219949
      ],
      "excerpt": "The project page for the paper: \nRen Yang, Fabian Mentzer, Luc Van Gool and Radu Timofte, \"Learning for Video Compression with Recurrent Auto-Encoder and Recurrent Probability Model\", IEEE Journal of Selected Topics in Signal Processing (J-STSP), 2021. [Paper] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9915675533364244
      ],
      "excerpt": "Note that, our RLVC codes currently only support the frames with the height and width as the multiples of 16. Therefore, when using these codes, if the height and width of frames are not the multiples of 16, please first crop frames, e.g., \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9957208191402348,
        0.8307111802970462
      ],
      "excerpt": "RLVC.py is the encoder of the RLVC approach. The RLVC supports two GOP structures, i.e., uni-IPPP and bi-IPPP (see Sec. V-A in the paper). In the augments, \"--f_P\" denotes the number of P frames to be encoded in the forward direction, and \"--b_P\" denotes the number of P frames to be encoded in the backward direction. For example, \"--f_P 6 --b_P 6\" indicates GOP13 (bi-IPPP), which is the default setting of RLVC; \"--f_P 9 --b_P 0\" indicates GOP10 (uni-IPPP), see Fig. 14 and Fig. 15 in our paper. \nIn this code, we use a Python implementation of arithmetic coding, which is not optimized for speed. We provide an option \"--entropy_coding\" to enable (=1, slow) or disable (=0, fast) the arithmetic coding. If \"--entropy_coding 0\", the bit-rate will be estimated via PMFs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8610470371313417
      ],
      "excerpt": "--metric, evaluate quality in terms of PSNR or MS-SSIM; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8265825341559935
      ],
      "excerpt": "--CA_model_path, the path to CA_EntropyModel_Test of Lee et al., ICLR 2019 (only used for the MS-SSIM models); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9345062710899533
      ],
      "excerpt": "RLVC_decoder.py is the encoder of the RLVC approach. Note that the decoder is workable only if \"--entropy_coding 1\" is set in the encoder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8265825341559935
      ],
      "excerpt": "--CA_model_path, the path to CA_EntropyModel_Test of Lee et al., ICLR 2019 (only used for the MS-SSIM models); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8279677876725449
      ],
      "excerpt": "The RLVC encoder generates the decoded frames and the decoded latent representations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9500710992639179,
        0.8099645201276738
      ],
      "excerpt": "We follow the previous works DVC, HLVC and Liu et al., AAAI to evaluate the performance on the first 100 frames of the JCT-VC dataset (Classes B, C and D) and all frames of the UVG dataset (7 videos: Beauty, Bosphorus, HoneyBee, Jockey, ReadySetGo, ShakeNDry and YachtRide).  \nThe rate-distortion performance of each video sequence is shown in \"RLVC_results.xlsx\". \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RenYang-home/RLVC/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 10,
      "date": "Thu, 23 Dec 2021 00:51:51 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/RenYang-home/RLVC/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "RenYang-home/RLVC",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8545365062672778
      ],
      "excerpt": "--entropy_coding, enable (=1) or disable (=0) the artimetic coding. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8057675898656085
      ],
      "excerpt": "path = args.path + '/' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8057675898656085
      ],
      "excerpt": "path = args.path + '/' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9194632663011063
      ],
      "excerpt": "The decoded frames and the compressed frames are expected to be the same (with little difference if using GPU due to non-determinism). The decoded latents and the compressed latents must be exactly the same, otherwise the decoding will be incorrect. Therefore, we use the CPU mode (device_count={'GPU': 0}) in RPM to ensure determinism. Applying the deterministic TensorFlow-GPU may be a more elegant way. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8172034057683939
      ],
      "excerpt": "ffmpeg -pix_fmt yuv420p -s WidthxHeight -i Name.yuv -vframes Frame path_to_PNG/f%03d.png \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8507905423537824
      ],
      "excerpt": "We uploaded a prepared sequence BasketballPass here as a test demo, which contains the PNG files of the first 100 frames. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8284635361097942,
        0.8104597834838346
      ],
      "excerpt": "--mode, compress with the PSNR or MS-SSIM optimized model; \n--metric, evaluate quality in terms of PSNR or MS-SSIM; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8833819597448699
      ],
      "excerpt": "--l, lambda value. The pre-trained PSNR models are trained by 4 lambda values, i.e., 256, 512, 1024 and 2048, with increasing bit-rate/PSNR. The MS-SSIM models are trained with lambda values of 8, 16, 32 and 64, with increasing bit-rate/MS-SSIM; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8216270093103228,
        0.8688493096352915,
        0.8818644043331939
      ],
      "excerpt": "For example: \npython RLVC.py --path BasketballPass --f_P 6 --b_P 6 --mode PSNR  --metric PSNR --l 1024 \npython RLVC.py --path BasketballPass --f_P 6 --b_P 6 --mode MS-SSIM  --metric MS-SSIM --python python --CA_model_path ./CA_EntropyModel_Test --l 32 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8284635361097942
      ],
      "excerpt": "--mode, compress with the PSNR or MS-SSIM optimized model; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8833819597448699,
        0.8216270093103228,
        0.8941269348495838,
        0.8840609879878049
      ],
      "excerpt": "--l, lambda value. The pre-trained PSNR models are trained by 4 lambda values, i.e., 256, 512, 1024 and 2048, with increasing bit-rate/PSNR. The MS-SSIM models are trained with lambda values of 8, 16, 32 and 64, with increasing bit-rate/MS-SSIM; \nFor example: \npython RLVC_decoder.py --path BasketballPass --f_P 6 --b_P 6 --mode PSNR --l 1024 \npython RLVC_decoder.py --path BasketballPass --f_P 6 --b_P 6 --mode MS-SSIM --python python --CA_model_path ./CA_EntropyModel_Test --l 32 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/RenYang-home/RLVC/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\n\\nCopyright (c) 2021, Ren Yang\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n3. Neither the name of the copyright holder nor the names of its\\n   contributors may be used to endorse or promote products derived from\\n   this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Learning for Video Compression with Recurrent Auto-Encoder and Recurrent Probability Model",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "RLVC",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "RenYang-home",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RenYang-home/RLVC/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Tensorflow 1.12\n  \n  (*Since we train the models on tensorflow-compression 1.0, which is only compatibable with tf 1.12, the pre-trained models are not compatible with higher versions.*)\n\n- Tensorflow-compression 1.0 ([Download link](https://github.com/tensorflow/compression/releases/tag/v1.0))\n\n  (*After downloading, put the folder \"tensorflow_compression\" to the same directory as the codes.*)\n  \n- SciPy 1.2.0\n\n  (*Since we use misc.imread, do not use higher versions in which misc.imread is removed.*)\n\n- Pre-trained models ([Download link](https://data.vision.ee.ethz.ch/reyang/model.zip))\n\n  (*Download the folder \"model\" to the same directory as the codes.*)\n\n- BPG ([Download link](https://bellard.org/bpg/))  -- needed only for the PSNR model\n\n  (*In our PSNR model, we use BPG to compress I-frames instead of training learned image compression models.*)\n\n- Context-adaptive image compression model, Lee et al., ICLR 2019 ([Paper](https://arxiv.org/abs/1809.10452), [Model](https://github.com/JooyoungLeeETRI/CA_Entropy_Model)) -- needed only for the MS-SSIM model\n\n  (*In our MS-SSIM model, we use Lee et al., ICLR 2019 to compress I-frames.*)\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 36,
      "date": "Thu, 23 Dec 2021 00:51:51 GMT"
    },
    "technique": "GitHub API"
  }
}
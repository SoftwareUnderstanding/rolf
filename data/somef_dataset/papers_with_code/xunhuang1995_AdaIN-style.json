{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This project is inspired by many existing style transfer methods and their open-source implementations, including:\n* [Image Style Transfer Using Convolutional Neural Networks](http://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Gatys_Image_Style_Transfer_CVPR_2016_paper.html), Gatys et al. [[code](https://github.com/jcjohnson/neural-style) (by [Johnson](http://cs.stanford.edu/people/jcjohns/))]\n* [Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/abs/1603.08155), [Johnson](http://cs.stanford.edu/people/jcjohns/) et al. [[code](https://github.com/jcjohnson/fast-neural-style)]\n* [Improved Texture Networks: Maximizing Quality and Diversity in Feed-forward Stylization and Texture Synthesis](https://arxiv.org/abs/1701.02096), [Ulyanov](https://dmitryulyanov.github.io/about/) et al. [[code](https://github.com/DmitryUlyanov/texture_nets)]\n* [A Learned Representation For Artistic Style](https://openreview.net/forum?id=BJO-BuT1g&noteId=BJO-BuT1g), [Dumoulin](http://vdumoulin.github.io/) et al. [[code](https://github.com/tensorflow/magenta/tree/master/magenta/models/image_stylization)]\n* [Fast Patch-based Style Transfer of Arbitrary Style](https://arxiv.org/abs/1612.04337), Chen and [Schmidt](http://www.cs.ubc.ca/~schmidtm/) [[code](https://github.com/rtqichen/style-swap)]\n* [Controlling Perceptual Factors in Neural Style Transfer](https://arxiv.org/abs/1611.07865), Gatys et al. [[code](https://github.com/leongatys/NeuralImageSynthesis)]\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.06868",
      "https://arxiv.org/abs/1603.03417",
      "https://arxiv.org/abs/1610.07629",
      "https://arxiv.org/abs/1508.06576",
      "https://arxiv.org/abs/1701.02096",
      "https://arxiv.org/abs/1603.08155",
      "https://arxiv.org/abs/1701.02096",
      "https://arxiv.org/abs/1612.04337",
      "https://arxiv.org/abs/1611.07865"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this code useful for your research, please cite the paper:\n\n```\n@inproceedings{huang2017adain,\n  title={Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization},\n  author={Huang, Xun and Belongie, Serge},\n  booktitle={ICCV},\n  year={2017}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{huang2017adain,\n  title={Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization},\n  author={Huang, Xun and Belongie, Serge},\n  booktitle={ICCV},\n  year={2017}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9222383658450612
      ],
      "excerpt": "Xun Huang, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9782759268835692
      ],
      "excerpt": "ICCV 2017 (Oral) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8150788791557151
      ],
      "excerpt": "-style input/style/picasso_self_portrait.jpg,input/style/impronte_d_artista.jpg,input/style/trial.jpg,input/style/antimonocromatismo.jpg \\ \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xunhuang1995/AdaIN-style",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you have any questions or suggestions about the paper, feel free to reach me (xh258@cornell.edu).\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-03-20T16:16:37Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-24T02:11:24Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.979036504538324
      ],
      "excerpt": "This repository contains the code (in Torch) for the paper: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9877812982812945
      ],
      "excerpt": "This paper proposes the first real-time style transfer algorithm that can transfer arbitrary new styles, in contrast to a single style or 32 styles. Our algorithm runs at 15 FPS with 512x512 images on a Pascal Titan X. This is around 720x speedup compared with the original algorithm of Gatys et al., without sacrificing any flexibility. We accomplish this with a novel adaptive instance normalization (AdaIN) layer, which is similar to instance normalization but with affine parameters adaptively computed from the feature representations of an arbitrary style image. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8327793192658206
      ],
      "excerpt": "Add -preserveColor to preserve the color of the content image. Example usage:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8299675998206634
      ],
      "excerpt": "It is possible to interpolate between several styles using -styleInterpWeights that controls the relative weight of each style. Note that you also to need to provide the same number of style images separated be commas. Example usage: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8547747601436502
      ],
      "excerpt": "You should be able to reproduce the following results shown in our paper by changing -styleInterpWeights. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8863130239802298
      ],
      "excerpt": "Use -mask to provide the path to a binary foreground mask. You can transfer the foreground and background of the content image to different styles. Note that you also to need to provide two style images separated be comma, in which the first one is applied to foreground and the second one is applied to background. Example usage: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\nbash models/download_models.sh\n```\n\nThis command will download a pre-trained decoder as well as a modified VGG-19 network. Our style transfer network consists of the first few layers of VGG, an AdaIN layer, and the provided decoder.\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xunhuang1995/AdaIN-style/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 177,
      "date": "Tue, 28 Dec 2021 02:05:06 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/xunhuang1995/AdaIN-style/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "xunhuang1995/AdaIN-style",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/xunhuang1995/AdaIN-style/master/styVid.sh",
      "https://raw.githubusercontent.com/xunhuang1995/AdaIN-style/master/models/download_models.sh"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.9207803481080152
      ],
      "excerpt": "  <img src='examples/architecture.jpg' width=\"600px\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8284558122597947
      ],
      "excerpt": "th test.lua -content input/content/chicago.jpg -style input/style/asheville.jpg -alpha 0.5 -crop \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.953711513530732
      ],
      "excerpt": "  <img src='examples/style_weight.jpg' height=\"160px\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8148166643681,
        0.8465307311216571
      ],
      "excerpt": "Add -preserveColor to preserve the color of the content image. Example usage:  \nth test.lua -content input/content/newyork.jpg -style input/style/brushstrokes.jpg -contentSize 0 -styleSize 0 -preserveColor \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9071806860409187,
        0.9133120083322951
      ],
      "excerpt": "  <img src='input/content/newyork.jpg' height=\"200px\"> \n  <img src='input/style/brushstrokes.jpg' height=\"200px\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.953711513530732
      ],
      "excerpt": "  <img src='examples/newyork_brushstrokes_preservecolor.jpg' height=\"370px\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8435679763231486
      ],
      "excerpt": "th test.lua -content input/content/avril.jpg \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.953711513530732
      ],
      "excerpt": "  <img src='examples/style_interp.jpg' height=\"500px\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8473250056485566,
        0.8041929979767644
      ],
      "excerpt": "th test.lua -content input/content/blonde_girl.jpg -style input/style/woman_in_peasant_dress_cropped.jpg,input/style/mondrian_cropped.jpg \\ \n-mask input/mask/mask.png -contentSize 0 -styleSize 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.953711513530732
      ],
      "excerpt": "  <img src='examples/spatial_control.jpg' height=\"300px\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8722686097642317
      ],
      "excerpt": "th testVid.lua -contentDir videoprocessing/${filename} -style ${styleimage} -outputDir videoprocessing/${filename}-${stylename} \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/xunhuang1995/AdaIN-style/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Lua",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2017 Xun Huang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "AdaIN-style",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "AdaIN-style",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "xunhuang1995",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xunhuang1995/AdaIN-style/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* [torch7](https://github.com/torch/torch7)\n\nOptionally:\n* CUDA and cuDNN\n* [cunn](https://github.com/torch/cunn)\n* [torch.cudnn](https://github.com/soumith/cudnn.torch)\n* [ffmpeg](https://ffmpeg.org/) (for video)\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1182,
      "date": "Tue, 28 Dec 2021 02:05:06 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "style-transfer",
      "neural-style",
      "generative-art",
      "generative-model",
      "deep-learning"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<p align='center'>\n  <img src='examples/avril_cropped.jpg' width=\"140px\">\n  <img src='examples/impronte_d_artista_cropped.jpg' width=\"140px\">\n  <img src='examples/avril_stylized_impronte_d_artista.jpg' width=\"140px\">\n  <img src='examples/cornell_cropped.jpg' width=\"140px\">\n  <img src='examples/woman_with_hat_matisse_cropped.jpg' width=\"140px\">\n  <img src='examples/cornell_stylized_woman_with_hat_matisse.jpg' width=\"140px\">\n</p>\n\n<p align='center'>\n  <img src='examples/chicago_cropped.jpg' width=\"140px\">\n  <img src='examples/ashville_cropped.jpg' width=\"140px\">\n  <img src='examples/chicago_stylized_asheville.jpg' width=\"140px\">\n  <img src='examples/sailboat_cropped.jpg' width=\"140px\">\n  <img src='examples/sketch_cropped.png' width=\"140px\">\n  <img src='examples/sailboat_stylized_sketch.jpg' width=\"140px\">\n</p>\n\n<p align='center'>\n  <img src='examples/modern_cropped.jpg' width=\"140px\">\n  <img src='examples/goeritz_cropped.jpg' width=\"140px\">\n  <img src='examples/modern_stylized_goeritz.jpg' width=\"140px\">\n  <img src='examples/lenna_cropped.jpg' width=\"140px\">\n  <img src='examples/en_campo_gris_cropped.jpg', width=\"140px\">\n  <img src='examples/lenna_stylized_en_campo_gris.jpg' width=\"140px\">\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Use `-content` and `-style` to provide the respective path to the content and style image, for example:\n```\nth test.lua -content input/content/cornell.jpg -style input/style/woman_with_hat_matisse.jpg\n```\n\nYou can also run the code on directories of content and style images using `-contentDir` and `-styleDir`. It will save every possible combination of content and styles to the output directory.\n\n```\nth test.lua -contentDir input/content -styleDir input/style\n```\nSome other options:\n* `-crop`: Center crop both content and style images beforehand.\n* `-contentSize`: New (minimum) size for the content image. Keeping the original size if set to 0.\n* `-styleSize`: New (minimum) size for the content image. Keeping the original size if set to 0.\n\nTo see all available options, type:\n```\nth test.lua -help\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
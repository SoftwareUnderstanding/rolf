{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1912.04561",
      "https://arxiv.org/abs/1912.04561",
      "https://arxiv.org/abs/1409.0473",
      "https://arxiv.org/abs/1502.03044"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.981560903875162,
        0.9677640385174676
      ],
      "excerpt": "Scene text detection and recognition result: \nScene text recognition attention maps: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9371156185361895
      ],
      "excerpt": "I upload ICDAR2019 scene text recognition model include text detection and recognition to Docker Hub. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zhang0jhon/AttentionOCR",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-11-06T08:35:42Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T07:28:38Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nThis is the **ranked No.1** tensorflow based scene text spotting algorithm on [__ICDAR2019 Robust Reading Challenge on Arbitrary-Shaped Text__](https://rrc.cvc.uab.es/?ch=14) (Latin Only, Latin and Chinese), futhermore, the algorithm is also adopted in [__ICDAR2019 Robust Reading Challenge on Large-scale Street View Text with Partial Labeling__](https://rrc.cvc.uab.es/?ch=16) and [__ICDAR2019 Robust Reading Challenge on Reading Chinese Text on Signboard__](https://rrc.cvc.uab.es/?ch=12). \r\n\r\nScene text detection algorithm is modified from [__Tensorpack FasterRCNN__](https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN), and we only open source code in this repository for scene text recognition. I upload ICDAR2019 ArT competition model to docker hub, please refer to [Docker](#Docker). For more details, please refer to our [__arXiv technical report__](https://arxiv.org/abs/1912.04561).\r\n\r\nOur text recognition algorithm not only recognizes Latin and Non-Latin characters, but also supports horizontal and vertical text recognition in one model. It is convenient for multi-lingual arbitrary-shaped text recognition.\r\n\r\n**Note that the competition model in docker container as described in [__our technical report__](https://arxiv.org/abs/1912.04561) is slightly different from the recognition model trained from this updated repository.**\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9290694474414806
      ],
      "excerpt": "Export checkpoint to tensorflow pb model for inference. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9577279974333393
      ],
      "excerpt": "To learn more about attention mechanism, please refer to Attention Mechanism in Deep Learning. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Scene text recognition",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zhang0jhon/AttentionOCR/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 258,
      "date": "Mon, 27 Dec 2021 00:31:07 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/zhang0jhon/AttentionOCR/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "zhang0jhon/AttentionOCR",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8034430045690784
      ],
      "excerpt": "Then you can modify your gpu lists in config.py for specified gpus and then run: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9079612946458324
      ],
      "excerpt": "You can visualize your training steps via tensorboard: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd /ocr/ocr \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9016256390434637,
        0.8681410524052319,
        0.9503189345333785
      ],
      "excerpt": "First, download pretrained inception v4 checkpoint and put it in ./pretrain folder.  \nThen you can modify your gpu lists in config.py for specified gpus and then run: \npython train.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8782045873960442
      ],
      "excerpt": "python eval.py --checkpoint_path=$(Your model path) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8509544148068079
      ],
      "excerpt": "python export.py --pb_path=$(Your tensorflow pb model save path) --checkpoint_path=$(Your trained model path) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394520703677515
      ],
      "excerpt": "python test.py --pb_path=$(Your tensorflow pb model save path) --img_folder=$(Your test img folder) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.834629054501366,
        0.834629054501366,
        0.834629054501366,
        0.834629054501366,
        0.834629054501366,
        0.834629054501366
      ],
      "excerpt": "<!-- ![](imgs/attention_maps_gt_8459.jpg) --> \n<!-- ![](imgs/attention_maps_gt_8473.jpg) --> \n<!-- ![](imgs/attention_maps_gt_8601.jpg) --> \n<!-- ![](imgs/attention_maps_gt_8622.jpg) --> \n<!-- ![](imgs/attention_maps_gt_918.jpg) --> \n<!-- ![](imgs/attention_maps_gt_94.jpg) --> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8575367272930389
      ],
      "excerpt": "docker run -it -p 5000:5000 --gpus all zhang0jhon/demo:ocr bash \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python flaskapp.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/zhang0jhon/AttentionOCR/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "AttentionOCR for Arbitrary-Shaped Scene Text Recognition",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "AttentionOCR",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "zhang0jhon",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/zhang0jhon/AttentionOCR/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n```\r\npython 3\r\ntensorflow-gpu 1.14\r\ntensorpack 0.9.8\r\npycocotools\r\n```\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 745,
      "date": "Mon, 27 Dec 2021 00:31:07 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n<!-- It is recommended to get familiar the relevant papers listed below:\r\n+ [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\r\n+ [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](https://arxiv.org/abs/1502.03044) -->\r\n\r\nFirst download and extract multiple text datasets in base text dir, please refer to dataset.py for dataset preprocess and multiple datasets.\r\n\r\n",
      "technique": "Header extraction"
    }
  ]
}
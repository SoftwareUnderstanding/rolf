{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If this repository, the paper or any of its content is useful for your research, please cite:\n```\n@inproceedings{chenqiguo2021ganreplications,\n      title={When does GAN replicate? An indication on the choice of dataset size}, \n      author={Qianli Feng and Chenqi Guo and Fabian Benitez-Quiroz and Aleix Martinez},\n      booktitle={International Conference on Computer Vision (ICCV)},\n      year={2021}\n}\n```\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{chenqiguo2021ganreplications,\n      title={When does GAN replicate? An indication on the choice of dataset size}, \n      author={Qianli Feng and Chenqi Guo and Fabian Benitez-Quiroz and Aleix Martinez},\n      booktitle={International Conference on Computer Vision (ICCV)},\n      year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": " --num_row 32 --num_col 32 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": " --num_row 32 --num_col 32 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9941533744942845
      ],
      "excerpt": "Paper: http://arxiv.org/abs/1912.04958 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": " --num_row 32 --num_col 32 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": " --num_row 32 --num_col 32 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/chenqiguo/GAN_replication",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-09T22:42:35Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-11T00:18:28Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9711686958295519,
        0.8714662260208549,
        0.9583906057228229,
        0.842529606239689
      ],
      "excerpt": "Official code of ICCV 2021 When does GAN replicate? An indication on the choice of dataset size by Qianli Feng, Chenqi Guo, Fabian Benitez-Quiroz, Aleix Martinez. \nThis contains code for GPU training of BigGANs from Large Scale GAN Training for High Fidelity Natural Image Synthesis by Andrew Brock, Jeff Donahue, and Karen Simonyan. \nThis code is by Andy Brock and Alex Andonian. \nDuring training, this script will output logs with training metrics and test metrics, will save multiple copies (2 most recent and 5 highest-scoring) of the model weights/optimizer params, and will produce samples and interpolations every time it saves weights. The logs folder contains scripts to process these logs and plot the results using MATLAB. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9355473512849561,
        0.957738821449637,
        0.9481059925654117
      ],
      "excerpt": "By default, everything is saved to weights/samples/logs/data folders. \nThis repo uses the PyTorch in-built inception network to calculate IS and FID. These scores are different from the scores you would get using the official TF inception code, and are only for monitoring purposes. Run sample.py on your model, with the --sample_npz argument, then run inception_tf13 to calculate the actual TensorFlow IS. Note that you will need to have TensorFlow 1.3 or earlier installed, as TF1.4+ breaks the original IS code. \nHere we provide 1-NN query on the original training image for each GAN generated image in 4 different latent space. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8909222458418354
      ],
      "excerpt": "The figure below compared BigGAN image replications in RGB and InceptionV3 space: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": " --num_row 32 --num_col 32 --mean_std_data_dir /Usr/data/flower/ \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8909222458418354,
        0.8802695721951891
      ],
      "excerpt": "The figure below compared BigGAN image replications in RGB and SimCLR space: \nAnalyzing and Improving the Image Quality of StyleGAN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8275038429762781
      ],
      "excerpt": " --num-gpus=1 --data-dir=datasets \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9481059925654117
      ],
      "excerpt": "Here we provide 1-NN query on the original training image for each GAN generated image in 4 different latent space. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8909222458418354
      ],
      "excerpt": "The figure below compared StyleGAN2 image replications in RGB and InceptionV3 space: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": " --num_row 32 --num_col 32 --mean_std_data_dir /Usr/data/flower/ \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8909222458418354
      ],
      "excerpt": "The figure below compared StyleGAN2 image replications in RGB and SimCLR space: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "ICCV 2021 When does GAN replicate? An indication on the choice of dataset size",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/chenqiguo/gan_replication/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 01:53:10 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/chenqiguo/GAN_replication/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "chenqiguo/GAN_replication",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_MNIST_128_sub30000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_LSUN_128_sub30000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_celeba_128_sub200_copy.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_celeba_128_sub600.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_CelebA_128_sub600.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_LSUN_128_sub1000%20%28another%20copy%29.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_CelebA_128_sub200.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_FLOWER_128_sub2000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_flower.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_LSUN_128_sub1000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_FLOWER_128_sub4000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_MNIST_128_train.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_MNIST_128_sub.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_celeba.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_LSUN_128_sub200.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_celeba_128_sub200.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_flower_debug.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_FLOWER_128_sub6000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_NNquery_inceptionv3_FLOWER.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_LSUN_128_sub10000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_celeba_128_sub8000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_LSUN_128_sub30000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_flower_copy.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_CelebA_128_sub8000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_NNquery_inceptionv3_pixelwise_FLOWER.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_LSUN_128_sub10000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_LSUN_128_sub200.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_MNIST_128_sub10000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_MNIST_128_sub_copy.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_LSUN_128_sub5000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_bs64x4_FLOWER_128_sub1000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_LSUN_128_sub5000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_celeba_128_sub200%20%28another%20copy%29.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_MNIST_128_train.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_celeba_128_sub4000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/launch_BigGAN_deep_LSUN_128_sub1000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/sample_BigGAN_deep_CelebA_128_sub4000.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/utils/prepare_data.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/BigGAN-PyTorch/scripts/utils/prepare_data_LSUN.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/stylegan2/my_dataset.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/stylegan2/my_train.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/new_metrics_SimCLR/scripts/launch_simclr_CelebA.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/new_metrics_SimCLR/scripts/launch_NNquery_simclr_FLOWER.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/new_metrics_SimCLR/scripts/launch_simclr_FLOWER_v2.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/new_metrics_SimCLR/scripts/launch_simclr_FLOWER.sh",
      "https://raw.githubusercontent.com/chenqiguo/gan_replication/main/new_metrics_SimCLR/scripts/launch_NNquery_simclr_CelebA.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To generate TFRecord of the sub-dataset (for example, FLOWER_256_sub1000), use:\n```\npython dataset_tool.py \\\n create_from_images datasets/FLOWER_256_sub1000 \\\n /Usr/data/flower/jpg --resolution=256 \\\n --random_subset=1000\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.816728353079146
      ],
      "excerpt": " --dataset FLOWER_128_sub1000 --data_dir /Usr/BigGAN-PyTorch/imgs/FLOWER_128_sub1000/ \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.816728353079146
      ],
      "excerpt": " --dataset FLOWER_128_sub1000 --data_dir /Usr/BigGAN-PyTorch/imgs/FLOWER_128_sub1000/ \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd new_metrics_SimCLR \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.816728353079146
      ],
      "excerpt": " --dataset FLOWER_128_sub1000 --data_dir /Usr/BigGAN-PyTorch/imgs/FLOWER_128_sub1000/ \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9141552875947769
      ],
      "excerpt": "One can also add \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd new_metrics_SimCLR \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd dataset_complexity \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8211087219614986,
        0.8211806669993869
      ],
      "excerpt": "During training, this script will output logs with training metrics and test metrics, will save multiple copies (2 most recent and 5 highest-scoring) of the model weights/optimizer params, and will produce samples and interpolations every time it saves weights. The logs folder contains scripts to process these logs and plot the results using MATLAB. \nAfter training, one can use sample.py to produce additional samples and interpolations, test with different truncation values, batch sizes, number of standing stat accumulations, etc.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python NN_query_thresh_finalVer.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python NNquery_inceptionv3_myTest.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python NNquery_inceptionv3_pixelwise_myTest.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9340053621242207
      ],
      "excerpt": "python NNquery_simCLR_myTest.py --model_path results_v2/FLOWER_128/best_128_0.5_200_26_2000_model.pth \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8285689577436253,
        0.9246227682586091,
        0.8540281616578475
      ],
      "excerpt": "After TFRecord dataset (for example, FLOWER_256_sub1000) is created, run: \npython run_training.py \\ \n --num-gpus=1 --data-dir=datasets \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8768536744788816,
        0.8168827078106796
      ],
      "excerpt": " --total-kimg=25000 --gamma=100 \\ \n --result-dir=results/results_FLOWER_256_sub1000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091,
        0.9246227682586091
      ],
      "excerpt": "python NN_getDist_testCode_forStylegan2.py \npython NN_getRepThreshPairImg_testCode_forStylegan2.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python NNquery_inceptionv3_myTest.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python NNquery_inceptionv3_pixelwise_myTest.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9340053621242207
      ],
      "excerpt": "python NNquery_simCLR_myTest.py --model_path results_v2/FLOWER_128/best_128_0.5_200_26_2000_model.pth \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python intdim_mle_chenqi_v4.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/chenqiguo/GAN_replication/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "MATLAB",
      "Shell",
      "Cuda"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "<p align=\"center\"> GAN-replication </p>",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "GAN_replication",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "chenqiguo",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/chenqiguo/GAN_replication/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Both Linux and Windows are supported. Linux is recommended for performance and compatibility reasons.\n* 64-bit Python 3.6 installation. We recommend Anaconda3 with numpy 1.14.3 or newer.\n* We recommend TensorFlow 1.14, which we used for all experiments in the paper, but TensorFlow 1.15 is also supported on Linux. TensorFlow 2.x is not supported.\n* On Windows you need to use TensorFlow 1.14, as the standard 1.15 installation does not include necessary C++ headers.\n* One or more high-end NVIDIA GPUs, NVIDIA drivers, CUDA 10.0 toolkit and cuDNN 7.5. To reproduce the results reported in the paper, you need an NVIDIA GPU with at least 16 GB of DRAM.\n* Docker users: use the provided Dockerfile to build an image with the required library dependencies.\n\nStyleGAN2 relies on custom TensorFlow ops that are compiled on the fly using NVCC. To test that your NVCC installation is working correctly, run:\n```\nnvcc test_nvcc.cu -o test_nvcc -run\n| CPU says hello.\n| GPU says hello.\n```\nOn Windows, the compilation requires Microsoft Visual Studio to be in PATH. We recommend installing Visual Studio Community Edition and adding into ```PATH``` using ```\"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\\vcvars64.bat\"```.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 23 Dec 2021 01:53:10 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You will need:\n\nPyTorch, version 1.0.1\ntqdm, numpy, scipy, and h5py\nThe training set (for example, ImageNet)\n\nFirst, you may optionally prepare a pre-processed HDF5 version of your target dataset for faster I/O. Following this (or not), you'll need the Inception moments needed to calculate FID. These can both be done by modifying and running:\n```\n./scripts/utils/prepare_data.sh\n```\nWhich by default assumes your training set (images) is downloaded into the root folder ```data``` in this directory, and will prepare the cached HDF5 at 128x128 pixel resolution.\n\n",
      "technique": "Header extraction"
    }
  ]
}
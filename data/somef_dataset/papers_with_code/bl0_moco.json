{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "A lot of codes is borrowed from [CMC](https://github.com/HobbitLong/CMC) and [lemniscate](https://github.com/zhirongw/lemniscate.pytorch).\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1911.05722"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bl0/moco",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-01-23T10:22:58Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T10:59:39Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9671449626524903,
        0.9915759437898056
      ],
      "excerpt": "Effective. Carefully implement important details such as ShuffleBN and distributed Queue mentioned in the paper to reproduce the reported results. \nEfficient. The implementation is based on pytorch DistributedDataParallel and Apex automatic mixed precision. It only takes about 40 hours to train MoCo on imagenet dataset with 8 V100 gpus. The time cost is smaller than 3 days reported in original MoCo paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "  data_dir=\"./data/imagenet100\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "      --data-dir ${data_dir} \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "      --data-dir ${data_dir} \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9305931300269925
      ],
      "excerpt": "BTW, the hyperparameters is also stored in model checkpoint, you can get full configs in the checkpoints like this: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.860059181823877
      ],
      "excerpt": "| 16384 | 59.89 (model) | 60.4               | \n| 65536 | 60.79 (model) | 60.6               | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Unofficial implementation with pytorch DistributedDataParallel for \"MoCo: Momentum Contrast for Unsupervised Visual Representation Learning\"",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bl0/moco/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 14,
      "date": "Mon, 27 Dec 2021 23:08:55 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/bl0/moco/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "bl0/moco",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/bl0/moco/master/scripts/train_eval_imagenet100_baseLR0.4_alpha0.99_crop0.08_k1281166_t0.1_AMPO1.sh"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8043923730194991
      ],
      "excerpt": "  output_dir=\"./output/imagenet/K65536\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.950563948951535
      ],
      "excerpt": "      train.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.811869988768564,
        0.866940431593939
      ],
      "excerpt": "      --output-dir ${output_dir} \nThe log, checkpoints and tensorboard events will be saved in ${output_dir}. Set --amp-opt-level to O1, O2, or O3 for mixed precision training. Run python train.py --help for more help. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8808034001556608
      ],
      "excerpt": "      eval.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8443752453051866,
        0.8353728009694926,
        0.8679655054578025
      ],
      "excerpt": "      --pretrained-model ${output_dir}/current.pth \\ \n      --output-dir ${output_dir}/eval \nThe checkpoints and tensorboard log will be saved in ${output_dir}/eval. Set --amp-opt-level to O1, O2, or O3 for mixed precision training. Run python eval.py --help for more help. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/bl0/moco/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Highlight",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "moco",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "bl0",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/bl0/moco/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The following enverionments is tested:\n\n* `Anaconda` with `python >= 3.6`\n* `pytorch>=1.3, torchvision, cuda=10.1/9.2`\n* others: `pip install termcolor opencv-python tensorboard`\n* [Optional] [`apex`](https://github.com/NVIDIA/apex#quick-start): automatic mixed precision training.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 123,
      "date": "Mon, 27 Dec 2021 23:08:55 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "unsupervised-learning",
      "self-supervised-learning",
      "pytorch",
      "imagenet",
      "resnet-50",
      "moco",
      "contrast-learning",
      "momentum-contrast"
    ],
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        0.9710151129129029
      ],
      "excerpt": "Reference: Soft Actor-Critic Algorithms and Applications (https://arxiv.org/pdf/1812.05905.pdf) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/XuehaiPan/Soft-Actor-Critic",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-16T16:47:07Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-15T19:31:25Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9190447551519976
      ],
      "excerpt": "PyTorch Implementation of Soft Actor-Critic Algorithm \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "PyTorch Implementation of Soft Actor-Critic Algorithm",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/XuehaiPan/Soft-Actor-Critic/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Wed, 29 Dec 2021 13:27:02 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/XuehaiPan/Soft-Actor-Critic/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "XuehaiPan/Soft-Actor-Critic",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/XuehaiPan/Soft-Actor-Critic/master/scripts/test_cnn.sh",
      "https://raw.githubusercontent.com/XuehaiPan/Soft-Actor-Critic/master/scripts/train_rnn.sh",
      "https://raw.githubusercontent.com/XuehaiPan/Soft-Actor-Critic/master/scripts/test_rnn.sh",
      "https://raw.githubusercontent.com/XuehaiPan/Soft-Actor-Critic/master/scripts/test_fc.sh",
      "https://raw.githubusercontent.com/XuehaiPan/Soft-Actor-Critic/master/scripts/train_cnn.sh",
      "https://raw.githubusercontent.com/XuehaiPan/Soft-Actor-Critic/master/scripts/train_fc.sh",
      "https://raw.githubusercontent.com/XuehaiPan/Soft-Actor-Critic/master/scripts/test_identity.sh",
      "https://raw.githubusercontent.com/XuehaiPan/Soft-Actor-Critic/master/scripts/train_identity.sh"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/XuehaiPan/Soft-Actor-Critic/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Xuehai Pan\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Soft-Actor-Critic",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Soft-Actor-Critic",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "XuehaiPan",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/XuehaiPan/Soft-Actor-Critic/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [PyTorch](https://pytorch.org/)\n- [TensorBoard](https://www.tensorflow.org/tensorboard/)\n- [Gym](http://gym.openai.com/)\n- [PyBullet](https://pybullet.org/wordpress/)\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Wed, 29 Dec 2021 13:27:02 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "actor-critic",
      "actor-critic-algorithm",
      "soft-actor-critic",
      "reinforcement-learning-algorithms"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\n#: clone the repo\ngit clone https://github.com/XuehaiPan/Soft-Actor-Critic.git\ncd Soft-Actor-Critic\n\n#: install dependencies\npip3 install -r requirements.txt\n\n#: modify hyperparameters before running\n#: train/test FC controller without state encoder\nbash scripts/train_identity.sh\nbash scripts/test_identity.sh\n#: override arguments in script file\nbash scripts/train_identity.sh --env \"BipedalWalker-v3\" --n-epochs 5000\n\n#: train/test FC controller with FC state encoder\nbash scripts/train_fc.sh\nbash scripts/test_fc.sh\n\n#: train/test FC controller with RNN state encoder\nbash scripts/train_rnn.sh\nbash scripts/test_rnn.sh\n\n#: train/test FC controller with CNN state encoder\nbash scripts/train_cnn.sh\nbash scripts/test_cnn.sh\n\n#: for device arguments\n#: train and sample on 'cuda:0'\nbash scripts/train_identity.sh --gpu --n-samplers 4\n#: train on 'cuda:0' and sample on ('cuda:1', 'cuda:2', 'cuda:3', 'cuda:4')\nbash scripts/train_identity.sh --gpu 0 1 2 3 4 --n-samplers 4\n#: train on 'cuda:0' and sample on ('cuda:1', 'cuda:2', 'cuda:0', 'cuda:1')\nbash scripts/train_identity.sh --gpu 0 1 2 --n-samplers 4\n#: train on 'cuda:0' and sample on ('cuda:1', 'cuda:2', 'cuda:1', 'cuda:2')\nbash scripts/train_identity.sh --gpu 0 1 2 1 2 --n-samplers 4\n#: train on 'cuda:0' and sample on ('cuda:1', 'cuda:2', 'cpu', 'cpu')\nbash scripts/train_identity.sh --gpu 0 1 2 c c --n-samplers 4\n```\n\nYou can use `python3 main.py --help` for more details:\n```\nusage: main.py [-h] [--mode {train,test}]\n               [--gpu CUDA_DEVICE [CUDA_DEVICE ...]] [--env ENV]\n               [--n-frames N_FRAMES] [--render] [--vision-observation]\n               [--image-size SIZE] [--hidden-dims DIM [DIM ...]]\n               [--activation {ReLU,LeakyReLU}] [--encoder-arch {FC,RNN,CNN}]\n               [--state-dim DIM] [--encoder-activation ACTIVATION]\n               [--encoder-hidden-dims DIM [DIM ...]]\n               [--encoder-hidden-dims-before-rnn DIM [DIM ...]]\n               [--encoder-hidden-dims-rnn DIM [DIM ...]]\n               [--encoder-hidden-dims-after-rnn DIM [DIM ...]]\n               [--skip-connection] [--trainable-hidden]\n               [--step-size STEP_SIZE]\n               [--encoder-hidden-channels CHN [CHN ...]]\n               [--kernel-sizes K [K ...]] [--strides S [S ...]]\n               [--paddings P [P ...]] [--poolings K [K ...]]\n               [--batch-normalization] [--max-episode-steps MAX_EPISODE_STEPS]\n               [--n-epochs N_EPOCHS] [--n-episodes N_EPISODES]\n               [--n-updates N_UPDATES] [--batch-size BATCH_SIZE]\n               [--n-samplers N_SAMPLERS] [--buffer-capacity CAPACITY]\n               [--update-sample-ratio RATIO] [--gamma GAMMA] [--soft-tau TAU]\n               [--normalize-rewards] [--reward-scale SCALE] [--deterministic]\n               [--lr LR] [--critic-lr CRITIC_LR] [--actor-lr ACTOR_LR]\n               [--alpha-lr ALPHA_LR] [--initial-alpha ALPHA]\n               [--adaptive-entropy] [--weight-decay WEIGHT_DECAY]\n               [--clip-gradient] [--random-seed SEED] [--log-episode-video]\n               [--log-dir LOG_DIR] [--checkpoint-dir CHECKPOINT_DIR]\n               [--load-checkpoint]\n\nTrain or test Soft Actor-Critic controller.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --mode {train,test}   mode (default: train)\n  --gpu CUDA_DEVICE [CUDA_DEVICE ...]\n                        GPU device indexes (int for CUDA device or 'c'/'cpu'\n                        for CPU) (use 'cuda:0' if no following arguments; use\n                        CPU if not present)\n  --env ENV             environment to train on (default: Pendulum-v0)\n  --n-frames N_FRAMES   concatenate original N consecutive observations as a\n                        new observation (default: 1)\n  --render              render the environment\n  --vision-observation  use rendered images as observation\n  --image-size SIZE     image size of vision observation (default: 96)\n  --hidden-dims DIM [DIM ...]\n                        hidden dimensions of FC controller\n  --activation {ReLU,LeakyReLU}\n                        activation function in controller networks (default:\n                        ReLU)\n  --max-episode-steps MAX_EPISODE_STEPS\n                        max steps per episode (default: 10000)\n  --n-epochs N_EPOCHS   number of training epochs (default: 1000)\n  --n-episodes N_EPISODES\n                        number of test episodes (default: 100)\n  --n-updates N_UPDATES\n                        number of learning updates per epoch (default: 256)\n  --batch-size BATCH_SIZE\n                        batch size (default: 256)\n  --n-samplers N_SAMPLERS\n                        number of parallel samplers (default: 4)\n  --buffer-capacity CAPACITY\n                        capacity of replay buffer (default: 1000000)\n  --update-sample-ratio RATIO\n                        speed ratio of training and sampling (sample speed <=\n                        training speed / ratio (ratio should be larger than\n                        1.0)) (default: 2.0)\n  --gamma GAMMA         discount factor for rewards (default: 0.99)\n  --soft-tau TAU        soft update factor for target networks (default: 0.01)\n  --normalize-rewards   normalize rewards for training\n  --reward-scale SCALE  reward scale factor for normalized rewards (default:\n                        1.0)\n  --deterministic       deterministic in evaluation\n  --weight-decay WEIGHT_DECAY\n                        weight decay (default: 0.0)\n  --clip-gradient       clip gradient on optimizer step\n  --random-seed SEED    random seed (default: 0)\n  --log-episode-video   save rendered episode videos to TensorBoard logs\n  --log-dir LOG_DIR     folder to save TensorBoard logs\n  --checkpoint-dir CHECKPOINT_DIR\n                        folder to save checkpoint\n  --load-checkpoint     load latest checkpoint in checkpoint dir\n\nstate encoder:\n  --encoder-arch {FC,RNN,CNN}\n                        architecture of state encoder network (default: FC)\n  --state-dim DIM       target state dimension of encoded state (use\n                        env.observation_space.shape if not present)\n  --encoder-activation ACTIVATION\n                        activation function in state encoder networks (use\n                        activation function in controller if not present)\n\nFC state encoder:\n  --encoder-hidden-dims DIM [DIM ...]\n                        hidden dimensions of FC state encoder\n\nRNN state encoder:\n  --encoder-hidden-dims-before-rnn DIM [DIM ...]\n                        hidden FC dimensions before GRU layers in RNN state\n                        encoder\n  --encoder-hidden-dims-rnn DIM [DIM ...]\n                        GRU hidden dimensions of RNN state encoder\n  --encoder-hidden-dims-after-rnn DIM [DIM ...]\n                        hidden FC dimensions after GRU layers in RNN state\n                        encoder\n  --skip-connection     add skip connection beside GRU layers in RNN state\n                        encoder\n  --trainable-hidden    set initial hidden of GRU layers trainable (use zeros\n                        as initial hidden if not present)\n  --step-size STEP_SIZE\n                        number of continuous steps for update (default: 16)\n\nCNN state encoder:\n  --encoder-hidden-channels CHN [CHN ...]\n                        channels of hidden conv layers in CNN state encoder\n  --kernel-sizes K [K ...]\n                        kernel sizes of conv layers in CNN state encoder\n                        (defaults: 3)\n  --strides S [S ...]   strides of conv layers in CNN state encoder (defaults:\n                        1)\n  --paddings P [P ...]  paddings of conv layers in CNN state encoder\n                        (defaults: K // 2)\n  --poolings K [K ...]  max pooling kernel size after activation function in\n                        CNN state encoder (defaults: 1)\n  --batch-normalization\n                        use batch normalization in CNN state encoder\n\nlearning rate:\n  --lr LR               learning rate (can be override by the following\n                        specific learning rate) (default: 0.0001)\n  --critic-lr CRITIC_LR\n                        learning rate for critic networks (use LR above if not\n                        present)\n  --actor-lr ACTOR_LR   learning rate for actor networks (use LR above if not\n                        present)\n\ntemperature parameter:\n  --alpha-lr ALPHA_LR   learning rate for temperature parameter (use ACTOR_LR\n                        above if not present)\n  --initial-alpha ALPHA\n                        initial value of temperature parameter (default: 1.0)\n  --adaptive-entropy    auto update temperature parameter while training\n```\n",
      "technique": "Header extraction"
    }
  ]
}
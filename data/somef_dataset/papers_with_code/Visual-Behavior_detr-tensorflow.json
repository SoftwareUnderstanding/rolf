{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The pretrained weights of this models are originaly provide from the Facebook repository https://github.com/facebookresearch/detr and made avaiable in tensorflow in this repository: https://github.com/Leonardo-Blanger/detr_tensorflow\n",
      "technique": "Header extraction"
    }
  ],
  "citation": [
    {
      "confidence": [
        0.9977994744046882,
        0.9422100272984922
      ],
      "excerpt": "<b>DETR paper:</b> https://arxiv.org/pdf/2005.12872.pdf <br> \n<b>Torch implementation: https://github.com/facebookresearch/detr</b> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.952778942845146
      ],
      "excerpt": "   box | 36.53 | 55.38 | 53.13 | 50.46 | 47.11 | 43.07 | 38.11 | 32.10 | 25.01 | 16.20 |  4.77 | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Visual-Behavior/detr-tensorflow",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-12-15T04:55:08Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-15T02:43:14Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9964869713045316
      ],
      "excerpt": "Tensorflow implementation of DETR : Object Detection with Transformers, including code for inference, training, and finetuning. DETR is a promising model that brings widely adopted transformers to vision models. We believe that models based on convolution and transformers will soon become the default choice for most practitioners because of the simplicity of the training procedure: NMS and anchors free! Therefore this repository is a step toward making this type of architecture widely available.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9819473181546504,
        0.931972973802832
      ],
      "excerpt": "<b>About this implementation:</b> This repository includes codes to run an inference with the original model's weights (based on the PyTorch weights), to train the model from scratch (multi-GPU training support coming soon) as well as examples to finetune the model on your dataset. Unlike the PyTorch implementation, the training uses fixed image sizes and a standard Adam optimizer with gradient norm clipping. \nAdditionally, our logging system is based on https://www.wandb.com/ so that you can get a great visualization of your model performance! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9850521457582084
      ],
      "excerpt": "This repository currently supports three dataset formats: COCO, VOC, and Tensorflow Object detection csv. The easiest way to get started is to set up your dataset based on one of these formats. Along with the datasets, we provide a code example to finetune your model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8835366577992327,
        0.9058707639884793
      ],
      "excerpt": "- img_dir is the image folder relative to the data_dir \n- ann_file is the validation annotation file relative to the data_dir \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9023323925509442,
        0.9447365870614627
      ],
      "excerpt": "The result is not the same as reported in the paper because the evaluation is run on the <b>original image size</b> and not on the larger images. The actual implementation resizes the image so that the shorter side is at least 800pixels and the longer side at most 1333. \nTo fine-tune the model on a new dataset we siply need to set the number of class to detect in our new dataset (nb_class). The method will remove the last layers that predict the box class&positions and add new layers to finetune. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9848632630873045
      ],
      "excerpt": "The following commands gives some examples to finetune the model on new datasets:  (Pacal VOC) and (The Hard hat dataset), with a realbatch_sizeof 8 and a virtualtarget_batchsize (gradient aggregate) of 32.--log``` is used for logging the training into wandb.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8835366577992327,
        0.9058707639884793
      ],
      "excerpt": "img_dir is the image folder relative to the data_dir \nann_file is the validation annotation file relative to the data_dir \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9832982110823472
      ],
      "excerpt": "Here is an example of running an inference with the model on your webcam. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Tensorflow implementation of DETR : Object Detection with Transformers",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Visual-Behavior/detr-tensorflow/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 25,
      "date": "Thu, 23 Dec 2021 16:25:26 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Visual-Behavior/detr-tensorflow/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Visual-Behavior/detr-tensorflow",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Visual-Behavior/detr-tensorflow/main/notebooks/How%20to%20load%20a%20dataset.ipynb",
      "https://raw.githubusercontent.com/Visual-Behavior/detr-tensorflow/main/notebooks/DETR%20Tensorflow%20-%20%20How%20to%20setup%20a%20custom%20dataset.ipynb",
      "https://raw.githubusercontent.com/Visual-Behavior/detr-tensorflow/main/notebooks/DETR%20Tensorflow%20-%20%20Finetuning%20tutorial.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The code has been currently tested with Tensorflow 2.3.0 and python 3.7. The following dependencies are required.\n\n\n```\nwandb\nmatplotlib\nnumpy\npycocotools\nscikit-image\nimageio\npandas\n```\n\n```\npip install -r requirements.txt\n```\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.999833231880651
      ],
      "excerpt": "1. Install \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8606584110637878
      ],
      "excerpt": "- data_dir is your coco dataset folder \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8214473929351954
      ],
      "excerpt": "python train_coco.py --data_dir /path/to/COCO --batch_size 8  --target_batch 32 --log \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": "5. Training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8678660373116779
      ],
      "excerpt": "<img src=\"images/detr-figure.png\"></img> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8536753758407865
      ],
      "excerpt": "<img src=\"images/wandb_logging.png\"></img> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8536753758407865
      ],
      "excerpt": "<img src=\"images/datasetsupport.png\"></img> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8468329775767071
      ],
      "excerpt": "python eval.py --data_dir /path/to/coco/dataset --img_dir val2017 --ann_file annotations/instances_val2017.json \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8237576424847335
      ],
      "excerpt": ": Load the pretrained model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8263816105918765
      ],
      "excerpt": "train_dt, class_names = load_tfcsv_dataset(config, config.batch_size, augmentation=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589658548129034
      ],
      "excerpt": ": Train the model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8477047239742574
      ],
      "excerpt": "python finetune_voc.py --data_dir /home/thibault/data/VOCdevkit/VOC2012 --img_dir JPEGImages --ann_dir Annotations --batch_size 8 --target_batch 32  --log \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.836365334782609
      ],
      "excerpt": "- img_dir and  ann_file set in the training file to load the training and validation differently \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233587553072689
      ],
      "excerpt": "python  finetune_hardhat.py --data_dir /home/thibault/data/hardhat --batch_size 8 --target_batch 32 --log \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.836365334782609
      ],
      "excerpt": "img_dir and  ann_file set in the training file to load the training and validation differently. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Visual-Behavior/detr-tensorflow/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Visual-Behavior\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "DETR : End-to-End Object Detection with Transformers (Tensorflow)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "detr-tensorflow",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Visual-Behavior",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Visual-Behavior/detr-tensorflow/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 90,
      "date": "Thu, 23 Dec 2021 16:25:26 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To get started with the repository you can check the following Jupyter notebooks:\n\n- \u270d [DETR Tensorflow - How to load a dataset.ipynb](https://github.com/Visual-Behavior/detr-tensorflow/blob/main/notebooks/How%20to%20load%20a%20dataset.ipynb)\n- \u270d [DETR Tensorflow - Finetuning tutorial.ipynb](https://github.com/Visual-Behavior/detr-tensorflow/blob/main/notebooks/DETR%20Tensorflow%20-%20%20Finetuning%20tutorial.ipynb)\n- \u270d [DETR Tensorflow - How to setup a custom dataset.ipynb](https://github.com/Visual-Behavior/detr-tensorflow/blob/main/notebooks/DETR%20Tensorflow%20-%20%20How%20to%20setup%20a%20custom%20dataset.ipynb)\n\nAs well as the logging board on wandb https://wandb.ai/thibault-neveu/detr-tensorflow-log and this report:\n\n- \ud83d\ude80 [Finetuning DETR on Tensorflow - A step by step guide](https://wandb.ai/thibault-neveu/detr-tensorflow-log/reports/Finetuning-DETR-on-Tensorflow-A-step-by-step-tutorial--VmlldzozOTYyNzQ)\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1706.03762"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8554783700051872
      ],
      "excerpt": "Results on dev set (averages on 10 runs except contex multi (best run)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8944178096468923
      ],
      "excerpt": "| Video - 3DCNN   | 0.236  | 0.141 | 0.189 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8944178096468923
      ],
      "excerpt": "| Video  |   |  | 0.227 | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jbdel/OMG_UMONS_submission",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-04-30T23:54:30Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-08T09:30:34Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8198647891176012,
        0.9291557553382854,
        0.862321742769449,
        0.9503800612127444
      ],
      "excerpt": "Monomodal features (linguisitic, visual and acoustic) are firstly extracted utterance wise. \nPlease refer to the text_cnn folder for linguistic features extraction, to the video_model folder for visual features and to the audio_model folder for acoustic features extraction. \nA new contextual model predicts the arousal and valence per video, for each utterance of the video \nThe model learns to take into account the context of an utterances (the preceding and following ones) before prediction. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9802029164807396
      ],
      "excerpt": "The architecture of this model is exactly the same of level 2, but each modality features are concatenated per utterance.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9627487715650112
      ],
      "excerpt": "| Text - CNN   | 0.078  | 0.25 | 0.165  | \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jbdel/OMG_UMONS_submission/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Wed, 29 Dec 2021 07:38:37 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/jbdel/OMG_UMONS_submission/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "jbdel/OMG_UMONS_submission",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/jbdel/OMG_UMONS_submission/master/context/compact-bilinear-pooling-tf/build.sh"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "| Text   |   | | 0.220  | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/jbdel/OMG_UMONS_submission/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C++",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "OMG_UMONS_submission",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "OMG_UMONS_submission",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "jbdel",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jbdel/OMG_UMONS_submission/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Python 3.4+\n* Tensorflow 1.4+\n\nThis github host the code to replicate the experiment of the UMONS team for the OMG Emotion Challenge.\n\nThis contribution is composed of three levels.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Wed, 29 Dec 2021 07:38:37 GMT"
    },
    "technique": "GitHub API"
  }
}
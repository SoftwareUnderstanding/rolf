{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We refered to\n* [FastSpeech2](https://arxiv.org/abs/2006.04558)\n* [ming024's FastSpeech implementation](https://github.com/ming024/FastSpeech2)\n* [Mellotron](https://github.com/NVIDIA/mellotron)\n* [Tacotron](https://github.com/keithito/tacotron)\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2106.03153",
      "https://arxiv.org/abs/2006.04558"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9255925309608671
      ],
      "excerpt": "./montreal-forced-aligner/bin/mfa_align dataset/wav16/ lexicon/librispeech-lexicon.txt  english datset/TextGrid/ -j 10 -v \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KevinMIN95/StyleSpeech",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-11T16:44:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-27T07:02:04Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8521614201444576
      ],
      "excerpt": ":sparkles: Thanks Guan-Ting Lin for sharing the pre-trained multi-speaker MelGAN vocoder in 16kHz, and the checkpoint is now available in Pre-trained 16k-MelGAN. For the usage details, please follow the instructions in MelGAN. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9577346912666332,
        0.9765690206421542
      ],
      "excerpt": "Few modifications on the Variance Adaptor wich were found to improve the quality of the model . 1) We replace the architecture of variance emdedding from one Conv1D layer to two Conv1D layers followed by a linear layer. 2) We add a layernorm and phoneme-wise positional encoding. Please refer to here. \nThis is an official code for our recent paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9745852857742432
      ],
      "excerpt": "We provide our implementation and pretrained models as open source in this repository. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9956434401186448
      ],
      "excerpt": "With rapid progress in neural text-to-speech (TTS) models, personalized speech generation is now in high demand for many applications. For practical applicability, a TTS model should generate high-quality speech with only a few audio samples from the given speaker, that are also short in length. However, existing methods either require to fine-tune the model or achieve low adaptation quality without fine-tuning. In this work, we propose StyleSpeech, a new TTS model which not only synthesizes high-quality speech but also effectively adapts to new speakers. Specifically, we propose Style-Adaptive Layer Normalization (SALN) which aligns gain and bias of the text input according to the style extracted from a reference speech audio. With SALN, our model effectively synthesizes speech in the style of the target speaker even from single speech audio. Furthermore, to enhance StyleSpeech's adaptation to speech from new speakers, we extend it to Meta-StyleSpeech by introducing two discriminators trained with style prototypes, and performing episodic training. The experimental results show that our models generate high-quality speech which accurately follows the speaker's voice with single short-duration (1-3 sec) speech audio, significantly outperforming baselines. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9637816076891397
      ],
      "excerpt": "| Model | Link to the model |  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9882558467340693,
        0.9424413859462989
      ],
      "excerpt": "to resample audios to 16kHz and for some other preperations. \nSecond, Montreal Forced Aligner (MFA) is used to obtain the alignments between the utterances and the phoneme sequences. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Official implementation of Meta-StyleSpeech and StyleSpeech",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KevinMIN95/StyleSpeech/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 19,
      "date": "Wed, 29 Dec 2021 04:42:29 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/KevinMIN95/StyleSpeech/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "KevinMIN95/StyleSpeech",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9672974656675488
      ],
      "excerpt": "Install python requirements. Please refer requirements.txt \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.811152276898926
      ],
      "excerpt": "Getting the pretrained models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8379134294280923
      ],
      "excerpt": "Our models are trained on LibriTTS dataset. Download, extract and place it in the dataset/ folder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8898963314049357
      ],
      "excerpt": "First, run  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python prepare_align.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.842178483577427
      ],
      "excerpt": "./montreal-forced-aligner/bin/mfa_align dataset/wav16/ lexicon/librispeech-lexicon.txt  english datset/TextGrid/ -j 10 -v \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python preprocess.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503189345333785,
        0.8852115710246338
      ],
      "excerpt": "python train.py \nTrain the Meta-StyleSpeech from pretrained StyleSpeech with \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/KevinMIN95/StyleSpeech/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 min95\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "StyleSpeech",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "KevinMIN95",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KevinMIN95/StyleSpeech/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 93,
      "date": "Wed, 29 Dec 2021 04:42:29 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "stylespeech",
      "meta-stylespeech",
      "official",
      "tts",
      "meta-learning",
      "text-to-speech",
      "neural-tts"
    ],
    "technique": "GitHub API"
  }
}
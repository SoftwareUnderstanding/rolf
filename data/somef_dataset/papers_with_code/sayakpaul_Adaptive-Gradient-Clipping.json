{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "I referred to the following resources during experimentation:\n* [Original JAX implementation of AGC](https://github.com/deepmind/deepmind-research/blob/master/nfnets/agc_optax.py) provided by the authors. \n* [Ross Wightman's implementation og AGC](https://github.com/rwightman/pytorch-image-models/blob/master/timm/utils/agc.py).\n* [Fast and Lean Data Science materials](https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/fast-and-lean-data-science) provided by GCP. \n",
      "technique": "Header extraction"
    }
  ],
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] Brock, Andrew, et al. \u201cHigh-Performance Large-Scale Image Recognition Without Normalization.\u201d ArXiv:2102.06171 [Cs, Stat], Feb. 2021. arXiv.org, http://arxiv.org/abs/2102.06171.\n\n[2] Ioffe, Sergey, and Christian Szegedy. \u201cBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.\u201d ArXiv:1502.03167 [Cs], Mar. 2015. arXiv.org, http://arxiv.org/abs/1502.03167.\n\n[3] Simonyan, Karen, and Andrew Zisserman. \u201cVery Deep Convolutional Networks for Large-Scale Image Recognition.\u201d ArXiv:1409.1556 [Cs], Apr. 2015. arXiv.org, http://arxiv.org/abs/1409.1556.\n\n[4] He, Kaiming, et al. \u201cDeep Residual Learning for Image Recognition.\u201d ArXiv:1512.03385 [Cs], Dec. 2015. arXiv.org, http://arxiv.org/abs/1512.03385.\n\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sayakpaul/Adaptive-Gradient-Clipping",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-02-18T04:39:11Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-12T18:33:54Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8991165655740406,
        0.9607557468081701,
        0.8434807506310213,
        0.8274836393615161,
        0.9639909783207209,
        0.9069619541358077,
        0.9425305531773516,
        0.9056377028792211
      ],
      "excerpt": "This repository provides a minimal implementation of adaptive gradient clipping (AGC) (as proposed in High-Performance Large-Scale Image Recognition Without Normalization<sup>1</sup>) in TensorFlow 2. The paper attributes AGC as a crucial component in order to train deep neural networks without batch normalization<sup>2</sup>. Readers are encouraged to consult the paper to understand why one might want to train networks without batch normalization given its paramount success.  \nMy goal with this repository is to be able to quickly train shallow networks with and without AGC. Therefore, I provide two Colab Notebooks which I discuss below. \nAGC.ipynb: Demonstrates training of a shallow network (only 0.002117 million parameters) with AGC.  \nBatchNorm.ipynb: Demonstrates training of a shallow network (only 0.002309 million parameters) with batch normalization.  \nBoth of these notebooks are end-to-end executable on Google Colab. Furthermore, they utilize the free TPUs (TPUv2-8) Google Colab provides allowing readers to experiment very quickly. \nBefore moving to the findings, please be aware of the following things: \n* The network I have used in order to demonstrate the results is extremely shallow. \n* The network is a mini VGG<sup>3</sup> style network whereas the original paper focuses on ResNet<sup>4</sup> style architectures.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9611080209473172,
        0.9746652844627771
      ],
      "excerpt": "* I clipped gradients of all the layers whereas in the original paper final linear layer wasn't clipped (refer to Section 4.1 of the original paper). \nBy comparing the training progress of two networks (trained with and without AGC), we see that with AGC network training is more stabilized. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8852179741940607
      ],
      "excerpt": "In the table below, I summarize results of the two aforementioned notebooks -  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Minimal implementation of adaptive gradient clipping (https://arxiv.org/abs/2102.06171) in TensorFlow 2. ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sayakpaul/Adaptive-Gradient-Clipping/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Fri, 24 Dec 2021 20:46:42 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sayakpaul/Adaptive-Gradient-Clipping/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "sayakpaul/Adaptive-Gradient-Clipping",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/sayakpaul/Adaptive-Gradient-Clipping/main/AGC.ipynb",
      "https://raw.githubusercontent.com/sayakpaul/Adaptive-Gradient-Clipping/main/BatchNorm.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sayakpaul/Adaptive-Gradient-Clipping/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Sayak Paul\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Adaptive-Gradient-Clipping",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Adaptive-Gradient-Clipping",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "sayakpaul",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sayakpaul/Adaptive-Gradient-Clipping/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 64,
      "date": "Fri, 24 Dec 2021 20:46:42 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "tensorflow2",
      "computer-vision",
      "deep-neural-networks",
      "normalization-free-training",
      "colab-notebook"
    ],
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1512.03385"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "   1-[transfer learning tutorial on pytorch](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html)\n   \n   2- [transfer learning tutorial](https://ruder.io/transfer-learning/)\n   \n   3- [implemnted CNN overview](https://medium.com/@sidereal/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5)\n   \n   4- [transfer learning tutorial on github](http://cs231n.github.io/transfer-learning/)\n      \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9943620222923303,
        0.95073913422319
      ],
      "excerpt": "refer - CS231n Convolutional NEural Network for Visual Recognition  \n      - Transfer Learning - Machine Learning's Next Frontier \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9666746817099406
      ],
      "excerpt": "ILSVRC 2015, the so-called Residual Neural Network (ResNet) by Kaiming He et al introduced  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/EdenMelaku/Transfer-Learning-Pytorch-Implementation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-02-18T09:19:33Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-12T15:52:28Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8872090135167648,
        0.9873624737663566
      ],
      "excerpt": "Transfer learning in torchvision implemtation with different models \nTransfer learning is the improvement of learning in a new \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9409326483708925,
        0.9699873343346092
      ],
      "excerpt": "to address single tasks, the development of algorithms that facilitate \ntransfer learning is a topic of ongoing interest in the machine-learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9974947082450212,
        0.9566293972029346,
        0.9305084546021439
      ],
      "excerpt": "Fine tuning - starts with a pretrained model and update all of the model\u2019s parameters for our new task,  \nin essence retraining the whole model.  \nFeature extraction- starts with a pretrained model and only update the final layer weights from which we derive predictions. It is called feature extraction  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8732449432234102
      ],
      "excerpt": "In 2012, AlexNet significantly outperformed all the prior competitors and won the challenge by reducing the top-5 error from 26% to 15.3%. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156839787876156,
        0.9873376005625728
      ],
      "excerpt": "The runner-up at the ILSVRC 2014 competition is dubbed VGGNet by the community and was developed by Simonyan and Zisserman . VGGNet consists of 16 convolutional layers and is very appealing because of its very uniform architecture.  \nSimilar to AlexNet, only 3x3 convolutions, but lots of filters. Trained on 4 GPUs for 2\u20133 weeks. see VGGNet document \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8624343732015741,
        0.9228913402534232,
        0.9208909676188753
      ],
      "excerpt": "anovel architecture with \u201cskip connections\u201d and features heavy batch normalization.They were able to train a NN with 152 layers while still having lower complexity than VGGNet.  \nIt achieves a top-5 error rate of 3.57% which beats human-level performance on this dataset. see ResNet document \nThe MNIST dataset is one of the most common datasets used for image classification and accessible from many different sources. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Hand written digit recognition implementation with different models",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/EdenMelaku/Transfer-Learning-Pytorch-Implementation/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Tue, 28 Dec 2021 14:30:30 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/EdenMelaku/Transfer-Learning-Pytorch-Implementation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "EdenMelaku/Transfer-Learning-Pytorch-Implementation",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8721525353375978
      ],
      "excerpt": "cd feature\\ extraction \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8721525353375978
      ],
      "excerpt": "cd feature\\ extraction \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8964040436076102
      ],
      "excerpt": "                 cd  fine\\ tuning \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "                 python3 minst_alexnet.py --dataFolder /temp/mnist_png \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "                 python3 minst_vgg.py --dataFolder /temp/mnist_png \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "                 python3 minstDataset+AlexNet.py --dataFolder /temp/mnist_png \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/EdenMelaku/Transfer-Learning-Pytorch-Implementation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Transfer-Learning-Pytorch-Implmentation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Transfer-Learning-Pytorch-Implementation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "EdenMelaku",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/EdenMelaku/Transfer-Learning-Pytorch-Implementation/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "EdenMelaku",
        "body": "",
        "dateCreated": "2019-11-14T09:53:15Z",
        "datePublished": "2020-01-08T04:34:30Z",
        "html_url": "https://github.com/EdenMelaku/Transfer-Learning-Pytorch-Implementation/releases/tag/1.0",
        "name": "Initial version",
        "tag_name": "1.0",
        "tarball_url": "https://api.github.com/repos/EdenMelaku/Transfer-Learning-Pytorch-Implementation/tarball/1.0",
        "url": "https://api.github.com/repos/EdenMelaku/Transfer-Learning-Pytorch-Implementation/releases/22666985",
        "zipball_url": "https://api.github.com/repos/EdenMelaku/Transfer-Learning-Pytorch-Implementation/zipball/1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": " \n you can run examples to test your trained model. you can either run testing.py (takes image and checkpoint path as an argument and predict number) or you can run demo_server.py to launch a flask server and takes base64 encoded image and sends predicted number back to the client. you can check my other repository [my github repository for client side android app](https://github.com/EdenMelaku/minstAndroidDemo) it has client side android implmentation for this project. \n \n if you haven't trained a model. you can download and use my model ...\n ```\n curl https://doc-0g-1o-docs.googleusercontent.com/docs/securesc/usnus0qm8arnkgli0kgnss8m1j9mdqcb/28ma8ier12pd2297c8rbd9p79vq87e7f/1551182400000/01693330806149924406/01693330806149924406/1uxdJON0MWQmJBTficbJieCSs4GqDzrHO?e=download&nonce=5ng79ccnfh33u&user=01693330806149924406&hash=dk4kufrkkn2koo89s0f5n3ej3kp9cjpf              \n```\nRunning example\n```\n                 cd  feature\\ extraction\n                 python3 testing.py --checkpoint /modelAlexNet.pth  --image photo.jpeg \n              \n```\nlaunching demo server \n```\n                 cd  feature\\ extraction\n                 python3 demo_server.py --checkpoint /modelAlexNet.pth \n              \n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Tue, 28 Dec 2021 14:30:30 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": " \n 1- **install python3** \n \n 2- **install requirements**:\n  ```\n  pip install -r requirements.txt\n  ```\n   \n 3- **Download and Extract dataset**:\n ```\ncurl https://raw.githubusercontent.com/EdenMelaku/Transfer-Learning-Pytorch-Implmentation/master/mnist_png.tar.gz | tar xzC /temp\n ```\n   \n ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": " \n ",
      "technique": "Header extraction"
    }
  ]
}
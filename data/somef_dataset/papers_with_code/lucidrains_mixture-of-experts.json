{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2006.16668\">Mixture of Experts</a>, for massively increasing the capacity (parameter count"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bibtex\n@misc{shazeer2017outrageously,\n    title   = {Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},\n    author  = {Noam Shazeer and Azalia Mirhoseini and Krzysztof Maziarz and Andy Davis and Quoc Le and Geoffrey Hinton and Jeff Dean},\n    year    = {2017},\n    eprint  = {1701.06538},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG}\n}\n```\n\n```bibtex\n@misc{lepikhin2020gshard,\n    title   = {GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding},\n    author  = {Dmitry Lepikhin and HyoukJoong Lee and Yuanzhong Xu and Dehao Chen and Orhan Firat and Yanping Huang and Maxim Krikun and Noam Shazeer and Zhifeng Chen},\n    year    = {2020},\n    eprint  = {2006.16668},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{lepikhin2020gshard,\n    title   = {GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding},\n    author  = {Dmitry Lepikhin and HyoukJoong Lee and Yuanzhong Xu and Dehao Chen and Orhan Firat and Yanping Huang and Maxim Krikun and Noam Shazeer and Zhifeng Chen},\n    year    = {2020},\n    eprint  = {2006.16668},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.CL}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{shazeer2017outrageously,\n    title   = {Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},\n    author  = {Noam Shazeer and Azalia Mirhoseini and Krzysztof Maziarz and Andy Davis and Quoc Le and Geoffrey Hinton and Jeff Dean},\n    year    = {2017},\n    eprint  = {1701.06538},\n    archivePrefix = {arXiv},\n    primaryClass = {cs.LG}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucidrains/mixture-of-experts",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-13T18:23:35Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-28T20:05:22Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.975458923933752
      ],
      "excerpt": "A Pytorch implementation of Sparsely Gated <a href=\"https://arxiv.org/abs/2006.16668\">Mixture of Experts</a>, for massively increasing the capacity (parameter count) of a language model while keeping the computation constant. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A Pytorch implementation of Sparsely-Gated Mixture of Experts, for massively increasing the parameter count of language models",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucidrains/mixture-of-experts/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 21,
      "date": "Thu, 30 Dec 2021 04:40:24 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lucidrains/mixture-of-experts/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "lucidrains/mixture-of-experts",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\n$ pip install mixture_of_experts\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lucidrains/mixture-of-experts/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Phil Wang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Sparsely Gated Mixture of Experts - Pytorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "mixture-of-experts",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "lucidrains",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucidrains/mixture-of-experts/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-12-19T19:39:20Z",
        "datePublished": "2021-12-19T19:39:31Z",
        "html_url": "https://github.com/lucidrains/mixture-of-experts/releases/tag/0.2.1",
        "name": "0.2.1",
        "tag_name": "0.2.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/tarball/0.2.1",
        "url": "https://api.github.com/repos/lucidrains/mixture-of-experts/releases/55630258",
        "zipball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/zipball/0.2.1"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-10-20T22:19:54Z",
        "datePublished": "2020-10-20T22:20:09Z",
        "html_url": "https://github.com/lucidrains/mixture-of-experts/releases/tag/0.2.0",
        "name": "0.2.0",
        "tag_name": "0.2.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/tarball/0.2.0",
        "url": "https://api.github.com/repos/lucidrains/mixture-of-experts/releases/32836773",
        "zipball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/zipball/0.2.0"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-07-17T23:29:30Z",
        "datePublished": "2020-07-17T23:29:51Z",
        "html_url": "https://github.com/lucidrains/mixture-of-experts/releases/tag/0.1.1",
        "name": "0.1.1",
        "tag_name": "0.1.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/tarball/0.1.1",
        "url": "https://api.github.com/repos/lucidrains/mixture-of-experts/releases/28693760",
        "zipball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/zipball/0.1.1"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-07-17T22:59:30Z",
        "datePublished": "2020-07-17T22:59:56Z",
        "html_url": "https://github.com/lucidrains/mixture-of-experts/releases/tag/0.1.0",
        "name": "0.1.0",
        "tag_name": "0.1.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/tarball/0.1.0",
        "url": "https://api.github.com/repos/lucidrains/mixture-of-experts/releases/28693313",
        "zipball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/zipball/0.1.0"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-07-17T21:45:25Z",
        "datePublished": "2020-07-17T21:45:41Z",
        "html_url": "https://github.com/lucidrains/mixture-of-experts/releases/tag/0.0.4",
        "name": "0.0.4",
        "tag_name": "0.0.4",
        "tarball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/tarball/0.0.4",
        "url": "https://api.github.com/repos/lucidrains/mixture-of-experts/releases/28691987",
        "zipball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/zipball/0.0.4"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-07-17T21:33:28Z",
        "datePublished": "2020-07-17T21:33:59Z",
        "html_url": "https://github.com/lucidrains/mixture-of-experts/releases/tag/0.0.3",
        "name": "0.0.3",
        "tag_name": "0.0.3",
        "tarball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/tarball/0.0.3",
        "url": "https://api.github.com/repos/lucidrains/mixture-of-experts/releases/28691775",
        "zipball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/zipball/0.0.3"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-07-17T20:53:41Z",
        "datePublished": "2020-07-17T20:54:32Z",
        "html_url": "https://github.com/lucidrains/mixture-of-experts/releases/tag/0.0.2",
        "name": "0.0.2",
        "tag_name": "0.0.2",
        "tarball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/tarball/0.0.2",
        "url": "https://api.github.com/repos/lucidrains/mixture-of-experts/releases/28690991",
        "zipball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/zipball/0.0.2"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-07-17T00:27:04Z",
        "datePublished": "2020-07-17T00:27:26Z",
        "html_url": "https://github.com/lucidrains/mixture-of-experts/releases/tag/0.0.1",
        "name": "0.0.1",
        "tag_name": "0.0.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/tarball/0.0.1",
        "url": "https://api.github.com/repos/lucidrains/mixture-of-experts/releases/28655945",
        "zipball_url": "https://api.github.com/repos/lucidrains/mixture-of-experts/zipball/0.0.1"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 143,
      "date": "Thu, 30 Dec 2021 04:40:24 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "artificial-intelligence",
      "deep-learning",
      "transformer",
      "mixture-of-experts"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\nimport torch\nfrom torch import nn\nfrom mixture_of_experts import MoE\n\nmoe = MoE(\n    dim = 512,\n    num_experts = 16,               #: increase the experts (#: parameters) of your model without increasing computation\n    hidden_dim = 512 * 4,           #: size of hidden dimension in each expert, defaults to 4 * dimension\n    activation = nn.LeakyReLU,      #: use your preferred activation, will default to GELU\n    second_policy_train = 'random', #: in top_2 gating, policy for whether to use a second-place expert\n    second_policy_eval = 'random',  #: all (always) | none (never) | threshold (if gate value > the given threshold) | random (if gate value > threshold * random_uniform(0, 1))\n    second_threshold_train = 0.2,\n    second_threshold_eval = 0.2,\n    capacity_factor_train = 1.25,   #: experts have fixed capacity per batch. we need some extra capacity in case gating is not perfectly balanced.\n    capacity_factor_eval = 2.,      #: capacity_factor_* should be set to a value >=1\n    loss_coef = 1e-2                #: multiplier on the auxiliary expert balancing auxiliary loss\n)\n\ninputs = torch.randn(4, 1024, 512)\nout, aux_loss = moe(inputs) #: (4, 1024, 512), (1,)\n```\n\nThe above should suffice for a single machine, but if you want a heirarchical mixture of experts (2 levels), as used in the GShard paper, please follow the instructions below\n\n```python\nimport torch\nfrom mixture_of_experts import HeirarchicalMoE\n\nmoe = HeirarchicalMoE(\n    dim = 512,\n    num_experts = (4, 4),       #: 4 gates on the first layer, then 4 experts on the second, equaling 16 experts\n)\n\ninputs = torch.randn(4, 1024, 512)\nout, aux_loss = moe(inputs) #: (4, 1024, 512), (1,)\n```\n\n1 billion parameters\n\n```python\nimport torch\nfrom mixture_of_experts import HeirarchicalMoE\n\nmoe = HeirarchicalMoE(\n    dim = 512,\n    num_experts = (22, 22)\n).cuda()\n\ninputs = torch.randn(1, 1024, 512).cuda()\nout, aux_loss = moe(inputs)\n\ntotal_params = sum(p.numel() for p in moe.parameters())\nprint(f'number of parameters - {total_params}')\n```\n\nIf you want some more sophisticated network for the experts, you can define your own and pass it into the `MoE` class as `experts`\n\n```python\nimport torch\nfrom torch import nn\nfrom mixture_of_experts import MoE\n\n#: a 3 layered MLP as the experts\n\nclass Experts(nn.Module):\n    def __init__(self, dim, num_experts = 16):\n        super().__init__()\n        self.w1 = nn.Parameter(torch.randn(num_experts, dim, dim * 4))\n        self.w2 = nn.Parameter(torch.randn(num_experts, dim * 4, dim * 4))\n        self.w3 = nn.Parameter(torch.randn(num_experts, dim * 4, dim))\n        self.act = nn.LeakyReLU(inplace = True)\n\n    def forward(self, x):\n        hidden1 = self.act(torch.einsum('end,edh->enh', x, self.w1))\n        hidden2 = self.act(torch.einsum('end,edh->enh', hidden1, self.w2))\n        out = torch.einsum('end,edh->enh', hidden2, self.w3)\n        return out\n\nexperts = Experts(512, num_experts = 16)\n\nmoe = MoE(\n    dim = 512,\n    num_experts = 16,\n    experts = experts\n)\n\ninputs = torch.randn(4, 1024, 512)\nout, aux_loss = moe(inputs) #: (4, 1024, 512), (1,)\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
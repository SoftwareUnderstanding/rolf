{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1502.01852",
      "https://arxiv.org/abs/2003.02570\n| Project page | TBA\n| Notebooks to reproduce experiments | [Link Notebooks](./notebooks"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9104388306336967,
        0.9860655120770058,
        0.9781574687631479,
        0.9860655120770058,
        0.9860655120770058,
        0.9985319060770389,
        0.9572487334023723,
        0.9860655120770058
      ],
      "excerpt": "    | Conv7      | 99.72%| 0%   | 1200|   MNIST |     5.1 | He Uniform  | \n    | Conv2      | 78.21%| 0%   | 1000| CIFAR-10|5.2, 5.4 | He Uniform  | \n    | Conv4      | 89.17%| 0%   | 1000| CIFAR-10|5.2, 5.4 | He Uniform  | \n    | Conv13     | 92.21%| 0%   | 1000| CIFAR-10|5.2, 5.4 | He Uniform  | \n    | ResNet50   | 92.53%| 0%   |  400| CIFAR-10|     5.4 | He Uniform  | \n    | ResNet50   | 92.32%| 30%  |  800| CIFAR-10|     5.4 | He Uniform  | \n    | ResNet50   | 92.02%| 50%  |  800| CIFAR-10|     5.4 | He Uniform  | \n    | ResNet50   | 90.97%| 70%  |  800| CIFAR-10|     5.4 | He Uniform  | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999961633757182
      ],
      "excerpt": "    - He Uniform: [He et al. 2015](https://arxiv.org/abs/1502.01852) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8910854798347893
      ],
      "excerpt": "- Datasets: [MNIST](http://yann.lecun.com/exdb/mnist/), [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "| Paper PDF | https://arxiv.org/abs/2003.02570 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9553055233818778,
        0.8944178096468923
      ],
      "excerpt": "| Source code | Link Github \n| Summary video | TBA \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ihsuy/Train-by-Reconnect",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-10-22T14:30:17Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-09T14:52:26Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8760233921896837
      ],
      "excerpt": "This repository contains the official code for the NeurIPS 2020 paper Train by Reconnect: Decoupling Locations of Weights from Their Values by Yushi Qiu and Reiji Suda. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9966474696551649,
        0.9960595498346474,
        0.9343743610090615,
        0.873551644797475
      ],
      "excerpt": "The University of Tokyo \nAbstract: What makes untrained deep neural networks (DNNs) different from the trained performant ones? By zooming into the weights in well-trained DNNs, we found that it is the location of weights that holds most of the information encoded by the training. Motivated by this observation, we hypothesized that weights in DNNs trained using stochastic gradient-based methods can be separated into two dimensions: the location of weights, and their exact values. To assess our hypothesis, we propose a novel method called lookahead permutation (LaPerm) to train DNNs by reconnecting the weights. We empirically demonstrate LaPerm's versatility while producing extensive evidence to support our hypothesis: when the initial weights are random and dense, our method demonstrates speed and performance similar to or better than that of regular optimizers, e.g., Adam. When the initial weights are random and sparse (many zeros), our method changes the way neurons connect, achieving accuracy comparable to that of a well-trained dense network. When the initial weights share a single value, our method finds a weight agnostic neural network with far-better-than-chance accuracy. \nThis repository contains the following contents: \n- train_by_reconnect: minimum code for reproducing main results mentioned in the paper. The code is commented and accompanied with working examples in notebooks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9414907742546436
      ],
      "excerpt": "        - LaPerm: Tensorflow implementation of LaPerm (Section 4). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.893291951214606,
        0.9302287581602335
      ],
      "excerpt": "        - agnosticize: Replace the weights in a model with a single shared value. (Section 5.5) \n        - random_prune: Randomly prune the model. (Section 5.4) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8506886698566595
      ],
      "excerpt": "        - PermutationTracer: Visualize and trace how the locations of weights has changed.      \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8190272079458116
      ],
      "excerpt": "- ***p%***: Percentage of weights that are randomly pruned before training, e.g., *p*=10% meaning 90% of weights are remained non-zero. (Section 5.4) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9619275668283628,
        0.8296019020207392
      ],
      "excerpt": "Define the model as demonstrated in the notebook. \nLoad the weights to model by \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.9694802929823498
      ],
      "excerpt": "    model.load_weights('../pretrained/Conv7.h5') \nAll material related to our paper is available via the following links: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9097969617726637
      ],
      "excerpt": "| Project page | TBA \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Official code for the NeurIPS 2020 paper Train by Reconnect: Decoupling Locations of Weights from Their Values by Yushi Qiu and Reiji Suda.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ihsuy/Train-by-Reconnect/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 27 Dec 2021 17:46:53 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ihsuy/Train-by-Reconnect/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ihsuy/Train-by-Reconnect",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ihsuy/Train-by-Reconnect/main/notebooks/ResNet50.ipynb",
      "https://raw.githubusercontent.com/ihsuy/Train-by-Reconnect/main/notebooks/Conv4.ipynb",
      "https://raw.githubusercontent.com/ihsuy/Train-by-Reconnect/main/notebooks/F1_and_F2.ipynb",
      "https://raw.githubusercontent.com/ihsuy/Train-by-Reconnect/main/notebooks/Conv2.ipynb",
      "https://raw.githubusercontent.com/ihsuy/Train-by-Reconnect/main/notebooks/Conv7.ipynb",
      "https://raw.githubusercontent.com/ihsuy/Train-by-Reconnect/main/notebooks/Conv13.ipynb",
      "https://raw.githubusercontent.com/ihsuy/Train-by-Reconnect/main/notebooks/Weight_profiles.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "    python \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8265834143699058
      ],
      "excerpt": "| Source code | Link Github \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8483121504834136
      ],
      "excerpt": "  <img src=\"https://github.com/ihsuy/Train-by-Reconnect/blob/main/Images/perm4.gif?raw=true\" height=\"230\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    - LaPerm.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "    - weight_utils.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991,
        0.8319532207227169
      ],
      "excerpt": "    - viz_utiles.py \n        - Profiler: Plot weight profiles for a given model. (Section 2) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8282633617843045
      ],
      "excerpt": "    model.load_weights('../pretrained/Conv7.h5') \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ihsuy/Train-by-Reconnect/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Yushi Qiu\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Train by Reconnect: Decoupling Locations of Weights from Their Values",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Train-by-Reconnect",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ihsuy",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ihsuy/Train-by-Reconnect/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Code in this repository requires:\n- Python 3.6 or higher\n- Tensorflow v2.1.0 or higher\nand the requirements highlighted in [requirements.txt](./requirements.txt)\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Mon, 27 Dec 2021 17:46:53 GMT"
    },
    "technique": "GitHub API"
  }
}
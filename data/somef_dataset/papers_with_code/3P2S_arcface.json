{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1801.07698",
      "https://arxiv.org/abs/1801.07698",
      "https://arxiv.org/abs/1512.03385",
      "https://arxiv.org/abs/1801.07698",
      "https://arxiv.org/abs/1801.04381",
      "https://arxiv.org/abs/1801.07698",
      "https://arxiv.org/abs/1512.03385",
      "https://arxiv.org/abs/1801.07698",
      "https://arxiv.org/abs/1801.04381",
      "https://arxiv.org/abs/1801.07698"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Thanks for these source codes porviding me with knowledges to complete this repository.\n\n- https://github.com/deepinsight/insightface (Official)\n    - Face Analysis Project on MXNet http://insightface.ai\n- https://github.com/zzh8829/yolov3-tf2\n    - YoloV3 Implemented in TensorFlow 2.0\n- https://github.com/ZhaoJ9014/face.evoLVe.PyTorch\n    - face.evoLVe: High-Performance Face Recognition Library based on PyTorch\n- https://github.com/luckycallor/InsightFace-tensorflow\n    - Tensoflow implementation of InsightFace (ArcFace: Additive Angular Margin Loss for Deep Face Recognition).\n- https://github.com/dmonterom/face_recognition_TF2\n    - Training a face Recognizer using ResNet50 + ArcFace in TensorFlow 2.0\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9521604751129622
      ],
      "excerpt": "Original Paper: &nbsp; Arxiv &nbsp; CVPR2019 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/3P2S/arcface",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-04T02:25:02Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-04T09:51:01Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8743374787689624,
        0.9702200492773748
      ],
      "excerpt": ":fire: ArcFace (Additive Angular Margin Loss for Deep Face Recognition, published in CVPR 2019) implemented in Tensorflow 2.0+. This is an unofficial implementation. :fire: \nAdditive Angular Margin Loss(ArcFace) has a clear geometric interpretation due to the exact correspondence to the geodesic distance on the hypersphere, and consistently outperforms the state-of-the-art and can be easily implemented with negligible computational overhead. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "Data Preparing \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8179619458099548
      ],
      "excerpt": ": Binary Image: convert really slow, but loading faster when traning. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.935043939647535
      ],
      "excerpt": "head_type: ArcHead #: or 'NormHead': FC to targets. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9164702277426373
      ],
      "excerpt": "train_dataset: './data/ms1m_bin.tfrecord' #: or './data/ms1m.tfrecord' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233741740337305,
        0.908733562838046,
        0.8322211584008948,
        0.9688954084487127,
        0.8646782111036414
      ],
      "excerpt": "- The sub_name is the name of outputs directory used in checkpoints and logs folder. (make sure of setting it unique to other models) \n- The head_type is used to choose ArcFace head or normal fully connected layer head for classification in training. (see more detail in ./modules/models.py) \n- The is_ccrop means doing central-cropping on both trainging and testing data or not. \n- The binary_img is used to choose the type of training data, which should be according to the data type you created in the Data-Preparing. \nHere have two modes for training your model, which should be perform the same results at the end. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.918710271024835
      ],
      "excerpt": ": traning with tf.GradientTape(), great for debugging. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.867271294038045
      ],
      "excerpt": ": training with model.fit(). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9243528409633959
      ],
      "excerpt": "Verification results (%) of different backbone, head tpye, data augmentation and loss function. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9456973371052921
      ],
      "excerpt": "- The 'CCrop' tag above means doing central-cropping on both trainging and testing data, which could eliminate the redundant boundary of intput face data (especially for AgeDB-30). \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/3P2S/arcface/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 19:26:16 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/3P2S/arcface/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "3P2S/arcface",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "All datasets used in this repository can be found from [face.evoLVe.PyTorch's Data-Zoo](https://github.com/ZhaoJ9014/face.evoLVe.PyTorch#Data-Zoo).\n\nNote:\n\n- Both training and testing dataset are \"Align_112x112\" version.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8172984194111891,
        0.8896212899863158
      ],
      "excerpt": "- You can run python ./dataset_checker.py to check if the dataloader work. \nDownload LFW, Aged30 and CFP-FP datasets, then extract them to /your/path/to/test_dataset. These testing data are already binary files, so it's not necessary to do any preprocessing. The directory structure should be like bellow. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.895222649498447
      ],
      "excerpt": "test_dataset: '/your/path/to/test_dataset' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8385569637801967
      ],
      "excerpt": "python take_pic.py -o path/to/dataset -n name \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8601387411103122
      ],
      "excerpt": "<img src=\"photo/architecture.JPG\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8140020261316089
      ],
      "excerpt": "Training and Testing \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8799103507643875
      ],
      "excerpt": "Download MS-Celeb-1M datasets, then extract and convert them to tfrecord as traning data as following. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9060935986199549
      ],
      "excerpt": "python data/convert_train_binary_tfrecord.py --dataset_path=\"/path/to/ms1m_align_112/imgs\" --output_path=\"./data/ms1m_bin.tfrecord\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9060935986199549
      ],
      "excerpt": "python data/convert_train_tfrecord.py --dataset_path=\"/path/to/ms1m_align_112/imgs\" --output_path=\"./data/ms1m.tfrecord\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8044290599680651
      ],
      "excerpt": "batch_size: 128 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": ": train \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8828665034782968
      ],
      "excerpt": "base_lr: 0.01 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633989807152664
      ],
      "excerpt": ": test \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9216610392576469
      ],
      "excerpt": "python train.py --mode=\"eager_tf\" --cfg_path=\"./configs/arc_res50.yaml\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8958425283399728
      ],
      "excerpt": "python train.py --mode=\"fit\" --cfg_path=\"./configs/arc_res50.yaml\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8254132011271154
      ],
      "excerpt": "You can download my trained models for testing from Benchmark and Models without training it yourself.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8708148446064828
      ],
      "excerpt": "python evaluate.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9291457871164801
      ],
      "excerpt": "python take_pic.py -o path/to/dataset -n name \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8532314952579001
      ],
      "excerpt": "| MobileNetV2 | ArcFace | Softmax | False | 98.67 | 90.87  |  88.51   | GoogleDrive | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.828134518112087
      ],
      "excerpt": "| MobileNetV2 | ArcFace | Softmax | True | 98.50 | 91.43 | 89.44 | GoogleDrive | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/3P2S/arcface/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Kuan-Yu Huang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "ArcFace Tensorflow 2",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "arcface",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "3P2S",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/3P2S/arcface/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\npython infer.py --update True\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 19:26:16 GMT"
    },
    "technique": "GitHub API"
  }
}
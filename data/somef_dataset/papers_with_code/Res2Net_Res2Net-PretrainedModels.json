{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this work or code is helpful in your research, please cite:\n```\n@article{gao2019res2net,\n  title={Res2Net: A New Multi-scale Backbone Architecture},\n  author={Gao, Shang-Hua and Cheng, Ming-Ming and Zhao, Kai and Zhang, Xin-Yu and Yang, Ming-Hsuan and Torr, Philip},\n  journal={IEEE TPAMI},\n  year={2021},\n  doi={10.1109/TPAMI.2019.2938758}, \n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{gao2019res2net,\n  title={Res2Net: A New Multi-scale Backbone Architecture},\n  author={Gao, Shang-Hua and Cheng, Ming-Ming and Zhao, Kai and Zhang, Xin-Yu and Yang, Ming-Hsuan and Torr, Philip},\n  journal={IEEE TPAMI},\n  year={2021},\n  doi={10.1109/TPAMI.2019.2938758}, \n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9996666385311364,
        0.8930530348544461
      ],
      "excerpt": "Our paper is accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). \n2020.10.20 PaddlePaddle version Res2Net achieves 85.13% top-1 acc. on ImageNet: PaddlePaddle Res2Net. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Res2Net/Res2Net-PretrainedModels",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you have any questions, feel free to E-mail me via: `shgao(at)live.com`\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-07-04T03:35:43Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-24T09:12:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We propose a novel building block for CNNs, namely Res2Net, by constructing hierarchical residual-like\nconnections within one single residual block. The Res2Net represents multi-scale features at a granular level and increases the range\nof receptive fields for each network layer. The proposed Res2Net block can be plugged into the state-of-the-art backbone CNN models,\ne.g. , ResNet, ResNeXt, BigLittleNet, and DLA. We evaluate the Res2Net block on all these models and demonstrate consistent performance gains over baseline models.\n<p align=\"center\">\n\t<img src=\"https://mftp.mmcheng.net/imgs800/19Res2Net.jpg\" alt=\"Sample\"  width=\"500\">\n\t<p align=\"center\">\n\t\t<em>Res2Net module</em>\n\t</p>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9354159719145946,
        0.8832355257746771
      ],
      "excerpt": "The official pytorch implemention of the paper \"Res2Net: A New Multi-scale Backbone Architecture\" \nOur paper is accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9943576628483521
      ],
      "excerpt": "2020.6.1 Res2Net is now in the official model zoo of the new deep learning framework Jittor. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9387041414732533,
        0.9202337488665965,
        0.9256582780626641,
        0.8573205249810336,
        0.9871747267154451
      ],
      "excerpt": "Using MMDetection v2 with Res2Net achieves better performance with less computational cost. \n2020.5.11 Res2Net achieves about 2% performance gain on Panoptic Segmentation based on detectron2 with no trick. We have released our code on: https://github.com/Res2Net/Res2Net-detectron2. \n2020.2.24 Our Res2Net_v1b achieves a considerable performance gain on mmdetection compared with existing backbone models. \nWe have released our code on: https://github.com/Res2Net/mmdetection. Detailed comparision between our method and HRNet, which previously generates best results, could be found at: https://github.com/Res2Net/mmdetection/tree/master/configs/res2net \n2020.2.21: Pretrained models of Res2Net_v1b with more than 2% improvement on ImageNet top1 acc. compared with original version of Res2Net are released! Res2Net_v1b achieves much better performance when transfer to other tasks such as object detection and semantic segmentation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "(ImageNet pretrained models) The official pytorch implemention of the TPAMI paper \"Res2Net: A New Multi-scale Backbone Architecture\"",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Res2Net/Res2Net-PretrainedModels/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 169,
      "date": "Mon, 27 Dec 2021 00:46:45 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Res2Net/Res2Net-PretrainedModels/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Res2Net/Res2Net-PretrainedModels",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8996322369390838
      ],
      "excerpt": "| Res2Net-50-26w-4s  | 25.70M | 4.2 | 22.01 | 6.15 |OneDrive \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8162139619409052
      ],
      "excerpt": "| Res2Net-101-26w-4s | 45.21M | 8.1 | 20.81 | 5.57 |OneDrive \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8344921521185694
      ],
      "excerpt": "You can load the pretrained model by using pretrained = True. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Res2Net/Res2Net-PretrainedModels/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Res2Net",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Res2Net-PretrainedModels",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Res2Net",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Res2Net/Res2Net-PretrainedModels/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "PyTorch>=0.4.1\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 829,
      "date": "Mon, 27 Dec 2021 00:46:45 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "res2net",
      "backbone",
      "pytorch",
      "multi-scale",
      "jittor"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\ngit clone https://github.com/gasvn/Res2Net.git\n\nfrom res2net import res2net50\nmodel = res2net50(pretrained=True)\n\n```\nInput image should be normalized as follows:\n```\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                  std=[0.229, 0.224, 0.225])\n```\n(By default, the model will be downloaded automatically.\nIf the default download link is not available, please refer to the Download Link listed on **Pretrained models**.)\n",
      "technique": "Header extraction"
    }
  ]
}
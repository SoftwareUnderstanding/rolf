{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Thank you to xView2 team for creating and releasing this amazing dataset and opportunity to invent a solution that can help to response to the global natural disasters faster. I really hope it will be usefull and the idea will be improved further.\n\n",
      "technique": "Header extraction"
    }
  ],
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": " - Competition and Dataset: https://www.xview2.org\n - UNet: https://arxiv.org/pdf/1505.04597.pdf\n - Pretrained models for Pytorch: https://github.com/Cadene/pretrained-models.pytorch\n - My 1st place solution from \"SpaceNet 4: Off-Nadir Building Footprint Detection Challenge\" (some ideas came from here): https://github.com/SpaceNetChallenge/SpaceNet_Off_Nadir_Solutions/tree/master/cannab",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8847707001475004
      ],
      "excerpt": "1st place solution for \"xView2: Assess Building Damage\" challenge. https://www.xview2.org \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DIUx-xView/xView2_first_place",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-12T17:41:35Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-12T03:13:06Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Solution developed using this environment:\n - Python 3 (based on Anaconda installation)\n - Pytorch 1.1.0+ and torchvision 0.3.0+ \n - Nvidia apex https://github.com/NVIDIA/apex\n - https://github.com/skvark/opencv-python\n - https://github.com/aleju/imgaug\n\n\nHardware:\nCurrent training batch size requires at least 2 GPUs with 12GB each. (Initially trained on Titan V GPUs). For 1 GPU batch size and learning rate should be found in practice and changed accordingly.\n\n\"train\", \"tier3\" and \"test\" folders from competition dataset should be placed to the current folder.\n\nUse \"train.sh\" script to train all the models. (~7 days on 2 GPUs).\nTo generate predictions/submission file use \"predict.sh\".\n\"evalution-docker-container\" folder contains code for docker container used for final evalution on hold out set (CPU version).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.928543059064583,
        0.9035170190748463
      ],
      "excerpt": "(Please Note: the code was developed during the competition and designed to perform separate experiments on different models. So, published as is without additional refactoring to provide fully training reproducibility). \nDataset for this competition well prepared and I have not found any problems with it. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.89017358825173
      ],
      "excerpt": "The problem with different nadirs and small shifts between \"pre\" and \"post\" images solved on models level: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9518745045469289,
        0.9723376736352535,
        0.8028155289077864
      ],
      "excerpt": " - Then, already pretrained localization models converted to classification Siamese Neural Network. So, \"pre\" and \"post\" images shared common weights from localization model and the features from the last Decoder layer concatenated to predict damage level for each pixel. This allowed Neural Network to look at \"pre\" and \"post\" separately in the same way and helped to ignore these shifts and different nadirs as well. \n - Morphological dilation with 5*5 kernel applied to classification masks. Dilated masks made predictions more \"bold\" - this improved accuracy on borders and also helped with shifts and nadirs. \nModels trained on different crops sizes from (448, 448) for heavy encoder to (736, 736) for light encoder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9310612018839856
      ],
      "excerpt": "Inference goes on full image size (1024, 1024) with 4 simple test-time augmentations (original, filp left-right, flip up-down, rotation to 180). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8779062718808955,
        0.9796734061824475
      ],
      "excerpt": "Classification models initilized using weights from corresponding localization model and fold number. They are Siamese Neural Networks with whole localization model shared between \"pre\" and \"post\" input images. Features from last Decoder layer combined together for classification. Pretrained weights are not frozen. \nUsing pretrained weights from localization models allowed to train classification models much faster and to have better accuracy. Features from \"pre\" and \"post\" images connected at the very end of the Decoder in bottleneck part, this helping not to overfit and get better generalizing model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "1st place solution for \"xView2: Assess Building Damage\" challenge.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DIUx-xView/xView2_first_place/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 17,
      "date": "Tue, 28 Dec 2021 20:28:53 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/DIUx-xView/xView2_first_place/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "DIUx-xView/xView2_first_place",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/DIUx-xView/xView2_first_place/master/evalution-docker-container/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/DIUx-xView/xView2_first_place/master/train.sh",
      "https://raw.githubusercontent.com/DIUx-xView/xView2_first_place/master/predict.sh",
      "https://raw.githubusercontent.com/DIUx-xView/xView2_first_place/master/evalution-docker-container/predict.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9711214109834954
      ],
      "excerpt": "from https://github.com/Cadene/pretrained-models.pytorch: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.854945736131497
      ],
      "excerpt": "Training masks generated using json files, \"un-classified\" type treated as \"no-damage\" (create_masks.py). \"masks\" folders will be created in \"train\" and \"tier3\" folders. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8479495362944713
      ],
      "excerpt": "All models trained with Train/Validation random split 90%/10% with fixed seeds (3 folds). Only checkpoints from epoches with best validation score used. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/DIUx-xView/xView2_first_place/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 vdurnov\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "xview2 1st place solution",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "xView2_first_place",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "DIUx-xView",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DIUx-xView/xView2_first_place/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "RitwikGupta",
        "body": "The weights are split into five files. Combine them using the command `cat split-weights-* > weights.tar.gz`. Put them in a `weights` directory in the project root.\r\n\r\n",
        "dateCreated": "2020-02-27T18:52:05Z",
        "datePublished": "2020-08-06T15:23:18Z",
        "html_url": "https://github.com/DIUx-xView/xView2_first_place/releases/tag/final",
        "name": "Release with weights",
        "tag_name": "final",
        "tarball_url": "https://api.github.com/repos/DIUx-xView/xView2_first_place/tarball/final",
        "url": "https://api.github.com/repos/DIUx-xView/xView2_first_place/releases/29398696",
        "zipball_url": "https://api.github.com/repos/DIUx-xView/xView2_first_place/zipball/final"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 38,
      "date": "Tue, 28 Dec 2021 20:28:53 GMT"
    },
    "technique": "GitHub API"
  }
}
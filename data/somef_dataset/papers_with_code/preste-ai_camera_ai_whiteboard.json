{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1612.08242"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Unified Gesture and Fingertip Detection : https://github.com/MahmudulAlam/Unified-Gesture-and-Fingertip-Detection\n2. TensorRT guide: https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#python_topics\n3. YOLO9000: Better, Faster, Stronger : https://arxiv.org/abs/1612.08242\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/preste-ai/AI_whiteboard",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-27T13:02:56Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-30T02:43:48Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9957642960783556
      ],
      "excerpt": "The idea of this project is to transform any wall or surface into an interactive whiteboard just with an ordinary RGB camera and your hand. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9087779856565281,
        0.965833365511036,
        0.9498695040991867
      ],
      "excerpt": "To use AI whiteboard correctly you need to find a wall or flat surface and place a camera at a distance of about 1 meter. It can be any wall/surface but the system works more accurately with the dark or light monotonous walls/surfaces. \nWe capture an image from a camera. Then we crop this image into a square. Next, we use a hand detector[1]  (YOLO[3] - deep neural network),to find a hand in the image. If there is a hand in the image, we crop that hand out of the image and feed it to a Fingertip detector[1]  (modified VGG16 - deep neural network). Next, if we can detect fingertips, we use their coordinates to control the whiteboard (See the control section below). \n| To draw | To move | To erase | To clean | To save |  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246241943538616
      ],
      "excerpt": "2. Convert frozen graph to onnx (.pb -> .onnx) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8142526247644517,
        0.9560705344097409
      ],
      "excerpt": "Metrics for Hand detection after model conversion.  \nIn order to determine the correctness of the detection, we use the value of IOU. If the value of IOU is more than 0.5 then the detector predicts a hand correctly otherwise - no. The results are given below.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Transform any wall to an intelligent whiteboard",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": " \n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "**Note:** The current TensorRT engines work correctly **only** on Jetson Xavier NX devices as TensorRT runs device-specific profiling during the optimization phase.If you want to use this models(engines) on others Jetson devices please convert .h5 model with `h5_to_trt.py` script on your platform. \n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/preste-ai/camera_ai_whiteboard/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Fri, 24 Dec 2021 20:48:39 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/preste-ai/AI_whiteboard/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "preste-ai/AI_whiteboard",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can download needed packages via pip using the `requirements.txt` file:\n\n```python\n  pip3 install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- [Jetson Xavier NX](https://developer.nvidia.com/embedded/learn/get-started-jetson-xavier-nx-devkit) with [JetPack 4.4](https://developer.nvidia.com/jetpack-sdk-44-archive) (CUDA 10.2, TensorRT 7.1.3, cuDNN 8.0)\n- [Install Tensorflow 1.15.3](https://docs.nvidia.com/deeplearning/frameworks/install-tf-jetson-platform/index.html)  \n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8712898244322753
      ],
      "excerpt": "Train: 9,500 images \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8737892364852982
      ],
      "excerpt": "Test : 1500 images \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": " python3 yolo_train.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": " python3 yolo_test.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8773457183499037,
        0.8121568128153179,
        0.8217286789715265
      ],
      "excerpt": "  python3 h5_to_trt.py --folder weights --weights_file yolo --fp 16 \nfolder weights : path to the folder with model \nweights_file : weights file name (without .h5) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8799962014076236
      ],
      "excerpt": "| Precision   | 84.80 % | 99.45 % | 99.45 % | 99.45 % | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/preste-ai/AI_whiteboard/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 PRESTE\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "AI_whiteboard",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "AI_whiteboard",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "preste-ai",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/preste-ai/AI_whiteboard/blob/main/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Check `config.py` file and set up needed parameters.\n- whiteboard_w : 200 - whiteboard width (px) (displayed on camera caputed image)\n- whiteboard_h : 200 - whiteboard height (px) (displayed on camera caputed image)\n- cam_w       : 320 - width (px) of a captured image \n- cam_h       : 240 - height (px) of a captured image\n- framerate   : 60 - camera capture framerate (for Raspberry Pi Camera)\n- zoom_koef   : 2 - zoom coefficient to resize whiteboard_w and whiteboard_h\n- confidence_ft_threshold : 0.5 - confidence threshold of Fingertips detector\n- confidence_hd_threshold : 0.8 - confidence threshold of Hand detector      \n\n---\nRun from a project root directory:\n\n**Jetson Devices**\n```python \n  python3 ai_whiteboard.py --rpc --trt \n```\n- rpc : If you want to use a Raspberry Pi Camera. Default: False\n- trt : If you want to use TensorRT engines. Default: False\n\n**Laptop**\n```python\n  python3 ai_whiteboard.py \n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Fri, 24 Dec 2021 20:48:39 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "jetson-xavier-nx",
      "jetson-devices",
      "fingertips-detector",
      "hand-detector",
      "raspberry-pi-camera",
      "tensorrt-engine",
      "whiteboard"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [Jetson Xavier NX](https://developer.nvidia.com/embedded/learn/get-started-jetson-xavier-nx-devkit) with [JetPack 4.4](https://developer.nvidia.com/jetpack-sdk-44-archive) (CUDA 10.2, TensorRT 7.1.3, cuDNN 8.0)\n- [Install Tensorflow 1.15.3](https://docs.nvidia.com/deeplearning/frameworks/install-tf-jetson-platform/index.html)  \n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Special thanks to Team Roboflow.ai\n- Special thanks to the staff at Chelan County PUD\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1506.02640\n - https://towardsdatascience.com/how-to-train-a-custom-object-detection-model-with-yolo-v5-917e9ce13208\n - https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework\n - Hands-On Machine Learning with\nScikit-Learn and TensorFlow by Aur\u00e9lien G\u00e9ron (O\u2019Reilly"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8845932381229517
      ],
      "excerpt": "Link to my article on Medium.com \"Applying Deep Learning to Environmental Issues\" published August 2020 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "||Photo: (c) 2014 Rudy Owens|| \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jshaffer94247/Counting-Fish",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-30T20:34:36Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-28T09:07:36Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Salmon life cycles follow a predictable pattern: hatch in freshwater, migrate to the ocean for the majority of their lives, and then migrate back to their original freshwater hatch sites before they spawn and then die. The time spent in freshwater and ocean salt water depends on the species.\n\nSalmon populations in the waters of Puget Sound are estimated each year when a mature portion of the salmon migrate back from the ocean to freshwater to spawn. In many areas, this pathway is partially obstructed by boat locks (Seattle), or hydroelectric dams (Bonneville) and the salmon travel through carefully built fish ladders on this upstream journey. As they pass through the ladders, viewing windows allow them to be seen by both tourists and biologists, and human viewers are still the primary way to count the fish.\n\n|Fish ladder| Bonneville Dam public window| Bonneville counting window (non-public)|\n|---|---|---|\n|<img src=\"./assets/fish_ladder.png\" alt=\"fish ladder explanation at https: //www youtube com/watch?v=sabk7Khq0kQ\" width='300' />| <img src=\"./assets/fish_143.jpg\" alt=\"man viewing fish through underwater viewing window\" width=\"200\"/>|<img src=\"http://www.oceanlight.com/stock-photo/bonneville-dam-salmon-count-photo-19368-548507.jpg\" alt=\"fisheries biologist counting salmon\"  height=\"200\" />|\n|Watch at https: //www youtube com/watch?v=sabk7Khq0kQ||Photo: (c) Phillip Colla OceanLight.com|\n\nOnce tallied, the estimated population for each species determines sport fishing limits such as the number of fish per day and the length of the fishing season. This data is also used to make decisions in the operation of salmon fisheries, commercial fishing, restaurants, and tourism.\n\n|Columbia River Chinook Season|Ballard Locks 2020 Sockeye Counts|\n|---|---|\n|<img src=\"./assets/chinook_2020_Columbia.png\" height='200'/>|<img src=\"./assets/ballard_locks_sockeye_counts_71220.jpg\" height='200'/>|\n|News source: https://wdfw.wa.gov/news/summer-chinook-salmon-fishing-open-july-much-columbia-river | Updated count: https://wdfw.wa.gov/fishing/reports/counts/lake-washington#sockeye|\n\n\nThe salmon counting task is easier when few are in the ladder; the task is more difficult when many are returning at once. Some locations estimate the full population by counting for a set period of time each day and comparing to historical data. In other locations, 24/7 video recording enables biologists to review footage and tally the counts later; weekend tallies can take staff multiple days to catch up on counts. At some sites, interested individuals can sign up for daily notifications on the latest counts.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "In the Pacific Northwest, salmon are vital to commerce and to the marine ecosystem, and fish population estimates are key factors in many policy decisions. Current methods require trained biologists to observe the fish passing a viewing window and manually record the fish count on a daily basis.\n\nThis project explored the possibility of using machine learning methods of object detection and classification to support these efforts, potentially enabling the collection of data in more locations and over longer time periods.\n\nCustom trained models (e.g. YOLO v5) using images from fish ladders showed that accurate fish detection is promising but non-trivial, counting fish in a still image does not solve the problem of counting fish in video, and that classifying fish by species requires excellent viewing conditions.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.864734543539211
      ],
      "excerpt": "Deep Learning Models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8136154087667344
      ],
      "excerpt": "Model Metrics \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8432929337641032,
        0.8432929337641032
      ],
      "excerpt": "|    |- 02_Model_Training_YOLOv5          (Google Colab notebook) \n|    |- 03_Model_Inference_YOLOv5         (Google Colab notebook) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9743287881071646,
        0.9203546348209798
      ],
      "excerpt": "Over the course of 2 weeks in June 2020, an internet search found 168 usable images of fish traveling past viewing windows. Of these, the majority were taken by tourists and often feature the silhouettes of children in front of the glass. Images of official viewing windows were very difficult to find, in part because 1) they are probably not particularly interesting to most people and 2) for security reasons, the fish cam at the Bonneville Dam (Willamette Falls) has been disabled. \nWith the use of image augmentation, the original collection of 168 images was expanded by including horizontal flip, random adjustments to exposure (+/- 25%), and random changes to rotation (+/- 15%). The final 504 images contained 725 annotated fish (averaging 4.3 per image), and included 2 null examples of viewing windows with no fish. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9344973057681097,
        0.969322402071921,
        0.8815515610956137,
        0.8620543523265073,
        0.883799594133959
      ],
      "excerpt": "For image classification, images need to contain a limited number of objects (preferably just one) and a machine learning algorithm will attempt to name the object in the image. All that is needed is an image and a single label, e.g. \"cat\" or \"dog\". \nObject detection refers to the case where there are multiple instances of an object or when there are a variety of other objects also in the image. In this situation, the image also needs to be labelled to show where each object is located. Most algorithms use a bounding box for this. \nThe original 168 fish images were manually labeled using the free tool \"labelImg\" (see https://pypi.org/project/labelImg/) to draw the bounding boxes. Free tools from roboflow.ai (see https://roboflow.ai/) were used to perform the image augmentation. Leveraging the roboflow tools provided several additional benefits: the bounding boxes were automatically adjusted for images that were randomly rotated, and the images and annotations could be quickly exported in multiple formats for use in a variety of models. \nDue to the poor quality of the images, a single class of \"fish\" was used. \nAfter building the first model, images or video were requested from one of the fish counting sites in Washington. This request was granted with a video segment of fish in one of the ladders. With these new images, but without fish identification expertise, it was possible to create 3 classes: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9571793325492616,
        0.985751979182349,
        0.988072157253986,
        0.9861215475500202
      ],
      "excerpt": " - 'unknown' for fish only partially in the viewing window, or whose adipose fin region is obscured by another fish or artifact \n\"You Only Look Once\". YOLO is a popular object detection machine learning model introduced in 2015 by a group of researchers at the University of Washington. Rather than pass an image classifier multiple times over an image to see if there was, say, a dog at the upper left, or maybe at the upper right, this new approach replaced the final layers of an image classifier with additional convolutional layers that allowed it to find all instances in one pass. The immediate improvement in speed was a major leap forward for computer vision and object detection. Since the original paper, the model has been improved several times with Version 5 being released in June 2020. \nGiven the popularity, speed, and accuracy of YOLO, the YOLO v5 model flow available through roboflow.ai was an obvious choice. Earlier YOLO versions have keras and tensorflow implementations and can be run on a variety of hardware. At this time, only a PyTorch version of YOLO v5 has been built. This version leverages the computational speed and efficiency of a GPU for excellent results, and there are a number of examples available in blog posts and in github. For this project, the Google Colaboratory template from roboflow.ai was used. This template configures the environment and builds the model, so a simple customization consists of uploading a new training set and selecting the number of epochs for training. Once trained, the confidence threshold can be adjusted before making predictions. \nFor this first model, it became apparent that labeling the fish by species was going to be highly problematic. First, identification is a challenge. Sport fishermen are discouraged from identifying fish by side view alone as this can be misleading; they are instead instructed to observe inside the mouth and to look at the color of the gum line. In cloudy, poorly lit conditions, other features such as silver highlights on the tail or where the black spots are located are very difficult to see. Second, training a model to recognize fish by species requires properly labeled images, and there were no fish experts working on this project. In lieu of counting by species, the project was scaled back to count them all as 'fish'. As a first pass, even this highlighted plenty of issues. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9508382905168348
      ],
      "excerpt": "Scaling back to just finding a generically labeled \"fish\", and scaling up to cloud based GPU resources with the latest YOLO v5 model, the results were mixed and not ready to replace a fisheries biologist. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.870184922287901,
        0.9457587297307009,
        0.9795700332548825,
        0.9553119694511292,
        0.8626632689010747,
        0.9339563009410758
      ],
      "excerpt": " 1. Impressive find: Even so, an unobstructed view is an easy improvement, and this is the case for the non-public viewing windows. \n 2. Humorous finds: This phantom floor fish is reminiscent of the light-dark patterns of the Viola-Jones algorithm, possibly providing a clue to what may be happening. A change in lighting may result in model improvements. Note the careful arrangement of can lights in the Bonneville viewing window shown previously. \n 3. Challenges: Height and width of window are not issues, but the depth of the tank is a problem. \nIn terms of model metrics, the graphs below show the results of 100 training epochs (blue) and progress on 1000 training epochs (orange). In the 1000 epoch case, the model stopped making significant improvements before all training epochs were completed. \nNote: as of July 2020, YOLO v5 does not have the ability to save the best model. \nFor the second model, images seemed crystal clear by comparison, so the classes were upgraded to adipose, no_adipose and unknown. For simple images, the model worked very well. It struggled when conditions were crowded and stronger shadows appeared. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9899100417611831
      ],
      "excerpt": "In the example above with the 'extra' fish label, this problem is easily solved in production by adjusting the threshold to be > 0.40; this would exclude the box with the confidence of 0.42. For now, the threshold on the model is set lower to provide information on where the model needs to be improved. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9710745656895641
      ],
      "excerpt": "Precision is the accuracy of the positive predictions (TP / TP+FP) or \"If you say it's a fish, what percentage of the time is it really a fish?\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9899073707456546,
        0.9100851938234715
      ],
      "excerpt": "For object detection, precision and recall are similar to their definitions in other types of machine learning. However, there is an additional consideration here, best illustrated with an example. Let's say the image has a single fish, and the model finds a single fish but draws the box on the floor. Would we want to call that a success? Or, what if it draws the box around only the head of the fish but not the body? Do we want to give it partial credit? The solution to this dilemma is something like partial credit, where the amount of overlap between the box drawn and the expected box determines the mAP (mean average precision). The most common metric here is \"50% overlap\", or mAP@.5. So, if we count the boxes where the model's box overlaps the label box by at least 50%, this model built with Phase 1 images was providing correct answers in roughly 50% of the cases, and the model rebuilt with Phase 2 images was providing correct answers about 70% of the time. \nBased on the results from YOLO v5, salmon counting by object detection is definitely possible, and there also remain several challenges to be solved. These challenges include: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9407929828481424,
        0.9507107090162941,
        0.9768947727282792
      ],
      "excerpt": "Viewing window height and width are not critical, but the depth needs to be carefully selected to reduce the number of fish that can obscure other fish \nCorrect species labels are required for training a model to separate sockeye, chinook, and coho in addition to other species \nFrom personal experience (easily confirmed by watching online videos), salmon swimming upstream in a fish ladder pause to rest for varying amounts of time. In some cases, they will swim slowly and maintain position, and at other times they will slow to the point that they drift backward with the current. This adds an additional level of complexity that will require an advanced system to track objects (fish) from one video frame to the next. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9206849331586106,
        0.9866907348572412
      ],
      "excerpt": " - Ability to track an individual fish regardless of forward or backward movement \n - Only a single count irrespective of the amount of time a fish remains in the viewing window \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.929163862852198,
        0.8481451406965576,
        0.9988231801414891
      ],
      "excerpt": "Hands-On Machine Learning with \nScikit-Learn and TensorFlow by Aur\u00e9lien G\u00e9ron (O\u2019Reilly). Second edition. Copyright 2019. \nReturn to Table of Contents \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Leveraging neural nets and deep learning to count fish passing through a fish ladder",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jshaffer94247/Counting-Fish/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 14:18:04 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/jshaffer94247/Counting-Fish/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "jshaffer94247/Counting-Fish",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/jshaffer94247/Counting-Fish/master/code/01_Finding_Images.ipynb",
      "https://raw.githubusercontent.com/jshaffer94247/Counting-Fish/master/code/03_Model_Inference_YOLOv5.ipynb",
      "https://raw.githubusercontent.com/jshaffer94247/Counting-Fish/master/code/02_Model_Training_YOLOv5.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8244453191770256
      ],
      "excerpt": "|Note 1               |Note 2|Note 3| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9498165119088007
      ],
      "excerpt": "Viewing windows with excellent lighting are required \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8092473267164679
      ],
      "excerpt": "Folder Structure \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9084679315341777
      ],
      "excerpt": "|<img src=\"./assets/fish_096_left.jpg\" alt=\"image rotate left and lighten\" width='150' />|<img src=\"./assets/fish_096_right.jpg\" alt=\"image rotate left and lighten\" width='150' />|<img src=\"./assets/fish_labels.png\" alt=\"labeled training image\" width='200' />|<img src=\"./assets/fish_151_null.jpg\" alt=\"labeled training image\" width='140' />| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8631985119870249
      ],
      "excerpt": "|<img src=\"http://www.eregulations.com/wp-content/uploads/2020/06/Marine_-_Sockeye_Ocean_1.3_-_brightness.jpg\" alt=\"chinook\" width=\"200\"/>|<img src=\"http://www.eregulations.com/wp-content/uploads/2020/06/Marine_-_Chinook_Ocean_1.3_brightness.jpg\" alt=\"chinook\" width=\"200\"/>|<img src=\"http://www.eregulations.com/wp-content/uploads/2020/06/Marine_-_Coho_Ocean_1.3_brightness.jpg\" alt=\"coho\" width=\"200\"/>|<img src=\"./assets/fish_147_mystery.png\" alt=\"https://www.ifish.net/gallery/data/1156/fishimage310.jpg\" width=\"200\"/>| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9085426846763158
      ],
      "excerpt": "|<img src=\"./assets/fish_impressive_find.png\" width=\"260\" />|<img src=\"./assets/fish_on_floor.png\" width=\"260\" />|<img src=\"./assets/fish_056_counting_challenge.jpg\" width=\"260\" />| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9017831499000427
      ],
      "excerpt": "|<img src=\"./assets/results_2_fish_1_each.png\" height=\"200\" />|<img src=\"./assets/fish_3_labels_4.png\" height=\"200\" />|<img src=\"./assets/crowded_1.png\" height=\"200\" />| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9017831499000427,
        0.9017831499000427
      ],
      "excerpt": "|1|<img src=\"./assets/metric_precision.png\" height=\"200\" />|<img src=\"./assets/metric_recall.png\" height=\"200\" />|<img src=\"./assets/metric_mAP.png\" height=\"200\" />| \n|2|<img src=\"./assets/RIS_500epoch_precision.png\" height=\"200\" />|<img src=\"./assets/RIS_500epoch_recall.png\" height=\"200\" />|<img src=\"./assets/RIS_500epoch_mAP.png\" height=\"200\" />| \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/jshaffer94247/Counting-Fish/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Leveraging Deep Learning to Facilitate Fish Counts",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Counting-Fish",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "jshaffer94247",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jshaffer94247/Counting-Fish/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 14,
      "date": "Wed, 29 Dec 2021 14:18:04 GMT"
    },
    "technique": "GitHub API"
  }
}
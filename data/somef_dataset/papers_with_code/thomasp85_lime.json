{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1602.04938"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "<!-- badges: end --> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/thomasp85/lime/master/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/thomasp85/lime",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-03-17T10:40:29Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-11T10:20:20Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8121340254003762
      ],
      "excerpt": "It gave explanations for their variations, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.946715772983591
      ],
      "excerpt": "This is an R port of the Python lime package \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9187028030945537,
        0.9228668603924756,
        0.8325326148838393,
        0.9594923759702365,
        0.928151526789277,
        0.9845451079983646,
        0.9722058142505381,
        0.9550317995538564,
        0.9847465952062372
      ],
      "excerpt": "lime (Local Interpretable Model-agnostic Explanations) approach for \nblack-box model explanations. All credits for the invention of the \napproach goes to the original developers. \nThe purpose of lime is to explain the predictions of black box \nclassifiers. What this means is that for any given prediction and any \ngiven classifier it is able to determine a small set of features in the \noriginal data that has driven the outcome of the prediction. To learn \nmore about the methodology of lime read the \npaper and visit the repository of \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Local Interpretable Model-Agnostic Explanations (R port of original Python package)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/thomasp85/lime/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 106,
      "date": "Sat, 25 Dec 2021 11:27:44 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/thomasp85/lime/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "thomasp85/lime",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "`lime` is available on CRAN and can be installed using the standard\napproach:\n\n``` r\ninstall.packages('lime')\n```\n\nTo get the development version, install from GitHub instead:\n\n``` r\n#: install.packages('devtools')\ndevtools::install_github('thomasp85/lime')\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8074361519140683
      ],
      "excerpt": "one observation at a time. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/thomasp85/lime/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "R",
      "C++",
      "CSS",
      "JavaScript"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/thomasp85/lime/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'YEAR: 2017\\nCOPYRIGHT HOLDER: Thomas Lin Pedersen\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "lime <img src=\"man/figures/logo.png\" width=\"131px\" height=\"140px\" align=\"right\" style=\"padding-left:10px;background-color:white;\" />",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "lime",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "thomasp85",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/thomasp85/lime/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "thomasp85",
        "body": "* Fixed use of `order()` on `data.frame` objects\r\n* Moved htmlwidgets, shiny, and shinythemes to suggests\r\n",
        "dateCreated": "2021-02-24T11:20:03Z",
        "datePublished": "2021-02-24T15:25:42Z",
        "html_url": "https://github.com/thomasp85/lime/releases/tag/v0.5.2",
        "name": "lime 0.5.2",
        "tag_name": "v0.5.2",
        "tarball_url": "https://api.github.com/repos/thomasp85/lime/tarball/v0.5.2",
        "url": "https://api.github.com/repos/thomasp85/lime/releases/38661131",
        "zipball_url": "https://api.github.com/repos/thomasp85/lime/zipball/v0.5.2"
      },
      {
        "authorType": "User",
        "author_name": "thomasp85",
        "body": "* Fixed namespace import from glmnet following changes there \r\n",
        "dateCreated": "2019-11-12T07:32:04Z",
        "datePublished": "2019-11-12T08:21:53Z",
        "html_url": "https://github.com/thomasp85/lime/releases/tag/v0.5.1",
        "name": "lime 0.5.1",
        "tag_name": "v0.5.1",
        "tarball_url": "https://api.github.com/repos/thomasp85/lime/tarball/v0.5.1",
        "url": "https://api.github.com/repos/thomasp85/lime/releases/21391481",
        "zipball_url": "https://api.github.com/repos/thomasp85/lime/zipball/v0.5.1"
      },
      {
        "authorType": "User",
        "author_name": "thomasp85",
        "body": "* `explain()` will now pass `...` on to the relevant `predict()` method (#150) \r\n* `explain.data.frame()` gains a `gower_pow` argument to modify the calculated  \r\n  gower distance before use by raising it to the power of the given value (#158) \r\n* Fixed a bug when calculating R^2 on single feature explanations (@pkopper, #157) \r\n* Fixed formatting of text prediction html presentation (#145) \r\n* Fixed a bug when setting feature select method to \"none\" (#141) \r\n* Changes default colouring from green-red to blue-red (#137) \r\n* `lime()` now warns when quantile binning is not feasible and uses standard  \r\n  binning instead (#154) \r\n* Changed the `lambda` value in the local model fit to match the one used in the \r\n  Python version according to the relationship given here: \r\n  https://stats.stackexchange.com/a/270705 \r\n* Added pkgdown site at https://lime.data-imaginist.com \r\n* Fixed a bug when using a proprocessor with data.frame explanations \r\n",
        "dateCreated": "2019-06-24T11:10:03Z",
        "datePublished": "2019-06-24T11:11:12Z",
        "html_url": "https://github.com/thomasp85/lime/releases/tag/v0.5.0",
        "name": "lime 0.5.0",
        "tag_name": "v0.5.0",
        "tarball_url": "https://api.github.com/repos/thomasp85/lime/tarball/v0.5.0",
        "url": "https://api.github.com/repos/thomasp85/lime/releases/18177988",
        "zipball_url": "https://api.github.com/repos/thomasp85/lime/zipball/v0.5.0"
      },
      {
        "authorType": "User",
        "author_name": "thomasp85",
        "body": "* Added a `NEWS.md` file to track changes to the package.\r\n* Fixed bug when explaining regression models, due to drop=TRUE defaults (#33)\r\n* Integer features are no longer converted to numeric during permutations (#32)\r\n* Fix bug when working with xgboost and tabular predictions (@martinju #1)\r\n* Training data can now contain `NA` values (#8) \r\n* Keep ordering when plotting with `plot_features()` (#38)\r\n* Fix support for mlr by extracting predictions correctly\r\n* Added support for `h2o` (@mdancho84) (#40)\r\n* Throws meaningful error when all permutations have 0 similarity to original\r\n  observation (#47)\r\n* Explaining data can now contain `NA` values (#45)\r\n* Support for `Date` and `POSIXt` columns. They will be kept constant during\r\n  permutations so that `lime` will explain the model behaviour at the given \r\n  timepoint based on the remaining features (#39).\r\n* Add `plot_explanations()` for an overview plot of a large explanation set\r\n",
        "dateCreated": "2017-11-24T10:32:51Z",
        "datePublished": "2017-11-24T10:36:20Z",
        "html_url": "https://github.com/thomasp85/lime/releases/tag/lime-0.3.1",
        "name": "lime v0.3.1",
        "tag_name": "lime-0.3.1",
        "tarball_url": "https://api.github.com/repos/thomasp85/lime/tarball/lime-0.3.1",
        "url": "https://api.github.com/repos/thomasp85/lime/releases/8644640",
        "zipball_url": "https://api.github.com/repos/thomasp85/lime/zipball/lime-0.3.1"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 460,
      "date": "Sat, 25 Dec 2021 11:27:44 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "r",
      "model-checking",
      "modeling",
      "model-evaluation",
      "caret"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Out of the box `lime` supports a long range of models, e.g.\u00a0those\ncreated with caret, parsnip, and mlr. Support for unsupported models are\neasy to achieve by adding a `predict_model` and `model_type` method for\nthe given model.\n\nThe following shows how a random forest model is trained on the iris\ndata set and how `lime` is then used to explain a set of new\nobservations:\n\n``` r\nlibrary(caret)\nlibrary(lime)\n\n#: Split up the data set\niris_test <- iris[1:5, 1:4]\niris_train <- iris[-(1:5), 1:4]\niris_lab <- iris[[5]][-(1:5)]\n\n#: Create Random Forest model on iris data\nmodel <- train(iris_train, iris_lab, method = 'rf')\n\n#: Create an explainer object\nexplainer <- lime(iris_train, model)\n\n#: Explain new observation\nexplanation <- explain(iris_test, explainer, n_labels = 1, n_features = 2)\n\n#: The output is provided in a consistent tabular format and includes the\n#: output from the model.\nexplanation\n#:> #: A tibble: 10 x 13\n#:>    model_type case  label label_prob model_r2 model_intercept model_prediction\n#:>    <chr>      <chr> <chr>      <dbl>    <dbl>           <dbl>            <dbl>\n#:>  1 classific\u2026 1     seto\u2026          1    0.681           0.129            0.987\n#:>  2 classific\u2026 1     seto\u2026          1    0.681           0.129            0.987\n#:>  3 classific\u2026 2     seto\u2026          1    0.692           0.123            0.984\n#:>  4 classific\u2026 2     seto\u2026          1    0.692           0.123            0.984\n#:>  5 classific\u2026 3     seto\u2026          1    0.686           0.129            0.983\n#:>  6 classific\u2026 3     seto\u2026          1    0.686           0.129            0.983\n#:>  7 classific\u2026 4     seto\u2026          1    0.695           0.119            0.985\n#:>  8 classific\u2026 4     seto\u2026          1    0.695           0.119            0.985\n#:>  9 classific\u2026 5     seto\u2026          1    0.694           0.123            0.984\n#:> 10 classific\u2026 5     seto\u2026          1    0.694           0.123            0.984\n#:> #: \u2026 with 6 more variables: feature <chr>, feature_value <dbl>,\n#:> #:   feature_weight <dbl>, feature_desc <chr>, data <list>, prediction <list>\n\n#: And can be visualised directly\nplot_features(explanation)\n```\n\n![](man/figures/README-unnamed-chunk-2-1.png)<!-- -->\n\n`lime` also supports explaining image and text models. For image\nexplanations the relevant areas in an image can be highlighted:\n\n``` r\nexplanation <- .load_image_example()\n\nplot_image_explanation(explanation)\n```\n\n![](man/figures/README-unnamed-chunk-3-1.png)<!-- -->\n\nHere we see that the second most probably class is hardly true, but is\ndue to the model picking up waxy areas of the produce and interpreting\nthem as wax-light surface.\n\nFor text the explanation can be shown by highlighting the important\nwords. It even includes a `shiny` application for interactively\nexploring text models:\n\n![interactive text explainer](man/figures/shine_text_explanations.gif)\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find the code or the models useful, please cite this paper:\n```\n@inproceedings{YuKoltun2016,\n\tauthor    = {Fisher Yu and Vladlen Koltun},\n\ttitle     = {Multi-Scale Context Aggregation by Dilated Convolutions},\n\tbooktitle = {ICLR},\n\tyear      = {2016},\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{YuKoltun2016,\n    author    = {Fisher Yu and Vladlen Koltun},\n    title     = {Multi-Scale Context Aggregation by Dilated Convolutions},\n    booktitle = {ICLR},\n    year      = {2016},\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fyu/dilation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-01-14T07:22:23Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-14T03:14:33Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Properties of dilated convolution are discussed in our [ICLR 2016 conference paper](http://arxiv.org/abs/1511.07122). This repository contains the network definitions and the trained models. You can use this code together with vanilla Caffe to segment images using the pre-trained models. If you want to train the models yourself, please check out the [document for training](https://github.com/fyu/dilation/blob/master/docs/training.md).\n\n**If you are looking for dilation models with state-of-the-art performance and Python implementation, please check out [Dilated Residual Networks](https://github.com/fyu/drn).**\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9013950808762354
      ],
      "excerpt": "In the case of using Anaconda \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9613519100537186,
        0.9276389946245487
      ],
      "excerpt": "You are more than welcome to train our model on a new dataset. To do that, please refer to the document for training. \nBesides Caffe support, dilated convolution is also implemented in other deep learning packages. For example, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Dilated Convolution for Semantic Image Segmentation",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "http://lasagne.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fyu/dilation/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 268,
      "date": "Sat, 25 Dec 2021 11:25:54 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/fyu/dilation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "fyu/dilation",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/fyu/dilation/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/fyu/dilation/master/pretrained/download_cityscapes.sh",
      "https://raw.githubusercontent.com/fyu/dilation/master/pretrained/download_vgg_conv.sh",
      "https://raw.githubusercontent.com/fyu/dilation/master/pretrained/download_camvid.sh",
      "https://raw.githubusercontent.com/fyu/dilation/master/pretrained/download_kitti.sh",
      "https://raw.githubusercontent.com/fyu/dilation/master/pretrained/download_pascal_voc.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8879673702764167
      ],
      "excerpt": "Install Caffe and its Python interface. Make sure that the Caffe version is newer than commit 08c5df. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9901359896581896
      ],
      "excerpt": "The required Python packages are numba numpy opencv. Python release from Anaconda is recommended. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9978940659002589
      ],
      "excerpt": "conda install numba numpy opencv \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/fyu/dilation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright (c) 2016 Fisher Yu\\n\\nPermission is hereby granted, free of charge, to any person obtaining\\na copy of this software and associated documentation files (the\\n\"Software\"), to deal in the Software without restriction, including\\nwithout limitation the rights to use, copy, modify, merge, publish,\\ndistribute, sublicense, and/or sell copies of the Software, and to\\npermit persons to whom the Software is furnished to do so, subject to\\nthe following conditions:\\n\\nThe above copyright notice and this permission notice shall be\\nincluded in all copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Multi-Scale Context Aggregation by Dilated Convolutions",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "dilation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "fyu",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fyu/dilation/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "predict.py is the main script to test the pre-trained models on images. The basic usage is\n\n    python predict.py <dataset name> <image path>\n\nGiven the dataset name, the script will find the pre-trained model and network definition. We currently support models trained from four datasets: pascal_voc, camvid, kitti, cityscapes. The steps of using the code is listed below:\n\n* Clone the code from Github\n\n    ```\n    git clone git@github.com:fyu/dilation.git\n    cd dilation\n    ```\n* Download pre-trained network\n\n    ```\n    sh pretrained/download_pascal_voc.sh\n    ```\n* Run pascal voc model on GPU 0\n\n    ```\n    python predict.py pascal_voc images/dog.jpg --gpu 0\n    ```\n    \n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 749,
      "date": "Sat, 25 Dec 2021 11:25:54 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "predict.py is the main script to test the pre-trained models on images. The basic usage is\n\n    python predict.py <dataset name> <image path>\n\nGiven the dataset name, the script will find the pre-trained model and network definition. We currently support models trained from four datasets: pascal_voc, camvid, kitti, cityscapes. The steps of using the code is listed below:\n\n* Clone the code from Github\n\n    ```\n    git clone git@github.com:fyu/dilation.git\n    cd dilation\n    ```\n* Download pre-trained network\n\n    ```\n    sh pretrained/download_pascal_voc.sh\n    ```\n* Run pascal voc model on GPU 0\n\n    ```\n    python predict.py pascal_voc images/dog.jpg --gpu 0\n    ```\n    \n",
      "technique": "Header extraction"
    }
  ]
}
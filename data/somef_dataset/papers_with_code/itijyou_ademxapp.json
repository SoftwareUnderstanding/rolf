{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This work is supported with supercomputing resources provided by the PSG cluster at NVIDIA and the Phoenix HPC service at the University of Adelaide.\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1512.03385",
      "https://arxiv.org/abs/1611.10080",
      "https://arxiv.org/abs/1611.10080"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use this code or these models in your research, please cite:\n\n    @Misc{word.zifeng.2016,\n        author = {Zifeng Wu and Chunhua Shen and Anton van den Hengel},\n        title = {Wider or Deeper: {R}evisiting the ResNet Model for Visual Recognition},\n        year = {2016}\n        howpublished = {arXiv:1611.10080}\n    }\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@Misc{word.zifeng.2016,\n    author = {Zifeng Wu and Chunhua Shen and Anton van den Hengel},\n    title = {Wider or Deeper: {R}evisiting the ResNet Model for Visual Recognition},\n    year = {2016}\n    howpublished = {arXiv:1611.10080}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8700321621842753,
        0.8090267943836726
      ],
      "excerpt": "[Model A](https://cdn.rawgit.com/itijyou/ademxapp/master/misc/ilsvrc_model_a.pdf)|19.20|4.73|[aar](https://cloudstor.aarnet.edu.au/plus/index.php/s/V7dncO4H0ijzeRj) \n[Model A1](https://cdn.rawgit.com/itijyou/ademxapp/master/misc/ilsvrc_model_a1.pdf)|19.54|4.75|[aar](https://cloudstor.aarnet.edu.au/plus/index.php/s/NOPhJ247fhVDnZH) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8684795368276368
      ],
      "excerpt": "Model A1, 2 conv.|fine|1024x2048|78.08|[aar](https://cloudstor.aarnet.edu.au/plus/index.php/s/2hbvpro6J4XKVIu) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/itijyou/ademxapp",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-11-24T06:45:36Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-07T09:20:44Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8916301118561818,
        0.9952249297678535,
        0.9616090660137092,
        0.9738228887245477,
        0.8097711873607195
      ],
      "excerpt": "Visual applications by the University of Adelaide \nIn designing our Model A, we did not over-optimize its structure for efficiency unless it was neccessary, which led us to a high-performance model without non-trivial building blocks. Besides, by doing so, we anticipate this model and its trivial variants to perform well when they are finetuned for new tasks, considering their better spatial efficiency and larger model sizes compared to conventional ResNet models. \nIn this work, we try to find a proper depth for ResNets, without grid-searching the whole space, especially when it is too costly to do so, e.g., on the ILSVRC 2012 classification dataset. \nFor more details, refer to our report: Wider or Deeper: Revisiting the ResNet Model for Visual Recognition. \nThis code is a refactored version of the one that we used in the competition, and has not yet been tested extensively, so feel free to open an issue if you find any problem. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8142862899040247
      ],
      "excerpt": "Training code for image classification on ILSVRC 2012 (Still needs to be evaluated.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8291559111354564,
        0.9727425669403839,
        0.9107371433732346
      ],
      "excerpt": "Segmentation results with multi-scale testing on VOC and Cityscapes \nModel A and Model A1 for ILSVRC with testing code \nSegmentation results with single-scale testing on VOC and Cityscapes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "    data/ilsvrc12/ILSVRC2012_val/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9289836973940797
      ],
      "excerpt": "Note: Due to a change of MXNet in padding at pooling layers, some of the computed feature maps in Model A will have different sizes from those stated in our report. However, this has no effect on Model A1, which always uses convolution layers (instead of pooling layers) for down-sampling. So, in most cases, just use Model A1, which was initialized from Model A, and tuned for 45k extra iterations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "    data/ilsvrc12/ILSVRC2012_train/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9158172822407098
      ],
      "excerpt": "Tune a Model A1 from our released Model A, and check its performance: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9859865447269304
      ],
      "excerpt": "It cost more than 40 days on our workstation with 4 Maxwell GTX Titan cards. So, be patient or try smaller models as described in our report. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9198973681120953,
        0.9794937523134953
      ],
      "excerpt": "Note: This code may not accurately reproduce our reported results, since there are subtle differences in implementation, e.g., different cropping strategies, interpolation methods, and padding strategies. \nWe show the effectiveness of our models (as pre-trained features) by semantic image segmenatation using plain dilated FCNs initialized from our models. Several A1 models tuned on the train set of PASCAL VOC, Cityscapes and ADE20K are available. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "    data/VOCdevkit/VOC2012 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8552142604021277
      ],
      "excerpt": "Check the performance of the pre-trained models: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "    data/cityscapes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9024545376730563
      ],
      "excerpt": "Check the performance of the pre-trained model: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8105370752705635
      ],
      "excerpt": "Tune a Model A1, and check its performance: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8258656090717994
      ],
      "excerpt": "Model A2, 2 conv.|fine|1024x2048|78.4|59.1|90.9|81.1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9586192962002953
      ],
      "excerpt": "For more information, refer to the official leaderboard. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9024545376730563
      ],
      "excerpt": "Check the performance of the pre-trained model: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code for https://arxiv.org/abs/1611.10080",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/itijyou/ademxapp/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 98,
      "date": "Mon, 27 Dec 2021 06:10:16 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/itijyou/ademxapp/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "itijyou/ademxapp",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/itijyou/ademxapp/master/tools/ilsvrc-cls_eval.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9495609924691306
      ],
      "excerpt": "To use, first install MXNet. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833114516308531
      ],
      "excerpt": "    ```bash \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9257175720597752
      ],
      "excerpt": "    with the following structure: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833114516308531
      ],
      "excerpt": "    ```bash \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833114516308531
      ],
      "excerpt": "    ```bash \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833114516308531
      ],
      "excerpt": "    ```bash \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9257175720597752
      ],
      "excerpt": "    with the following structure: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833114516308531
      ],
      "excerpt": "    ```bash \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9257175720597752
      ],
      "excerpt": "    with the following structure: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833114516308531,
        0.9662014118758282
      ],
      "excerpt": "    bash \n    git clone https://github.com/mcordts/cityscapesScripts.git data/cityscapesScripts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833114516308531
      ],
      "excerpt": "    bash \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833114516308531
      ],
      "excerpt": "    ```bash \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9257175720597752
      ],
      "excerpt": "    with the following structure: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833114516308531
      ],
      "excerpt": "    bash \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8148265713571851
      ],
      "excerpt": "Download the ILSVRC 2012 classification val set 6.3GB, and put the extracted images into the directory: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8218972584963264
      ],
      "excerpt": "Download the models as below, and put them into the directory: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9097243750784404,
        0.9193032141586432
      ],
      "excerpt": "    python iclass/ilsvrc.py --data-root data/ilsvrc12 --output output --batch-images 10 --phase val --weights models/ilsvrc-cls_rna-a_cls1000_ep-0001.params --split val --test-scales 320 --gpus 0 --no-choose-interp-method --pool-top-infer-style caffe \npython iclass/ilsvrc.py --data-root data/ilsvrc12 --output output --batch-images 10 --phase val --weights models/ilsvrc-cls_rna-a1_cls1000_ep-0001.params --split val --test-scales 320 --gpus 0 --no-choose-interp-method \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8538612334178313
      ],
      "excerpt": "Download the ILSVRC 2012 classification train set 138GB, and put the extracted images into the directory: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8933044413218201,
        0.9403110003198905
      ],
      "excerpt": "    python iclass/ilsvrc.py --gpus 0,1,2,3 --data-root data/ilsvrc12 --output output --model ilsvrc-cls_rna-a_cls1000 --batch-images 256 --crop-size 224 --lr-type linear --base-lr 0.1 --to-epoch 90 --kvstore local --prefetch-threads 8 --prefetcher process --backward-do-mirror \npython iclass/ilsvrc.py --data-root data/ilsvrc12 --output output --batch-images 10 --phase val --weights output/ilsvrc-cls_rna-a_cls1000_ep-0090.params --split val --test-scales 320 --gpus 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9297416234512466,
        0.9450842783010156
      ],
      "excerpt": "    python iclass/ilsvrc.py --gpus 0,1,2,3 --data-root data/ilsvrc12 --output output --model ilsvrc-cls_rna-a1_cls1000_from-a --batch-images 256 --crop-size 224 --weights models/ilsvrc-cls_rna-a_cls1000_ep-0001.params --lr-type linear --base-lr 0.01 --to-epoch 9 --kvstore local --prefetch-threads 8 --prefetcher process --backward-do-mirror \npython iclass/ilsvrc.py --data-root data/ilsvrc12 --output output --batch-images 10 --phase val --weights output/model ilsvrc-cls_rna-a1_cls1000_from-a_ep-0009.params --split val --test-scales 320 --gpus 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8933044413218201,
        0.9403110003198905
      ],
      "excerpt": "    python iclass/ilsvrc.py --gpus 0,1,2,3 --data-root data/ilsvrc12 --output output --model ilsvrc-cls_rna-a1_cls1000 --batch-images 256 --crop-size 224 --lr-type linear --base-lr 0.1 --to-epoch 90 --kvstore local --prefetch-threads 8 --prefetcher process --backward-do-mirror \npython iclass/ilsvrc.py --data-root data/ilsvrc12 --output output --batch-images 10 --phase val --weights output/ilsvrc-cls_rna-a1_cls1000_ep-0090.params --split val --test-scales 320 --gpus 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8611396402871991
      ],
      "excerpt": "Download the PASCAL VOC 2012 dataset 2GB, and put the extracted images into the directory: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9358678388117333,
        0.9358678388117333
      ],
      "excerpt": "    python issegm/voc.py --data-root data/VOCdevkit --output output --phase val --weights models/voc_rna-a1_cls21_s8_ep-0001.params --split val --test-scales 500 --test-flipping --gpus 0 \npython issegm/voc.py --data-root data/VOCdevkit --output output --phase val --weights models/voc_rna-a1_cls21_s8_coco_ep-0001.params --split val --test-scales 500 --test-flipping --gpus 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.909822587525505
      ],
      "excerpt": "model|training data|testing scale|mean IoU (%)|download \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8824558514439843
      ],
      "excerpt": "model|training data|testing scale|mean IoU (%) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8411709432305723
      ],
      "excerpt": "Download the Cityscapes dataset, and put the extracted images into the directory: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9358678388117333
      ],
      "excerpt": "    python issegm/voc.py --data-root data/cityscapes --output output --phase val --weights models/cityscapes_rna-a1_cls19_s8_ep-0001.params --split val --test-scales 2048 --test-flipping --gpus 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.93639655689743,
        0.9286872053323798,
        0.9326395483789048
      ],
      "excerpt": "    python issegm/voc.py --gpus 0,1,2,3 --split train --data-root data/cityscapes --output output --model cityscapes_rna-a1_cls19_s8 --batch-images 16 --crop-size 500 --origin-size 2048 --scale-rate-range 0.7,1.3 --weights models/ilsvrc-cls_rna-a1_cls1000_ep-0001.params --lr-type fixed --base-lr 0.0016 --to-epoch 140 --kvstore local --prefetch-threads 8 --prefetcher process --cache-images 0 --backward-do-mirror \npython issegm/voc.py --gpus 0,1,2,3 --split train --data-root data/cityscapes --output output --model cityscapes_rna-a1_cls19_s8_x1-140 --batch-images 16 --crop-size 500 --origin-size 2048 --scale-rate-range 0.7,1.3 --weights output/cityscapes_rna-a1_cls19_s8_ep-0140.params --lr-type linear --base-lr 0.0008 --to-epoch 64 --kvstore local --prefetch-threads 8 --prefetcher process --cache-images 0 --backward-do-mirror \npython issegm/voc.py --data-root data/cityscapes --output output --phase val --weights output/cityscapes_rna-a1_cls19_s8_x1-140_ep-0064.params --split val --test-scales 2048 --test-flipping --gpus 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.909822587525505
      ],
      "excerpt": "model|training data|testing scale|mean IoU (%)|download \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": "    |   |-- training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": "        |-- training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9152091694859633
      ],
      "excerpt": "    python issegm/voc.py --data-root data/ade20k --output output --phase val --weights models/ade20k_rna-a1_cls150_s8_ep-0001.params --split val --test-scales 500 --test-flipping --test-steps 2 --gpus 0 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/itijyou/ademxapp/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/itijyou/ademxapp/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b' Copyright 2017 The University of Adelaide\\n\\n Licensed under the Apache License, Version 2.0 (the \"License\");\\n you may not use this file except in compliance with the License.\\n You may obtain a copy of the License at\\n\\n     http://www.apache.org/licenses/LICENSE-2.0\\n\\n Unless required by applicable law or agreed to in writing, software\\n distributed under the License is distributed on an \"AS IS\" BASIS,\\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n See the License for the specific language governing permissions and\\n limitations under the License.\\n\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "ademxapp",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ademxapp",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "itijyou",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/itijyou/ademxapp/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 336,
      "date": "Mon, 27 Dec 2021 06:10:16 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "resnet-38",
      "semantic-segmentation",
      "cityscapes"
    ],
    "technique": "GitHub API"
  }
}
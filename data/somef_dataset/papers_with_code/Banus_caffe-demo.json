{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": ".. _1:\n\n[1] Iandola, F. N., Moskewicz, M. W., Ashraf, *et al.* (2016). SqueezeNet: \nAlexNet-level accuracy with 50x fewer parameters and <1MB model size.\n`Arxiv <http://arxiv.org/abs/1602.07360>`__. \n\n.. _2:\n\n[2] Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2015). \nYou Only Look Once: Unified, Real-Time Object Detection. \n`Arxiv <http://arxiv.org/abs/1506.02640>`__.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8490817347094297
      ],
      "excerpt": "   scaling and center crop \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Banus/caffe-demo",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-10-31T16:38:21Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-11T17:42:31Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9129967521309617
      ],
      "excerpt": "Create the environent with: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8424330109919367
      ],
      "excerpt": "The supported networks are specified in a network.ini configuration \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "model = path_to_caffe_prototxt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8999531193718416,
        0.9641939301427074
      ],
      "excerpt": "anchors = list of floats \nThe parameter type specifies the kind of network to load; as for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "   scaling and center crop \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8941942516558345
      ],
      "excerpt": "The parameters model and weights point to the Caffe files \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9001219401078483,
        0.9117880882184125,
        0.9457968344561962,
        0.896248133049056
      ],
      "excerpt": "(.caffemodel). All the paths are relative to the configuration file. \nThe labels parameter points to a file with the name of the \nrecognized classes in the order expected by the model. Currently are \navailable the classes for the ImageNet, Places250, PascalVOC and MSCoCo \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503193425589125
      ],
      "excerpt": "available, the mean of the input image is used instead. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8080824548324314
      ],
      "excerpt": "model. You can override the parameter for a specific network by \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Collection of deep learning demos based on neworks from the Caffe Zoo",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Banus/caffe-demo/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Tue, 28 Dec 2021 20:20:50 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Banus/caffe-demo/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Banus/caffe-demo",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/Banus/caffe-demo/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Banus/caffe-demo/master/models/download_models.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To run the demos, you need to compile the toolbox \n`Caffe <https://github.com/BVLC/caffe>`_ with Python support; follow the\ninstructions on the \n`BVLC website <http://caffe.berkeleyvision.org/installation.html>`_.\nYou both Python 2.7 and Python 3.5 distributions are supported.\n\nYou need also to install the Python interfaces for OpenCV; on Ubuntu:\n\n.. code:: bash\n\n    sudo apt-get install python-opencv\n\nThe script searches the current location of the Caffe toolbox in the\nenvironmental variable ``CAFFE_ROOT``. Set it to your Caffe installation, e.g:\n\n.. code:: bash\n\n    export CAFFET_ROOT=${HOME}/caffe\n\nYou can download automatically all the networks supported by the demo\nrunning the following script (beware: it will download around 500 MB):\n\n.. code:: bash\n\n    cd models && ./download_models.sh all\n\nYou can also download only the models you plan to use by passing them as\nparameters, e.g.\n\n.. code:: bash\n\n    ./download_models.sh caffenet squeezenet\n\n`YOLO <https://github.com/banus/caffe-yolo>`_ models cannot be\nautomatically downloaded from Google Drive and thus you have to download them\nmanually in the `models/yolo` path.\nThe links to the network weights in Caffe format are here:\n\n+ `tiny_yolo <https://drive.google.com/open?id=0Bx7QZuu7oVBbNEt5YmUzRGNXZlk>`_ (CoCo classes)\n+ `tiny_yolo_voc <https://drive.google.com/open?id=0Bx7QZuu7oVBbSEdpaDBGMVFIVk0>`_ (Pascal VOC classes)\n+ `darknet <https://drive.google.com/open?id=0Bx7QZuu7oVBbU19ZdU5neFl0T1k>`__ (ImageNet 1k)\n+ `tiny <https://drive.google.com/open?id=0Bx7QZuu7oVBbRUxyRk9NOFRueGM>`_ (ImageNet 1k)\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9862080451635238,
        0.8816943733189382,
        0.9275333945612022
      ],
      "excerpt": "You can run the demos in Windows by installing one of the \nCaffe for Windows &lt;https://github.com/BVLC/caffe/tree/windows&gt;_ pre-built \nTo install the script dependences, such as OpenCV, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.868822586531394,
        0.8966360634403558
      ],
      "excerpt": "If you use Python 3, Caffe currently supports only the version 3.5, so you may \nhave to create a virtual environment and activate it. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8840830408604178
      ],
      "excerpt": "environments) if you are using Python 3: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9201623672289224,
        0.8039964829152001,
        0.9940979294722775,
        0.9895906924935007
      ],
      "excerpt": "conda create -n caffe python=3.5 \nactivate caffe \nconda install scikit-image \nconda install -c conda-forge py-opencv protobuf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8221534294748023
      ],
      "excerpt": "conda create -n caffe -f caffe-env.yml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9680501544441069
      ],
      "excerpt": "To download the models, use the Git bash shell: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9825471640550012,
        0.8540596680686704
      ],
      "excerpt": "cd models &amp;&amp; sh download_models.sh all \nThe YOLO models will need to be downloaded manually. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9101052096926969
      ],
      "excerpt": "section specifies if the CPU or the GPU (default) should be used for the \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8597720428915796
      ],
      "excerpt": ".cfg file. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Banus/caffe-demo/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/Banus/caffe-demo/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 2-Clause License\\n\\nCopyright (c) 2016, Emanuele Plebani\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n Redistributions of source code must retain the above copyright notice, this\\n  list of conditions and the following disclaimer.\\n\\n Redistributions in binary form must reproduce the above copyright notice,\\n  this list of conditions and the following disclaimer in the documentation\\n  and/or other materials provided with the distribution.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n\\n\\nYoloDetector is based on code from caffe-yolo: \\n    https://github.com/xingwangsfu/caffe-yolo\\n\\nand is free for non-commercial use.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "|Python27| |Python35| |License|\n\n.. |Python27| image:: https://img.shields.io/badge/python-2.7-blue.svg\n    :target: https://www.python.org/\n\n.. |Python35| image:: https://img.shields.io/badge/python-3.5-blue.svg\n    :target: https://www.python.org/\n\n.. |License| image:: https://img.shields.io/badge/license-BSD2-blue.svg\n    :target: https://github.com/Banus/caffe-demo/blob/master/LICENSE\n\n\nCaffe demo",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "caffe-demo",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Banus",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Banus/caffe-demo/blob/master/README.rst",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 15,
      "date": "Tue, 28 Dec 2021 20:20:50 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "python",
      "caffe",
      "deep-learning"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This is a showcase of a small collection of neural networks implemented\nin Caffe, in order to evaluate their speed and accuracy on videos and\nimages. A webcam interface is also available for live demos.\n\n.. figure:: docs/jaguarUI.jpg\n   :alt: Classification interface\n\n**Demo interface.** Image classification with SqueezeNet.\nJaguar image by *CaptainGiraffehands* on \n`Imgur <http://imgur.com/gallery/md8HT>`_.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Download all the models:\n\n.. code:: bash\n\n    cd models && ./download_models.sh all\n    cd ..\n\nTry the classification interface with *SqueezeNet* [1_]:\n\n.. code:: bash\n\n    python deep_classification.py images/jaguar.jpg squeezenet\n\nTry classification on webcam with *GoogleNet*:\n\n.. code:: bash\n\n    python deep_classification.py webcam googlenet\n\nTry the detection interface (CoCo classes) with the *Yolo-tiny* model:\n\n.. code:: bash\n\n    python deep_classification.py images/giraffe.jpg tiny_yolo\n\nAnd the detection interface with Pascal VOC classes:\n\n.. code:: bash\n\n    python deep_classification.py images/dog.jpg tiny_yolo_voc\n\n\n.. figure:: docs/dogUI.jpg\n   :alt: Detection interface\n\n**Detection interface.** Object detection with YOLO-tiny.\nImage from `Darknet <http://pjreddie.com/darknet/yolo/>`_ by Joseph Chet Redmon.\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
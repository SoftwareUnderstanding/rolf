{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1508.01211"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [Listen, Attend and Spell](https://arxiv.org/pdf/1508.01211.pdf)\n- [Attention-Based Models for Speech Recognition](https://arxiv.org/pdf/1506.07503.pdf)\n- [On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition](https://arxiv.org/pdf/1902.01955.pdf)\n- Char RNNLM: [TensorFlow-Char-RNN](https://github.com/crazydonkey200/tensorflow-char-rnn)\n- A nice Pytorch version: [End-to-end-ASR-Pytorch](https://github.com/Alexander-H-Liu/End-to-end-ASR-Pytorch).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8257494055532204
      ],
      "excerpt": "Results trained on LibriSpeech-360 (WER) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/30stomercury/Automatic-Speech-Recognition",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-11-19T14:55:42Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T08:40:18Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9857759211046412
      ],
      "excerpt": "This is a tensorflow implementation of end-to-end ASR. Though there are several fantastic github repos in tensorflow, I tried to implement it without using tf.contrib.seq2seq API in this repo. In addition, the performance on LibriSpeech dev/test sets is evaluated and the evaluation results are reasonable. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9043174907391182
      ],
      "excerpt": "MFCC/fbank acoustic features with per utterance CMVN. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8831471922353172
      ],
      "excerpt": "Note that this project is still in progress. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9455154840219827
      ],
      "excerpt": "    - Currently, I only test this model on MFCC 39 (13+delta+accelerate) features. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.97524581942442
      ],
      "excerpt": "CNN-based Listener. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9641032507464323,
        0.9347585444603863
      ],
      "excerpt": "In my experience, adding more data is the best policy. \nA better way to check if your model is learning in a right way is to monitor the speech-text aligments in tensorboard or set verbosity=1. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9024206089626198
      ],
      "excerpt": "The definitions of the args are described in las/arguments.py. You can modify all args there before preprocessing, training, testing and decoding. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9620242064349239
      ],
      "excerpt": "[ ] Decoding with subword-based RNNLM.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "End-to-End Speech Recognition Using Tensorflow",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/30stomercury/Automatic_Speech_Recognition/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Mon, 27 Dec 2021 17:46:37 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/30stomercury/Automatic-Speech-Recognition/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "30stomercury/Automatic-Speech-Recognition",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/30stomercury/Automatic_Speech_Recognition/master/prepare_libri_data.sh",
      "https://raw.githubusercontent.com/30stomercury/Automatic_Speech_Recognition/master/run.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Libirspeech train/dev/test data\n```bash\nbash prepare_libri_data.sh \n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9630513359443713
      ],
      "excerpt": "bash run.sh \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9466492719854323
      ],
      "excerpt": "  <img src=\"demo/las.png\" width=\"610\" height=\"400\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "Char/Subword text encoding. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8721276624230738
      ],
      "excerpt": "LAS training (visualized with tensorboard: loss, sample text outputs, features, alignments).   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9284376511028222
      ],
      "excerpt": "  <img src=\"demo/align.png\" width=\"730\" height=\"200\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008783753051563
      ],
      "excerpt": "The definitions of the args are described in las/arguments.py. You can modify all args there before preprocessing, training, testing and decoding. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "Train RNNLM:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8765944928524806,
        0.8801088077198941
      ],
      "excerpt": "python3 test.py --split SPLIT \\           #: test or dev \n                --unit UNIT \\  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8476177771819052,
        0.8801088077198941
      ],
      "excerpt": "python3 decode.py --split SPLIT \\         #: test or dev \n                  --unit UNIT \\  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8056271915495306
      ],
      "excerpt": "| Model |  dev-clean  |  test-clean  |  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8639700126890775
      ],
      "excerpt": "[ ] Evaluate the performance with subword unit: Subword las training.  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/30stomercury/Automatic-Speech-Recognition/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "A TensorFlow Implementation of [Listen Attention and Spell](https://arxiv.org/abs/1508.01211)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Automatic-Speech-Recognition",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "30stomercury",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/30stomercury/Automatic-Speech-Recognition/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\npip3 install virtualenv\nvirtualenv --python=python3 venv\nsource venv/bin/activate\npip3 install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 34,
      "date": "Mon, 27 Dec 2021 17:46:37 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "speech-recognition",
      "listen-attend-and-spell",
      "tensorflow",
      "automatic-speech-recognition",
      "asr",
      "librispeech",
      "tfrecord",
      "location-aware-attention"
    ],
    "technique": "GitHub API"
  }
}
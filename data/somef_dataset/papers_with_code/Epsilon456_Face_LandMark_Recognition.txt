# Face_LandMark_Recognition

## Overview
This algorithm analyzes images of faces to identify landmark points corresponding to the center of each eye. The algorithm uses an an hour-glass structure based off the "Stacked Hourglass Networks for Human Pose Estimation" paper. The main advantage of this structure is that it allows the convolutional network to be aware of both local features and non-local features across the image.  

The link to the paper can be found here:https://arxiv.org/abs/1603.06937

## Datasets
The dataset used for this code comes from kaggle's "Face Images with Marked Landmark Points" dataset which can be found here:
https://www.kaggle.com/drgilermo/face-images-with-marked-landmark-points
The dataset consists of images of faces with a corresponding csv file which contains the coordinates for the landmarks on each image. Only the left and right eye centers are used in this demonstration.

## Algorithm description

### Heat Map
Rather than reducing the resolution of an image through convolution and pooling operations and then feeding the results into a fully connected network, this method instead expands the resolution back to the original by the use of convolution transpose operations. As a result, the network will output an image with the same resolution as the original input image. 
In order to make the labels the same shape as the network output tensor, a heatmap is generated for each image.  The heatmap is the same resolution as the original image, however, it has an extra axis for the left and right eyes. The shape of the heatmap is [batchSize,96,96,2].

The heat map is generated by a preprocessing function that will take the distance between a given pixel and a given landmark point.  The euclidian distance is then fed through a decaying exponential acitviation function.  As a result, pixels closest to the landmark will contain higher values in the heatmap and pixels furtherst from the landmark will contain values approaching zero.

### Hour Glass
The network contains to halves - a "downsample" section and an "upsample" section.  At each layer of the downsample section, the resolution of the image is decreased by half as the number of convolutional filters is increased.  Lowering the resolution in this way makes the network more aware of features that are further away from each other.  At the same time, the heatmap's resolution is decreased so that a version of the heatmap at the same resolution as any given downsample layer is available. 

The upsample section brings doubles the resolution at each layer while decreasing the number of filters. This gives the network more awareness of features that are next to each other. In each upsample layer, the sum of the previous layer and the corresponding downsampled layer is added together before the convolution is performed.

{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1904.12935",
      "https://arxiv.org/abs/1403.6652",
      "https://arxiv.org/abs/1904.12935"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9996487902675577
      ],
      "excerpt": "Paper presented at ICLR 2019 workshop on Representation Learning on Graphs and Manifolds. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222383658450612
      ],
      "excerpt": "@article{oh2019advancing,   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9933537248551054,
        0.9999537354568557,
        0.9960965048981569
      ],
      "excerpt": "    author={Oh, Jihun and Cho, Kyunghyun and Bruna, Joan},   \n      journal={arXiv preprint arXiv:1904.12935},   \n        year={2019}   \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/oj9040/GraphSAGE_RL",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-23T19:37:15Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-15T11:39:33Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9233763901165701
      ],
      "excerpt": "local neighborhoods and by learning in a mini-batch gradient descent fashion. The \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9289052476855434
      ],
      "excerpt": "and memory efficiency when inferring a batch of target nodes with diverse \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714250411818691,
        0.9485681175309401,
        0.9168598303817667,
        0.9945781944508919,
        0.9489070937224374,
        0.8998125752301518
      ],
      "excerpt": "from high variance in training and inference, leading to sub-optimum accuracy. \nWe propose a new data-driven sampling approach to reason about the real-valued \nimportance of a neighborhood by a non-linear regressor, and to use the value as a \ncriterion for subsampling neighborhoods. The regressor is learned using a valuebased \nreinforcement learning. The implied importance for each combination of \nvertex and neighborhood is inductively extracted from the negative classification \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9598806431110144,
        0.8810416402974854
      ],
      "excerpt": "using three datasets, our method enhanced the baseline using the uniform \nsampling, outperforming recent variants of a graph neural network in accuracy. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8013659882375369
      ],
      "excerpt": "As input, at minimum the code requires that a --train_prefix option is specified which specifies the following data files: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8102797930774399,
        0.8272509329037371
      ],
      "excerpt": "<train_prefix>-id_map.json -- A json-stored dictionary mapping the graph node ids to consecutive integers. \n<train_prefix>-class_map.json -- A json-stored dictionary mapping the graph node ids to classes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8557995018665662
      ],
      "excerpt": "To run random walks for the unsupervised model and to generate the <prefix>-walks.txt file) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9740213450150645,
        0.8940330190882022,
        0.8735615260478407,
        0.9620242064349239,
        0.8742001871839643,
        0.8663643806374103,
        0.9620242064349239,
        0.9852635929070211
      ],
      "excerpt": "The user must also specify a --model, the variants of which are described in detail in the paper: \n* mean_concat -- GraphSage with mean-concat based aggregator \n* mean_add -- GraphSage with mean-add based aggregator (default) \n* graphsage_seq -- GraphSage with LSTM-based aggregator \n* graphsage_maxpool -- GraphSage with max-pooling aggregator (as described in the NIPS 2017 paper) \n* graphsage_meanpool -- GraphSage with mean-pooling aggregator (a variant of the pooling aggregator, where the element-wie mean replaces the element-wise max). \n* gcn -- GraphSage with GCN-based aggregator \n* n2v -- an implementation of DeepWalk (called n2v for short in the code.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8935130479267401
      ],
      "excerpt": "The output of the model and log files will be stored in a subdirectory of the base_log_dir. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9536640235152143
      ],
      "excerpt": "Note that the full log outputs and stored embeddings can be 5-10Gb in size (on the full data when running with the unsupervised variant). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Advancing GraphSAGE with A Data-driven Node Sampling",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Below dataset are not included in github due to big size, but can be downloaded from links\n\nPPI (Protein-Protein Interaction)\n\n    $ wget http://snap.stanford.edu/graphsage/ppi.zip\n\nReddit\n\n    $ wget http://snap.stanford.edu/graphsage/reddit.zip\n\n\nPubmed is included in ./data/pubmed folder\nFor the dataset with different format, convert it using create_Graph_forGraphSAGE.py.\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/oj9040/GraphSAGE_RL/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Sun, 26 Dec 2021 12:03:12 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/oj9040/GraphSAGE_RL/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "oj9040/GraphSAGE_RL",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/oj9040/GraphSAGE_RL/master/example_supervised.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9308802241565115
      ],
      "excerpt": "or start a Jupyter Notebook instead of bash: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8676582071725453,
        0.9035953920195159,
        0.8683762030448401
      ],
      "excerpt": "You can also run the GPU image using nvidia-docker: \n$ docker build -t graphsage:gpu -f Dockerfile.gpu . \n$ nvidia-docker run -it graphsage:gpu bash \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8491726280382825
      ],
      "excerpt": "Finally, a --base_log_dir should be specified (it defaults to the current directory). \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8463362338332842
      ],
      "excerpt": "<train_prefix>-G.json -- A networkx-specified json file describing the input graph. Nodes have 'val' and 'test' attributes specifying if they are a part of the validation and test sets, respectively. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8774619703448931
      ],
      "excerpt": "<train_prefix>-walks.txt [optional] --- A text file specifying random walk co-occurrences (one pair per line) (*only for unsupervised version of graphsage) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8144936398056025
      ],
      "excerpt": "To run random walks for the unsupervised model and to generate the <prefix>-walks.txt file) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.827613632252934,
        0.8510818500008063
      ],
      "excerpt": "The supervised model will output F1 scores, while the unsupervised model will train embeddings and store them. \nThe unsupervised embeddings will be stored in a numpy formated file named val.npy with val.txt specifying the order of embeddings as a per-line list of node ids. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/oj9040/GraphSAGE_RL/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Advancing GraphSAGE with A Data-driven Node Sampling",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "GraphSAGE_RL",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "oj9040",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/oj9040/GraphSAGE_RL/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Recent versions of TensorFlow, numpy, scipy, sklearn, and networkx are required (but networkx must be <=1.11). You can install all the required packages using the following command:\n\n\t$ pip install -r requirements.txt\n\nTo guarantee that you have the right package versions, you can use [docker](https://docs.docker.com/) to easily set up a virtual environment. See the Docker subsection below for more info.\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The example_unsupervised.sh file contains example usages for three dataset (PPI, Reddit, Pubmed) of the code in the supervised classification task.\n\nIf your benchmark/task does not require generalizing to unseen data, we recommend you try setting the \"--identity_dim\" flag to a value in the range [64,256].\nThis flag will make the model embed unique node ids as attributes, which will increase the runtime and number of parameters but also potentially increase the performance.\nNote that you should set this flag and *not* try to pass dense one-hot vectors as features (due to sparsity).\nThe \"dimension\" of identity features specifies how many parameters there are per node in the sparse identity-feature lookup table.\n\n*Note:* For the PPI data, and any other multi-ouput dataset that allows individual nodes to belong to multiple classes, it is necessary to set the `--sigmoid` flag during supervised training. By default the model assumes that the dataset is in the \"one-hot\" categorical setting.\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 19,
      "date": "Sun, 26 Dec 2021 12:03:12 GMT"
    },
    "technique": "GitHub API"
  }
}
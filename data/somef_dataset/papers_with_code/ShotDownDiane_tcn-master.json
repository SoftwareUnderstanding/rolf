{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- https://github.com/locuslab/TCN/ (TCN for Pytorch)\n- https://arxiv.org/pdf/1803.01271.pdf (An Empirical Evaluation of Generic Convolutional and Recurrent Networks\nfor Sequence Modeling)\n- https://arxiv.org/pdf/1609.03499.pdf (Original Wavenet paper)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8772692606136239
      ],
      "excerpt": "Reproducible results \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": "m.fit(x, y, epochs=10, validation_split=0.2) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ShotDownDiane/tcn-master",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-28T08:17:10Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-04T16:07:33Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8207436385098936,
        0.8884615282464804
      ],
      "excerpt": "TCNs exhibit longer memory than recurrent architectures with the same capacity. \nConstantly performs better than LSTM/GRU architectures on a vast range of tasks (Seq. MNIST, Adding Problem, Copy Memory, Word-level PTB...). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8347993157070009
      ],
      "excerpt": "  <b>Visualization of a stack of dilated causal convolutional layers (Wavenet, 2016)</b><br><br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833103669914182
      ],
      "excerpt": "The usual way is to import the TCN layer and use it inside a Keras model. An example is provided below for a regression task (cf. tasks/ for other examples): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8577302739126875
      ],
      "excerpt": "o = Dense(1)(o) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8318928940561254
      ],
      "excerpt": "A ready-to-use TCN model can be used that way (cf. tasks/ for the full code): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.860059181823877
      ],
      "excerpt": "model = compiled_tcn(...) \nmodel.fit(x, y) #: Keras model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9460710737895867
      ],
      "excerpt": "padding: String. The padding to use in the convolutions. 'causal' for a causal network (as in the original implementation) and 'same' for a non-causal network. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8559252145189965
      ],
      "excerpt": "dropout_rate: Float between 0 and 1. Fraction of the input units to drop. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.918617708960551
      ],
      "excerpt": "3D tensor with shape (batch_size, timesteps, input_dim). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9678334323593218
      ],
      "excerpt": "For a Many to Many regression, a cheap fix for now is to change the number of units of the final Dense layer. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9251928896482415
      ],
      "excerpt": "If a TCN has only one stack of residual blocks with a kernel size of 2 and dilations [1, 2, 4, 8], its receptive field is 2 * 1 * 8 = 16. The image below illustrates it: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9038108852247264
      ],
      "excerpt": "If the TCN has now 2 stacks of residual blocks, wou would get the situation below, that is, an increase in the receptive field to 32: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9277819045824917
      ],
      "excerpt": "If we increased the number of stacks to 3, the size of the receptive field would increase again, such as below: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9497313588471271,
        0.911462496040253,
        0.9196640848252542
      ],
      "excerpt": "Thanks to @alextheseal for providing such visuals. \nMaking the TCN architecture non-causal allows it to take the future into consideration to do its prediction as shown in the figure below. \nHowever, it is not anymore suitable for real-time applications. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762,
        0.8312475494599624,
        0.9430446856127283
      ],
      "excerpt": "Special thanks to: @qlemaire22 \nReproducible results are possible on (NVIDIA) GPUs using the tensorflow-determinism library. It was tested with keras-tcn by @lingdoc and he got reproducible results. \nThe task consists of feeding a large array of decimal numbers to the network, along with a boolean array of the same length. The objective is to sum the two decimals where the boolean array contain the two 1s. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9789720396303067
      ],
      "excerpt": "The model takes time to learn this task. It's symbolized by a very long plateau (could take ~8 epochs on some runs). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9675889659343418,
        0.8403334765405364,
        0.9263409646022193,
        0.9915824725718667
      ],
      "excerpt": "- At the beginning, there's the vector x of length N. This is the vector to copy. \n- At the end, N+1 9s are present. The first 9 is seen as a delimiter. \n- In the middle, only 0s are there. \nThe idea is to copy the content of the vector x to the end of the large array. The task is made sufficiently complex by increasing the number of 0s in the middle. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.977597364636078
      ],
      "excerpt": "The idea here is to consider MNIST images as 1-D sequences and feed them to the network. This task is particularly hard because sequences are 28*28 = 784 elements. In order to classify correctly, the network has to remember all the sequence. Usual LSTM are unable to perform well on this task. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9551255523974804
      ],
      "excerpt": "Testing is based on Tox. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ShotDownDiane/tcn-master/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 07:40:38 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ShotDownDiane/tcn-master/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ShotDownDiane/tcn-master",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ShotDownDiane/tcn-master/master/tasks/exchange_rate/demo.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ShotDownDiane/tcn-master/master/tasks/receptive-field/run.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\ngit clone git@github.com:philipperemy/keras-tcn.git\ncd keras-tcn\nvirtualenv -p python3.6 venv\nsource venv/bin/activate\npip install -r requirements.txt #: change to tensorflow if you dont have a gpu.\npip install . --upgrade #: install it as a package.\n```\n\nNote: Only compatible with Python 3 at the moment. Should be almost compatible with python 2.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.999746712887969
      ],
      "excerpt": "pip install keras-tcn \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9880101850468401
      ],
      "excerpt": "Installation (Python 3) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.999746712887969
      ],
      "excerpt": "pip install tox \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8144338362021298,
        0.8674641586158056
      ],
      "excerpt": "Input shape \nOutput shape \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8836704212480256
      ],
      "excerpt": "  <img src=\"misc/Dilated_Conv.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9094013538584199,
        0.8801854956928516
      ],
      "excerpt": "from tensorflow.keras import Input, Model \nfrom tcn import TCN, tcn_full_summary \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9457175861910134,
        0.8603932075448177,
        0.9142911678144386,
        0.9142911678144386
      ],
      "excerpt": "    import numpy as np \n    pos_indices = np.random.choice(size, size=int(size // 2), replace=False) \n    x_train = np.zeros(shape=(size, timesteps, 1)) \n    y_train = np.zeros(shape=(size, 1)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "o = TCN(return_sequences=True)(i) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from tcn import compiled_tcn \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8023880945069958
      ],
      "excerpt": "TCN(nb_filters=64, kernel_size=2, nb_stacks=1, dilations=[1, 2, 4, 8, 16, 32], padding='causal', use_skip_connections=True, dropout_rate=0.0, return_sequences=True, activation='linear', kernel_initializer='he_normal', use_batch_norm=False, **kwargs) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8828147611847278
      ],
      "excerpt": "kwargs: Any other arguments for configuring parent class Layer. For example \"name=str\", Name of the model. Use unique names when using multiple TCN. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8836704212480256
      ],
      "excerpt": "  <img src=\"misc/Non_Causal.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8836704212480256
      ],
      "excerpt": "  <img src=\"misc/Adding_Task.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8836704212480256
      ],
      "excerpt": "  <img src=\"misc/Copy_Memory_Task.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8836704212480256
      ],
      "excerpt": "  <img src=\"misc/Sequential_MNIST_Task.png\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ShotDownDiane/tcn-master/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Philippe R\\xc3\\xa9my\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Keras TCN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "tcn-master",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ShotDownDiane",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ShotDownDiane/tcn-master/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Once `keras-tcn` is installed as a package, you can take a glimpse of what's possible to do with TCNs. Some tasks examples are  available in the repository for this purpose:\n\n```bash\ncd adding_problem/\npython main.py #: run adding problem task\n\ncd copy_memory/\npython main.py #: run copy memory task\n\ncd mnist_pixel/\npython main.py #: run sequential mnist pixel task\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Wed, 29 Dec 2021 07:40:38 GMT"
    },
    "technique": "GitHub API"
  }
}
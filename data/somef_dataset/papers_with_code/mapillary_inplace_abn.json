{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1712.02616",
      "https://arxiv.org/abs/1712.02616"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use In-Place Activated BatchNorm in your research, please cite:\n```bibtex\n@inproceedings{rotabulo2017place,\n  title={In-Place Activated BatchNorm for Memory-Optimized Training of DNNs},\n  author={Rota Bul\\`o, Samuel and Porzi, Lorenzo and Kontschieder, Peter},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  year={2018}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{rotabulo2017place,\n  title={In-Place Activated BatchNorm for Memory-Optimized Training of DNNs},\n  author={Rota Bul\\`o, Samuel and Porzi, Lorenzo and Kontschieder, Peter},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  year={2018}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9600732982240069
      ],
      "excerpt": "Update 08 Jan. 2019: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/mapillary/inplace_abn/main/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mapillary/inplace_abn",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to InPlace-ABN\nWe want to make contributing to this project as easy and transparent as\npossible.\nPull Requests\nWe actively welcome pull requests addressing bugs. Each pull request should be\nreferenced in a corresponding Issue explaining the bug and how to reproduce it.\nContributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\nComplete your CLA here: https://code.facebook.com/cla\nLicense\nBy contributing to InPlace-ABN, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-11-23T10:47:45Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-20T09:13:24Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8107626854932574,
        0.9297194252583445,
        0.9659572310318358,
        0.8039187584519077
      ],
      "excerpt": "In-Place Activated BatchNorm for Memory-Optimized Training of DNNs \nIn-Place Activated BatchNorm (InPlace-ABN) is a novel approach to reduce the memory required for training deep networks. \nIt allows for up to 50% memory savings in modern architectures such as ResNet, ResNeXt and Wider ResNet by redefining \nBN + non linear activation as a single in-place operation, while smartly dropping or recomputing intermediate buffers as \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9829546495306456,
        0.8957014492501412
      ],
      "excerpt": "This repository contains a PyTorch implementation of the InPlace-ABN layer, as well as some \ntraining scripts to reproduce the ImageNet classification results reported in our paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.95246361333157
      ],
      "excerpt": "We have now also released the inference code for semantic segmentation, together with the Mapillary Vistas trained model leading to #1 position on the Mapillary Vistas Semantic Segmentation leaderboard. More information can be found at the bottom of this page. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8316992173805077,
        0.902973776045962,
        0.9871903471591372
      ],
      "excerpt": "When processing a BN-Activation-Convolution sequence in the forward pass, most deep learning frameworks need to store \ntwo big buffers, i.e. the input x of BN and the input z of Conv. \nThis is necessary because the standard implementations of the backward passes of BN and Conv depend on their inputs to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8903258046301161
      ],
      "excerpt": "Using Inplace-ABN to replace the BN-Activation sequence, we can safely discard x, thus saving up to 50% GPU memory at \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.987527855880591
      ],
      "excerpt": "To achieve this, we rewrite the backward pass of BN in terms of its output y, which is in turn reconstructed from z \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9350907482768466
      ],
      "excerpt": "The parametrization for the scaling factor of BN changed compared to standard BN, in order to ensure an invertible transformation. Specifically, the scaling factor becomes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8988647877488712
      ],
      "excerpt": "In order to force the compilation of the native CUDA functions on systems that do not \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8900302989146218
      ],
      "excerpt": "where {archs} is a list of target CUDA architectures, e.g. Pascal;Volta, 6.0;6.5 etc. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8411243353392794
      ],
      "excerpt": "formatted as described above, while keeping a log of relevant metrics in Tensorboard format and periodically saving \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9007601821125624,
        0.9029547701668864
      ],
      "excerpt": "here for a complete list of configurable parameters). \nAll parameters not explicitly specified in the configuration file are set to their defaults, also available in \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8178357569607204
      ],
      "excerpt": "Validation is run by scripts/train_imagenet.py at the end of every training epoch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9346221914516141
      ],
      "excerpt": "transferring weights across compatible networks (e.g. from ResNeXt101 with ReLU to ResNeXt101 with Leaky \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8344407760732245,
        0.9514435999162787
      ],
      "excerpt": "We release our WideResNet38 + DeepLab3 segmentation model trained on the Mapillary Vistas research set. \nThis is the model used to reach #1 position on the MVD semantic segmentation leaderboard. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8757296395960211
      ],
      "excerpt": "The results on the test data written above were obtained by employing only scale 1.0 + flipping. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8389199193207081,
        0.859277900119605
      ],
      "excerpt": "- Enabled multiprocessing and inplace ABN synchronization over multiple processes (previously using threads). It now requires to use DistributedDataParallel instead of DataParallel \n- Added compatibility with fp16 (currently allows fp16 input but requires the module to stay in fp32 mode) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "In-Place Activated BatchNorm for Memory-Optimized Training of DNNs",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mapillary/inplace_abn/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 172,
      "date": "Thu, 23 Dec 2021 23:24:25 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mapillary/inplace_abn/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "mapillary/inplace_abn",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Our script uses [torchvision.datasets.ImageFolder](http://pytorch.org/docs/master/torchvision/datasets.html#torchvision.datasets.ImageFolder)\nfor loading ImageNet data, which expects folders organized as follows:\n```\nroot/train/[class_id1]/xxx.{jpg,png,jpeg}\nroot/train/[class_id1]/xxy.{jpg,png,jpeg}\nroot/train/[class_id2]/xxz.{jpg,png,jpeg}\n...\n\nroot/val/[class_id1]/asdas.{jpg,png,jpeg}\nroot/val/[class_id1]/123456.{jpg,png,jpeg}\nroot/val/[class_id2]/__32_.{jpg,png,jpeg}\n...\n```\nImages can have any name, as long as the extension is that of a recognized image format.\nClass ids are also free-form, but they are expected to match between train and validation data.\nNote that the training data in the standard ImageNet distribution is already given in the required format, while\nvalidation images need to be split into class sub-folders as described above.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8981706589972761
      ],
      "excerpt": "Using Inplace-ABN to replace the BN-Activation sequence, we can safely discard x, thus saving up to 50% GPU memory at \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9714207429223904
      ],
      "excerpt": "cd scripts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8231975121365623,
        0.9714207429223904
      ],
      "excerpt": "pixels, you can run: \ncd scripts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9714207429223904
      ],
      "excerpt": "cd scripts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8874543109893867,
        0.8886244123283052
      ],
      "excerpt": "Update 04 Jul. 2019: version 1.0.0 \n- Complete rewrite of the CUDA code following the most recent native BN implementation from Pytorch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9497380439086344
      ],
      "excerpt": "- Requires now PyTorch 1.1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9497380439086344
      ],
      "excerpt": "- Requires now PyTorch 1.0 \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8130442830668445
      ],
      "excerpt": "<p align=\"center\"><img width=\"70%\" src=\"inplace_abn.png\" /></p> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8647354795712904
      ],
      "excerpt": "<img src=\"./equation.svg\">. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8403335287609472
      ],
      "excerpt": "| ResNet101v1, InPlace-ABN sync  | 512   | 77.07 / 93.45  | 78.58 / 94.40  | 78.25 / 94.19 | 1552ae0f3d610108df702135f56bd27b | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.850761770535175
      ],
      "excerpt": "As an example, the command to train ResNeXt101 with InPlace-ABN, Leaky ReLU and batch_size = 512 is: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.809721226274636
      ],
      "excerpt": "python -m torch.distributed.launch --nproc_per_node &lt;n. GPUs per node&gt; train_imagenet.py --log-dir /path/to/tensorboard/logs experiments/resnext101_ipabn_lr_512.json /path/to/imagenet/root \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8471995363824647
      ],
      "excerpt": "As an example, to validate the ResNeXt101 trained above using 10-crops of size 224 from images scaled to 256 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8346599548497423
      ],
      "excerpt": "To use this, please download the .pth.tar model file linked above and run the test_vistas.py script as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9055207639764207,
        0.8762165809529852,
        0.9121748789889201
      ],
      "excerpt": "python test_vistas.py /path/to/model.pth.tar /path/to/input/folder /path/to/output/folder \nThe script will process all .png, .jpg and .jpeg images from the input folder and write the predictions in the \noutput folder as .png images. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mapillary/inplace_abn/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cuda",
      "C++",
      "C"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\r\\n\\r\\nCopyright (c) 2017, mapillary\\r\\nAll rights reserved.\\r\\n\\r\\nRedistribution and use in source and binary forms, with or without\\r\\nmodification, are permitted provided that the following conditions are met:\\r\\n\\r\\n Redistributions of source code must retain the above copyright notice, this\\r\\n  list of conditions and the following disclaimer.\\r\\n\\r\\n Redistributions in binary form must reproduce the above copyright notice,\\r\\n  this list of conditions and the following disclaimer in the documentation\\r\\n  and/or other materials provided with the distribution.\\r\\n\\r\\n* Neither the name of the copyright holder nor the names of its\\r\\n  contributors may be used to endorse or promote products derived from\\r\\n  this software without specific prior written permission.\\r\\n\\r\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\r\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\r\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\r\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\r\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\r\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\r\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\r\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\r\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\r\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\r\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "In-Place Activated BatchNorm",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "inplace_abn",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "mapillary",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mapillary/inplace_abn/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "This release updates `ABN`, `InPlaceABN` and `InPlaceABNSync` to feature parity with recent versions of Pytorch's BatchNormNd layers:\r\n* Add a `track_running_stats` parameter to enable / disable computation of running statistics independently from the layer's training state\r\n* Add a `num_batches_tracked` buffer, and allow passing `momentum=None` to support cumulative moving average for tracking running stats instead of exponential moving average\r\n* As a side-effect, now support loading parameters from standard BatchNorm without work-arounds. Still, if the loaded parameters contain negative weight elements the output will differ compared to standard BatchNorm\r\n\r\nAdditional changes:\r\n* Fix backward pass in eval mode: it was not properly accounting for the activation function\r\n* Refactor code to follow more sensible formatting standards\r\n* Add type annotations\r\n* Improve docstrings\r\n* Update installation instructions, pointing to the PyPI package",
        "dateCreated": "2020-09-03T13:58:43Z",
        "datePublished": "2020-09-03T14:23:58Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v1.1.0",
        "name": "Feature parity with Pytorch's BatchNormNd, code clean-up",
        "tag_name": "v1.1.0",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v1.1.0",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/30663683",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v1.1.0"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "",
        "dateCreated": "2020-04-22T13:53:02Z",
        "datePublished": "2020-04-22T13:53:55Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v1.0.12",
        "name": "Pytorch 1.5.0+ compatibility",
        "tag_name": "v1.0.12",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v1.0.12",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/25766459",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v1.0.12"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "",
        "dateCreated": "2020-01-27T14:04:35Z",
        "datePublished": "2020-01-27T14:05:27Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v1.0.11",
        "name": "Pytorch 1.4.0+ compatibility",
        "tag_name": "v1.0.11",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v1.0.11",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/23151477",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v1.0.11"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "This release contains an improved implementation of the fix for the backward pass in v1.0.9 which uses less temporary memory at no additional computational cost.",
        "dateCreated": "2020-01-08T11:16:59Z",
        "datePublished": "2020-01-08T11:19:29Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v1.0.10",
        "name": "Optimized backward pass using less temporary memory",
        "tag_name": "v1.0.10",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v1.0.10",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/22674701",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v1.0.10"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "In previous versions, both the input/output tensor `y` and the gradient tensor `dy` were overwritten during the backward pass. This was causing issues with some network topologies, producing wrong gradients.\r\n\r\nTo fix this issue, a pair of temporary tensors is now created during the backward pass to hold the results of intermediate computations. This change will increase the amount of temporary memory required, meaning that in some cases where GPU memory utilization was already very close to the limit OOM errors might now occur. An alternative, more complex fix is also possible at the expense of additional computational costs. We are evaluating the impact of these changes and will provide updates in a future release.",
        "dateCreated": "2020-01-07T14:27:46Z",
        "datePublished": "2020-01-07T14:39:07Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v1.0.9",
        "name": "Avoid overwriting input tensors during backward pass",
        "tag_name": "v1.0.9",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v1.0.9",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/22649229",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v1.0.9"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "",
        "dateCreated": "2019-11-22T14:51:27Z",
        "datePublished": "2019-11-22T14:52:08Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v1.0.8",
        "name": "Pytorch 1.3.0+ compatibility",
        "tag_name": "v1.0.8",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v1.0.8",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/21688182",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v1.0.8"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "This release fixes a compatibility issue with CUDA 10.0, resulting in compilation errors in some cases.",
        "dateCreated": "2019-09-04T16:44:15Z",
        "datePublished": "2019-09-04T16:45:32Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v1.0.7",
        "name": "Bugfix: compatibility with CUDA 10.0",
        "tag_name": "v1.0.7",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v1.0.7",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/19754870",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v1.0.7"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "At compile time, when determining whether to enable CUDA support, we now base the decision on the Pytorch version installed:\r\n* If a CUDA-enabled Pytorch is detected, we attempt to compile CUDA support\r\n* If a CPU-only Pytorch is detected, we disable CUDA support",
        "dateCreated": "2019-08-23T08:25:39Z",
        "datePublished": "2019-08-23T08:30:39Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v1.0.6",
        "name": "Bugfix: compilation on systems without a CUDA enabled device",
        "tag_name": "v1.0.6",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v1.0.6",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/19488282",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v1.0.6"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "InPlace-ABN can now be compiled and used without CUDA. Note that Synchronized InPlace-ABN is still only supported in conjunction with CUDA-enabled Pytorch.",
        "dateCreated": "2019-08-20T14:52:44Z",
        "datePublished": "2019-08-20T14:54:25Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v1.0.5",
        "name": "CPU-only support",
        "tag_name": "v1.0.5",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v1.0.5",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/19408865",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v1.0.5"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "State dicts from standard BatchNorm layers trained with Pytorch v1.0.0 or newer can now be properly loaded by `ABN`, `InPlaceABN` and `InPlaceABNSync`.",
        "dateCreated": "2019-08-14T08:22:21Z",
        "datePublished": "2019-08-14T08:29:40Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v1.0.4",
        "name": "Compatibility with post-Pytorch v1.0.0 BN state dicts",
        "tag_name": "v1.0.4",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v1.0.4",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/19278576",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v1.0.4"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "Added a couple of functions to manage distributed groups with `InplaceABNSync`:\r\n* `active_group`: create a distributed group where each worker can decide wether to participate or not.\r\n* `set_active_group`: scan a model, passing a distributed group to all layers that implement a `set_group()` method.\r\n\r\nThese are intended to simplify handling of asymmetric computational graphs in `DistributedDataParallel` when using `InplaceABNSync`. A typical usage is as follows:\r\n```python\r\nclass DynamicModel(nn.Module):\r\n    def __init__(self):\r\n        super(DynamicModel, self).__init__()\r\n        self.conv1 = nn.Conv2d(4, 4, 1)\r\n        self.bn1 = InplaceABNSync(4)\r\n        self.conv2 = nn.Conv2d(4, 4, 1)\r\n        self.bn2 = InplaceABNSync(4)\r\n    \r\n    def forward(x):\r\n        x = self.conv1(x)\r\n        x = self.bn1(x)\r\n        \r\n        # Call some data-dependent function telling us wether the second part of the network\r\n        # should be traversed or not\r\n        active = self.get_active(x)\r\n        \r\n        # Create process group containing only the active workers, pass it to bn2\r\n        set_active_group(self.bn2, active_group(active))\r\n        \r\n        # Run the second part of the network only if active is True\r\n        if active:\r\n            x = self.conv2(x)\r\n            x = self.bn2(x)\r\n        \r\n        return x\r\n```",
        "dateCreated": "2019-07-16T15:02:19Z",
        "datePublished": "2019-07-16T15:14:52Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v1.0.3",
        "name": "Distributed group handling",
        "tag_name": "v1.0.3",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v1.0.3",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/18648667",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v1.0.3"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "",
        "dateCreated": "2019-07-08T12:52:51Z",
        "datePublished": "2019-07-08T12:58:41Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v1.0.2",
        "name": "Packaging improvements and Vistas script bugfixes",
        "tag_name": "v1.0.2",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v1.0.2",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/18470672",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v1.0.2"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "This update adds back support for mixed precision training. These combinations of inputs / parameters are now supported:\r\n- `float32` input, `float32` weight and bias\r\n- `float64` input, `float64` weight and bias\r\n- `float16` input, `float16` weight and bias\r\n- `float16` input, `float32` weight and bias\r\n\r\n**Note**: in the `float16` cases all internal operations are still performed with `float32` math, and `float16` is not supported when operating in CPU mode.",
        "dateCreated": "2019-07-05T10:05:58Z",
        "datePublished": "2019-07-05T10:11:33Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v1.0.1",
        "name": "Mixed precision support",
        "tag_name": "v1.0.1",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v1.0.1",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/18433175",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v1.0.1"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "This release marks some major changes in `inplace_abn`:\r\n- Complete rewrite of the CUDA code following the most recent native BN implementation from Pytorch\r\n- Improved synchronized BN implementation, correctly handling different per-GPU batch sizes and Pytorch distributed groups\r\n- The iABN layers are now packaged in an installable python library to simplify use in other projects\r\n- The Imagenet / Vistas scripts are still available in the `scripts` folder",
        "dateCreated": "2019-07-04T13:23:14Z",
        "datePublished": "2019-07-04T13:44:39Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v1.0.0",
        "name": "Split iABN library from training scripts, improved native code and synchronized BN",
        "tag_name": "v1.0.0",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v1.0.0",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/18415502",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v1.0.0"
      },
      {
        "authorType": "User",
        "author_name": "rotabulo",
        "body": "We added the possibility of training ResNet with inplace ABN layers.\r\n\r\nIn addition we released ResNet34 and ResNet50 pre-trained on ImageNet.",
        "dateCreated": "2019-02-14T08:25:00Z",
        "datePublished": "2019-02-14T13:18:12Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v0.1.1",
        "name": "Added ResNet",
        "tag_name": "v0.1.1",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v0.1.1",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/15559500",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v0.1.1"
      },
      {
        "authorType": "User",
        "author_name": "rotabulo",
        "body": "This is a code refactoring to enable compatibility with Pytorch v1.0. \r\n\r\nAdditional changes:\r\n- Moved from multi-threading training to distributed training using multiple processes\r\n- We provide an adapted implementation of synchronized inplace ABN\r\n- Our inplace ABN layer is compatible with fp16 tensors.",
        "dateCreated": "2019-01-08T13:32:43Z",
        "datePublished": "2019-01-08T13:43:39Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v0.1",
        "name": "Pytorch v1.0-compatible release",
        "tag_name": "v0.1",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v0.1",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/14855153",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v0.1"
      },
      {
        "authorType": "User",
        "author_name": "rotabulo",
        "body": "This is a partial code refactoring to enable compatibility with Pytorch v0.4.1. In particular:\r\n- Fixed compatibility with pytorch>=0.4.1 due to change of AT_ASSERT\r\n- Fixed GPU allocation of tensors created in CUDA code\r\n\r\nAdditional changes:\r\n- Added segmentation models and scripts to run inference on Vistas\r\n- Updated license",
        "dateCreated": "2018-09-18T09:44:53Z",
        "datePublished": "2019-01-07T13:37:16Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v0.0.3",
        "name": "Pytorch v0.4.1-compatible release",
        "tag_name": "v0.0.3",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v0.0.3",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/14833158",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v0.0.3"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "This is a partial code refactoring to enable compatibility with Pytorch v0.4. In particular:\r\n- Native functions have been rewritten to use the new ATen-based extension interface introduced in v0.4. As a side effect, the native code doesn't need to be pre-compiled anymore. Instead, we are now using Pytorch's newly introduced run-time library loading mechanism.\r\n- The python code has been modified to account for the fact that `autograd.Variable` does not exist anymore.\r\n\r\nAdditional changes:\r\n- ABN modules have been slightly refactored, leading to a slight change in the structure of the overall models' `state_dict`s. As a consequence, pre-trained models need to be re-downloaded (updated links in `README.md`).\r\n",
        "dateCreated": "2018-07-18T09:38:37Z",
        "datePublished": "2018-07-18T09:50:33Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v0.0.2",
        "name": "Pytorch v0.4-compatible release",
        "tag_name": "v0.0.2",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v0.0.2",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/11982894",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v0.0.2"
      },
      {
        "authorType": "User",
        "author_name": "ducksoup",
        "body": "**NOTE: this is the last release that is compatible with Pytorch v0.3**\r\n\r\nAfter this release, the code will undergo partial rewrite to adapt to the changes introduced in Pytorch v0.4 regarding Tensors / Variables and native functions. As a consequence, we are completely dropping support for versions of Pytorch before v0.3.",
        "dateCreated": "2018-05-08T10:22:30Z",
        "datePublished": "2018-07-17T13:35:16Z",
        "html_url": "https://github.com/mapillary/inplace_abn/releases/tag/v0.0.1",
        "name": "Pytorch v0.3-compatible release",
        "tag_name": "v0.0.1",
        "tarball_url": "https://api.github.com/repos/mapillary/inplace_abn/tarball/v0.0.1",
        "url": "https://api.github.com/repos/mapillary/inplace_abn/releases/11965882",
        "zipball_url": "https://api.github.com/repos/mapillary/inplace_abn/zipball/v0.0.1"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To install PyTorch, please refer to https://github.com/pytorch/pytorch#installation.\n\n**NOTE 1: our code _requires_ PyTorch v1.1 or later**\n\n**NOTE 2: we are only able to provide support for Linux platforms and CUDA versions >= 10.0**\n\n**NOTE 3: in general, it is not possible to load weights from a network trained with standard BN into an InPlace-ABN network without severe performance degradation, due to the different handling of BN scaling parameters**\n\nTo install the package containing the iABN layers:\n```bash\npip install inplace-abn\n```\nNote that some parts of InPlace-ABN have native C++/CUDA implementations, meaning that the command above will need to\ncompile them.\n\nAlternatively, to download and install the latest version of our library, also obtaining a copy of the Imagenet / Vistas\nscripts:\n```bash\ngit clone https://github.com/mapillary/inplace_abn.git\ncd inplace_abn\npython setup.py install\ncd scripts\npip install -r requirements.txt\n```\nThe last of the commands above will install some additional libraries required by the Imagenet / Vistas scripts.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1185,
      "date": "Thu, 23 Dec 2021 23:24:25 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We have successfully used InPlace-ABN with a DeepLab3 segmentation head that was trained on top of the WideResNet38\nmodel above.\nDue to InPlace-ABN, we can significantly increase the amount of input data to this model, which eventually allowed us to\nobtain #1 positions on [Cityscapes](https://www.cityscapes-dataset.com/benchmarks/#scene-labeling-task),\n[Mapillary Vistas](https://eval-vistas.mapillary.com/featured-challenges/1/leaderboard/1), [AutoNUE](http://cvit.iiit.ac.in/scene-understanding-challenge-2018/benchmarks.php),\n[Kitti](http://www.cvlibs.net/datasets/kitti/eval_semseg.php?benchmark=semantics2015) and\n[ScanNet](http://dovahkiin.stanford.edu/adai/semantic_label) segmentation leaderboards.\nThe training settings mostly follow the description in our [paper](https://arxiv.org/abs/1712.02616).\n\n",
      "technique": "Header extraction"
    }
  ]
}
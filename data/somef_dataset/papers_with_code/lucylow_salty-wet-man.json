{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1409.1556\n* Alex Krizhevsky. 2012. ImageNet Classification with Deep Convolutional Networks\n* Yahoo Engineering's Caffe DL library and CaffeOnSpark model. https://yahooeng.tumblr.com/post/151148689421/open-sourcing-a-deep-learning-solution-for\n* CS231n Computer Vision at Stanford University School of Engineering. Fei Fei Lee. https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv\n* Gabriel Goh. Image Synthesis from Yahoo's open_nsfw. https://open_nsfw.gitlab.io/\n* Client-Side NSFW Classification. https://nsfwjs.com/\n* Ring-Filter image processing algorithm for Order Statistics. http://mfleck.cs.illinois.edu/order-statistics.html\n* Mask R-CNN framework for object instance segmentation. https://arxiv.org/abs/1703.06870\n* Margaret M. FleckDavid A. Forsyth Chris Bregler. Finding Naked People. 1996. http://luthuli.cs.uiuc.edu/~daf/papers/naked.pdf\n* PyTorch tutorial review. https://github.com/ritchieng/the-incredible-pytorch and https://pytorch.org/tutorials/\n* ImageNet training in PyTorch. https://github.com/pytorch/examples/tree/master/imagenet\n* PyTorch Image Models. https://github.com/rwightman/pytorch-image-models\n* Image Captioning PyTorch. https://github.com/ruotianluo/ImageCaptioning.pytorch\n* PyTorch Visualizatoins. Implementation of convolutional neural network.\nhttps://github.com/utkuozbulak/pytorch-cnn-visualizations\n* Facebook AI Research. \"Detectron2\". Object detection and segmentation using PyTorch.\nhttps://github.com/facebookresearch/detectron2\n* Facebook AI Research.  \"Faster R-CNN and Mask R-CNN in PyTorch 1.0\". Creating detection and segmentation models using PyTorch .https://github.com/facebookresearch/maskrcnn-benchmark/\n* https://en.wikipedia.org/wiki/Gamergate_controversy\n* https://en.wikipedia.org/wiki/Cyberstalking\n\n\n\n\n",
      "https://arxiv.org/abs/1703.06870\n* Margaret M. FleckDavid A. Forsyth Chris Bregler. Finding Naked People. 1996. http://luthuli.cs.uiuc.edu/~daf/papers/naked.pdf\n* PyTorch tutorial review. https://github.com/ritchieng/the-incredible-pytorch and https://pytorch.org/tutorials/\n* ImageNet training in PyTorch. https://github.com/pytorch/examples/tree/master/imagenet\n* PyTorch Image Models. https://github.com/rwightman/pytorch-image-models\n* Image Captioning PyTorch. https://github.com/ruotianluo/ImageCaptioning.pytorch\n* PyTorch Visualizatoins. Implementation of convolutional neural network.\nhttps://github.com/utkuozbulak/pytorch-cnn-visualizations\n* Facebook AI Research. \"Detectron2\". Object detection and segmentation using PyTorch.\nhttps://github.com/facebookresearch/detectron2\n* Facebook AI Research.  \"Faster R-CNN and Mask R-CNN in PyTorch 1.0\". Creating detection and segmentation models using PyTorch .https://github.com/facebookresearch/maskrcnn-benchmark/\n* https://en.wikipedia.org/wiki/Gamergate_controversy\n* https://en.wikipedia.org/wiki/Cyberstalking\n\n\n\n\n"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* https://www.unicef.org/innovation/apply-ChildOnlineSafety\n* https://www.consumernotice.org/data-protection/internet-safety-for-kids/#explaining-online-risks-to-kids\n* https://raisingchildren.net.au/school-age/play-media-technology/online-safety/internet-safety-6-8-years \n* Karen Simonyan, Andrew Zisserman. Very Deep Convolutional Networks for Large-Scale Image Recognition . https://arxiv.org/abs/1409.1556\n* Alex Krizhevsky. 2012. ImageNet Classification with Deep Convolutional Networks\n* Yahoo Engineering's Caffe DL library and CaffeOnSpark model. https://yahooeng.tumblr.com/post/151148689421/open-sourcing-a-deep-learning-solution-for\n* CS231n Computer Vision at Stanford University School of Engineering. Fei Fei Lee. https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv\n* Gabriel Goh. Image Synthesis from Yahoo's open_nsfw. https://open_nsfw.gitlab.io/\n* Client-Side NSFW Classification. https://nsfwjs.com/\n* Ring-Filter image processing algorithm for Order Statistics. http://mfleck.cs.illinois.edu/order-statistics.html\n* Mask R-CNN framework for object instance segmentation. https://arxiv.org/abs/1703.06870\n* Margaret M. FleckDavid A. Forsyth Chris Bregler. Finding Naked People. 1996. http://luthuli.cs.uiuc.edu/~daf/papers/naked.pdf\n* PyTorch tutorial review. https://github.com/ritchieng/the-incredible-pytorch and https://pytorch.org/tutorials/\n* ImageNet training in PyTorch. https://github.com/pytorch/examples/tree/master/imagenet\n* PyTorch Image Models. https://github.com/rwightman/pytorch-image-models\n* Image Captioning PyTorch. https://github.com/ruotianluo/ImageCaptioning.pytorch\n* PyTorch Visualizatoins. Implementation of convolutional neural network.\nhttps://github.com/utkuozbulak/pytorch-cnn-visualizations\n* Facebook AI Research. \"Detectron2\". Object detection and segmentation using PyTorch.\nhttps://github.com/facebookresearch/detectron2\n* Facebook AI Research.  \"Faster R-CNN and Mask R-CNN in PyTorch 1.0\". Creating detection and segmentation models using PyTorch .https://github.com/facebookresearch/maskrcnn-benchmark/\n* https://en.wikipedia.org/wiki/Gamergate_controversy\n* https://en.wikipedia.org/wiki/Cyberstalking\n\n\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9763986598557183,
        0.9763986598557183
      ],
      "excerpt": "  [![GitHub Issues](https://img.shields.io/github/issues/lucylow/salty-wet-man.svg)](https://github.com/lucylow/salty-wet-man/issues) \n  [![GitHub Pull Requests](https://img.shields.io/github/issues-pr/lucylow/salty-wet-man.svg)](https://github.com/lucylow/salty-wet-man/pulls) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9868512987915664,
        0.9806664955162817,
        0.9867789689443636
      ],
      "excerpt": "Object Recognition  \nNSFW Object Recognition: Content-Based Retrival via Localization  \nNSFW Object Recognition: Image Cropping  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9859267605787863
      ],
      "excerpt": "Deep Learning's Impact on Computer Vision \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8947754346132817
      ],
      "excerpt": "ImageNet used for Large Scale Object Recognition \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9759775677121064
      ],
      "excerpt": "Benchmark - ImageNet Large-Scale Visual Recognition Challenge (ILSVRC) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8935306062678985
      ],
      "excerpt": "Skin region properties - image, color, and texture   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.938811228897985
      ],
      "excerpt": "Uses image decomposition, pattern matching, and clustering algorithms \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Identify region outline \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.808141182110391
      ],
      "excerpt": "Object Image Segmentation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8993909064343208
      ],
      "excerpt": "How would salty-wet-man choose the image crops? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Region proposals \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9606712260438129
      ],
      "excerpt": "Region detection without proposals \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9312907016997455
      ],
      "excerpt": "Consider varient VGG19 classifer \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/lucylow/salty-wet-man/master/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucylow/salty-wet-man",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-07-03T13:21:51Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-27T04:50:29Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9979063478531227
      ],
      "excerpt": "The goal of Salty Wet Man is to flag inappropriate online content to make the internet a safer and more inclusive space for everyone.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9864192201149874
      ],
      "excerpt": "A chessboard features 16 playing pieces with 6 types where each piece has special moves and the end game is to capture the opponent's King resulting in \"checkmate\". What is the most powerful piece on the chess board? Many people will say the King or Queen because they are the highest rank. However I believe the most powerful are the nine Pawns (lowest rank). This is because through pawn promotion gameplay, the nine Pawns have the power to get promoted to become Queens, Rooks, Bishops, or Knights. Therefore we need to nurture and protect them throught gameplay as they are the seeds for the future.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9918814697811905,
        0.996227383633769,
        0.9964110854245248,
        0.9755130641230674
      ],
      "excerpt": "Children are increasingly exposed to digital media and online technology at an early age. They are going online to do schoolwork, play games, and socialize with over 4 billion people (1 in 3 children) connected to the internet. Around 60% of fourth to eighth graders have access to phones or tablets and almost half of them have access to a computer in their bedrooms.  \nAccess to the internet can lead to risks of exposure to online predators  posed by online sexual abuse and exploitation, cyberbullying, exposure to harmful inappropriate content, and use and sharing of personal data. The COVID19 global pandemic with it's lockdown measures has led to widespread school closures and physical distancing measures increasing our dependence on technology to connect. Law enforcement authorities and reporting agencies have seen a statistically signficant increase in the amount of child sexual abuse material being shared online, of which an ever increasing percentage involves self-generated content. \nInnovation at UNICEF is about doing new things to solve problems and improve the lives of children around the world. Technological solutions like Online Protection Tools are key to efficiently respond the digital risks for children. Four categories of digital risks defined by UNICEF:  Content, Contact, Conduct and Contract Risks: https://www.unicef.org/innovation/apply-ChildOnlineSafety. Focusing on Content Risks, which is defined as exposure to harmful or age-inappropriate content, such as pornography, child sexual abuse material, hate speech and extremism, discriminatory or hateful content, disinformation, online games, gambling, content that endorses risky or unhealthy behaviours and violent content which may be upsetting or show criminal activity.  \nDefining NSFW material is subjective and the task of identifying these images is non-trivial \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8159233578290993
      ],
      "excerpt": "[NSFW] negatively trained for inappropriate images that are not safe for work \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9674849055836569,
        0.9968029537584643
      ],
      "excerpt": "Theoretically CNN is best since large learning capacity and complexity \nStationarity of statistics \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8915448960245231,
        0.8600593291130838
      ],
      "excerpt": "Heavy computation required - Size of CNN network limited by GPU memory avaliabe \nHighly optimized implementation of 2D convolutions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8756184418165548,
        0.9255538785171809
      ],
      "excerpt": "Small image datasets (order of tens of thousands of images) -  MNIST digit-recognition with best error rate   \nLarge image datasets (order of hundreds of thousands of images) - ImageNet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9083798306767952
      ],
      "excerpt": "Image Location with Large Areas of Skin-colored Regions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9797985114963556
      ],
      "excerpt": "Absraction of an image to search for colored textured regions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9593453742049358
      ],
      "excerpt": "Group 2D and 3D constraints on body/skin regions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9790429879963971
      ],
      "excerpt": "VGG16 is a CNN for large-scale image recognition  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9813054417000305
      ],
      "excerpt": "Implemented with Keras and Tensorflow backend in this project \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8106530475083757
      ],
      "excerpt": "Fixed input of 224 x 224 RGB image \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8560692786448973
      ],
      "excerpt": "Large disk/bandwidth network achitecture with +533MB \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "Data Augmentation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8129689881283703
      ],
      "excerpt": "Image captioning using PyTorch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8528859813806426,
        0.840976353753461
      ],
      "excerpt": "Download and convert the VGG16 model to TensorFlow.js format \nLaunch Node.js script to load converted model and compute maximally-activating input images for  convnet's filters using gradient ascent in the input space. Save image files under dist/filters directory  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8065601589620599
      ],
      "excerpt": "Increase the number of filters to visualize per convolutional layer from default 8 to larger value (ex. 18): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9453203999530694
      ],
      "excerpt": "Default image used for internal-activation and CAM visualization is \"nsfw.jpg\". Switch to another image by using the \"--image waifu-pic.jpeg\" \ud83d\udc40 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9062184827433778,
        0.9463827142459872,
        0.9386636561810056
      ],
      "excerpt": "HTML5 Local Storage Data \nSalty Wet Man cache stores data on user's local device \nData.js information is removed when user clears cache \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.978027802044922
      ],
      "excerpt": "Template for configuring privacy and security \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Online binary classification to filter/flag for inappropriate unsolicited NSFW content ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucylow/salty-wet-man/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Wed, 29 Dec 2021 07:42:23 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lucylow/salty-wet-man/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "lucylow/salty-wet-man",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8268393564608785,
        0.8814900702670583
      ],
      "excerpt": "  [![GitHub Issues](https://img.shields.io/github/issues/lucylow/salty-wet-man.svg)](https://github.com/lucylow/salty-wet-man/issues) \n  [![GitHub Pull Requests](https://img.shields.io/github/issues-pr/lucylow/salty-wet-man.svg)](https://github.com/lucylow/salty-wet-man/pulls) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8689319022887403
      ],
      "excerpt": "GPU Implementation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8186547307689883
      ],
      "excerpt": "Image captioning using PyTorch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9525029657535969
      ],
      "excerpt": "Install Python dependencies and packages (Keras, TensorFlow, and TensorFlow.js) - best to run from virtualenv \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.84027946561644
      ],
      "excerpt": "yarn visualize --gpu --filters 18 \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8235832741002259
      ],
      "excerpt": "Dataset over 15 million labeled images \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8608941652513795
      ],
      "excerpt": "Training, validation, and testing images \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8308504338313635
      ],
      "excerpt": "Total 16 Layers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8009233303116292
      ],
      "excerpt": "Download and convert the VGG16 model to TensorFlow.js format \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lucylow/salty-wet-man/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "JavaScript",
      "CSS",
      "HTML"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/lucylow/salty-wet-man/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b\"Copyright (c) <2021>, <Legacy Quantum Salty Wet Man>\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\\n2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\\n3. All advertising materials mentioning features or use of this software must display the following acknowledgement: This product includes software developed by the <copyright holder>.\\n4. Neither the name of the <Legacy Quantum Salty Wet Man> nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY <Legacy Quantum Salty Wet Man> ''AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n\"",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Salty Wet Man (SWM)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "salty-wet-man",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "lucylow",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucylow/salty-wet-man/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 13,
      "date": "Wed, 29 Dec 2021 07:42:23 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "nsfw",
      "tensorflow",
      "image-classification",
      "keras",
      "image-processing",
      "image-recognition",
      "image-analysis",
      "neural-network",
      "image-manipulation",
      "tensorflow-js",
      "gradient",
      "gradient-activation",
      "waifu-dataset",
      "activation-functions",
      "imagenet-classifier",
      "imagenet",
      "imagenet-classification-challenge",
      "vgg16",
      "data-augmentation",
      "qbic"
    ],
    "technique": "GitHub API"
  }
}
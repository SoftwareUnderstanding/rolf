{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1811.07246",
      "https://arxiv.org/abs/1612.00593",
      "https://arxiv.org/abs/1801.07829",
      "https://arxiv.org/abs/1811.07246",
      "https://arxiv.org/abs/1903.05711",
      "https://arxiv.org/abs/1908.07906",
      "https://arxiv.org/abs/1905.03304",
      "https://arxiv.org/abs/1910.12240",
      "https://arxiv.org/abs/1806.01411",
      "https://arxiv.org/abs/2008.09088"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. [PointNet:](https://arxiv.org/abs/1612.00593) Deep Learning on Point Sets for 3D Classification and Segmentation\n2. [Dynamic Graph CNN](https://arxiv.org/abs/1801.07829) for Learning on Point Clouds\n3. [PPFNet:](https://arxiv.org/pdf/1802.02669.pdf) Global Context Aware Local Features for Robust 3D Point Matching\n4. [PointConv:](https://arxiv.org/abs/1811.07246) Deep Convolutional Networks on 3D Point Clouds\n5. [PointNetLK:](https://arxiv.org/abs/1903.05711) Robust & Efficient Point Cloud Registration using PointNet\n6. [PCRNet:](https://arxiv.org/abs/1908.07906) Point Cloud Registration Network using PointNet Encoding\n7. [Deep Closest Point:](https://arxiv.org/abs/1905.03304) Learning Representations for Point Cloud Registration\n8. [PRNet:](https://arxiv.org/abs/1910.12240) Self-Supervised Learning for Partial-to-Partial Registration\n9. [FlowNet3D:](https://arxiv.org/abs/1806.01411) Learning Scene Flow in 3D Point Clouds\n10. [PCN:](https://arxiv.org/pdf/1808.00671.pdf) Point Completion Network\n11. [RPM-Net:](https://arxiv.org/pdf/2003.13479.pdf) Robust Point Matching using Learned Features\n12. [3D ShapeNets:](https://people.csail.mit.edu/khosla/papers/cvpr2015_wu.pdf) A Deep Representation for Volumetric Shapes\n13. [DeepGMR:](https://arxiv.org/abs/2008.09088) Learning Latent Gaussian Mixture Models for Registration\n14. [CMU:](https://arxiv.org/pdf/2010.16085.pdf) Correspondence Matrices are Underrated\n15. [MaskNet:](https://arxiv.org/pdf/2010.09185.pdf) A Fully-Convolutional Network to Estimate Inlier Points",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.8109194328925066
      ],
      "excerpt": "| 4 | Registration | PointNetLK, PCRNet, DCP, PRNet, RPM-Net, DeepGMR | \n| 5 | Flow Estimation | FlowNet3D | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vinits5/learning3d",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-21T21:37:11Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T13:22:28Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9867222955921148,
        0.931886293122797,
        0.9719724409550632,
        0.8564076828429169,
        0.810289693801199
      ],
      "excerpt": "Learning3D is an open-source library that supports the development of deep learning algorithms that deal with 3D data. The Learning3D exposes a set of state of art deep neural networks in python. A modular code has been provided for further development. We welcome contributions from the open-source community. \n[24 Dec. 2020]: MaskNet is now ready to enhance the performance of registration algorithms in learning3d for occluded point clouds. \n[24 Dec. 2020]: Loss based on the predicted and ground truth correspondences is added in learning3d after consideration of Correspondence Matrices are Underrated paper. \n[24 Dec. 2020]: PointConv, latent feature estimation using convolutions on point clouds is now available in learning3d. \n[16 Oct. 2020]: DeepGMR, registration using gaussian mixture models is now available in learning3d \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8529873560569169
      ],
      "excerpt": "Correspondence Loss (based on this paper) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This is a complete package of recent deep learning methods for 3D point clouds in pytorch (with pretrained models).",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "B: Batch Size, N: No. of points and C: Channels.\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vinits5/learning3d/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 50,
      "date": "Tue, 28 Dec 2021 23:56:02 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/vinits5/learning3d/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "vinits5/learning3d",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8440086932508041
      ],
      "excerpt": "RPM-Net (clean-trained.pth, noisy-trained.pth, partial-pretrained.pth) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/vinits5/learning3d/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cuda",
      "C++"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License\\n\\nCopyright (c) 2010-2019 Google, Inc. http://angularjs.org\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\nTHE SOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Learning3D: A Modern Library for Deep Learning on 3D Point Clouds Data.",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "learning3d",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "vinits5",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vinits5/learning3d/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. CUDA 10.0 or higher\n2. Pytorch 1.3 or higher\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Copy the file from \"examples\" folder outside of the directory \"learning3d\"\n2. Now, run the file. (ex. python test_pointnet.py)\n- Your Directory/Location\n\t- learning3d\n\t- test_pointnet.py\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 290,
      "date": "Tue, 28 Dec 2021 23:56:02 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "**Important Note: Clone this repository in your project. Please don't add your codes in \"learning3d\" folder.**\n\n1. All networks are defined in the module \"models\".\n2. All loss functions are defined in the module \"losses\".\n3. Data loaders are pre-defined in data_utils/dataloaders.py file.\n4. All pretrained models are provided in learning3d/pretrained folder.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "> from learning3d.models import PointNet, DGCNN, PPFNet\\\n> pn = PointNet(emb_dims=1024, input_shape='bnc', use_bn=False)\\\n> dgcnn = DGCNN(emb_dims=1024, input_shape='bnc')\\\n> ppf = PPFNet(features=['ppf', 'dxyz', 'xyz'], emb_dims=96, radius='0.3', num_neighbours=64)\n\n| Sr. No. | Variable | Data type | Shape | Choices | Use |\n|:---:|:---:|:---:|:---:|:---:|:---:|\n| 1. | emb_dims | Integer | Scalar | 1024, 512 | Size of feature vector for the each point|\n| 2. | input_shape | String | - | 'bnc', 'bcn' | Shape of input point cloud|\n| 3. | output | tensor | BxCxN | - | High dimensional embeddings for each point|\n| 4. | features | List of Strings | - | ['ppf', 'dxyz', 'xyz'] | Use of various features |\n| 5. | radius | Float | Scalar | 0.3 | Radius of cluster for computing local features |\n| 6. | num_neighbours | Integer | Scalar | 64 | Maximum number of points to consider per cluster |\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "> from learning3d.models import Classifier, PointNet, Segmentation\\\n> classifier = Classifier(feature_model=PointNet(), num_classes=40)\\\n> seg = Segmentation(feature_model=PointNet(), num_classes=40)\n\n| Sr. No. | Variable | Data type | Shape | Choices | Use |\n|:---:|:---:|:---:|:---:|:---:|:---:|\n| 1. | feature_model | Object | - | PointNet / DGCNN | Point cloud embedding network |\n| 2. | num_classes | Integer | Scalar | 10, 40 | Number of object categories to be classified |\n| 3. | output | tensor | Classification: Bx40, Segmentation: BxNx40 | 10, 40 | Probabilities of each category or each point |\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "> from learning3d.models import PointNet, PointNetLK, DCP, iPCRNet, PRNet, PPFNet, RPMNet\\\n> pnlk = PointNetLK(feature_model=PointNet(), delta=1e-02, xtol=1e-07, p0_zero_mean=True, p1_zero_mean=True, pooling='max')\\\n> dcp = DCP(feature_model=PointNet(), pointer_='transformer', head='svd')\\\n> pcrnet = iPCRNet(feature_moodel=PointNet(), pooling='max')\\\n> rpmnet = RPMNet(feature_model=PPFNet())\\\n> deepgmr = DeepGMR(use_rri=True, feature_model=PointNet(), nearest_neighbors=20)\n\n| Sr. No. | Variable | Data type | Choices | Use | Algorithm |\n|:---:|:---:|:---:|:---:|:---:|:---:|\n| 1. | feature_model | Object | PointNet / DGCNN | Point cloud embedding network | PointNetLK | \n| 2. | delta | Float | Scalar | Parameter to calculate approximate jacobian | PointNetLK |\n| 3. | xtol | Float | Scalar | Check tolerance to stop iterations | PointNetLK |\n| 4. | p0_zero_mean | Boolean | True/False | Subtract mean from template point cloud |  PointNetLK |\n| 5. | p1_zero_mean | Boolean | True/False | Subtract mean from source point cloud | PointNetLK |\n| 6. | pooling | String | 'max' / 'avg' | Type of pooling used to get global feature vectror | PointNetLK |\n| 7. | pointer_ | String | 'transformer' / 'identity' | Choice for Transformer/Attention network | DCP |\n| 8. | head | String | 'svd' / 'mlp' | Choice of module to estimate registration params | DCP |\n| 9. | use_rri | Boolean | True/False | Use nearest neighbors to estimate point cloud features. | DeepGMR |\n| 10. | nearest_neighbores | Integer | 20/any integer | Give number of nearest neighbors used to estimate features | DeepGMR |\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "> from learning3d.models import MaskNet, PointNet\\\n> masknet = MaskNet(feature_model=PointNet(), is_training=True)\n\n| Sr. No. | Variable | Data type | Choices | Use |\n|:---:|:---:|:---:|:---:|:---:|\n| 1. | feature_model | Object | PointNet / DGCNN | Point cloud embedding network |\n| 2. | is_training | Boolean | True / False | Specify if the network will undergo training or testing |\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "> from learning3d.models import PCN\\\n> pcn = PCN(emb_dims=1024, input_shape='bnc', num_coarse=1024, grid_size=4, detailed_output=True)\n\n| Sr. No. | Variable | Data type | Choices | Use |\n|:---:|:---:|:---:|:---:|:---:|\n| 1. | emb_dims | Integer | 1024, 512 | Size of feature vector for each point | \n| 2. | input_shape | String | 'bnc' / 'bcn' | Shape of input point cloud |\n| 3. | num_coarse | Integer | 1024 | Shape of output point cloud |\n| 4. | grid_size | Integer | 4, 8, 16 | Size of grid used to produce detailed output | \n| 5. | detailed_output | Boolean | True / False | Choice for additional module to create detailed output point cloud|\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Use the following to create pretrained model provided by authors.\n> from learning3d.models import create_pointconv\\\n> PointConv = create_pointconv(classifier=True, pretrained='path of checkpoint')\\\n> ptconv = PointConv(emb_dims=1024, input_shape='bnc', input_channel_dim=6, classifier=True)\n\n**OR**\\\nUse the following to create your own PointConv model.\n\n> PointConv = create_pointconv(classifier=False, pretrained=None)\\\n> ptconv = PointConv(emb_dims=1024, input_shape='bnc', input_channel_dim=3, classifier=True)\n\nPointConv variable is a class. Users can use it to create a sub-class to override *create_classifier* and *create_structure* methods in order to change PointConv's network architecture.\n\n| Sr. No. | Variable | Data type | Choices | Use |\n|:---:|:---:|:---:|:---:|:---:|\n| 1. | emb_dims | Integer | 1024, 512 | Size of feature vector for each point | \n| 2. | input_shape | String | 'bnc' / 'bcn' | Shape of input point cloud |\n| 3. | input_channel_dim | Integer | 3/6 | Define if point cloud contains only xyz co-ordinates or normals and colors as well |\n| 4. | classifier | Boolean | True / False | Choose if you want to use a classifier with PointConv |\n| 5. | pretrained | Boolean | String | Give path of the pretrained classifier model (only use it for weights given by authors) |\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "> from learning3d.models import FlowNet3D\\\n> flownet = FlowNet3D()\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "> from learning3d.data_utils import ModelNet40Data, ClassificationData, RegistrationData, FlowData\\\n> modelnet40 = ModelNet40Data(train=True, num_points=1024, download=True)\\\n> classification_data = ClassificationData(data_class=ModelNet40Data())\\\n> registration_data = RegistrationData(algorithm='PointNetLK', data_class=ModelNet40Data(), partial_source=False, partial_template=False, noise=False)\\\n> flow_data = FlowData()\n\n| Sr. No. | Variable | Data type | Choices | Use |\n|:---:|:---:|:---:|:---:|:---:|\n| 1. | train | Boolean | True / False | Split data as train/test set |\n| 2. | num_points | Integer | 1024 | Number of points in each point cloud |\n| 3. | download | Boolean | True / False | If data not available then download it |\n| 4. | data_class | Object | - | Specify which dataset to use |\n| 5. | algorithm | String | 'PointNetLK', 'PCRNet', 'DCP', 'iPCRNet' | Algorithm used for registration |\n| 6. | partial_source | Boolean | True / False | Create partial source point cloud |\n| 7. | partial_template | Boolean | True / False | Create partial template point cloud |\n| 8. | noise | Boolean | True / False | Add noise in source point cloud |\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "> from learning3d.data_utils import UserData\\\n> dataset = UserData(application, data_dict)\n\n|Sr. No. | Application | Required Key | Respective Value |\n|:---:|:---:|:---:|:---:|\n| 1. | 'classification' | 'pcs' | Point Clouds (BxNx3) |\n|    |                  | 'labels' | Ground Truth Class Labels (BxN) |\n| 2. | 'registration' | 'template' | Template Point Clouds (BxNx3) |\n|    |                | 'source' | Source Point Clouds (BxNx3) |\n|    |                | 'transformation' | Ground Truth Transformation (Bx4x4)|\n| 3. | 'flow_estimation' | 'frame1' | Point Clouds (BxNx3) |\n|    |                   | 'frame2' | Point Clouds (BxNx3) |\n|    |                   | 'flow' | Ground Truth Flow Vector (BxNx3)|\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "> from learning3d.losses import RMSEFeaturesLoss, FrobeniusNormLoss, ClassificationLoss, EMDLoss, ChamferDistanceLoss, CorrespondenceLoss\\\n> rmse = RMSEFeaturesLoss()\\\n> fn_loss = FrobeniusNormLoss()\\\n> classification_loss = ClassificationLoss()\\\n> emd = EMDLoss()\\\n> cd = ChamferDistanceLoss()\\\n> corr = CorrespondenceLoss()\n\n| Sr. No. | Loss Type | Use |\n|:---:|:---:|:---:|\n| 1. | RMSEFeaturesLoss | Used to find root mean square value between two global feature vectors of point clouds |\n| 2. | FrobeniusNormLoss | Used to find frobenius norm between two transfromation matrices |\n| 3. | ClassificationLoss | Used to calculate cross-entropy loss | \n| 4. | EMDLoss | Earth Mover's distance between two given point clouds |\n| 5. | ChamferDistanceLoss | Chamfer's distance between two given point clouds |\n| 6. | CorrespondenceLoss | Computes cross entropy loss using the predicted correspondence and ground truth correspondence for each source point |\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Copy the file from \"examples\" folder outside of the directory \"learning3d\"\n2. Now, run the file. (ex. python test_pointnet.py)\n- Your Directory/Location\n\t- learning3d\n\t- test_pointnet.py\n\n",
      "technique": "Header extraction"
    }
  ]
}
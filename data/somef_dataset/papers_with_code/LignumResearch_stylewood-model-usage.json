{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1812.04948](https://arxiv.org/abs/1812.04948",
      "https://arxiv.org/abs/1812.04948"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "For the paper, we trained StyleGAN to generate synthetic images. We have included a copy of the license from the original StyleGAN repository.\n\n- A Style-Based Generator Architecture for Generative Adversarial Networks. Tero Karras (NVIDIA), Samuli Laine (NVIDIA), Timo Aila (NVIDIA). [https://arxiv.org/abs/1812.04948](https://arxiv.org/abs/1812.04948). [StyleGAN \u2014 Official TensorFlow Implementation](https://github.com/NVlabs/stylegan).\n\nTo train StyleGAN, we used a dataset containing identified microscopic cross-section images of hardwoods species by the XDD research team.\n\n- SUGIYAMA, Junji, HWANG, Sung Wook, ZHAI, ShengCheng, KOBAYASHI, Kayoko, KANAI, Izumi, KANAI, Keiko. [Xylarium Digital Database for Wood Information Science and Education](http://hdl.handle.net/2433/250016).\n\nThe complete set of references can be found in our paper. \n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/LignumResearch/stylewood-model-usage",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-23T00:07:44Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-19T00:15:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9828397087733199,
        0.8734593759424724
      ],
      "excerpt": "This repository was created to provide the original implementation for the paper \"Creating high-resolution microscopic cross-section images of hardwood species using generative adversarial networks\", written by Dercilio Junior Verly Lopes, Gustavo Fardin Monti, Greg W. Burgreen, Jord\u00e3o Cabral Moulin, Gabrielly dos Santos Bobadilha, Edward D. Entsminger and Ramon Ferreira Oliveira. \nIn this repository, you will find the code used for training. Here is a basic summary of the directories in this repository: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9676756707950774
      ],
      "excerpt": "collab/: Contains notebook, generator and code for web application. See and use the notebook on Collab. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8391677372842642,
        0.9081410386355906
      ],
      "excerpt": "metrics/: Contains FID score calculation \nresults/: Contains model's trained snapshot at 7446 kimg selected to show implementation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Generative adversarial network and wood anatomy.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/LignumResearch/stylewood-model-usage/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 17:43:15 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/LignumResearch/stylewood-model-usage/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "LignumResearch/stylewood-model-usage",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/LignumResearch/stylewood-model-usage/main/collab/StyleWoodGUI.ipynb",
      "https://raw.githubusercontent.com/LignumResearch/stylewood-model-usage/main/Support/Supplemental%20material_2_Confidence%20interval%20and%20t_test.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8604775525780001
      ],
      "excerpt": "<img src=\"https://github.com/LignumResearch/stylewood-model-usage/blob/main/images/mosaic.png?raw=true\" alt=\"Mosaic of randomly generated images using our model.\" width=\"830\"/> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/LignumResearch/stylewood-model-usage/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "StyleWood: Training and using GANs to generate microscopic cross-section images of hardwood species",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "stylewood-model-usage",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "LignumResearch",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/LignumResearch/stylewood-model-usage/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* CentOS Linux 7. **Not tested in Windows**.\n* 64-bit Python 3.7 installation.\n* TensorFlow 1.14 with GPU support.\n* One or more high-end NVIDIA GPUs with at least 11GB of DRAM. We recommend NVIDIA RTX 2080 Ti GPU.\n* NVIDIA driver 411.63, CUDA toolkit 10.0, cuDNN 7.6.4.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Wed, 29 Dec 2021 17:43:15 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "__[step 1.] Prepare dataset__ \n\n* Make sure to download the TFRecords of the dataset [here](https://drive.google.com/file/d/1uYK-whQluEXNoqvnAp-Se9tdxi_4XNfj/view?usp=sharing)\n\n__[step 2.] Config__:\n\n1. Edit [train.py](./train.py) with the path of the unzipped file from step 1. Change **Line 37**.\n2. Edit [train.py](./train.py) lines 40-43 with the number of GPUS that will be used for training. By default, 4 GPUS will be used. \n\n__[step 3.] Training__:\n\n1. Run [train.py](./train.py) as ```python train.py```. \n\n* Bear in mind that StyleGAN is computationally expensive to train and use.\n* Visualization of training progress can be done by TensorBoard. \n* Within the results folder, a new directory will be created with training information.\n* Training is expected to last days (maybe weeks) depending on computational power. \n\n__[step 4.] Image generation__:\n\n1a. You can use [random_figure.py](./random_figure.py) to generate 100 images using the author's snapshot. If you want to generate a different number of images, change line 33 in the same file. \n\n1b. You can also use your own snapshot generated by your training stage. If that is the case, change line 26 with your own snapshot in [random_figure.py](./random_figure.py). \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "See our Google Collab notebook [here](https://colab.research.google.com/drive/1U0NU7CLlW3gTYVzwlYEgANfd8Uh7vFkc?usp=sharing). In the collab you will be able to generate image transitions as the below. \n\n<img src=\"https://github.com/LignumResearch/stylewood-model-usage/blob/main/images/transition.gif?raw=true\" alt=\"Transition using our generator.\" width=\"512\">\n\nWe also prepared a playlist containing video tutorials explaining how to use the Google Collab notebook and the web application. [See the playlist on youtube.](https://youtube.com/playlist?list=PLx56vSb2wN6blKRc7OzvxKjwn-i1Sl8oJ)\n\n\nYou can choose to run the web application locally as well, but you will need to install the pre-requisites. \n\nHere's what we used to run the web application on a Windows Machine:\n- Python (We used 3.7).\n    - Comes with Anaconda.\n- [Anaconda](https://www.anaconda.com/products/individual#Downloads) (Optional but useful). Open the Anaconda CLI and type\n    - `conda create --name stylewood python=3.7`\n    - `activate stylewood` (Run this every time you need to re-open the CLI)\n- cudatoolkit \n    - `conda install cudatoolkit`\n        - Requires adding Anaconda Enviroment library bins to path on Windows otherwise missing DLL error may happen\n        - The path should be available from the Anaconda Install: `Anaconda/envs/envname/Library/bin`\n        - [See how to add a directory to path on Windows.](https://docs.microsoft.com/en-us/previous-versions/office/developer/sharepoint-2010/ee537574(v=office.14))\n    - Can also be [downloaded from NVidia.](https://developer.nvidia.com/cuda-toolkit)\n- Tensorflow with GPU support. We used 1.14 \n    - `pip install tensorflow-gpu==1.14`\n    - 2.0 or greater isn't compatible with StyleGan\n- Streamlit. We used v0.82\n    - `pip install streamlit==0.82`\n- After installing the packages, run the streamlit application.\n    - Go to the directory that contains the Collab files `cd C:/user/directory/collab`\n    - `streamlit run webapp.py`\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
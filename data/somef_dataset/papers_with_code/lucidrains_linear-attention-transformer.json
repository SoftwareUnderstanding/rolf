{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2006.16236}\n}\n```\n\n```bibtex\n@article{shen2019efficient,\n  author    = {Zhuoran Shen and\n               Mingyuan Zhang and\n               Haiyu Zhao and\n               Shuai Yi and\n               Hongsheng Li},\n  title     = {Efficient Attention: Attention with Linear Complexities},\n  journal   = {CoRR},\n  volume    = {abs/1812.01243},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1812.01243}\n}\n```\n\n```bibtex\n@inproceedings{kitaev2020reformer,\n    title       = {Reformer: The Efficient Transformer},\n    author      = {Nikita Kitaev and Lukasz Kaiser and Anselm Levskaya},\n    booktitle   = {International Conference on Learning Representations},\n    year        = {2020},\n    url         = {https://openreview.net/forum?id=rkgNKkHtvB}\n}\n```\n\n```bibtex\n@misc{shazeer2020glu,\n    title   = {GLU Variants Improve Transformer},\n    author  = {Noam Shazeer},\n    year    = {2020},\n    url     = {https://arxiv.org/abs/2002.05202}\n}\n```\n\n```bibtex\n@misc{wang2020linformer,\n    title   = {Linformer: Self-Attention with Linear Complexity},\n    author  = {Sinong Wang and Belinda Z. Li and Madian Khabsa and Han Fang and Hao Ma},\n    year    = {2020},\n    eprint  = {2006.04768}\n}\n```\n\n```bibtex\n@misc{bhojanapalli2020lowrank,\n    title   = {Low-Rank Bottleneck in Multi-head Attention Models},\n    author  = {Srinadh Bhojanapalli and Chulhee Yun and Ankit Singh Rawat and Sashank J. Reddi and Sanjiv Kumar},\n    year    = {2020},\n    eprint  = {2002.07028}\n}\n```\n\n```bibtex\n@techreport{zhuiyiroformer,\n    title   = {RoFormer: Transformer with Rotary Position Embeddings - ZhuiyiAI},\n    author  = {Jianlin Su},\n    year    = {2021},\n    url     = \"https://github.com/ZhuiyiTechnology/roformer\",\n}\n```",
      "https://arxiv.org/abs/2002.05202}\n}\n```\n\n```bibtex\n@misc{wang2020linformer,\n    title   = {Linformer: Self-Attention with Linear Complexity},\n    author  = {Sinong Wang and Belinda Z. Li and Madian Khabsa and Han Fang and Hao Ma},\n    year    = {2020},\n    eprint  = {2006.04768}\n}\n```\n\n```bibtex\n@misc{bhojanapalli2020lowrank,\n    title   = {Low-Rank Bottleneck in Multi-head Attention Models},\n    author  = {Srinadh Bhojanapalli and Chulhee Yun and Ankit Singh Rawat and Sashank J. Reddi and Sanjiv Kumar},\n    year    = {2020},\n    eprint  = {2002.07028}\n}\n```\n\n```bibtex\n@techreport{zhuiyiroformer,\n    title   = {RoFormer: Transformer with Rotary Position Embeddings - ZhuiyiAI},\n    author  = {Jianlin Su},\n    year    = {2021},\n    url     = \"https://github.com/ZhuiyiTechnology/roformer\",\n}\n```"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bibtex\n@inproceedings{katharopoulos-et-al-2020,\n  author    = {Katharopoulos, A. and Vyas, A. and Pappas, N. and Fleuret, F.},\n  title     = {Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention},\n  booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},\n  year      = {2020},\n  url       = {https://arxiv.org/abs/2006.16236}\n}\n```\n\n```bibtex\n@article{shen2019efficient,\n  author    = {Zhuoran Shen and\n               Mingyuan Zhang and\n               Haiyu Zhao and\n               Shuai Yi and\n               Hongsheng Li},\n  title     = {Efficient Attention: Attention with Linear Complexities},\n  journal   = {CoRR},\n  volume    = {abs/1812.01243},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1812.01243}\n}\n```\n\n```bibtex\n@inproceedings{kitaev2020reformer,\n    title       = {Reformer: The Efficient Transformer},\n    author      = {Nikita Kitaev and Lukasz Kaiser and Anselm Levskaya},\n    booktitle   = {International Conference on Learning Representations},\n    year        = {2020},\n    url         = {https://openreview.net/forum?id=rkgNKkHtvB}\n}\n```\n\n```bibtex\n@misc{shazeer2020glu,\n    title   = {GLU Variants Improve Transformer},\n    author  = {Noam Shazeer},\n    year    = {2020},\n    url     = {https://arxiv.org/abs/2002.05202}\n}\n```\n\n```bibtex\n@misc{wang2020linformer,\n    title   = {Linformer: Self-Attention with Linear Complexity},\n    author  = {Sinong Wang and Belinda Z. Li and Madian Khabsa and Han Fang and Hao Ma},\n    year    = {2020},\n    eprint  = {2006.04768}\n}\n```\n\n```bibtex\n@misc{bhojanapalli2020lowrank,\n    title   = {Low-Rank Bottleneck in Multi-head Attention Models},\n    author  = {Srinadh Bhojanapalli and Chulhee Yun and Ankit Singh Rawat and Sashank J. Reddi and Sanjiv Kumar},\n    year    = {2020},\n    eprint  = {2002.07028}\n}\n```\n\n```bibtex\n@techreport{zhuiyiroformer,\n    title   = {RoFormer: Transformer with Rotary Position Embeddings - ZhuiyiAI},\n    author  = {Jianlin Su},\n    year    = {2021},\n    url     = \"https://github.com/ZhuiyiTechnology/roformer\",\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@techreport{zhuiyiroformer,\n    title   = {RoFormer: Transformer with Rotary Position Embeddings - ZhuiyiAI},\n    author  = {Jianlin Su},\n    year    = {2021},\n    url     = \"https://github.com/ZhuiyiTechnology/roformer\",\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{bhojanapalli2020lowrank,\n    title   = {Low-Rank Bottleneck in Multi-head Attention Models},\n    author  = {Srinadh Bhojanapalli and Chulhee Yun and Ankit Singh Rawat and Sashank J. Reddi and Sanjiv Kumar},\n    year    = {2020},\n    eprint  = {2002.07028}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{wang2020linformer,\n    title   = {Linformer: Self-Attention with Linear Complexity},\n    author  = {Sinong Wang and Belinda Z. Li and Madian Khabsa and Han Fang and Hao Ma},\n    year    = {2020},\n    eprint  = {2006.04768}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{shazeer2020glu,\n    title   = {GLU Variants Improve Transformer},\n    author  = {Noam Shazeer},\n    year    = {2020},\n    url     = {https://arxiv.org/abs/2002.05202}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{kitaev2020reformer,\n    title       = {Reformer: The Efficient Transformer},\n    author      = {Nikita Kitaev and Lukasz Kaiser and Anselm Levskaya},\n    booktitle   = {International Conference on Learning Representations},\n    year        = {2020},\n    url         = {https://openreview.net/forum?id=rkgNKkHtvB}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{shen2019efficient,\n  author    = {Zhuoran Shen and\n               Mingyuan Zhang and\n               Haiyu Zhao and\n               Shuai Yi and\n               Hongsheng Li},\n  title     = {Efficient Attention: Attention with Linear Complexities},\n  journal   = {CoRR},\n  volume    = {abs/1812.01243},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1812.01243}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{katharopoulos-et-al-2020,\n  author    = {Katharopoulos, A. and Vyas, A. and Pappas, N. and Fleuret, F.},\n  title     = {Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention},\n  booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},\n  year      = {2020},\n  url       = {https://arxiv.org/abs/2006.16236}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucidrains/linear-attention-transformer",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-04T21:34:56Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-14T16:30:17Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9626073777303975,
        0.9768182786023425
      ],
      "excerpt": "A fully featured Transformer that mixes (QK\u1d40)V local attention with Q(K\u1d40V) global attention (scales linearly with respect to sequence length) for efficient long-range language modeling. \nLinformer is another variant of attention with linear complexity championed by Facebook AI. It only works with non-autoregressive models of a fixed sequence length. If your problem satisfies that criteria, you may choose to try it out. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9702066987003809
      ],
      "excerpt": "This repository also contains a concise implementation of this efficient attention for images \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.87161585596901
      ],
      "excerpt": "  key_dim = 64       #: can be decreased to 32 for more memory savings \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Transformer based on a variant of attention that is linear complexity in respect to sequence length",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucidrains/linear-attention-transformer/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 30,
      "date": "Tue, 21 Dec 2021 01:15:31 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lucidrains/linear-attention-transformer/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "lucidrains/linear-attention-transformer",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\n$ pip install linear-attention-transformer\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8252331592278599
      ],
      "excerpt": "<img src=\"./linear-attention.png\" width=\"700px\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from linear_attention_transformer import LinearAttentionTransformerLM, LinformerSettings \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8639258741734444
      ],
      "excerpt": "    depth = 6, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from linear_attention_transformer import LinearAttentionTransformerLM, LinformerContextSettings \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8639258741734444
      ],
      "excerpt": "    depth = 6, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "    causal = True, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "    receives_context = True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8916312378474042
      ],
      "excerpt": "from linear_attention_transformer.images import ImageLinearAttention \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lucidrains/linear-attention-transformer/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Phil Wang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Linear Attention Transformer",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "linear-attention-transformer",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "lucidrains",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lucidrains/linear-attention-transformer/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-09-07T20:15:30Z",
        "datePublished": "2021-09-07T20:16:23Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.19.1",
        "name": "0.19.1",
        "tag_name": "0.19.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.19.1",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/49154627",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.19.1"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-08-21T17:07:47Z",
        "datePublished": "2021-08-21T17:09:16Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.18.2",
        "name": "0.18.2",
        "tag_name": "0.18.2",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.18.2",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/48224827",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.18.2"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-04-14T03:14:44Z",
        "datePublished": "2021-04-14T03:14:55Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.18.1",
        "name": "0.18.1",
        "tag_name": "0.18.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.18.1",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/41390335",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.18.1"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-04-03T23:30:28Z",
        "datePublished": "2021-04-03T23:30:46Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.18.0",
        "name": "0.18.0",
        "tag_name": "0.18.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.18.0",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/40907021",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.18.0"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-03-30T03:43:13Z",
        "datePublished": "2021-03-30T03:43:37Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.17.2",
        "name": "0.17.2",
        "tag_name": "0.17.2",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.17.2",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/40670979",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.17.2"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-03-30T03:40:08Z",
        "datePublished": "2021-03-30T03:40:22Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.17.1",
        "name": "0.17.1",
        "tag_name": "0.17.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.17.1",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/40670915",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.17.1"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-03-30T01:12:06Z",
        "datePublished": "2021-03-30T01:12:27Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.17.0",
        "name": "0.17.0",
        "tag_name": "0.17.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.17.0",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/40667297",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.17.0"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-03-29T15:52:32Z",
        "datePublished": "2021-03-29T15:53:31Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.16.1",
        "name": "0.16.1",
        "tag_name": "0.16.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.16.1",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/40644030",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.16.1"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-03-29T03:39:44Z",
        "datePublished": "2021-03-29T03:40:02Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.16.0",
        "name": "0.16.0",
        "tag_name": "0.16.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.16.0",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/40611972",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.16.0"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-03-29T02:30:57Z",
        "datePublished": "2021-03-29T02:31:16Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.15.5",
        "name": "0.15.5",
        "tag_name": "0.15.5",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.15.5",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/40610593",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.15.5"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-03-25T23:14:52Z",
        "datePublished": "2021-03-25T23:15:12Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.15.4",
        "name": "0.15.4",
        "tag_name": "0.15.4",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.15.4",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/40447865",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.15.4"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2021-01-02T01:25:58Z",
        "datePublished": "2021-01-02T01:26:23Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.15.3",
        "name": "0.15.3",
        "tag_name": "0.15.3",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.15.3",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/35903127",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.15.3"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-12-20T05:24:25Z",
        "datePublished": "2020-12-20T05:25:30Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.15.2",
        "name": "0.15.2",
        "tag_name": "0.15.2",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.15.2",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/35534999",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.15.2"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-12-12T01:45:29Z",
        "datePublished": "2020-12-12T01:46:19Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.15.1",
        "name": "0.15.1",
        "tag_name": "0.15.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.15.1",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/35180872",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.15.1"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-10-29T17:03:18Z",
        "datePublished": "2020-10-29T17:03:35Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.15.0",
        "name": "0.15.0",
        "tag_name": "0.15.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.15.0",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/33231280",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.15.0"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-10-20T22:40:58Z",
        "datePublished": "2020-10-20T22:41:13Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.14.1",
        "name": "0.14.1",
        "tag_name": "0.14.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.14.1",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/32837455",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.14.1"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-10-09T07:22:48Z",
        "datePublished": "2020-10-09T07:23:19Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.14.0",
        "name": "0.14.0",
        "tag_name": "0.14.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.14.0",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/32357005",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.14.0"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-10-05T04:11:52Z",
        "datePublished": "2020-10-05T04:12:13Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.12.1",
        "name": "0.12.1",
        "tag_name": "0.12.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.12.1",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/32149373",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.12.1"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-10-05T04:07:04Z",
        "datePublished": "2020-10-05T04:07:35Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.12.0",
        "name": "0.12.0",
        "tag_name": "0.12.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.12.0",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/32149318",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.12.0"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-08-05T19:59:30Z",
        "datePublished": "2020-08-05T19:59:52Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.11.1",
        "name": "0.11.1",
        "tag_name": "0.11.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.11.1",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/29380593",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.11.1"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-07-12T23:49:07Z",
        "datePublished": "2020-07-12T23:49:39Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.11.0",
        "name": "0.11.0",
        "tag_name": "0.11.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.11.0",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/28484875",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.11.0"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-07-08T17:32:30Z",
        "datePublished": "2020-07-08T17:32:55Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.10.3",
        "name": "0.10.3",
        "tag_name": "0.10.3",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.10.3",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/28369110",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.10.3"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-06-29T22:34:46Z",
        "datePublished": "2020-06-29T22:35:15Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.10.1",
        "name": "0.10.1",
        "tag_name": "0.10.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.10.1",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/28044055",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.10.1"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-06-29T07:26:13Z",
        "datePublished": "2020-06-29T07:26:45Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.10.0",
        "name": "0.10.0",
        "tag_name": "0.10.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.10.0",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/28013394",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.10.0"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-06-29T00:30:39Z",
        "datePublished": "2020-06-29T00:31:00Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.9.2",
        "name": "0.9.2",
        "tag_name": "0.9.2",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.9.2",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/28006979",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.9.2"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "",
        "dateCreated": "2020-06-29T00:17:56Z",
        "datePublished": "2020-06-29T00:18:19Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.9.1",
        "name": "0.9.1",
        "tag_name": "0.9.1",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.9.1",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/28006858",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.9.1"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "Add linformer",
        "dateCreated": "2020-06-28T21:01:15Z",
        "datePublished": "2020-06-28T21:01:33Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.9.0",
        "name": "0.9.0",
        "tag_name": "0.9.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.9.0",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/28004890",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.9.0"
      },
      {
        "authorType": "User",
        "author_name": "lucidrains",
        "body": "Add all dropouts",
        "dateCreated": "2020-06-21T23:24:01Z",
        "datePublished": "2020-06-21T23:24:41Z",
        "html_url": "https://github.com/lucidrains/linear-attention-transformer/releases/tag/0.8.0",
        "name": "0.8.0",
        "tag_name": "0.8.0",
        "tarball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/tarball/0.8.0",
        "url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/releases/27767529",
        "zipball_url": "https://api.github.com/repos/lucidrains/linear-attention-transformer/zipball/0.8.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 319,
      "date": "Tue, 21 Dec 2021 01:15:31 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "artificial-intelligence",
      "deep-learning",
      "attention-mechanism",
      "transformer",
      "pytorch"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Language model\n\n```python\nimport torch\nfrom linear_attention_transformer import LinearAttentionTransformerLM\n\nmodel = LinearAttentionTransformerLM(\n    num_tokens = 20000,\n    dim = 512,\n    heads = 8,\n    depth = 1,\n    max_seq_len = 8192,\n    causal = True,                  #: auto-regressive or not\n    ff_dropout = 0.1,               #: dropout for feedforward\n    attn_layer_dropout = 0.1,       #: dropout right after self-attention layer\n    attn_dropout = 0.1,             #: dropout post-attention\n    emb_dim = 128,                  #: embedding factorization, to save on memory\n    dim_head = 128,                 #: be able to fix the dimension of each head, making it independent of the embedding dimension and the number of heads\n    blindspot_size = 64,            #: this gives the q(kv) attention a blindspot of 64 tokens back in the causal case, but gives back an order of magnitude return in memory savings. should be paired with local attention of at least a window size of this setting. setting this to 1 will allow for full q(kv) attention of past\n    n_local_attn_heads = 4,         #: number of local attention heads for (qk)v attention. this can be a tuple specifying the exact number of local attention heads at that depth\n    local_attn_window_size = 128,   #: receptive field of the local attention\n    reversible = True,              #: use reversible nets, from Reformer paper\n    ff_chunks = 2,                  #: feedforward chunking, from Reformer paper\n    ff_glu = True,                  #: use GLU variant for feedforward\n    attend_axially = False,         #: will fold the sequence by the local attention window size, and do an extra strided attention followed by a feedforward with the cheap q(kv) attention\n    shift_tokens = True             #: add single token shifting, for great improved convergence\n).cuda()\n\nx = torch.randint(0, 20000, (1, 8192)).cuda()\nmodel(x) #: (1, 8192, 512)\n```\n\nTransformer\n\n```python\nimport torch\nfrom linear_attention_transformer import LinearAttentionTransformer\n\nmodel = LinearAttentionTransformer(\n    dim = 512,\n    heads = 8,\n    depth = 1,\n    max_seq_len = 8192,\n    n_local_attn_heads = 4\n).cuda()\n\nx = torch.randn(1, 8192, 512).cuda()\nmodel(x) #: (1, 8192, 512)\n```\n\nEncoder / decoder\n\n```python\nimport torch\nfrom linear_attention_transformer import LinearAttentionTransformerLM\n\nenc = LinearAttentionTransformerLM(\n    num_tokens = 20000,\n    dim = 512,\n    heads = 8,\n    depth = 6,\n    max_seq_len = 4096,\n    reversible = True,\n    n_local_attn_heads = 4,\n    return_embeddings = True\n).cuda()\n\ndec = LinearAttentionTransformerLM(\n    num_tokens = 20000,\n    dim = 512,\n    heads = 8,\n    depth = 6,\n    causal = True,\n    max_seq_len = 4096,\n    reversible = True,\n    receives_context = True,\n    n_local_attn_heads = 4\n).cuda()\n\nsrc = torch.randint(0, 20000, (1, 4096)).cuda()\nsrc_mask = torch.ones_like(src).bool().cuda()\n\ntgt = torch.randint(0, 20000, (1, 4096)).cuda()\ntgt_mask = torch.ones_like(tgt).bool().cuda()\n\ncontext = enc(src, input_mask = src_mask)\nlogits = dec(tgt, context = context, input_mask = tgt_mask, context_mask = src_mask)\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
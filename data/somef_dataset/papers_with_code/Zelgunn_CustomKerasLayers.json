{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2002.10444"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{jaderberg2015spatial,\n  title={Spatial transformer networks},\n  author={Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and others},\n  booktitle={Advances in neural information processing systems},\n  pages={2017--2025},\n  year={2015}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{de2020batch,\n    title={Batch normalization biases deep residual networks towards shallow paths},\n    author={De, Soham and Smith, Samuel L},\n    journal={arXiv preprint arXiv:2002.10444},\n    year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{he2016deep,\n  title={Deep residual learning for image recognition},\n  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},\n  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},\n  pages={770--778},\n  year={2016}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9996041012744451,
        0.99999919224502,
        0.9999999984528145,
        0.8944178096468923,
        0.9954488832581693
      ],
      "excerpt": "  title={Deep residual learning for image recognition}, \n  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian}, \n  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition}, \n  pages={770--778}, \n  year={2016} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9934694770574943,
        0.9970828332269493,
        0.9999537354568557,
        0.9664456561658856
      ],
      "excerpt": "    title={Batch normalization biases deep residual networks towards shallow paths}, \n    author={De, Soham and Smith, Samuel L}, \n    journal={arXiv preprint arXiv:2002.10444}, \n    year={2020} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9859379936648053,
        0.9984105949232318,
        0.988536099279406,
        0.9868512987915664,
        0.9864698047705643
      ],
      "excerpt": "  title={Spatial transformer networks}, \n  author={Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and others}, \n  booktitle={Advances in neural information processing systems}, \n  pages={2017--2025}, \n  year={2015} \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Zelgunn/CustomKerasLayers",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-19T09:33:58Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-22T13:40:55Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9056537592890719
      ],
      "excerpt": "3. Spatial Tranformer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8376387699419952
      ],
      "excerpt": "Currently implemented paper (SkipInit): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "ResBlock, DenseBlock and SpatialTransformer layers made with the Keras Layer API and TF2.0.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Zelgunn/CustomKerasLayers/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Fri, 24 Dec 2021 12:45:38 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Zelgunn/CustomKerasLayers/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Zelgunn/CustomKerasLayers",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8587476985249702
      ],
      "excerpt": "    a. Usage \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8292341622537164
      ],
      "excerpt": "Very basic tests on Cifar10 are provided in /tests for ResBlock and DenseBlock. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Zelgunn/CustomKerasLayers/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Custom Keras Layers",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "CustomKerasLayers",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Zelgunn",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Zelgunn/CustomKerasLayers/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 14,
      "date": "Fri, 24 Dec 2021 12:45:38 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You must provide a `Localisation network` (Layer or Model) to the Spatial Transformer.\n\nIf the dimension of the output of the `Localisation network` if not 6, the Spatial Transformer\nwill add one dense layer with an output of dimension 6 (and flatten its inputs).\n\nWhy 6 ? It is the dimension of `theta`, the affine 2x3 transformation matrix used to transform\n the input.\n \nThe transformation is performed through differentiable bilinear sampling.    \n\nHere is a small example:\n```python\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Input\nfrom CustomKerasLayers import SpatialTransformer\n\n#: Build\ninput_shape = (128, 128, 3)\nencoder_input_shape = (64, 64, 3)\n\nlocalisation_net = Sequential(...)\nspatial_transformer = SpatialTransformer(localisation_net,\n                                         output_size=encoder_input_shape)\nencoder = Sequential(...)\n...\n\n#: Call\ninput_layer = Input(input_shape)\n\noutput_theta = False\nif output_theta:\n    layer, theta = spatial_transformer(input_layer, output_theta=True)\nelse:\n    layer = spatial_transformer(input_layer)\n   \nlayer = encoder(layer)\n...\n\n```\n",
      "technique": "Header extraction"
    }
  ]
}
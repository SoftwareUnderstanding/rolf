{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1409.1556",
      "https://arxiv.org/abs/1512.00567",
      "https://arxiv.org/abs/14091556. 2014; \n\n\n\n"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Olah C, Mordvintsev A, Schubert L. Feature visualization. Distill. 2017 Nov 7;2(11).\n2. \tGoogle AI Blog: Inceptionism: Going Deeper into Neural Networks [Internet]. [cited 2021 Aug 16]. Available from: https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html\n3. \tPalanisamy K, Singhania D, Yao A. Rethinking CNN Models for Audio Classification. arXiv. 2020 Jul 22;\n4. \tSimonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:14091556. 2014; \n\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8888888649844091
      ],
      "excerpt": "Special credit to our TAs: Pedro F da Costa and Beatrix Benk\u00c5** \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/smhall97/deep_dreaming_music",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-05T05:01:34Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-11T09:32:51Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.981553682842318,
        0.9949599399053899,
        0.9830011198737731,
        0.9536338888049678,
        0.9909492564641809
      ],
      "excerpt": "Neuromatch Academy Deep Learning 2021 project by Maryam Faramarzi, Siobhan Hall, M\u00e1t\u00e9 Moh\u00e1csi, Pablo Oyarzo, Jonathan Reus and Katherine Baquero \nSpecial credit to our TAs: Pedro F da Costa and Beatrix Benk\u00c5** \nDuring the last decade CNNs have become increasingly powerful as models for computer vision. Their development has been carried conjointly with the exploration of their internal informational structure (1) and feature-inference processes. One of these approaches known as \u201cdreaming\u201d, initially developed by Google (2), has proven to be an effective method to maximize features and to take convolutional neural networks to the territory of stimuli generation.  \nIn this work, we ask how audible waveforms can be reconstructed from features by exploring dreaming algorithms as a method. This method has the capacity to work as an introspective technique for understanding internal network representations, as well as potentially acting as a generative approach for novel audio output.  \nCNNs have been used to achieve state-of-the-art performance classifying music genres from (Mel Scale) spectrograms (3), thus we choose to explore the problem of music genre classification as a starting point for exploring internal representations. While most literature on CNN-based music genre classifiers use Mel-scale Spectrograms, this audio representation can be potentially limiting in the specific situation of deep dreaming on spectrograms, where the end goal is to reconstruct an audible time-domain waveform. It is for this reason we investigated the following audio transforms: Short-Time-Fourier Transforms (STFTs) and Mel-spectrograms. These will be collectively referred to as Spectrograms throughout. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9253824202039701
      ],
      "excerpt": "To investigate the best approach to training a classifier as well as choosing the type of audio data transform that can be reconverted to music once \u201cdreamed\u201d upon. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.951232532257774
      ],
      "excerpt": "Preparing the data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9284249978037538
      ],
      "excerpt": "- The STFTs were computed with the real and imaginary part, as well as only the real component. Both of these versions were used separately \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9666268081178534
      ],
      "excerpt": "For either approach, one can choose to normalize the gradient or not (which usually leads to faster learning at the cost of sometimes opting for less nuanced dream features) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8806740052322108,
        0.8435415267232191
      ],
      "excerpt": "Maximize activation of a single genre \nMaximize activation difference between a single genre and another (or all other) genre(s) \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/smhall97/deep_dreaming_music/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Tue, 21 Dec 2021 21:51:14 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/smhall97/deep_dreaming_music/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "smhall97/deep_dreaming_music",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/smhall97/deep_dreaming_music/main/Combined_CNN_Training.ipynb",
      "https://raw.githubusercontent.com/smhall97/deep_dreaming_music/main/Feature_visualisation_VGG16.ipynb",
      "https://raw.githubusercontent.com/smhall97/deep_dreaming_music/main/Deep_Dream_Music.ipynb",
      "https://raw.githubusercontent.com/smhall97/deep_dreaming_music/main/Audio%20data%20preparation/wav2spectrograms.ipynb",
      "https://raw.githubusercontent.com/smhall97/deep_dreaming_music/main/Audio%20data%20preparation/AudioFormatConversion.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8669712963304532
      ],
      "excerpt": "- 1000 audio tracks (length: 30 seconds; 22050 Hz Mono 16-bit audio files in .wav format) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/smhall97/deep_dreaming_music/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Deep Dreaming Music",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "deep_dreaming_music",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "smhall97",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/smhall97/deep_dreaming_music/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Tue, 21 Dec 2021 21:51:14 GMT"
    },
    "technique": "GitHub API"
  }
}
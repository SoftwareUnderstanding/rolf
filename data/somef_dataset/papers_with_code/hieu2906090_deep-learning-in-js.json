{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1409.1556>.\n**<4>** \u201cUnderstanding SSD MultiBox\u2014Real-Time Object Detection In Deep Learn- ing\u201d by Eddie Forson: <http://mng.bz/07dJ>.\n**<5>** \u201cReal-time Object Detection with YOLO, YOLOv2, and now YOLOv3\u201d by Jona- than Hui: <http://mng.bz/KEqX>.\n\n## PART III: ADVANCED DL IN TENSORFLOW.JS\n\n### C6 - Working with data\n\n#### CREATING A TF.DATA.DATASET FROM AN ARRAY\n\n#### CREATING A TF.DATA.DATASET FROM A CSV FILE\n\n(206"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8456806903995955
      ],
      "excerpt": "    if validationLoss &lt; minValidationLoss \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9998819138098194,
        0.9061005469315193,
        0.9999999998660201,
        0.9986237085856801
      ],
      "excerpt": "<1> Wei Liu et al., \u201cSSD: Single Shot MultiBox Detector,\u201d Lecture Notes in Computer Science \n9905, 2016, http://mng.bz/G4qD. \n<2> Joseph Redmon et al., \u201cYou Only Look Once: Unified, Real-Time Object Detection,\u201d Pro- ceedings IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 779\u2013788, http://mng.bz/zlp1. \n<3> Karen Simonyan and Andrew Zisserman, \u201cVery Deep Convolutional Networks for Large-Scale Image Recognition,\u201d submitted 4 Sept. 2014, https://arxiv.org/abs/1409.1556. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9998018087723242
      ],
      "excerpt": "\uf0a1 Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin, \u201cWhy Should I Trust You? Explaining the Predictions of Any Classifier,\u201d 2016, https://arxiv.org/pdf/1602.04938.pdf. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "loss = meanAbsoluteError(targets, prediciton) + 12Rate * 12(kernel) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "\uf0a1 Machine translation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9984782760541836
      ],
      "excerpt": "\uf0a1 Chris Olah and Shan Carter, \u201cAttention and Augmented Recurrent Neural Net- works,\u201d Distill, 8 Sept. 2016, https://distill.pub/2016/augmented-rnns/. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8162474953880842
      ],
      "excerpt": "\uf0a1 Stephan Raaijmakers, Deep Learning for Natural Language Processing, Manning Publications, in press, www.manning.com/books/deep-learning-for-natural- language-processing. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8456806903995955
      ],
      "excerpt": "    if x &lt; epsilon: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8710406967946426,
        0.873967791040656
      ],
      "excerpt": "\uf0a1 Richard S. Sutton and Andrew G. Barto, Reinforcement Learning: An Introduction, A Bradford Book, 2018. \n\uf0a1 David Silver\u2019s lecture notes on reinforcement learning at University College London: http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9900995999957883,
        0.9982918108653015
      ],
      "excerpt": "\uf0a1 Denis Baylor et al., \u201cTFX: A TensorFlow-Based Production-Scale Machine Learning Platform,\u201d KDD 2017, www.kdd.org/kdd2017/papers/view/tfx-a- tensorflow-based-production-scale-machine-learning-platform. \n\uf0a1 Raghuraman Krishnamoorthi, \u201cQuantizing Deep Convolutional Networks forEfficient Inference: A Whitepaper,\u201d June 2018, https://arxiv.org/pdf/ 1806.08342.pdf. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9840846195802034
      ],
      "excerpt": "Pose Net (Detect Skeletal key points) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/js-data-learn/deep-learning-in-js",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-25T03:06:53Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-10-25T11:11:35Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "![Basic RL visulization](readme-imgs/basic-rl.png)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8886145499926035,
        0.9688688655961551
      ],
      "excerpt": "(66) Because TensorFlow.js optimizes its computation by scheduling on the GPU, tensors might not always be accessible to the CPU. The calls to dataSync in listing 2.8 tell TensorFlow.js to finish computing the tensor and pull the value from the GPU into the CPU, so it can be printed out or otherwise shared with a non-TensorFlow operation. \nTo counteract this, we will first normalize our data. This means that we will scale our features so that they have zero mean and unit standard deviation. This type of normal- ization is common and may also be referred to as standard transformation or z-score nor- malization. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9838201181099936
      ],
      "excerpt": "(71) The complete list of callback triggers (in model.fit() function), as of version 0.12.0, is onTrainBegin, onTrainEnd, onEpochBegin, onEpochEnd, onBatchBegin, and onBatchEnd. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8539239257208191
      ],
      "excerpt": "    `Epoch ${epoch + 1} of ${NUM_EPOCHS} completed.`); trainLoss = logs.loss; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9511957020642029
      ],
      "excerpt": "(84) This is because part of the sigmoid function (the part close to the cen- ter) is fairly close to being a straight line \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9615120911305841
      ],
      "excerpt": "(87) This brings up a common \u201cgotcha\u201d in building multilayer neural networks: be sure to include nonlinear activations in the hidden layers. Failing to do so results in wasted computation resources and time, with potential increases in numerical instability (observe the wigglier loss curves in panel B of figure 3.4) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9632878063396476,
        0.9705089150483014
      ],
      "excerpt": "\uf0a1 The number of dense layers in a model, like the ones in listings 3.1 and 3.2 \n\uf0a1 What type of initializer to use for the kernel of a dense layer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9561214362221265
      ],
      "excerpt": "\uf0a1 The type of optimizer used for training (such as 'sgd' versus 'adam'; see info \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8253880828926791,
        0.9186280383204978,
        0.8033254040662451
      ],
      "excerpt": "\uf0a1 How many epochs to train the model for \n\uf0a1 The learning rate of the optimizer \n\uf0a1 Whether the learning rate of the optimizer should be decreased gradually as \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9979737054737187,
        0.9041785941754492
      ],
      "excerpt": "    for learningRate of [1e-5, 1e-4, 1e-3, 1e-2]: \n    Create a model using whose dense layer consists of `units` units Train the model with an optimizer with `learningRate` \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8621735948535137
      ],
      "excerpt": "(111) However, accuracy is a bad choice for loss function because it suffers from the same zero-gradient issue as the accuracy in binary classification. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9870666627754017
      ],
      "excerpt": "  for i in (0 to length of oneHotTruth) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9085714311256389,
        0.992033386536342,
        0.9247427076519357,
        0.8959200557720989,
        0.8821891376776447,
        0.9467679277860059,
        0.984269282749176
      ],
      "excerpt": "(121) The groups of conv2d-maxPooling2d layers are the working horse of feature extraction \nBy passing the input image data through the successive layers of con- volution and pooling, we get tensors that become smaller and smaller in size and more and more abstract in the feature space \n(122) Compared to a dense layer, a conv2d layer has more configuration parameters. kernelSize and filters are two key parameters of the conv2d layer \n(125) a conv2d layer is \u201csparsely connected.\u201d While dense layers learn global patterns in the input, convolutional layers learn local patterns\u2014patterns within the small window of the kernel. \n(126) A maxPooling2d layer serves two main purposes in a convnet. First, it makes the convnet less sensitive to the exact location of key features in the input image -> positional invariance. \n(127) The higher the level, the more abstract the representation and the more removed from the pixel-level values the features are. \n(131) the benefit of using larger batch sizes is that it produces a more consistent and less variable gradient update to the model\u2019s weights than a smaller batch size \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9443910370879753
      ],
      "excerpt": "(135) The second way to get image tensors in the browser is to use the TensorFlow.js func- tion tf.browser.fromPixels() on HTML elements that contain image data\u2014this includes img, canvas, and video elements. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.912267568496293
      ],
      "excerpt": "Resize by using 1 of 2 tf.image.resizeBilinear() or tf.image.resizeNearestNeigbor() (less computationally intensive than bilinear interpolation) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9712117532314903,
        0.9762790535724866,
        0.9897821203584454,
        0.9398112143698086,
        0.9892266014010156,
        0.9570553256789754,
        0.9768486806154667,
        0.909822445401985
      ],
      "excerpt": "(156) We mentioned previously that the compile() call configures the optimizer, loss function, and metrics. However, the method also lets the model refresh the list of weight variables to be updated during those calls. \n(157) Note that some of the layers we\u2019ve frozen contain no weights (such as the maxPooling2d layer and the flatten layer) and therefore don\u2019t contribute to the count of nontrain- able parameters when they are frozen. \n(158) These differences reflect the advantage of transfer learning: by reusing weights in the early layers (the feature- extracting layers) of the model, the model gets a nice head start relative to learning everything from scratch. This is because the data encountered in the transfer-learning task is similar to the data used to train the original model. \n(166) Instead of holding concrete values, a symbolic tensor specifies only a shape and a dtype. A symbolic tensor can be thought of as a \u201cslot\u201d or a \u201cplace- holder,\u201d into which an actual tensor value may be inserted later, given that the tensor value has a compatible shape and dtype. (167) It is a \u201cblueprint\u201d for the shape and dtype of the actual tensor values that the model or layer object will output. \n(167) In the new approach, we use the tf.model() function, which takes a configuration object with two mandatory fields: inputs and outputs. The inputs field is required to be a symbolic tensor (or, alternatively, an array of symbolic tensors), and likewise for the outputs field. Therefore, we can obtain the symbolic tensors from the original MobileNet model and feed them to a tf.model() call. The result is a new model that consists of a part of the original MobileNet. \n(167) The last few layers of a deep convnet are sometimes referred to as the head. What we are doing with the tf.model() call can be referred to as truncating the model. The truncated MobileNet preserves the feature- extracting layers while discarding the head. \n(169) This kind of lower-dimension representation of inputs is often referred to as an embedding. \nNOTE: This will predict the output at layer (n) -> this will become the input of our model when using pretrained. In the layer declaration, remove first dim as this is the batch of training exams. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9183808664408302
      ],
      "excerpt": "(170) As a result of the two-model setup, it is not possible to train the new head directly using the image tensors (of the shape [numExamples, 224, 224, 3]). Instead, the new head must be trained on the embeddings of the images\u2014 the output of the truncated MobileNet. Luckily, we have already collected those embedding tensors \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9951118178393367,
        0.9035710143656451,
        0.9799896605055101
      ],
      "excerpt": "(172) One interesting aspect of the method we used in this example is that the training and inference process involves two separate model objects. (177) Another advantage of this approach is that it exposes the embeddings and makes it easier to apply machine-learning techniques that make direct use of these embeddings. \n(173) In some cases, embeddings give us vector representations for things that are not even origi- nally represented as numbers (such as the word embeddings in chapter 9). \nIn cases where the number of reference examples is not too large, and the dimensionality of the input is not too high, using kNN can be computationally more efficient than train- ing a neural network and running it for inference. However, kNN inference doesn\u2019t scale well with the amount of data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9762383683904071
      ],
      "excerpt": "(177) Fine-tuning is a technique that helps you reach levels of accuracy not achievable just by training the new head of the transfer model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8569570862637145
      ],
      "excerpt": "this.model = \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9235657658401968,
        0.9649383334752409,
        0.9371971117251984
      ],
      "excerpt": "Visual way of the above method: \nEvery inference takes only one predict() call and is therefore a more streamlined process. () This enables us to perform the fine- tuning trick. This is what we will explore in the next section. \n(180) Some layers from the transfer model will be unfreezed and contiunuing to receive the updates of the head layer (in fine tuning process) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9100712961502695,
        0.8423338596051392,
        0.8486998922114131,
        0.9632427017485571,
        0.8975031618760531
      ],
      "excerpt": "Each time you freeze or unfreeze any layers by changing their trainable attri- bute, you need to call the compile() method of the model again in order for the change to take effect. \nObviously, if the validation set lacks certain words, it won\u2019t be a very good set to measure the model\u2019s accuracy on. This is why we use a custom function (balancedTrainValSplit in listing 5.8) \n(183) So why does fine-tuning help? It can be understood as an increase in the model capacity. \n(184) One question you might want to ask is, here we unfreeze only one layer in the base model, but will unfreezing more layers help? The short answer is, it depends, because unfreezing even more layers gives the model even higher capacity. But as we men- tioned in chapter 4 and will discuss in greater detail in chapter 8, higher capacity leads to a higher risk of overfitting ... \n(186) The nice things about using synthesized data are 1) the true label values are automati- cally known, and 2) we can generate as much data as we want. Every time we generate a scene image, the type of the object and its bounding box are automatically available to us from the generation process. (commonly used techniques in DL). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9733189651803366
      ],
      "excerpt": "(191) Why do we do this instead of using binary cross entropy as we did for the phishing- detection example in chapter 3? We need to combine two metrics of accuracy here: one for the shape prediction and one for the bounding-box prediction. The latter task involves predicting continuous values and can be viewed as a regression task. Therefore, MSE is a natural metric for bounding boxes. In order to combine the met- rics, we just \u201cpretend\u201d that the shape prediction is also a regression task. This trick allows us to use a single metric function (the tf.metric.meanSquaredError() call in listing 5.10) to encapsulate the loss for both predictions. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9673734345799629
      ],
      "excerpt": "(194) Instead of using a single meanSquaredError metric as the loss function, the loss function of a real object-detection model is a weighted sum of two types of losses: 1) a softmax cross-entropy-like loss for the probability scores pre- dicted for object classes and 2) a meanSquaredError or meanAbsolute- Error-like loss for bounding boxes. The relative weight between the two types of loss values is carefully tuned to ensure balanced contributions from both sources of error. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233670605967054
      ],
      "excerpt": "<4> \u201cUnderstanding SSD MultiBox\u2014Real-Time Object Detection In Deep Learn- ing\u201d by Eddie Forson: http://mng.bz/07dJ. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8478525269993724
      ],
      "excerpt": "(206) In Node.js, we can connect to a local CSV file by using a URL handle with the file:// prefix, like the following: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8305720783504648,
        0.9920766715918217
      ],
      "excerpt": "Done by using tf.data.generator(). \n(207) Generator datasets are powerful and tremendously flexible and allow developers to connect models to all sorts of data-providing APIs, such as data from a database query, from data downloaded piecemeal over the network, or from a piece of con- nected hardware. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9512652761144252,
        0.8422835596017442,
        0.9893017366444677,
        0.931198464479407,
        0.987999628347592,
        0.8813859943830232
      ],
      "excerpt": "The first way to access data from a dataset is to stream it all out into an array using Dataset.toArray(). The user should use caution when executing this function to not inadver- tently produce an array that is too large for the JavaScript runtime. \nThe second way to access data from a dataset is to execute a function on each example of the dataset using dataset.forEachAsync(f). \n(210) tf.data.Dataset provides a chainable API of methods to perform these sorts of operations, described in table 6.3. Each of these methods returns a new Dataset object, but don\u2019t be misled into thinking that all the elements of the dataset are cop- ied or that all the elements are iterated over for each method call! The tf.data .Dataset API only loads and transforms elements in a lazy fashion. \n(212) It is very important that the data is shuffled the same way when we are taking the samples, so we don\u2019t end up with the same example in both sets; thus we use the same random seed for both when sampling both pipelines. \n(214) Foremost, we don\u2019t need to write code to manage and orchestrate the downloading of pieces of our dataset\u2014this is handled for us in an efficient, as-needed streaming manner. \n(223) Since the Dataset object does not actually contact the remote resource until the data is needed, it\u2019s important to take care to write the error handling in the right place. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9876170145146775,
        0.9956906013889412,
        0.9526339105393741,
        0.997869125457863
      ],
      "excerpt": "(228) One final note: when using the webcam, it is often a good idea to draw, process, and discard an image before making predictions on the feed. () Similar to the webcam API, the microphone API creates a lazy iterator allowing the caller to request frames as needed, packaged neatly as tensors suitable for consumption directly into a model. \n(242) As such, this may not be enough to completely get rid of overfitting. Another risk of using data augmentation is that the training data is now less likely to match the distribution of the inference data, introduc- ing skew. \n(243) It\u2019s also important to see that augmentation should not be applied to the validation or testing set. \n(249) In general, it is good practice to limit the size of the data to be rendered in interactive visualizations for the sake of a smooth and responsive UI. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9295899640320303
      ],
      "excerpt": "(252) A histogram assigns the values into bins. Each bin is simply a continuous range for the value, with a lower bound and an upper bound. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008682974013386
      ],
      "excerpt": "\uf0a1 Visualizing the outputs of intermediate layers (intermediate activations) of a convnet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9712023802798877
      ],
      "excerpt": "(266) This process is schematically gradient ascent in input space, as opposed to the gradient descent in weight space that underlies typical model training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9479523862668312,
        0.9456239638648714
      ],
      "excerpt": "Here, auxModel is an auxiliary model object created with the familiar tf.model() function. It has the same input as the original model but outputs the activation of a given convolutional layer. \n(269) The question that CAM (Class activation map) aims to answer is \u201cwhich parts of the input image play the most important roles in causing the convnet to output its top classification decision? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9928040701262129,
        0.9907859756080275,
        0.8840972792541678,
        0.983534618348982,
        0.9537079703296164,
        0.9431494791329043,
        0.9650491514225852
      ],
      "excerpt": "\uf0a1 TensorSpace (tensorspace.org) uses animated 3D graphics to visualize the topology and internal activations of convnets in the browser. It is built on top of TensorFlow.js, three.js, and tween.js. \n\uf0a1 The TensorFlow.js tSNE library (github.com/tensorflow/tfjs-tsne) is an effi- cient implementation of the t-distributed Stochastic Neighbor Embedding (tSNE) algorithm based on WebGL. It can help you visualize high-dimensional datasets by projecting them to a 2D space while preserving the important struc- tures in the data. \n(276) generator/iterator specification of JavaScript (http://mng.bz/RPWK) \n() As we described in chapter 6, a tf.data.Dataset object, when used in conjunction with the fitDataset() method of a tf.Model object, enables us to train the model even if the data is too large to fit into WebGL memory (or any applicable backing memory type) as a whole. \n(280) To over- come underfitting, we usually increase the power of the model by making it bigger. \n() In particular, the kernelRegularizer and dropoutRate parameters are the ways in which we\u2019ll combat overfitting later. \n(282) With a regularized weight, the loss of the model includes an extra term. In pseudo-code, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8993783524828086,
        0.9378384396708138,
        0.9559657035968937
      ],
      "excerpt": "Here, l2Rate * l2(kernel) is the extra L2-regularization term of the loss function. Unlike the MAE, this term does not depend on the model\u2019s predictions. \nAs a result, the training process will try to not only minimize the target-prediction mismatch but also reduce the sum of the squares of the kernel\u2019s elements. \n(283) Since the L2 regularizer works by encouraging the kernel of the hidden dense layer to have smaller values, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9984078177157203,
        0.951909113607992,
        0.9721784161507621,
        0.8892291047491016
      ],
      "excerpt": "An intuitive way to understand this is that L2 regularization enforces the principle of Occam\u2019s razor. Generally speaking, a larger magnitude in a weight param- eter tends to cause the model to fit to fine-grained details in the training features that it sees, and a smaller magnitude tends to let the model ignore such details. \n(288) Keep in mind that machine learning can only be used to learn patterns that are present in the training data. In this case, getting up-to-date data and continuously training new models will be a via- ble solution. \n(297) Comparing the structure of simpleRNN and that of the dense layer (figure 9.1), we can see two major differences: \n\uf0a1 SimpleRNN processes the input elements (time steps) one step at a time. This reflects the sequential nature of the inputs, something a dense layer can\u2019t do. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8927730455755288,
        0.9692752185892598
      ],
      "excerpt": "The output from a previous time step (for example, y1) is used by the layer when it processes the next time step (such as x2). \n(298) You can see that the output at time step i becomes the \u201cstate\u201d for the next time step (next iteration). State is an important concept for RNNs. It is how an RNN \u201cremembers\u201d what happened in the steps of the input sequence it has already seen. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9511700348840567
      ],
      "excerpt": "() Furthermore, the for loop reflects another important property of RNNs: parameter sharing. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9776027941154488,
        0.985247501959963,
        0.9978574051490967,
        0.9657605755328219
      ],
      "excerpt": "(302) GRU and LSTM are RNNs designed to solve the vanishing-gradient problem, and GRU is the simpler of the two. \n(304) For instance, suppose we\u2019re trying to classify a movie review as positive or negative. The review may start by saying \u201cthis movie is pretty enjoyable,\u201d but halfway through the review, it then reads \u201chow- ever, the movie isn\u2019t as good as other movies based on similar ideas.\u201d At this point, the memory regarding the initial praise should be largely forgotten, because it is the later part of the review that should weigh more in determining the final sentiment-analysis result of this review. \n() The important thing to remember is that the internal structure of GRU allows the RNN to learn when to carry over old state and when to update the state with information from the inputs. This learning is embodied by updates to the tunable weights, Wz, Uz, Wr, Wr, W, and U (in addition to the omitted bias terms). \nJust like one-hot encoding (figure 9.6), word embedding is a way to represent a word as a vector (a 1D tensor in TensorFlow.js). However, word embeddings allow the values of the vector\u2019s elements to be trained, instead of hard- coded according to a rigid rule such as the word-to-index map in one-hot encoding. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8266536679001595,
        0.964715660067971,
        0.9441814912567613,
        0.8575924854033371,
        0.9206511985851403,
        0.9715742651640497
      ],
      "excerpt": "\uf0a1 It addresses the size problem with one-hot encodings. embeddingDims is usually much smaller than vocabularySize. \n\uf0a1 By not being opinionated about how to order the words in the vocabulary and by allowing the embedding matrix to be trained via backpropagation just like all other neural network weights, word embeddings can learn semantic rela- tions between words. Words with similar meanings should have embedding vec- tors that are closer in the embedding space. \n\uf0a1Also, the fact that the embedding space has multiple dimensions (for example, 128) should allow the embedding vectors to capture different aspects of words. \n(314) Why do we need to do truncation and padding? TensorFlow.js models require the inputs to fit() to be a tensor, and a tensor must have a concrete shape. \n(317) However, it needs to be pointed out that a conv1d layer by itself is not able to learn sequential patterns beyond its kernel size. \nThe slower performance of LSTM and RNNs is related to their step-by-step internal operations, which cannot be parallelized; convolutions are amenable to par- allelization by design. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8077006509214897,
        0.9438235282507602,
        0.8890805603493954
      ],
      "excerpt": "The Embedding Projector tool provides two algorithms for dimension reduction: t-distrib- uted stochastic neighbor embedding (t-SNE) and principal component analysis (PCA) \nOne of the best known pretrained word- embedding sets is GloVe (for Global Vectors) by the Stanford Natural Language Pro- cessing Group (see https://nlp.stanford.edu/projects/glove/). \nSome variety of Seq2seq tasks: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9490277540745182
      ],
      "excerpt": "(326) The role of the attention mechanism is to enable each output character to \u201cattend\u201d to the correct characters in the input sequence. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8546500102273951,
        0.8914272212853802,
        0.9740384904821412,
        0.9258181311350698,
        0.950129355970855,
        0.948247973583877,
        0.9602149927567335,
        0.94757701023559,
        0.9828916570238679,
        0.9843405623385035,
        0.9606883870269131,
        0.9858037170564865,
        0.9943489030345984,
        0.9234093558359783,
        0.9100320666176499
      ],
      "excerpt": "\uf0a1 Andrej Karpathy, \u201cThe Unreasonable Effectiveness of Recurrent Neural Net- works,\u201d blog, 21 May 2015, http://mng.bz/6wK6. \n\uf0a1 Zafarali Ahmed, \u201cHow to Visualize Your Recurrent Neural Network with Atten- tion in Keras,\u201d Medium, 29 June 2017, http://mng.bz/6w2e. \n\uf0a1 In the date-conversion example, we described a decoding technique based on argMax(). This approach is often referred to as the greedy decoding technique because it extracts the output symbol of the highest probability at every step. A popular alternative to the greedy-decoding approach is beam-search decoding, which examines a larger range of possible output sequences in order to deter- mine the best one. You can read more about it from Jason Brownlee, \u201cHow to Implement a Beam Search Decoder for Natural Language Processing,\u201d 5 Jan. 2018, https://machinelearningmastery.com/beam-search-decoder-natural- language-processing/. \n\uf0a1 Stephan Raaijmakers, Deep Learning for Natural Language Processing, Manning Publications, in press, www.manning.com/books/deep-learning-for-natural- language-processing. \n(379) A natural solution is to build a neural network to select an action based on the observation. This is the basic idea behind the policy network. \n() The reason we don\u2019t include the sigmoid nonlinearity directly in the last (output) layer of the policy network is that we need the logits for training, as we\u2019ll see shortly. \n(380) Why do we prefer the more complicated random- sampling approach with tf.multinomial() over this simpler approach? The answer is that we want the randomness that comes with tf.multinomial(). \n(381) In other words, it has to \u201clearn swimming by swimming,\u201d a key feature of RL problems. \n(382) We want to assign higher scores to the actions in the early and middle parts of the episode and assign lower ones to the actions near the end. \nThis brings us to the idea of reward discounting, a simple but important idea in RL that the value of a certain step should equal the immediate reward plus the reward that is expected for the future. \nPolicy Gradient: It compares the logits (unnormal- ized probability scores) and the actual action selected at the step and returns the gradient of the discrepancy between the two with respect to the policy network\u2019s weights. \nThe gradients, together with the rewards from the training episodes, form the basis of our RL method. This is why this method belongs to the family of RL algorithms called policy gradients. \n(384) During training, we let the agent play a number of games (say, N games) and collect all the discounted rewards according to equation 11.1, as well as the gradients from all the steps. Then, we combine the discounted rewards and gradients by multiplying the gradients with a normalized version of the discounted rewards. The reward normaliza- tion here is an important step. It linearly shifts and scales all the discounted rewards from the N games so that they have an overall mean value of 0 and overall standard deviation of 1. An example of applying this normalization on the discounted rewards is shown in figure 11.6. It illustrates the normalized, discounted rewards from a short episode (length = 4) and a longer one (length = 20). From this figure, it should be clear what steps are favored by the REINFORCE algorithm: they are the actions made in the early and middle parts of longer episodes. By contrast, all the steps from the shorter (length-4) episode are assigned negative values. What does a negative normal- ized reward mean? It means that when it is used to update the policy network\u2019s weights later, it will steer the network away from making a similar choice of actions given similar state inputs in the future. This is in contrast to a positive normalized reward, which will steer the policy network toward choosing similar actions given simi- lar inputs in the future. \nIllustrate for the training process of a Policy Net: \n(388) If the char- acteristics of the system change over time, we won\u2019t have to derive new mathematical solutions from scratch: we can just re-run the RL algorithm and let the agent adapt itself to the new situation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9615141004229345,
        0.9420511579174285,
        0.954861920518232,
        0.9492023734828303
      ],
      "excerpt": "(390) One key challenge in the snake game is the snake\u2019s growth. With the length-growth rule, however, the agent must learn to avoid bumping into its own body, which gets harder as the snake eats more fruit and grows longer. \nThis sparse and complex reward structure is also the main reason why the policy gradient and REINFORCE method will not work well on this problem. \nThe policy-gradient method works better when the rewards are frequent and simple, as in the cart-pole problem. \nMDP requirement: The state of the environment at the next step is determined completely by the state and the action taken by the agent at the current step. In other words, MDP assumes that your history (how you got to your current state) is irrelevant to deciding what you should do next. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8294739010988151,
        0.9801882419958428
      ],
      "excerpt": "(394) A Q-value, denoted Q(s, a), is a function of the current state (s) and the action (a). \n(395) Therefore, the RL problem of finding the best decision-making process is reduced to learning the function Q(s, a). This is why this learning algorithm is called Q-learning. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9041620693191785
      ],
      "excerpt": "Q-learning is about predicting the values of all possible actions (Q-values). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9543674499547112,
        0.96317477397817
      ],
      "excerpt": "() The programmer in you will immediately notice that the Bellman equation (equation 11.3) is recursive: all the Q-values on the right-hand side of the equation can be expanded further using the equation itself. \n_The beauty and power of Bellman equation is that it allows us to turn the Q-learning problem into a supervised learning problem, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8418311296162462,
        0.9121745342835902,
        0.9433387749430459,
        0.8623205076788084,
        0.9170904674544752
      ],
      "excerpt": "(399) We will train our DQN by pressuring it to match the Bellman equation. If all goes well, this means that our DQN will reflect both the immediate rewards and the optimal dis- counted future rewards. \n() Computing samples of input requires the current state si and the action we took at that state, aj, both of which are directly available in the game history. \n(400) The random-play part is easily achieved using a random-number generator. The remembering part is achieved with a data structure known as replay memory. \nHow the replay memory work: \n1 si, observation of the current state at step i (the board configuration). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9801269760430653
      ],
      "excerpt": "rent step. From this, you can see the fact that the replay memory is not just for a single episode of the game. Instead, it concatenates the results from multiple game episodes. Once a previous game is over, the training algorithm simply starts a new one and keeps appending the new records to the replay memory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8445422811103668
      ],
      "excerpt": "The Replay Memory can be thought as a \"dataset\" for the DQN. But it kept update as the training goes on. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9435371098189349,
        0.98753538363111,
        0.8670055500662809
      ],
      "excerpt": "Choose the action that corresponds to the maximum element of qValues \n(402) In RL problems based on the epsilon-greedy policy, the initial and final values of epsilon are tunable hyperparameters, and so is the time course of epsilon\u2019s down-ramping. \nIllustration how the predicted Q-values are extracted from the replay memory in a step of the DQN training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.974089523912911
      ],
      "excerpt": "(406) As you may have noticed, an important trick in the deep Q-learning algorithm here is the use of two instances of DQNs. They are called the online DQN and the target DQN, respectively. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9288207017531077
      ],
      "excerpt": "(409) To improve the snake agent further, we need to tweak the epsilon-greedy algorithm to encourage the snake to explore better moves when its length is long. (https://github.com/carsonprindle/OpenAIExam2018.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8640077070041166
      ],
      "excerpt": "\uf0a1 Richard S. Sutton and Andrew G. Barto, Reinforcement Learning: An Introduction, A Bradford Book, 2018. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9116438698133046,
        0.9445734475236715,
        0.8874525643746339,
        0.9930501821261558,
        0.9071859475163535,
        0.9121582437918966
      ],
      "excerpt": "\uf0a1 Maxim Laplan, Deep Reinforcement Learning Hands-On: Apply Modern RL Methods, with Deep Q-networks, Value Iteration, Policy Gradients, TRPO, AlphaGo Zero, and More, Packt Publishing, 2018. \n(439) One common development mistake is to forget to account for Cross-Origin Resource Sharing (CORS) when setting up a bucket in GCP () but after the initial load, the model can be loaded much faster from the browser cache. \n(440) One nice property of web deployment is that prediction happens directly within the browser. \nA downside of making predictions within the browser is model security. Sending the model to the user makes it easy for the user to keep the model and use it for other purposes. \n() 2 approaches to serving models as cloud serve: \nServe on a NodeJS server with native JS. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9901584542336284,
        0.9548671528430285
      ],
      "excerpt": "The model secu- rity story and data privacy story are identical to the web page deployment. \nNote that the model running in the browser extension has access to the same hard- ware acceleration as the model running in the web page and, indeed, uses much of the same code. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9887189600115226,
        0.919498643453575,
        0.9736130179037891,
        0.9199371952914137,
        0.9332645191277156,
        0.8460587593213232,
        0.9848973422845644,
        0.9376681537080359,
        0.9115856176986848,
        0.9638945048068017,
        0.9905682638072362,
        0.9749266385397906,
        0.9023534672168741,
        0.9838253373803909,
        0.8765078466986003,
        0.9982509086027465,
        0.9894539950044583,
        0.8617153266711098
      ],
      "excerpt": "(458) These difficult steps include understanding the problem domain well enough to be able to determine what sort of data is needed, what sort of predictions can be made with reasonable accuracy and generalization power, how the machine-learning model fits into the overall solution that addresses a practical problem, and how to measure the degree to which the model succeeds at doing its job. \n1. Determine if machine learning is the right approach. First, consider if machine learn- ing is the right approach to your problem, and proceed with the following steps only if the answer is yes. In some cases, a non-machine-learning approach will work equally well or perhaps even better, at a lower cost. \n2. Define the machine-learning problem. Determine what sort of data is available and what you are trying to predict using the data. \n3. Check if your data is sufficient. Determine if the amount of data you already have is sufficient for model training. You may need to collect more data or hire peo- ple to manually label an unlabeled dataset. \n4. Identify a way to reliably measure the success of a trained model on your goal. For simple tasks, this may be just prediction accuracy, but in many cases, it will require more sophisticated, domain-specific metrics. \n5. Prepare the evaluation process. Design the validation process that you\u2019ll use to eval- uate your models. In particular, you should split your data into three homoge- neous yet nonoverlapping sets: a training set, a validation set, and a test set. The validation- and test-set labels ought not to leak into the training data. For instance, with temporal prediction, the validation and test data should come from time intervals after the training data. Your data-preprocessing code should be covered by tests to guard against bugs (section 12.1). \n6. Vectorize the data. Turn your data into tensors, or n-dimensional arrays\u2014the lin- gua franca of machine-learning models in frameworks such as TensorFlow.js and TensorFlow. You often need to preprocess the tensorized data in order to make it more amenable to your models (for example, through normalization). \n7. Beat the commonsense baseline. Develop a model that beats a non-machine-learning baseline (such as predicting the population average for a regression problem or predicting the last datapoint in a time-series prediction problem), thereby demonstrating that machine learning can truly add value to your solution. This may not always be the case (see step 1). \n8. Develop a model with sufficient capacity. Gradually refine your model architecture by tuning hyperparameters and adding regularization. Make changes based on the prediction accuracy on the validation set only, not the training set or the test set. Remember that you should get your model to overfit the problem (achieve a better prediction accuracy on the training set than on the validation set), thus identifying a model capacity that\u2019s greater than what you need. Only then should you begin to use regularization and other approaches to reduce overfitting. \n9. Tune hyperparameters. Beware of validation-set overfitting when tuning hyperpa- rameters. Because hyperparameters are determined based on the performance on the validation set, their values will be overspecialized for the validation set and therefore may not generalize well to other data. It is the purpose of the test set to obtain an unbiased estimate of the model\u2019s accuracy after hyperparame- ter tuning. So, you shouldn\u2019t use the test set when tuning the hyperparameters. \n10. Validate and evaluate the trained model. As we discussed in section 12.1, test your model with an up-to-date evaluation dataset, and decide if the prediction accu- racy meets a predetermined criterion for serving actual users. In addition, per- form a deeper analysis of the model\u2019s quality on different slices (subsets) of the data, aiming at detecting any unfair behaviors (such as vastly different accura-cies on different slices of the data) or unwanted biases. Proceed to the final step only if the model passes these evaluation criteria. \n11. Optimize and deploy the model. Perform model optimization in order to shrink its size and boost its inference speed. Then deploy the model into the serving envi- ronment, such as a web page, a mobile app, or an HTTP service endpoint (sec- tion 12.3). \nReview of models and layer types in TF js_ \nDensely connected networks and multilayer perceptrons: Such networks are specialized for unordered vector data (for example, the numeric features in the phishing-website-detection problem and the housing- price-prediction problem). Each dense layer attempts to model the relation between all possible pairs of input features and the layer\u2019s output activations. This is achieved through a matrix multiplication between the dense layer\u2019s kernel and the input vector. MLPs are most commonly used for categorical data. \nConvolutional Network: Convolutional layers look at local spatial patterns by applying the same geometric transformation to different spatial locations (patches) in an input tensor. \nRecurrent Neural Network: RNNs work by processing sequences of inputs one timestamp at a time and maintain- ing a state throughout. A state is typically a vector or a set of vectors (a point in a geo- metric space). RNNs should be used preferentially over 1D convnets in the case of sequences in which the patterns of interest are not temporally invariant (for instance, time-series data in which the recent past is more important than the distant past). \nThree RNN layer types are available in TensorFlow.js: simpleRNN, GRU, and LSTM. For most practical purposes, you should use either GRU or LSTM. LSTM is the more powerful of the two, but it is also computationally more expensive. You can think of GRU as a simpler and cheaper alternative to LSTM. \nSome pretrained model net: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8318863939481395
      ],
      "excerpt": "Possibilities Application of DL: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8270478798755899
      ],
      "excerpt": "\u2013 Predictive healthcare\u2014Mapping patient medical records to predicted treat- \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8857049364719191,
        0.9331278905943956
      ],
      "excerpt": "\u2013 Behavioral targeting\u2014Mapping a set of website attributes to a potential \nviewer\u2019s behavior on the website (including page views, clicks, and other \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8635239536867576,
        0.992745091382021,
        0.8447357552725345
      ],
      "excerpt": "product to predictions about how well the product will perform on the mar- \nket (sales and profits in different areas of the market) \n\uf0a1 Mapping image to vector \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8644476013248454
      ],
      "excerpt": "\u2013 Diet helper\u2014Mapping images of foods and dishes to predicted health effects (for example, calorie counts or allergy warnings) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9032792514117989,
        0.8014484276107248,
        0.9884601705719389,
        0.9857959086848144,
        0.8361608746193864,
        0.887520742748065
      ],
      "excerpt": "\uf0a1 Mapping time-series data to vector \n\u2013 Brain-computer interfaces\u2014Mapping electroencephalogram (EEG) signals to user intentions. \n\u2013 Behavioral targeting\u2014Mapping past history of product purchases (such as movie or book purchases) to probabilities of purchasing other products in the future \n\u2013 Prediction of earthquakes and aftershocks\u2014Mapping seismic instrument data sequences to the predicted likelihoods of earthquakes and ensuing after- shocks \n\uf0a1 Mapping text to vector \n\u2013 Email sorter\u2014Mapping email content to generic or user-defined labels (for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9822875313447035
      ],
      "excerpt": "\u2013 Speech-based medical triaging\u2014Mapping a patient\u2019s description of illness to the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8270478798755899
      ],
      "excerpt": "\uf0a1 Mapping text to text \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9200767675863118,
        0.9847703416532351
      ],
      "excerpt": "\u2013 Automated alt-text generation\u2014Given an image, generating a short snippet of text that captures the essence of the content \n\u2013 Mobility aids for the visually impaired\u2014Mapping images of interior or exterior surroundings to spoken guidance and warnings about potential mobility haz- ards (for example, locations of exits and obstacles) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9298007942611884
      ],
      "excerpt": "\u2013 Image-based 3D reconstruction\u2014Mapping ordinary images to images of the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9380070558829903,
        0.9810063992628267,
        0.9047706811978506,
        0.9320668441754936,
        0.9502250618247736
      ],
      "excerpt": "\uf0a1 Mapping image and time-series data to vector \n\u2013 Doctor\u2019s multimodal assistant\u2014Mapping a patient\u2019s medical image (such as an MRI) and history of vital signs (blood pressure, heart rate, and so on) to pre- dictions of treatment outcomes \n\uf0a1 Mapping image and text to text \n\u2013 Image-based question answering\u2014Mapping an image and a question related to \nit (for instance, an image of a used car and a question about its make and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Learning Deep Learn Using Tensorflow JS",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hieu2906090/deep-learning-in-js/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "(231) If, for instance, our training data and inference data are samples from different distributions, we say there is dataset skew.\n\n(232) Our ideal states that the samples are independent and identically distributed (IID).\n\n(233) Certainly if we know the size of the datasets (17,000 in this case), we can specify the window to be larger than the entire dataset, and we are all set.\n\n(234) The right approach here is to shuffle the entire dataset by using a windowSize >= the number of samples in the dataset.\n\n(235) Outliers are samples in our dataset that are very unusual and somehow do not belong to the underlying distribution.\n\n>![Type of missind data info box](./readme-imgs/type-of-missing-data.png)\n>![Type of missind data info box](./readme-imgs/type-of-missing-data-2.png)\n\n(237) Only if your missing data is MCAR are you completely safe to discard samples. () More sophisticated techniques involve building predictors for the missing features from the available features and using those.\n\n(239) A simple way to quickly look at the statistics of your dataset is to use a tool like Facets (<https://pair-code.github.io/facets/>).\n\n(240) In gen- eral, it\u2019s best to z-normalize (normalize the mean and standard deviation of) your data before training.\n\n(241) A good place to get started is the page on responsible AI practices at <https://ai.google/education/responsible-ai-practices>\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 03:47:16 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/js-data-learn/deep-learning-in-js/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "js-data-learn/deep-learning-in-js",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/hieu2906090/deep-learning-in-js/master/dljs-folder/iris/serve.sh",
      "https://raw.githubusercontent.com/hieu2906090/deep-learning-in-js/master/dljs-folder/iris/build-resources.sh",
      "https://raw.githubusercontent.com/hieu2906090/deep-learning-in-js/master/dljs-folder/visualize-convnet/main.sh",
      "https://raw.githubusercontent.com/hieu2906090/deep-learning-in-js/master/dljs-folder/cart-pole/serve.sh",
      "https://raw.githubusercontent.com/hieu2906090/deep-learning-in-js/master/dljs-folder/mnist-transfer-cnn/serve.sh",
      "https://raw.githubusercontent.com/hieu2906090/deep-learning-in-js/master/dljs-folder/mnist-transfer-cnn/build-resources.sh",
      "https://raw.githubusercontent.com/hieu2906090/deep-learning-in-js/master/dljs-folder/sentiment/serve.sh",
      "https://raw.githubusercontent.com/hieu2906090/deep-learning-in-js/master/dljs-folder/sentiment/build-resources.sh",
      "https://raw.githubusercontent.com/hieu2906090/deep-learning-in-js/master/dljs-folder/simple-object-detection/upload_model.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8460413165907612
      ],
      "excerpt": "(66) Because TensorFlow.js optimizes its computation by scheduling on the GPU, tensors might not always be accessible to the CPU. The calls to dataSync in listing 2.8 tell TensorFlow.js to finish computing the tensor and pull the value from the GPU into the CPU, so it can be printed out or otherwise shared with a non-TensorFlow operation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "name: 'attention' \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8646266716537603
      ],
      "excerpt": "(67) const dataMean = data.mean(0); -> Return mean along horizontal axis (mean of each col) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8149124156715745
      ],
      "excerpt": "\uf0a1 The batch size for training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.817157984539639
      ],
      "excerpt": "  for units of [10, 20, 50, 100, 200]: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8054973610841307
      ],
      "excerpt": "(166) Instead of holding concrete values, a symbolic tensor specifies only a shape and a dtype. A symbolic tensor can be thought of as a \u201cslot\u201d or a \u201cplace- holder,\u201d into which an actual tensor value may be inserted later, given that the tensor value has a compatible shape and dtype. (167) It is a \u201cblueprint\u201d for the shape and dtype of the actual tensor values that the model or layer object will output. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8699979387167155
      ],
      "excerpt": "NOTE: This will predict the output at layer (n) -> this will become the input of our model when using pretrained. In the layer declaration, remove first dim as this is the batch of training exams. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9005706289175454
      ],
      "excerpt": "const data = tf.data.csv( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8065094943406945
      ],
      "excerpt": "The second way to access data from a dataset is to execute a function on each example of the dataset using dataset.forEachAsync(f). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9068013504395142,
        0.8019924149478602
      ],
      "excerpt": "  auxModel.apply(input, {training: true}).gather([filterIndex], 3); \nHere, auxModel is an auxiliary model object created with the familiar tf.model() function. It has the same input as the original model but outputs the activation of a given convolutional layer. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "\uf0a1 Text summarization \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "name: 'attention' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8213380337316241
      ],
      "excerpt": "qValues = DQN.predict(observation) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/js-data-learn/deep-learning-in-js/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "JavaScript",
      "HTML",
      "Python",
      "Shell",
      "CSS"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "DEEP LEARNING IN TENSORFLOW JS EBOOK",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "deep-learning-in-js",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "js-data-learn",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/js-data-learn/deep-learning-in-js/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 03:47:16 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ibab/tensorflow-wavenet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-09-12T13:50:45Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-27T19:32:26Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9752866978988367
      ],
      "excerpt": "This is a TensorFlow implementation of the WaveNet generative neural \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9472697268699019
      ],
      "excerpt": "DeepMind blog post and paper for details). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9074680218171165
      ],
      "excerpt": "The network models the conditional probability to generate the next \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9936819427083871
      ],
      "excerpt": "The core of the network is constructed as a stack of <em>causal dilated layers</em>, each of which is a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9060536709920333,
        0.9390991618005047
      ],
      "excerpt": "The outputs of all layers are combined and extended back to the original number \nof channels by a series of dense postprocessing layers, followed by a softmax \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8055506044320377
      ],
      "excerpt": "The loss function is the cross-entropy between the output for each timestep and the input at the next timestep. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.870474604584953
      ],
      "excerpt": "In this repository, the network implementation can be found in <a href=\"./wavenet/model.py\">model.py</a>. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9721096012663376,
        0.9900777350445424,
        0.969074616286564
      ],
      "excerpt": "Global conditioning refers to modifying the model such that the id of a set of mutually-exclusive categories is specified during training and generation of .wav file. \nIn the case of the VCTK, this id is the integer id of the speaker, of which there are over a hundred. \nThis allows (indeed requires) that a speaker id be specified at time of generation to select which of the speakers it should mimic. For more details see the paper or source code. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8560015541703196,
        0.9943127779296458,
        0.9123358981333219
      ],
      "excerpt": "* It specifies the \nsize of the embedding vector that is looked up based on the id of the speaker. \nThe global conditioning logic in train.py and audio_reader.py is \"hard-wired\" to the VCTK corpus at the moment in that it expects to be able to determine the speaker id from the pattern of file naming used in VCTK, but can be easily be modified. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9144048435111831
      ],
      "excerpt": "generated by @jyegerlehner based on speaker 280 from the VCTK corpus. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8928736316529022,
        0.8630473331827399,
        0.8084274223406027
      ],
      "excerpt": "It uses the implementation from the Fast Wavenet repository. \nYou can follow the link for an explanation of how it works. \nThis reduces the time needed to generate samples to a few minutes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9834754706216701
      ],
      "excerpt": "--gc_channels=32 specifies 32 is the size of the embedding vector, and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.83920031163328,
        0.9700462945547682
      ],
      "excerpt": "--gc_cardinality=377 is required \nas 376 is the largest id of a speaker in the VCTK corpus. If some other corpus \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9794109933128932,
        0.8028384253147993,
        0.8906205778517882,
        0.8025669092753783
      ],
      "excerpt": "--gc_id=311 specifies the id of speaker, speaker 311, for which a sample is \nto be generated. \nCurrently there is no local conditioning on extra information which would allow \ncontext stacks or controlling what speech is generated. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A TensorFlow implementation of DeepMind's WaveNet paper",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ibab/tensorflow-wavenet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1289,
      "date": "Mon, 27 Dec 2021 20:29:55 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ibab/tensorflow-wavenet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ibab/tensorflow-wavenet",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ibab/tensorflow-wavenet/master/ci/test.sh",
      "https://raw.githubusercontent.com/ibab/tensorflow-wavenet/master/ci/install.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8566424483362889
      ],
      "excerpt": "--gc_cardinality=377 is required \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8339760374674506
      ],
      "excerpt": "<img src=\"images/network.png\" width=\"300\"></img> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503189345333785
      ],
      "excerpt": "python train.py --data_dir=corpus \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9355986061254542
      ],
      "excerpt": "python train.py --help \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8972617479604759
      ],
      "excerpt": "python train.py --data_dir=corpus --gc_channels=32 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8286520355160079
      ],
      "excerpt": "* It tells the train.py script that \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9129617675176488
      ],
      "excerpt": "Example output \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8282735602319446,
        0.9280185704370648
      ],
      "excerpt": "You can use the generate.py script to generate audio using a previously trained model. \npython generate.py --samples 16000 logdir/train/2017-02-13T16-45-34/model.ckpt-80000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9120585341026817
      ],
      "excerpt": "python generate.py --wav_out_path=generated.wav --samples 16000 logdir/train/2017-02-13T16-45-34/model.ckpt-80000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9120585341026817
      ],
      "excerpt": "python generate.py --wav_out_path=generated.wav --save_every 2000 --samples 16000 logdir/train/2017-02-13T16-45-34/model.ckpt-80000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9382957476159418
      ],
      "excerpt": "python generate.py --samples 16000 logdir/train/2017-02-13T16-45-34/model.ckpt-80000 --fast_generation=false \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.917155450939047
      ],
      "excerpt": "python generate.py --samples 16000  --wav_out_path speaker311.wav --gc_channels=32 --gc_cardinality=377 --gc_id=311 logdir/train/2017-02-13T16-45-34/model.ckpt-80000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8865986842193302
      ],
      "excerpt": "printed out by the train.py script at training time. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ibab/tensorflow-wavenet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License (MIT) Copyright (c) 2016 Igor Babuschkin\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of\\nthis software and associated documentation files (the \"Software\"), to deal in\\nthe Software without restriction, including without limitation the rights to\\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\\nof the Software, and to permit persons to whom the Software is furnished to do\\nso, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "A TensorFlow implementation of DeepMind's WaveNet paper",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "tensorflow-wavenet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ibab",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ibab/tensorflow-wavenet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "TensorFlow needs to be installed before running the training script.\nCode is tested on TensorFlow version 1.0.1 for Python 2.7 and Python 3.5.\n\nIn addition, [librosa](https://github.com/librosa/librosa) must be installed for reading and writing audio.\n\nTo install the required python packages, run\n```bash\npip install -r requirements.txt\n```\n\nFor GPU support, use\n```bash\npip install -r requirements_gpu.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Install the test requirements\n```\npip install -r requirements_test.txt\n```\n\nRun the test suite\n```\n./ci/test.sh\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5201,
      "date": "Mon, 27 Dec 2021 20:29:55 GMT"
    },
    "technique": "GitHub API"
  }
}
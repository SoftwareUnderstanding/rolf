{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2006.06873",
      "https://arxiv.org/abs/1905.09263",
      "https://arxiv.org/abs/2006.06873",
      "https://arxiv.org/abs/2010.05646",
      "https://arxiv.org/abs/1910.06711"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* [FastSpeech: Fast, Robust and Controllable Text to Speech](https://arxiv.org/abs/1905.09263)\n* [FastPitch: Parallel Text-to-speech with Pitch Prediction](https://arxiv.org/abs/2006.06873)\n* [HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis](https://arxiv.org/abs/2010.05646)\n* [MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis](https://arxiv.org/abs/1910.06711)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "Christian Sch\u00e4fer, github: cschaefer26 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/as-ideas/ForwardTacotron",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-03T12:33:51Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-18T08:36:54Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9821737259724125
      ],
      "excerpt": "we modified Tacotron (Fork from fatchord's WaveRNN) to generate speech in a single forward pass using a duration predictor to align text and generated mel spectrograms. Hence, we call the model ForwardTacotron (see Figure 1). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9682221934949715,
        0.9920878420224696,
        0.8374916460136924,
        0.9182180363929653
      ],
      "excerpt": "- Controllability: It is possible to control the speed of the generated utterance. \n- Efficiency: In contrast to FastSpeech and Tacotron, the model of ForwardTacotron \ndoes not use any attention. Hence, the required memory grows linearly with text size, which makes it possible to synthesize large articles at once. \nImplemented a modified FastPitch model as an alternative tts model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9175487196665042
      ],
      "excerpt": "Check out the pretrained FastPitch model in colab! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9804142594333648
      ],
      "excerpt": "The samples are generated with a model trained on LJSpeech and vocoded with WaveRNN, MelGAN, or HiFiGAN.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8035765301618735
      ],
      "excerpt": "Change the params in the config.yaml according to your needs and follow the steps below: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8113744161801809
      ],
      "excerpt": "(4) Generate Sentences with Griffin-Lim vocoder: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9243904610840094
      ],
      "excerpt": "For training the model on your own dataset just bring it to the LJSpeech-like format: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.929913495456988
      ],
      "excerpt": "For languages other than English, change the language and cleaners params in the hparams.py, e.g. for French: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8809410276642531
      ],
      "excerpt": "Our pre-trained LJSpeech model is compatible with the pre-trained vocoders: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9755369737074066
      ],
      "excerpt": "Here is a dummy example of exporting the model in TorchScript: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9021979543772933
      ],
      "excerpt": "For the necessary preprocessing steps (text to tokens) please refer to: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.923595160202603,
        0.9259292856377467,
        0.9809661096989204,
        0.8752973519663414
      ],
      "excerpt": "Sound quality of the models varies quite a bit, so it is important to cherry-pick the best one. \nFor cherry-picking it is useful to listen to the validation sound samples in tensorboard.  \nThe sound quality of the samples is measured by an additional metric (L1 distance of mel specs). \nThe top k models according to the above metric are constantly monitored and checkpointed under path/to/checkpoint/top_k_models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "\u23e9 Generating speech in a single forward pass without any attention!",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/as-ideas/ForwardTacotron/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 91,
      "date": "Tue, 28 Dec 2021 09:15:36 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/as-ideas/ForwardTacotron/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "as-ideas/ForwardTacotron",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/as-ideas/ForwardTacotron/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/as-ideas/ForwardTacotron/master/notebooks/synthesize.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Make sure you have:\n\n* Python >= 3.6\n\nInstall espeak as phonemizer backend (for macOS use brew):\n```\nsudo apt-get install espeak\n```\n\nThen install the rest with pip:\n```\npip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.806346151826096
      ],
      "excerpt": "You can try out the latest pretrained model with the following notebook: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9040392588607754
      ],
      "excerpt": "  <img src=\"assets/model.png\" width=\"700\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8106463134975855
      ],
      "excerpt": "Check out the pretrained FastPitch model in colab! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8890818307099057
      ],
      "excerpt": "  <img src=\"assets/energy_tb.png\" width=\"700\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8198697680971225,
        0.8278121020599903,
        0.9246227682586091
      ],
      "excerpt": " python preprocess.py --path /path/to/ljspeech \n(2) Train Tacotron with: \npython train_tacotron.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091,
        0.8278121020599903,
        0.9246227682586091
      ],
      "excerpt": "python train_tacotron.py --force_align \n(3) Train ForwardTacotron with: \npython train_forward.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8189606045760597
      ],
      "excerpt": "To vocode the resulting .mel or .npy files use the inference.py script from the MelGAN or HiFiGAN repo and point to the model output folder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8869686573946546
      ],
      "excerpt": "  <img src=\"assets/tensorboard.png\" width=\"700\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8899646277706683
      ],
      "excerpt": "  <b>Figure 2:</b> Tensorboard example for training a ForwardTacotron model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8184353136239687
      ],
      "excerpt": "After downloading the models you can synthesize text using the pretrained models with \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8813394238276272
      ],
      "excerpt": "python gen_forward.py --input_text 'Hi there!' --checkpoint forward_step90k.pt wavernn --voc_checkpoint wave_step_575k.pt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.80857184265743
      ],
      "excerpt": "Here is a dummy example of exporting the model in TorchScript: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8900486270063179
      ],
      "excerpt": "from models.forward_tacotron import ForwardTacotron \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8890818307099057
      ],
      "excerpt": "  <img src=\"assets/tensorboard_wavernn.png\" width=\"700\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8899646277706683
      ],
      "excerpt": "  <b>Figure 3:</b> Tensorboard example for training a WaveRNN model. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/as-ideas/ForwardTacotron/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright (c) 2017 Keith Ito\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\nTHE SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "\u23e9 ForwardTacotron",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ForwardTacotron",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "as-ideas",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/as-ideas/ForwardTacotron/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 517,
      "date": "Tue, 28 Dec 2021 09:15:36 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "axelspringerai",
      "text-to-speech",
      "python",
      "pytorch",
      "tacotron",
      "tts",
      "forwardtacotron"
    ],
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1806.08804\r\n* SAGPool: http://proceedings.mlr.press/v97/lee19c.html\r\n* GAT: https://arxiv.org/abs/1710.10903\r\n* g-U-Nets: http://proceedings.mlr.press/v97/gao19a.html\r\n* GCN: https://arxiv.org/abs/1609.02907\r\n\r\n# Running GNN models:\r\nAfter simulating the dataset, you can run the GNN models by the following command:\r\n\r\n```bash\r\npython demo.py \r\n```\r\n\r\nThis file runs the GNN models above with the different training settings. You can tune general parameters such as the dataset, the number of views and the models included. You can also tune specific hyperparameters of models by running the files ```main_gat.py```, ```main_gcn.py```, ```main_gunet.py```, ```main_diffpool.py``` and ```main_sag.py```. These files contain methods for training the models and hyperparameters such as number of layers, learning rate and dimensions of specific layers. \r\n\r\n# Extracting the reproducibility scores\r\n\r\nAfter running the GNNs, the file ```extract_results.py``` extracts the weights of the learnt GNNs. Then, it computes the overlap scores with different combinations of settings such as views, training strategies, top biomarkers to be considered. The output file is a pandas dataframe containing reproducibility matrix of the GNNs used. This dataframe is saved as a pickle file.\r\n\r\n# Plotting the heatmaps of the reproducibility matrices\r\n\r\nAfter saving the dataframes with ```extract_results.py```, now you run the file ```plot_heatmaps.py``` to visualize the heatmaps of the reproducibility matrices. Note that the displayed plots contain heatmaps of 3 matrices:\r\n* Reproducibility matrix using the views average method.\r\n* Reproducibility matrix using the rank correlation method.\r\n* Overall reproducibility matrix.\r\n\r\n<p align=\"center\">\r\n  <img src=\"./fig2.png\">\r\n</p>\r\n\r\n# Related references\r\nIdentifying the best data-driven feature selection method for boosting reproducibility in classification tasks:\r\nGeorges, N., Mhiri, I., Rekik, I., & Alzheimer\u2019s Disease Neuroimaging Initiative: Identifying the best data-driven feature selection method for boosting reproducibility in classification tasks. \r\n[https://www.sciencedirect.com/science/article/pii/S0031320319304832] (2020",
      "https://arxiv.org/abs/1710.10903\r\n* g-U-Nets: http://proceedings.mlr.press/v97/gao19a.html\r\n* GCN: https://arxiv.org/abs/1609.02907\r\n\r\n# Running GNN models:\r\nAfter simulating the dataset, you can run the GNN models by the following command:\r\n\r\n```bash\r\npython demo.py \r\n```\r\n\r\nThis file runs the GNN models above with the different training settings. You can tune general parameters such as the dataset, the number of views and the models included. You can also tune specific hyperparameters of models by running the files ```main_gat.py```, ```main_gcn.py```, ```main_gunet.py```, ```main_diffpool.py``` and ```main_sag.py```. These files contain methods for training the models and hyperparameters such as number of layers, learning rate and dimensions of specific layers. \r\n\r\n# Extracting the reproducibility scores\r\n\r\nAfter running the GNNs, the file ```extract_results.py``` extracts the weights of the learnt GNNs. Then, it computes the overlap scores with different combinations of settings such as views, training strategies, top biomarkers to be considered. The output file is a pandas dataframe containing reproducibility matrix of the GNNs used. This dataframe is saved as a pickle file.\r\n\r\n# Plotting the heatmaps of the reproducibility matrices\r\n\r\nAfter saving the dataframes with ```extract_results.py```, now you run the file ```plot_heatmaps.py``` to visualize the heatmaps of the reproducibility matrices. Note that the displayed plots contain heatmaps of 3 matrices:\r\n* Reproducibility matrix using the views average method.\r\n* Reproducibility matrix using the rank correlation method.\r\n* Overall reproducibility matrix.\r\n\r\n<p align=\"center\">\r\n  <img src=\"./fig2.png\">\r\n</p>\r\n\r\n# Related references\r\nIdentifying the best data-driven feature selection method for boosting reproducibility in classification tasks:\r\nGeorges, N., Mhiri, I., Rekik, I., & Alzheimer\u2019s Disease Neuroimaging Initiative: Identifying the best data-driven feature selection method for boosting reproducibility in classification tasks. \r\n[https://www.sciencedirect.com/science/article/pii/S0031320319304832] (2020",
      "https://arxiv.org/abs/1609.02907\r\n\r\n# Running GNN models:\r\nAfter simulating the dataset, you can run the GNN models by the following command:\r\n\r\n```bash\r\npython demo.py \r\n```\r\n\r\nThis file runs the GNN models above with the different training settings. You can tune general parameters such as the dataset, the number of views and the models included. You can also tune specific hyperparameters of models by running the files ```main_gat.py```, ```main_gcn.py```, ```main_gunet.py```, ```main_diffpool.py``` and ```main_sag.py```. These files contain methods for training the models and hyperparameters such as number of layers, learning rate and dimensions of specific layers. \r\n\r\n# Extracting the reproducibility scores\r\n\r\nAfter running the GNNs, the file ```extract_results.py``` extracts the weights of the learnt GNNs. Then, it computes the overlap scores with different combinations of settings such as views, training strategies, top biomarkers to be considered. The output file is a pandas dataframe containing reproducibility matrix of the GNNs used. This dataframe is saved as a pickle file.\r\n\r\n# Plotting the heatmaps of the reproducibility matrices\r\n\r\nAfter saving the dataframes with ```extract_results.py```, now you run the file ```plot_heatmaps.py``` to visualize the heatmaps of the reproducibility matrices. Note that the displayed plots contain heatmaps of 3 matrices:\r\n* Reproducibility matrix using the views average method.\r\n* Reproducibility matrix using the rank correlation method.\r\n* Overall reproducibility matrix.\r\n\r\n<p align=\"center\">\r\n  <img src=\"./fig2.png\">\r\n</p>\r\n\r\n# Related references\r\nIdentifying the best data-driven feature selection method for boosting reproducibility in classification tasks:\r\nGeorges, N., Mhiri, I., Rekik, I., & Alzheimer\u2019s Disease Neuroimaging Initiative: Identifying the best data-driven feature selection method for boosting reproducibility in classification tasks. \r\n[https://www.sciencedirect.com/science/article/pii/S0031320319304832] (2020",
      "https://arxiv.org/abs/2109.02248\r\n\r\n\r\n# License\r\nOur code is released under MIT License (see LICENSE file for details"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nIf our code is useful for your work please cite our paper:\r\n\r\n```latex\r\nTo be uploaded soon.\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Identifying the best data-driven feature selection method for boosting reproducibility in classification tasks:\r\nGeorges, N., Mhiri, I., Rekik, I., & Alzheimer\u2019s Disease Neuroimaging Initiative: Identifying the best data-driven feature selection method for boosting reproducibility in classification tasks. \r\n[https://www.sciencedirect.com/science/article/pii/S0031320319304832] (2020)\r\n\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9886589891498987,
        0.9936901243506697
      ],
      "excerpt": "<sup>1</sup>BASIRA Lab, Faculty of Computer and Informatics, Istanbul Technical University, Istanbul, Turkey \n<sup>2</sup>School of Science and Engineering, Computing, University of Dundee, UK \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944484218006108,
        0.9474635993655147,
        0.9944484218006108,
        0.9856067409390947,
        0.9944484218006108
      ],
      "excerpt": "* DiffPool: https://arxiv.org/abs/1806.08804 \n* SAGPool: http://proceedings.mlr.press/v97/lee19c.html \n* GAT: https://arxiv.org/abs/1710.10903 \n* g-U-Nets: http://proceedings.mlr.press/v97/gao19a.html \n* GCN: https://arxiv.org/abs/1609.02907 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/basiralab/RG-Select",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-22T13:59:48Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-07T06:55:37Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8552334014059232,
        0.9879039204610567
      ],
      "excerpt": "RG-Select for GNN reproducibility assessment with datasets of multigraphs coded up in Python by Mohammed Amine Gharsallaoui. Please contact mohammedaminegh@gmail.com for further inquiries. Thanks. \nThis repository provides the official PyTorch implementation of the following paper: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9579830149947053
      ],
      "excerpt": "Investigating Reproducibility in Graph NeuralNetworks using Multigraph Data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8624958180179244,
        0.8742631903169785,
        0.9992324907201747,
        0.9994728812467116,
        0.9933918622647894
      ],
      "excerpt": "<sup>1</sup>BASIRA Lab, Faculty of Computer and Informatics, Istanbul Technical University, Istanbul, Turkey \n<sup>2</sup>School of Science and Engineering, Computing, University of Dundee, UK \nAbstract: Graph neural networks (GNNs) have witnessed an unprecedented proliferation in tackling several problems in computer vision, computer-aided diagnosis and related fields. While prior studies have focused on boosting the model accuracy, quantifying the reproducibility of the most discriminative features identified by GNNs is still an intact problem that yields concerns about their reliability in clinical applications in particular. Specifically, the reproducibility of biological markers across clinical datasets and distribution shifts across classes (e.g., healthy and disordered brains) is of paramount importance in revealing the underpinning mechanisms of diseases as well as propelling the development of personalized treatment. Motivated by these issues, we propose, for the first time, reproducibility-based GNN selection (RG-Select), a framework for GNN reproducibility assessment via the quantification of the most discriminative features (i.e., biomarkers) shared between different models. To ascertain the soundness of our framework, the reproducibility assessment embraces variations of different factors such as training strategies and data perturbations. Despite these challenges, our framework successfully yielded replicable conclusions across different training strategies and various clinical datasets. Our findings could thus pave the way for the development of biomarker trustworthiness and reliability assessment methods for computer-aided diagnosis and prognosis tasks. RG-Select code is available on GitHub at https://github.com/basiralab/RG-Select. \nThis work is published in Neural Networks. Based on graph topology, RG-Select is a framework that evaluates the reproducibility of graph neural networks (GNNs). Our framework investigates the reproducibility using the learnt GNN weights. Studying the commonalities of the most discriminative biomarkers across GNN, RG-select assigns a reproducibility score for each model while incorporating the variations of many factors such as training strategies, edges (e.g., brain connectivity measures) and the number of top biomarkers to be selected. We have evaluated our model using cross-validation and few-shot approach with small- and large-scale datasets. In this repository, we release the code for the reproducibility evaluation for simulated vectors representing the learnt weights respective to different GNNs. \nWe provide a demo code for the usage of RG-Select for GNN reproducibility assessment with datasets of multigraphs. In simulate_data.py, we generate datasets of mutigraphs. The hyperparameters of multigraphs (e.g., number of nodes and number of views) can be varied by the user. In addition, the user can vary the distribution properties of the generated populations of graphs.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9571281406540143,
        0.9635070706906114
      ],
      "excerpt": "* the standard deviations of populations of the two classes. \n* the means of populations of the two classes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.927188780727345
      ],
      "excerpt": "After running the GNNs, the file extract_results.py extracts the weights of the learnt GNNs. Then, it computes the overlap scores with different combinations of settings such as views, training strategies, top biomarkers to be considered. The output file is a pandas dataframe containing reproducibility matrix of the GNNs used. This dataframe is saved as a pickle file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8559103698008971,
        0.8998162371741371
      ],
      "excerpt": "* Reproducibility matrix using the views average method. \n* Reproducibility matrix using the rank correlation method. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Quantifying the Reproducibility of Graph Neural Networks using Multigraph Brain Data",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/basiralab/RG-Select/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 18:28:48 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/basiralab/RG-Select/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "basiralab/RG-Select",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nThe code has been tested with Python 3, PyTorch 1.7.1 on Windows. GPU is not required to run the code. You also need other dependencies (e.g., numpy, pandas, matplotlib, seaborn) which can be installed via: \r\n\r\n```sh\r\n$ pip install numpy\r\n$ pip install torch\r\n$ pip install pandas\r\n$ pip install scikit-learn\r\n$ pip install matplotlib\r\n$ pip install seaborn\r\n```\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8591879853065795
      ],
      "excerpt": "You can generate the simulated data with the following command: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8836704212480256
      ],
      "excerpt": "  <img src=\"fig1.PNG\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python simulate_data.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8836704212480256
      ],
      "excerpt": "  <img src=\"./fig2.png\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/basiralab/RG-Select/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "RG-Select",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "RG-Select",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "basiralab",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/basiralab/RG-Select/blob/main/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "After simulating the dataset, you can run the GNN models by the following command:\r\n\r\n```bash\r\npython demo.py \r\n```\r\n\r\nThis file runs the GNN models above with the different training settings. You can tune general parameters such as the dataset, the number of views and the models included. You can also tune specific hyperparameters of models by running the files ```main_gat.py```, ```main_gcn.py```, ```main_gunet.py```, ```main_diffpool.py``` and ```main_sag.py```. These files contain methods for training the models and hyperparameters such as number of layers, learning rate and dimensions of specific layers. \r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 26 Dec 2021 18:28:48 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "reproducible-research",
      "reproducibility",
      "reproducible-science",
      "graph-neural-networks",
      "multigraph",
      "classification",
      "deep-learning",
      "brain-connectivity"
    ],
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Video presentation for this project: https://www.youtube.com/watch?v=B24XlEfF-u4\n\n- Darkflow library (Darknet translated to TensorFlow) https://github.com/thtrieu/darkflow\n- Darknet framework https://github.com/pjreddie/darknet\n- Darknet project site:  https://pjreddie.com/darknet/yolo/ . Use to download configuration and pretrained weights files.\n- Jay, M. Series of YOLO tutorials: https://www.youtube.com/watch?v=PyjBd7IDYZs&list=PLX-LrBk6h3wSGvuTnxB2Kj358XfctL4BM&index=1 and \nhttps://github.com/markjay4k/YOLO-series \n- Instructions for setting up YOLO using Anaconda and Windows https://expschoolwork.blogspot.com/2018/11/using-yolo-in-anaconda.html\n- Redmon, J., Divvala, S., Girshick, R., Farhadi, A. (2015). You Only Look Once: unified, real-time object detection. Retrieved from:  https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf\n- Redmon, J., Farhadi, A. (2016). YOLO9 000: Better, Faster, Stronger. Retrieved from https://arxiv.org/pdf/1612.08242v1.pdf\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nweakly/MSDSProject-II",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-23T19:31:40Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-09T03:38:04Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9816770545609532,
        0.965593319548706,
        0.9929754199905934,
        0.9872322272480462
      ],
      "excerpt": "The goal of this project is to conduct a feasibility study of applying deep learning techniques for detecting objects in the video recordings of the home security systems, such as the Ring doorbell, in order to be able to eventually build a customizable home security system. There are many potential scenarios where a custom-tuned home security system could be useful, for example, to notify homeowners that their mail and packages have been delivered, to combat so-called \u201cporch pirates\u201d, to detect undesirable activity nearby (e.g., people displaying guns) or to let parents know that their children safely returned home after taking their family dog for a walk.  \nThe Ring doorbell records video clips when detecting motion within a predetermined perimeter. However, this motion sensor can be triggered not only by humans walking up to the door, but by wild and domestic animals, passing vehicles, etc. So, the first step of this project is using an algorithm capable of processing video feed in real (or near real) time to identify and classify objects, and then training the model to identify additional context-dependent objects in the video recordings (video feed). \nFor a more detailed explanation of the project please watch the video presentation https://www.youtube.com/watch?v=B24XlEfF-u4 . It contains a description of the project, some practical suggestions and lessons learned while working on this project. \nFor this project, I assembled custom training and testing datasets using the following tools and data sources: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8967323194963777
      ],
      "excerpt": "- additional training pictures of a crowbar were taken by the author of the project;  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8560813400158055
      ],
      "excerpt": "- additional data augmentation techniques were randomly applied to the training data set (rotation, flipping, scaling, translation, color saturation changes, and cropping) using Photoshop batch processing.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693595135064157
      ],
      "excerpt": "Since the detection speed is a very important factor in processing security videos, among all available CNN approaches  I chose to use a one-stage detector model, namely the YOLO (\"You Only look Once\") model originally introduced in 2015 in the paper written by Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi.  The updated YOLOv2 algorithm was translated to Tensorflow by Trieu H. Trinh and is available as an open source darkflow package (https://github.com/thtrieu/darkflow).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9874093515511969,
        0.9482372463305114
      ],
      "excerpt": "Applied to the videos (please see mp4 files in Data/Processed folder),  the YOLOv2 and its smaller modification YOLOv2 tiny showed good detection results for large objects in both normal and low light conditions as long as there is an unobstructed view of an object.   I was also able to reach 25-26 frames per second while processing videos on GeForce GTX1050  and above 34 frames per second on GPU GeForce RTX 2070 for the full YOLOv2 (74 frames per seconds for YOLOv2-tiny), all of which are higher than 15 per second used in the Ring video recordings and is sufficient to process real-time surveyance video. \nYOLOv2  and YOLOv2-tiny are very fast models capable of processing real-time video stream and providing reliable detection results for large objects with an unobstructed view; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8257590990894219,
        0.9693233063950834,
        0.8573846994859025
      ],
      "excerpt": "It is possible to create custom -built object detection systems for video surveillance using the YOLOv2 model and its tiny modification as demonstrated by the Ring example; \nThe loss function is an important training indicator, but a lower loss does not necessarily guarantee a better model.  When training on a dataset of images scraped from Google image search, I reached the lowest moving average loss of all my model - 0.5441. However, the model had a very low recall. Training on a dataset of still images extracted from the Ring videos resulted in a moving average loss of 0.6824, however, the model had a high false positive rate. It was incorrectly identifying crowbars where they were previously present in training images, clearly picking up on some other features.  When training on a more balanced set, the moving average loss was fluctuating between 0.9 and 1.01 and not decreasing any further.  This model turned out to provide better detection results.  \nHowever, increasing accuracy would require a more thorough training process and better training dataset (training exclusively on images collected from the internet resulted in prediction confidence of only 2-5%; using many still images extracted from the Ring videos resulted in an overfitted model which was \"detecting\" non-existing crowbars in the locations previously seen on training photos and not detecting objects in the previously unseen locations; combining training sets yielded the best results); \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Object Detection in the Home Video Security Systems",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nweakly/MSDSProject-II/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 23:19:36 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/nweakly/MSDSProject-II/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "nweakly/MSDSProject-II",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/nweakly/MSDSProject-II/master/YOLO_Model_Test.ipynb",
      "https://raw.githubusercontent.com/nweakly/MSDSProject-II/master/DataCollection.ipynb",
      "https://raw.githubusercontent.com/nweakly/MSDSProject-II/master/Preprocessing_Test_Video.ipynb",
      "https://raw.githubusercontent.com/nweakly/MSDSProject-II/master/DataPreprocessing.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Next, I used the transfer learning approach, or a technique when a machine learning model trained to complete one task is repurposed to accomplished a different related task.  Due to the resource limitations, I chose a modification of the YOLOv2 model called YOLOv2-tiny as the pre-trained basis and changed its last two layers in order to train a new model on a custom dataset of crowbar pictures.\nThis required adjustments to the copy of .cfg file created for the new model (keep the original cfg file intact):\n- in the last  [region] layer set the number of layers the model is  training for to 1:\n\n```\n[region]\nanchors = 1.08,1.19,  3.42,4.41,  6.63,11.38,  9.42,5.11,  16.62,10.52\nbias_match=1\nclasses=1\ncoords=4\nnum=5\nsoftmax=1\n```\n\n- in the second to last [convolutional] layer, set the number of filters to 30 (num*(number of classes+5)=5*(1+5)=30:\n\n```\n\n[convolutional]\nsize=1\nstride=1\npad=1\nfilters=30\nactivation=linear\n\n[region]\nanchors = 1.08,1.19,  3.42,4.41,  6.63,11.38,  9.42,5.11,  16.62,10.52\n\n```\n\n- change the labels.txt file (saved in the darkflow master directory) to reflect the only class we are training for:\n\n```\ncrowbar\n```\n\nNext, train the new model by using the following command and referencing the new cfg file, the weights file for the pretrained model and folders for the training images and corresponding annotations:\n\n```\npython flow  -- model cfg/yolov2-tiny-1c-4.cfg  --load bin/yolov2-tiny.weights --train --annotations new-model/annotations --dataset new_model/new_data --gpu 1.0\n```\nnote: --gpu 1.0 parameter means that the training will be conducted 100% on GPU \n\nAfter training is complete, it is useful to save the graph and weights to protobuf file (.pb):\n\n```\npython flow  --model cfg/yolov2-tiny-1c-4.cfg  --load bin/yolov2-tiny.weights  --savepb\n```\nThis command will generate .pb and .meta files that contain all the information necessary to make predictions using the newly trained model( using --pbLoad and --metaLoad instead of the --model and --load parameters in the demo example above).\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8096682767276875
      ],
      "excerpt": "- Annotating_images.py and Drawing_Boxes.py scripts were used to manually draw bounding boxes around crowbars (to train a custom model) and create xml files with image annotations;  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8652995101997221
      ],
      "excerpt": "python flow --model cfg/yolov2.cfg --load bin/yolov2.weights --demo videofile.avi  --gpu 1.0 --saveVideo \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/nweakly/MSDSProject-II/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Natalia Weakly\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Object Detection in the Home Video Security Systems",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "MSDSProject-II",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "nweakly",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nweakly/MSDSProject-II/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Anaconda package (64-bit version) on Windows 10\n- Python 3.5 or higher\n- TensorFlow (GPU version preferred)\n- OpenCV\n- Cython extensions - Python to C compiler and wrapper to be able to call DarkNet C code from Python\n- Jupyter Notebook\n- DarkNet framework - original implementation of the YOLO algorithm written in C and CUDA by Joseph Redmon https://github.com/pjreddie/darknet\n- Darkflow - package translating Darknet to TensorFlow\n- cfg (configuration) and weights files for the YOLO model downloaded from https://pjreddie.com/darknet/yolo/\n- highly recommended - a separate conda virtual environment (to resolve version conflicts for the deep learning libraries) and use Anaconda for installations\n- GPU GeForce RTX 2070 used during model training process, GeForce GTX1050 for all other file processing.\n\nFor detailed installation instructions please refere to a post by Abhijeet Kumar (https://appliedmachinelearning.blog/2018/05/27/running-yolo-v2-for-real-time-object-detection-on-videos-images-via-darkflow/ ) or https://expschoolwork.blogspot.com/2018/11/using-yolo-in-anaconda.html .\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 23:19:36 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Finally,  I used the newly trained model on previously unseen still images and videos.  Several images from the same folder can be forwarded for predictions at the same time using the following command:\n\n```\npython flow --imgdir new_model/test_pics  --pbLoad built_graph/yolov2-tiny-1c-4.pb --metaLoad built_graph/yolov2-tiny-1c-4.meta  --gpu 1.0 \n```\n\nNotes: \n- by default, the output images with bounding boxes are saved in a new subfolder out in the same folder ( new_model/test_pics/out );\n- add --json if you would like to generate output json files with the pixel location for each bounding box.\n\nI also tested the model on the videos containing crowbars with some neutral backgrounds and video files from the Ring doorbell.  \n```\npython flow  --pbLoad built_graph/yolov2-tiny-1c-4.pb --metaLoad built_graph/yolov2-tiny-1c-4.meta  --demo new_model/test_video/IMG_0851.MOV --threshold 0.67 --gpu 1.0 --saveVideo\n```\n\nPlease see examples of the results in  https://github.com/nweakly/MSDSProject-II/tree/master/new_model/test_video and  https://github.com/nweakly/MSDSProject-II/tree/master/new_model/test_ring_video . \n\nNote: darkflow also allows using information about different checkpoints generated during training to produce predictions. In many cases it is useful to compare results at the different stages, however, checkpoint files are not included in this repository due to space restrictions.\n\n",
      "technique": "Header extraction"
    }
  ]
}
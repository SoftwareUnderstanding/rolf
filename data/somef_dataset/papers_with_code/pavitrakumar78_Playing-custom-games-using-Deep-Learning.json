{
  "citation": [
    {
      "confidence": [
        0.9976821089163788
      ],
      "excerpt": "Paper Link: http://arxiv.org/abs/1312.5602 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9105368110547479
      ],
      "excerpt": "[4] Lasagne:        https://github.com/Lasagne/Lasagne \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pavitrakumar78/Playing-custom-games-using-Deep-Learning",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-05-11T14:02:24Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-02-28T17:48:22Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9835749341037406
      ],
      "excerpt": "Implementation of Google's paper on playing atari games using deep learning in python. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977976999050051
      ],
      "excerpt": "This project presents an implementation of a model (based on the above linked paper) that successfully learns control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. This model is tested on variety of Atari and custom made games and its performance is compared with human players. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.978027802044922,
        0.8031947244803442,
        0.988790249753922
      ],
      "excerpt": "pygame (for flappy bird and shooter) \nGPU with CC score of greater than or equal to 3 (refer http://deeplearning.net/software/theano/library/tensor/nnet/conv.html and https://developer.nvidia.com/cuda-gpus) \nThe model is trained for 2 Atari games - Space Invaders and Breakout. The model was trained for about 12-13 hrs and has achieved  good performace that is consistent with the paper.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9964665043365224
      ],
      "excerpt": "I have trained a plain vanilla Q learning (based on http://sarvagyavaish.github.io/FlappyBirdRL/) based agent where the agent gets information such as the x and y distance from the pipes to compare the performance of this game-specific model to a generalized model as described in the Google's paper. Training time is about 2-3 hrs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9898307409885386
      ],
      "excerpt": "Similar to the Atari games, I have trained the same model with minor only minor modificaions to the parameters to play Flappy Bird - although the performance is not as good as the Q learning mode which had explicit game data - it still gets a decent average score of about 20-30. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9926341390704798,
        0.8032487280584143
      ],
      "excerpt": "This is a very simple game I made using pygame where the player controls a  \"spaceship\" is tasked to dodge the incomming \"meteoroids\" and stay alive as long as possible. I also tried an (silly?) experiment where I trained different models wherein each model had agents with different degrees of control over the space ship and compared the performance of the same. \nTo run the agent with just 2 control setting (left and right):   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.800415154524015
      ],
      "excerpt": "To run the agent with just 8 control setting (all directions):   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9671834520041785,
        0.937599189931897
      ],
      "excerpt": "For all the below graphs, the X axis is the traning timeline and the Y axis the score funtion for each game. \n(Note: scores in Shooter anf flappy bird have been modified (reward amplified) because the original +1 or -1 is not applicable since the player does not have \"lives\" here and rewards are also very sparse in the these 2 games.)   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9254751311447194
      ],
      "excerpt": "Atari Space Invaders: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9254751311447194
      ],
      "excerpt": "Atari Space Invaders: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9855341014352333,
        0.9558043407935296
      ],
      "excerpt": "Number of epochs and train cycles has been adjusted such that all the above code when used for traning takes only about 12-15 hrs max. depending on your CPU and GPU (My CPU: i5 3.4 GHz and GPU: nVidia GeForce 660). Also, do not expect super human level performance (as said in Google's paper) from the models as I have trained it only for 12-15 hrs - more traning with further parameter tuning can improve the scores of all the above games. \nThe deep Q network used in this project is a modified version of spragunr's dqn code (https://github.com/spragunr/deep_q_rl). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation of Google's paper on playing atari games using deep learning in python.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pavitrakumar78/Playing-custom-games-using-Deep-Learning/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Wed, 22 Dec 2021 00:32:08 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/pavitrakumar78/Playing-custom-games-using-Deep-Learning/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "pavitrakumar78/Playing-custom-games-using-Deep-Learning",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "Python 2.7 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8918974083095406
      ],
      "excerpt": "[4] Lasagne:        https://github.com/Lasagne/Lasagne \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9616489437187804
      ],
      "excerpt": "[6] CUDA:       https://developer.nvidia.com/cudnn \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9041855898597737,
        0.9041855898597737
      ],
      "excerpt": "python AtariGame-Breakout/tester.py --rom_file breakout.bin --play_games 10 --display_screen --load_weights breakout_models/dep-q-rmsprop-breakout99-epoch.pkl \npython AtariGame-SpaceInvaders/tester.py --rom_file space_invaders.bin --play_games 10 --display_screen --load_weights spaceinvaders_models/dep-q-rmsprop-space_invaders99-epoch.pkl \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python FlappyQ/run_qvflappy.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9012080009866169
      ],
      "excerpt": "python FlappyBirdDQN/ftester.py --play_games 10 --display_screen --load_weights flappy_models/dep-q-flappy-60-epoch.pkl \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9012080009866169
      ],
      "excerpt": "python ShooterDQN/stester2.py --play_games 10 --display_screen --load_weights shooter_models/dep-q-shooter-nipscuda-8movectrl-99-epoch.pkl   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9012080009866169
      ],
      "excerpt": "python ShooterDQN/stester4.py --play_games 10 --display_screen --load_weights shooter_models/dep-q-shooter-nipscuda-4movectrl-99-epoch.pkl   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9091685980182701
      ],
      "excerpt": "python ShooterDQN/stester8.py --play_games 10 --display_screen --load_weights shooter_models/dep-q-shooter-nipscuda-2movectrl-80-epoch.pkl \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/pavitrakumar78/Playing-custom-games-using-Deep-Learning/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Playing custom games using Deep Learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Playing-custom-games-using-Deep-Learning",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "pavitrakumar78",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pavitrakumar78/Playing-custom-games-using-Deep-Learning/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 25,
      "date": "Wed, 22 Dec 2021 00:32:08 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "atari-games",
      "custom-game",
      "reinforcement-learning",
      "dqn"
    ],
    "technique": "GitHub API"
  }
}
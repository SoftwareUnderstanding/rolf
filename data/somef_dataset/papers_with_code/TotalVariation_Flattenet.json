{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The code has been largely taken from [HRNet-Semantic-Segmentation ](https://github.com/HRNet/HRNet-Semantic-Segmentation/tree/pytorch-v1.1).\n\nOther References:\n\n[PyTorch-Encoding](https://github.com/zhanghang1989/PyTorch-Encoding)\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1812.01187"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9897575745217783
      ],
      "excerpt": "I sincerely hope this work or code would be helpful for your research. If you  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TotalVariation/Flattenet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-01-31T16:48:29Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-19T13:23:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This is a partially official pytorch implementation accompanying the publication \n[Flattenet: A Simple and Versatile Framework for Dense Pixelwise Prediction]( http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8932465&isnumber=8600701).\nThis code repo only contains the **semantic segmentation part**. It is worth noting that \na number of **modifications** have been made after the paper has been published in order to \nimprove the performance. We evaluate the adapted method on PASCAL-Context and PASCAL VOC 2012.\n\nTo deal with the reduced feature resolution problem, we introduce a novel Flattening Module \nwhich takes as input the coarse-grained feature maps (patch-wise visual descriptors) produced by \na Fully Convolutional Network (FCN) and then outputs dense pixel-wise visual descriptors. \nThe process described above is represented in the schematic diagram below. \nA FCN equipped with the Flattening Module, which we refer to as FlatteNet, can accomplish various \ndense prediction tasks in an effective and efficient manner. \n<p align=\"center\">\n<img src=\"figures/flattenmodule-1.png\" width=\"800\">\n</p>\n\nAn illustration of the structure of Flattening Module is displayed below. We have newly incorporated a context\naggregation component into the design, which is implemented as a pyramid pooling module or self-attention\nmodule.\n\n<p align=\"center\">\n<img src=\"figures/gconv-1.png\" width=\"100\">\n</p>\n\nThe overall architecture is displayed below.\n\n<p align=\"center\">\n  <img src=\"figures/flattenet-1.png\" width=\"200\">\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9084209541318548
      ],
      "excerpt": "All the models are trained on two NVIDIA GTX1080Ti GPUs with the official \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8691661791673625,
        0.9441485206938091
      ],
      "excerpt": "in the paper. \nThe weights of pretrained model are converted from  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9411407515794424
      ],
      "excerpt": "The models are evaluated using six scales of  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8612035936848151,
        0.9411407515794424
      ],
      "excerpt": "Note: The GFLOPs of self-attention block are not calculated. \nThe models are evaluated using six scales of  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9157770923709878
      ],
      "excerpt": "The input size is set to 512x512. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8612035936848151,
        0.8491806377981677
      ],
      "excerpt": "Note: The GFLOPs of self-attention block are not calculated. \nFor example, train FlatteNet on PASCAL-Context with a batch size of 8 on 2 GPUs: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9364330673572951
      ],
      "excerpt": "For example, evaluating our model on the PASCAL-Context validation set with multi-scale and flip testing: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.998067127318002
      ],
      "excerpt": "Despite the fact that the intention of this paper is to achieve my Master degree,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A pytorch implementation of Flattenet.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TotalVariation/Flattenet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 02:14:39 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/TotalVariation/Flattenet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "TotalVariation/Flattenet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Pytorch version: 1.3.1\n\nPlease refer to [HRNet-Semantic-Segmentation ](https://github.com/HRNet/HRNet-Semantic-Segmentation/tree/pytorch-v1.1)\nfor other details.\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8223365810912198
      ],
      "excerpt": "[0.5; 0.75; 1; 1.25; 1.5; 1.75] and flipping on the PASCAL VOC 2012 test set. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8242997747235125
      ],
      "excerpt": "| No | ResNet-101 | PPM | 83.09 | 49.7 | 45.4 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8113706188272007,
        0.8326843301341885
      ],
      "excerpt": "For example, train FlatteNet on PASCAL-Context with a batch size of 8 on 2 GPUs: \npython -m torch.distributed.launch --nproc_per_node=2 tools/train.py --cfg config/pctx_res101_att.yml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8949146110560525,
        0.8696420531298055
      ],
      "excerpt": "python tools/test.py --cfg  config/pctx_res101_att.yml \\ \n                     TEST.MODEL_FILE output/pascal_ctx/pctx_res101_att/best.pth \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/TotalVariation/Flattenet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/TotalVariation/Flattenet/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) [2019] [Microsoft]\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n\\n=======================================================================================\\n3-clause BSD licenses\\n=======================================================================================\\n1. syncbn - For details, see lib/models/syncbn/LICENSE\\n         Copyright (c) 2017 mapillary\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "FlatteNet :sweat_smile: :sweat_smile: :sweat_smile:",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Flattenet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "TotalVariation",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TotalVariation/Flattenet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Fri, 24 Dec 2021 02:14:39 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "semantic-segmentation",
      "pascal-context",
      "pascal-voc2012"
    ],
    "technique": "GitHub API"
  }
}
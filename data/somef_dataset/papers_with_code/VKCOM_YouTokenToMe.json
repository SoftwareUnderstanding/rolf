{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1910.13267"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "Key advantages: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9505751292525139
      ],
      "excerpt": "* BPE-dropout (as described in Provilkov et al, 2019) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/VKCOM/YouTokenToMe",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-06T11:38:28Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T08:19:20Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9060212875641537,
        0.9582040386406251
      ],
      "excerpt": "YouTokenToMe is an unsupervised text tokenizer focused on computational efficiency. It currently implements fast Byte Pair Encoding (BPE) [Sennrich et al.]. \nOur implementation is much faster in training and tokenization than Hugging Face, fastBPE \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8710296557453907
      ],
      "excerpt": "  Check out our benchmark results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9291796620485059
      ],
      "excerpt": "The algorithm has  O(N) complexity, where N is the length of training data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9840027468648466
      ],
      "excerpt": "that cross word boundaries. Just like in SentencePiece, all space symbols were replaced by meta symbol \"\u2581\" (U+2581). It allows sequences of tokens to be converted back to text and for word boundaries to be restored. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8997597339376304
      ],
      "excerpt": "Trains BPE model and saves to file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9423080213891576,
        0.8875942997474334
      ],
      "excerpt": "coverage: float, fraction of characters covered by the model. Must be in the range [0, 1]. A good value to use is about 0.9999. \nn_threads: int, number of parallel threads used to run. If -1 is passed, then all available threads are going to be used. Note that the number of threads is limited by 8 (see benchmark). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9632602154104352,
        0.9677151842967018,
        0.8455494779869406
      ],
      "excerpt": "bos_id: int, reserved id for begin of sentence token \neos_id: int, reserved id for end of sentence token \nReturns: Class youtokentome.BPE with the loaded model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "youtokentome.BPE(model, n_threads=-1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9596218028677687,
        0.8196888229282902
      ],
      "excerpt": "sentences: list of strings, sentences for tokenization. \noutput_type: enum, sentence can be tokenized to ids or subwords. Use OutputType.ID for ids and OutputType.SUBWORD for subwords. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8058964407383934,
        0.8541580512171464,
        0.9332989543203959
      ],
      "excerpt": "dropout_prob: float, BPE-dropout probability (the probability of a merge being dropped). Must be in the range [0, 1]. \nReturns: If output_type is equal to youtokentome.OutputType.ID or youtokentome.OutputType.SUBWORD  \n then a list of lists of integers or list of lists of strings will be returned \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": " to i-th subword. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731244103601121
      ],
      "excerpt": "Returns: int. Size of vocabulary. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9691790165416055
      ],
      "excerpt": "Convert each id to subword and concatenate with space symbol. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9482471256755157,
        0.8490690597079743,
        0.859727441717076
      ],
      "excerpt": "ids: list of lists of integers. All integers must be in the range [0, vocab_size-1] \nignore_ids: collection of integers. These indices would be ignored during the decoding. All integers must be in the range [0, vocab_size-1] [default: None] \nReturns: List of strings. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8488774965944276
      ],
      "excerpt": "  --help  Show this message and exit. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762,
        0.935043939647535
      ],
      "excerpt": "  decode  Decode ids to text. \n  encode  Encode text to ids or subwords. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9623343593008797
      ],
      "excerpt": "  --coverage FLOAT      Fraction of characters covered by the model.  [default: 1.0] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.805020898159536,
        0.8488774965944276
      ],
      "excerpt": "  --eos_id INTEGER      'End of sentence' token id.  [default: 3] \n  --help                Show this message and exit. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8507870580187753,
        0.8992423585146161
      ],
      "excerpt": "Apply BPE encoding for a corpus of sentences. Use stdin for input and stdout for output. \nBy default, encoding works in parallel using n_threads threads. Number of threads is limited by \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.935043939647535
      ],
      "excerpt": "Encode text to ids or subwords. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9481539697107289,
        0.9519599708277205
      ],
      "excerpt": "  --bos                Add tab 'begin of sentence'. \n  --eos                Add tab 'end of sentence'. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8164236433057428,
        0.8488774965944276
      ],
      "excerpt": "  --dropout_prob       BPE-dropout probability (the probability of a merge being dropped). [default: 0] \n  --help               Show this message and exit. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8488774965944276
      ],
      "excerpt": "  --help        Show this message and exit. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "Decode ids to text. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.89895885555939,
        0.8488774965944276
      ],
      "excerpt": "  --ignore_ids  List of indices to ignore for decoding. Example: --ignore_ids=1,2,3 \n  --help        Show this message and exit. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Unsupervised text tokenizer focused on computational efficiency",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/VKCOM/YouTokenToMe/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 61,
      "date": "Wed, 29 Dec 2021 22:41:44 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/VKCOM/YouTokenToMe/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "VKCOM/YouTokenToMe",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/VKCOM/YouTokenToMe/master/tests/speed_test/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\npip install youtokentome\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8014503249724706
      ],
      "excerpt": "Class youtokentome.BPE has the following methods: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421910132587719
      ],
      "excerpt": "YouTokenToMe supports the following commands: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9014548210977287
      ],
      "excerpt": "With the --stream option, --n_threads will be ignored and all sentences will be processed one by one. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731786263811625
      ],
      "excerpt": "  --output_type TEXT   'id' or 'subword'.  [required] \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8858003949231855,
        0.8000807279381997
      ],
      "excerpt": "youtokentome.BPE.train(data, model, vocab_size, coverage, n_threads=-1, pad_id=0, unk_id=1, bos_id=2, eos_id=3) \nTrains BPE model and saves to file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8938548275228733
      ],
      "excerpt": "data: string, path to file with training data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008799632903568
      ],
      "excerpt": "model: string, path to the trained model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8346683650051508
      ],
      "excerpt": "reverse: bool, if True the output sequence of tokens will be reversed \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8786829442168927
      ],
      "excerpt": "Usage: yttm [OPTIONS] COMMAND [ARGS]... \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8737873112808705,
        0.8190869369466598
      ],
      "excerpt": "  bpe     Train BPE model. \n  decode  Decode ids to text. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8833013677071059,
        0.8737873112808705
      ],
      "excerpt": "Usage: yttm bpe [OPTIONS] \nTrain BPE model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.824413554835027,
        0.8212415796092828
      ],
      "excerpt": "  --data PATH           Training data file path.  [required] \n  --model PATH          Output model file path.  [required] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8833013677071059
      ],
      "excerpt": "Usage: yttm encode [OPTIONS] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8833013677071059
      ],
      "excerpt": "Usage: yttm vocab [OPTIONS] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8108370442192434
      ],
      "excerpt": "Convert ids back to text. Use stdin for input and stdout for output. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8833013677071059,
        0.8190869369466598
      ],
      "excerpt": "Usage: yttm decode [OPTIONS] \nDecode ids to text. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/VKCOM/YouTokenToMe/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "C++",
      "Python",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Boost Software License - Version 1.0 - August 17th, 2003\\n\\nPermission is hereby granted, free of charge, to any person or organization\\nobtaining a copy of the software and accompanying documentation covered by\\nthis license (the \"Software\") to use, reproduce, display, distribute,\\nexecute, and transmit the Software, and to prepare derivative works of the\\nSoftware, and to permit third-parties to whom the Software is furnished to\\ndo so, all subject to the following:\\n\\nThe copyright notices in the Software and this entire statement, including\\nthe above license grant, this restriction and the following disclaimer,\\nmust be included in all copies of the Software, in whole or in part, and\\nall derivative works of the Software, unless such copies or derivative\\nworks are solely in the form of machine-executable object code generated by\\na source language processor.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT\\nSHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE\\nFOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,\\nARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\\nDEALINGS IN THE SOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "YouTokenToMe",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "YouTokenToMe",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "VKCOM",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/VKCOM/YouTokenToMe/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "yutkin",
        "body": "",
        "dateCreated": "2020-02-13T09:49:37Z",
        "datePublished": "2020-02-13T09:57:47Z",
        "html_url": "https://github.com/VKCOM/YouTokenToMe/releases/tag/v1.0.6",
        "name": "Memory usage improved",
        "tag_name": "v1.0.6",
        "tarball_url": "https://api.github.com/repos/VKCOM/YouTokenToMe/tarball/v1.0.6",
        "url": "https://api.github.com/repos/VKCOM/YouTokenToMe/releases/23636389",
        "zipball_url": "https://api.github.com/repos/VKCOM/YouTokenToMe/zipball/v1.0.6"
      },
      {
        "authorType": "User",
        "author_name": "yutkin",
        "body": "",
        "dateCreated": "2019-11-20T09:07:42Z",
        "datePublished": "2019-11-20T09:08:20Z",
        "html_url": "https://github.com/VKCOM/YouTokenToMe/releases/tag/v1.0.5",
        "name": "Fix failing builds from .tar.gz",
        "tag_name": "v1.0.5",
        "tarball_url": "https://api.github.com/repos/VKCOM/YouTokenToMe/tarball/v1.0.5",
        "url": "https://api.github.com/repos/VKCOM/YouTokenToMe/releases/21612342",
        "zipball_url": "https://api.github.com/repos/VKCOM/YouTokenToMe/zipball/v1.0.5"
      },
      {
        "authorType": "User",
        "author_name": "yutkin",
        "body": "* Add support of dropout in encoding\r\n\r\n* Add support of IDs ignoring for decoding\r\n\r\n* Fix unhandled exception on unknown `--output_type`",
        "dateCreated": "2019-11-19T18:07:20Z",
        "datePublished": "2019-11-19T18:08:13Z",
        "html_url": "https://github.com/VKCOM/YouTokenToMe/releases/tag/v1.0.4",
        "name": "Add dropout support",
        "tag_name": "v1.0.4",
        "tarball_url": "https://api.github.com/repos/VKCOM/YouTokenToMe/tarball/v1.0.4",
        "url": "https://api.github.com/repos/VKCOM/YouTokenToMe/releases/21594517",
        "zipball_url": "https://api.github.com/repos/VKCOM/YouTokenToMe/zipball/v1.0.4"
      },
      {
        "authorType": "User",
        "author_name": "yutkin",
        "body": "Fix https://github.com/VKCOM/YouTokenToMe/issues/33",
        "dateCreated": "2019-11-05T13:24:53Z",
        "datePublished": "2019-11-05T13:25:26Z",
        "html_url": "https://github.com/VKCOM/YouTokenToMe/releases/tag/v1.0.3",
        "name": "Fix macOS build",
        "tag_name": "v1.0.3",
        "tarball_url": "https://api.github.com/repos/VKCOM/YouTokenToMe/tarball/v1.0.3",
        "url": "https://api.github.com/repos/VKCOM/YouTokenToMe/releases/21222166",
        "zipball_url": "https://api.github.com/repos/VKCOM/YouTokenToMe/zipball/v1.0.3"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 781,
      "date": "Wed, 29 Dec 2021 22:41:44 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "natural-language-processing",
      "word-segmentation",
      "nlp",
      "bpe",
      "tokenization"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Let's start with a self-contained example. \n\n```python\nimport random\n\nimport youtokentome as yttm\n\ntrain_data_path = \"train_data.txt\"\nmodel_path = \"example.model\"\n\n#: Generating random file with training data\n#: 10000 lines with 100 characters in each line\nn_lines = 10000\nn_characters = 100\nwith open(train_data_path, \"w\") as fout:\n    for _ in range(n_lines):\n        print(\"\".join([random.choice(\"abcd \") for _ in range(n_characters)]), file=fout)\n\n#: Generating random text\ntest_text = \"\".join([random.choice(\"abcde \") for _ in range(100)])\n\n#: Training model\nyttm.BPE.train(data=train_data_path, vocab_size=5000, model=model_path)\n\n#: Loading model\nbpe = yttm.BPE(model=model_path)\n\n#: Two types of tokenization\nprint(bpe.encode([test_text], output_type=yttm.OutputType.ID))\nprint(bpe.encode([test_text], output_type=yttm.OutputType.SUBWORD))\n```\n\n&nbsp;\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\n$ yttm bpe --data TRAINING_DATA_FILE --model OUTPUT_MODEL_FILE --vocab_size 2000\n$ yttm encode --model OUTPUT_MODEL_FILE --output_type subword < TEST_DATA_FILE > ENCODED_DATA \n```\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1106.1813"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9694409041864287
      ],
      "excerpt": "- [PoisBinOrdNonNor](https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.5362) - Generation of a chosen number of count, binary, ordinal, and continuous random variables, with specified correlations and marginal properties. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/balima78/SyntheticData",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-26T10:28:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-26T19:11:24Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8485983670990223
      ],
      "excerpt": "a draft for a CRAN task view on Synthetic Data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9783676382192892,
        0.9822608188465223,
        0.9949380110596387,
        0.9132404056881354,
        0.9685023253520714,
        0.8943720421300143,
        0.9663572699163417
      ],
      "excerpt": "Testing and validating applications or data products requires the use of data that is not always available to us.  \nAs an alternative to real data, we have the possibility to generate fake or synthetic data in a format similar to real data. This task view collects information on R packages with functionalities to generate synthetic data. \n[Wikipedia](https://en.wikipedia.org/wiki/Synthetic_data) defines synthetic data as follows: Synthetic data is \"any production data applicable to a given situation that are not obtained by direct measurement\" according to the McGraw-Hill Dictionary of Scientific and Technical Terms; where Craig S. Mullins, an expert in data management, defines production data as \"information that is persistently stored and used by professionals to conduct business processes.\" \nBase **R** allow us to genetare data vectors according to different distributions  \nwith functions as: `rnorm`, `rexp`, `rpois`, `runif`, `rmultinom`, `sample`... This CRAN task view contains a list of packages that can be used to generate synthetic data. Also, several packages to deal with unbalanced data are listed. \nThe [rOpenSci Task View: Open Data](https://github.com/ropensci-archive/opendata#cran-task-view-open-data) repository provides information about using R to obtain, parse, manipulate, create, and share open data. Moreover the [WebTechnologies Task View](https://cran.r-project.org/web/views/WebTechnologies.html) addresses how to obtain and parse web-based data. Furthermore, a curated list of data packages can be found at [ropensci-archive/data-packages](https://github.com/ropensci-archive/data-packages).  \nThe development of this task view is fairly new and still in its early stages and therefore subject to changes. Suggestions for additions and extensions to the task view maintainer are welcomed. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9424461019791677,
        0.9876798888711875
      ],
      "excerpt": "- [conjurer](https://www.foyi.co.nz/posts/documentation/documentationconjurer/) -Builds synthetic data applicable across multiple domains. This package also provides flexibility to control data distribution to make it relevant to many industry examples as described in the [vignette](https://cran.r-project.org/web/packages/conjurer/vignettes/introduction_to_conjurer.html). \n- [datasynthR](https://github.com/jknowles/datasynthR) (not on CRAN) - Functions to procedurally generate synthetic data in R for testing and collaboration. Allows the user to generate data of known distributional properties with known correlation structures. This is useful for testing statistical model data, building functions to operate on very large datasets, or training others in using R! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9912825377913348,
        0.9473022832514127
      ],
      "excerpt": "- [fakeR](https://cran.r-project.org/web/packages/fakeR/vignettes/my-vignette.html) - Simulates Data from a Data Frame of Different Variable Types. The package contains the functions `simulate_dataset` and `simulate_dataset_ts` to simulate time-independent and time-dependent data. It randomly samples character and factor variables from contingency tables and numeric and ordered factors from a multivariate normal distribution. It currently supports the simulation of stationary and zero-inflated count time series. \n- [gendata](https://cran.r-project.org/web/packages/gendata/gendata.pdf) - Generate and Modify Synthetic Datasets. Set of functions to create datasets using a correlation matrix. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9485909803270414,
        0.8848054566672784,
        0.9227560451493343,
        0.977292180734102,
        0.9788931598552633,
        0.9771011459300304,
        0.9887976814730005,
        0.9374475104266083
      ],
      "excerpt": "- [OpenSDPsynthR](https://github.com/opensdp/OpenSDPsynthR) (not on CRAN) - Generate synthetic education data that is realistic for use by analysts across the education sector. Synthetic data should be able to be generated on-demand and responsive to inputs from the user. \n- [rstyles](https://cran.r-project.org/web/packages/rstyles/index.html) - Package allows to generate simulated datasets using algorithms that mimic different response styles to survey questions. \n- [sdglinkage](https://rdrr.io/cran/sdglinkage/) - Synthetic Data Generation for Linkage Methods Development. A tool for synthetic data generation that can be used for linkage method development, with elements of i) gold standard file with complete and accurate information and ii) linkage files that are corrupted as we often see in raw dataset. \n- [SimMultiCorrData](https://github.com/AFialkowski/SimMultiCorrData) - The goal of SimMultiCorrData is to generate continuous (normal or non-normal), binary, ordinal, and count (Poisson or Negative Binomial) variables with a specified correlation matrix. It can also produce a single continuous variable. This package can be used to simulate data sets that mimic real-world situations (i.e. clinical data sets, plasmodes, as in Vaughan et al., 2009). \n- [simPop](https://www.jstatsoft.org/article/view/v079i10) - Simulation of Complex Synthetic Data Information. Tools and methods to simulate populations for surveys based on auxiliary data. The tools include model-based methods, calibration and combinatorial optimization algorithms. \n- [simstudy](https://cran.r-project.org/web/packages/simstudy/vignettes/simstudy.html) - This package has a collection of functions that allow users to generate simulated data sets in order to explore modeling techniques or better understand data generating processes. \n- [synthpop](https://www.synthpop.org.uk/index.html) - This package for R allows users to create synthetic versions of confidential individual-level data for use by researchers interested in making inferences about the population that the data represent. It allows the synthesis process to be customised in many different ways according to the characteristics of the data being synthesised. \n- [MicSim](https://microsimulation.pub/articles/00105) - Performing Continuous-Time Microsimulation. This entry-level toolkit allows performing continuous-time microsimulation for a wide range of demographic applications. Given a initial population, mortality rates, divorce rates, marriage rates, education changes, etc. and their transition matrix can be defined and included for the simulation of future states of the population. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9798658095536948,
        0.9295624329102506,
        0.869543787421842
      ],
      "excerpt": "- [saeSim](https://wahani.github.io/saeSim/) - Tools for the simulation of data in the context of small area estimation. Combine all steps of your simulation - from data generation over drawing samples to model fitting - in one object. \n**Specific types of data** \n- [survsim](https://www.jstatsoft.org/article/view/v059i02) - Simulation of Simple and Complex Survival Data. Simulation of simple and complex survival data including recurrent and multiple events and competing risks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9912825377913348
      ],
      "excerpt": "- [fakeR](https://cran.r-project.org/web/packages/fakeR/vignettes/my-vignette.html) - Simulates Data from a Data Frame of Different Variable Types. The package contains the functions `simulate_dataset` and `simulate_dataset_ts` to simulate time-independent and time-dependent data. It randomly samples character and factor variables from contingency tables and numeric and ordered factors from a multivariate normal distribution. It currently supports the simulation of stationary and zero-inflated count time series. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9875181186786348,
        0.9854580854610897,
        0.8593447116621816,
        0.9452611100848461,
        0.9552673178722747
      ],
      "excerpt": "- [ebal](https://web.stanford.edu/~jhain/ebalancepage.html) - Entropy reweighting to create balanced samples. Implements entropy balancing, a data preprocessing procedure that allows users to reweight a dataset such that the covariate distributions in the reweighted data satisfy a set of user specified moment conditions. This can be useful to create balanced samples in observational studies with a binary treatment where the control group data can be reweighted to match the covariate moments in the treatment group. Entropy balancing can also be used to reweight a survey sample to known characteristics from a target population. \n- [imbalance](https://github.com/ncordon/imbalance) - Preprocessing Algorithms for Imbalanced DatasetsClass imbalance usually damages the performance of classifiers. This package provides a set of tools to work with imbalanced datasets: novel oversampling algorithms, filtering of instances and evaluation of synthetic instances. \n- [IRIC](https://github.com/shuzhiquan/IRIC) (not on CRAN) - An R library for binary imbalanced classification. Integrates a wide set of solutions for imbalanced binary classification. \n- [ROSE](https://journal.r-project.org/archive/2014/RJ-2014-008/index.html) - Random Over-Sampling Examples. Thi package provides functions to deal with binary classification problems in the presence of imbalanced classes. Synthetic balanced samples are generated according to ROSE (Menardi and Torelli, 2013). Functions that implement more traditional remedies to the class imbalance are also provided, as well as different metrics to evaluate a learner accuracy. These are estimated by holdout, bootstrap or cross-validation methods. \n- [smotefamily](https://cran.r-project.org/web/packages/smotefamily/smotefamily.pdf) - A Collection of Oversampling Techniques for Class Imbalance Problem Based on SMOTE. A collection of various oversampling techniques developed from SMOTE is provided. SMOTE is a oversampling technique which synthesizes a new minority instance between a pair of one minority instance and one of its K nearest neighbor. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8744938667915751
      ],
      "excerpt": "- [unbalanced](https://github.com/dalpozz/unbalanced) - Racing for Unbalanced Methods Selection. This R package implements some well-known techniques for unbalanced classification tasks and provides a racing strategy to adaptively select the best methods for a given dataset, classification algorithms and accuracy measure adopted. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9157027638295855,
        0.9467587787408688
      ],
      "excerpt": "- [GenOrd](https://rdrr.io/cran/GenOrd/#vignettes) - Simulation of Discrete Random Variables with Given Correlation Matrix and Marginal Distributions. A gaussian copula based procedure for generating samples from discrete random variables with prescribed correlation matrix and marginal distributions. \n- [fakir](https://thinkr-open.github.io/fakir/) (not on CRAN) - The goal of {fakir} is to provide fake datasets that can be used to teach R. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.997826676760437,
        0.9867630240864096
      ],
      "excerpt": "- [NestedCategBayesImpute](https://cran.r-project.org/web/packages/NestedCategBayesImpute/NestedCategBayesImpute.pdf) - Modeling, Imputing and Generating Synthetic Versions of Nested Categorical Data in the Presence of Impossible Combinations. This tool set provides a set of functions to fit the nested Dirichlet process mixture of products of multinomial distributions (NDPMPM) model for nested categorical household data in the presence of impossible combinations. It has direct applications in imputing missing values for and generating synthetic versions of nested household data. \n- [NHSRdatasets](https://cran.r-project.org/web/packages/NHSRdatasets/index.html) - Free United Kingdom National Health Service (NHS) and other healthcare, or population health-related data for education and training purposes. This package contains synthetic data based on real healthcare datasets, or cuts of open-licenced official data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9022187597399193,
        0.9411833594624,
        0.9725057985522592,
        0.9814803238566623,
        0.875375822777546
      ],
      "excerpt": "- [psychmeta](https://github.com/psychmeta/psychmeta) - This package provides tools for computing bare-bones and psychometric meta-analyses and for generating psychometric data for use in meta-analysis simulations. \n- [sgr](https://cran.r-project.org/web/packages/sgr/sgr.pdf) - Sample Generation by Replacement simulations. The package can be used to perform fake data analysis according to the sample generation by replacement approach. It includes functions for making simple inferences about discrete/ordinal fake data. The package allows to study the implications of fake data for empirical results. \n- [synthACS](http://cran.nexr.com/web/packages/synthACS/synthACS.pdf) - Synthetic Microdata and Spatial MicroSimulation Modeling for ACS Data. Provides access to curated American Community Survey (ACS) base tables. Builds synthetic micro-datasets at any user-specified geographic level with ten default attributes; and, conducts spatial microsimulation modeling (SMSM) via simulated annealing. \n- [SynthTools](https://github.com/RTIInternational/SynthTools) - Tools and Tests for Experiments with Partially Synthetic Data Sets. A set of functions to support experimentation in the utility of partially synthetic data sets. All functions compare an observed data set to one or a set of partially synthetic data sets derived from the observed data to (1) check that data sets have identical attributes, (2) calculate overall and specific variable perturbation rates, (3) check for potential logical inconsistencies, and (4) calculate confidence intervals and standard errors of desired variables in multiple imputed data sets. Confidence interval and standard error formulas have options for either synthetic data sets or multiple imputed data sets. \n- [wakefield](https://github.com/trinker/wakefield) - A package designed to quickly generate random data sets. The user passes `n` (number of rows) and predefined vectors to the `r_data_frame` function to produce a `dplyr::tbl_df` object. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9479767926938959
      ],
      "excerpt": "GitHub repository for this TaskView \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "a draft for a CRAN task view on Synthetic Data",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/balima78/SyntheticData/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 19:55:36 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/balima78/SyntheticData/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "balima78/SyntheticData",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8046549951343172
      ],
      "excerpt": "Version:    2021-05-09                                    \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/balima78/SyntheticData/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "HTML",
      "R"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Bruno Lima\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SyntheticData",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SyntheticData",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "balima78",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/balima78/SyntheticData/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 19:55:36 GMT"
    },
    "technique": "GitHub API"
  }
}
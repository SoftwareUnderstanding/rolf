{
  "citation": [
    {
      "confidence": [
        0.9826628511165726,
        0.8374695145293155,
        0.9944484218006108
      ],
      "excerpt": "RCNN: https://arxiv.org/pdf/1311.2524.pdf \nFastRCNN: https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf \nFasterRCNN: https://arxiv.org/pdf/1506.01497.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8028046190715625,
        0.9967889944387858
      ],
      "excerpt": "SSD: https://www.cs.unc.edu/~wliu/papers/ssd.pdf \nMaskRCNN: https://research.fb.com/wp-content/uploads/2017/08/maskrcnn.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8422862053358879
      ],
      "excerpt": "Edit pascal_label_map.pbtxt and put one class called \"person\" \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cftang0827/pedestrian-detection-ssdlite",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-09-03T07:50:52Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-20T13:11:09Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Use TensorFlow object detection API and MobileNet SSDLite model to train a pedestrian detector by using VOC 2007 + 2012 dataset",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cftang0827/pedestrian_detection_ssdlite/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 13,
      "date": "Wed, 29 Dec 2021 23:20:50 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/cftang0827/pedestrian-detection-ssdlite/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "cftang0827/pedestrian-detection-ssdlite",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/cftang0827/pedestrian_detection_ssdlite/master/train/train.sh",
      "https://raw.githubusercontent.com/cftang0827/pedestrian_detection_ssdlite/master/train/make_data_tf_record.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```pip install git+https://github.com/cftang0827/pedestrian_detection_ssdlite```\n\nAfter installation, you can use the API:\n```python\nimport cv2\nfrom pedestrian_detection_ssdlite import api\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('test_img/example.jpg')\nbbox_list = api.get_person_bbox(img, thr=0.6)\nprint(bbox_list)\n\nfor i in bbox_list:\n    cv2.rectangle(img, i[0], i[1], (125, 255, 51), thickness=2)\n\nplt.imshow(img[:, :, ::-1])\nplt.show()\n```\n\nand you will get the list of person bbox:\n```[[(267, 62), (343, 270)], [(201, 65), (255, 227)], [(187, 64), (228, 169)]]```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8764899801871157
      ],
      "excerpt": "To avoid dependencies issue, we switched tf version from 1.x.x to 2.x.x, and we use tensorflow.compat.v1 so we can still get the same way with tf 1.x.x \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.987920405542396
      ],
      "excerpt": "git clone https://github.com/tensorflow/models.git \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8185938136098632
      ],
      "excerpt": "Edit create_pascal_tf_record_only_person.py and modify to the version that extract only one class, I used \"person\" here for example \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8144627046987601
      ],
      "excerpt": "Make training and validation dataset to tfrecord format \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233234957817607,
        0.8227902444541284
      ],
      "excerpt": "Find the proper config file for your model and algorithm, put it into directory, I used ssdlite_mobilenet_v2_coco.config for example. You can find the config in models/research/object_detection/samples/configs/, and modify some part (training dataset path, pretrained model ckpt path) of config file to your custom dataset. \nUse ./train.sh and start train the model \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/cftang0827/pedestrian-detection-ssdlite/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 cftang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "pedestrian_detection_ssdlite",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pedestrian-detection-ssdlite",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "cftang0827",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cftang0827/pedestrian-detection-ssdlite/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 28,
      "date": "Wed, 29 Dec 2021 23:20:50 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "object-detection",
      "pedestrian-detection",
      "tensorflow",
      "tensorflow-object-detection-api"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```pip install git+https://github.com/cftang0827/pedestrian_detection_ssdlite```\n\nAfter installation, you can use the API:\n```python\nimport cv2\nfrom pedestrian_detection_ssdlite import api\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('test_img/example.jpg')\nbbox_list = api.get_person_bbox(img, thr=0.6)\nprint(bbox_list)\n\nfor i in bbox_list:\n    cv2.rectangle(img, i[0], i[1], (125, 255, 51), thickness=2)\n\nplt.imshow(img[:, :, ::-1])\nplt.show()\n```\n\nand you will get the list of person bbox:\n```[[(267, 62), (343, 270)], [(201, 65), (255, 227)], [(187, 64), (228, 169)]]```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Try `test.py`, and I also provided a simple interface for using model, if you don't want to know the detail, please just copy whole api directory to your project and follow the way in `test.py`, you will know how to use it.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. https://medium.com/@WuStangDan/step-by-step-tensorflow-object-detection-api-tutorial-part-1-selecting-a-model-a02b6aabe39e\n2. https://becominghuman.ai/tensorflow-object-detection-api-tutorial-training-and-evaluating-custom-object-detector-ed2594afcf73\n3. https://blog.techbridge.cc/2019/02/16/ssd-hand-detection-with-tensorflow-object-detection-api/\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2009.04968\n\n## Infer masked token with BERT\n\n### Description\n\nBERT's authors trained it in two tasks and one of them is **Masked Language Model** (MLM"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.999056863701977
      ],
      "excerpt": "Read article at https://arxiv.org/abs/2009.04968 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "Downloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 714M/714M [01:07<00:00, 10.7MB/s] \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DimasDMM/transformers",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-13T21:25:02Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-27T14:14:21Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The goal of this tasks consists of generating a text about a specific topic or situation. We used two models in this experiment: GPT-2 and a Transformer model.\n\nOn the one hand, despite GPT-2 was only trained to predict the next token in a sentence, it surprisingly learned basic competence in some tasks like translating between languages and answering questions. On the other hand, we implemented a basic Transformer encoder-decoder architecture to analyse whether it is able to generate a similar text to the training data.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "In Question-Answering tasks, the model receives a text and a question regarding to the text, and it should mark the beginning and end of the answer in the text.\n\nIn this case, it is necessary to fine-tune BERT. We will use XQuAD (Cross-lingual Question Answering Dataset) to fine-tune it, which consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set of SQuAD v1.1 together with their professional translations into 10 languages. Source: https://github.com/deepmind/xquad\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "BERT's authors trained it in two tasks and one of them is **Masked Language Model** (MLM). The task consists of mask some input tokens randomly, and then try to predict those random tokens. Hence, we do not need to pretrain BERT and we can directly test it.\n\nIn this repository, I have implemented **a basic script to infer the masked token** in a sentence.\n\nRead the BERT paper: https://arxiv.org/pdf/1810.04805.pdf\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8655024421887938
      ],
      "excerpt": "You can see the code execution step by step in the notebook Infer masked token with BERT. Additionally, the notebooks are available at Kaggle: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9135289640053814
      ],
      "excerpt": "Input text: This is a [MASK] model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "model 0.03972144424915314 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.866391939778773
      ],
      "excerpt": "You can see the code execution step by step in the notebook Question answering with BERT. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Bunch of experiments with Transformers, BERT and GPT-2. Experiments include question-answering and conditional text generation.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DimasDMM/transformers/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 11:20:57 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/DimasDMM/transformers/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "DimasDMM/transformers",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/DimasDMM/transformers/master/misc/dockerfiles/python/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/DimasDMM/transformers/master/notebooks/Question-answering-with-BERT.ipynb",
      "https://raw.githubusercontent.com/DimasDMM/transformers/master/notebooks/Infer-masked-token-with-BERT.ipynb",
      "https://raw.githubusercontent.com/DimasDMM/transformers/master/notebooks/Conditional-Text-Generation-with-Transformers.ipynb",
      "https://raw.githubusercontent.com/DimasDMM/transformers/master/notebooks/Conditional-Text-Generation-with-GPT-2.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/DimasDMM/transformers/master/manager.sh",
      "https://raw.githubusercontent.com/DimasDMM/transformers/master/misc/bin/environment-vars.sh",
      "https://raw.githubusercontent.com/DimasDMM/transformers/master/misc/bin/down.sh",
      "https://raw.githubusercontent.com/DimasDMM/transformers/master/misc/bin/python-container.sh",
      "https://raw.githubusercontent.com/DimasDMM/transformers/master/misc/bin/run.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.80256922138614,
        0.9760167858563285
      ],
      "excerpt": "- https://www.kaggle.com/dimasmunoz/infer-masked-token-with-bert \nNote: These commands have been tested in MacOS and Git Bash (Windows). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9024244133818035
      ],
      "excerpt": "sh manager.sh bert \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9024244133818035
      ],
      "excerpt": "$ sh manager.sh bert \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8126903595378137
      ],
      "excerpt": "Once the docker container is running, execute the BERT script as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8166370517598589,
        0.8392480892657456
      ],
      "excerpt": "Downloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 714M/714M [01:07<00:00, 10.7MB/s] \nInput text: This is a [MASK] model \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/DimasDMM/transformers/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Shell",
      "Python",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Experiments with Transformers\n\n> Read article at https://arxiv.org/abs/2009.04968\n\n## Infer masked token with BERT\n\n### Description\n\nBERT's authors trained it in two tasks and one of them is **Masked Language Model** (MLM). The task consists of mask some input tokens randomly, and then try to predict those random tokens. Hence, we do not need to pretrain BERT and we can directly test it.\n\nIn this repository, I have implemented **a basic script to infer the masked token** in a sentence.\n\nRead the BERT paper: https://arxiv.org/pdf/1810.04805.pdf\n\n### Code\n\nWith this repository, there are some commands in Bash to run the Python code in a Docker container. Anyway, you can find all the Python scripts at [./code](./code)\n\nYou can see the code execution step by step in the notebook [Infer masked token with BERT](./notebooks/Infer-masked-token-with-BERT.ipynb). Additionally, the notebooks are available at Kaggle:\n- https://www.kaggle.com/dimasmunoz/infer-masked-token-with-bert\n\n### Commands\n\n> Note: These commands have been tested in MacOS and Git Bash (Windows).\n\nYou can start/stop the docker container with these two commands:\n```sh\nsh manager.sh docker:run\nsh manager.sh docker:down\n```\n\nOnce the docker container is running, execute the BERT script as follows:\n```sh\nsh manager.sh bert\n```\n\nThen, it will display a prompt where you can write your sentences with a masked token. For example:\n```\n$ sh manager.sh bert\nDownloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 996k/996k [00:02<00:00, 485kB/s]\nDownloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:00<00:00, 176kB/s]\nDownloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 714M/714M [01:07<00:00, 10.7MB/s]\n\nInput text: This is a [MASK] model\n----------------------------------------\nmathematical 0.04100513085722923\nmodel 0.03972144424915314\nsingle 0.01666860282421112\nsimilar 0.014901496469974518\ncommon 0.01419056300073862",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "transformers",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "DimasDMM",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DimasDMM/transformers/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Mon, 27 Dec 2021 11:20:57 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "nlp",
      "bert",
      "gpt-2",
      "transformers"
    ],
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1511.06434\r\n\r\nA video with sound can be found [here](https://www.instagram.com/p/Bv0Vd-tlOwi/"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pearsonkyle/Neural-Nebula",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-02T00:56:59Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-23T13:25:54Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8451440391846129
      ],
      "excerpt": "Use the generator, for an example see the save_imgs method \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A deep conv. generative adversarial network trained on nebula and images of space",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pearsonkyle/Neural-Nebula/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Wed, 22 Dec 2021 03:10:21 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/pearsonkyle/Neural-Nebula/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "pearsonkyle/Neural-Nebula",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The  `create_dataset` function will cut random slices from an images to create a new data set. This function requires you to put images in a new directory before hand\r\n```python\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\n\r\nfrom dcgan import create_dataset \r\n\r\n#: first resize the original image to 75% \r\n#: then cut 100 random 128x128 subframes from each image in the directory \r\nx_train, y_train = create_dataset(128,128, nSlices=100, resize=0.75, directory='space/')\r\n\r\n#: scale RGB data between 0 and 1\r\nx_train /= 255 \r\n\r\n#: plot results to make sure data looks good!\r\nfig, axs = plt.subplots(4, 4)\r\nfor i in range(4):\r\n    for j in range(4):\r\n        axs[i,j].imshow( x_train[ np.random.randint(x_train.shape[0]) ] )\r\n        axs[i,j].axis('off')\r\nplt.show()\r\n```\r\nAn example output should look like this: \r\n\r\n![](https://github.com/pearsonkyle/Neural-Nebula/blob/master/images/nebula_training_sample.png)\r\n\r\nIf `x_train` is empty make sure you have `.jpg` or `.png` files in the directory where your images are stored (e.g. `space/`) \r\n\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8545678442294142
      ],
      "excerpt": "check the directory images/ and then use Imagemagick, gimp or ffmpeg to create a gif. For example after running the cifar_example.py cd into the images/ directory and run the code below  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/pearsonkyle/Neural-Nebula/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Neural-Nebula",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Neural-Nebula",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "pearsonkyle",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pearsonkyle/Neural-Nebula/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [Python 3+](https://www.anaconda.com/distribution/)\r\n- Keras, Tensorflow, Matplotlib, Numpy, PIL, Scikit-learn\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 87,
      "date": "Wed, 22 Dec 2021 03:10:21 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Clone the repo, cd into the directory, launch iPython and paste the example below \r\n```python \r\nimport tensorflow as tf\r\nfrom dcgan import DCGAN, create_dataset\r\n\r\nif __name__ == '__main__':\r\n\r\n    x_train, y_train = create_dataset(128,128, nSlices=150, resize=0.75, directory='space/')\r\n    assert(x_train.shape[0]>0)\r\n\r\n    x_train /= 255 \r\n\r\n    dcgan = DCGAN(img_rows = x_train[0].shape[0],\r\n                    img_cols = x_train[0].shape[1],\r\n                    channels = x_train[0].shape[2], \r\n                    latent_dim=32,\r\n                    name='nebula_32_128')\r\n                    \r\n    dcgan.train(x_train, epochs=1000, batch_size=32, save_interval=100)\r\n```\r\nAfter it's done training check the `images/` folder for outputs during the training process\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Prior to running the code below you will have to remove the upsampling layers in the GAN ([line 84](https://github.com/pearsonkyle/Neural-Nebula/blob/master/dcgan.py#L84) and [line 95](https://github.com/pearsonkyle/Neural-Nebula/blob/master/dcgan.py#L95) ) in order to preserve the 32 x 32 output resolution of the generator\r\n```python\r\nfrom keras.datasets import cifar10\r\nfrom dcgan import DCGAN\r\n\r\nif __name__ == '__main__':\r\n\r\n    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\r\n\r\n    #: only birds, then scale images between 0-1\r\n    x_train = x_train[ (y_train==2).reshape(-1) ] \r\n    x_train = x_train/255\r\n    \r\n    dcgan = DCGAN(img_rows = x_train[0].shape[0],\r\n                    img_cols = x_train[0].shape[1],\r\n                    channels = x_train[0].shape[2], \r\n                    latent_dim=128,\r\n                    name='cifar_128')\r\n\r\n    dcgan.train(x_train, epochs=10001, batch_size=32, save_interval=100)\r\n    \r\n    dcgan.save_imgs('final') \r\n```\r\nBelow is an animation of the training process every 500 training batches. The code above took ~10 minutes to run on a GTX 1070. These are random samples from the generator during training. After just 10 minutes of training you can start to see structure that resembles a bird. There's only so much structure you can get from a 32 x 32 pixel image to begin with... More realistic images can be chosen by evaluating them with the discriminator after generating. \r\n\r\n![](https://github.com/pearsonkyle/Neural-Nebula/blob/master/images/cifar_bird.gif)\r\n\r\n",
      "technique": "Header extraction"
    }
  ]
}
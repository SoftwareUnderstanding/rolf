{
  "citation": [
    {
      "confidence": [
        0.9997174689769062
      ],
      "excerpt": "MuVER: Improving First-Stage Entity Retrieval with Multi-View Entity Representations. Xinyin Ma, Yong Jiang, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei Huang, Weiming Lu \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    --epoch 30  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Alibaba-NLP/MuVER",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-07T12:42:09Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-12T15:26:31Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9687777387459373
      ],
      "excerpt": "This repo contains the code and pre-trained model for our EMNLP 2021 paper:      \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9854792124628368
      ],
      "excerpt": "Important: Since constrastive learning relies heavily on a large batch size, as reported in our paper, we use eight v100(16g) to train our model. The hyperparameters for our best model are in logs/zeshel_hyper_param.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "[EMNLP 2021] MuVER: Improving First-Stage Entity Retrieval with  Multi-View Entity Representations",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Data:   \nWe follow facebookresearch/BLINK to download and preprocess data. See [instructions](https://github.com/facebookresearch/BLINK/tree/master/examples/zeshel) about how to download and convert to BLINK format. You will get a folder with the following structure:\n```\n- zeshel\n  | - mentions\n  | - documents\n  | - blink_format \n```\n\n* Model:  \nModel for zeshel can be downloaded on https://drive.google.com/file/d/1BBTue5Vmr3MteGcse-ePqplWjccqm9_A/view?usp=sharing\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/alibaba-nlp/muver/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 12:33:21 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Alibaba-NLP/MuVER/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Alibaba-NLP/MuVER",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9296651658680221
      ],
      "excerpt": "We provice the code to train your MuVER. Train the code with the following command: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "    --name distributed_multi_view \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9078431934650627
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=YOUR_GPU_DEVICES python muver/multi_view/train.py  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "    --name distributed_multi_view \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Alibaba-NLP/MuVER/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "MuVER",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "MuVER",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Alibaba-NLP",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Alibaba-NLP/MuVER/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The requirements for our code are listed in requirements.txt, install the package with the following command:  \n```\npip install -r requirements.txt\n```\nFor [huggingface/transformers](https://github.com/huggingface/transformers), we tested it under version 4.1.X and 4.2.X.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 21,
      "date": "Sat, 25 Dec 2021 12:33:21 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "entity-linking",
      "entity-retrieval"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* **Without View Merging**:  \n```\nexport PYTHONPATH='.'  \nCUDA_VISIBLE_DEVICES=YOUR_GPU_DEVICES python muver/multi_view/train.py \n    --pretrained_model path_to_model/bert-base \n    --dataset_path path_to_dataset/zeshel\n    --bi_ckpt_path path_to_model/best_zeshel.bin \n    --max_cand_len 40 \n    --max_seq_len 128\n    --do_test \n    --test_mode test \n    --data_parallel \n    --eval_batch_size 16\n    --accumulate_score\n```\n\n\nExpected Result:  \n\n|      World       |  R@1   |  R@2   |  R@4   |  R@8   |  R@16  |  R@32  |  R@50  |  R@64  |  \n|------------------|--------|--------|--------|--------|--------|--------|--------|--------|  \n| forgotten_realms | 0.6208 | 0.7783 | 0.8592 | 0.8983 | 0.9342 | 0.9533 | 0.9633 | 0.9700 |  \n|       lego       | 0.4904 | 0.6714 | 0.7690 | 0.8357 | 0.8791 | 0.9091 | 0.9208 | 0.9249 |  \n|    star_trek     | 0.4743 | 0.6130 | 0.6967 | 0.7606 | 0.8159 | 0.8581 | 0.8805 | 0.8919 |  \n|      yugioh      | 0.3432 | 0.4861 | 0.6040 | 0.7004 | 0.7596 | 0.8201 | 0.8512 | 0.8672 |  \n|      total       | 0.4496 | 0.5970 | 0.6936 | 0.7658 | 0.8187 | 0.8628 | 0.8854 | 0.8969 |  \n\n* **With View Merging**:\n```\nexport PYTHONPATH='.'  \nCUDA_VISIBLE_DEVICES=YOUR_GPU_DEVICES python muver/multi_view/train.py \n    --pretrained_model path_to_model/bert-base \n    --dataset_path path_to_dataset/zeshel\n    --bi_ckpt_path path_to_model/best_zeshel.bin \n    --max_cand_len 40 \n    --max_seq_len 128 \n    --do_test \n    --test_mode test \n    --data_parallel \n    --eval_batch_size 16\n    --accumulate_score\n    --view_expansion  \n    --merge_layers 4  \n    --top_k 0.4\n```\nExpected result:   \n|      World       |  R@1   |  R@2   |  R@4   |  R@8   |  R@16  |  R@32  |  R@50  |  R@64  |\n|------------------|--------|--------|--------|--------|--------|--------|--------|--------|\n| forgotten_realms | 0.6175 | 0.7867 | 0.8733 | 0.9150 | 0.9375 | 0.9600 | 0.9675 | 0.9708 |\n|       lego       | 0.5046 | 0.6889 | 0.7882 | 0.8449 | 0.8882 | 0.9183 | 0.9324 | 0.9374 |\n|    star_trek     | 0.4810 | 0.6253 | 0.7121 | 0.7783 | 0.8271 | 0.8706 | 0.8935 | 0.9030 |\n|      yugioh      | 0.3444 | 0.5027 | 0.6322 | 0.7300 | 0.7902 | 0.8429 | 0.8690 | 0.8826 |\n|      total       | 0.4541 | 0.6109 | 0.7136 | 0.7864 | 0.8352 | 0.8777 | 0.8988 | 0.9084 |\n\nOptional Argument:\n* --data_parallel: whether you want to use multiple gpus.\n* --accumulate_score: accumulate score for each entity. Obtain a higher score but will take much time to inference.  \n* --view_expansion: whether you want to merge and expand view.\n* --top_k: top_k pairs are expected to merge in each layer.\n* --merge_layers: the number of layers for merging.\n* --test_mode: If you want to generate candidates for train/dev set, change the test_mode to train or dev, which will generate candidates outputs and save it under the directory where you save the test model.\n\n",
      "technique": "Header extraction"
    }
  ]
}
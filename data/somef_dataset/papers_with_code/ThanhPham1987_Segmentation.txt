# Segmentation
1. Segmentation Overview

- Semantic segmentation performs pixel-level labeling with a set of object categories (e.g., human, car, tree, sky) for all image pixels. 

- Instance segmentation extends semantic segmentation scope further by detecting and delineating each object of interest in the image (e.g., partitioning of individual persons).
  
- Panoptic segmentation unifies the typically distinct tasks of semantic segmentation (assign a class label to each pixel) and instance segmentation (detect and segment each object instance).
  
![img_1.png](img_1.png)

For example:

+ Medical image analysis (tumor boundary extraction and measurement of tissue volumes).

+ Robotic perception

+ Video surveillance

+ Augmented reality

+ Image compression

+ Autonomous vehicle (navigable surface and pedestrian detection)

2. DL-BASED IMAGE SEGMENTATION MODELS

This section provides a detailed review of more than a hundred deep learning-based segmentation methods proposed until 2019, grouped into 10 categories (based on their model architecture). It is worth mentioning that there are some pieces that are common among many of these works, such as having encoder and decoder parts, skip-connections, multi-scale analysis, and more recently the use of dilated convolution. Because of this, it is difficult to mention the unique contributions of each work, but easier to group them based on their underlying architectural contribution over previous works. Besides the architectural categorization
of these models, one can also group them based on the segmentation goal into: semantic, instance, panoptic, and depth segmentation categories. But due to the big difference in terms of volume of work in those tasks, we decided to follow the architectural grouping.

3.1 Fully Convolutional Networks

Long et al. [31] proposed one of the first deep learning works for semantic image segmentation, using a fully convolutional network (FCN). An FCN (Figure 7) includes only convolutional layers, which enables it to take an image of arbitrary size and produce a segmentation map of the same size. The authors modified existing CNN architectures, such as VGG16 and GoogLeNet, to manage non-fixed sized input and output, by replacing all fully-connected layers with the fully-convolutional layers. As a result, the model outputs a spatial segmentation map instead of classification scores.

![image](https://user-images.githubusercontent.com/22832922/140115453-260c8052-5a8a-4e8f-96ef-594affca7a2c.png)

Through the use of skip connections in which featuremaps from the final layers of the model are up-sampled and fused with feature maps of earlier layers (Figure 8), the model combines semantic information (from deep, coarse layers) and appearance information (from shallow, fine layers) in order to produce accurate and detailed segmentations. The model was tested on PASCAL VOC, NYUDv2, and SIFT Flow, and achieved state-of-the-art segmentation performance.

![image](https://user-images.githubusercontent.com/22832922/140117812-d551dc6e-9701-43a3-9dfe-c8eb2c2b0910.png)

This work is considered a milestone in image segmentation, demonstrating that deep networks can be trained for semantic segmentation in an end-to-end manner on variablesized images. However, despite its popularity and effectiveness, the conventional FCN model has some limitations—it is not fast enough for real-time inference, it does not take into account the global context information in an efficient way, and it is not easily transferable to 3D images. Several efforts have attempted to overcome some of the limitations of the FCN.

For instance, Liu et al. [32] proposed a model called ParseNet, to address an issue with FCN—ignoring global context information. ParseNet adds global context to FCNs by using the average feature for a layer to augment the features at each location. The feature map for a layer is pooled over the whole image resulting in a context vector. This context vector is normalized and unpooled to produce new feature maps of the same size as the initial ones. These feature maps are then concatenated. In a nutshell, ParseNet is an FCN with the described module replacing the convolutional layers (Figure 9).

![image](https://user-images.githubusercontent.com/22832922/140121784-4bf10536-799e-432e-84b2-6fe8e831e063.png)

FCNs have been applied to a variety of segmentation problems, such as brain tumor segmentation [33], instanceaware semantic segmentation [34], skin lesion segmentation [35], and iris segmentation [36].

Reference:

[1] https://arxiv.org/pdf/2001.05566.pdf

[2] https://arxiv.org/pdf/2007.00047.pdf

[3] https://arxiv.org/pdf/2108.11250v1.pdf

Apendix:

delineate (v) 

(1) to describe something very exactly 

(2) to decide or show the exact limits of something; 

(3) to show a line or border, for example on a map

{
  "citation": [
    {
      "confidence": [
        0.9473504848550303
      ],
      "excerpt": "Open SimCLR results comparison on tensorboard.dev: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8786044417622563
      ],
      "excerpt": "  <a href=\"https://tensorboard.dev/experiment/A3laNdafRBes0oR45Y6LiA/#scalars\" target=\"_blank\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9249808528262904
      ],
      "excerpt": "| Method  | Batch Size | ResNet | Projection output dimensionality | Epochs | Optimizer | STL-10 | CIFAR-10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "| Logistic Regression | - | - | - | 40 | Adam | 0.358 | 0.389 | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Spijkervet/SimCLR",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-10T10:52:29Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-24T05:50:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9581660181054422,
        0.8272915699636102
      ],
      "excerpt": "PyTorch implementation of SimCLR: A Simple Framework for Contrastive Learning of Visual Representations by T. Chen et al. \nIncluding support for: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8950631836916996,
        0.9446705136074536
      ],
      "excerpt": "Link to paper \nOpen SimCLR in Google Colab Notebook (with TPU support) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8396473736930664
      ],
      "excerpt": "This downloads a pre-trained model and trains the linear classifier, which should receive an accuracy of \u00b182.9% on the STL-10 test set. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8188440924442218
      ],
      "excerpt": "SimCLR for PyTorch is now available as a Python package! Simply run and use it in your project: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9545313595162825
      ],
      "excerpt": "These are the top-1 accuracy of linear classifiers trained on the (frozen) representations learned by SimCLR: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9204217756568253
      ],
      "excerpt": "SimCLR is a \"simple framework for contrastive learning of visual representations\". The contrastive prediction task is defined on pairs of augmented examples, resulting in 2N examples per minibatch. Two augmented versions of an image are considered as a correlated, \"positive\" pair (x_i and x_j). The remaining 2(N - 1) augmented examples are considered negative examples. The contrastive prediction task aims to identify x_j in the set of negative examples for a given x_i. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8155522112929886
      ],
      "excerpt": "or in place: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8346495273053635
      ],
      "excerpt": "This implementation features the Adam optimizer and the LARS optimizer, with the option to decay the learning rate using a cosine decay schedule. The optimizer and weight decay can be configured in the config/config.yaml file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "PyTorch implementation of SimCLR: A Simple Framework for Contrastive Learning of Visual Representations by T. Chen et al.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/spijkervet/simclr/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 98,
      "date": "Mon, 27 Dec 2021 00:46:30 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Spijkervet/SimCLR/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Spijkervet/SimCLR",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/spijkervet/simclr/master/setup.sh",
      "https://raw.githubusercontent.com/spijkervet/simclr/master/run_all.sh",
      "https://raw.githubusercontent.com/spijkervet/simclr/master/setup_apex.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9975790152367754,
        0.9215471799007166,
        0.9969566654472617,
        0.9770335174395833
      ],
      "excerpt": "git clone https://github.com/spijkervet/SimCLR.git &amp;&amp; cd SimCLR \nwget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar \nsh setup.sh || python3 -m pip install -r requirements.txt || exit 1 \nconda activate simclr \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9250371135840701
      ],
      "excerpt": "wget https://github.com/Spijkervet/SimCLR/releases/download/1.1/checkpoint_100.tar -O checkpoint_100.tar \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8493920100057469,
        0.999746712887969
      ],
      "excerpt": "SimCLR for PyTorch is now available as a Python package! Simply run and use it in your project: \npip install simclr \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8627128566269915
      ],
      "excerpt": "Simply run the following to pre-train a ResNet encoder using SimCLR on the CIFAR-10 dataset: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9340747452236376
      ],
      "excerpt": "python linear_evaluation.py --dataset=STL10 --model_path=. --epoch_num=100 --resnet resnet50 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8997722664086865
      ],
      "excerpt": "python linear_evaluation.py --model_path=. --epoch_num=100 --resnet=resnet18 --logistic_batch_size=32 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from simclr import SimCLR \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9349148923003944
      ],
      "excerpt": "python main.py --dataset CIFAR10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8501445223312123,
        0.8501445223312123,
        0.8501445223312123,
        0.8501445223312123
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0 python main.py --nodes 2 --nr 0 \nCUDA_VISIBLE_DEVICES=1 python main.py --nodes 2 --nr 1 \nCUDA_VISIBLE_DEVICES=2 python main.py --nodes 2 --nr 2 \nCUDA_VISIBLE_DEVICES=N python main.py --nodes 2 --nr 3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8016044744607514
      ],
      "excerpt": "| Method  | Batch Size | ResNet | Projection output dimensionality | Epochs | Optimizer | STL-10 | CIFAR-10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9276696769293497
      ],
      "excerpt": "python linear_evaluation.py --model_path=. --epoch_num=100 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8587218341159187
      ],
      "excerpt": "To test a trained model, make sure to set the model_path variable in the config/config.yaml to the log ID of the training (e.g. logs/0). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python linear_evaluation.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9177683179226663,
        0.8163942101437064
      ],
      "excerpt": "python linear_evaluation.py --model_path=./save --epoch_num=40 \nThe configuration of training can be found in: config/config.yaml. I personally prefer to use files instead of long strings of arguments when configuring a run. An example config.yaml file: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8779731492716857
      ],
      "excerpt": ": train options \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8199444860642056
      ],
      "excerpt": ": model options \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "normalize: True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8240138726085549
      ],
      "excerpt": "model_path: \"logs/0\" #: set to the directory containing checkpoint_#:#:.tar  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Spijkervet/SimCLR/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Janne Spijkervet\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SimCLR",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SimCLR",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Spijkervet",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Spijkervet/SimCLR/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "Spijkervet",
        "body": "config.yaml\r\n```\r\n{\r\n  \"batch_size\": 256,\r\n  \"dataset\": \"STL10\",\r\n  \"epochs\": 100,\r\n  \"fp16\": false,\r\n  \"fp16_opt_level\": \"O2\",\r\n  \"logistic_batch_size\": 256,\r\n  \"logistic_epochs\": 100,\r\n  \"model_num\": 40,\r\n  \"model_path\": \"logs/0\",\r\n  \"normalize\": true,\r\n  \"optimizer\": \"Adam\",\r\n  \"projection_dim\": 64,\r\n  \"resnet\": \"resnet50\",\r\n  \"seed\": 42,\r\n  \"start_epoch\": 0,\r\n  \"temperature\": 0.5,\r\n  \"workers\": 16\r\n}\r\n```",
        "dateCreated": "2020-03-12T18:43:27Z",
        "datePublished": "2020-03-12T23:00:46Z",
        "html_url": "https://github.com/Spijkervet/SimCLR/releases/tag/1.2",
        "name": "SimCLR weights (ResNet50, 256 batch size, 100 epochs)",
        "tag_name": "1.2",
        "tarball_url": "https://api.github.com/repos/Spijkervet/SimCLR/tarball/1.2",
        "url": "https://api.github.com/repos/Spijkervet/SimCLR/releases/24483712",
        "zipball_url": "https://api.github.com/repos/Spijkervet/SimCLR/zipball/1.2"
      },
      {
        "authorType": "User",
        "author_name": "Spijkervet",
        "body": "config.yaml:\r\n```\r\n# train options\r\nseed: 42 # sacred handles automatic seeding when passed in the config\r\nbatch_size: 256\r\nworkers: 16\r\nstart_epoch: 0\r\nepochs: 100\r\ndataset: \"STL10\" # STL10\r\n\r\n# model options\r\nresnet: \"resnet18\"\r\nnormalize: True\r\nprojection_dim: 64 # \"[...] to project the representation to a 128-dimensional latent space\"\r\n\r\n# loss options\r\noptimizer: \"Adam\" # or LARS (experimental)\r\ntemperature: 0.5 # see appendix B.7.: Optimal temperature under different batch sizes\r\n\r\n# reload options\r\nmodel_path: \"logs/0\" # set to the directory containing `checkpoint_##.tar` \r\nmodel_num: 40 # set to checkpoint number\r\n\r\n# mixed-precision training\r\nfp16: False \r\nfp16_opt_level: \"O2\"\r\n\r\n\r\n# logistic regression options\r\nlogistic_batch_size: 256\r\nlogistic_epochs: 100\r\n```",
        "dateCreated": "2020-03-12T16:54:21Z",
        "datePublished": "2020-03-12T17:25:07Z",
        "html_url": "https://github.com/Spijkervet/SimCLR/releases/tag/1.1",
        "name": "SimCLR weights (ResNet18, 256 batch size, 100 epochs)",
        "tag_name": "1.1",
        "tarball_url": "https://api.github.com/repos/Spijkervet/SimCLR/tarball/1.1",
        "url": "https://api.github.com/repos/Spijkervet/SimCLR/releases/24472933",
        "zipball_url": "https://api.github.com/repos/Spijkervet/SimCLR/zipball/1.1"
      },
      {
        "authorType": "User",
        "author_name": "Spijkervet",
        "body": "A pre-trained SimCLR model with the following parameters:\r\n\"batch_size\": 256,\r\n\"epochs\": 40,\r\n\"n_out\": 64,\r\n\"normalize\": true,\r\n\"resnet\": \"resnet18\",\r\n\"seed\": 634715003,\r\n\"start_epoch\": 0,\r\n\"temperature\": 0.5,\r\n\"workers\": 16\r\n\r\nAccuracy with a logistic regression classifier trained on top of SimCLR on STL-10 test set: 0.72\r\n",
        "dateCreated": "2020-03-11T19:50:07Z",
        "datePublished": "2020-03-11T19:56:11Z",
        "html_url": "https://github.com/Spijkervet/SimCLR/releases/tag/1.0",
        "name": "SimCLR weights (40 epochs)",
        "tag_name": "1.0",
        "tarball_url": "https://api.github.com/repos/Spijkervet/SimCLR/tarball/1.0",
        "url": "https://api.github.com/repos/Spijkervet/SimCLR/releases/24441125",
        "zipball_url": "https://api.github.com/repos/Spijkervet/SimCLR/zipball/1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\ntorch\ntorchvision\ntensorboard\npyyaml\n```\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 430,
      "date": "Mon, 27 Dec 2021 00:46:30 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "simclr",
      "pytorch",
      "contrastive-learning",
      "unsupervised-learning",
      "representation-learning"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Run the following command to setup a conda environment:\n```\nsh setup.sh\nconda activate simclr\n```\n\nOr alternatively with pip:\n```\npip install -r requirements.txt\n```\n\nThen, simply run for single GPU or CPU training:\n```\npython main.py\n```\n\nFor distributed training (DDP), use for every process in nodes, in which N is the GPU number you would like to dedicate the process to:\n```\nCUDA_VISIBLE_DEVICES=0 python main.py --nodes 2 --nr 0\nCUDA_VISIBLE_DEVICES=1 python main.py --nodes 2 --nr 1\nCUDA_VISIBLE_DEVICES=2 python main.py --nodes 2 --nr 2\nCUDA_VISIBLE_DEVICES=N python main.py --nodes 2 --nr 3\n```\n\n`--nr` corresponds to the process number of the N nodes we make available for training.\n\n",
      "technique": "Header extraction"
    }
  ]
}
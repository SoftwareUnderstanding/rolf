{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1611.01576, 2016.\n4. Kutuzov A., Kuzmenko E. (2017) WebVectors: A Toolkit for Building Web Interfaces for Vector Semantic Models. In: Ignatov D. et al. (eds) Analysis of Images, Social Networks and Texts. AIST 2016. Communications in Computer and Information Science, vol 661. Springer, Cham  \n5. A. Odena and I. Goodfellow, \u201cTensorfuzz: Debugging neural networks with coverage-guided fuzzing,\u201d arXiv preprint https://arxiv.org/abs/1807.10875, 2018.  \n6. Karpathy, A.; Johnson, J.; and Li, F.-F. 2015. Visualizing and understanding recurrent networks. arXiv preprint.\n7. Stephen Merity, Nitish Shirish Keskar, and Richard Socher. An analysis of neural language modeling at multiple scales. https://arxiv.org/abs/1803.08240, 2018. ",
      "https://arxiv.org/abs/1807.10875, 2018.  \n6. Karpathy, A.; Johnson, J.; and Li, F.-F. 2015. Visualizing and understanding recurrent networks. arXiv preprint.\n7. Stephen Merity, Nitish Shirish Keskar, and Richard Socher. An analysis of neural language modeling at multiple scales. https://arxiv.org/abs/1803.08240, 2018. ",
      "https://arxiv.org/abs/1803.08240, 2018. "
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8054474547341693
      ],
      "excerpt": "[ ] Obtain results for short and long texts \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ngc436/language_model",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-10-12T19:32:00Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-01-28T14:42:38Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9231953571906051
      ],
      "excerpt": "Current repository contains experiments on language modeling for text classification. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9696149337258896,
        0.9468268704190138
      ],
      "excerpt": "[ ] Add CNN model \n[ ] Add SVM and XgBoost tools \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9380342806759296,
        0.9710087041128412,
        0.8946802559996034
      ],
      "excerpt": "[x] Prepare model with fasttext embeddings (1 - without preprocessing)    \n[x] Prepare model with fasttext embeddings (2 - lemmatized)    \n[X] Reduce the dictionary and substitute rare words with oov (?) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9710087041128412,
        0.9675911281522089,
        0.9513584737945192
      ],
      "excerpt": "[ ] Tune model with hyperopt \n[x] Check model_1542229255 on comments with more than 50 tokens \n[ ] Prepare report on language model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8396297517563066
      ],
      "excerpt": "[ ] Add representation in latent space from VAE \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9595274873362689,
        0.8372396012058242
      ],
      "excerpt": "More data  \n[x] Divide on chunks   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8815990837068118
      ],
      "excerpt": "Cleaner data   \n[x] Fix dirty data issue (html, phone instead of id) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.941165807659659
      ],
      "excerpt": "[ ] Optimization with hyperopt   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9332713641420816
      ],
      "excerpt": "[ ] Look at fasttext work in case of unlemmatized input for the best performing models above (prepare this input)  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.932599931933171
      ],
      "excerpt": "[ ] Create new verification with 500 samples (50 positive, other - negative) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123563591613231
      ],
      "excerpt": "[ ] Obtain results for short and long texts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9391505182611909
      ],
      "excerpt": "J. Howard and S. Ruder.  Universal language model fine-tuning for text classification. Association for Computational Linguistics (ACL), 2018. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8776973799384795
      ],
      "excerpt": "Kutuzov A., Kuzmenko E. (2017) WebVectors: A Toolkit for Building Web Interfaces for Vector Semantic Models. In: Ignatov D. et al. (eds) Analysis of Images, Social Networks and Texts. AIST 2016. Communications in Computer and Information Science, vol 661. Springer, Cham   \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JessikaSmith/language_model/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 14:28:09 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ngc436/language_model/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ngc436/language_model",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8162678873545649
      ],
      "excerpt": "[x] Prepare train/test/val \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8322905163898139
      ],
      "excerpt": "[x] Change percentage of positive examples in training set (?) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9037729351192054
      ],
      "excerpt": "[x] Add TripAdvisor proocessed comments to train/test \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ngc436/language_model/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Maria Khodorchenko\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Language Models Repository\n\nCurrent repository contains experiments on language modeling for text classification. \n\n## Steps to be done\n- [x] Prepare train/test/val\n- [ ] Get TM results\n- [x] Implement QRNN\n- [x] Implement BiQRNN\n- [x] Implement simple LSTM\n- [x] Implement BiLSTM\n- [ ] Add CNN model\n- [ ] Add SVM and XgBoost tools\n- [x] initial classification results\n- [x] Implement VAE  \n\n## TODO's\n- [x] Prepare new test/train/ver with extracted entities\n- [x] Find out why loss becomes NaN in QRNN (too high learning rate)\n- [ ] Preprocess embedding data to zero mean and unit variance  \n- [x] Check on models_dir/model_1542027692.h5 weights (w2v embedding)  \n- [ ] Add cross-validation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "language_model",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ngc436",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ngc436/language_model/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 14:28:09 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "language-model",
      "keras-tensorflow",
      "bilstm",
      "text-classification",
      "nlp"
    ],
    "technique": "GitHub API"
  }
}
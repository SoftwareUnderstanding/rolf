{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [WAVENET](https://arxiv.org/pdf/1609.03499.pdf) \n- [A Universal Music Translation Network](https://arxiv.org/pdf/1805.07848.pdf)\n- [WAVE-U-NET](https://arxiv.org/pdf/1806.03185.pdf)\n- https://github.com/MTG/DeepConvSep\n- https://github.com/ShichengChen/WaveUNet\n\n<div style=\"page-break-after: always;\"></div>\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8906174419333412
      ],
      "excerpt": "U-Wave-Net Structure \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ShichengChen/Audio-Source-Separation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-05-30T13:30:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-18T15:34:32Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9737891997691791
      ],
      "excerpt": "Data Augmentation for FacebookNet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.905965163855696
      ],
      "excerpt": "TODO for facebook net \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9619404902550615
      ],
      "excerpt": "Data Augmentation for U-Wave-Net \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8083915150931811
      ],
      "excerpt": "- Input is a quantized audio array, for example, input.shape = L. L is the length of the audio. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9611004740939515
      ],
      "excerpt": "- Left yellow circle is a tanh fuction and right yellow circle is sigmoid \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8501739371242472
      ],
      "excerpt": "- K is the layer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9680632333579167,
        0.859495734844457
      ],
      "excerpt": "A is mix audio, B is vocals and C is accompaniment. \nThe deepmind wavenet's input and label are only A \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8395756117933525
      ],
      "excerpt": "I use A[0:100] to predict B[50] instead of using A[0:50] to predict A[50] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8147501213715782,
        0.8081230189929841
      ],
      "excerpt": "- After the three blocks, there is an additional 1 * 1 layer \n- An average pooling with a kernel size of 800(if sample size for one second is 16000) follows \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8390769491308679,
        0.896027077191314
      ],
      "excerpt": "- The above figure is new version wavenet \n- The encoding audio is used to condition a WaveNet decoder. The conditioning signal is passed through a 1 \u00d7 1 layer that is different for each WaveNet layer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8200588955587446,
        0.8619511991857762
      ],
      "excerpt": "- Loss fuction is softmax \nUniformly select a segment of length between 0.25 and 0.5 seconds \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9805615399060642,
        0.912719403386399
      ],
      "excerpt": "I used data augmentation strategy from u-wave-net paper. For example, A is mix audio, B is vocals and C is accompaniment. B * factor0 + C * factor1 = newA, I used newA as input and C*factor1 as label. Factor0 and factor1 is chosen uniformly from the interval [0.7, 1.0]. \nI used Ccmixter as dataset. Ccmixter has 3 Children's songs, two songs as training data and the other as testing data, the result on testing data is also very good even though is slightly worse than training data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8309201967063623
      ],
      "excerpt": "First 45 songs for training and last 5 songs for testing, the results is still not good. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8477479525223115
      ],
      "excerpt": "Add downsample and upsample, add confusion loss, use short time fourier transform to preprocess the raw audio. The results are worse than structure A. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.972427381624374
      ],
      "excerpt": "Try to add decoding part to structure A. The bottleneck during inference is the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9798033182981145,
        0.9786439078443746
      ],
      "excerpt": "- Downsampling discards features for every other time step to halve the time resolution \n- Concat concatenates the current high-level features with more local features x \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9680632333579167
      ],
      "excerpt": "A is mix audio, B is vocals and C is accompaniment.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9728444074368733
      ],
      "excerpt": "Factor0 and factor1 is chosen uniformly from the interval [0.7, 1.0]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "WaveNet for the separation of audio sources",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ShichengChen/WaveNetSeparateAudio/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Sun, 26 Dec 2021 08:21:52 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ShichengChen/Audio-Source-Separation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ShichengChen/Audio-Source-Separation",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/useAandBsimultaneously.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/clean_ccmixter_corpus2.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/vstrain.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/clean_ccmixter_corpus.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/playTorch.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/originalLoss.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/plotLoss.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/archives/debugTestingData.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/archives/tensorflowMNIST.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/archives/trainVS.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/archives/dataAugmentation.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/archives/playTensorflow.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/archives/train.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/archives/vocalSeparation/trainS.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/archives/vocalSeparation/data_utils.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/archives/vocalSeparation/.ipynb_checkpoints/data_utils-checkpoint.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/archives/vocalSeparation/.ipynb_checkpoints/trainS-checkpoint.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/.ipynb_checkpoints/debugTestingData-checkpoint.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/.ipynb_checkpoints/useAandBsimultaneously-checkpoint.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/.ipynb_checkpoints/train-checkpoint.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/.ipynb_checkpoints/originalLoss-checkpoint.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/.ipynb_checkpoints/clean_ccmixter_corpus-checkpoint.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/.ipynb_checkpoints/trainVS-checkpoint.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/.ipynb_checkpoints/tensorflowMNIST-checkpoint.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/.ipynb_checkpoints/playTorch-checkpoint.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/.ipynb_checkpoints/clean_ccmixter_corpus2-checkpoint.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/.ipynb_checkpoints/playTensorflow-checkpoint.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/.ipynb_checkpoints/dataAugmentation-checkpoint.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/.ipynb_checkpoints/plotLoss-checkpoint.ipynb",
      "https://raw.githubusercontent.com/ShichengChen/WaveNetSeparateAudio/master/.ipynb_checkpoints/vstrain-checkpoint.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8275433272887399
      ],
      "excerpt": "Audio Source Separation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8158998384895894
      ],
      "excerpt": "WaveNet for Audio Source Separation  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8288305174705919
      ],
      "excerpt": "- Input is a quantized audio array, for example, input.shape = L. L is the length of the audio. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8099966221410565
      ],
      "excerpt": "- The input and output are quantized using 8-bit mu-law encoding \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ShichengChen/Audio-Source-Separation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License (MIT) Copyright (c) 2016 Igor Babuschkin\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of\\nthis software and associated documentation files (the \"Software\"), to deal in\\nthe Software without restriction, including without limitation the rights to\\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\\nof the Software, and to permit persons to whom the Software is furnished to do\\nso, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Table of Contents",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Audio-Source-Separation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ShichengChen",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ShichengChen/Audio-Source-Separation/blob/master/readme.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 45,
      "date": "Sun, 26 Dec 2021 08:21:52 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "wavenet-pytorch"
    ],
    "technique": "GitHub API"
  }
}
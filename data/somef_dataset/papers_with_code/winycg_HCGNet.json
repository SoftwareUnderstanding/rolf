{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1711.05611"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@inproceedings{yang2020gated,\n  title={Gated Convolutional Networks with Hybrid Connectivity for Image Classification},\n  author={Yang, Chuanguang and An, Zhulin and Zhu, Hui and Hu, Xiaolong and Zhang, Kun and Xu, Kaiqiang and Li, Chao and Xu, Yongjun},\n  booktitle={Thirty-Fourth AAAI Conference on Artificial Intelligence},\n  pages = {12581--12588},\n  year={2020}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "FGSM (Fast gradient sign mthod) is proposed by\n[Explaining and harnessing adversarial examples](https://arxiv.org/pdf/1412.6572.pdf) paper. Our experiemnts refer the implementation by [foolbox](https://github.com/bethgelab/foolbox) .\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Network dissection method is proposed by\n[Network Dissection: Quantifying Interpretability of Deep Visual Representations](https://arxiv.org/abs/1711.05611) paper. Our experiemnts refer the official implementation: https://github.com/CSAILVision/NetDissect-Lite\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{yang2020gated,\n  title={Gated Convolutional Networks with Hybrid Connectivity for Image Classification},\n  author={Yang, Chuanguang and An, Zhulin and Zhu, Hui and Hu, Xiaolong and Zhang, Kun and Xu, Kaiqiang and Li, Chao and Xu, Yongjun},\n  booktitle={Thirty-Fourth AAAI Conference on Artificial Intelligence},\n  pages = {12581--12588},\n  year={2020}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/winycg/HCGNet",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please feel free to report issues and any related problems to Chuanguang Yang (yangchuanguang@ict.ac.cn).\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-11-21T12:20:04Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T06:55:14Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9746771948426234
      ],
      "excerpt": "This project provides source code for our AAAI-2020 paper HCGNet. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.806453982912234
      ],
      "excerpt": "When the training finishes, the best model file  HCGNet_B_best.pth.tar is saved in ./checkpoint/. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8884229710084982
      ],
      "excerpt": "Evaluation on interpretability based on the ImageNet pretrained model HCGNet-B: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9056715034550223,
        0.8512866432466618
      ],
      "excerpt": "We compare the unique detectors of HCGNet-B against other popular SOTA models as follows: \nEvaluation on adversarial robustness based on ImageNet pretrained models: HCGNet-B and other popular networks: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801341400692148,
        0.860059181823877
      ],
      "excerpt": "Attack models with different perturbation energies\uff1a0.001~0.005. We report top-1 accuracy on ImageNet validation set after attacking. \n| Model | 0.000| 0.001 | 0.002 | 0.003 | 0.004 | 0.005| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8019699433842047
      ],
      "excerpt": "| ResNeXt-50  | 0.776  | 0.382  |  0.239 |    0.177 | 0.148 | 0.131 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8085428027704326
      ],
      "excerpt": "We experiment HCGNet-B pretrained on ImageNet as a backbone on the Mask-RCNN system to implement object detection and instance segmentation tasks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "[AAAI-2020] Official implementations of HCGNets: Gated Convolutional Networks with Hybrid Connectivity for Image Classification",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/winycg/HCGNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Sat, 25 Dec 2021 10:06:17 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/winycg/HCGNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "winycg/HCGNet",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/winycg/HCGNet/master/network_dissection/script/dlbroden.sh",
      "https://raw.githubusercontent.com/winycg/HCGNet/master/network_dissection/script/dlzoo_example.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Download the ImageNet dataset to YOUR_IMAGENET_PATH and move validation images to labeled subfolders\n    - The [script](https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh) may be helpful.\n\n- Create a datasets subfolder under your cloned HCGNet and a symlink to the ImageNet dataset\n\n```\n$ cd HCGNet\n$ mkdir data\n$ ln -s PATH_TO_YOUR_IMAGENET ./data/\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9893272198983933,
        0.9906248903846466
      ],
      "excerpt": "$ git clone https://github.com/winycg/HCGNet.git \n$ cd HCGNet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9736629876602173,
        0.9666866584681653,
        0.996714160028586,
        0.9478897992756803
      ],
      "excerpt": "$ pip uninstall pillow \n$ conda uninstall --force jpeg libtiff -y \n$ conda install -c conda-forge libjpeg-turbo \n$ CC=\"cc -mavx2\" pip install --no-cache-dir -U --force-reinstall --no-binary :all: --compile pillow-simd \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.847007973711487
      ],
      "excerpt": "--nproc_per_node : Your GPU number for training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd network_dissection/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd FGSM_attack/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9244487712405576
      ],
      "excerpt": "- 2 means your GPU number \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9126921437653545,
        0.843384653375927
      ],
      "excerpt": "python main_cifar.py --dataset cifar10 --arch HCGNet_A1 \n| Model | Params | FLOPS | CIFAR-10 | CIFAR-100 |  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8179727036183359,
        0.8219947171772221,
        0.8514229627917018,
        0.8079065090082965
      ],
      "excerpt": "--nproc_per_node : Your GPU number for training. \nWhen the training finishes, the best model file  HCGNet_B_best.pth.tar is saved in ./checkpoint/. \npython -m torch.distributed.launch --nproc_per_node=2 main_imagenet.py --arch HCGNet_B --gpu-id 0,1 --resume --checkpoint ./checkpoint/HCGNet_B_best.pth.tar --evaluate \n| Model | Params | FLOPS | Top-1 | Top-5 | Pretrained model| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9333384803827206
      ],
      "excerpt": "python main.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python attack.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8508907190137017,
        0.8005569439453106,
        0.8056949218511433
      ],
      "excerpt": "You can download our pretrained detection and segmentation model file from HCGNet_detection.pth. You need to configure the path of HCGNet-B pretrained model by pretrained key in hcgnet_config.py . \n./tools/dist_test.sh configs/hcgnet_config.py \\ checkpoints/HCGNet_detection.pth \\ \n2 --out results.pkl --eval bbox segm \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/winycg/HCGNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "HCGNets: Gated Convolutional Networks with Hybrid Connectivity for Image Classification",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "HCGNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "winycg",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/winycg/HCGNet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Ubuntu 16.04 LTS\n\nPython 3 ([Anaconda](https://www.anaconda.com/) is recommended)\n\nCUDA 9 or newer\n\nPyTorch 0.4 or newer\n\nNVIDIA [NCCL](https://docs.nvidia.com/deeplearning/sdk/nccl-install-guide/index.html)\n\n[Foolbox](https://github.com/bethgelab/foolbox)\n\n[MMDection](https://github.com/open-mmlab/mmdetection)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "You need to install [MMDection](https://github.com/open-mmlab/mmdetection) at first and obtain a `mmdetection` folder.  Then you need to move the  `detection/hcgnet.py`  and `detection/__init__.py` to `mmdetection/mmdet/models/backbones/` , as well as `detection/hcgnet_config.py` to `mmdetection/configs/` in your  folder.  \n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 43,
      "date": "Sat, 25 Dec 2021 10:06:17 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel, \"InfoGAN: Interpretable Representation Learning by\nInformation Maximizing Generative Adversarial Nets\", June 2016 (https://arxiv.org/pdf/1606.03657.pdf)\n\n[2] Alec Radford, Luke Metz and Soumith Chintala, \"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\" Jan 2016 (https://arxiv.org/pdf/1511.06434)\n\n[3] Mehdi Mirza, Simon Osindero, \"Conditional Generative Adversarial Nets\", Nov 2014 (https://arxiv.org/pdf/1411.1784)\n\n[4] Agustinus Kristiadi on InfoGAN (https://wiseodd.github.io/techblog/2017/01/29/infogan/)\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/gitlost-murali/InfoGAN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-11-08T01:34:57Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-11-08T06:11:54Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9360946324974069,
        0.9743448867091421,
        0.9720028535089166,
        0.9473444540995022
      ],
      "excerpt": "For a better understanding of InfoGANs, it's better to have grip on GANs, CGANs (Conditional GANs). \nhas two neural networks , one called as generator and other is a discriminator. The task of generator is to mimic the probability distribution of given dataset. At a high level, a generative model means you have mapped the probability distribution of the data itself. In the case of images, that means you have a probability for every possible combination of pixel values. This also means you can generate new data points by sampling from this distribution ( by choosing combinations with large probability). In Computer vision, this means that we can generate new images entirely from no prior data. \nThe way it works is similar to a thief and police story. Imagine that a thief always wants to generate fake notes (mimic actual images distribution / mimic actual images (pixel combinations) ) and fool the police to get away with it. Police, on the other hand, wants to determine ways to detect fake notes (To detect a sample that comes from generated probability distribution). It is like a constant mutual development process. \nOur stable state is having an equally trained Discriminator (Police to catch fake notes) and Generator (Skilled criminal to mimic currency). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9172001919807207,
        0.8141883790568839,
        0.9344212403123966,
        0.9930984801599445,
        0.960250489074316,
        0.9638438121661603
      ],
      "excerpt": "We pass random noise again through Generator to generate fake images. We pass this fake images labelled as True ,(To fool the discriminator) through the discriminator. When passed through Discriminator (Police), we will know the places where we fail to fool the police. Notice the differences and we(Criminal/Generator) work on them. Note that we work on Police's current state of mind, which  means we keep discriminator untrianed during this process. \nknow the places where we fail to fool the police == Compute loss \nNotice the differences and work on them  == Compute gradients and update weights of generator \nThere's an interesting hypothesis given in DCGAN(Deep Convolutional GAN) paper that there are structures in the random noise vectors which enforce meaningful and consistent impact on the generator. Example given below, is from the DCGAN paper, you could see that when input noise vectors of men are manipulated, images of women with glasses are generated from generator when resulting (manipulated) noise vector is fed. This is impressive and you could also notice that this is similar to arithmetic involved in word embeddings' famous example of King - Man + Woman = Queen \nIf you've gone through the above description of GANs, you might have understood that generator generates samples from random noise(Entangled Representation). Wouldn't it be nice if we input a known vector (Disentangled representation) instead of random noise ? Let's say I want to generate handwritten images of a given number. This (Label ===> model ==> image) is the reverse of image classification (image ===> model ==> Label). We are passing in conditional information to the generator for producing images. On the other hand, instead of making the discriminator just classify the images real/fake we pass the label along with the image. Now discriminating, it is classifying whether the label given to the input image is true/not. \nBecause when passing real world data like faces,images of buildings, there are a lot of hidden concepts a.k.a Latent concepts. Neural Networks are capable of capturing this latent concepts well because of their non-linear activation functions. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8612723872733375,
        0.8804301861020609
      ],
      "excerpt": "For the generator we pass in Z (Random Noise) along with C (categorical distribution). Note that C's distribution may vary with the application to Gaussian / whatever. If it is a categorical distribution, you expect each dimension in C to hold some information regarding shape, rotation etc. For example, [0 0 0 1] may represent a latent concept like rotation. We start with a uniformly distributed C [0.2 0.2 0.2 0.2 0.2]. \nAnd with the training process, we expect neural network architecture to update C. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8461022731303705
      ],
      "excerpt": "Process is similar, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A demo script explaining InfoGAN on MNIST Dataset",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Murali81/InfoGAN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Sat, 25 Dec 2021 15:01:32 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/gitlost-murali/InfoGAN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "gitlost-murali/InfoGAN",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Murali81/InfoGAN/master/InfoGAN.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.809743223596325
      ],
      "excerpt": "A demo script explaining InfoGAN on MNIST Dataset \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/gitlost-murali/InfoGAN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "InfoGAN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "InfoGAN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "gitlost-murali",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/gitlost-murali/InfoGAN/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 15:01:32 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1609.03499",
      "https://arxiv.org/abs/1611.09482",
      "https://arxiv.org/abs/1711.10433"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9896978521113555,
        0.9292667041145718,
        0.955057295555343
      ],
      "excerpt": "Keras implementation of Wavenet (https://arxiv.org/abs/1609.03499). \nAlso includes an implementation of Fast/Queued Wavenet (https://arxiv.org/abs/1611.09482) \nAnd an implementation of Parallel Wavenet (https://arxiv.org/abs/1711.10433). \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/PhilippeNguyen/keras_wavenet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-12-17T23:12:52Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-22T22:33:28Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9800848002782397,
        0.8921015598442716
      ],
      "excerpt": "The Wavenet and Fast Wavenet implementations are based off the Nsynth implementations (https://github.com/tensorflow/magenta/tree/master/magenta/models/nsynth), but now are written using Keras layers instead of using pure tensorflow. I hope you find that this implementation is more flexible, easier to read, and easier to modify. I have some small modifications to the original model, which I'll list in a section below. \nMy Parallel Wavenet implementation reads in a trained Keras Wavenet model and uses this to train a Parallel/Student Wavenet. The Parallel Wavenet paper leaves out some details which I've filled in with some educated guesses, though there's no guarantees it's correct. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "keras implementation of wavenet/parallel wavenet",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/PhilippeNguyen/keras_wavenet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Wed, 29 Dec 2021 18:48:56 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/PhilippeNguyen/keras_wavenet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "PhilippeNguyen/keras_wavenet",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/PhilippeNguyen/keras_wavenet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "keras_wavenet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "keras_wavenet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "PhilippeNguyen",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/PhilippeNguyen/keras_wavenet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "For original Wavenet:\n * keras\n * numpy\n * scipy\n * librosa\n\n The original Wavenet implementation outputs a sparse categorical distribution, which can be trained with any keras backend. The discretized mixture of logistics distribution requires tensorflow_probability\n\nIn addition to the above, for Fast/Queued Wavenet:\n * tensorflow\n\nIn addition to the above, for Parallel Wavenet:\n * tensorflow_probability\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 10,
      "date": "Wed, 29 Dec 2021 18:48:56 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "For training the original wavenet, use the build_wavenet.py script.\nHopefully I've organized the code well enough to make it simple to modify. The build_model function in the build_wavenet.py script will build the complete model.\n * keras_wavenet/layers/wavenet provides specific keras layers used in the Wavenet model.\n * keras_wavenet/model/wavenet provides some of the larger structures used in the wavenet model. For example, res_block builds the residual block core of the wavenet model. It's these functions/structures which you will want to look at/modify if you want to create a wavenet-like model for a different domain.\n\nOnce you have a trained wavenet, you can generate samples from it using the Fast/Queued Wavenet algorithm. Use the run_wavenet.py script.\n\nIf you have a trained wavenet, you can also use it to train a parallel wavenet using build_parallel_wavenet.py.\n",
      "technique": "Header extraction"
    }
  ]
}
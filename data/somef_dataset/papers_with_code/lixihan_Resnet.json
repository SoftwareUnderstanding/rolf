{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "For more information regarding resnet, please go to https://github.com/KaimingHe/deep-residual-networks and http://arxiv.org/abs/1512.03385.\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lixihan/Resnet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-10-10T10:07:18Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-11-05T11:38:07Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9628098051448947
      ],
      "excerpt": "This repository contains the residual network model to classify the SIGNS dataset. In recent years, neural networks have become deeper and deeper. They can represent complex functions and learn features at many different levels of abstraction, from edges (at the lower layers) to very complex features (at the deeper layers). However, they have a huge problem: vanishing gradients. To tackle this problem, residual networks have been created. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9595966237685009,
        0.9260898634530068
      ],
      "excerpt": "The ResNet block with \"skip connection\" can easily learn an identity function. Adding more ResNet blocks to the middle/end of a big neural network doesn't hurt the performance and doesn't really hurt the neural network compared with the simpler version. \nThere are two different Resnet blocks in this model: the identity block and the convolutional block. The identity block is the standard block in ResNets. The input activation has the same dimension as the output activation. The settings for the convolutional blocks are: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9600590343448435
      ],
      "excerpt": "The identity block is implemented in identity_block(X, f, filters, stage, block), and the architecture is: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9491317773680714,
        0.9158980122941915,
        0.9083227222783463
      ],
      "excerpt": "The convolutional block is implemented in convolutional_block(X, f, filters, stage, block, s = 2), and the architecture is: \nBased on the identity block and the convolutional block, the final architecture is shown as follows: \nThe details of the ResNet architecture: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9275990173187545,
        0.9693126979483818,
        0.9693126979483818,
        0.9693126979483818,
        0.9693126979483818
      ],
      "excerpt": "Stage 1: CONV2D has 64 filters of shape (7,7) and uses a stride of (2,2). MaxPooling uses a (3,3) window and a (2,2) stride. \nStage 2: The convolutional block uses 3 set of filters of size [64,64,256], f=3, and s=1. The 2 identity blocks use 3 set of filters of size [64,64,256], and f=3. \nStage 3: The convolutional block uses 3 set of filters of size [128,128,512], f=3, and s=2. The 3 identity blocks use 3 set of filters of size [128,128,512], and f=3. \nStage 4: The convolutional block uses 3 set of filters of size [256, 256, 1024], f=3, and s=2. The 5 identity blocks use 3 set of filters of size [256, 256, 1024], and f=3. \nStage 5: The convolutional block uses 3 set of filters of size [512, 512, 2048], f=3, and s=2. The 2 identity blocks use 3 set of filters of size [512, 512, 2048], and f=3. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9878536867144995,
        0.9641884044288463
      ],
      "excerpt": "The model is implemented in ResNet50(input_shape = (64, 64, 3), classes = 6) based on Keras. \nThe SIGNS data set is of the shape (64, 64, 3). There are 6 classes, representing number from 0 to 6. Each data point is a gesture picture corresponding to the number. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9497363803586905
      ],
      "excerpt": "(2) prepare_image: conduct the pre-processing of the image. Obtain the image as the input. Convert the image into the RGB format. Adjust the dimensions of the image to (64, 64, 3). Conduct mean subtraction and feature scaling.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Residual Network for SIGNS dataset",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lixihan/Resnet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 21:32:59 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lixihan/Resnet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "lixihan/Resnet",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/lixihan/Resnet/master/ResNet-Xihan.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9786951994046935,
        0.8837680365796365
      ],
      "excerpt": "To set up the environment, you need to satisfy the following requirements: \n| Python        |            2.7|  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.956696558938904,
        0.9979947896609701,
        0.8363561834341373
      ],
      "excerpt": "Befofore running the API, you need to set up the environment based on the requirements. To run the requirements: \n$ pip install -r requirements.txt \nTest the API based on the following steps: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.895316127703052,
        0.8815199928591164
      ],
      "excerpt": "| number of training examples|              1080|  \n|     number of test examples|               120| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8086108647863313
      ],
      "excerpt": "| Tensorflow    |         1.10.0| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8197854736643756
      ],
      "excerpt": "(1) Prepare a sample picture sample.jpg for classfication.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8471240950275255
      ],
      "excerpt": "$ curl -X POST -F image=@sample.jpg 'http://localhost:5000/predict' \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lixihan/Resnet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Resnet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Resnet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "lixihan",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lixihan/Resnet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Run the model:\n\nmodel = ResNet50(input_shape = (64, 64, 3), classes = 6)\n\n2. Before training the model, compile the model:\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nWe use Adam as the optimizer, the categorical cross-entropy loss as the loss function, and accuracy as the evaluation metric.\n\n3. Fit the model:\n\nmodel.fit(X_train, Y_train, epochs = 10, batch_size = 32)\n\nWe use 10 epochs for fitting. Try other epochs can achieve different results. Better performance can be achieved for ~20 epochs, but this would be time-consuming on a CPU.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 21:32:59 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] CK S\u00f8nderby,\nT Raiko,\nL Maal\u00f8e,\nSK S\u00f8nderby,\nO Winther.\n_Ladder Variational Autoencoders_, NIPS 2016\n\n[2] L Maal\u00f8e, M Fraccaro, V Li\u00e9vin, O Winther.\n_BIVA: A Very Deep Hierarchy of Latent Variables for Generative Modeling_,\nNeurIPS 2019\n\n[3] DP Kingma,\nT Salimans,\nR Jozefowicz,\nX Chen,\nI Sutskever,\nM Welling.\n_Improved Variational Inference with Inverse Autoregressive Flow_,\nNIPS 2016\n\n[4] I Higgins, L Matthey, A Pal, C Burgess, X Glorot, M Botvinick, \nS Mohamed, A Lerchner.\n_beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework_,\nICLR 2017\n\n[5] Y Burda, RB Grosse, R Salakhutdinov.\n_Importance Weighted Autoencoders_,\nICLR 2016\n\n[6] T Salimans, A Karpathy, X Chen, DP Kingma.\n_PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications_,\nICLR 2017\n\n[7] H Larochelle, I Murray.\n_The neural autoregressive distribution estimator_,\nAISTATS 2011\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9625923568277878
      ],
      "excerpt": "| multi-dSprites (0-2) | 12         | 26.9         | 23.2          |     | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "| CIFAR10              | 15         | 7128 (3.35)  | 7068 (3.32)   |     | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8187756947909643
      ],
      "excerpt": "Gated residual blocks (--gated). \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/addtt/ladder-vae-pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-12-05T14:12:01Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-14T19:43:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9598235882618746
      ],
      "excerpt": "PyTorch implementation of Ladder Variational Autoencoders (LVAE) [1]: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "with diagonal covariance. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8722350907195175
      ],
      "excerpt": "rather than only on the layer above (see for example [2]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8590115006753323
      ],
      "excerpt": "- free bits [3] instead of beta annealing [4] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8220600652433817,
        0.9865031337936674
      ],
      "excerpt": "  likelihood lower bound. The bound converges to the actual log likelihood as  \n  the number of samples goes to infinity [5]. Note that the model is always \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8585192543170297,
        0.9233063682895661
      ],
      "excerpt": "- Each pixel in the images is modeled independently. The likelihood is Bernoulli \n  for binary images, and discretized mixture of logistics with 10  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9557125146197823,
        0.8611569009609668
      ],
      "excerpt": "- One day I'll get around to evaluating the IW bound on all datasets with 10000 samples. \nStatically binarized MNIST [7], see Hugo Larochelle's website http://www.cs.toronto.edu/~larocheh/public/datasets/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8742782758689281,
        0.8056005287421447
      ],
      "excerpt": "CelebA rescaled and cropped to 64x64 &ndash; see code for details. The path in experiment.data.DatasetLoader has to be modified \nbinary multi-dSprites: 64x64 RGB shapes (0 to 2) in each image \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8451420038513869
      ],
      "excerpt": "We can get a rough idea of what's going on at layer i as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9176915446864808
      ],
      "excerpt": "  that they are all conditioned on the same samples. These correspond to one  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.846278042912959
      ],
      "excerpt": "For each of these samples (each small image in the images below), pick the  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.950850065458263
      ],
      "excerpt": "z for layers i+1 to L. These S samples are shown in one row of the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8294259974060083,
        0.9567567444232322,
        0.9330341446603287,
        0.8214550309116078
      ],
      "excerpt": "from a low-level layer, as such layers mostly model local structure and details. \nHigher layers on the other hand model global structure, and we observe more and \nmore variability in each row as we move to higher layers. When the sampling  \nhappens in the top layer (i = L), all samples are completely independent,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9696817145794243
      ],
      "excerpt": "Downsampling by a factor of 2 in the beginning of inference. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9271233149836372,
        0.9017193225794307,
        0.8791102974944646
      ],
      "excerpt": "  multi-dSprites), and 3 times otherwise. The spatial size of the final feature  \n  map is always 2x2. \n  Between these downsampling steps there is approximately the same number of \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8150910968696733,
        0.9394449182630016,
        0.8351800233291372,
        0.8114802154263582
      ],
      "excerpt": "The deterministic parts of bottom-up and top-down architecture are (almost) \n  perfectly mirrored for simplicity. \nStochastic layers have spatial random variables, and the number of rvs per \n  \"location\" (i.e. number of channels of the feature map after sampling from a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8581151507159371,
        0.8602330278599576
      ],
      "excerpt": "All other feature maps in deterministic paths have 64 channels. \nSkip connections in the generative model (--skip). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8436226262537605,
        0.9693731986130547,
        0.9344171159357898,
        0.9106886456438802
      ],
      "excerpt": "Learned prior of the top layer (--learn-top-prior). \nA form of data-dependent initialization of weights (--data-dep-init). \n  See code for details. \nfreebits=1.0 in experiments with more than 6 stochastic layers, and 0.5 for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Ladder Variational Autoencoders (LVAE) in PyTorch",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/addtt/ladder-vae-pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Thu, 30 Dec 2021 06:54:19 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/addtt/ladder-vae-pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "addtt/ladder-vae-pytorch",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npip install -r requirements.txt\nCUDA_VISIBLE_DEVICES=0 python main.py --zdims 32 32 32 --downsample 1 1 1 --nonlin elu --skip --blocks-per-layer 4 --gated --freebits 0.5 --learn-top-prior --data-dep-init --seed 42 --dataset static_mnist\n```\n\nDependencies include [boilr](https://github.com/addtt/boiler-pytorch) (a framework \nfor PyTorch) and [multiobject](https://github.com/addtt/multi-object-datasets)\n(which provides multi-object datasets with PyTorch dataloaders).\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8722222714191809
      ],
      "excerpt": "- One day I'll get around to evaluating the IW bound on all datasets with 10000 samples. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8257130296916612
      ],
      "excerpt": "  that they are all conditioned on the same samples. These correspond to one  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8464328765661114
      ],
      "excerpt": "|  dataset             | num layers | -ELBO        | - log p(x) \u2264 <br> [100 iws] | - log p(x) \u2264 <br> [1000 iws] | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.811854372964597
      ],
      "excerpt": "| SVHN                 | 15         | 4012 (1.88)  | 3973 (1.87)   |     | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8027198740027641
      ],
      "excerpt": "  trained with the ELBO (1 sample). \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/addtt/ladder-vae-pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Andrea Dittadi\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Ladder Variational Autoencoders (LVAE)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ladder-vae-pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "addtt",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/addtt/ladder-vae-pytorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npip install -r requirements.txt\nCUDA_VISIBLE_DEVICES=0 python main.py --zdims 32 32 32 --downsample 1 1 1 --nonlin elu --skip --blocks-per-layer 4 --gated --freebits 0.5 --learn-top-prior --data-dep-init --seed 42 --dataset static_mnist\n```\n\nDependencies include [boilr](https://github.com/addtt/boiler-pytorch) (a framework \nfor PyTorch) and [multiobject](https://github.com/addtt/multi-object-datasets)\n(which provides multi-object datasets with PyTorch dataloaders).\n\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npip install -r requirements.txt\nCUDA_VISIBLE_DEVICES=0 python main.py --zdims 32 32 32 --downsample 1 1 1 --nonlin elu --skip --blocks-per-layer 4 --gated --freebits 0.5 --learn-top-prior --data-dep-init --seed 42 --dataset static_mnist\n```\n\nDependencies include [boilr](https://github.com/addtt/boiler-pytorch) (a framework \nfor PyTorch) and [multiobject](https://github.com/addtt/multi-object-datasets)\n(which provides multi-object datasets with PyTorch dataloaders).\n\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 58,
      "date": "Thu, 30 Dec 2021 06:54:19 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "generative-models",
      "vae",
      "variational-inference",
      "ladder-vae",
      "unsupervised-learning",
      "variational-autoencoders",
      "ladder-variational-autoencoders",
      "representation-learning"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npip install -r requirements.txt\nCUDA_VISIBLE_DEVICES=0 python main.py --zdims 32 32 32 --downsample 1 1 1 --nonlin elu --skip --blocks-per-layer 4 --gated --freebits 0.5 --learn-top-prior --data-dep-init --seed 42 --dataset static_mnist\n```\n\nDependencies include [boilr](https://github.com/addtt/boiler-pytorch) (a framework \nfor PyTorch) and [multiobject](https://github.com/addtt/multi-object-datasets)\n(which provides multi-object datasets with PyTorch dataloaders).\n\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
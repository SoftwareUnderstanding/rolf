{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "BERT pytorch is from: https://github.com/huggingface/pytorch-pretrained-BERT <br/>\r\nBERT: https://github.com/google-research/bert <br/>\r\nWe also used some code from: https://github.com/kevinduh/san_mrc <br/>\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1904.09482",
      "https://arxiv.org/abs/1907.11983",
      "https://arxiv.org/abs/1908.03265",
      "https://arxiv.org/abs/1911.03437",
      "https://arxiv.org/abs/2002.07972",
      "https://arxiv.org/abs/2004.08994",
      "https://arxiv.org/abs/1904.09482",
      "https://arxiv.org/abs/1907.11983",
      "https://arxiv.org/abs/1908.03265",
      "https://arxiv.org/abs/1911.03437"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n```\r\n@inproceedings{liu2019mt-dnn,\r\n    title = \"Multi-Task Deep Neural Networks for Natural Language Understanding\",\r\n    author = \"Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng\",\r\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\r\n    month = jul,\r\n    year = \"2019\",\r\n    address = \"Florence, Italy\",\r\n    publisher = \"Association for Computational Linguistics\",\r\n    url = \"https://www.aclweb.org/anthology/P19-1441\",\r\n    pages = \"4487--4496\"\r\n}\r\n\r\n\r\n@article{liu2019mt-dnn-kd,\r\n  title={Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding},\r\n  author={Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng},\r\n  journal={arXiv preprint arXiv:1904.09482},\r\n  year={2019}\r\n}\r\n\r\n\r\n@article{he2019hnn,\r\n  title={A Hybrid Neural Network Model for Commonsense Reasoning},\r\n  author={He, Pengcheng and Liu, Xiaodong and Chen, Weizhu and Gao, Jianfeng},\r\n  journal={arXiv preprint arXiv:1907.11983},\r\n  year={2019}\r\n}\r\n\r\n\r\n@article{liu2019radam,\r\n  title={On the Variance of the Adaptive Learning Rate and Beyond},\r\n  author={Liu, Liyuan and Jiang, Haoming and He, Pengcheng and Chen, Weizhu and Liu, Xiaodong and Gao, Jianfeng and Han, Jiawei},\r\n  journal={arXiv preprint arXiv:1908.03265},\r\n  year={2019}\r\n}\r\n\r\n\r\n@article{jiang2019smart,\r\n  title={SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization},\r\n  author={Jiang, Haoming and He, Pengcheng and Chen, Weizhu and Liu, Xiaodong and Gao, Jianfeng and Zhao, Tuo},\r\n  journal={arXiv preprint arXiv:1911.03437},\r\n  year={2019}\r\n}\r\n```\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{jiang2019smart,\n  title={SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization},\n  author={Jiang, Haoming and He, Pengcheng and Chen, Weizhu and Liu, Xiaodong and Gao, Jianfeng and Zhao, Tuo},\n  journal={arXiv preprint arXiv:1911.03437},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{liu2019radam,\n  title={On the Variance of the Adaptive Learning Rate and Beyond},\n  author={Liu, Liyuan and Jiang, Haoming and He, Pengcheng and Chen, Weizhu and Liu, Xiaodong and Gao, Jianfeng and Han, Jiawei},\n  journal={arXiv preprint arXiv:1908.03265},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{he2019hnn,\n  title={A Hybrid Neural Network Model for Commonsense Reasoning},\n  author={He, Pengcheng and Liu, Xiaodong and Chen, Weizhu and Gao, Jianfeng},\n  journal={arXiv preprint arXiv:1907.11983},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{liu2019mt-dnn-kd,\n  title={Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding},\n  author={Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng},\n  journal={arXiv preprint arXiv:1904.09482},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{liu2019mt-dnn,\n    title = \"Multi-Task Deep Neural Networks for Natural Language Understanding\",\n    author = \"Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng\",\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P19-1441\",\n    pages = \"4487--4496\"\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9993510466769998,
        0.8388711920974846,
        0.9222383658450612
      ],
      "excerpt": "Xiaodong Liu*, Pengcheng He*, Weizhu Chen and Jianfeng Gao<br/> \nMulti-Task Deep Neural Networks for Natural Language Understanding<br/> \nACL 2019 <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9993510466769998,
        0.8475604207426413,
        0.9402107675288106,
        0.9993510466769998
      ],
      "excerpt": "Xiaodong Liu, Pengcheng He, Weizhu Chen and Jianfeng Gao<br/> \nImproving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding <br/> \narXiv version <br/> \nPengcheng He, Xiaodong Liu, Weizhu Chen and Jianfeng Gao<br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9402107675288106,
        0.9999594644859255
      ],
      "excerpt": "arXiv version <br/> \nLiyuan Liu, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao and Jiawei Han <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9402107675288106,
        0.9993510466769998
      ],
      "excerpt": "arXiv version <br/> \nHaoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao and Tuo Zhao <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9402107675288106,
        0.999998599486631
      ],
      "excerpt": "arXiv version <br/> \nXiaodong Liu, Yu Wang, Jianshu Ji, Hao Cheng, Xueyun Zhu, Emmanuel Awa, Pengcheng He, Weizhu Chen, Hoifung Poon, Guihong Cao, Jianfeng Gao<br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9402107675288106,
        0.999994661998742
      ],
      "excerpt": "arXiv version <br/> \nXiaodong Liu, Hao Cheng, Pengcheng He, Weizhu Chen, Yu Wang, Hoifung Poon and Jianfeng Gao<br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9402107675288106
      ],
      "excerpt": "arXiv version <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.890734504593722,
        0.8868183352878298,
        0.890734504593722
      ],
      "excerpt": "Pretrained UniLM: https://github.com/microsoft/unilm <br/> \nPretrained Response Generation Model: https://github.com/microsoft/DialoGPT <br/> \nInternal MT-DNN repo: https://github.com/microsoft/mt-dnn <br/> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/microsoft/MT-DNN/master/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/microsoft/MT-DNN",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nFor help or issues using MT-DNN, please submit a GitHub issue.\r\n\r\nFor personal communication related to this package, please contact Xiaodong Liu (`xiaodl@microsoft.com`), Yu Wang (`yuwan@microsoft.com`), Pengcheng He (`penhe@microsoft.com`), Weizhu Chen (`wzchen@microsoft.com`), Jianshu Ji (`jianshuj@microsoft.com`), Emmanuel Awa (`Emmanuel.Awa@microsoft.com`) or Jianfeng Gao (`jfgao@microsoft.com`).\r\n\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-14T19:25:46Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T14:31:07Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9940965247914962,
        0.9912497947153934,
        0.9793556792400642
      ],
      "excerpt": "MT-DNN, an open-source natural language understanding (NLU) toolkit that makes it easy for researchers and developers to train customized deep learning models. Built upon PyTorch and Transformers, MT-DNN is designed to facilitate rapid customization for a broad spectrum of NLU tasks, using a variety of objectives (classification, regression, structured prediction) and text encoders (e.g., RNNs, BERT, RoBERTa, UniLM).   \nA unique feature of MT-DNN is its built-in support for robust and transferable learning using the adversarial multi-task learning paradigm. To enable efficient production deployment, MT-DNN supports multi-task knowledge distillation, which can substantially compress a deep neural model without significant performance drop.  We demonstrate the effectiveness of MT-DNN on a wide range of NLU applications across general and biomedical domains.   \nThis repository is a pip installable package that implements the Multi-Task Deep Neural Networks (MT-DNN) for Natural Language Understanding, as described in the following papers: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8577707596151322
      ],
      "excerpt": "Multi-Task Deep Neural Networks for Natural Language Understanding<br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8022169834517647
      ],
      "excerpt": "Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8293830178244861
      ],
      "excerpt": "Hybrid Neural Network Model for Commonsense Reasoning <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8603346247000166
      ],
      "excerpt": "On the Variance of the Adaptive Learning Rate and Beyond <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8043338969028725
      ],
      "excerpt": "SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9137200099608279
      ],
      "excerpt": "The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8184885419971552
      ],
      "excerpt": "Adversarial Training for Large Neural Language Models <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8920761007244342,
        0.8899461251007105
      ],
      "excerpt": "Depending on what data_format you have set in the configuration object MTDNNConfig, please follow the detailed data format below to prepare your data: \nPremiseOnly : single text, i.e. premise. Data format is \"id\" \\t \"label\" \\t \"premise\" .   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9339145255847316
      ],
      "excerpt": "PremiseAndMultiHypothesis : one text as premise and multiple candidates of texts as hypothesis. Data format is \"id\" \\t \"label\" \\t \"premise\" \\t \"hypothesis_1\" \\t \"hypothesis_2\" \\t ... \\t \"hypothesis_n\".   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9427539812512333
      ],
      "excerpt": "Yes, we released the pretrained shared embedings via MTL which are aligned to BERT base/large models: mt_dnn_base.pt and mt_dnn_large.pt. </br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9967840874768388,
        0.9372790521094025
      ],
      "excerpt": "For SciTail/SNLI tasks, the purpose is to test generalization of the learned embedding and how easy it is adapted to a new domain instead of complicated model structures for a direct comparison with BERT. Thus, we use a linear projection on the all domain adaptation settings. \nThe difference is in the QNLI dataset. Please refere to the GLUE official homepage for more details. If you want to formulate QNLI as pair-wise ranking task as our paper, make sure that you use the old QNLI data. </br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.877601411872619,
        0.8670333488494621
      ],
      "excerpt": "If you have issues to access the old version of the data, please contact the GLUE team. \nWe can use the multi-task refinement model to run the prediction and produce a reasonable result. But to achieve a better result, it requires a fine-tuneing on each task. It is worthing noting the paper in arxiv is a littled out-dated and on the old GLUE dataset. We will update the paper as we mentioned below. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Multi-Task Deep Neural Networks for Natural Language Understanding",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/microsoft/MT-DNN/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 22,
      "date": "Wed, 29 Dec 2021 05:17:30 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/microsoft/MT-DNN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "microsoft/MT-DNN",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/microsoft/MT-DNN/master/docker/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/microsoft/MT-DNN/master/examples/classification/tc_mnli.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/microsoft/MT-DNN/master/scripts/download.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "A [setup.py](./setup.py) file is provided in order to simplify the installation of this package. \r\n\r\n1. To install the package, please run the command below (from directory root)  \r\n\r\n    ```Python\r\n    pip install -e .\r\n    ```\r\n\r\n1. Running the command tells pip to install the `mt-dnn` package from source in development mode. This just means that any updates to `mt-dnn` source directory will immediately be reflected in the installed package without needing to reinstall; a very useful practice for a package with constant updates.\r\n\r\n1. It is also possible to install directly from Github, which is the best way to utilize the package in external projects (while still reflecting updates to the source as it's installed as an editable '-e' package).\r\n\r\n    ```Python\r\n    pip install -e git+git@github.com:microsoft/mt-dnn.git@master#:egg=mtdnn\r\n    ```\r\n\r\n1. Either command, from above, makes `mt-dnn` available in your conda virtual environment. You can verify it was properly installed by running:\r\n \r\n    ```Python\r\n    pip list | grep mtdnn\r\n    ```  \r\n> For Mixed Precision and Distributed Training, please install NVIDIA apex by following instructions [here](https://github.com/NVIDIA/apex#linux)  \r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9256256881884376
      ],
      "excerpt": "Then run the prepro script with flags:   &gt; sh experiments/glue/prepro.sh --old_glue </br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8947626018990187
      ],
      "excerpt": "Pretrained UniLM: https://github.com/microsoft/unilm <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9353412455566276
      ],
      "excerpt": "Internal MT-DNN repo: https://github.com/microsoft/mt-dnn <br/> \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8259237418020459
      ],
      "excerpt": "PremiseAndMultiHypothesis : one text as premise and multiple candidates of texts as hypothesis. Data format is \"id\" \\t \"label\" \\t \"premise\" \\t \"hypothesis_1\" \\t \"hypothesis_2\" \\t ... \\t \"hypothesis_n\".   \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/microsoft/MT-DNN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'    MIT License\\r\\n\\r\\n    Copyright (c) Microsoft Corporation.\\r\\n\\r\\n    Permission is hereby granted, free of charge, to any person obtaining a copy\\r\\n    of this software and associated documentation files (the \"Software\"), to deal\\r\\n    in the Software without restriction, including without limitation the rights\\r\\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\r\\n    copies of the Software, and to permit persons to whom the Software is\\r\\n    furnished to do so, subject to the following conditions:\\r\\n\\r\\n    The above copyright notice and this permission notice shall be included in all\\r\\n    copies or substantial portions of the Software.\\r\\n\\r\\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\r\\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\r\\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\r\\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\r\\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\r\\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\r\\n    SOFTWARE\\r\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Multi-Task Deep Neural Networks for Natural Language Understanding",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "MT-DNN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "microsoft",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/microsoft/MT-DNN/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "awaemmanuel",
        "body": "## MTDNN v1.1.0 introduces components to build a full pipeline\r\n\r\nMTDNN v1.1.0 incorporates reusable components to build end to end NLU systems. The new additions include `MTDNNDataBuilder` and `MTDNNTokenizer`.  \r\n\r\n## Useful Links\r\n- Find installation instructions and steps [here](https://github.com/microsoft/MT-DNN/blob/master/README.md#pip-install-package).   \r\n - For instructions on how to use the package, please follow this [link](https://github.com/microsoft/MT-DNN/blob/master/README.md#how-to-use).  \r\n- To see MTDNN v1.1.0 in action, a Jupyter [notebook](https://github.com/microsoft/MT-DNN/blob/master/examples/classification/tc_mnli.ipynb) is provided to show a runnable example using the MNLI dataset [here](https://github.com/microsoft/MT-DNN/blob/master/README.md#run-an-example).   \r\n\r\n\r\n### Summary of Feature/v1.1.0 (#6)\r\n- Add Data Builder Component\r\n- Add Data Tokenizer Component\r\n- Update Process with Data Builder and Tokenizer\r\n- Create new process pipeline for the data\r\n- Add support for transformers\r\n- Add sample MNLI data versioned by Git LFS\r\n- Add support for MLM  \r\n- Update README instructions\r\n- Add: component governance files\r\n- Fix component governance dependency alerts\r\n- update dep for component governance alerts\r\n- Create Github Page with and set theme jekyll-theme-cayman\r\n- Update text classification example\r\n-  Update generate_requirements_txt.py",
        "dateCreated": "2020-07-02T01:40:38Z",
        "datePublished": "2020-07-02T01:58:18Z",
        "html_url": "https://github.com/microsoft/MT-DNN/releases/tag/v1.1.0",
        "name": "[v1.1.0] - MTDNN Full Pipeline Components ",
        "tag_name": "v1.1.0",
        "tarball_url": "https://api.github.com/repos/microsoft/MT-DNN/tarball/v1.1.0",
        "url": "https://api.github.com/repos/microsoft/MT-DNN/releases/28139127",
        "zipball_url": "https://api.github.com/repos/microsoft/MT-DNN/zipball/v1.1.0"
      },
      {
        "authorType": "User",
        "author_name": "awaemmanuel",
        "body": "**In this release, we package MT-DNN as a pip installable library ready to be absorbed in your NLU applications  directly from this repository.**\r\n\r\nMulti-Task Deep Neural Networks for Natural Language Understanding (MT-DNN), an open-source natural language understanding (NLU) toolkit that makes it easy for researchers and developers to train customized deep learning models. Built upon PyTorch and Transformers, MT-DNN is designed to facilitate rapid customization for a broad spectrum of NLU tasks, using a variety of objectives (classification, regression, structured prediction) and text encoders (e.g., RNNs, BERT, RoBERTa, UniLM). \r\n\r\nA unique feature of MT-DNN is its built-in support for robust and transferable learning using the adversarial multi-task learning paradigm. To enable efficient production deployment, MT-DNN supports multi-task knowledge distillation, which can substantially compress a deep neural model without significant performance drop. We demonstrate the effectiveness of MT-DNN on a wide range of NLU applications across general and biomedical domains.\r\n\r\n### Installation steps  \r\nFor instructions on installing this repo, please refer to this link: [Pip install Package](https://github.com/microsoft/mt-dnn/#pip-install-package) \r\n\r\n### How to use steps\r\nFor instructions on how to use the components provided in this library for your task, please refer to this: [How To Use](https://github.com/microsoft/mt-dnn/#how-to-use) \r\n\r\n### Learning more about MT-DNN\r\nFor more information about MT-DNN, please refer to the following papers:\r\n\r\n* [Multi-Task Deep Neural Networks for Natural Language Understanding - ACL 2019](https://aclweb.org/anthology/papers/P/P19/P19-1441/) - Xiaodong Liu,  Pengcheng He, Weizhu Chen and Jianfeng Gao\r\n\r\n\r\n* [Improving Multi-Task Deep Neural Networks via Knowledge Distillation for Natural Language Understanding](https://arxiv.org/abs/1904.09482) - Xiaodong Liu, Pengcheng He, Weizhu Chen and Jianfeng Gao\r\n\r\n\r\n* [Hybrid Neural Network Model for Commonsense Reasoning ](https://arxiv.org/abs/1907.11983) - Pengcheng He, Xiaodong Liu, Weizhu Chen and Jianfeng Gao  \r\n\r\n\r\n* [On the Variance of the Adaptive Learning Rate and Beyond](https://arxiv.org/abs/1908.03265) -  Liyuan Liu, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao and Jiawei Han\r\n\r\n\r\n* [SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization](https://arxiv.org/abs/1911.03437) - Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao and Tuo Zhao \r\n\r\n\r\n* [The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding ](https://arxiv.org/abs/2002.07972) - Xiaodong Liu, Yu Wang, Jianshu Ji, Hao Cheng, Xueyun Zhu, Emmanuel Awa, Pengcheng He, Weizhu Chen, Hoifung Poon, Guihong Cao, Jianfeng Gao  \r\n\r\n\r\n* [Adversarial Training for Large Neural Language Models](https://arxiv.org/abs/2004.08994) - Xiaodong Liu, Hao Cheng, Pengcheng He, Weizhu Chen, Yu Wang, Hoifung Poon and Jianfeng Gao\r\n\r\n",
        "dateCreated": "2020-03-26T14:57:59Z",
        "datePublished": "2020-07-02T01:41:58Z",
        "html_url": "https://github.com/microsoft/MT-DNN/releases/tag/v1.0.0",
        "name": "MT-DNN: Now Pip installable ",
        "tag_name": "v1.0.0",
        "tarball_url": "https://api.github.com/repos/microsoft/MT-DNN/tarball/v1.0.0",
        "url": "https://api.github.com/repos/microsoft/MT-DNN/releases/26089430",
        "zipball_url": "https://api.github.com/repos/microsoft/MT-DNN/zipball/v1.0.0"
      }
    ],
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "An example Jupyter [notebook](./examples/classification/tc_mnli.ipynb) is provided to show a runnable example using the MNLI dataset. The notebook reads and loads the MNLI data provided for your convenience [here](./sample_data).  This dataset is mainly used for natural language inference (NLI) tasks, where the inputs are sentence pairs and the labels are entailment indicators.  \r\n\r\n> **NOTE:** The MNLI data is very large and would need [Git LFS](https://docs.github.com/en/github/managing-large-files/installing-git-large-file-storage) installed on your machine to pull it down.  \r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 103,
      "date": "Wed, 29 Dec 2021 05:17:30 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "natural-language-processing",
      "mt-dnn",
      "natural-language-understanding",
      "multi-task-learning"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "An example Jupyter [notebook](./examples/classification/tc_mnli.ipynb) is provided to show a runnable example using the MNLI dataset. The notebook reads and loads the MNLI data provided for your convenience [here](./sample_data).  This dataset is mainly used for natural language inference (NLI) tasks, where the inputs are sentence pairs and the labels are entailment indicators.  \r\n\r\n> **NOTE:** The MNLI data is very large and would need [Git LFS](https://docs.github.com/en/github/managing-large-files/installing-git-large-file-storage) installed on your machine to pull it down.  \r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n\r\n1. Create a model configuration object, `MTDNNConfig`, with the necessary parameters to initialize the MT-DNN model. Initialization without any parameters will default to a similar configuration that initializes a BERT model. This configuration object can be initialized wit training and learning parameters like `batch_size` and `learning_rate`. Please consult the class implementation for all parameters.   \r\n\r\n    ```Python\r\n    BATCH_SIZE = 16\r\n    MULTI_GPU_ON = True\r\n    MAX_SEQ_LEN = 128\r\n    NUM_EPOCHS = 5\r\n    config = MTDNNConfig(batch_size=BATCH_SIZE, \r\n                        max_seq_len=MAX_SEQ_LEN, \r\n                        multi_gpu_on=MULTI_GPU_ON)\r\n    ```\r\n\r\n1. Define the task parameters to train for and initialize an `MTDNNTaskDefs` object. Definition can be a single or multiple tasks to train. MTDNNTaskDefs can take a python dict, yaml or json file with task(s) defintion. \r\n\r\n    ```Python\r\n    DATA_DIR = \"../../sample_data/\"\r\n    DATA_SOURCE_DIR = os.path.join(DATA_DIR, \"MNLI\")\r\n    tasks_params = {\r\n                    \"mnli\": {\r\n                        \"data_format\": \"PremiseAndOneHypothesis\",\r\n                        \"encoder_type\": \"BERT\",\r\n                        \"dropout_p\": 0.3,\r\n                        \"enable_san\": True,\r\n                        \"labels\": [\"contradiction\", \"neutral\", \"entailment\"],\r\n                        \"metric_meta\": [\"ACC\"],\r\n                        \"loss\": \"CeCriterion\",\r\n                        \"kd_loss\": \"MseCriterion\",\r\n                        \"n_class\": 3,\r\n                        \"split_names\": [\r\n                            \"train\",\r\n                            \"dev_matched\",\r\n                            \"dev_mismatched\",\r\n                            \"test_matched\",\r\n                            \"test_mismatched\",\r\n                        ],\r\n                        \"data_source_dir\": DATA_SOURCE_DIR,\r\n                        \"data_process_opts\": {\"header\": True, \"is_train\": True, \"multi_snli\": False,},\r\n                        \"task_type\": \"Classification\",\r\n                    },\r\n                }\r\n\r\n    #: Define the tasks\r\n    task_defs = MTDNNTaskDefs(tasks_params)\r\n    ```\r\n\r\n1. Create a data tokenizing object, `MTDNNTokenizer`. Based on the model initial checkpoint, it wraps around the model's Huggingface transformers library to encode the data to **MT-DNN** format. This becomes the input to the data building stage.  \r\n\r\n    ```\r\n    tokenizer = MTDNNTokenizer(do_lower_case=True)\r\n\r\n    #: Testing out the tokenizer  \r\n    print(tokenizer.encode(\"What NLP toolkit do you recommend\", \"MT-DNN is a fantastic toolkit\"))  \r\n    \r\n    #: ([101, 2054, 17953, 2361, 6994, 23615, 2079, 2017, 16755, 102, 11047, 1011, 1040, 10695, 2003, 1037, 10392, 6994, 23615, 102], None, [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\r\n    ```\r\n\r\n1. Create a data preprocessing object, `MTDNNDataBuilder`. This class is responsible for converting the data into the MT-DNN format depending on the task. This object is responsible for creating the vectorized data for each task.   \r\n\r\n    ```\r\n    #:#: Load and build data\r\n    data_builder = MTDNNDataBuilder(tokenizer=tokenizer,\r\n                                    task_defs=task_defs,\r\n                                    data_dir=DATA_SOURCE_DIR,\r\n                                    canonical_data_suffix=\"canonical_data\",\r\n                                    dump_rows=True)\r\n\r\n    #:#: Build data to MTDNN Format as an iterable of each specific task\r\n    vectorized_data = data_builder.vectorize()\r\n    ```\r\n \r\n1. Create a data preprocessing object, `MTDNNDataProcess`. This creates the training, test and development PyTorch dataloaders needed for training and testing. We also need to retrieve the necessary training options required to initialize the model correctly, for all tasks.  \r\n\r\n    ```Python\r\n    data_processor = MTDNNDataProcess(config=config, \r\n                                    task_defs=task_defs, \r\n                                    vectorized_data=vectorized_data)\r\n\r\n    #: Retrieve the multi task train, dev and test dataloaders\r\n    multitask_train_dataloader = data_processor.get_train_dataloader()\r\n    dev_dataloaders_list = data_processor.get_dev_dataloaders()\r\n    test_dataloaders_list = data_processor.get_test_dataloaders()\r\n\r\n    #: Get training options to initialize model\r\n    decoder_opts = data_processor.get_decoder_options_list()\r\n    task_types = data_processor.get_task_types_list()\r\n    dropout_list = data_processor.get_tasks_dropout_prob_list()\r\n    loss_types = data_processor.get_loss_types_list()\r\n    kd_loss_types = data_processor.get_kd_loss_types_list()\r\n    tasks_nclass_list = data_processor.get_task_nclass_list()\r\n    num_all_batches = data_processor.get_num_all_batches()\r\n    ```\r\n\r\n1. Now we can create an `MTDNNModel`. \r\n    ```Python\r\n    model = MTDNNModel(\r\n        config,\r\n        task_defs,\r\n        pretrained_model_name=\"bert-base-uncased\",\r\n        num_train_step=num_all_batches,\r\n        decoder_opts=decoder_opts,\r\n        task_types=task_types,\r\n        dropout_list=dropout_list,\r\n        loss_types=loss_types,\r\n        kd_loss_types=kd_loss_types,\r\n        tasks_nclass_list=tasks_nclass_list,\r\n        multitask_train_dataloader=multitask_train_dataloader,\r\n        dev_dataloaders_list=dev_dataloaders_list,\r\n        test_dataloaders_list=test_dataloaders_list,\r\n    )\r\n    ```\r\n1. At this point the MT-DNN model allows us to fit to the model and create predictions. The fit takes an optional `epochs` parameter that overwrites the epochs set in the `MTDNNConfig` object. \r\n\r\n    ```Python\r\n    model.fit(epochs=NUM_EPOCHS)\r\n    ```\r\n\r\n\r\n1. The predict function can take an optional checkpoint, `trained_model_chckpt`. This can be used for inference and running evaluations on an already trained PyTorch MT-DNN model.  \r\nOptionally using a previously trained model as checkpoint.  \r\n\r\n    ```Python\r\n    #: Predict using a PyTorch model checkpoint\r\n    checkpt = \"./checkpoint/model_4.pt\"\r\n    model.predict(trained_model_chckpt=checkpt)\r\n\r\n    ```\r\n\r\n",
      "technique": "Header extraction"
    }
  ]
}
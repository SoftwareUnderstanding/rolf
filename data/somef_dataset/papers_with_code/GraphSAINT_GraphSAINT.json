{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Supported by DARPA under FA8750-17-C-0086, NSF under CCF-1919289 and OAC-1911229.\n\nWe thank Matthias Fey for providing a [reference implementation](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.GraphSAINTSampler) in the PyTorch Geometric library.\n\nWe thank the [OGB team](https://ogb.stanford.edu/) for using GraphSAINT on large scale experiments.\n\n* ICLR 2020:\n\n```\n@inproceedings{graphsaint-iclr20,\ntitle={{GraphSAINT}: Graph Sampling Based Inductive Learning Method},\nauthor={Hanqing Zeng and Hongkuan Zhou and Ajitesh Srivastava and Rajgopal Kannan and Viktor Prasanna},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJe8pkHFwS}\n}\n```\n\n\n* IEEE/IPDPS 2019:\n\n\n```\n@INPROCEEDINGS{graphsaint-ipdps19,\nauthor={Hanqing Zeng and Hongkuan Zhou and Ajitesh Srivastava and Rajgopal Kannan and Viktor Prasanna},\nbooktitle={2019 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},\ntitle={Accurate, Efficient and Scalable Graph Embedding},\nyear={2019},\nmonth={May},\n}\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1907.10903"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Supported by DARPA under FA8750-17-C-0086, NSF under CCF-1919289 and OAC-1911229.\n\nWe thank Matthias Fey for providing a [reference implementation](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.GraphSAINTSampler) in the PyTorch Geometric library.\n\nWe thank the [OGB team](https://ogb.stanford.edu/) for using GraphSAINT on large scale experiments.\n\n* ICLR 2020:\n\n```\n@inproceedings{graphsaint-iclr20,\ntitle={{GraphSAINT}: Graph Sampling Based Inductive Learning Method},\nauthor={Hanqing Zeng and Hongkuan Zhou and Ajitesh Srivastava and Rajgopal Kannan and Viktor Prasanna},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJe8pkHFwS}\n}\n```\n\n\n* IEEE/IPDPS 2019:\n\n\n```\n@INPROCEEDINGS{graphsaint-ipdps19,\nauthor={Hanqing Zeng and Hongkuan Zhou and Ajitesh Srivastava and Rajgopal Kannan and Viktor Prasanna},\nbooktitle={2019 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},\ntitle={Accurate, Efficient and Scalable Graph Embedding},\nyear={2019},\nmonth={May},\n}\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@INPROCEEDINGS{graphsaint-ipdps19,\nauthor={Hanqing Zeng and Hongkuan Zhou and Ajitesh Srivastava and Rajgopal Kannan and Viktor Prasanna},\nbooktitle={2019 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},\ntitle={Accurate, Efficient and Scalable Graph Embedding},\nyear={2019},\nmonth={May},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{graphsaint-iclr20,\ntitle={{GraphSAINT}: Graph Sampling Based Inductive Learning Method},\nauthor={Hanqing Zeng and Hongkuan Zhou and Ajitesh Srivastava and Rajgopal Kannan and Viktor Prasanna},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJe8pkHFwS}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8283216015784888
      ],
      "excerpt": "Hanqing Zeng (zengh@usc.edu), Hongkuan Zhou (hongkuaz@usc.edu) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8375030220685753
      ],
      "excerpt": "This repo contains source code of our two papers (ICLR '20 and IEEE/IPDPS '19, see the Citation Section). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "|JK-Net| :heavy_check_mark: | | | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/GraphSAINT/GraphSAINT",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-02-04T04:25:44Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-20T12:28:21Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9872720458586239,
        0.8343249729130496,
        0.9761849443664135,
        0.9851478324661262,
        0.9934607066948888,
        0.9896286865709251,
        0.8749257483153959,
        0.9814833007620023,
        0.9816628540977532,
        0.8809316894369008
      ],
      "excerpt": "GraphSAINT is a general and flexible framework for training GNNs on large graphs. GraphSAINT highlights a novel minibatch method specifically optimized for data with complex relationships (i.e., graphs). The traditional way of training a GNN is: 1). Construct a GNN on the full training graph; 2). For each minibatch, pick some nodes at the output layer as the root node. Backtrack the inter-layer connections from the root node until reaching the input layer; 3). Forward and backward propagation based on the loss on the roots. The way GraphSAINT trains a GNN is: 1). For each minibatch, sample a small subgraph from the full training graph; 2). Construct a complete GNN on the small subgraph. No sampling is performed within GNN layers; 3). Forward and backward propagation based on the loss on the subgraph nodes. \nGraphSAINT performs \"graph sampling\" based training, whereas others perform \"layer sampling\" based training. Why does it matter to change the perspective of sampling? GraphSAINT achieves the following: \nAccuracy: We perform simple yet effective normalization to eliminate the bias introduced by graph sampling. In addition, since any sampling process incurs information loss due to dropped neighbors, we propose light-weight graph samplers to preserve important neighbors based on topological characteristics. In fact, graph sampling can also be understood as data augmentation or training regularization (e.g., we may see the edge sampling as a minibatch version of DropEdge). \nEfficiency: While \"neighbor explosion\" is a headache for many layer sampling based methods, GraphSAINT provides a clean solution to it thanks to the graph sampling philosophy. As each GNN layer is complete and unsampled, the number of neighbors keeps constant no matter how deep we go. Computation cost per minibatch reduces from exponential to linear, w.r.t. GNN depth. \nFlexibility: Layer propagation on a minibatch subgraph of GraphSAINT is almost identical to that on the full graph. Therefore, most GNN architectures designed for the full graph can be seamlessly trained by GraphSAINT. On the other hand, some layer sampling algorithms only support limited number of GNN architectures. Take JK-net as an example: the jumping knowledge connection requires node samples in shallower layers as a superset of node samplers in the deeper layers --- minibatches of FastGCN and AS-GCN do not satisfy such condition. \nScalability: GraphSAINT achieves scalability w.r.t. 1). graph size: our subgraph size does not need to grow proportionally with the training graphs size. So even if we are dealing with a million-node graph, the subgraphs can still easily fit in the GPU memory; 2). model size: by resolving \"neighbor explosion\", training cost scales linearly with GNN width and depth; and 3). amount of parallel resources: graph sampling is highly scalable by trivial task parallelism. In addition, resolving \"neighbor explosion\" also implies dramatic reduction in communication overhead, which is critical in distributed setting (see our IEEE/IPDPS '19 or hardware accelerator development). \nThis repo contains source code of our two papers (ICLR '20 and IEEE/IPDPS '19, see the Citation Section). \nThe ./graphsaint directory contains the Python implementation of the minibatch training algorithm in ICLR '20. We provide two implementations, one in Tensorflow and the other in PyTorch. The two versions follow the same algorithm. Note that all experiments in our paper are based on the Tensorflow implementation. New experiments on open graph benchmark are based on the PyTorch version.  \nThe ./ipdps19_cpp directory contains the C++ implementation of the parallel training techniques described in IEEE/IPDPS '19 (see ./ipdps19_cpp/README.md). All the rest of this repository are for GraphSAINT in ICLR '20. \nThe GNN architectures supported by this repo: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8769809074386324
      ],
      "excerpt": "The graph samplers supported by this repo: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8641838915814889
      ],
      "excerpt": "|Full graph| :heavy_check_mark: | :heavy_check_mark: | | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9372283961820981
      ],
      "excerpt": "* Full graph: always returns the full training graph. Meant to be a baseline. No real \"sampling\" is going on. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9940482409262603,
        0.8871147927471418
      ],
      "excerpt": "New: We are testing GraphSAINT on Open Graph Benchmark. Currently, we have results for the ogbn-products graph. Note that the ogbn-products accuracy on the leaderboard trained with other methods are mostly under the transductive setting. Our results are under inductive learning (which is harder). \nAll results in ICLR '20 can be reproduced by running the config in ./train_config/. For example, ./train_config/table2/*.yml stores all the config for Table 2 of our paper. ./train_config/explore/*,yml stores all the config for deeper GNNs and various GNN architectures (GAT, JK, etc.). In addition, results related to OGB are trained by the config in ./train_config/open_graph_benchmark/*.yml. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8225589400843432
      ],
      "excerpt": "All datasets used in our papers are available for download: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8338689191321973
      ],
      "excerpt": "PPI-large (a larger version of PPI) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8442991172546226
      ],
      "excerpt": "... (more to be added) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9283020312322575,
        0.94139342907,
        0.8887009910426695,
        0.9626749622770335
      ],
      "excerpt": "The configuration files to reproduce the Table 2 results are packed in ./train_config/table2/. \nFor detailed description of the configuration file format, please see ./train_config/README.md \nBelow we describe how to customize this code base for your own research / product. \nAll samplers are implemented as subclass of GraphSampler in ./graphsaint/graph_samplers.py. There are two ways to implement your sampler subclass: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8838566318478359
      ],
      "excerpt": "    * Pros: Easy to implement \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.918882911120308
      ],
      "excerpt": "2) Implement in cython. You need to add a subclass of the Sampler in ./graphsaint/cython_sampler.pyx. In the subclass, you only need to overwrite the __cinit__ and sample functions. The sample function defines the sequential behavior of the sampler. We automatically perform task-level parallelism by launching multiple samplers at the same time. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "[ICLR 2020; IPDPS 2019] Fast and accurate minibatch training for deep GNNs and large graphs (GraphSAINT: Graph Sampling Based Inductive Learning Method).",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/GraphSAINT/GraphSAINT/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 58,
      "date": "Thu, 23 Dec 2021 08:40:40 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/GraphSAINT/GraphSAINT/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "GraphSAINT/GraphSAINT",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Suppose your full graph contains N nodes. Each node has C classes, and length-F initial attribute vector. If your train/val/test split is a/b/c (i.e., a+b+c=1), then:\n\n`adj_full.npz`: a sparse matrix in CSR format, stored as a `scipy.sparse.csr_matrix`. The shape is N by N. Non-zeros in the matrix correspond to all the edges in the full graph. It doesn't matter if the two nodes connected by an edge are training, validation or test nodes. For unweighted graph, the non-zeros are all 1.\n\n`adj_train.npz`: a sparse matrix in CSR format, stored as a `scipy.sparse.csr_matrix`. The shape is also N by N. However, non-zeros in the matrix only correspond to edges connecting two training nodes. The graph sampler only picks nodes/edges from this `adj_train`, not `adj_full`. Therefore, neither the attribute information nor the structural information are revealed during training. Also, note that only aN rows and cols of `adj_train` contains non-zeros. See also issue #11. For unweighted graph, the non-zeros are all 1.\n\n`role.json`: a dictionary of three keys. Key `'tr'` corresponds to the list of all training node indices. Key `va` corresponds to the list of all validation node indices. Key `te` corresponds to the list of all test node indices. Note that in the raw data, nodes may have string-type ID. You would need to re-assign numerical ID (0 to N-1) to the nodes, so that you can index into the matrices of adj, features and class labels.\n\n`class_map.json`: a dictionary of length N. Each key is a node index, and each value is either a length C binary list (for multi-class classification) or an integer scalar (0 to C-1, for single-class classification).\n\n`feats.npy`: a `numpy` array of shape N by F. Row i corresponds to the attribute vector of node i.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8878939041565685
      ],
      "excerpt": "|  GNN arch  |  Tensorflow  |  PyTorch  |  C++  | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8878939041565685
      ],
      "excerpt": "|  Sampler  |  Tensorflow  |  PyTorch  |  C++  | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9023697225149864
      ],
      "excerpt": "\u2502   run_graphsaint.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9105919151782922
      ],
      "excerpt": "We have a cython module which need compilation before training can start. Compile the module by running the following from the root directory: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "\u2502   \u2502   globals.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.950563948951535,
        0.91892912920148
      ],
      "excerpt": "\u2502   \u2502   \u2502    train.py \n\u2502   \u2502   \u2502    model.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.950563948951535,
        0.91892912920148
      ],
      "excerpt": "\u2502       \u2502    train.py \n\u2502       \u2502    model.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.816835953028745,
        0.9148452521095207
      ],
      "excerpt": "python convert.py &lt;dataset name&gt; \nFor example python convert.py ppi will convert dataset PPI and save new data in GraphSAGE format to ./data.ignore/ppi/ \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/GraphSAINT/GraphSAINT/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C++",
      "Cython",
      "C",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Hanqing Zeng, Hongkuan Zhou\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "GraphSAINT: Graph <u>Sa</u>mpling Based <u>In</u>ductive Learning Me<u>t</u>hod",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "GraphSAINT",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "GraphSAINT",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/GraphSAINT/GraphSAINT/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* python >= 3.6.8\n* tensorflow >=1.12.0  / pytorch >= 1.1.0\n* cython >=0.29.2\n* numpy >= 1.14.3\n* scipy >= 1.1.0\n* scikit-learn >= 0.19.1\n* pyyaml >= 3.12\n* g++ >= 5.4.0\n* openmp >= 4.0\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "First of all, please compile cython samplers (see above).\n\n\nWe suggest looking through the available command line arguments defined in `./graphsaint/globals.py` (shared by both the Tensorflow and PyTorch versions). By properly setting the flags, you can maximize CPU utilization in the sampling step (by telling the number of available cores), select the directory to place log files, and turn on / off loggers (Tensorboard, Timeline, ...), etc.\n\n\n*NOTE*: For all methods compared in the paper (GraphSAINT, GCN, GraphSAGE, FastGCN, S-GCN, AS-GCN, ClusterGCN), sampling or clustering is **only** performed during training.\nTo obtain the validation / test set accuracy, we run the full batch GNN on the full graph (training + validation + test nodes), and calculate F1 score only for the validation / test nodes. See also issue #11.\n\n\n\n\nFor simplicity of implementation, during validation / test set evaluation, we perform layer propagation using the full graph adjacency matrix. For Amazon or Yelp, this may cause memory issue for some GPUs. If an out-of-memory error occurs, please use the `--cpu_eval` flag to force the val / test set evaluation to take place on CPU (the minibatch training will still be performed on GPU). See below for other Flags.\n\n\nTo run the code on CPU\n\n\n```\npython -m graphsaint.<tensorflow/pytorch>_version.train --data_prefix ./data/<dataset_name> --train_config <path to train_config yml> --gpu -1\n```\n\n\nTo run the code on GPU\n\n\n```\npython -m graphsaint.<tensorflow/pytorch>_version.train --data_prefix ./data/<dataset_name> --train_config <path to train_config yml> --gpu <GPU number>\n```\n\n\nFor example `--gpu 0` will run on the first GPU. Also, use `--gpu <GPU number> --cpu_eval` to make GPU perform the minibatch training and CPU to perform the validation / test evaluation.\n\n\nWe have also implemented dual-GPU training to further speedup runtime. Simply add the flag `--dualGPU` and assign two GPUs using the `--gpu` flag. Currently this only works for GPUs supporting memory pooling and connected by NvLink.\n\n**New**: we have prepared specific scripts to train OGB graphs. See `./graphsaint/open_graph_benchmark/` for the scripts and instructions.\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 275,
      "date": "Thu, 23 Dec 2021 08:40:40 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Add a layer in `./graphsaint/<tensorflow or pytorch>_version/layers.py`. You would also need to do some minor update to `__init__` function of the `GraphSAINT` class in `./graphsaint/<tensorflow or pytorch>_version/models.py`, so that the model knows how to lookup the correct class based on the keyword in the `yml` config.\n\n",
      "technique": "Header extraction"
    }
  ],
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "gcn",
      "graph-sampling",
      "iclr",
      "graphsage",
      "jk-net",
      "gat",
      "ipdps"
    ],
    "technique": "GitHub API"
  }
}
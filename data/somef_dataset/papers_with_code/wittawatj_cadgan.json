{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1905.05882\n\n* Full paper: main text + supplement [on arXiv](https://arxiv.org/abs/1905.05882",
      "https://arxiv.org/abs/1905.05882",
      "https://arxiv.org/abs/1801.04406"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9677640385174676
      ],
      "excerpt": "ICML 2019 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wittawatj/cadgan",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you have questions or comments, please contact [Wittawat](http://wittawat.com/) and [Patsorn](https://www.cc.gatech.edu/~psangklo/).\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-12T18:12:22Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-21T04:05:19Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9385870104617403,
        0.912971168815904
      ],
      "excerpt": "Repository containing resources from our paper: \nKernel Mean Matching for Content Addressability of GANs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8912641615540822
      ],
      "excerpt": "We propose a novel procedure which adds content-addressability to any given \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8512715815212621,
        0.9090428750180085,
        0.9258476406582528,
        0.9511044075711144,
        0.8534398746833171
      ],
      "excerpt": "procedure allows users to control the generative process by specifying a set \n(arbitrary size) of desired examples based on which similar samples are \ngenerated from the model. The proposed approach, based on kernel mean matching, \nis applicable to any generative models which transform latent vectors to \nsamples, and does not require retraining of the model. Experiments on various \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9619350104370512,
        0.966102871168183,
        0.9159824760909232
      ],
      "excerpt": "tower) show that our approach is able to generate images which are consistent \nwith the input set, while retaining the image quality of the original model. To \nour knowledge, this is the first work that attempts to construct, at test \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8235825678340634
      ],
      "excerpt": "Automatic dependency resolution only works with a new version of pip. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8445173837063314
      ],
      "excerpt": "  cdg, and all the code in cadgan folder is accessible through cdg. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "ICML 2019. Turn a pre-trained GAN model into a content-addressable model without retraining.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wittawatj/cadgan/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Sat, 25 Dec 2021 06:08:19 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/wittawatj/cadgan/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "wittawatj/cadgan",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/wittawatj/cadgan/master/ipynb/process_compression_3imgs.ipynb",
      "https://raw.githubusercontent.com/wittawatj/cadgan/master/ipynb/mnist_g_kmm.ipynb",
      "https://raw.githubusercontent.com/wittawatj/cadgan/master/ipynb/misc/Load_dataframe.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/wittawatj/cadgan/master/cadgan/ex/start_tensorboard.sh",
      "https://raw.githubusercontent.com/wittawatj/cadgan/master/cadgan/ex/run_lars_tower.sh",
      "https://raw.githubusercontent.com/wittawatj/cadgan/master/cadgan/ex/run_lars_celeba.sh",
      "https://raw.githubusercontent.com/wittawatj/cadgan/master/cadgan/ex/run_lars_bridge.sh",
      "https://raw.githubusercontent.com/wittawatj/cadgan/master/cadgan/ex/run_lars_bedroom.sh",
      "https://raw.githubusercontent.com/wittawatj/cadgan/master/cadgan/ex/run_mnist.sh",
      "https://raw.githubusercontent.com/wittawatj/cadgan/master/cadgan/ex/run_mnist_color.sh",
      "https://raw.githubusercontent.com/wittawatj/cadgan/master/cadgan/gan/cifar10/batch_train_dcgans.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9846953673651484,
        0.9200642600693112,
        0.9712942982099737,
        0.8030650668398628,
        0.9780129821727064,
        0.9984521807011597,
        0.9961133246203249,
        0.941695258297383,
        0.9686297084284448,
        0.9426885472459776
      ],
      "excerpt": "      First upgrade you pip with pip install --upgrade pip. \nIf you use Anaconda, consider creating a new environment before installing cadgan.  \nconda create -n cadgan pytorch=0.4.1 \nwhere cadgan in the above command is an arbitrary name for the environment. \nActivate the environment with conda activate cadgan. You might want to \n  install Jupyter notebook with conda install jupyter. \nMake you you activate the environment first. Then, install the cadgan \n  package. This repo is set up so that once you clone, you can do \npip install -e /path/to/the/folder/of/this/repo/ \nto install as a Python package. In Python, we can then do import cadgan as \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8672013387833163,
        0.9023697225149864,
        0.9023697225149864,
        0.9023697225149864,
        0.9023697225149864,
        0.9023697225149864,
        0.9023697225149864
      ],
      "excerpt": "[x] test that all script can successfully run \n[x] run_mnist.sh \n[x] run_lars_bridge.sh \n[x] run_lars_bedroom.sh \n[x] run_lars_tower.sh \n[x] run_lars_celeba.sh \n[x] run_mnist_color.sh \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9254474401188778,
        0.8270241833348263
      ],
      "excerpt": "Main text only here (file size: 7.3MB) \nSupplementary file only here (file size: 32MB) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/wittawatj/cadgan/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Wittawat Jitkrittum, Patsorn Sangkloy, Waleed Gondal, Amit Raj\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Content ADdressable GAN (CADGAN)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "cadgan",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "wittawatj",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wittawatj/cadgan/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You will need to change values in `settings.ini` to your local path. This is\nimportant since we will be using relative path in the script. \n\n* Results will be saved in `expr_results_path`\n* `data_path` should point to where you store all your input data\n* `problem_model_path` will be used for storing various pre-trained models (warning: this can be quite large)\n* See comment in settings.ini for more details\n\nWe provide an example script to run CADGAN in `ex/run_gkmm.py`\n\nFor example, here is the command to run CADGAN for celebAHQ dataset on Mescheder et al., 2018's pre-trained model:\n\n    python3 run_gkmm.py \\\n        --extractor_type vgg_face \\\n        --extractor_layers 35 \\\n        --texture 0\\\n        --depth_process no \\\n        --g_path celebAHQ_00/chkpts/model.pt \\\n        --g_type celebAHQ.yaml \\\n        --g_min -1.0 \\\n        --g_max 1.0 \\\n        --logdir log_celeba_face/ \\\n        --device gpu \\\n        --n_sample 1 \\\n        --n_opt_iter 1000 \\\n        --lr 5e-2 \\\n        --seed 99 \\\n        --img_log_steps 500 \\\n        --cond_path  celebaHQ/ \\\n        --kernel imq \\\n        --kparams -0.5 1e+2 \\\n        --img_size 224\n\n* The above command will use all images in `[data_path]/celebaHQ/` as conditional images, with the generator from `[problem_model_path]/celebAHQ_00/chkpts/model.pt` and then store results in `[expr_results_path]/log_celeba_face/`. When this is run for the first time, the GAN model will be downloaded automatically. The required feature extractor (VGG face, in this case) will also be downloaded automatically. Downloading these models may take some time. The size of each model is roughly 300-600 MB. The results are written to a Tensorboard log folder. Simply use Tensorboard to see the result. This can be done by, for instance, \n\n        ./cadgan/ex/start_tensorboard.sh [expr_results_path]/log_celeba_face/\n\n* Note that possible value of `g_type` are `lsun_bedroom.yaml` `lsun_bridge.yaml` `celebAHQ.yaml` `lsun_tower.yaml` `mnist_dcgan` `colormnist_dcgan`. If the specified generator doesn't exist yet, the code will download the pre-trained model used in the paper into the specified location.\n\nSee `run_lars_bedroom.sh`, `run_lars_bridge.sh`, `run_lars_tower.sh`, `run_mnist.sh` and `run_mnist_color.sh` for other model options.\n\nWe also provide 2 example images for each of the dataset in `data/` that can be\nused for testing.\n\nIn case you want to experiment with the parameters, we use `ex/cmd_gkmm.py` to\ngenerate commands for multiple combinations of parameters. This requires\n`cmdprod` package available here: https://github.com/wittawatj/cmdprod .\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 20,
      "date": "Sat, 25 Dec 2021 06:08:19 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "machine-learning",
      "kernel-methods",
      "generative-adversarial-network",
      "generative-model"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We consider a GAN model from [Mescheder et al., 2018](https://arxiv.org/abs/1801.04406) pretrained on CelebA-HQ. We run our proposed procedure using the three images (with border) at the corners as the input. All images in the triangle are the output from our procedure. Each of the output images is positioned such that the closeness to a corner (an input image) indicates the importance (weight) of the corresponding input image.\n\n<img src=\"https://github.com/wittawatj/cadgan/blob/master/illus/m3_triangle_interpolation_v2.png\" width=\"70%\">\n\n<!--<img src=\"https://github.com/wittawatj/cadgan/blob/master/illus/m3_triangle_interpolation_v5.png\" width=\"70%\">-->\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "For a simple demo example on MNIST, check out this [Colab\nnotebook](https://colab.research.google.com/drive/1gH2naGOwxYNz6OGDydc9SPz7AHJlc5u7). No local installation is required.\n\n",
      "technique": "Header extraction"
    }
  ]
}
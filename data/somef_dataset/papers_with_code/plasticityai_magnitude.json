{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1810.11190",
      "https://arxiv.org/abs/1810.11190"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you'd like to [cite our paper at EMNLP 2018](http://aclweb.org/anthology/D18-2021), you can use the following BibTeX citation:\n```latex\n@inproceedings{patel2018magnitude,\n  title={Magnitude: A Fast, Efficient Universal Vector Embedding Utility Package},\n  author={Patel, Ajay and Sands, Alexander and Callison-Burch, Chris and Apidianaki, Marianna},\n  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},\n  pages={120--126},\n  year={2018}\n}\n```\nor follow the [Google Scholar link](https://scholar.google.com/scholar?cluster=5916903042122216495&hl=en&as_sdt=0,5) for other ways to cite the paper.\n\nIf you'd like to cite this repository you can use the following DOI badge: &nbsp;[![DOI](https://zenodo.org/badge/122715432.svg)](https://zenodo.org/badge/latestdoi/122715432)\n\nClicking on the badge will lead to a page that will help you generate proper BibTeX citations, JSON-LD citations, and other citations.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{patel2018magnitude,\n  title={Magnitude: A Fast, Efficient Universal Vector Embedding Utility Package},\n  author={Patel, Ajay and Sands, Alexander and Callison-Burch, Chris and Apidianaki, Marianna},\n  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},\n  pages={120--126},\n  year={2018}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "Constructing a Magnitude Object \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9327105443920798
      ],
      "excerpt": "Citing this Repository \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9195926162616405,
        0.8528760958819365
      ],
      "excerpt": "| Cold single key query                                                                                                                                 | 0.0001s           | \u2501&nbsp;<sup>1</sup>  | \u2501&nbsp;<sup>1</sup> | 1.6437s                                                | \n| Warm single key query <br /><sup>(same key as cold query)</sup>                                                                                     | 0.00004s          | \u2501&nbsp;<sup>1</sup>  | \u2501&nbsp;<sup>1</sup> | 0.0004s                                            | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8252756551763226
      ],
      "excerpt": "| First most_similar_approx search query <br /><sup>(n=10, effort=1.0) (worst case)</sup>                                                           | N/A                   | N/A                  | 29.610s         | -                                                      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173
      ],
      "excerpt": "| Stanford - GloVe            | Wikipedia 2014 + Gigaword 5 6B                                  | 50D,&nbsp;100D,&nbsp;200D,&nbsp;300D                                             | 50D,&nbsp;100D,&nbsp;200D,&nbsp;300D                                                 | 50D,&nbsp;100D,&nbsp;200D,&nbsp;300D                                                 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8334316807263773,
        0.8334316807263773
      ],
      "excerpt": "| Facebook - fastText | English Wikipedia 2017 16B                                      | 300D                                                                                                                                                                                                                                                                                       | 300D                                                                                                                                                                                                                                                                                              | 300D                                                                                                                                                                                                                                                                                           | \n| Facebook - fastText | English Wikipedia 2017 + subword 16B                            | 300D                                                                                                                                                                                                                                                                               | 300D                                                                                                                                                                                                                                                                                      | 300D                                                                                                                                                                                                                                                                                   | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278824608274014
      ],
      "excerpt": ": (https://en.wikipedia.org/wiki/Buffalo_buffalo_Buffalo_buffalo_buffalo_buffalo_Buffalo_buffalo) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/plasticityai/magnitude",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-02-24T07:28:16Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-18T23:04:26Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9861264801262313
      ],
      "excerpt": "A feature-packed Python package and vector storage file format for utilizing vector embeddings in machine learning models in a fast, efficient, and simple manner developed by Plasticity. It is primarily intended to be a simpler / faster alternative to Gensim, but can be used as a generic key-vector store for domains outside NLP. It offers unique features like out-of-vocabulary lookups and streaming of large models over HTTP. Published in our paper at EMNLP 2018 and available on arXiv. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9539106374210172,
        0.8545431398157872
      ],
      "excerpt": "Benchmarks and Features \nPre-converted Magnitude Formats of Popular Embeddings Models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8445140417806873,
        0.857668085314543,
        0.908925214220865,
        0.8876512106406997
      ],
      "excerpt": "Basic Out-of-Vocabulary Keys \nAdvanced Out-of-Vocabulary Keys \nHandling Misspellings and Typos \nConcatenation of Multiple Models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8959860346374626
      ],
      "excerpt": "Using Magnitude with a ML library \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "Concurrency and Parallelism \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.982249486640725,
        0.9976917079625827,
        0.942920977474007
      ],
      "excerpt": "Vector space embedding models have become increasingly common in machine learning and traditionally have been popular for natural language processing applications. A fast, lightweight tool to consume these large vector space embedding models efficiently is lacking. \nThe Magnitude file format (.magnitude) for vector embeddings is intended to be a more efficient universal vector embedding format that allows for lazy-loading for faster cold starts in development, LRU memory caching for performance in production, multiple key queries, direct featurization to the inputs for a neural network, performant similiarity calculations, and other nice to have features for edge cases like handling out-of-vocabulary keys or misspelled keys and concatenating multiple vector models together. It also is intended to work with large vector models that may not fit in memory. \nIt uses SQLite, a fast, popular embedded database, as its underlying data store. It uses indexes for fast key lookups as well as uses memory mapping, SIMD instructions, and spatial indexing for fast similarity search in the vector space off-disk with good memory performance even between multiple processes. Moreover, memory maps are cached between runs so even after closing a process, speed improvements are reaped. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.803661023267053,
        0.9019268285523251
      ],
      "excerpt": "| Optimized for threading and multiprocessing                                                                                                       | \u2705                     | \u2705                    | \u2705                   | \u2705                                                      | \n| Bulk and multiple key lookup with padding, truncation, placeholder, and featurization support                                                         | \u2705                     | \u2705                    | \u2705                   | \u2705                                                      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.812688777577461,
        0.9798955634789287
      ],
      "excerpt": "| Basic out-of-vocabulary key lookup <br /><sup>(character n-gram feature hashing)</sup>                                                                | \u2705                     | \u2705                    | \u2705                   | \u2705                                                      | \n| Advanced out-of-vocabulary key lookup with support for misspellings <br /><sup>(character n-gram feature hashing to similar in-vocabulary keys)</sup> | \u274c                     | \u2705                    | \u2705                   | \u2705                                                      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9123789764070888
      ],
      "excerpt": "| Built-in training for new models                                                                                                                      | \u274c                     | \u274c                    | \u274c                   | \u274c                                                      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9407617394728568,
        0.9397718470324327
      ],
      "excerpt": "<sup>2: uses mmap to read from disk, so the OS will still allocate pages of memory when memory is available, but it can be shared between processes and isn't managed within each process for extremely large files which is a performance win</sup><br/> \n<sup>*: All benchmarks were performed on the Google News pre-trained word vectors (GoogleNews-vectors-negative300.bin) with a MacBook Pro (Retina, 15-inch, Mid 2014) 2.2GHz quad-core Intel Core i7 @ 16GB RAM on SSD over an average of trials where feasible.</sup> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9575736325234169
      ],
      "excerpt": "| Contributor                                                         | Data                                                        | Light<br/><br/><sup>(basic support for out-of-vocabulary keys)</sup>                                                                                                                                                                                                                                                                                                | Medium<br/><i>(recommended)</i><br/><br/><sup>(advanced support for out-of-vocabulary keys)</sup>                                                                                                                                                                                                                                                                           | Heavy<br/><br/><sup>(advanced support for out-of-vocabulary keys and faster most_similar_approx)</sup>                                                                                                                                                                                                                                                                | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8002261658836117
      ],
      "excerpt": "| Google - word2vec        | Google News 100B                                                | 300D                                                                                                                                                                                                                                                                          | 300D                                                                                                                                                                                                                                                                                 | 300D                                                                                                                                                                                                                                                                              | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8465737939151796
      ],
      "excerpt": "| Facebook - fastText | Common Crawl 600B                                               | 300D                                                                                                                                                                                                                                                                                           | 300D                                                                                                                                                                                                                                                                                                  | 300D                                                                                                                                                                                                                                                                                               | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9293964732847706
      ],
      "excerpt": "<sup>By default, lazy loading is enabled. You can pass in an optional lazy_loading argument to the constructor with the value -1 to disable lazy-loading and pre-load all vectors into memory (a la Gensim), 0 (default) to enable lazy-loading with an unbounded in-memory LRU cache, or an integer greater than zero X to enable lazy-loading with an LRU cache that holds the X most recently used vectors in memory.</sup>  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906801461944859
      ],
      "excerpt": "<sup>Optionally, you can set the truncate_left argument to True if you want the beginning of the the list of keys in each example to be truncated instead of the end in case it is longer than pad_to_length when specified.</sup> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9096243650362936,
        0.9442268708027531
      ],
      "excerpt": "<sup>Optionally, you can pass in the placeholders argument, which will increase the dimensions of each vector by a placeholders amount, zero-padding those extra dimensions. This is useful, if you plan to add other values and information to the vectors and want the space for that pre-allocated in the vectors for efficiency.</sup> \n<sup>Optionally, you can pass in the language argument with an ISO 639-1 Language Code, which, if you are using Magnitude for word vectors, will ensure the library respects stemming and other language-specific features for that language. The default is en for English. You can also pass in None if you are not using Magnitude for word vectors. </sup> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.806485973030136
      ],
      "excerpt": "for key, vector in vectors: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.854983910498393
      ],
      "excerpt": "You can query for the vector of a key like so:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341183693450782
      ],
      "excerpt": "You can query for the vector of multiple keys like so:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9226844144746983
      ],
      "excerpt": "You can query for the most similar key out of a list of keys to a given key like so: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8020539985549341
      ],
      "excerpt": "You can query for which key doesn't match a list of keys to a given key like so: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8266708133727854
      ],
      "excerpt": "You can also query for the most similar keys using an approximate nearest neighbors index which is much faster, but doesn't guarantee the exact answer:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8787246963576812
      ],
      "excerpt": "You can query for all keys closer to a key than another key is like so: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8438018708365448
      ],
      "excerpt": "You can access all of the underlying vectors in the model in a large numpy.memmap array of size (len(vectors) x vectors.emb_dim) like so: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9911493054983761,
        0.9105753145463018
      ],
      "excerpt": "For word vector representations, handling out-of-vocabulary keys is important to handling new words not in the trained model, handling mispellings and typos, and making models trained on the word vector representations more robust in general. \nOut-of-vocabulary keys are handled by assigning them a random vector value. However, the randomness is deterministic. So if the same out-of-vocabulary key is encountered twice, it will be assigned the same random vector value for the sake of being able to train on those out-of-vocabulary keys. Moreover, if two out-of-vocabulary keys share similar character n-grams (\"uberx\", \"uberxl\") they will placed close to each other even if they are both not in the vocabulary: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9588888359130128
      ],
      "excerpt": "If using a Magnitude file with advanced out-of-vocabulary support (Medium or Heavy), out-of-vocabulary keys will also be embedded close to similar keys (determined by string similarity) that are in the vocabulary: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9428766457504738
      ],
      "excerpt": "This also makes Magnitude robust to a lot of spelling errors: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9763651492700305
      ],
      "excerpt": "Character n-grams are used to create this effect for out-of-vocabulary keys. The inspiration for this feature was taken from Facebook AI Research's Enriching Word Vectors with Subword Information, but instead of utilizing character n-grams at train time, character n-grams are used at inference so the effect can be somewhat replicated (but not perfectly replicated) in older models that were not trained with character n-grams like word2vec and GloVe. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8439437293530212
      ],
      "excerpt": "You can concatenate more than two vector models, simply by passing more arguments to constructor. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.923256811270569
      ],
      "excerpt": "The first argument to FeaturizerMagnitude should be an approximate upper-bound on the number of values for the feature. Since there are < 100 parts of speech tags and < 100 syntax dependencies, we choose 100 for both in the example above. The value chosen will determine how many dimensions Magnitude will automatically assign to the particular the FeaturizerMagnitude object to reduce the chance of a hash collision. The namespace argument can be any string that describes your additional feature. It is optional, but highly recommended. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8001009836430872,
        0.9153798970587277
      ],
      "excerpt": "  ]) #: array of size 5 x (300 + 4 + 4) or 5 x 308 \n: Or get a unique vector for every 'buffalo' in: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8001009836430872
      ],
      "excerpt": "  ]) #: array of size 8 x (300 + 4 + 4) or 8 x 308 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9062328951734471,
        0.9929989716949806,
        0.8548781337931537,
        0.9435635810056596,
        0.8985900580030329,
        0.8771551861868152
      ],
      "excerpt": "A machine learning model, given this output, now has access to parts of speech information and syntax dependency information instead of just word vector information. In this case, this additional information can give neural networks stronger signal for semantic information and reduce the need for training data. \nMagnitude makes it very easy to quickly build and iterate on models that need to use vector representations by taking care of a lot of pre-processing code to convert a dataset of text (or keys) into vectors. Moreover, it can make these models more robust to out-of-vocabulary words and misspellings. \nThere is example code available using Magnitude to build an intent classification model for the ATIS (Airline Travel Information Systems) dataset (Train/Test), used for chatbots or conversational interfaces, in a few popular machine learning libraries below. \nYou can access a guide for using Magnitude with Keras (which supports TensorFlow, Theano, CNTK) at this Google Colaboratory Python notebook. \nThe PyTorch guide is coming soon. \nThe TFLearn guide is coming soon. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8803229854284796
      ],
      "excerpt": "You can create a batch generator for X and y data with batchify, like so: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "  for X_batch, y_batch in batch_gen: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9785438668836577,
        0.9058408390324235
      ],
      "excerpt": "The library is thread safe (it uses a different connection to the underlying store per thread), is read-only, and it never writes to the file. Because of the light-memory usage, you can also run it in multiple processes (or use multiprocessing) with different address spaces without having to duplicate the data in-memory like with other libraries and without having to create a multi-process shared variable since data is read off-disk and each process keeps its own LRU memory cache. For heavier functions, like most_similar a shared memory mapped file is created to share memory between processes. \nThe Magnitude package uses the .magnitude file format instead of .bin, .txt, .vec, or .hdf5 as with other vector models like word2vec, GloVe, fastText, and ELMo. There is an included command-line utility for converting word2vec, GloVe, fastText, and ELMo files to Magnitude files. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8469228474647956
      ],
      "excerpt": "The input format will automatically be determined by the extension / the contents of the input file. You should only need to perform this conversion once for a model. After converting, the Magnitude file format is static and it will not be modified or written to make concurrent read access safe. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9295887600142213
      ],
      "excerpt": "* You can pass in the -h flag for help and to list all flags. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.889973833590338
      ],
      "excerpt": "* You can add an approximate nearest neighbors index to the file (increases size) with the -a flag which will enable the use of the most_similar_approx function. The -t &lt;TREES&gt; flag controls the number of trees in the approximate neigherest neighbors index (higher is more accurate) when used in conjunction with the -a flag (if not supplied, the number of trees is automatically determined). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9199914752242349,
        0.9570452501930493
      ],
      "excerpt": "Magnitude models are generally large files (multiple GB) that take up a lot of disk space, even though the .magnitude format makes it fast to utilize the vectors. Magnitude has an option to stream these large files over HTTP.  \nThis is explicitly different from the remote loading feature, in that the model doesn't even need to be downloaded at all. You can begin querying models immediately with no disk space used at all.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8678796880882883
      ],
      "excerpt": "vecs.query(\"king\") #: Returns: the vector for \"king\" quickly, even with no local model file downloaded \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8404153879901951
      ],
      "excerpt": "You can play around with a demo of this in a Google Colaboratory Python Notebook. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.93442105406727
      ],
      "excerpt": "While there is some added network latency since the data is being streamed, Magnitude will still use an in-memory cache as specified by the lazy_loading constructor parameter. Since languages generally have a Zipf-ian distribution, the network latency should largely not be an issue after the cache is warmed after being queried a small number of times. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8405992276325998,
        0.9117511752375732,
        0.9770568929583975,
        0.9570404513514029,
        0.9895029678897127
      ],
      "excerpt": "may be slow as they are not optimized for streaming yet. You can see how this streaming mode performs currently in the benchmarks, however, it will get faster as we optimize it in the future! \nCurrently, we only provide English word vector models on this page pre-converted to the .magnitude format. You can, however, still use Magnitude with word vectors of other languages. Facebook has trained their fastText vectors for many different languages. You can down the .vec file for any language you want and then convert it to .magnitude with the converter. \nCurrently, reading Magnitude files is only supported in Python, since it has become the de-facto language for machine learning. This is sufficient for most use cases. Extending the file format to other languages shouldn't be difficult as SQLite has a native C implementation and has bindings in most languages. The file format itself and the protocol for reading and searching is also fairly straightforward upon reading the source code of this repository. \nCurrently, natural language processing is the most popular domain that uses pre-trained vector embedding models for word vector representations. There are, however, other domains like computer vision that have started using pre-trained vector embedding models like Deep1B for image representation. This library intends to stay agnostic to various domains and instead provides a generic key-vector store and interface that is useful for all domains. \nThe main repository for this project can be found on GitLab. The GitHub repository is only a mirror. Pull requests for more tests, better error-checking, bug fixes, performance improvements, or documentation or adding additional utilties / functionalities are welcome on GitLab. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9784866151763713
      ],
      "excerpt": "In addition to the \"Light\", \"Medium\", and \"Heavy\" flavors, add a \"Ludicrous\" flavor that will be of an even larger file size but removes the constraint of the initially slow most_similar lookups. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A fast, efficient universal vector embedding utility package.",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Other documentation is not available at this time. See the source file directly (it is well commented) if you need more information about a method's arguments or want to see all supported features.\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/plasticityai/magnitude/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 105,
      "date": "Fri, 24 Dec 2021 11:16:27 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/plasticityai/magnitude/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "plasticityai/magnitude",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/plasticityai/magnitude/master/install-colab.sh",
      "https://raw.githubusercontent.com/plasticityai/magnitude/master/pymagnitude/third_party/allennlp/custom_extensions/make.sh",
      "https://raw.githubusercontent.com/plasticityai/magnitude/master/pymagnitude/third_party/_apsw/tools/valgrind.sh",
      "https://raw.githubusercontent.com/plasticityai/magnitude/master/pymagnitude/third_party/_apsw/tools/coverage.sh",
      "https://raw.githubusercontent.com/plasticityai/magnitude/master/pymagnitude/third_party/_apsw/tools/spellcheck.sh",
      "https://raw.githubusercontent.com/plasticityai/magnitude/master/pymagnitude/third_party/_pysqlite/test.sh"
    ],
    "technique": "File Exploration"
  },
  "identifier": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://zenodo.org/badge/latestdoi/122715432",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://zenodo.org/badge/latestdoi/122715432",
      "technique": "Regular expression"
    }
  ],
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can install this package with `pip`:\n```python\npip install pymagnitude #: Python 2.7\npip3 install pymagnitude #: Python 3\n```\n\nGoogle Colaboratory has some dependency issues with installing Magnitude due to conflicting dependencies. You can use the following snippet to install Magnitude on Google Colaboratory:\n```bash\n#: Install Magnitude on Google Colab\n! echo \"Installing Magnitude.... (please wait, can take a while)\"\n! (curl https://raw.githubusercontent.com/plasticityai/magnitude/master/install-colab.sh | /bin/bash 1>/dev/null 2>/dev/null)\n! echo \"Done installing Magnitude.\"\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.870055743973743
      ],
      "excerpt": "| Few dependencies                                                                                                                                      | \u2705                     | \u2705                    | \u2705                   | \u2705                                                      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8166976446469147
      ],
      "excerpt": "You can access a guide for using Magnitude with Keras (which supports TensorFlow, Theano, CNTK) at this Google Colaboratory Python notebook. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8152218375417528
      ],
      "excerpt": "You can import MagnitudeUtils like so: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8613167870050099
      ],
      "excerpt": "You can download a Magnitude model from a remote source like so: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9358202342413179
      ],
      "excerpt": "By default, download_model will download files from http://magnitude.plasticity.ai to a ~/.magnitude folder created automatically. If the file has already been downloaded, it will not be downloaded again. You can change the directory of the local download folder using the optional download_dir argument. You can change the domain from which models will be downloaded with the optional remote_path argument. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8120379236321446
      ],
      "excerpt": "Make most_similar_approx optimized for streaming \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8340351196132942
      ],
      "excerpt": "File Format and Converter \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8566442874081907,
        0.8265444775797774
      ],
      "excerpt": "| First most_similar search query <br /><sup>(n=10) (worst case)</sup>                                                                              | 247.05s               | \u2501&nbsp;<sup>1</sup>  | \u2501&nbsp;<sup>1</sup> | -                                                      | \n| First most_similar search query <br /><sup>(n=10) (average case) (w/ disk persistent cache)</sup>                                                 | 1.8217s           | \u2501&nbsp;<sup>1</sup>  | \u2501&nbsp;<sup>1</sup> | -                                                      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8477889713783411,
        0.8147713072951849
      ],
      "excerpt": "| Warm subsequent most_similar search <br /><sup>(n=10) (same key as first query)</sup>                                                             | 0.00004s          | 0.00004s         | 0.00004s        | -                                                      | \n| First most_similar_approx search query <br /><sup>(n=10, effort=1.0) (worst case)</sup>                                                           | N/A                   | N/A                  | 29.610s         | -                                                      | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8079085962417776,
        0.8832318895949025
      ],
      "excerpt": "| Warm subsequent most_similar_approx search <br /><sup>(n=10, effort=1.0) (same key as first query)</sup>                                          | N/A                   | N/A                  | 0.00004s        | -                                                      | \n| File size                                                                                                                                             | 4.21GB                | 5.29GB               | 10.74GB             | 0.00GB                                             | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from pymagnitude import * \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from pymagnitude import * \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from pymagnitude import * \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8184394336364812,
        0.8184394336364812
      ],
      "excerpt": "pos_vectors.query(\"NN\") #: - array([ 0.08040417, -0.71705252,  0.61228951,  0.32322192])  \npos_vectors.query(\"JJ\") #: - array([-0.11681135,  0.10259253,  0.8841201 , -0.44063763]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8184394336364812,
        0.8184394336364812
      ],
      "excerpt": "dependency_vectors.query(\"nsubj\") #: - array([-0.81043793,  0.55401352, -0.10838071,  0.15656626]) \ndependency_vectors.query(\"prep\") #: - array([-0.30862918, -0.44487267, -0.0054573 , -0.84071788]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from pymagnitude import * \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "  from pymagnitude import MagnitudeUtils \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936606094659785
      ],
      "excerpt": "    print(X_batch, y_batch) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8184394336364812
      ],
      "excerpt": "  #: array([[0., 1., 0., 0., 0., 0.]  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8184394336364812
      ],
      "excerpt": "  #: array([1., 5.]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.903283509891786
      ],
      "excerpt": "Optionally, you can bulk convert many files by passing an input folder and output folder instead of an input file and output file. All .txt, .bin, .vec, .hdf5 files in the input folder will be converted to .magnitude files in the the output folder. The output folder must exist before a bulk conversion operation. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/plasticityai/magnitude/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b\"\\xef\\xbb\\xbfCopyright (c) 2004-2015 Gerhard H\\xc3\\xa4ring\\n\\nThis software is provided 'as-is', without any express or implied warranty. In\\nno event will the authors be held liable for any damages arising from the use\\nof this software.\\n\\nPermission is granted to anyone to use this software for any purpose,\\nincluding commercial applications, and to alter it and redistribute it freely,\\nsubject to the following restrictions:\\n\\n    1. The origin of this software must not be misrepresented; you must not\\n       claim that you wrote the original software. If you use this software in\\n       a product, an acknowledgment in the product documentation would be\\n       appreciated but is not required.\\n\\n    2. Altered source versions must be plainly marked as such, and must not be\\n       misrepresented as being the original software.\\n\\n    3. This notice may not be removed or altered from any source distribution.\\n\"",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# <div align=\"center\">Magnitude: a fast, simple vector embedding utility library<br /><br />",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "magnitude",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "plasticityai",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/plasticityai/magnitude/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-25T11:25:07Z",
        "datePublished": "2020-05-25T11:26:09Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.143",
        "name": "Release 0.1.143",
        "tag_name": "0.1.143",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.143",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26859652",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.143"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-25T09:37:08Z",
        "datePublished": "2020-05-25T09:38:10Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.142",
        "name": "Release 0.1.142",
        "tag_name": "0.1.142",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.142",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26856548",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.142"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-25T07:45:26Z",
        "datePublished": "2020-05-25T07:46:28Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.140",
        "name": "Release 0.1.140",
        "tag_name": "0.1.140",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.140",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26853291",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.140"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-25T07:28:09Z",
        "datePublished": "2020-05-25T07:29:11Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.139",
        "name": "Release 0.1.139",
        "tag_name": "0.1.139",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.139",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26852847",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.139"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-25T07:16:50Z",
        "datePublished": "2020-05-25T07:17:52Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.138",
        "name": "Release 0.1.138",
        "tag_name": "0.1.138",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.138",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26852593",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.138"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-25T07:11:10Z",
        "datePublished": "2020-05-25T07:12:12Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.137",
        "name": "Release 0.1.137",
        "tag_name": "0.1.137",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.137",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26852405",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.137"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-25T06:54:08Z",
        "datePublished": "2020-05-25T06:55:10Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.136",
        "name": "Release 0.1.136",
        "tag_name": "0.1.136",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.136",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26852042",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.136"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-25T06:26:23Z",
        "datePublished": "2020-05-25T06:27:25Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.135",
        "name": "Release 0.1.135",
        "tag_name": "0.1.135",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.135",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26851464",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.135"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-25T05:21:49Z",
        "datePublished": "2020-05-25T05:22:51Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.132",
        "name": "Release 0.1.132",
        "tag_name": "0.1.132",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.132",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26849680",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.132"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-25T05:13:49Z",
        "datePublished": "2020-05-25T05:14:51Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.131",
        "name": "Release 0.1.131",
        "tag_name": "0.1.131",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.131",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26849576",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.131"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-25T05:02:22Z",
        "datePublished": "2020-05-25T05:03:24Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.130",
        "name": "Release 0.1.130",
        "tag_name": "0.1.130",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.130",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26849396",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.130"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-25T01:28:43Z",
        "datePublished": "2020-05-25T01:29:45Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.129",
        "name": "Release 0.1.129",
        "tag_name": "0.1.129",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.129",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26846989",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.129"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-25T00:46:21Z",
        "datePublished": "2020-05-25T00:47:23Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.128",
        "name": "Release 0.1.128",
        "tag_name": "0.1.128",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.128",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26846510",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.128"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-24T23:25:31Z",
        "datePublished": "2020-05-24T23:26:33Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.127",
        "name": "Release 0.1.127",
        "tag_name": "0.1.127",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.127",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26845702",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.127"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-24T23:18:22Z",
        "datePublished": "2020-05-24T23:19:24Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.126",
        "name": "Release 0.1.126",
        "tag_name": "0.1.126",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.126",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26845618",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.126"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-24T23:12:45Z",
        "datePublished": "2020-05-24T23:13:46Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.125",
        "name": "Release 0.1.125",
        "tag_name": "0.1.125",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.125",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26845560",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.125"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-24T23:06:13Z",
        "datePublished": "2020-05-24T23:07:15Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.124",
        "name": "Release 0.1.124",
        "tag_name": "0.1.124",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.124",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26845522",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.124"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-24T23:00:21Z",
        "datePublished": "2020-05-24T23:01:23Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.123",
        "name": "Release 0.1.123",
        "tag_name": "0.1.123",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.123",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26845475",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.123"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-24T22:51:00Z",
        "datePublished": "2020-05-24T22:52:02Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.122",
        "name": "Release 0.1.122",
        "tag_name": "0.1.122",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.122",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26845382",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.122"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2020-05-24T22:38:40Z",
        "datePublished": "2020-05-24T22:39:43Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.121",
        "name": "Release 0.1.121",
        "tag_name": "0.1.121",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.121",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/26845227",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.121"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2018-11-28T03:23:17Z",
        "datePublished": "2018-11-28T04:09:21Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.120",
        "name": "Release 0.1.120",
        "tag_name": "0.1.120",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.120",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/14222711",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.120"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2018-11-25T04:53:44Z",
        "datePublished": "2018-11-25T05:40:37Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.119",
        "name": "Release 0.1.119",
        "tag_name": "0.1.119",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.119",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/14169957",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.119"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2018-11-10T00:24:58Z",
        "datePublished": "2018-11-10T01:13:49Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.118",
        "name": "Release 0.1.118",
        "tag_name": "0.1.118",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.118",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/13932022",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.118"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2018-11-09T07:57:27Z",
        "datePublished": "2018-11-09T08:50:54Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.117",
        "name": "Release 0.1.117",
        "tag_name": "0.1.117",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.117",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/13915437",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.117"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2018-11-09T07:12:55Z",
        "datePublished": "2018-11-09T07:56:35Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.116",
        "name": "Release 0.1.116",
        "tag_name": "0.1.116",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.116",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/13914738",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.116"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2018-11-08T20:28:23Z",
        "datePublished": "2018-11-08T20:32:05Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.115",
        "name": "Release 0.1.115",
        "tag_name": "0.1.115",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.115",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/13907424",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.115"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2018-11-08T18:34:47Z",
        "datePublished": "2018-11-08T18:38:31Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.114",
        "name": "Release 0.1.114",
        "tag_name": "0.1.114",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.114",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/13905065",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.114"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2018-11-08T17:25:58Z",
        "datePublished": "2018-11-08T17:29:53Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.113",
        "name": "Release 0.1.113",
        "tag_name": "0.1.113",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.113",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/13903768",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.113"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2018-11-08T16:04:57Z",
        "datePublished": "2018-11-08T16:08:42Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.112",
        "name": "Release 0.1.112",
        "tag_name": "0.1.112",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.112",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/13901898",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.112"
      },
      {
        "authorType": "User",
        "author_name": "plasticity-admin",
        "dateCreated": "2018-11-08T15:05:01Z",
        "datePublished": "2018-11-08T15:49:48Z",
        "html_url": "https://github.com/plasticityai/magnitude/releases/tag/0.1.111",
        "name": "Release 0.1.111",
        "tag_name": "0.1.111",
        "tarball_url": "https://api.github.com/repos/plasticityai/magnitude/tarball/0.1.111",
        "url": "https://api.github.com/repos/plasticityai/magnitude/releases/13901393",
        "zipball_url": "https://api.github.com/repos/plasticityai/magnitude/zipball/0.1.111"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1495,
      "date": "Fri, 24 Dec 2021 11:16:27 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "python",
      "natural-language-processing",
      "nlp",
      "machine-learning",
      "vectors",
      "embeddings",
      "word2vec",
      "fasttext",
      "glove",
      "gensim",
      "fast",
      "memory-efficient",
      "machine-learning-library",
      "word-embeddings"
    ],
    "technique": "GitHub API"
  }
}
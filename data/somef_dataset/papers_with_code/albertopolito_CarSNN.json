{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1711.05101 . Default: 0 .\nTo change the epoch to run the train you have to change the parameter num_epoch in spiking_model_LIF.py script at row 13\n\nExample of command to run the code:\n```\nCUDA_VISIBLE_DEVICES=0 python STBP_dvs_n_car.py --filenet ./net/net_1_4a32c3z2a32c3z2a_100_100.txt --fileresult res_prova_input_100_100_st_1_sl_10_bs_40_15tw_2_ch_trained.txt --batch_size 40 --channel 2 --lr 1e-3 --lr_decay_epoch 20 --lr_decay_value 0.5 --threshold 0.4 --att_window 100 100 0 0 --sample_length 10 --sample_time 1\n```\n\nRunning this code, the weights of the networks are firstly initialized by the values at directories: \"net_1_4a32c3z2a32c3z2a_50_50\", \"net_1_4a32c3z2a32c3z2a_50_50_no_ceil\", \"net_1_4a32c3z2a32c3z2a_100_100\", \"net_1_4a32c3z2a32c3z2a_100_100_no_ceil\", \"net_1_4a32c3z2a32c3z2a_128_128\", \"net_1_4a32c3z2a32c3z2a_128_128_no_ceil\". These values are the results of pre-training of the networks, with neuron threshold equal to 0.4, for 50 epochs using the bias. After that the networks are trained without bias. If you are not interested to reduce the amount of memory used, you can maintain the bias and so change a bit the script \"spiking_model_LIF.py\". This lead to higher accuracy results."
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9932984175916814,
        0.9976801769497279,
        0.9975788273939303,
        0.9999428975807528,
        0.9516107412588403,
        0.9664456561658856
      ],
      "excerpt": "If you used these results in your research, please refer to the paper \nA. Viale, A. Marchisio, M. Martina, G. Masera and M. Shafique, \"CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous Cars on the Loihi Neuromorphic Research Processor,\" 2021 International Joint Conference on Neural Networks (IJCNN), Virtual Event, July 2021. \n  author={A. {Viale} and A. {Marchisio} and M. {Martina} and G. {Masera} and M. {Shafique}}, \n  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)},  \n  title={CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous Cars on the Loihi Neuromorphic Research Processor},  \n  year={2021}, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8944178096468923
      ],
      "excerpt": "  pages={}} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9218387569487573
      ],
      "excerpt": "  \"stride (number<10)\".  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9218387569487573
      ],
      "excerpt": "  \"dropout percentage (number>=10)\". \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/albertopolito/CarSNN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-24T14:46:34Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-09T16:17:32Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9846125857864627
      ],
      "excerpt": "Implementation of CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous Cars on the Loihi Neuromorphic Chip \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.989518696740641
      ],
      "excerpt": "CarSNN is a novel SNN model for the \u201ccars vs. background\u201d classification of event-based streams implemented on neuromorphic hardware.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8141523182909943,
        0.8132339751928183
      ],
      "excerpt": "We use also three different attention windows on the input image in order to speedup the train and test process and to achieve good results. \nWe adopt an accumulation strategy and we give to the network an input image every 1 ms and we predict the class. After 10 sample (so 10 ms) we choose the true classification according to the most predicted.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9279210380462444
      ],
      "excerpt": "The network files are only files with as many rows as the layers used every row identify a layer we give some example to make it easy to understand: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8019135416658847
      ],
      "excerpt": "  \"size of input\" \"size of output\". \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation of CarSNN:  An Efficient Spiking Neural Network for Event-Based Autonomous Cars on the Loihi Neuromorphi",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/albertopolito/CarSNN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 27 Dec 2021 08:31:48 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/albertopolito/CarSNN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "albertopolito/CarSNN",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8046722791214872
      ],
      "excerpt": "  \"size of input\" \"size of output\". \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/albertopolito/CarSNN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "MATLAB"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "CarSNN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "CarSNN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "albertopolito",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/albertopolito/CarSNN/blob/main/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The following parts describe how to use this code.\nTo run this code you must download the dataset from the link https://www.prophesee.ai/2018/03/13/dataset-n-cars/ and then you must change the format of the images with the provided matlab code. Then you can train the network and visualize the test results.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "To run the network we define some arguments to give at the command line:\n* --filenet : is the path of the network we would use. Example: --filenet ./net/net_1_4a32c3z2a32c3z2a_100_100.txt .\n* --fileresult : is the path to save a txt file with some initialization information and the accuracy achieved at every epoch. Default: './result.txt' .\n* --sample_time : for many ms we would accumulate the events before give them to the network. Default: 1 . \n* --sample_length : how many accumulated sample we use to find the class of the stream. Default: 10 . \n* --batch_size : the batch size used both in train and test. Default: 40 .\n* --lr : learning rate. Default: 1e-3 .\n* --lr_decay_epoch : after many epoch we would ciclically modify the lr by --lr_decay_value factor. Default: 20 .\n* --lr_decay_value : how to modify the learning rate. At every lr_decay_epoch we multiply the old learning rate value with this factor that can be greater or less than zero. Default: 0.5 . \n* --threshold : the neuron threshold after that we have an output spike. Default: 0.4 .\n* --n_decay : decay value for the membrane potential of every neurons used (we suggest a number less or equal to 0.2). Default: 0.2 .\n* --att_window : the attention window size and shift. Example --att_window 50 60 20 10 describe and attention window of x size of 50, y size of 60, x shift of 20 and y shift of 10\n* --weight_decay : it is the weight regularization described for the Adam optimizer at the link https://arxiv.org/abs/1711.05101 . Default: 0 .\nTo change the epoch to run the train you have to change the parameter num_epoch in spiking_model_LIF.py script at row 13\n\nExample of command to run the code:\n```\nCUDA_VISIBLE_DEVICES=0 python STBP_dvs_n_car.py --filenet ./net/net_1_4a32c3z2a32c3z2a_100_100.txt --fileresult res_prova_input_100_100_st_1_sl_10_bs_40_15tw_2_ch_trained.txt --batch_size 40 --channel 2 --lr 1e-3 --lr_decay_epoch 20 --lr_decay_value 0.5 --threshold 0.4 --att_window 100 100 0 0 --sample_length 10 --sample_time 1\n```\n\nRunning this code, the weights of the networks are firstly initialized by the values at directories: \"net_1_4a32c3z2a32c3z2a_50_50\", \"net_1_4a32c3z2a32c3z2a_50_50_no_ceil\", \"net_1_4a32c3z2a32c3z2a_100_100\", \"net_1_4a32c3z2a32c3z2a_100_100_no_ceil\", \"net_1_4a32c3z2a32c3z2a_128_128\", \"net_1_4a32c3z2a32c3z2a_128_128_no_ceil\". These values are the results of pre-training of the networks, with neuron threshold equal to 0.4, for 50 epochs using the bias. After that the networks are trained without bias. If you are not interested to reduce the amount of memory used, you can maintain the bias and so change a bit the script \"spiking_model_LIF.py\". This lead to higher accuracy results.\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Mon, 27 Dec 2021 08:31:48 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "With the script Occurrences_and_translation.m you can derive the event occurences for every pixel both negative and positive.\n\nThis code is also usefull to cahnge the format of the inputs. The python code would at input .DAT files that describe the spike trace of the event streams.\nThese files have 4 column with the following format:\n\n\"timestamp of event in usec\" \"x coordinate\" \"y coordinate\" \"polarity of event (-1 or 1)\"\n\nIf you desire you can write your own dataset and give your images with the above format without change nothing\n\n",
      "technique": "Header extraction"
    }
  ]
}
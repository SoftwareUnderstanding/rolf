{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1912.04488",
      "https://arxiv.org/abs/1912.04488",
      "https://arxiv.org/abs/2003.10152",
      "https://arxiv.org/abs/2003.10152",
      "https://arxiv.org/abs/2003.10152"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please consider citing our papers in your publications if the project helps your research. BibTeX reference is as follows.\n```\n@inproceedings{wang2020solo,\n  title     =  {{SOLO}: Segmenting Objects by Locations},\n  author    =  {Wang, Xinlong and Kong, Tao and Shen, Chunhua and Jiang, Yuning and Li, Lei},\n  booktitle =  {Proc. Eur. Conf. Computer Vision (ECCV)},\n  year      =  {2020}\n}\n\n```\n\n```\n@article{wang2020solov2,\n  title={SOLOv2: Dynamic, Faster and Stronger},\n  author={Wang, Xinlong and Zhang, Rufeng and  Kong, Tao and Li, Lei and Shen, Chunhua},\n  journal={arXiv preprint arXiv:2003.10152},\n  year={2020}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{wang2020solov2,\n  title={SOLOv2: Dynamic, Faster and Stronger},\n  author={Wang, Xinlong and Zhang, Rufeng and  Kong, Tao and Li, Lei and Shen, Chunhua},\n  journal={arXiv preprint arXiv:2003.10152},\n  year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{wang2020solo,\n  title     =  {{SOLO}: Segmenting Objects by Locations},\n  author    =  {Wang, Xinlong and Kong, Tao and Shen, Chunhua and Jiang, Yuning and Li, Lei},\n  booktitle =  {Proc. Eur. Conf. Computer Vision (ECCV)},\n  year      =  {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9998580421658192,
        0.9999885386406284,
        0.9992393194923946
      ],
      "excerpt": "Xinlong Wang, Tao Kong, Chunhua Shen, Yuning Jiang, Lei Li   \nIn: Proc. European Conference on Computer Vision (ECCV), 2020 \narXiv preprint (arXiv 1912.04488)    \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999859781959258,
        0.9992393194923946
      ],
      "excerpt": "Xinlong Wang, Rufeng Zhang, Tao Kong, Lei Li, Chunhua Shen       \narXiv preprint (arXiv 2003.10152)   \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MY-Swich/SOLO_my",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-09-02T17:29:46Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-03T03:14:25Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9433296442167397
      ],
      "excerpt": "This project hosts the code for implementing the SOLO algorithms for instance segmentation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8196367465813696,
        0.8546583561756514,
        0.9579188808186961,
        0.931279899002129,
        0.8530622120329378,
        0.9487851675210998,
        0.8505925399734336
      ],
      "excerpt": "Direct instance segmentation: Our method takes an image as input, directly outputs instance masks and corresponding class probabilities, in a fully convolutional, box-free and grouping-free paradigm. \nHigh-quality mask prediction: SOLOv2 is able to predict fine and detailed masks, especially at object boundaries. \nState-of-the-art performance: Our best single model based on ResNet-101 and deformable convolutions achieves 41.7% in AP on COCO test-dev (without multi-scale testing). A light-weight version of SOLOv2 executes at 31.3 FPS on a single V100 GPU and yields 37.1% AP. \nSOLOv2 is available. Code and trained models of SOLOv2 are released. (08/07/2020) \nLight-weight models and R101-based models are available. (31/03/2020)  \nSOLOv1 is available. Code and trained models of SOLO and Decoupled SOLO are released. (28/03/2020) \nFor your convenience, we provide the following trained models on COCO (more models are coming soon). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8063780290279408,
        0.9366127160540743
      ],
      "excerpt": "Light-weight means light-weight backbone, head and smaller input size. Please refer to the corresponding config files for details. \nThis is a reimplementation and the numbers are slightly different from our original paper (within 0.3% in mask AP). \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MY-Swich/SOLO_my/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 22 Dec 2021 22:40:08 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/MY-Swich/SOLO_my/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "MY-Swich/SOLO_my",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/MY-Swich/SOLO_my/master/docker/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/MY-Swich/SOLO_my/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/MY-Swich/SOLO_my/master/demo/inference_demo.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/MY-Swich/SOLO_my/master/tools/slurm_train.sh",
      "https://raw.githubusercontent.com/MY-Swich/SOLO_my/master/tools/slurm_test.sh",
      "https://raw.githubusercontent.com/MY-Swich/SOLO_my/master/tools/dist_test.sh",
      "https://raw.githubusercontent.com/MY-Swich/SOLO_my/master/tools/dist_train.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This implementation is based on [mmdetection](https://github.com/open-mmlab/mmdetection)(v1.0.0). Please refer to [INSTALL.md](docs/INSTALL.md) for installation and dataset preparation.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9175259359356988
      ],
      "excerpt": "For your convenience, we provide the following trained models on COCO (more models are coming soon). \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8148588678152761
      ],
      "excerpt": "SOLOv2_R50_1x | No | 54ms | 34.8 | download \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8778487586960795
      ],
      "excerpt": "Example:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.898584498893152,
        0.9130679612931553,
        0.836863059330239,
        0.8778487586960795,
        0.8723685769332038,
        0.9202684885786453,
        0.8778487586960795,
        0.9218974270439672,
        0.8665729780878333,
        0.8778487586960795,
        0.91859587229505
      ],
      "excerpt": "python tools/train.py ${CONFIG_FILE} \npython tools/train.py configs/solo/solo_r50_fpn_8gpu_1x.py \n./tools/dist_test.sh ${CONFIG_FILE} ${CHECKPOINT_FILE} ${GPU_NUM}  --show --out  ${OUTPUT_FILE} --eval segm \nExample:  \n./tools/dist_test.sh configs/solo/solo_r50_fpn_8gpu_1x.py SOLO_R50_1x.pth  8  --show --out results_solo.pkl --eval segm \npython tools/test_ins.py ${CONFIG_FILE} ${CHECKPOINT_FILE} --show --out  ${OUTPUT_FILE} --eval segm \nExample:  \npython tools/test_ins.py configs/solo/solo_r50_fpn_8gpu_1x.py  SOLO_R50_1x.pth --show --out  results_solo.pkl --eval segm \npython tools/test_ins_vis.py ${CONFIG_FILE} ${CHECKPOINT_FILE} --show --save_dir  ${SAVE_DIR} \nExample:  \npython tools/test_ins_vis.py configs/solo/solo_r50_fpn_8gpu_1x.py  SOLO_R50_1x.pth --show --save_dir  work_dirs/vis_solo \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/MY-Swich/SOLO_my/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cuda",
      "C++",
      "Shell",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/MY-Swich/SOLO_my/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'SOLO for non-commercial purposes\\n\\nCopyright (c) 2019 the authors\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n Redistributions of source code must retain the above copyright notice, this\\n  list of conditions and the following disclaimer.\\n\\n Redistributions in binary form must reproduce the above copyright notice,\\n  this list of conditions and the following disclaimer in the documentation\\n  and/or other materials provided with the distribution.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SOLO: Segmenting Objects by Locations",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SOLO_my",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "MY-Swich",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MY-Swich/SOLO_my/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 22 Dec 2021 22:40:08 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Once the installation is done, you can download the provided models and use [inference_demo.py](demo/inference_demo.py) to run a quick demo.\n\n",
      "technique": "Header extraction"
    }
  ]
}
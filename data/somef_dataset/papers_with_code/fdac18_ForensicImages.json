{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.06870\n\nhttps://github.com/matterport/Mask_RCNN\n\n# Milestones:\nSeptember 28: \nFinished project proposal. Presented plan on October 1st to the class. \n\nOctober 12:\n* Rosemary - explore the pre-trained imagnet models https://github.com/cvjena/cnn-models, read https://arxiv.org/pdf/1612.01452.pdf, figure out how to install caffe to run the model, know what should be the format of the input data if not stated in the above link, selected a model to download: AlexNet_cvgj first, apply model to a subset of images provided by sara\n* Tasmia - dataset of dates have been  processed so that the date can be extracted. Not all dates are in correct format. so fixed that. After that got the unique list of data so that there's no repeatition. Then built a dictionary where key is each date from processed dataset of dates and values are all the weather details prior to that date from the weather dataset\n\nOctober 26:\n* Rosemary - Meet with Professor Mockus to discuss mean.js app goals. Change the code in /opt/mean.js/public/js/scr.js to add a tracking feature for visitation to images that are viewed but no label/tag was added. Look at the code where the image is loaded to add this information to the db. Goal: Apply to all 1M images (get final layer"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "October 12: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fdac18/ForensicImages",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-09-11T19:59:34Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-04-04T22:22:30Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9612011768550992,
        0.9825696821970625,
        0.9918049609068946,
        0.8861106567486092,
        0.9428593790699928,
        0.9554043533725269
      ],
      "excerpt": "Final project for the analysis of forensic images \nIn this project, I want to automate the labeling process of one million forensic images with the goal of detecting what stage of decomposition a corpse is at. \nFor this project three main skill-sets are required and any one with any of these skills is more than welcome to join me. \nImproving the current online platform that facilitates the manual labeling process for gathering training data \nApplying various image processing techniques to preprocess the dataset before training, and using image augmentation to artificially increase the size of the training data. \nHelping with model development, with the aim of detecting forensic features in trained images \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9385544111895455
      ],
      "excerpt": "Finished project proposal. Presented plan on October 1st to the class.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9359854977201757
      ],
      "excerpt": "* Tasmia - dataset of dates have been  processed so that the date can be extracted. Not all dates are in correct format. so fixed that. After that got the unique list of data so that there's no repeatition. Then built a dictionary where key is each date from processed dataset of dates and values are all the weather details prior to that date from the weather dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Final project for DA",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://imgaug.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fdac18/ForensicImages/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Tue, 21 Dec 2021 20:31:25 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/fdac18/ForensicImages/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "fdac18/ForensicImages",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/fdac18/ForensicImages/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "TeX",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "ForensicImages",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ForensicImages",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "fdac18",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fdac18/ForensicImages/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Tue, 21 Dec 2021 20:31:25 GMT"
    },
    "technique": "GitHub API"
  }
}
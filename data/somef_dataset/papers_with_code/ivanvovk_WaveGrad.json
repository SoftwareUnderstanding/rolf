{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Nanxin Chen et al., [WaveGrad: Estimating Gradients for Waveform Generation](https://arxiv.org/pdf/2009.00713.pdf)\n* Jonathan Ho et al., [Denoising Diffusion Probabilistic Models](https://arxiv.org/pdf/2006.11239.pdf)\n* [Denoising Diffusion Probabilistic Models repository](https://github.com/hojonathanho/diffusion) (TensorFlow implementation), from which diffusion calculations have been adopted\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "[x] High-fidelity generation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9725140271112827
      ],
      "excerpt": "|   12 iterations   |   +   |     0.10      |     0.69      |        4.55        | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ivanvovk/WaveGrad",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-09-03T16:02:39Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T04:51:09Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8343288991248883
      ],
      "excerpt": "Implementation (PyTorch) of Google Brain's high-fidelity WaveGrad vocoder (paper). First implementation on GitHub with high-quality generation for 6-iterations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8406551037458322
      ],
      "excerpt": "[x] Training also successfully runs on a single 12GB GPU with batch size 96. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8446537847835132
      ],
      "excerpt": "[x] Flexible architecture configuration for your own data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9157814798231424
      ],
      "excerpt": "[x] 100- and lower-iteration inferences are faster than real-time on RTX 2080 Ti. 6-iteration inference is faster than one reported in the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9818171192620007
      ],
      "excerpt": "WaveGrad is a conditional model for waveform generation through estimating gradients of the data density with WaveNet-similar sampling quality. This vocoder is neither GAN, nor Normalizing Flow, nor classical autoregressive model. The main concept of vocoder is based on Denoising Diffusion Probabilistic Models (DDPM), which utilize Langevin dynamics and score matching frameworks. Furthemore, comparing to classic DDPM, WaveGrad achieves super-fast convergence (6 iterations and probably lower) w.r.t. Langevin dynamics iterative sampling scheme. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8272824785276043
      ],
      "excerpt": "Once model is trained, grid search for the best schedule* for a needed number of iterations in notebooks/inference.ipynb. The code supports parallelism, so you can specify more than one number of jobs to accelerate the search. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8079127891472848
      ],
      "excerpt": "6-iteration schedule was obtained using grid search. After, based on obtained scheme, by hand, I found a slightly better approximation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9703843833001013
      ],
      "excerpt": "*Note: uploaded checkpoint is a dict with a single key 'model'. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9597807453654043
      ],
      "excerpt": "By default model runs in a mixed-precision way. Batch size is modified compared to the paper (256 -> 96) since authors trained their model on TPU. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8452260333198457
      ],
      "excerpt": "(NEW: 10/24/2020) Huge update. Distributed training and mixed-precision support. More correct positional encoding. CLI support for inference. Parallel grid search. Model size significantly decreased. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8546173892839257,
        0.9541557503930269,
        0.926106509419728
      ],
      "excerpt": "Stable training and fixed-iteration inference with significant background static noise left. All positional encoding issues are solved. \nStable training of 25-, 50- and 1000-fixed-iteration models. Found no linear scaling (C=5000 from paper) of positional encoding (bug). \nStable training of 25-, 50- and 1000-fixed-iteration models. Fixed positional encoding downscaling. Parallel segment sampling is replaced by full-mel sampling. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation of Google Brain's WaveGrad high-fidelity vocoder (paper: https://arxiv.org/pdf/2009.00713.pdf). First implementation on GitHub.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ivanvovk/WaveGrad/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 38,
      "date": "Sat, 25 Dec 2021 22:04:33 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ivanvovk/WaveGrad/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ivanvovk/WaveGrad",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ivanvovk/WaveGrad/master/notebooks/inference.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ivanvovk/WaveGrad/master/runs/train.sh",
      "https://raw.githubusercontent.com/ivanvovk/WaveGrad/master/runs/inference.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Make train and test filelists of your audio data like ones included into `filelists` folder.\n2. Make a configuration file* in `configs` folder.\n\n***Note:** if you are going to change `hop_length` for STFT, then make sure that the product of your upsampling `factors` in config is equal to your new `hop_length`.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Clone this repo:\n\n```bash\ngit clone https://github.com/ivanvovk/WaveGrad.git\ncd WaveGrad\n```\n\n2. Install requirements:\n```bash\npip install -r requirements.txt\n```\n\n___\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8704561404618596
      ],
      "excerpt": "[x] Estimated RTF on popular GPU and CPU devices (see below). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9221259495415409,
        0.9223204412708105
      ],
      "excerpt": "Open runs/train.sh script and specify visible GPU devices and path to your configuration file. If you specify more than one GPU the training will run in distributed mode. \nRun sh runs/train.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8417670427659354
      ],
      "excerpt": "Put your mel-spectrograms in some folder. Make a filelist. Then run this command with your own arguments: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8247329307519082
      ],
      "excerpt": "Open runs/train.sh script and specify visible GPU devices and path to your configuration file. If you specify more than one GPU the training will run in distributed mode. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8287888227411123
      ],
      "excerpt": "To track your training process run tensorboard by tensorboard --logdir=logs/YOUR_LOGDIR_FOLDER. All logging information and checkpoints will be stored in logs/YOUR_LOGDIR_FOLDER. logdir is specified in config file. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ivanvovk/WaveGrad/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\n\\nCopyright (c) 2020, Ivan Vovk\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n3. Neither the name of the copyright holder nor the names of its\\n   contributors may be used to endorse or promote products derived from\\n   this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "WaveGrad",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "WaveGrad",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ivanvovk",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ivanvovk/WaveGrad/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 314,
      "date": "Sat, 25 Dec 2021 22:04:33 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "wavegrad",
      "vocoder",
      "text-to-speech",
      "tts",
      "tts-engines",
      "speech",
      "speech-synthesis",
      "ljspeech",
      "probabilistic-models",
      "diffusion-models"
    ],
    "technique": "GitHub API"
  }
}
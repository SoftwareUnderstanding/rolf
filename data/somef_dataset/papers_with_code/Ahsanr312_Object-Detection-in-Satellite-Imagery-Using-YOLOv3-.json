{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1804.02767\n\n#### Darknet framework: http://pjreddie.com/darknet/"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Ahsanr312/Object-Detection-in-Satellite-Imagery-Using-YOLOv3-",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-10-19T17:45:55Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-13T15:12:29Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9943010551159374,
        0.9651515692611101
      ],
      "excerpt": "This repository provides the insight of object detection in Satellite Imagery using YOLOv3. As in satellite imagery the objects are in fewer number of pixels and varies in number of pixels depending on high/low resolution imagery. Hence, some crucial changes are required that are discussed in the repository to detect target objects in satellite imagery. A simple laptop (windows, linux or mac) is all you need for this project, as we will be using Google Colab for training and testing purpose. \nGoogle Colab will be used for the training of YOLOv3. It provides a free service as well as a pro service that can be only used when you pay for it. In our case the free service provided is sufficient enough to train YOLOv3 on our custom dataset. The only disadvantage that I noted is that one can only use it for 12 hours in a single go, after that you will be disconnected and the files will deleted. Though, this problem is solved with help of the falgs in training time. YOLOv3 while training saves weights so even the training is interrupted we can resume training from last saved weights. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9396157090578285
      ],
      "excerpt": "Log in to your google account and go to google drive. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8012866970212649,
        0.8442025367239091
      ],
      "excerpt": "After successful upload, right click on the \"Train_YOLOv3.ipynb\" file and select open with -> Google Colaboratory. The file will opened in the colab. \nNext, we need to choose GPU for our training. To do so, click on \"Edit\" and select \"Notebook settings\" and then choose \"GPU\" under Hardware accelerator option.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.888842718723843
      ],
      "excerpt": "This notebook is created for training YOLOv3 for only one object. But you can do it for as much objects as you desire by changing some parameters. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8775434874477589
      ],
      "excerpt": "width & height represents network resolution. If your training dataset is contains 416x416 dimension images and the network resolution is set to 608x608 then all your dataset will be resized to 608x608 for training. So be careful what you choose before training your model. Network resolution must be set to a multiple of 32 i.e. 416, 448, ..., 608, 640, ... . The higher the network resolution the better the precision of your model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "YOLOv3 - Neural Networks for Object Detection in satellite Imagery. ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Ahsanr312/Object-Detection-in-Satellite-Imagery-Using-YOLOv3-/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Fri, 24 Dec 2021 09:19:53 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Ahsanr312/Object-Detection-in-Satellite-Imagery-Using-YOLOv3-/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Ahsanr312/Object-Detection-in-Satellite-Imagery-Using-YOLOv3-",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Ahsanr312/Object-Detection-in-Satellite-Imagery-Using-YOLOv3-/main/Train_YOLOv3.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- An image dataset is a folder containing images of our target object for which we want to train YOLOv3. There must be a minimum of 100 images that contains the target object. For example I have trained YOLOv3 to recognize Target object, so I have made a dataset comprising of 402 images while each image contains atleast one Target object.\n- Secondly, we need object location in each image that is exactly where the object/objects are located in each images. For this purpose, we need to label each image from our training dataset. An external software will be used for image labeling, that is, \"LabelImg\". You can download it for Windows/Linux from https://tzutalin.github.io/labelImg/ \n- It is a good practice that your training dataset includes images that have objects which we do not want to detect or objects that have key similarities with our target object. This will lead our model to better learn the difference and won't generate false alarms. These images are called negative samples and we should add them with their respective label text file i.e. (empty .txt file). Optimal practice would be adding the same number of positve and negative samples but if not possible low number of negative samples would have an impact too. \n- LabelImg Usage:\n  - Run LabelImg then click on \"Open Dir\" and choose the folder where the training dataset is located.\n  - For \"Change save dir\", choose the same training dataset folder.\n  - Then select saving format which by default is \"PascalVOC\" click to change it to \"YOLO\" format.\n  - For labeling the object, click \"Create RectBox\" and select the area where the target object is located. Then add the label by giving object name (which in our case is Target Object).\n  - Then click on \"Save\" which will generate a .txt for the respective image. Do this for the complete training dataset.\n  - Finally, rename this training dataset folder to \"images\" and compress to get images.zip\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8168531370865534,
        0.8183702801961353,
        0.8568695540124736
      ],
      "excerpt": "Next, we need to choose GPU for our training. To do so, click on \"Edit\" and select \"Notebook settings\" and then choose \"GPU\" under Hardware accelerator option.  \nPress \"save\" and you are good to go. \nNow run each cell one by one and wait for the first cell to complete the execution. (You can run all cells together by clicking \"Runtime\" and then selecting \"Run all\" but I recommend run one cell at a time and check the output and play around) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8213275704993287
      ],
      "excerpt": "Cfg file parameters: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Ahsanr312/Object-Detection-in-Satellite-Imagery-Using-YOLOv3-/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Object-Detection-in-Satellite-Imagery-Using-YOLOv3",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Object-Detection-in-Satellite-Imagery-Using-YOLOv3-",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Ahsanr312",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Ahsanr312/Object-Detection-in-Satellite-Imagery-Using-YOLOv3-/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Fri, 24 Dec 2021 09:19:53 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "train-yolov3",
      "training-dataset",
      "google-colab",
      "labelimg",
      "object-detection",
      "satellite-imagery",
      "darknet"
    ],
    "technique": "GitHub API"
  }
}
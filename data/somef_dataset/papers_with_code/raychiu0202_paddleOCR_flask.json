{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2009.09941\n- [more](./doc/doc_en/update_en.md",
      "https://arxiv.org/abs/2009.09941"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.999251770319566
      ],
      "excerpt": "- 2021.4.8 release end-to-end text recognition algorithm PGNet which is published in AAAI 2021. Find tutorial here\uff1brelease multi language recognition models, support more than 80 languages recognition; especically, the performance of English recognition model is Optimized. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9980269494114387
      ],
      "excerpt": "- 2020.9.22 Update the PP-OCR technical article, https://arxiv.org/abs/2009.09941 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9648889021544168,
        0.9156566588472104,
        0.9998076183875745,
        0.9829671698339112
      ],
      "excerpt": "Ultra lightweight ppocr_mobile series models: detection (3.0M) + direction classifier (1.4M) + recognition (5.0M) = 9.4M \nGeneral ppocr_server series models: detection (47.1M) + direction classifier (1.4M) + recognition (94.9M) = 143.4M \nSupport Chinese, English, and digit recognition, vertical text recognition, and long text recognition \nSupport multi-language recognition: Korean, Japanese, German, French \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/raychiu0202/paddleOCR_flask",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-28T01:40:27Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-12T07:50:24Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "PaddleOCR aims to create multilingual, awesome, leading, and practical OCR tools that help users train better models and apply them into practice.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.815106976172323
      ],
      "excerpt": "- Static graph: develop branch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9037171427526969,
        0.918664374871272,
        0.909786167111149,
        0.9536073320273553
      ],
      "excerpt": "- 2021.4.8 release end-to-end text recognition algorithm PGNet which is published in AAAI 2021. Find tutorial here\uff1brelease multi language recognition models, support more than 80 languages recognition; especically, the performance of English recognition model is Optimized. \n- 2021.1.21 update more than 25+ multilingual recognition models models list, including\uff1aEnglish, Chinese, German, French, Japanese\uff0cSpanish\uff0cPortuguese Russia Arabic and so on.  Models for more languages will continue to be updated Develop Plan. \n- 2020.12.15 update Data synthesis tool, i.e., Style-Text\uff0ceasy to synthesize a large number of images which are similar to the target scene image. \n- 2020.11.25 Update a new data annotation tool, i.e., PPOCRLabel, which is helpful to improve the labeling efficiency. Moreover, the labeling results can be used in training of the PP-OCR system directly. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8886034359529978
      ],
      "excerpt": "- more \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8288351407460303,
        0.8133740703210695,
        0.9048771550258446
      ],
      "excerpt": "Rich toolkits related to the OCR areas \nSemi-automatic data annotation tool, i.e., PPOCRLabel: support fast and efficient data annotation \nData synthesis tool, i.e., Style-Text: easy to synthesize a large number of images which are similar to the target scene image \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9886531329542464
      ],
      "excerpt": "The above pictures are the visualizations of the general ppocr_server model. For more effect pictures, please see More visualizations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9430406281719005
      ],
      "excerpt": "Scan the QR code below with your Wechat, you can access to official technical exchange group. Look forward to your participation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9893623633608055
      ],
      "excerpt": "Mobile DEMO experience (based on EasyEdge and Paddle-Lite, supports iOS and Android systems): Sign in to the website to obtain the QR code for  installing the App \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8470348489146027
      ],
      "excerpt": "Note : Compared with models 1.1, which are trained with static graph programming paradigm, models 2.0 are the dynamic graph trained version and achieve close performance. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8157067308736388,
        0.8131098140023612,
        0.9212142513686847,
        0.9607044559947128
      ],
      "excerpt": "| Chinese and English ultra-lightweight OCR model (9.4M)       | ch_ppocr_mobile_v2.0_xx      | Mobile & server   |inference model / pre-trained model|inference model / pre-trained model |inference model / pre-trained model      | \n| Chinese and English general OCR model (143.4M)               | ch_ppocr_server_v2.0_xx      | Server            |inference model / pre-trained model    |inference model / pre-trained model    |inference model / pre-trained model  |   \nFor more model downloads (including multiple languages), please refer to PP-OCR v2.0 series model downloads. \nFor a new language request, please refer to Guideline for new language_requests. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9954181077794458,
        0.860059181823877
      ],
      "excerpt": "PP-OCR is a practical ultra-lightweight OCR system. It is mainly composed of three parts: DB text detection[2], detection frame correction and CRNN text recognition[7]. The system adopts 19 effective strategies from 8 aspects including backbone network selection and adjustment, prediction head design, data augmentation, learning rate transformation strategy, regularization parameter selection, pre-training model use, and automatic model tailoring and quantization to optimize and slim down the models of each module. The final results are an ultra-lightweight Chinese and English OCR model with an overall size of 3.5M and a 2.8M English digital OCR model. For more details, please refer to the PP-OCR technical article (https://arxiv.org/abs/2009.09941). Besides, The implementation of the FPGM Pruner [8] and PACT quantization [9] is based on PaddleSlim. \nChinese OCR model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "English OCR model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "Multilingual OCR model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9579491984280083
      ],
      "excerpt": "it is necessary to submit the dict text to this path and name it with {language}_dict.txt that contains a list of all characters. Please see the format example from other files in that folder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9754285120101559
      ],
      "excerpt": "it is necessary to submit the corpus to this path and name it with {language}_corpus.txt that contains a list of words in your language. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9700802467567973
      ],
      "excerpt": "Of course, the more, the better. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9080834692607338
      ],
      "excerpt": "More details, please refer to Multilingual OCR Development Plan. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9517436376782173,
        0.9637996179111497,
        0.8755251888340795,
        0.9467886552218907,
        0.9321671712655877
      ],
      "excerpt": "We welcome all the contributions to PaddleOCR and appreciate for your feedback very much. \nMany thanks to Khanh Tran and Karl Horky for contributing and revising the English documentation. \nMany thanks to zhangxin for contributing the new visualize function\u3001add .gitignore and discard set PYTHONPATH manually. \nMany thanks to lyl120117 for contributing the code for printing the network structure. \nThanks xiangyubo for contributing the handwritten Chinese OCR datasets. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/raychiu0202/paddleOCR_flask/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 12:15:47 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/raychiu0202/paddleOCR_flask/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "raychiu0202/paddleOCR_flask",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/raychiu0202/paddleOCR_flask/main/deploy/docker/hubserving/gpu/Dockerfile",
      "https://raw.githubusercontent.com/raychiu0202/paddleOCR_flask/main/deploy/docker/hubserving/cpu/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/raychiu0202/paddleOCR_flask/tree/main/deploy/cpp_infer/docs"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/raychiu0202/paddleOCR_flask/main/train.sh",
      "https://raw.githubusercontent.com/raychiu0202/paddleOCR_flask/main/deploy/cpp_infer/tools/build.sh",
      "https://raw.githubusercontent.com/raychiu0202/paddleOCR_flask/main/deploy/cpp_infer/tools/run.sh",
      "https://raw.githubusercontent.com/raychiu0202/paddleOCR_flask/main/deploy/lite/prepare.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9346741718590027,
        0.8889066179857147
      ],
      "excerpt": "Support PIP installation, easy to use \nSupport Linux, Windows, MacOS and other systems \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.960655865757732
      ],
      "excerpt": "Also, you can scan the QR code below to install the App (Android support only) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "<a name=\"language_requests\"></a> \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9197735714648932,
        0.9197735714648932,
        0.9197735714648932
      ],
      "excerpt": "    <img src=\"doc/imgs_results/ch_ppocr_mobile_v2.0/test_add_91.jpg\" width=\"800\"> \n    <img src=\"doc/imgs_results/multi_lang/img_01.jpg\" width=\"800\"> \n    <img src=\"doc/imgs_results/multi_lang/img_02.jpg\" width=\"800\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8887481150430047
      ],
      "excerpt": "<img src=\"./doc/ocr-android-easyedge.png\"  width = \"200\" height = \"200\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8606280910157142
      ],
      "excerpt": "OCR Quick Start \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8890818307099057
      ],
      "excerpt": "    <img src=\"./doc/ppocr_framework.png\" width=\"800\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9197735714648932,
        0.9197735714648932,
        0.9197735714648932,
        0.9197735714648932
      ],
      "excerpt": "    <img src=\"./doc/imgs_results/ch_ppocr_mobile_v2.0/test_add_91.jpg\" width=\"800\"> \n    <img src=\"./doc/imgs_results/ch_ppocr_mobile_v2.0/00015504.jpg\" width=\"800\"> \n    <img src=\"./doc/imgs_results/ch_ppocr_mobile_v2.0/00056221.jpg\" width=\"800\"> \n    <img src=\"./doc/imgs_results/ch_ppocr_mobile_v2.0/rotate_00052204.jpg\" width=\"800\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9197735714648932
      ],
      "excerpt": "    <img src=\"./doc/imgs_results/ch_ppocr_mobile_v2.0/img_12.jpg\" width=\"800\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9197735714648932,
        0.9197735714648932
      ],
      "excerpt": "    <img src=\"./doc/imgs_results/french_0.jpg\" width=\"800\"> \n    <img src=\"./doc/imgs_results/korean.jpg\" width=\"800\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "<a name=\"language_requests\"></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8762600540369976
      ],
      "excerpt": "In folder ppocr/utils/dict, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9017649551544327
      ],
      "excerpt": "In folder ppocr/utils/corpus, \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/raychiu0202/paddleOCR_flask/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C++",
      "Java",
      "CMake",
      "Makefile",
      "Dockerfile",
      "PowerShell",
      "Batchfile",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Apache License 2.0",
      "url": "https://api.github.com/licenses/apache-2.0"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright Jason R. Coombs\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to\\ndeal in the Software without restriction, including without limitation the\\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\\nsell copies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\\nIN THE SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Introduction",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "paddleOCR_flask",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "raychiu0202",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/raychiu0202/paddleOCR_flask/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 23 Dec 2021 12:15:47 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [Installation](./doc/doc_en/installation_en.md)\n- [Quick Start(Chinese)](./doc/doc_en/quickstart_en.md)\n- [Quick Start(English&Multi-languages)](./doc/doc_en/multi_languages_en.md)\n- [Code Structure](./doc/doc_en/tree_en.md)\n- Algorithm Introduction\n    - [Text Detection Algorithm](./doc/doc_en/algorithm_overview_en.md)\n    - [Text Recognition Algorithm](./doc/doc_en/algorithm_overview_en.md)\n    - [PP-OCR Pipeline](#PP-OCR-Pipeline)\n- Model Training/Evaluation\n    - [Text Detection](./doc/doc_en/detection_en.md)\n    - [Text Recognition](./doc/doc_en/recognition_en.md)\n    - [Direction Classification](./doc/doc_en/angle_class_en.md)\n    - [Yml Configuration](./doc/doc_en/config_en.md)\n- Inference and Deployment\n    - [Quick Inference Based on PIP](./doc/doc_en/whl_en.md)\n    - [Python Inference](./doc/doc_en/inference_en.md)\n    - [C++ Inference](./deploy/cpp_infer/readme_en.md)\n    - [Serving](./deploy/pdserving/README.md)\n    - [Mobile](./deploy/lite/readme_en.md)\n    - [Benchmark](./doc/doc_en/benchmark_en.md)  \n- Data Annotation and Synthesis\n    - [Semi-automatic Annotation Tool: PPOCRLabel](./PPOCRLabel/README.md)\n    - [Data Synthesis Tool: Style-Text](./StyleText/README.md)\n    - [Other Data Annotation Tools](./doc/doc_en/data_annotation_en.md)\n    - [Other Data Synthesis Tools](./doc/doc_en/data_synthesis_en.md)\n- Datasets\n    - [General OCR Datasets(Chinese/English)](./doc/doc_en/datasets_en.md)\n    - [HandWritten_OCR_Datasets(Chinese)](./doc/doc_en/handwritten_datasets_en.md)\n    - [Various OCR Datasets(multilingual)](./doc/doc_en/vertical_and_multilingual_datasets_en.md)\n- [Visualization](#Visualization)\n- [New language requests](#language_requests)\n- [FAQ](./doc/doc_en/FAQ_en.md)\n- [Community](#Community)\n- [References](./doc/doc_en/reference_en.md)\n- [License](#LICENSE)\n- [Contribution](#CONTRIBUTION)\n\n\n\n<a name=\"PP-OCR-Pipeline\"></a>\n\n",
      "technique": "Header extraction"
    }
  ]
}
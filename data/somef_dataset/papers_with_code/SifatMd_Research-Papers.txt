# Research-Papers

Inspired by Dr. Andrew Ng's advice on [how to read research papers](https://youtu.be/733m6qBH-jI?t=160), I will keep a list of research papers that either I have already read or plan on reading.

| Research Paper Name                                                                  | URL                              | Progress (\*/10) |
|--------------------------------------------------------------------------------------|----------------------------------|------------------|
| Attention is All You Need                                                            | [arxiv](https://arxiv.org/abs/1706.03762v5)   | 10   |      
| Generative Adversarial Nets                                                          | [arxiv](https://arxiv.org/abs/1406.2661)  | 10       | 
| BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding     | [arxiv](https://arxiv.org/abs/1810.04805) | 7        |
| Conditional Generative Adversarial Nets                                              | [arxiv](https://arxiv.org/abs/1411.1784)  | 10       |
| Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks | [arxiv](https://arxiv.org/abs/1511.06434) | 10 | 
| Jekyll: Attacking Medical Image Diagnostics using Deep Generative Models             | [Link](https://people.cs.vt.edu/vbimal/publications/jekyll-eurosp20.pdf) |      10 |
| Automated Crowdturfing Attacks and Defenses in Online Review Systems                 | [Link](https://dl.acm.org/doi/abs/10.1145/3133956.3133990?casa_token=bIXUVE4mZxEAAAAA:T84ktHuSd_RQ6rdf43ie6NbfWyAXs5ns7RafzMWL_dh0fOc_x17xgIdw7A4bal_CubAlAzoMXOQ) |      10 |
| EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks             | [arxiv](https://arxiv.org/abs/1905.11946)    | 5 |
| Defending Against Neural Fake News           | [Link](http://papers.nips.cc/paper/9106-defending-against-neural-fake-news.pdf) | 10 | 
| Explaining and Harnessing Adversarial Examples | [arxiv](https://arxiv.org/abs/1412.6572) | 10 | 
| Towards Evaluating the Robustness of Neural Networks | [arxiv](https://arxiv.org/abs/1608.04644) | 10 |
| Robust Physical World Attacks on Deep Learning Visual Classification | [arxiv](https://arxiv.org/abs/1707.08945) | 10 |
| Efficient Transformers: A Survey        | [arxiv](https://arxiv.org/abs/2009.06732)   | 1 | 
| Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods | [arxiv](https://arxiv.org/abs/1705.07263) | 4 | 

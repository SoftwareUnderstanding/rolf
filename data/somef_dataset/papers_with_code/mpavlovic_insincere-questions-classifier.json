{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "https://arxiv.org/pdf/1409.0473.pdf <br>\nhttps://www.tensorflow.org/tutorials/text/nmt_with_attention <br>\nhttps://www.kaggle.com/wowfattie/3rd-place <br>\nhttps://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings <br>\nhttps://www.kaggle.com/theoviel/improve-your-score-with-text-preprocessing-v2 <br>\nhttps://www.kaggle.com/c/quora-insincere-questions-classification/discussion/80568 <br>\n\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mpavlovic/insincere-questions-classifier",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-11-23T21:39:40Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-11-25T22:32:07Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.988546707882293
      ],
      "excerpt": "Deep learning model for the Quora Insincere Questions Classification competition on Kaggle. Based on bidirectional LSTMs, GRUs and Bahdanau attention. Implemented in TensorFlow 2.0 and Keras. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8884327002064788
      ],
      "excerpt": "The model is in essence a logistic regression classifier whose inputs are featrures extracted in previous layers:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9527325686803052,
        0.9834047903864416,
        0.9351850168281489,
        0.914411137031262,
        0.9940272823896573,
        0.9184616108348114,
        0.9488501108016091
      ],
      "excerpt": "The input to the model are two 300 dimensional weighted sums of pretrained embeddings available on the competition, concatenated to a single 600 dimensional input vector passed to the embedding layer. Embeddings were frozen during training.<br><br> \nAfter spatial dropout, a bidirectional LSTM layer is applied, whose states are averaged and max pooled. Besides that, the last output state is passed to the Bahdanau attention layer as a query, together with all states over time as values. This was done separately for the first 256 dimensions of the output states, which are result of the left-to-right LSTM pass. The same thing was repeated for the second 256 dimensions of the LSTM states (right-to-left pass).<br><br> \nThe second middle layer is a bidirectional GRU, but implemented as two separate layers - one in the LTR, and other in RTL direction. This may look as a weird choice, but couple of experiments constantly showed better performance when implemented this way. The GRU states from both directions were averaged and max pooled, as well as passed to the respective Bahdanau attention layers as values, together with last output states as queries.<br><br> \nAll average, max pool and attention outputs are concatenated and passed to a single neuron in the output dense layer. Vectors from LSTM layer are passed through a skip connection over the GRU layers. Output layer is effectively a logistic regression classifier whose input is a vector of extracted features from different network layers. \nPreprocessing for embeddings coverage - it was very important to preprocess text to ensure as higher embeddings coverage as possible. These techniques included cleaning of contractions and special characters, simpler spelling correction, lowercasing of words whose uppercased versions didn't exist in embeddings and/or usage of stemmers and lemmatizer. See References for more details about preprocessing.<br><br> \nWeighted averaging and concatenation of embeddings - the model was firstly trained with 0.7 * GloVe + 0.3 * Paragram embeddings, as it was shown here. Other two embeddings were averaged later (0.7 * WikiNews + 0.3 * GoogleNews) and concatenated to the first ebmeddings average. Both techniques improved model performance.<br><br> \nCustom threshold search - finding of the right decision threshold was also one of the crucial steps in obtaining high leaderboard result. The search was done with the help of 5-folded cross validation - after training on each fold, a threshold with highest F1 score was retained. Thresholds from all folds were later averaged to the single final threshold value.<br><br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Solution for the Quora Insincere Questions Classification Kaggle competition.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mpavlovic/insincere-questions-classifier/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 10:02:53 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mpavlovic/insincere-questions-classifier/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "mpavlovic/insincere-questions-classifier",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.9040392588607754
      ],
      "excerpt": "<img src=\"model.PNG\" width=\"640\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mpavlovic/insincere-questions-classifier/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Milan Pavlovi\\xc4\\x87\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Insincere Questions Classifier",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "insincere-questions-classifier",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "mpavlovic",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mpavlovic/insincere-questions-classifier/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please install the following requirements:\n* Python 3.6\n* TensorFlow 2.0\n* Numpy\n* Pandas\n* Scikit-learn\n* Gensim\n* NLTK\n<br><br>\n\nThe submission script which was executed as a Kaggle kernel is `submission_script.py` file. It Is also available \n[here](https://www.kaggle.com/milanp/quora-insincere-questions-late-submission-script/code?scriptVersionId=23933427) as a public kernel.\n<br><br>\nIf you want to make experiments with different models and hyperparameters, please use `main.py` and `build_model.py` files. The model can be tweaked in `build_model.py` file, whereas 5-folded cross validated experiment is executed in `main.py`. Before running, please update the appropriate paths to train and test datasets (lines 37 and 38), as well as paths to embedding files (lines 40-43) in `main.py`. Both training data and pretrained embeddings are available on the competition's [official website](https://www.kaggle.com/c/quora-insincere-questions-classification/). You can also change some hyperparameters in `hparams` dictionary in lines 97-120 of `main.py`. \n<br><br>\nSettings from every experiment will be saved to a separate folder, which will be printed out at the end. Both `main.py` and `build_model.py` files are modified and belong to a small competition framework which is described in detail [here](https://github.com/mpavlovic/toxic-comments-classification).\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 10:02:53 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "keras",
      "lstm",
      "gru",
      "quora-insincere-question",
      "kaggle-competition",
      "deep-learning",
      "tensorflow-2",
      "python-3",
      "bahdanau-attention",
      "text-classifier"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please install the following requirements:\n* Python 3.6\n* TensorFlow 2.0\n* Numpy\n* Pandas\n* Scikit-learn\n* Gensim\n* NLTK\n<br><br>\n\nThe submission script which was executed as a Kaggle kernel is `submission_script.py` file. It Is also available \n[here](https://www.kaggle.com/milanp/quora-insincere-questions-late-submission-script/code?scriptVersionId=23933427) as a public kernel.\n<br><br>\nIf you want to make experiments with different models and hyperparameters, please use `main.py` and `build_model.py` files. The model can be tweaked in `build_model.py` file, whereas 5-folded cross validated experiment is executed in `main.py`. Before running, please update the appropriate paths to train and test datasets (lines 37 and 38), as well as paths to embedding files (lines 40-43) in `main.py`. Both training data and pretrained embeddings are available on the competition's [official website](https://www.kaggle.com/c/quora-insincere-questions-classification/). You can also change some hyperparameters in `hparams` dictionary in lines 97-120 of `main.py`. \n<br><br>\nSettings from every experiment will be saved to a separate folder, which will be printed out at the end. Both `main.py` and `build_model.py` files are modified and belong to a small competition framework which is described in detail [here](https://github.com/mpavlovic/toxic-comments-classification).\n\n",
      "technique": "Header extraction"
    }
  ]
}
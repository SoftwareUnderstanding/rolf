{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "My thanks are due to members in Yoshiyuki Kubota lab: in particular to Hidetoshi Urakubo for helpful discussion and preparing mitochondria labels from the SNEMI dataset. \n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1505.04597"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. International Conference on Medical image computing and computer-assisted intervention, 234-241. ([link](https://arxiv.org/abs/1505.04597))\n\n```\n@misc{ronneberger2015unet,\n    title={U-Net: Convolutional Networks for Biomedical Image Segmentation},\n    author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},\n    year={2015},\n    eprint={1505.04597},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}\n```\n\n2. Urakubo, H., Bullmann, T., Kubota, Y., Oba, S., & Ishii, S., (2019). UNI-EM: An Environment for Deep Neural Network-Based Automated Segmentation of Neuronal Electron Microscopic Images. Scientific Reports 9, 19413. ([link](https://www.nature.com/articles/s41598-019-55431-0))\n\n```\n@article{urakubo_bullmann_kubota_oba_ishii_2019,\n  title={UNI-EM: An Environment for Deep Neural Network-Based Automated Segmentation of Neuronal Electron Microscopic Images},\n  author={Urakubo, Hidetoshi and Bullmann, Torsten and Kubota, Yoshiyuki and Oba, Shigeyuki and Ishii, Shin},\n  year={2019},\n  DOI={10.1101/607366}\n}\n```\n\n3. Arganda-Carreras, I., Seung, S., H., Vishwanathan, A., & Berger, D., R. (2013). SNEMI3D: 3D Segmentation of neurites in EM images. ISBI 2013. ([link](http://brainiac2.mit.edu/SNEMI3D/home))\n\n```\n@article{kasthuri2015saturated,\n  title={Saturated reconstruction of a volume of neocortex},\n  author={Kasthuri, Narayanan and Hayworth, Kenneth Jeffrey and Berger, Daniel Raimund and Schalek, Richard Lee and Conchello, Jos{\\'e} Angel and Knowles-Barley, Seymour and Lee, Dongil and V{\\'a}zquez-Reina, Amelio and Kaynig, Verena and Jones, Thouis Raymond and others},\n  journal={Cell},\n  volume={162},\n  number={3},\n  pages={648--661},\n  year={2015},\n  publisher={Elsevier}\n}\n```\n\n4. YunYang1994. (2019). U-Net: Convolutional Networks for Biomedical Image Segmentation. GitHub repository. https://github.com/YunYang1994/TensorFlow2.0-Examples\n```\n@Github_Project{TensorFlow2.0-Examples,\n  title={U-Net: Convolutional Networks for Biomedical Image Segmentation},\n  author={YunYang1994},\n  email={www.dreameryangyun@sjtu.edu.cn},\n  url={https://github.com/YunYang1994/TensorFlow2.0-Examples},\n  year={2019},\n}\n```\n\n5. albumentations-team. (2020). albumentations. GitHub repository. https://github.com/albumentations-team/albumentations\n```\n@Article{info11020125,\n    author = {Buslaev, Alexander and Iglovikov, Vladimir I. and Khvedchenya, Eugene and Parinov, Alex and Druzhinin, Mikhail and Kalinin, Alexandr A.},\n    title = {Albumentations: Fast and Flexible Image Augmentations},\n    journal = {Information},\n    volume = {11},\n    year = {2020},\n    number = {2},\n    article-number = {125},\n    URL = {https://www.mdpi.com/2078-2489/11/2/125},\n    ISSN = {2078-2489},\n    DOI = {10.3390/info11020125}\n}\n```\n\n6. Tukiainen, M. (2019). ImageDataAugmentor. GitHub repository. https://github.com/mjkvaak/ImageDataAugmentor\n\n```\n@misc{mjkvaak_aug,\n  author = {Tukiainen, M.},\n  title = {ImageDataAugmentor},\n  year = {2019},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {https://github.com/mjkvaak/ImageDataAugmentor/}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{mjkvaak_aug,\n  author = {Tukiainen, M.},\n  title = {ImageDataAugmentor},\n  year = {2019},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {https://github.com/mjkvaak/ImageDataAugmentor/}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@Article{info11020125,\n    author = {Buslaev, Alexander and Iglovikov, Vladimir I. and Khvedchenya, Eugene and Parinov, Alex and Druzhinin, Mikhail and Kalinin, Alexandr A.},\n    title = {Albumentations: Fast and Flexible Image Augmentations},\n    journal = {Information},\n    volume = {11},\n    year = {2020},\n    number = {2},\n    article-number = {125},\n    URL = {https://www.mdpi.com/2078-2489/11/2/125},\n    ISSN = {2078-2489},\n    DOI = {10.3390/info11020125}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{kasthuri2015saturated,\n  title={Saturated reconstruction of a volume of neocortex},\n  author={Kasthuri, Narayanan and Hayworth, Kenneth Jeffrey and Berger, Daniel Raimund and Schalek, Richard Lee and Conchello, Jos{\\'e} Angel and Knowles-Barley, Seymour and Lee, Dongil and V{\\'a}zquez-Reina, Amelio and Kaynig, Verena and Jones, Thouis Raymond and others},\n  journal={Cell},\n  volume={162},\n  number={3},\n  pages={648--661},\n  year={2015},\n  publisher={Elsevier}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{urakubo_bullmann_kubota_oba_ishii_2019,\n  title={UNI-EM: An Environment for Deep Neural Network-Based Automated Segmentation of Neuronal Electron Microscopic Images},\n  author={Urakubo, Hidetoshi and Bullmann, Torsten and Kubota, Yoshiyuki and Oba, Shigeyuki and Ishii, Shin},\n  year={2019},\n  DOI={10.1101/607366}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{ronneberger2015unet,\n    title={U-Net: Convolutional Networks for Biomedical Image Segmentation},\n    author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},\n    year={2015},\n    eprint={1505.04597},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sumiya-kuroda/EMsegmentation-mito",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-18T03:01:44Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-10T09:09:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "`SNEMI3D_mito` contains 50 training images, 20 validation iamges, and 30 test images. Each of them is an 8-bit grayscale png file and has a size of 1024 x 1024 pixels. [CLAHE](https://imagej.net/Enhance_Local_Contrast_(CLAHE)) was applied beforehand to prevent the amplification of noise. Below is the directory structure of `SNEMI3D_mito`, and when you input your own EM images to the U-Net, your datasets should have the same structure.\n\n```\nSNEMI3D_mito/\n\u251c\u2500\u2500 train/\n\u2502   \u251c\u2500\u2500 images/ \n\u2502   \u2502    \u251c\u2500\u2500 0000.png\n\u2502   \u2502    \u251c\u2500\u2500 0001.png\n\u2502   \u2502    \u251c\u2500\u2500 ...\n\u2502   \u2502    \u2514\u2500\u2500 0049.png\n\u2502   \u2514\u2500\u2500 labels/\n\u2502        \u251c\u2500\u2500 0000.png\n\u2502        \u251c\u2500\u2500 0001.png\n\u2502        \u251c\u2500\u2500 ...\n\u2502        \u2514\u2500\u2500 0049.png\n\u251c\u2500\u2500 valid/\n\u2502   \u251c\u2500\u2500 images/ \n\u2502   \u2502    \u251c\u2500\u2500 0050.png\n\u2502   \u2502    \u251c\u2500\u2500 0051.png\n\u2502   \u2502    \u251c\u2500\u2500 ...\n\u2502   \u2502    \u2514\u2500\u2500 0069.png\n\u2502   \u2514\u2500\u2500 labels/ \n\u2502        \u251c\u2500\u2500 0050.png\n\u2502        \u251c\u2500\u2500 0051.png\n\u2502        \u251c\u2500\u2500 ...\n\u2502        \u2514\u2500\u2500 0069.png\n\u2514\u2500\u2500 test/\n    \u251c\u2500\u2500 images/ \n    \u2502    \u251c\u2500\u2500 0070.png\n    \u2502    \u251c\u2500\u2500 0071.png\n    \u2502    \u251c\u2500\u2500 ...\n    \u2502    \u2514\u2500\u2500 0099.png\n    \u2514\u2500\u2500 labels/\n         \u251c\u2500\u2500 0070.png\n         \u251c\u2500\u2500 0071.png\n         \u251c\u2500\u2500 ...\n         \u2514\u2500\u2500 0099.png\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "**U-Net** is a CNN used to segment areas of an image by class, and known for higher RAND index score of mitochodnria segmentation from electron microscopy images [1,2]. This repository provides the Python code for automatic segmentation of mitochondria using (2D) U-Net from EM images by [SNEMI3D](http://brainiac2.mit.edu/SNEMI3D/) [3].\n\nThe code for U-Net model was adapted from [this repositroy](https://github.com/YunYang1994/TensorFlow2.0-Examples) [4]. Keras has a built-in class `ImageDataGenerator` for data augmentation, but I have also tried to use the combination of more flexible tools: [`albumentations`](https://github.com/albumentations-team/albumentations) and [`ImageDataAugmentor`](https://github.com/mjkvaak/ImageDataAugmentor) (see [`seg_mito_albumentations.ipynb`](https://github.com/sumiya-kuroda/EMsegmentation-mito/blob/master/notebooks/seg_mito_albumentations.ipynb))[5,6]. \n\n<img src=\"https://github.com/sumiya-kuroda/EMsegmentation-mito/blob/master/misc/fig.png\" alt=\"example\" title=\"example\">\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "EM segmentation of mitochondria from SNEMI3D data",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sumiya-kuroda/EMsegmentation-mito/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Wed, 22 Dec 2021 19:29:07 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sumiya-kuroda/EMsegmentation-mito/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "sumiya-kuroda/EMsegmentation-mito",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/sumiya-kuroda/EMsegmentation-mito/master/notebooks/seg_mito_albumentations.ipynb",
      "https://raw.githubusercontent.com/sumiya-kuroda/EMsegmentation-mito/master/notebooks/seg_mito_keras.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8432523518828996
      ],
      "excerpt": "OS Platform and Distribution: Linux Ubuntu 18.04 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9069938650747974,
        0.9857659135807597,
        0.9292426276295549,
        0.9631203550342607,
        0.8811827986415804
      ],
      "excerpt": "CUDA/cuDNN version: CUDA 10.1 / cuDNN 7.6.5 \nPython version: 3.6.9 \nTensorFlow version: 2.1.0 \nTensorFlow installed from: pipenv install tensorflow==2.1.0 \nOnce you installed packages, you can start training and testing with following command. They use dataset/SNEMI3D_mito data by default. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8174540907975313,
        0.8180114234170689,
        0.8633989807152664,
        0.8180114234170689
      ],
      "excerpt": ": training \n$ pipenv run python3 training_mito.py \n: test \n$ pipenv run python3 test_mito.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.82476921035949
      ],
      "excerpt": "At the same time, you can try segmentaion of your own files (after saving your U-Net model to a HDF file). Put your EM images into the dataset direcotry, and use prediction_mito.py. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9054857050121244
      ],
      "excerpt": "$ pipenv run python3 prediction_mito.py --input dataset/demo \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sumiya-kuroda/EMsegmentation-mito/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "EMsegmentation-mito",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "EMsegmentation-mito",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "sumiya-kuroda",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sumiya-kuroda/EMsegmentation-mito/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Wed, 22 Dec 2021 19:29:07 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "connectome",
      "segmentation",
      "u-net",
      "mitochondria",
      "deep-learning"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Install packages on `requirements.txt` or `Pipfile` from the command line, with whatever package managers you prefer. The instruction below was using `pipenv`.\n\n```sh\n$ pip install pipenv\n$ pipenv install\n#: use pipenv graph to check installed packages\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
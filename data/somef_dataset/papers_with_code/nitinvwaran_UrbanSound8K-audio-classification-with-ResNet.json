{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1512.03385"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8772692606136239
      ],
      "excerpt": "Residual Networks <br /> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nitinvwaran/UrbanSound8K-audio-classification-with-ResNet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-05-05T21:16:48Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-25T00:50:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8891708994469337,
        0.8377923119166353
      ],
      "excerpt": "This project aims to classify the environmental sounds from the UrbanSound8K dataset, using a ResNet-18 architecture. <br /> \nIn addition, Google's Speech Command Dataset is also classified using the ResNet-18 architecture. <br /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8678229112594223,
        0.9140452106262658
      ],
      "excerpt": "This is the dataset creator's recommended approach: 10-fold Cross Validation, using all data in each fold for training and validation.  <br /> \nThe average of the validation accuracy, training accuracy, and training loss across 10-folds is taken at the end of each epoch. <br /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.846984707842938
      ],
      "excerpt": "This is the test accuracy on a sample of 11,004 voice files \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9017556720161661,
        0.8382829343539328,
        0.8321491612459216
      ],
      "excerpt": "Validation Accuracy is 90.17% (9,980 datapoints) \nThis is the validation accuracy after 30 epochs \nGENERAL COMMENTS ABOUT DATA PREPARATION. MODELING, AND ACKNOWLEDGEMENTS <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8248124247888752
      ],
      "excerpt": "This is the dataset released by Google Research, related to Keyword Spotting. The paper about the dataset is here: https://arxiv.org/pdf/1804.03209.pdf <br/>  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8567855989753509
      ],
      "excerpt": "The ResNet-18 architecture is the residual network architecture with 18 layers. More information on Residual Networks can be found in the link to the paper:  ('Deep Residual Learning for Image Recognition': https://arxiv.org/abs/1512.03385). <br /> Residual Networks were initially used for Image Object Detection and Image Classification.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9869362287945266
      ],
      "excerpt": "Inspired by work from Google Research for Audio Classification ('CNN Architectures for Large Scale Audio Classification': https://ai.google/research/pubs/pub45611), this github project was born with the idea to use Residual Networks for Audio Classification of Environmental Sound data such as the UrbanSound8K. The ResNet-18 layer was selected, with the aim to create a smaller model that could be optimized and deployed for smaller devices such as Mobile Phone and Raspberry Pi.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8279950376499531
      ],
      "excerpt": "1. All .wav files were downsampled to 16KHz with single (Mono) channel \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.962062084766886
      ],
      "excerpt": "   The number of Mel Filterbanks applied is 128. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9524863191734106
      ],
      "excerpt": "5. Batch-size of 250 was selected, to give the inputs to the model as [250,75,128] ([batch_size, frame_length, number_mel_filterbanks_frequecies] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8793608057769868,
        0.931809440797091,
        0.9518756175879436,
        0.8543144148835046,
        0.8679600825758033
      ],
      "excerpt": "Model, Optimizer, and Loss details \n1. Resnet-18 Model is used with ResNet v1 block, with the final layer being a dense layer for 10 classes. \n2. Adam Optimizer is used with initial learning rate of 0.01. \n3. Categorical Cross-Entropy Loss is used with mean reduction. \n4. Full-batch-size is used for training and gradient descent, given the small dataset size.  \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nitinvwaran/UrbanSound8K-audio-classification-with-ResNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 15,
      "date": "Wed, 22 Dec 2021 03:10:42 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/nitinvwaran/UrbanSound8K-audio-classification-with-ResNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "nitinvwaran/UrbanSound8K-audio-classification-with-ResNet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8139894315667757
      ],
      "excerpt": "This is a standard train-dev-test split on all the 8732 datapoints from the dataset.  <br /> \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8296626440240239
      ],
      "excerpt": "The test, validation, and train accuracies from the approach are reported below. Data is split into train-dev-test split of roughly 60-20-20 <br/> <br /> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/nitinvwaran/UrbanSound8K-audio-classification-with-ResNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "UrbanSound8K Audio Classification and Speech Command Dataset Classification with ResNet-18",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "UrbanSound8K-audio-classification-with-ResNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "nitinvwaran",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nitinvwaran/UrbanSound8K-audio-classification-with-ResNet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 38,
      "date": "Wed, 22 Dec 2021 03:10:42 GMT"
    },
    "technique": "GitHub API"
  }
}
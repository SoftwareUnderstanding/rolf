{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1808.03715\n- Music Transformer AI Model: https://arxiv.org/abs/1809.04281\n- Relative self-attention: https://arxiv.org/abs/1803.02155\n- Original Transformer paper: https://arxiv.org/abs/1803.02155\n- Guide to the above, with code: https://nlp.seas.harvard.edu/2018/04/03/attention.html\n- Very readable introduction to attention/transformers: http://www.peterbloem.nl/blog/transformers\n\n",
      "https://arxiv.org/abs/1809.04281\n- Relative self-attention: https://arxiv.org/abs/1803.02155\n- Original Transformer paper: https://arxiv.org/abs/1803.02155\n- Guide to the above, with code: https://nlp.seas.harvard.edu/2018/04/03/attention.html\n- Very readable introduction to attention/transformers: http://www.peterbloem.nl/blog/transformers\n\n",
      "https://arxiv.org/abs/1803.02155\n- Original Transformer paper: https://arxiv.org/abs/1803.02155\n- Guide to the above, with code: https://nlp.seas.harvard.edu/2018/04/03/attention.html\n- Very readable introduction to attention/transformers: http://www.peterbloem.nl/blog/transformers\n\n",
      "https://arxiv.org/abs/1803.02155\n- Guide to the above, with code: https://nlp.seas.harvard.edu/2018/04/03/attention.html\n- Very readable introduction to attention/transformers: http://www.peterbloem.nl/blog/transformers\n\n"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8414367536088724,
        0.986419902726789,
        0.9912556242864674,
        0.994799811898885
      ],
      "excerpt": "Effective encoding of MIDI data: https://arxiv.org/abs/1808.03715 \nMusic Transformer AI Model: https://arxiv.org/abs/1809.04281 \nRelative self-attention: https://arxiv.org/abs/1803.02155 \nOriginal Transformer paper: https://arxiv.org/abs/1803.02155 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/chathasphere/pno-ai",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-08-13T21:53:48Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-24T06:29:37Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9856148182940511,
        0.9111358450889023,
        0.89930341582338
      ],
      "excerpt": "An implementation of Google Magenta's Music Transformer in Python/Pytorch. This library is designed to train a neural network on Piano MIDI data to generate musical samples. MIDIs are encoded into \"Event Sequences\", a dense array of musical instructions (note on, note off, dynamic change, time shift) encoded as numerical tokens. A custom transformer model learns to predict instructions on training sequences, and in generate.py a trained model can randomly sample from its learned distribution. (It is recommended to 'prime' the model's internal state with a MIDI input.) \nThe initial dataset comes from several years of recordings from the International Piano-e-Competition: over 1,000 performances played by professional pianists on a Yamaha Disklavier. Obtainable here. A sufficiently large dataset (order of 50 MB) of piano MIDIs should be sufficient to train a model. \nGoogle Colab is a good free option for experimentation. But for running a model for multiple hours, I would recommend using a Google Cloud compute instance with GPU driver(s). This tutorial from fast.ai shows you how to get up and running on a GPU instance. (I would recommend using a non-preemptible instance for sanity's sake.) Once you're ssh'ed in... \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Music Transformer Sequence Generation in Pytorch",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Chatha-Sphere/pno-ai/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 16,
      "date": "Wed, 29 Dec 2021 12:11:31 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/chathasphere/pno-ai/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "chathasphere/pno-ai",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9979731764490047,
        0.8454102943647224
      ],
      "excerpt": "- Run source activate and pip install pretty-midi --user to install the preprocessing dependency to your conda environment. \n- From a tmux screen, use python run.py and you're good to go! You can scp saved models back to your host machine. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8289669050403863
      ],
      "excerpt": "Pianistic Neuralnetworks Output Aleatoric Improvisations \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/chathasphere/pno-ai/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License\\n\\nCopyright (c) 2010-2019 Google, Inc. http://angularjs.org\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\nTHE SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "pno-ai",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pno-ai",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "chathasphere",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/chathasphere/pno-ai/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 64,
      "date": "Wed, 29 Dec 2021 12:11:31 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1908.08681v3\" alt=\"ArXiv\">\n        <img src=\"https://img.shields.io/badge/Paper-arXiv-blue.svg\" /></a>\n    <a href=\"https://scholar.googleusercontent.com/scholar.bib?q=info:j0C1gbodjP4J:scholar.google.com/&output=citation&scisdr=CgX0hbDMEOzUo74J6TM:AAGBfm0AAAAAX1QM8TNcu4tND6FEofKsXzM3cs1uCAAW&scisig=AAGBfm0AAAAAX1QM8Y5elaJ1IW-BKOuU1zFTYNp-QaNQ&scisf=4&ct=citation&cd=-1&hl=en\" alt=\"Cite\">\n          <img src=\"https://img.shields.io/badge/Cite-BibTex-blue.svg\" /></a>\n     <a href=\" \" alt=\"Citations\">\n          <img src=\"https://img.shields.io/badge/Google Scholar-428-lightgrey.svg\" /></a>\n    <a href=\"https://www.bmvc2020-conference.com/conference/papers/paper_0928.html\" alt=\"Publication\">\n          <img src=\"https://img.shields.io/badge/BMVC-2020-red.svg\" /></a>\n     <a href=\"https://twitter.com/DigantaMisra1\" alt=\"Twitter\">\n          <img src=\"https://img.shields.io/twitter/url/https/twitter.com/DigantaMisra1.svg?style=social&label=Follow%20%40DigantaMisra1\" /></a>\n     <a href=\"https://console.paperspace.com/github/digantamisra98/Mish/blob/master/Layers_Acc.ipynb\">\n          <img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"/>\n          </a>\n</p>\n\n\n<h1 align=\"center\">Mish: Self Regularized <br> Non-Monotonic Activation Function</h1>\n<p align=\"center\">BMVC 2020 <a href=\"https://www.bmvc2020-conference.com/assets/papers/0928.pdf\" target=\"_blank\">(Official Paper",
      "https://arxiv.org/abs/1908.08681v3",
      "https://arxiv.org/abs/1804.06882",
      "https://arxiv.org/abs/1804.06882",
      "https://arxiv.org/abs/1804.06882",
      "https://arxiv.org/abs/1710.09412",
      "https://arxiv.org/abs/1905.04899",
      "https://arxiv.org/abs/1905.04899",
      "https://arxiv.org/abs/1905.04899",
      "https://arxiv.org/abs/1912.05027",
      "https://arxiv.org/abs/1905.04899",
      "https://arxiv.org/abs/1905.04899",
      "https://arxiv.org/abs/1908.08681"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@article{misra2019mish,\n  title={Mish: A self regularized non-monotonic neural activation function},\n  author={Misra, Diganta},\n  journal={arXiv preprint arXiv:1908.08681},\n  year={2019}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{misra2019mish,\n  title={Mish: A self regularized non-monotonic neural activation function},\n  author={Misra, Diganta},\n  journal={arXiv preprint arXiv:1908.08681},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9482401847497453
      ],
      "excerpt": "  <a href=\"https://open.spotify.com/episode/4sT9sxjSbAKtvJ6hTFg9zc\" alt=\"Spotify\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944798088296921
      ],
      "excerpt": "(08/2020): Talk on Mish and Non-Linear Dynamics at Computer Vision Talks. Watch on: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8111036989382164,
        0.9105368110547479,
        0.86718837060696
      ],
      "excerpt": "  1. [Mish](https://github.com/digantamisra98/Mish/blob/master/README.md#mish) <br> \n     a. [Loss landscape](https://github.com/digantamisra98/Mish#loss-landscape)  \n  2. [ImageNet Scores](https://github.com/digantamisra98/Mish#imagenet-scores) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9105368110547479,
        0.9105368110547479
      ],
      "excerpt": "     a. [MNIST](https://github.com/digantamisra98/Mish#mnist)<br> \n     b. [CIFAR10](https://github.com/digantamisra98/Mish#cifar10)<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9783965953207839,
        0.9962872627708379,
        0.9495015411646179
      ],
      "excerpt": "  6. [Results](https://github.com/digantamisra98/Mish#results)<br> \n     a. [Summary of Results (Vision Tasks)](https://github.com/digantamisra98/Mish#summary-of-results-vision-tasks)<br> \n     b. [Summary of Results (Language Tasks)](https://github.com/digantamisra98/Mish#summary-of-results-language-tasks)<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9993824150199532
      ],
      "excerpt": "  10. [Cite this work](https://github.com/digantamisra98/Mish#cite-this-work) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.8356013927728488,
        0.8356013927728488
      ],
      "excerpt": "|Pelee Net|Leaky ReLU|70.7%|90%| \n|Pelee Net|Mish|71.4%|90.4%| \n|Pelee Net|Swish|71.5%|90.7%| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.8356013927728488
      ],
      "excerpt": "|CSPPelee Net|Leaky ReLU|70.9%|90.2%| \n|CSPPelee Net|Mish|71.2%|90.3%| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9105368110547479,
        0.9105368110547479,
        0.9105368110547479,
        0.9847115019064655,
        0.9626356225854676,
        0.9105368110547479,
        0.9105368110547479,
        0.9105368110547479,
        0.9105368110547479,
        0.9860820212794102,
        0.9626356225854676,
        0.9747762585923935,
        0.807194058632709
      ],
      "excerpt": "  1. [Sparsha Mishra](https://github.com/SparshaMishra) \n  2. [Alexandra Deis](https://github.com/Lexie88rus) \n  3. [Alexey Bochkovskiy](https://github.com/AlexeyAB) \n  4. [Chien-Yao Wang](https://github.com/WongKinYiu/CrossStagePartialNetworks) \n  5. [Thomas Brandon](https://github.com/thomasbrandon) \n  6. [Less Wright](https://github.com/lessw2020) \n  7. [Manjunath Bhat](https://github.com/thebhatman) \n  8. [Ajay Uppili Arasanipalai](https://github.com/iyaja) \n  9. [Federico Lois](https://github.com/redknightlois) \n  10. [Javier Ideami](https://github.com/javismiles) \n  11. [Ioannis Anifantakis](https://github.com/ioannisa) \n  12. [George Christopoulos](https://github.com/geochri) \n  13. [Miklos Toth](https://hu.linkedin.com/in/miklostoth) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/digantamisra98/Mish",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-10T14:05:18Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-28T04:22:48Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "*Comparison is done based on the best metric score (Test accuracy) across 3 runs.*\n\n|Activation Function| Mish > Baseline Model | Mish < Baseline Model |\n|---|---|---|\n|Penalized TanH|5|0|\n|ELU|5|0|\n|Sigmoid|5|0|\n|SReLU|4|0|\n|TanH|4|1|\n|Swish|3|2|\n|ReLU|2|3|\n|Leaky ReLU|2|3|\n|GELU|1|2|\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "*Comparison is done based on the high priority metric, for image classification the Top-1 Accuracy while for Generative Networks and Image Segmentation the Loss Metric. Therefore, for the latter, Mish > Baseline is indicative of better loss and vice versa. For Embeddings, the AUC metric is considered.*\n\n|Activation Function| Mish > Baseline Model | Mish < Baseline Model |\n|---|---|---|\n|ReLU|55|20|\n|Swish-1|53|22|\n|SELU|26|1|\n|Sigmoid|24|0|\n|TanH|24|0|\n|HardShrink(\u03bb = 0.5)|23|0|\n|Tanhshrink|23|0|\n|PReLU(Default Parameters)\t|23|2|\n|Softsign|22|1|\n|Softshrink (\u03bb = 0.5)|22|1|\n|Hardtanh|21|2|\n|ELU(\u03b1=1.0)|21|7|\n|LogSigmoid|20|4|\n|GELU|19|3|\n|E-Swish (\u03b2=1.75)|19|7|\n|CELU(\u03b1=1.0)|18|5|\n|SoftPlus(\u03b2 = 1)|17|7|\n|Leaky ReLU(\u03b1=0.3)|17|8|\n|Aria-2(\u03b2 = 1, \u03b1=1.5)|16|2|\n|ReLU6|16|8|\n|SQNL|13|1|\n|Weighted TanH (Weight = 1.7145)|12|1|\n|RReLU|12|11|\n|ISRU (\u03b1=1.0)|11|1|\n|Le Cun's TanH|10|2|\n|Bent's Identity|10|5|\n|Hard ELisH|9|1|\n|Flatten T-Swish|9|3|\n|Soft Clipping (\u03b1=0.5)|9|3|\n|SineReLU (\u03b5 = 0.001)|9|4|\n|ISRLU (\u03b1=1.0)|9|4|\n|ELisH|7|3|\n|SReLU|7|6|\n|Hard Sigmoid|1|0|\n|Thresholded ReLU(\u03b8=1.0)|1|0|\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9010591491522891
      ],
      "excerpt": "(02/2020): Podcast episode on Mish at Machine Learning Caf\u00e9 is out now. Listen on:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.902133520866793
      ],
      "excerpt": "(02/2020): Talk on Mish and Non-Linear Dynamics at Sicara is out now. Watch on: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9994185779859776
      ],
      "excerpt": "(07/2020): CROWN: A comparison of morphology for Mish, Swish and ReLU produced in collaboration with Javier Ideami. Watch on: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9066195480130569
      ],
      "excerpt": "(12/2020): Talk on From Smooth Activations to Robustness to Catastrophic Forgetting at Weights & Biases Salon is out now. Watch on: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "  <summary><b>Contents</b>: (Click to expand)</summary> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856656944165435
      ],
      "excerpt": "  4. [Variation of Parameter Comparison](https://github.com/digantamisra98/Mish#variation-of-parameter-comparison)<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8792876446506973
      ],
      "excerpt": "     b. [Summary of Results (Language Tasks)](https://github.com/digantamisra98/Mish#summary-of-results-language-tasks)<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9704973356549657,
        0.9164450933483127,
        0.9966498576528875
      ],
      "excerpt": "Minimum of f(x) is observed to be \u2248-0.30884 at x\u2248-1.1924<br> \nMish has a parametric order of continuity of: C<sup>\u221e</sup> \nDerivative of Mish with respect to Swish and \u0394(x) preconditioning: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9669728734525261
      ],
      "excerpt": "We hypothesize the \u0394(x) to be exhibiting the properties of a pre-conditioner making the gradient more smoother. Further details are provided in the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8105448964970018
      ],
      "excerpt": "To visit the interactive Loss Landscape visualizer, click here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9266672291604374,
        0.8823984879170762
      ],
      "excerpt": "Mish provides much better accuracy, overall lower loss, smoother and well conditioned easy-to-optimize loss landscape as compared to both Swish and ReLU. For all loss landscape visualizations please visit this readme.  \nWe also investigate the output landscape of randomly initialized neural networks as shown below. Mish has a much smoother profile than ReLU. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8949604588104644
      ],
      "excerpt": "For PyTorch based ImageNet scores, please refer to this readme \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8560643840629637
      ],
      "excerpt": "Results on CSPResNext-50: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8560643840629637
      ],
      "excerpt": "Results on CSPResNet-50: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8105755666870592
      ],
      "excerpt": "Results on CSPDarkNet-53: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8455892482224618
      ],
      "excerpt": "For PyTorch based MS-COCO scores, please refer to this readme \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.973266224098203,
        0.9806394084844002,
        0.9840572231132433
      ],
      "excerpt": "Credits to AlexeyAB, Wong Kin-Yiu and Glenn Jocher for all the help with benchmarking MS-COCO and ImageNet. \nTo observe how increasing the number of layers in a network while maintaining other parameters constant affect the test accuracy, fully connected networks of varying depths on MNIST, with each layer having 500 neurons were trained. Residual Connections were not used because they enable the training of arbitrarily deep networks. BatchNorm was used to lessen the dependence on initialization along with a dropout of 25%. The network is optimized using SGD on a batch size of 128, and for fair comparison, the same learning rates for each activation function was maintained. In the experiments, all 3 activations maintained nearly the same test accuracy for 15 layered Network. Increasing number of layers from 15 gradually resulted in a sharp decrease in test accuracy for Swish and ReLU, however, Mish outperformed them both in large networks where optimization becomes difficult. \nThe consistency of Mish providing better test top-1 accuracy as compared to Swish and ReLU was also observed by increasing Batch Size for a ResNet v2-20 on CIFAR-10 for 50 epochs while keeping all other network parameters to be constant for fair comparison. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9873971331592655
      ],
      "excerpt": "Gaussian Noise with varying standard deviation was added to the input in case of MNIST classification using a simple conv net to observe the trend in decreasing test top-1 accuracy for Mish and compare it to that of ReLU and Swish. Mish mostly maintained a consistent lead over that of Swish and ReLU (Less than ReLU in just 1 instance and less than Swish in 3 instance) as shown below. The trend for test loss was also observed following the same procedure. (Mish has better loss than both Swish and ReLU except in 1 instance) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9975401035011343
      ],
      "excerpt": "The P-values were computed for different activation functions in comparison to that of Mish on terms of Top-1 Testing Accuracy of a Squeeze Net Model on CIFAR-10 for 50 epochs for 23 runs using Adam Optimizer at a Learning Rate of 0.001 and Batch Size of 128. It was observed that Mish beats most of the activation functions at a high significance level in the 23 runs, specifically it beats ReLU at a high significance of P < 0.0001. Mish also had a comparatively lower standard deviation across 23 runs which proves the consistency of performance for Mish. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "|Swish-1|87.32%|4.22%|0.414|P = 0.1973|0.386|-0.3975 to 0.0844| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762,
        0.9693233393948762,
        0.9693233393948762,
        0.9693233393948762,
        0.9693233393948762,
        0.9693233393948762
      ],
      "excerpt": "|ReLU|86.66%|4.398%|0.584|P < 0.0001|1.645536|-1.1179 to -0.5247| \n|ELU(\u03b1=1.0)|86.41%|4.211%|0.3371|P < 0.0001|2.918232|-1.2931 to -0.8556| \n|Leaky ReLU(\u03b1=0.3)|86.85%|4.112%|0.4569|P < 0.0001|1.47632|-0.8860 to -0.3774| \n|RReLU|86.87%|4.138%|0.4478|P < 0.0001|1.444091|-0.8623 to -0.3595| \n|SELU|83.91%|4.831%|0.5995|P < 0.0001|7.020812|-3.8713 to -3.2670| \n|SoftPlus(\u03b2 = 1)|83.004%|5.546%|1.4015|P < 0.0001|4.345453|-4.7778 to -4.1735| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762,
        0.9693233393948762,
        0.8863390458906978
      ],
      "excerpt": "|Hardtanh|82.78%|5.209%|0.4491|P < 0.0001|11.093842|-4.9522 to -4.4486| \n|LogSigmoid|81.98%|5.705%|1.6751|P < 0.0001|4.517156|-6.2221 to -4.7753| \n|PReLU|85.66%|5.101%|2.2406|P = 0.0004|1.128135|-2.7715 to -0.8590| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "|CELU(\u03b1=1.0)|86.23%|4.243%|0.50941|P < 0.0001| 2.741669|-1.5231 to -0.9804| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762,
        0.9693233393948762,
        0.9693233393948762,
        0.9693233393948762,
        0.9693233393948762,
        0.9693233393948762,
        0.9693233393948762,
        0.9693233393948762,
        0.8043934539767648,
        0.9693233393948762,
        0.9693233393948762,
        0.9693233393948762,
        0.9693233393948762,
        0.9693233393948762,
        0.9693233393948762
      ],
      "excerpt": "|Softshrink(\u03bb = 0.5)|82.35%|5.4915%|0.71959|P < 0.0001|8.830541|-5.4762 to -4.7856| \n|Tanhshrink|82.35%|5.446%|0.94508|P < 0.0001|7.083564|-5.5646 to -4.7032| \n|Tanh|83.15%|5.161%|0.6887| P < 0.0001|7.700198|-4.6618 to -3.9938| \n|Softsign|82.66%|5.258%|0.6697|P < 0.0001|8.761157|-5.1493 to -4.4951| \n|Aria-2(\u03b2 = 1, \u03b1=1.5)|81.31%|6.0021%|2.35475|P < 0.0001|3.655362|-7.1757 to -5.1687| \n|Bent's Identity|85.03%|4.531%|0.60404|P < 0.0001|4.80211|-2.7576 to -2.1502| \n|SQNL|83.44%|5.015%|0.46819|P < 0.0001|9.317237|-4.3009 to -3.7852| \n|ELisH|87.38%|4.288%|0.47731|P = 0.4283|0.235784|-0.3643 to 0.1573| \n|Hard ELisH|85.89%|4.431%|0.62245|P < 0.0001|3.048849|-1.9015 to -1.2811| \n|SReLU|85.05%|4.541%|0.5826|P < 0.0001|4.883831|-2.7306 to -2.1381| \n|ISRU (\u03b1=1.0)|86.85%|4.669%|0.1106|P < 0.0001|5.302987|-4.4855 to -3.5815| \n|Flatten T-Swish|86.93%|4.459%|0.40047|P < 0.0001|1.378742|-0.7865 to -0.3127| \n|SineReLU (\u03b5 = 0.001)|86.48%|4.396%|0.88062|P < 0.0001|1.461675|-1.4041 to -0.5924| \n|Weighted Tanh (Weight = 1.7145)|80.66%|5.985%|1.19868|P < 0.0001|7.638298|-7.3502 to -6.2890| \n|LeCun's Tanh|82.72%|5.322%|0.58256|P < 0.0001|9.551812|-5.0566 to -4.4642| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "|ISRLU (\u03b1=1.0)|86.69%|4.231%|0.5788|P < 0.0001|1.572874|-1.0753 to -0.4856| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.854949822218576
      ],
      "excerpt": "News: Ajay Arasanipalai recently submitted benchmark for CIFAR-10 training for the Stanford DAWN Benchmark using a Custom ResNet-9 + Mish which achieved 94.05% accuracy in just 10.7 seconds in 14 epochs on the HAL Computing Cluster. This is the current fastest training of CIFAR-10 in 4 GPUs and 2nd fastest training of CIFAR-10 overall in the world. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9968029537584643,
        0.9582279996633336,
        0.9634355821700253
      ],
      "excerpt": "  * Comparison of Convergence Rates. \n  * Normalizing constant for Mish to eliminate the use of Batch Norm. \n  * Regularizing effect of the first derivative of Mish with repect to Swish.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762,
        0.9354991362906252
      ],
      "excerpt": "  <summary><b>Acknowledgments:</b> (Click to expand)</summary> \n  Thanks to all the people who have helped and supported me massively through this project who include: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Official Repsoitory for \"Mish: A Self Regularized Non-Monotonic Neural Activation Function\" [BMVC 2020]",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/digantamisra98/Mish/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 123,
      "date": "Tue, 28 Dec 2021 09:16:15 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/digantamisra98/Mish/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "digantamisra98/Mish",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/digantamisra98/Mish/master/Layers_Acc.ipynb",
      "https://raw.githubusercontent.com/digantamisra98/Mish/master/exps/Mish_test.ipynb",
      "https://raw.githubusercontent.com/digantamisra98/Mish/master/exps/Mish_CIFAR.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.874229535627311
      ],
      "excerpt": "  1. [Mish](https://github.com/digantamisra98/Mish/blob/master/README.md#mish) <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8292558621065437
      ],
      "excerpt": "  3. [MS-COCO](https://github.com/digantamisra98/Mish#ms-coco) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8918974083095406
      ],
      "excerpt": "     a. [MNIST](https://github.com/digantamisra98/Mish#mnist)<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.944225729912855
      ],
      "excerpt": "|Model|Mish|AP50...95|mAP50|CPU - 90 Watt - FP32 (Intel Core i7-6700K, 4GHz, 8 logical cores) OpenCV-DLIE, FPS|VPU-2 Watt- FP16 (Intel MyriadX) OpenCV-DLIE, FPS|GPU-175 Watt- FP32/16 (Nvidia GeForce RTX 2070) DarkNet-cuDNN, FPS| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8918974083095406,
        0.8918974083095406,
        0.8918974083095406
      ],
      "excerpt": "  1. [Sparsha Mishra](https://github.com/SparshaMishra) \n  2. [Alexandra Deis](https://github.com/Lexie88rus) \n  3. [Alexey Bochkovskiy](https://github.com/AlexeyAB) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8918974083095406,
        0.8918974083095406,
        0.8918974083095406,
        0.8918974083095406
      ],
      "excerpt": "  6. [Less Wright](https://github.com/lessw2020) \n  7. [Manjunath Bhat](https://github.com/thebhatman) \n  8. [Ajay Uppili Arasanipalai](https://github.com/iyaja) \n  9. [Federico Lois](https://github.com/redknightlois) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9201182849250232,
        0.8509709097180108
      ],
      "excerpt": "  11. [Ioannis Anifantakis](https://github.com/ioannisa) \n  12. [George Christopoulos](https://github.com/geochri) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8681312211973341
      ],
      "excerpt": "        <img src=\"podcast_logo/applepodcasts.png\" width=\"150\"/></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.909130101466226
      ],
      "excerpt": "        <img src=\"podcast_logo/yt1.png\" width=\"100\"/></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.909130101466226
      ],
      "excerpt": "        <img src=\"podcast_logo/yt1.png\" width=\"100\"/></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.909130101466226
      ],
      "excerpt": "        <img src=\"podcast_logo/yt1.png\" width=\"100\"/></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.909130101466226
      ],
      "excerpt": "        <img src=\"podcast_logo/yt1.png\" width=\"100\"/></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8681191465534992
      ],
      "excerpt": "  <div style=\"text-align:center\"><img src =\"poster_landscape-1.png\"  width=\"1000\"/></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.848243279937108
      ],
      "excerpt": "  <img width=\"500\" src=\"Observations/Mish3.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.848243279937108
      ],
      "excerpt": "  <img width=\"1000\" src=\"Observations/Derivatives.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8691961266413946
      ],
      "excerpt": "<div style=\"text-align:center\"><img src =\"llmish.gif\"  width=\"500\" height=\"300\"/></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8681191465534992
      ],
      "excerpt": "<div style=\"text-align:center\"><img src =\"landscapes/d8v1.png\"  width=\"1000\"/></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8681191465534992
      ],
      "excerpt": "<div style=\"text-align:center\"><img src =\"landscapes/landscape-1.png\"  width=\"1000\"/></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8457312089802624,
        0.8457312089802624,
        0.8457312089802624
      ],
      "excerpt": "|CSPResNext50-PANet-SPP|||||512 x 512|42.4%|64.4%|45.9%| \n|CSPResNext50-PANet-SPP||:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|512 x 512|42.3%|64.3%|45.7%| \n|CSPResNext50-PANet-SPP|:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|512 x 512|42.3%|64.2%|45.8%| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.867047507742109,
        0.867047507742109
      ],
      "excerpt": "  <img src=\"Observations/layersacc.png\"  width=\"400\"/> \n  <img src=\"Observations/batchacc.png\"  width=\"400\"/>  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8400772374710221,
        0.867047507742109
      ],
      "excerpt": "  <img src=\"Observations/noise.png\"  width=\"400\"/> \n  <img src=\"Observations/noise1.png\"  width=\"400\"/>  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.867047507742109,
        0.867047507742109
      ],
      "excerpt": "  <img src=\"Observations/initc10.png\"  width=\"400\"/> \n  <img src=\"Observations/densec10.png\"  width=\"400\"/> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/digantamisra98/Mish/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Diganta Misra\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "L41)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Mish",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "digantamisra98",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/digantamisra98/Mish/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1178,
      "date": "Tue, 28 Dec 2021 09:16:15 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "activation-functions",
      "mathematics",
      "neural-networks",
      "computer-vision",
      "bmvc",
      "bmvc20",
      "object-detection",
      "image-classification"
    ],
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1909.04063",
      "https://arxiv.org/abs/1909.04063",
      "https://arxiv.org/abs/1704.01665",
      "https://arxiv.org/abs/1704.01212",
      "https://arxiv.org/abs/1909.04063"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this work or the associated paper useful, it can be cited as below.\n\n    @article{barrett2019exploratory,\n      title={Exploratory Combinatorial Optimization with Reinforcement Learning},\n      author={Barrett, Thomas D and Clements, William R and Foerster, Jakob N and Lvovsky, AI},\n      journal={arXiv preprint arXiv:1909.04063},\n      year={2019}\n    }\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{barrett2019exploratory,\n  title={Exploratory Combinatorial Optimization with Reinforcement Learning},\n  author={Barrett, Thomas D and Clements, William R and Foerster, Jakob N and Lvovsky, AI},\n  journal={arXiv preprint arXiv:1909.04063},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Described above. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ilBarbara/BioRL",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-02-23T05:43:43Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-04T13:17:54Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9886323100636684,
        0.8984442527779954
      ],
      "excerpt": "Implementation of ECO-DQN as reported in \"Exploratory Combinatorial Optimization with Reinforcement Learning\". \nWe train agents on two different types of graph called Erdos-Renyi (ER) and Barabasi-Albert (BA).  For each graph type we train the agents on 20, 40, 60, 100, 200 and 500 vertex graphs. Note the code typically refers to a vertex as a spin. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401285779395833
      ],
      "excerpt": "- The network parameters at various points over training and of the fully trained agent. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8229660285845495,
        0.8643683711310106,
        0.8925730686632174
      ],
      "excerpt": "- The averaged results, summarized in a pandas dataframe and saved to results_xxx.pkl. \n- The raw results on each graph, summarized in a pandas dataframe and saved to results_xxx_raw.pkl. \n- The full history of every test episode, saved to results_xxx_histories.pkl. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.895648827994902
      ],
      "excerpt": "A script to test pre-trained agents on different graph sets is provided in experiments/pre_trained_agent/test_eco.py. Simply edit the network_save_loc and graph_save_loc parameters to point at the desired agent and test_graphs.  Moreover, the pretrained agents as produced for the paper can be found in experiments/pre_trained_agent/networks/eco/. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9784272293026564,
        0.9835057322186627
      ],
      "excerpt": "Please note this is our implementation of S2V-DQN, however the original repository is provided by Hanjun Dai here. \nContains the graph instances used in the paper.  This is split into three catagories: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9069315205949333,
        0.9285195711283185,
        0.9889717604396373,
        0.8856294260604268
      ],
      "excerpt": "- testing: Sets of 50 graphs for each graph type and size.  These are the graphs against which the agents are tested during training. \n- validation:  Sets of 100 graphs for each graph type and size.  These are the graphs on which the performances of trained agents are tested. \nWithin each of these sub-folders, the opts/ folder contains the \"optimum\" solutions/values (best known for the benchmarking graphs, and the best found by any of our optimization methods as described in the supplemental material of the paper for testing and validation graphs). \nThe graph sets themselves are .pkl files that un-pickle to be list graphs.  Ultimately, the code wants these as a list of numpy arrays, however the load_graph_set(...) function in experiments/utils.py will also convert lists of either networkx graphs or scipy sparse matrices into the correct form (these are more memory efficient ways of storing large graphs).  If you wish to point the code at custom sets of graphs, they should match one of these formats and be appropriately stored in a .pkl file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8842518452627519
      ],
      "excerpt": "Contains source code for ECO-DQN.  This consists of three directories which, at a very high level are: \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ilBarbara/BioRL/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 22 Dec 2021 11:15:48 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ilBarbara/BioRL/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ilBarbara/BioRL",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8612171552660846
      ],
      "excerpt": "The creates a directory ER_20spin/eco/network to store following. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.822587296544623
      ],
      "excerpt": "- The test scores over training, as a .pkl file and plotted. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ilBarbara/BioRL/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Macaulay2",
      "Python",
      "C",
      "JavaScript",
      "Fortran",
      "HTML",
      "CSS"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Thomas D Barrett\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "eco-dqn",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "BioRL",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ilBarbara",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ilBarbara/BioRL/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Beyond standard packages found in most Python distributions (e.g. numpy, matplotlib etc), this project requires:\n\n- pytorch\n- networkx\n- numba\n- pandas\n\nAlternatively, the included [``environment.yml``](environment.yml) file will produce a working environment called ``spin-solver``.\n\n    >>> git clone --recursive https://github.com/tomdbar/eco-dqn\n    >>> cd eco-dqn\n    >>> conda env create -f environment.yml (<-- optional)\n    >>> source active spin-solver (<-- optional)\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "*Scripts to reproduce the agents trained in the paper can be found in the [``experiments``](experiments) folder.  It is straightforward to modify these to use different training/testing data or parameters.*\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Wed, 22 Dec 2021 11:15:48 GMT"
    },
    "technique": "GitHub API"
  }
}
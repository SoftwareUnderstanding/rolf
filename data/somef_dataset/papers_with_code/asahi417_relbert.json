{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2110.15705",
      "https://arxiv.org/abs/2005.14165",
      "https://arxiv.org/abs/1810.08854",
      "https://arxiv.org/abs/2005.14165",
      "https://arxiv.org/abs/2005.14165",
      "https://arxiv.org/abs/2110.15705"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use any of these resources, please cite the following [paper](https://arxiv.org/abs/2110.15705):\n```\n@inproceedings{ushio-etal-2021-distilling-relation-embeddings,\n    title = \"{D}istilling {R}elation {E}mbeddings from {P}re-trained {L}anguage {M}odels\",\n    author = \"Ushio, Asahi  and\n      Schockaert, Steven  and\n      Camacho-Collados, Jose\",\n    booktitle = \"EMNLP 2021\",\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{ushio-etal-2021-distilling-relation-embeddings,\n    title = \"{D}istilling {R}elation {E}mbeddings from {P}re-trained {L}anguage {M}odels\",\n    author = \"Ushio, Asahi  and\n      Schockaert, Steven  and\n      Camacho-Collados, Jose\",\n    booktitle = \"EMNLP 2021\",\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/asahi417/relbert",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-25T00:45:27Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-18T09:23:45Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9838406475466364
      ],
      "excerpt": "We release the package relbert that includes the official implementation of \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9939131301433162,
        0.8794625054686446
      ],
      "excerpt": "RelBERT is a state-of-the-art lexical relation embedding model (i.e. model representing any word pair such as \"Paris-France\" as a fixed-length vector) based on large-scale pretrained masked language models. RelBERT also establishes a very strong baseline to solve analogies in a zero-shot transfer fashion and even outperform strong few-shot models such as GPT-3 and Analogical Proportion (AP). \n|                    |   SAT (full) |   SAT |   U2 |   U4 |   Google |   BATS | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9965190090731619,
        0.8646771193690029,
        0.9806496476129262,
        0.9697820112833615,
        0.846442575397572,
        0.826642847819184
      ],
      "excerpt": "We also report the performance of RelBERT universal relation embeddings on lexical relation classification datasets, which reinforces the capability of RelBERT to model relations.  \nAll datasets are public and available in the following links: analogy questions, lexical relation classification. \nPlease have a look our paper to know more about RelBERT and AnalogyTool or AP paper for more information about the datasets. \nIn this repository, we release a python package relbert to work around with RelBERT and its checkpoints via huggingface modelhub and gensim. \nIn brief, what you can do with the relbert is summarized as below: \n- Get a high quality embedding vector given a pair of word \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.977770664607198
      ],
      "excerpt": "- Reproduce the results of our EMNLP 2021 paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8460005547622456,
        0.9520604032832616,
        0.9806333376430711,
        0.9235889493624326,
        0.9235889493624326,
        0.8869606773260599
      ],
      "excerpt": "model = RelBERT('asahi417/relbert-roberta-large') \nAs the model checkpoint, we release following three models on the huggingface modelhub. \n- asahi417/relbert-roberta-large: RelBERT based on RoBERTa large with custom prompt (recommended as this is the best model in our experiments). \n- asahi417/relbert-roberta-large-autoprompt: RelBERT based on RoBERTa large with AutoPrompt. \n- asahi417/relbert-roberta-large-ptuning: RelBERT based on RoBERTa large with P-tuning. \nThen you give a word pair to the model to get the embedding. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "v_tokyo_japan = model.get_embedding(['Tokyo', 'Japan']) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9146435983239791
      ],
      "excerpt": "the same relation with the ['Tokyo', 'Japan'] is ['Paris', 'France']. Would the RelBERT embedding be possible to retain it with simple cosine similarity? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9412846551965917,
        0.9673895520179856,
        0.9850001991814654,
        0.9824729358164725,
        0.9671562298638912
      ],
      "excerpt": "Bravo! The distance between['Tokyo', 'Japan']and['Paris', 'France']` is the closest among the candidates. \nIn fact, this pipeline is how we evaluate the RelBERT on the analogy question. \nTo get the similar word pairs in terms of the RelBERT embedding, we convert the RelBERT embedding to a gensim model file with a fixed vocabulary. \nSpecifically, we take the vocabulary of the RELATIVE embedding that is released as a part of \nAnalogy Tool, and generate the embedding for all the word pairs with RelBERT (asahi417/relbert-roberta-large). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9340039308265301
      ],
      "excerpt": "To reproduce the experimental result of our EMNLP 2021 paper, you have to clone the repository. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "The official implementation of \"Distilling Relation Embeddings from Pre-trained Language Models, EMNLP 2021 main conference\", a high-quality relation embedding based on language models.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/asahi417/relbert/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Tue, 28 Dec 2021 00:38:46 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/asahi417/relbert/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "asahi417/relbert",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/asahi417/relbert/master/examples/experiments/main/evaluate.sh",
      "https://raw.githubusercontent.com/asahi417/relbert/master/examples/experiments/main/train.sh",
      "https://raw.githubusercontent.com/asahi417/relbert/master/examples/experiments/main/prompt.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8971116438642808
      ],
      "excerpt": "(check the camera-ready version here). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8436235832174899
      ],
      "excerpt": "The RelBERT embedding gensim file can be found here. For example, you can get the nearest neighbours as below. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9879863063452118,
        0.9906248903846466,
        0.999746712887969
      ],
      "excerpt": "git clone https://github.com/asahi417/relbert \ncd relbert \npip install . \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8667899240556969
      ],
      "excerpt": "sh ./examples/experiments/main/train.sh \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from relbert import RelBERT \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from relbert import cosine_similarity \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8900486270063179,
        0.817266128260708
      ],
      "excerpt": "from gensim.models import KeyedVectors \nmodel = KeyedVectors.load_word2vec_format('gensim_model.bin', binary=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8114714240201648
      ],
      "excerpt": "Then, you can train RelBERT model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8718029328008009
      ],
      "excerpt": "sh ./examples/experiments/main/train.sh \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/asahi417/relbert/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "RelBERT",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "relbert",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "asahi417",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/asahi417/relbert/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "asahi417",
        "body": "",
        "dateCreated": "2021-09-10T10:07:44Z",
        "datePublished": "2021-09-10T10:08:11Z",
        "html_url": "https://github.com/asahi417/relbert/releases/tag/v0.0.2",
        "name": "Beta",
        "tag_name": "v0.0.2",
        "tarball_url": "https://api.github.com/repos/asahi417/relbert/tarball/v0.0.2",
        "url": "https://api.github.com/repos/asahi417/relbert/releases/49337428",
        "zipball_url": "https://api.github.com/repos/asahi417/relbert/zipball/v0.0.2"
      },
      {
        "authorType": "User",
        "author_name": "asahi417",
        "body": "",
        "dateCreated": "2021-09-06T21:12:37Z",
        "datePublished": "2021-09-06T21:13:20Z",
        "html_url": "https://github.com/asahi417/relbert/releases/tag/v0.0.1",
        "name": "alpha",
        "tag_name": "v0.0.1",
        "tarball_url": "https://api.github.com/repos/asahi417/relbert/tarball/v0.0.1",
        "url": "https://api.github.com/repos/asahi417/relbert/releases/49092396",
        "zipball_url": "https://api.github.com/repos/asahi417/relbert/zipball/v0.0.1"
      },
      {
        "authorType": "User",
        "author_name": "asahi417",
        "body": "init",
        "dateCreated": "2021-07-25T09:01:45Z",
        "datePublished": "2021-09-05T21:40:24Z",
        "html_url": "https://github.com/asahi417/relbert/releases/tag/v0.0.0",
        "name": "init",
        "tag_name": "v0.0.0",
        "tarball_url": "https://api.github.com/repos/asahi417/relbert/tarball/v0.0.0",
        "url": "https://api.github.com/repos/asahi417/relbert/releases/49039133",
        "zipball_url": "https://api.github.com/repos/asahi417/relbert/zipball/v0.0.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 14,
      "date": "Tue, 28 Dec 2021 00:38:46 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "nlp",
      "bert",
      "relation-extraction"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```shell\npip install relbert\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
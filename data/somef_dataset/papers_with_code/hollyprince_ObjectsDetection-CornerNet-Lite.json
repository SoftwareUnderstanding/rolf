{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1904.08900",
      "https://arxiv.org/abs/1904.08900* \n\n## Getting Started\n### Software Requirement\n- Python 3.7\n- PyTorch 1.0.0\n- CUDA 10\n- GCC 4.9.2 or above\n\n### Installing Dependencies\nPlease first install [Anaconda](https://anaconda.org) and create an Anaconda environment using the provided package list `conda_packagelist.txt`.\n```\nconda create --name CornerNet_Lite --file conda_packagelist.txt --channel pytorch\n```\n\nAfter you create the environment, please activate it.\n```\nsource activate CornerNet_Lite\n```\n\n### Compiling Corner Pooling Layers\nCompile the C++ implementation of the corner pooling layers. (GCC4.9.2 or above is required.)\n```\ncd <CornerNet-Lite dir>/core/models/py_utils/_cpools/\npython setup.py install --user\n```\n\n### Compiling NMS\nCompile the NMS code which are originally from [Faster R-CNN](https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/nms/cpu_nms.pyx) and [Soft-NMS](https://github.com/bharatsingh430/soft-nms/blob/master/lib/nms/cpu_nms.pyx).\n```\ncd <CornerNet-Lite dir>/core/external\nmake\n```\n\n### Downloading Models\nIn this repo, we provide models for the following detectors:\n- [CornerNet-Saccade](https://drive.google.com/file/d/1MQDyPRI0HgDHxHToudHqQ-2m8TVBciaa/view?usp=sharing)\n- [CornerNet-Squeeze](https://drive.google.com/file/d/1qM8BBYCLUBcZx_UmLT0qMXNTh-Yshp4X/view?usp=sharing)\n- [CornerNet](https://drive.google.com/file/d/1e8At_iZWyXQgLlMwHkB83kN-AN85Uff1/view?usp=sharing)\n\nPut the CornerNet-Saccade model under `<CornerNet-Lite dir>/cache/nnet/CornerNet_Saccade/`, CornerNet-Squeeze model under `<CornerNet-Lite dir>/cache/nnet/CornerNet_Squeeze/` and CornerNet model under `<CornerNet-Lite dir>/cache/nnet/CornerNet/`. (\\* Note we use underscore instead of dash in both the directory names for CornerNet-Saccade and CornerNet-Squeeze.)\n\nNote: The CornerNet model is the same as the one in the original [CornerNet repo](https://github.com/princeton-vl/CornerNet). We just ported it to this new repo.\n\n### Running the Demo Script\nAfter downloading the models, you should be able to use the detectors on your own images. We provide a demo script `demo.py` to test if the repo is installed correctly.\n```\npython demo.py\n```\nThis script applies CornerNet-Saccade to `demo.jpg` and writes the results to `demo_out.jpg`.\n\nIn the demo script, the default detector is CornerNet-Saccade. You can modify the demo script to test different detectors. For example, if you want to test CornerNet-Squeeze:\n```python\n#!/usr/bin/env python\n\nimport cv2\nfrom core.detectors import CornerNet_Squeeze\nfrom core.vis_utils import draw_bboxes\n\ndetector = CornerNet_Squeeze()\nimage    = cv2.imread(\"demo.jpg\")\n\nbboxes = detector(image)\nimage  = draw_bboxes(image, bboxes)\ncv2.imwrite(\"demo_out.jpg\", image)\n```\n\n### Using CornerNet-Lite in Your Project\nIt is also easy to use CornerNet-Lite in your project. You will need to change the directory name from `CornerNet-Lite` to `CornerNet_Lite`. Otherwise, you won't be able to import CornerNet-Lite.\n```\nYour project\n\u2502   README.md\n\u2502   ...\n\u2502   foo.py\n\u2502\n\u2514\u2500\u2500\u2500CornerNet_Lite\n\u2502\n\u2514\u2500\u2500\u2500directory1\n\u2502   \n\u2514\u2500\u2500\u2500...\n```\n\nIn `foo.py`, you can easily import CornerNet-Saccade by adding:\n```python\nfrom CornerNet_Lite import CornerNet_Saccade\n\ndef foo():\n    cornernet = CornerNet_Saccade()\n    # CornerNet_Saccade is ready to use\n\n    image  = cv2.imread('/path/to/your/image')\n    bboxes = cornernet(image)\n```\n\nIf you want to train or evaluate the detectors on COCO, please move on to the following steps.\n\n## Training and Evaluation\n\n### Installing MS COCO APIs\n```\nmkdir -p <CornerNet-Lite dir>/data\ncd <CornerNet-Lite dir>/data\ngit clone git@github.com:cocodataset/cocoapi.git coco\ncd <CornerNet-Lite dir>/data/coco/PythonAPI\nmake install\n```\n\n### Downloading MS COCO Data\n- Download the training/validation split we use in our paper from [here](https://drive.google.com/file/d/1dop4188xo5lXDkGtOZUzy2SHOD_COXz4/view?usp=sharing) (originally from [Faster R-CNN](https://github.com/rbgirshick/py-faster-rcnn/tree/master/data))\n- Unzip the file and place `annotations` under `<CornerNet-Lite dir>/data/coco`\n- Download the images (2014 Train, 2014 Val, 2017 Test) from [here](http://cocodataset.org/#download)\n- Create 3 directories, `trainval2014`, `minival2014` and `testdev2017`, under `<CornerNet-Lite dir>/data/coco/images/`\n- Copy the training/validation/testing images to the corresponding directories according to the annotation files\n\nTo train and evaluate a network, you will need to create a configuration file, which defines the hyperparameters, and a model file, which defines the network architecture. The configuration file should be in JSON format and placed in `<CornerNet-Lite dir>/configs/`. Each configuration file should have a corresponding model file in `<CornerNet-Lite dir>/core/models/`. i.e. If there is a `<model>.json` in `<CornerNet-Lite dir>/configs/`, there should be a `<model>.py` in `<CornerNet-Lite dir>/core/models/`. There is only one exception which we will mention later.\n\n### Training and Evaluating a Model\nTo train a model:\n```\npython train.py <model>\n```\n\nWe provide the configuration files and the model files for CornerNet-Saccade, CornerNet-Squeeze and CornerNet in this repo. Please check the configuration files in `<CornerNet-Lite dir>/configs/`.\n\nTo train CornerNet-Saccade:\n```\npython train.py CornerNet_Saccade\n```\nPlease adjust the batch size in `CornerNet_Saccade.json` to accommodate the number of GPUs that are available to you.\n\nTo evaluate the trained model:\n```\npython evaluate.py CornerNet_Saccade --testiter 500000 --split <split>\n```\n\nIf you want to test different hyperparameters during evaluation and do not want to overwrite the original configuration file, you can do so by creating a configuration file with a suffix (`<model>-<suffix>.json`). There is no need to create `<model>-<suffix>.py` in `<CornerNet-Lite dir>/core/models/`.\n\nTo use the new configuration file:\n```\npython evaluate.py <model> --testiter <iter> --split <split> --suffix <suffix>\n```\n\nWe also include a configuration file for CornerNet under multi-scale setting, which is `CornerNet-multi_scale.json`, in this repo. \n\nTo use the multi-scale configuration file:\n```\npython evaluate.py CornerNet --testiter <iter> --split <split> --suffix multi_scale"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9449813035477502,
        0.9747466821846071
      ],
      "excerpt": "CornerNet-Lite: Efficient Keypoint Based Object Detection \nHei Law, Yun Teng, Olga Russakovsky, Jia Deng \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hollyprince/ObjectsDetection-CornerNet-Lite",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-22T11:42:46Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-15T07:43:09Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8901459620661598
      ],
      "excerpt": "Code for reproducing results in the following paper: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9321853331929578
      ],
      "excerpt": "Compile the C++ implementation of the corner pooling layers. (GCC4.9.2 or above is required.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9233482290680008
      ],
      "excerpt": "Compile the NMS code which are originally from Faster R-CNN and Soft-NMS. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8118458986738207,
        0.9343831142139524
      ],
      "excerpt": "It is also easy to use CornerNet-Lite in your project. You will need to change the directory name from CornerNet-Lite to CornerNet_Lite. Otherwise, you won't be able to import CornerNet-Lite. \nYour project \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9143103657542786
      ],
      "excerpt": "We provide the configuration files and the model files for CornerNet-Saccade, CornerNet-Squeeze and CornerNet in this repo. Please check the configuration files in &lt;CornerNet-Lite dir&gt;/configs/. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9341425949709286,
        0.8418471502970342
      ],
      "excerpt": "Please adjust the batch size in CornerNet_Saccade.json to accommodate the number of GPUs that are available to you. \nTo evaluate the trained model: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9248092804753151
      ],
      "excerpt": "We also include a configuration file for CornerNet under multi-scale setting, which is CornerNet-multi_scale.json, in this repo.  \n",
      "technique": "Supervised classification"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "In this repo, we provide models for the following detectors:\n- [CornerNet-Saccade](https://drive.google.com/file/d/1MQDyPRI0HgDHxHToudHqQ-2m8TVBciaa/view?usp=sharing)\n- [CornerNet-Squeeze](https://drive.google.com/file/d/1qM8BBYCLUBcZx_UmLT0qMXNTh-Yshp4X/view?usp=sharing)\n- [CornerNet](https://drive.google.com/file/d/1e8At_iZWyXQgLlMwHkB83kN-AN85Uff1/view?usp=sharing)\n\nPut the CornerNet-Saccade model under `<CornerNet-Lite dir>/cache/nnet/CornerNet_Saccade/`, CornerNet-Squeeze model under `<CornerNet-Lite dir>/cache/nnet/CornerNet_Squeeze/` and CornerNet model under `<CornerNet-Lite dir>/cache/nnet/CornerNet/`. (\\* Note we use underscore instead of dash in both the directory names for CornerNet-Saccade and CornerNet-Squeeze.)\n\nNote: The CornerNet model is the same as the one in the original [CornerNet repo](https://github.com/princeton-vl/CornerNet). We just ported it to this new repo.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- Download the training/validation split we use in our paper from [here](https://drive.google.com/file/d/1dop4188xo5lXDkGtOZUzy2SHOD_COXz4/view?usp=sharing) (originally from [Faster R-CNN](https://github.com/rbgirshick/py-faster-rcnn/tree/master/data))\n- Unzip the file and place `annotations` under `<CornerNet-Lite dir>/data/coco`\n- Download the images (2014 Train, 2014 Val, 2017 Test) from [here](http://cocodataset.org/#download)\n- Create 3 directories, `trainval2014`, `minival2014` and `testdev2017`, under `<CornerNet-Lite dir>/data/coco/images/`\n- Copy the training/validation/testing images to the corresponding directories according to the annotation files\n\nTo train and evaluate a network, you will need to create a configuration file, which defines the hyperparameters, and a model file, which defines the network architecture. The configuration file should be in JSON format and placed in `<CornerNet-Lite dir>/configs/`. Each configuration file should have a corresponding model file in `<CornerNet-Lite dir>/core/models/`. i.e. If there is a `<model>.json` in `<CornerNet-Lite dir>/configs/`, there should be a `<model>.py` in `<CornerNet-Lite dir>/core/models/`. There is only one exception which we will mention later.\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hollyprince/ObjectsDetection-CornerNet-Lite/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Mon, 27 Dec 2021 14:25:23 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hollyprince/ObjectsDetection-CornerNet-Lite/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "hollyprince/ObjectsDetection-CornerNet-Lite",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\nmkdir -p <CornerNet-Lite dir>/data\ncd <CornerNet-Lite dir>/data\ngit clone git@github.com:cocodataset/cocoapi.git coco\ncd <CornerNet-Lite dir>/data/coco/PythonAPI\nmake install\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Please first install [Anaconda](https://anaconda.org) and create an Anaconda environment using the provided package list `conda_packagelist.txt`.\n```\nconda create --name CornerNet_Lite --file conda_packagelist.txt --channel pytorch\n```\n\nAfter you create the environment, please activate it.\n```\nsource activate CornerNet_Lite\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8830326931139051
      ],
      "excerpt": "Compile the C++ implementation of the corner pooling layers. (GCC4.9.2 or above is required.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9528557246768159
      ],
      "excerpt": "python setup.py install --user \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8829415321722242
      ],
      "excerpt": "If you want to train or evaluate the detectors on COCO, please move on to the following steps. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9073290539525173
      ],
      "excerpt": "\u2502   foo.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.822492968530294
      ],
      "excerpt": "In foo.py, you can easily import CornerNet-Saccade by adding: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from CornerNet_Lite import CornerNet_Saccade \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8576591754281959
      ],
      "excerpt": "To train a model: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8303798559955017,
        0.9503189345333785
      ],
      "excerpt": "To train CornerNet-Saccade: \npython train.py CornerNet_Saccade \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hollyprince/ObjectsDetection-CornerNet-Lite/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C++"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\n\\nCopyright (c) 2019, Princeton University\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n Redistributions of source code must retain the above copyright notice, this\\n  list of conditions and the following disclaimer.\\n\\n Redistributions in binary form must reproduce the above copyright notice,\\n  this list of conditions and the following disclaimer in the documentation\\n  and/or other materials provided with the distribution.\\n\\n* Neither the name of the copyright holder nor the names of its\\n  contributors may be used to endorse or promote products derived from\\n  this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "CornerNet-Lite: Training, Evaluation and Testing Code",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ObjectsDetection-CornerNet-Lite",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "hollyprince",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hollyprince/ObjectsDetection-CornerNet-Lite/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Python 3.7\n- PyTorch 1.0.0\n- CUDA 10\n- GCC 4.9.2 or above\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Please first install [Anaconda](https://anaconda.org) and create an Anaconda environment using the provided package list `conda_packagelist.txt`.\n```\nconda create --name CornerNet_Lite --file conda_packagelist.txt --channel pytorch\n```\n\nAfter you create the environment, please activate it.\n```\nsource activate CornerNet_Lite\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "After downloading the models, you should be able to use the detectors on your own images. We provide a demo script `demo.py` to test if the repo is installed correctly.\n```\npython demo.py\n```\nThis script applies CornerNet-Saccade to `demo.jpg` and writes the results to `demo_out.jpg`.\n\nIn the demo script, the default detector is CornerNet-Saccade. You can modify the demo script to test different detectors. For example, if you want to test CornerNet-Squeeze:\n```python\n#:!/usr/bin/env python\n\nimport cv2\nfrom core.detectors import CornerNet_Squeeze\nfrom core.vis_utils import draw_bboxes\n\ndetector = CornerNet_Squeeze()\nimage    = cv2.imread(\"demo.jpg\")\n\nbboxes = detector(image)\nimage  = draw_bboxes(image, bboxes)\ncv2.imwrite(\"demo_out.jpg\", image)\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Mon, 27 Dec 2021 14:25:23 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "After downloading the models, you should be able to use the detectors on your own images. We provide a demo script `demo.py` to test if the repo is installed correctly.\n```\npython demo.py\n```\nThis script applies CornerNet-Saccade to `demo.jpg` and writes the results to `demo_out.jpg`.\n\nIn the demo script, the default detector is CornerNet-Saccade. You can modify the demo script to test different detectors. For example, if you want to test CornerNet-Squeeze:\n```python\n#:!/usr/bin/env python\n\nimport cv2\nfrom core.detectors import CornerNet_Squeeze\nfrom core.vis_utils import draw_bboxes\n\ndetector = CornerNet_Squeeze()\nimage    = cv2.imread(\"demo.jpg\")\n\nbboxes = detector(image)\nimage  = draw_bboxes(image, bboxes)\ncv2.imwrite(\"demo_out.jpg\", image)\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf <br>\n[2] https://arxiv.org/pdf/1511.06434.pdf <br>\n[3] https://github.com/soumith/ganhacks <br>\n[4] https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0 <br>\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AKASHKADEL/dcgan-mnist",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-08-13T22:22:01Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T11:50:31Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Deep Convolutional GAN is one of the most coolest and popular deep learning technique. It is a great improvement upon the [original GAN network](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf) that was first introduced by Ian Goodfellow at NIPS 2014. (DCGANs are much more stable than Vanilla GANs) DCGAN uses the same framework of generator and discriminator. This is analogous to solving a two player minimax game: Ideally the goal of the discriminator is to be very sharp in distinguishing between the real and fake data, whereas, generator aims at faking data in such a way that it becomes nearly impossible for the discriminator to classify it as a fake. The below gif shows how quickly dcgan learns the distribution of mnist and generates real looking digits.\n\n![](https://github.com/AKASHKADEL/dcgan-mnist/blob/master/results/fixed_noise/animated.gif)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9444544572167117
      ],
      "excerpt": "A small PyTorch tutorial for DCGAN on MNIST dataset. The implementation primarily follows the paper: Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "PyTorch Implementation of DCGAN",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AKASHKADEL/dcgan-mnist/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Thu, 23 Dec 2021 23:34:43 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/AKASHKADEL/dcgan-mnist/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "AKASHKADEL/dcgan-mnist",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/AKASHKADEL/dcgan-mnist/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "DCGAN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "dcgan-mnist",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "AKASHKADEL",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AKASHKADEL/dcgan-mnist/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Python 3+ distribution\n* PyTorch >= 1.0\n\nOptional:\n\n* Matplolib and Imageio to produce basic visualizations.\n* Cuda >= 10.0\n\nOnce everything is installed, you can go ahead and run the below command to train a model on 100 Epochs and store the sample outputs from generator in the ```results``` folder.\n\n```python main.py --num-epochs 100 --output-path ./results/ ```\n\nYou can also generate sample output using a fixed noise vector (It's easier to interpret the output on a fixed noise. Ex: the above gif), use this\n\n```python main.py --num-epochs 100 --output-path ./results/ --use-fixed ```\n\nYou can change the model setting by playing with the learning rate, num_epochs, batch size, etc\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Thu, 23 Dec 2021 23:34:43 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deeplearning",
      "gans",
      "dcgan",
      "pytorch",
      "visualization"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To get started and to replicate the above result, follow the instructions in this section. This wil allow you to train the model from scratch and help produce basic visualizations. \n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "citation": [
    {
      "confidence": [
        0.9806040058243822
      ],
      "excerpt": "The original YOLOv3 paper by Joseph Redmon and Ali Farhadi:  https://arxiv.org/pdf/1804.02767.pdf \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rvbcia/pytorch-yolo-custom",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-01-11T21:14:10Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-01-12T12:00:35Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9059207595095633,
        0.8673370026550298
      ],
      "excerpt": "This fork is a work in progress.  It will be noted here when this is ready for broader, more production, use.  Issues are welcome. \nUser may bring custom data with a custom number of classes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977066178241453
      ],
      "excerpt": "For more details on updates and status of this fork, see notes at the bottom of the README.md \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9719947809812138
      ],
      "excerpt": "This project is a \"You Only Look Once\" v3 sample using PyTorch, a fork of https://github.com/ayooshkathuria/pytorch-yolo-v3, with updates and improvements specifically for architecture on custom data labeled with VoTT (versus the classic download of VOC or COCO data and pre-existing labels).  This fork allows the user to bring their own dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9397569963669261
      ],
      "excerpt": "This project is a work in progress and issues are welcome (it's also a hobby at this point, so updates may be slow) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9153982377969044
      ],
      "excerpt": "Training is very sensitive to the amount of layers to unfreeze for transfer learning which is set on command line (try more, then work down to less - affects first pass); if the loss does not decrease/model converge, try opening up more layers to be trained upon \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8509438303947003
      ],
      "excerpt": "Use one of these two labeling tools and export to YOLO format: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8056756819351688
      ],
      "excerpt": "in the [net] part at the beginning (steps are epochs, here), e.g.: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8327618671148487,
        0.8590611732779867,
        0.8095730165803203
      ],
      "excerpt": "Modify the anchors in the yolov3-tiny-x.cfg or yolov3-x.cfg in the [net] section and the [yolo] sections with the new anchor box x, y values. \nChanging Filters and Classes \nEnsure the yolov3-tiny-x.cfg or yolov3-x.cfg is set up correctly.  Note, the number of classes will affect the last convolutional layer filter numbers (conv layers before the yolo layer) as well as the yolo layers themselves - so will need to be modified manually to suit the needs of the user. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8582416794430492
      ],
      "excerpt": "Addressed issue of detecting small objects \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8878099378808878
      ],
      "excerpt": "Performance on par with other architectures (a bit faster than SSD, even) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9532998528713068
      ],
      "excerpt": "[x] Replace CUDA flag in lieu of the simple tensor_xyz.to(device) method \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9060404661823492
      ],
      "excerpt": "[x] Fix the learning rate adjustment to decrease more consistently during training and finetuning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8023945395000381
      ],
      "excerpt": "[x] Ensure this codebase works with full sized YOLOv3 network \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8017051121161701
      ],
      "excerpt": "[ ] Checkpoint only models with better loss values than previous ones (use checkpoint functionality in PyTorch) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "wljdoejfpw",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rvbcia/pytorch-yolo-custom/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 00:35:04 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/rvbcia/pytorch-yolo-custom/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "rvbcia/pytorch-yolo-custom",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/rvbcia/pytorch-yolo-custom/tree/master/data_aug/docs"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Install the required Python packages (`pip install -r requirements.txt`).\n* Download the [full YOLO v3 (237 MB)](https://pjreddie.com/media/files/yolov3.weights) or [tiny YOLO v3 (33.8 MB)](https://pjreddie.com/media/files/yolov3-tiny.weights) model.  **Fun fact:  this project utilizes the weights originating in Darknet format**.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8685275255312541
      ],
      "excerpt": "<a href=\"https://github.com/tzutalin/labelImg\" target=\"_blank\">labelIMG</a> (probably easiest to pip3 install labelImg) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8262337112301398
      ],
      "excerpt": "<img src=\"imgs/id_plumeria_sml.png\" width=\"70%\" align=\"center\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8640042911664376
      ],
      "excerpt": "There are two phases in training: 1) the first pass (set number of epochs in cfg file and layers to train on set on command line) and 2) fine-tuning (all parameters are trained upon, i.e. all layers \"opened up\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8288876616508039,
        0.8852682493589278,
        0.8622247522278391
      ],
      "excerpt": "If you wish to train on all labeled images, make sure they are all in the train.txt file (this is read by the customloader.py). \nThe data output folder should be a subdirectory here with the images, labels and pointer file. \nTo summarize, within the appropriate config file located under the cfg folder (note, examples are there), the following properties will be modified as per instructions here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8886465595473138
      ],
      "excerpt": "anchors = 25,87, 44,55, 46,110, 72,74, 80,118, 93,45, 105,72, 127,96, 144,58 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8886465595473138
      ],
      "excerpt": "anchors = 25,87, 44,55, 46,110, 72,74, 80,118, 93,45, 105,72, 127,96, 144,58 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.894266524671365
      ],
      "excerpt": "Run Kmeans algorithm:  these anchors should be manually discovered with and specified in the cfg file.  Run scripts/convert_labels.py and then kmeans.py on new annotatino format output.  (a workaround for now to get anchors) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9323524999376706
      ],
      "excerpt": "Create a list of the training images file paths, one per line, called train.txt and place it in the data folder.  e.g. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9303447009175363,
        0.8778487586960795,
        0.8289443115749424,
        0.8942789510331012
      ],
      "excerpt": "Create a list of the test images file paths, one per line, called test.txt and place it in the data folder.  e.g. \nCmd example: \npython eval.py --cfg cfg/yolov3-2class.cfg --weights runs/&lt;your trained model&gt;.pth --overlap 0.3 \npython eval.py --help \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8559921181505474
      ],
      "excerpt": "[x] Add a custom collate function to train.py to detect empty boxes and exclude \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9134185667851503
      ],
      "excerpt": "[x] Add finetuning to the train.py script \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8529541764331016
      ],
      "excerpt": "[x] Fix customloader.py to take custom (as an argument) anchors, anchor numbers and model input dims \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/rvbcia/pytorch-yolo-custom/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "A Fork of PyTorch Implemation of YOLOv3 to Accomodate Custom Data",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pytorch-yolo-custom",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "rvbcia",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rvbcia/pytorch-yolo-custom/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Cmd example:\n\n    python train.py --cfg cfg/yolov3-2class.cfg --weights yolov3.weights --datacfg data/obj.data --lr 0.0005 --unfreeze 2\n\nUsage:\n\n    python train.py --help\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Cmd example:\n\n    python live.py --cfg cfg/yolov3-tiny.cfg --weights runs/<your trained model>.pth --datacfg data/obj.data --confidence 0.6\n\nUsage:\n    \n    python live.py --help\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 00:35:04 GMT"
    },
    "technique": "GitHub API"
  }
}
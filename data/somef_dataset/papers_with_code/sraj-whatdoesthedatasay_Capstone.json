{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1609.08144"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sraj-whatdoesthedatasay/Capstone",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-13T20:20:07Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-20T21:17:54Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Agents in various operational sites have to do a vast variety of tasks and have to multitask using the tools they have.  These agents are the face of the company to a lot of customers and the customer experience provided by these agents is very important in driving customer's perception of the product and the company.\n\nIn global companies, some agents also have to service accounts of accountholders who speak other languages. So it is important that agents have multiple tools at their fingertips that enable them to do their jobs better.  In addition, better tools can drive more efficiency which can help to reduce staffing demand and drive lower costs for organizations.\n\nThis project was to develop a suite of tools (called AA for Agent Assistant) to help agents in their efforts in servicing customers.  There were 3 ML based tools that have been developed here to assist the agents in their effort:\n\n#1 **English to Spanish translator**:  The intent of this tool is to enable agents to communicate with Spanish-speaking customers. This was built using English and Spanish datasets of multiple sentences.  It was built using natural language processing tools in [scikit-learn](https://scikit-learn.org/stable/) and [NLTK](https://www.nltk.org/).  A sequence-to-sequence LSTM model was built using the underlying data to develop a model to enable translation.  The model's accuracy was around 80% for the test and train population.\n\n#2 **Sentence Completion**: The intent of this tool is to enable an agent to complete their sentences after they had typed the first few words making them faster at their job.  This would be akin to how gmail completes sentences after you have typed a few words.  The same English sentences that were used for translation were used.  However, the input feature was the first few words from the English lines and the last few words from the same English line was the target for the model.  Similar to the translation algorithm, another sequence-to-sequence LSTM model was built to enable completion.  The model's completion accuracy is displayed to be ~80% for the test population, however, the proposed sentence completers are not as clear. \n\n#3 **Chatbot to help agents**:  The intent of this tool is to enable an agent to type in a question about some credit card feature and it would then answer the question.  Using the FAQ from a bank's webpage and randomizing permutations, a chat corpus was created.  This is then used to used to train the model where a question is mapped to the intent behind the question.  Intent can range from how to apply, how to earn rewards, what is reported to the credit bureaus etc.  Each intent has a unique answer and the chatbot would respond with that answer.  The model accuracy here was over 95% primarily because the chat corpus was built around the FAQ words.\n\nFor the Translator and Completer, the execution of training and inferencing the LSTM model had to be developed separately. Given the long run-times, additional functions were developed to continue with the epoch training after a few epoch runs.  Also a set of decoding functions had to be developed to read in the text and load that into a certain form for the model's encoder and decoder to use and translate/complete.  A streamlit app was developed for all the 3 models so that AA can be demonstrated to agents and interested organizations.\n\nSome challenges that were faced (especially for the Translator and Completer), was that not all lines could be used due to system & memory limitations in the training process.  This limited the training of the model and the translations/completions it can come up with.  Also the model wouldn't run on a laptop and had to be run on Google Cloud Platform in order to run over a few hours.  Both Translator and Completer needed over 50 epochs which took over 5 hours to run on Google Cloud Platform.\n\nLooking forward, the opportunity is to improve the algorithms and use more data in conjunction to improve the quality of the translation and completions.  For the chat model, the opportunity is to train the model on actual chat conversations so that it can be trained better on unseen data and develop better response.\n\n \n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.951349271221848,
        0.8030241701881762,
        0.9575045847165166,
        0.9798804893002058,
        0.8047337548378946
      ],
      "excerpt": "This project used the data for translater and sentence completer from the following source:  \nLink to dataset of Spanish-English sentences: http://www.manythings.org/anki/spa-eng.zip \nThe initial dataset had ~128k rows with each row having the English and corresponding Spanish line.  This had been curated by lines coming from different sources.  There were about 19k duplicate English lines that were then de-duped from the dataset.  There were also sentences with very few or very high characters as well as sentences with fewer words.  Sentences with less than 18 characters and with less than 4 words and with more than 50 characters were removed.  The lower end counts were removed to not have very sparse matrices in the eventual dataset.  The above suppressions resulted in ~80k records for the Translator and ~50k records for the Completer. \nFor the chatbot, the data was sourced from a primary banks' website from the FAQ page with questions and answers.  The chat corpus was developed using words from the questions and permutations created to expand to multiple questions.  Each question was tagged to an 'intent' and the intent was mapped to an 'answer'.  For example, questions related to application of a card was tagged as CardApplication intent with a defined answer for that intent. \nHere are sample rows from the dataset that were used for the Translator, Sentence Completer and the Chatbot. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8945774326964449
      ],
      "excerpt": "|question   |intent | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8813481725055574,
        0.8938720449232365,
        0.9705103586541731,
        0.9136414357848133,
        0.9397040466679306,
        0.8700538500745199,
        0.9708713216248634,
        0.9730067769609047,
        0.8913102667462444,
        0.957411014157431,
        0.8397504820331012,
        0.9526825055861308
      ],
      "excerpt": "Standard processing such as converting to lower case characters, removing punctuations, removing extra spaces and digits for English & Spanish sentences \nExamined the data and removed duplicate English sentences \nCreated 2 new variables around count of characters and words for English & Spanish sentences and reviewed distributions by count of characters and words \nFor Translator, kept lines with characters between 18 and 50 \nFor Completer, same pruning for characters and also deleted lines with less than 4 words \nTranslator and Sentence completers need NLP based models.  These models need to store the words and their sequence that comes together to form a sentence.   \nThis makes sequence-2-sequence LSTM models the ideal model to use since it has to retain memory of the past sequence to create the new words.  There are other options like using embedding and teacher-forced training that can further enhance the model. \nThis modelling exercise was influenced by Francois Chollet's usage of sequence-2-sequence LSTM models.  https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html.  Google's translation (https://arxiv.org/abs/1609.08144) and Facebook's translation were also based on LSTM albeit with a lot more encoder and decoder layers, more evolved algorithms and lot of memory / computation power to build these out. \nTrain and Test split were created and the model was trained through multiple epochs.  The local machine was not able to handle the higher memory resulting in the program crashing or running very slow.  So training was moved to the Google Cloud Platform with a Cuda instance, 8-CPU machines, 64GB RAM and 100GB disk. This made the epochs run for more lines and much faster.  \nThe training program was modified to store the model every 5 epochs.  In addition, another function was written to load the interim model as well as load other data required for training.  This needed converting the interim dictionaries that were created into pickled files that would then have to be read again for the model to continue learning using the loaded model. \nIn addition an inference model had to be developed, where one would pass the text that had to be translated as input, it would then predict the translation or sentence completion by reading the encoder and decoder configurations from the saved model - and it would then write the translated Spanish text or the completed sentence. \nHere are the tactical steps for the model building process mapped to the scripts in the github: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9568587839966112
      ],
      "excerpt": "St2: reads in the 'EngSpa.csv' file from the previous step, parses the 'eng' and 'spa' columns from the file to a dataframe, builds out lists to be used for modelling, creates dictionaries of words from input and target features with a forward and reverse view.  It then creates two 3-dimensional array (#lines * #words in the line * #tokens for input or target) that is then used for modelling and models are created using multiple epochs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9568587839966112,
        0.9407410889796134
      ],
      "excerpt": "St2:  reads in the 'eng.csv' file from the previous step, parses the 'eng_pre' and 'eng_post' columns from the file to a dataframe, builds out lists to be used for modelling, creates dictionaries of words from input and target features with a forward and reverse view.  It then creates two 3-dimensional array (#lines * #words in the line * #tokens for input or target) that is then used for modelling and models are created using multiple epochs. \nSt3: reads in the model as well as dictionaries and other inputs for the model.  This then creates the function that can be used for completing sentences. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8994409372693476,
        0.8690729972772842,
        0.9537113102219922
      ],
      "excerpt": "Developed a column with permutation of different words from the questions column \nTokenized data to remove punctuation  \nLemmatized data so only singular forms of words remained \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9037813259514667
      ],
      "excerpt": "Dataset included ~36k rows of chat related questions and the corresponding intent \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9904848473157729
      ],
      "excerpt": "Vectorized data using Tf-IDF Vectorizer with 2 grams and max_df=2.0, min_df=5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9523260900494647,
        0.9733183140393764,
        0.9526825055861308
      ],
      "excerpt": "The logistic regression model scored extremely well.  This was mainly because the 'chat corpus' was developed using permutations of the questions from the FAQ.  So there were not many unseen words - which would happen in an actual chat conversation.  A next step here would be to train the model on actual chat questions and then map to the intent and evaluate how the model would do. \nTested a Neural Net model but the performance was so strong from the Logistic Regression model that there was not a lot of value in evaluating different models.  This would be more relevant when one is building the model on actual varied chat transcripts. \nHere are the tactical steps for the model building process mapped to the scripts in the github: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9778309594801774
      ],
      "excerpt": "We were able to achieve our goal of helping Chat agents by providing them tools to enable translation, sentence completion as well as a chatbot to quickly look up product terms.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9402917173934225,
        0.8752431766682447,
        0.9865046703654703,
        0.9401686864571908,
        0.9912249817276632
      ],
      "excerpt": "The streamlit code is stored in main folder and is called GlobalStreamlit.py.  It creates a side-frame which allows to pick between the 3 apps and then the app can be used to try out one of the 3 options. \nThe 3 different models have varying levels of success and have different future directions.  \nThe translator does an okay job on words it has been trained upon.  It translates short sentences well.  However, it falls short when it sees an unknown word or is given longer sentences.  This is mainly driven because the model was trained only on 18k lines due to limitation of how much space was needed for LSTM models.  The next step here is to use enhanced algorithms which have embedding features, more layers using more computing power & memory (so it can consume more lines) to develop better translations. \nThe sentence completer wasn't as good as expected.  Similar to the translator, the completer was trained only on 40k rows due to memory limitations.  The completions were somewhat limited - potentially because of so many combinations being possible for sentence completions.  The next step here would be similar that we would need to enhance algorithms that use memory better and use more data to build better completers. \nThe chat model does an inherently solid job of figuring out intent if the right words are in the question text.  It then accurately figures out intent and plays back the answer.  In order to make the model more successful, one should train the model on actual chat transcripts (these were not available for bank or similar institutions) with the correct intent labelled.  This would significantly improve the ability to comprehend different questions and come up with the right answers. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "|   |__ data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9107851237638755
      ],
      "excerpt": "|       |__St2_NLP_model_text.ipynb #:Creates the NLP model (cs_model.p) that is used for Streamlit \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "|   |__ data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8412751523035309
      ],
      "excerpt": "|       |__St3_CompleteSentence.ipynb #:Inference model to do the sentence completions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "|   |__ data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "|__ ML_AI for CS agents.pdf \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sraj-whatdoesthedatasay/Capstone/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Chat agents have to perform multiple tasks simultaneously that can slow them down.   They have to cover multiple languages at times, they have look up product questions so that they can get back to the customer quickly - and all these activities can slow then down as well as introduce the likelihood of errors.\n\n**We aim to help chat operations agents** by developing tools using ML models to improve their efficiency and effectiveness.\n\nWe have used ML models to **have a translater that can translate from English to Spanish**, **a sentence completer that can finish their sentences after they have typed a few words**, and **a chatbot that can answer their product related questions**.  \n\n---\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 20:08:15 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sraj-whatdoesthedatasay/Capstone/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "sraj-whatdoesthedatasay/Capstone",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/sraj-whatdoesthedatasay/Capstone/main/COF_CS_Chat/St2_NLP_model_text.ipynb",
      "https://raw.githubusercontent.com/sraj-whatdoesthedatasay/Capstone/main/COF_CS_Chat/St1_CreateChatCorpus.ipynb",
      "https://raw.githubusercontent.com/sraj-whatdoesthedatasay/Capstone/main/TranslateEngSpan/St3_TranslateNewText.ipynb",
      "https://raw.githubusercontent.com/sraj-whatdoesthedatasay/Capstone/main/TranslateEngSpan/St2_DataProcessModel.ipynb",
      "https://raw.githubusercontent.com/sraj-whatdoesthedatasay/Capstone/main/TranslateEngSpan/St1_Read_EDA_EngSpanish.ipynb",
      "https://raw.githubusercontent.com/sraj-whatdoesthedatasay/Capstone/main/SentenceCompletion/St3_CompleteSentence.ipynb",
      "https://raw.githubusercontent.com/sraj-whatdoesthedatasay/Capstone/main/SentenceCompletion/St2_DataProcessModel_Eng.ipynb",
      "https://raw.githubusercontent.com/sraj-whatdoesthedatasay/Capstone/main/SentenceCompletion/St1_Read_EDA_Eng.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8721339510055713
      ],
      "excerpt": "The app has 3 functionalities that leverages models to make predictions: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.861977522425654
      ],
      "excerpt": "Split data into train and test sets using train-test-split with split ratio of  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003261166765615
      ],
      "excerpt": "Test score: .996 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8425465175082578
      ],
      "excerpt": "|      |__eng.csv #:English CSV file created after St1 below is run \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8135982498196904
      ],
      "excerpt": "|       |__St1_Read_EDA_Eng.ipynb #:Reads the spa.txt file, does basic EDA \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594415679061906
      ],
      "excerpt": "|       |__spa.txt #:Raw data file that is used to then create the eng.csv file \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8425465175082578
      ],
      "excerpt": "|      |__EngSpa.csv #:Spanish English CSV file created after St1 below is run \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594415679061906
      ],
      "excerpt": "|       |__spa.txt #:Raw data file that is used to then create the eng.csv file \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "|__ GlobalStreamlit.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sraj-whatdoesthedatasay/Capstone/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Capstone Project",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Capstone",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "sraj-whatdoesthedatasay",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sraj-whatdoesthedatasay/Capstone/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Wed, 29 Dec 2021 20:08:15 GMT"
    },
    "technique": "GitHub API"
  }
}
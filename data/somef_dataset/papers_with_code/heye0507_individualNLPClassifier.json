{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1801.06146\n\n## Input format\n- For individual classification model generation, store all the datasets into demo_data/ or create new folder under /individualNLPClassifier/your_data_folder\n- The dataset should be in JSON format\n- Each JSON file is an object with the fields id, num_data_points, and data_points. data_points is an array of objects with the fields body, embedding, and source. body is the original text of the message. source is the site the message came from. embedding is the embedding produced language model (For non-Basilica dataset, simply make it empty list [], Please see demo.json in demo_data/ folder for more details"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/heye0507/individualNLPClassifier",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-09-16T22:53:07Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-10T13:56:18Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9763888382369934,
        0.9805105122737802
      ],
      "excerpt": "Individual level NLP classifier is a consulting project worked with Basilica.ai. Basilica.ai is a B2B startup that providing sentiment as a service for social media companies. The goal is to have individual level classifiers so that companies can sort newly generated social media posts based on individual user's interest. \nHere are the slides for the project \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9586160324919997
      ],
      "excerpt": "jupyter_notebooks : Contains all the jupyter notebooks for building up this project, including EDA, ULMFit / BERT training and post PCA / Siamese network analysis \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8084069144963605
      ],
      "excerpt": "PSM_nlp.bert_interface and PSM_npl.bert_trainer contains BERT pre-processing and training API \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9126568701051674
      ],
      "excerpt": "Here is an example of how to build both trainer for BERT and AWD_LSTM \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.959961309707981
      ],
      "excerpt": ":#:#: For AWD_LSTM model #:#:#: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8317890737247443,
        0.8368976702470713
      ],
      "excerpt": "ULMFit, using AWD_LSTM as encoder (language model), build classification head on top of fine-tuned language model https://arxiv.org/abs/1801.06146 \nFor individual classification model generation, store all the datasets into demo_data/ or create new folder under /individualNLPClassifier/your_data_folder \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Insight Basilica Consulting Project",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/heye0507/individualNLPClassifier/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 21:55:23 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/heye0507/individualNLPClassifier/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "heye0507/individualNLPClassifier",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/jupyter_notebooks/pca_test.ipynb",
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/jupyter_notebooks/siamese_BERT_dev.ipynb",
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/jupyter_notebooks/bert_fastai.ipynb",
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/jupyter_notebooks/ulmfit_final.ipynb",
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/jupyter_notebooks/Test_main.ipynb",
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/jupyter_notebooks/test_module.ipynb",
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/jupyter_notebooks/Test_trainer.ipynb",
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/jupyter_notebooks/Convert_format.ipynb",
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/jupyter_notebooks/Test_BERT.ipynb",
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/jupyter_notebooks/siamese_dev.ipynb",
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/jupyter_notebooks/Test_module.ipynb",
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/jupyter_notebooks/awd_lstm_base_dev.ipynb",
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/jupyter_notebooks/pca_input.ipynb",
      "https://raw.githubusercontent.com/heye0507/individualNLPClassifier/master/jupyter_notebooks/Test_BERT_Trainer.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Clone repository and update python path\n```\ncd ~\ngit clone https://github.com/heye0507/individualNLPClassifier.git\ncd individualNLPClassifier/\ndocker build -t nlp_classifier .\ndocker run -it nlp_classifier\n```\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8253729202767536
      ],
      "excerpt": "PSM_nlp can be used as a python package \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.816243068372582
      ],
      "excerpt": "python3 setup.py build \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8463256716893556
      ],
      "excerpt": "path = Path(os.getcwd() + '/demo_data') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9655205239144661
      ],
      "excerpt": ":#:#: Please note you will need GPU to run the following line #:#:#: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8463256716893556
      ],
      "excerpt": "path = Path(os.getcwd() + '/demo_data') \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8311108564550707,
        0.9133368656218674,
        0.8401558704798054,
        0.8801854956928516,
        0.8801854956928516
      ],
      "excerpt": "python3 setup.py build \nimport PSM_nlp \nimport os \nfrom PSM_nlp.bert_interface import * \nfrom PSM_nlp.bert_trainer import * \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.8401558704798054
      ],
      "excerpt": "import PSM_nlp \nimport os \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8214116752289031,
        0.8801854956928516
      ],
      "excerpt": "from PSM_nlp.trainer import * \nfrom PSM_nlp.downloader import * \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8211421438225519
      ],
      "excerpt": "model_path = path/'models' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8447504201026536
      ],
      "excerpt": "The dataset should be in JSON format \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/heye0507/individualNLPClassifier/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Matthew Rubashkin\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Individual Level NLP Classifier",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "individualNLPClassifier",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "heye0507",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/heye0507/individualNLPClassifier/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Tue, 28 Dec 2021 21:55:23 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Run the following two lines for demo\n\n- Take Basilica dataset(s)\n- Using AWD_LSTM pre-trained general classification model, fine tune classification head on new dataset\n- Save the Pytorch model for in the designated path\n```\nsource activate nlp_model_gen\npython3 runner.py --input-file=demo_data/\n```\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1706.03762",
      "https://arxiv.org/abs/1810.04805"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Other great repositories with this model include: \n - [Ross Wightman's repo](https://github.com/rwightman/pytorch-image-models)\n - [Phil Wang's repo](https://github.com/lucidrains/vit-pytorch)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "<div style=\"text-align: center; padding: 10px\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9514562468139621
      ],
      "excerpt": "If you find a bug, create a GitHub issue, or even better, submit a pull request. Similarly, if you have questions, simply post them as GitHub issues. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lukemelas/PyTorch-Pretrained-ViT",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-10-25T18:36:57Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T12:52:34Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9171582554132327,
        0.9873707354637336
      ],
      "excerpt": "This repository contains an op-for-op PyTorch reimplementation of the Visual Transformer architecture from Google, along with pre-trained models and examples. \nThe goal of this implementation is to be simple, highly extensible, and easy to integrate into your own projects.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8860352523429983
      ],
      "excerpt": " * Evaluate on ImageNet or your own data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8302568026256196
      ],
      "excerpt": " * Export to ONNX for efficient inference \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9086195866555702,
        0.8863425306443846
      ],
      "excerpt": "The ViT architecture works as follows: (1) it considers an image as a 1-dimensional sequence of patches, (2) it prepends a classification token to the sequence, (3) it passes these patches through a transformer encoder (like BERT), (4) it passes the first token of the output of the transformer through a small MLP to obtain the classification logits.  \nViT is trained on a large-scale dataset (ImageNet-21k) with a huge amount of compute.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9885621691751023,
        0.9306939752013773,
        0.935946320776926
      ],
      "excerpt": "ViT-PyTorch is a PyTorch re-implementation of ViT. It is consistent with the original Jax implementation, so that it's easy to load Jax-pretrained weights. \nAt the same time, we aim to make our PyTorch implementation as simple, flexible, and extensible as possible. \nLoading a pretrained model is easy: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9068720277076172
      ],
      "excerpt": "Details about the models are below: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8516505734420676
      ],
      "excerpt": "Loading custom configurations is just as easy:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9179972296588512
      ],
      "excerpt": ": The following is equivalent to ViT('B_16') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Vision Transformer (ViT) in PyTorch",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 54,
      "date": "Sat, 25 Dec 2021 23:35:02 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lukemelas/PyTorch-Pretrained-ViT/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "lukemelas/PyTorch-Pretrained-ViT",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/lukemelas/PyTorch-Pretrained-ViT/master/jax_to_pytorch/explore-conversion.ipynb",
      "https://raw.githubusercontent.com/lukemelas/PyTorch-Pretrained-ViT/master/jax_to_pytorch/explore-conversion-21k.ipynb",
      "https://raw.githubusercontent.com/lukemelas/PyTorch-Pretrained-ViT/master/examples/simple/example.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/lukemelas/PyTorch-Pretrained-ViT/master/jax_to_pytorch/jax_weights/download.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Install with pip:\n```bash\npip install pytorch_pretrained_vit\n```\n\nOr from source:\n```bash\ngit clone https://github.com/lukemelas/ViT-PyTorch\ncd ViT-Pytorch\npip install -e .\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.978963208378272
      ],
      "excerpt": "Install with pip install pytorch_pretrained_vit and load a pretrained ViT with: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.810821887359724
      ],
      "excerpt": "At the moment, you can easily: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8474617303018263
      ],
      "excerpt": "|    Name         | Pretrained on |Finetuned on|Available? | \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8801854956928516,
        0.9024287239548907
      ],
      "excerpt": "from pytorch_pretrained_vit import ViT \nmodel = ViT('B_16_imagenet1k', pretrained=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8290199818908017
      ],
      "excerpt": " * Load pretrained ViT models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8290199818908017,
        0.8778487586960795
      ],
      "excerpt": "Load pretrained models \nExample: Classify \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516,
        0.9024287239548907
      ],
      "excerpt": "from pytorch_pretrained_vit import ViT \nmodel = ViT('B_16_imagenet1k', pretrained=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from pytorch_pretrained_vit import ViT \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lukemelas/PyTorch-Pretrained-ViT/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "ViT PyTorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "PyTorch-Pretrained-ViT",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "lukemelas",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lukemelas/PyTorch-Pretrained-ViT/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "lukemelas",
        "body": "This release adds pretrained models saved using the older serialization format. This deals with a bug in `torch.hub`. ",
        "dateCreated": "2020-10-30T15:46:39Z",
        "datePublished": "2020-11-03T22:54:49Z",
        "html_url": "https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/tag/0.0.2",
        "name": "Pretrained models with older serialization format",
        "tag_name": "0.0.2",
        "tarball_url": "https://api.github.com/repos/lukemelas/PyTorch-Pretrained-ViT/tarball/0.0.2",
        "url": "https://api.github.com/repos/lukemelas/PyTorch-Pretrained-ViT/releases/33428337",
        "zipball_url": "https://api.github.com/repos/lukemelas/PyTorch-Pretrained-ViT/zipball/0.0.2"
      },
      {
        "authorType": "User",
        "author_name": "lukemelas",
        "body": "",
        "dateCreated": "2020-10-30T15:46:39Z",
        "datePublished": "2020-10-30T18:47:28Z",
        "html_url": "https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/tag/0.0.1",
        "name": "Pretrained models",
        "tag_name": "0.0.1",
        "tarball_url": "https://api.github.com/repos/lukemelas/PyTorch-Pretrained-ViT/tarball/0.0.1",
        "url": "https://api.github.com/repos/lukemelas/PyTorch-Pretrained-ViT/releases/33285633",
        "zipball_url": "https://api.github.com/repos/lukemelas/PyTorch-Pretrained-ViT/zipball/0.0.1"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 335,
      "date": "Sat, 25 Dec 2021 23:35:02 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Below is a simple, complete example. It may also be found as a Jupyter notebook in `examples/simple` or as a [Colab Notebook]().  \n<!-- TODO: new Colab -->\n\n```python\nimport json\nfrom PIL import Image\nimport torch\nfrom torchvision import transforms\n\n#: Load ViT\nfrom pytorch_pretrained_vit import ViT\nmodel = ViT('B_16_imagenet1k', pretrained=True)\nmodel.eval()\n\n#: Load image\n#: NOTE: Assumes an image `img.jpg` exists in the current directory\nimg = transforms.Compose([\n    transforms.Resize((384, 384)), \n    transforms.ToTensor(),\n    transforms.Normalize(0.5, 0.5),\n])(Image.open('img.jpg')).unsqueeze(0)\nprint(img.shape) #: torch.Size([1, 3, 384, 384])\n\n#: Classify\nwith torch.no_grad():\n    outputs = model(img)\nprint(outputs.shape)  #: (1, 1000)\n```\n\n<!-- ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "You can easily extract features with `model.extract_features`:\n```python\nfrom efficientnet_pytorch import EfficientNet\nmodel = EfficientNet.from_pretrained('efficientnet-b0')\n\n#: ... image preprocessing as in the classification example ...\nprint(img.shape) #: torch.Size([1, 3, 384, 384])\n\nfeatures = model.extract_features(img)\nprint(features.shape) #: torch.Size([1, 1280, 7, 7])\n``` -->\n\n<!-- ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Exporting to ONNX for deploying to production is now simple:\n```python\nimport torch\nfrom efficientnet_pytorch import EfficientNet\n\nmodel = EfficientNet.from_pretrained('efficientnet-b1')\ndummy_input = torch.randn(10, 3, 240, 240)\n\nmodel.set_swish(memory_efficient=False)\ntorch.onnx.export(model, dummy_input, \"test-b1.onnx\", verbose=True)\n```\n\n[Here](https://colab.research.google.com/drive/1rOAEXeXHaA8uo3aG2YcFDHItlRJMV0VP) is a Colab example. -->\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
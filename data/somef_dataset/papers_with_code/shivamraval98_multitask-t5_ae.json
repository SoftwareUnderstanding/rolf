{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/pdf/1910.10683)\n\n[2] [Towards Zero-Shot Conditional Summarization with Adaptive Multi-Task Fine-Tuning](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7757121/)\n\n[3] [Improving Adverse Drug Event Extraction with SpanBERT on Different Text Typologies](https://arxiv.org/pdf/2105.08882.pdf)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```bibtex\n@inproceedings{raval2021exploring,\n  title={Exploring a Unified Sequence-To-Sequence Transformer for Medical Product Safety Monitoring in Social Media},\n  author={Raval, Shivam and Sedghamiz, Hooman and Santus, Enrico and Alhanai, Tuka and Ghassemi, Mohammad and Chersoni, Emmanuele},\n  booktitle={The 2021 Conference on Empirical Methods in Natural Language Processing},\n  year={2021},\n  organization={Association for Computational Linguistics (ACL)}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{raval2021exploring,\n  title={Exploring a Unified Sequence-To-Sequence Transformer for Medical Product Safety Monitoring in Social Media},\n  author={Raval, Shivam and Sedghamiz, Hooman and Santus, Enrico and Alhanai, Tuka and Ghassemi, Mohammad and Chersoni, Emmanuele},\n  booktitle={The 2021 Conference on Empirical Methods in Natural Language Processing},\n  year={2021},\n  organization={Association for Computational Linguistics (ACL)}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8942856639420041
      ],
      "excerpt": "How to Cite \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9911894225838389
      ],
      "excerpt": "| SMM4H Task 1 (AE Detection)<br /> <br /> Train (80%) <br /> Validation (10%) <br /> Test (10%)                                    | 15,482 <br /> <br /> 12,386 <br /> 1,548 <br /> 1,548 | 1,339 <br /> <br /> 1,071 <br /> 134 <br /> 134 | 14,143 <br /> <br /> 11,315 <br /> 1,414 <br /> 1,414 | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/shivamraval98/MultiTask-T5_AE",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-10T00:33:38Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-09T06:14:52Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.83269162449766,
        0.9700388975001877,
        0.9880187273304409
      ],
      "excerpt": "Exploring a Unified Sequence-To-Sequence Transformer for Medical Product Safety Monitoring in Social Media accepted to be published in EMNLP 2021 Findings track explores the sequence-to-sequence transformers to detect and extract Adverse Events (AE) from various source for medical product safety monitoring. \nAdverse Events (AE) are harmful events resulting from the use of medical products. Although social media may be crucial for early AE detection, the sheer scale of this data makes it logistically intractable to analyze using human agents, with NLP representing the only low-cost and scalable alternative. In this paper, we frame AE Detection and Extraction as a sequence-to-sequence problem using the T5 model architecture and achieve strong performance improvements over competitive baselines on several English benchmarks (F1 = 0.71, 12.7% relative improvement for AE Detection; Strict F1 = 0.713, 12.4% relative improvement for AE Extraction). \nGiven an input sequence of words that potentially contains drug, dosage and AE mentions, we frame the AE detection (i.e. binary classification) and extraction (i.e. span detection) tasks as seq-to-seq problems, further finetuning T5 to generate Y, which is either the classification label or the text span with the AE. The example of prefixes used is shown in the figure below: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9564342744478275,
        0.873380738882455
      ],
      "excerpt": "The datasets used for experimentation is mentioned below: \nThis dataset was introduced for the Shared Tasks on AE in the Workshop on Social Media Mining for Health Applications (SMM4H) (Weissenbacher et al., 2018). The dataset is composed of Twitter posts, typically short, informal texts with non-standard ortography, and it contains annotations for both detection (i.e., Task 1, classification) and extraction (i.e., Task 2, NER) of Adverse Events. The preparation of AE Detection dataset for SMM4H Task 1 requires SMM4H19_Task1.csv file in the /src/data/datasets/SMM4H_Task1/ folder. (column names: tweet_id, tweet, label). Similarly as Task 1 dataset, the importer function for Task 2 expects a file SMM4H19_Task2.csv in the /src/data/datasets/SMM4H_Task2/ folder. (column names: tweet_id,begin,end,type,extraction,drug,tweet,meddra_code,meddra_term <br /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.955405422400886
      ],
      "excerpt": "CADEC contains 1,250 medical forum posts annotated with patient-reported AEs. In this dataset, texts are long and informal, often deviating from English syntax and punctuation rules. Forum posts may contain more than one AE. For our goals, we adopted the training, validation, and test splits proposed by Dai et al. (2020). The importer for CADEC expects a zip file CADEC.zip in the /src/data/datasets/CADEC/ folder and the dataset is available at: https://data.csiro.au/collections/collection/CIcsiro:10948/SQcadec/RP1/RS25/RORELEVANCE/STsearch-by-keyword/RI1/RT1/ (download the CADEC.v2.zip)  <br /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9630185134733544
      ],
      "excerpt": "This dataset (Gurulingappa et al., 2012) contains case reports extracted from MEDLINE and it was used for multi-task training, as it contains annotations for all tasks: drugs, dosage, AE detection and extraction. Splits are stratified, to maintain an equal ratio of positive and negative examples.This dataset is automatically prepared by the code by loading the dataset from the huggingface datasets package. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9514431570990971
      ],
      "excerpt": "This dataset is a manually curated benchmark based on tweets. It is used exclusively to test the performance of the multi-task models, as it was originally introduced only for testing purposes (Dietrich et al., 2020). The importer for WEB-RADR expects the file WEB_RADR.csv in the folder /src/data/datasets/WEB_RADR/. (column names: tweet_id, tweet, label, extraction) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8434337625699467
      ],
      "excerpt": "The SMM4H Twitter AE French dataset was introduced in the SMM4H20 (https://www.aclweb.org/anthology/2020.smm4h-1.4.pdf) and the importer expects the file SMM4H_French.csv in the folder /src/data/datasets/SMM4H_French/. (column_names: tweet_id, tweet, label). This dataset is only used for testing the zero-shot transfer learning. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9095060206813687
      ],
      "excerpt": "After all the datastes being placed in their respective folders, the following command can be executed to load and prepare all the datasets for the model input. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/shivamraval98/multitask-t5_ae/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 26 Dec 2021 03:01:45 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/shivamraval98/MultiTask-T5_AE/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "shivamraval98/MultiTask-T5_AE",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\ncd ae-detect\npip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\npython3 -m venv t5_ade\nsource t5_ade/bin/activate\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8742566661384142
      ],
      "excerpt": "| ADE Corpus v2 (AE Extraction) <br /> <br /> Train (60%) <br /> Validation (20%) <br /> Test (20%)          | 6,821 <br /> <br /> 4,091 <br /> 1,365 <br /> 1,365   | 6,821 <br /> <br /> 4,091 <br /> 1,365 <br /> 1,365 | -                                                     | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8742566661384142
      ],
      "excerpt": "| ADE Corpus v2 (Drug Dosage Extraction) <br /> <br /> Train (60%) <br /> Validation (20%) <br /> Test (20%) | 279 <br /> <br /> 167 <br /> 56 <br /> 56             | -                                                   | -                                                     | \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9076548000363133,
        0.8761283009744154
      ],
      "excerpt": "SMM4H Task 2 Dataset Splits: /src/data/splits/SMM4H_Task2 \n| Dataset                                                                                                                           | Total                                                 | Positive                                        | Negative                                              | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8154590633371204
      ],
      "excerpt": "| SMM4H Task 1 (AE Detection)<br /> <br /> Train (80%) <br /> Validation (10%) <br /> Test (10%)                                    | 15,482 <br /> <br /> 12,386 <br /> 1,548 <br /> 1,548 | 1,339 <br /> <br /> 1,071 <br /> 134 <br /> 134 | 14,143 <br /> <br /> 11,315 <br /> 1,414 <br /> 1,414 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.932494145655716,
        0.8761283009744154
      ],
      "excerpt": "Dataset Splits: /src/data/splits/CADEC \n| Dataset                                                                                                                           | Total                                         | Positive                                      | Negative                                 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8631752332057389
      ],
      "excerpt": "| SMM4H Task 1 (AE Detection, AE Extraction and Drug Extraction)<br /> <br /> Train (70%) <br /> Validation (15%) <br /> Test (15%) | 1,250 <br /> <br /> 875 <br /> 187 <br /> 188 | 1,105 <br /> <br /> 779 <br /> 163 <br /> 163 | 145 <br /> <br /> 96 <br /> 24 <br /> 25 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8761283009744154
      ],
      "excerpt": "| Dataset                                                                                                    | Total                                                 | Positive                                            | Negative                                              | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8178142395090153
      ],
      "excerpt": "| ADE Corpus v2 (AE Detection)<br /> <br /> Train (60%) <br /> Validation (20%) <br /> Test (20%)            | 23,516 <br /> <br /> 14,109 <br /> 4,703 <br /> 4,704 | 6,821 <br /> <br /> 4,091 <br /> 1,365 <br /> 1,365 | 16,695 <br /> <br /> 10,018 <br /> 3,338 <br /> 3,339 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.846039884546491
      ],
      "excerpt": "| ADE Corpus v2 (Drug Extraction) <br /> <br/> Train (60%) <br /> Validation (20%) <br /> Test (20%)         | 7,100  <br /> <br /> 4,260 <br /> 1,420 <br /> 1,420  | 7,100 <br /> <br /> 4,260 <br /> 1,420 <br /> 1,420 | -                                                     | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8761283009744154
      ],
      "excerpt": "| Dataset                                                            | Total  | Positive | Negative | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8761283009744154
      ],
      "excerpt": "| Dataset                                                            | Total  | Positive | Negative | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/shivamraval98/MultiTask-T5_AE/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Shivam Raval\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "MultiTask-T5_AE :book:",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "MultiTask-T5_AE",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "shivamraval98",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/shivamraval98/MultiTask-T5_AE/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\ncd ae-detect\npip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\n#:Train Models\npython train_baseline.py\n#:Evaluate Models\npython eval_baseline.py\n```\n More details of the parameters that can be changed are mentioned in the train_baseline.py.\n \n ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": " ```python\n #: Single Task T5 Model\n python t5_train.py\n \n #:Multi-Task T5 Model\n python t5_multi_task_train.py\n\n#:T5 Evaluation\npython t5_eval.py\n ```\nThere are couple of options for running the multi-task setting which are described in the script. The T5 model can be trained on Task Balancing (TB) or Task plus Dataset Balancing (TDB) approach for Proportional Mixing (PM) or Temperature Scaling (TS) strategies. For evaluation, the test set and the trained model path information can be changed in t5_eval.py script.\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Sun, 26 Dec 2021 03:01:45 GMT"
    },
    "technique": "GitHub API"
  }
}
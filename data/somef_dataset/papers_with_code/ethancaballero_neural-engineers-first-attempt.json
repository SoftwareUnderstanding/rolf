{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[Barronalex](https://github.com/barronalex/Dynamic-Memory-Networks-in-TensorFlow)'s and [Therne](https://github.com/therne/dmn-tensorflow)'s tf-DMN+s,\n\n[Alexander Johansen's seq2seq modules](https://github.com/alrojo/tensorflow-tutorial/blob/master/lab3_RNN/tf_utils.py#L11),\n\nJon Gauthier's [RML attempt](https://github.com/hans/ipython-notebooks/blob/master/Reward-augmented%20maximum%20likelihood%20learning%20for%20autoencoders.ipynb) & [policy gradient module](https://github.com/hans/thinstack-rl/blob/master/reinforce.py#L25)\n\nMarkNeumann's [adapative attention module](https://github.com/DeNeutoy/act-rte-inference/blob/master/AdaptiveIAAModel.py#L197-L247)\n\nand seqGANs [policy gradient modules](https://github.com/LantaoYu/SeqGAN/blob/master/generator.py#L105-L113).\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1706.03762\n\n-Use a Differentiable Programming Language as decribed in \"Differentiable Functional Program Interpreters\" https://arxiv.org/abs/1611.01988 so that you can scrap all score/value estimators from RL and just get the exact gradient of the reward with respect to the parameters\n\n-Hindsight Experience Replay https://arxiv.org/abs/1707.01495\n\n-unsupervisedly pretrain the encoder & decoder\n\n-better/bigger data such as maybe the 150370 docstring2code pairs from https://github.com/EdinburghNLP/code-docstring-corpus or the 17000 programming challenge description2code pairs (original was just 7000",
      "https://arxiv.org/abs/1611.01988 so that you can scrap all score/value estimators from RL and just get the exact gradient of the reward with respect to the parameters\n\n-Hindsight Experience Replay https://arxiv.org/abs/1707.01495\n\n-unsupervisedly pretrain the encoder & decoder\n\n-better/bigger data such as maybe the 150370 docstring2code pairs from https://github.com/EdinburghNLP/code-docstring-corpus or the 17000 programming challenge description2code pairs (original was just 7000",
      "https://arxiv.org/abs/1707.01495\n\n-unsupervisedly pretrain the encoder & decoder\n\n-better/bigger data such as maybe the 150370 docstring2code pairs from https://github.com/EdinburghNLP/code-docstring-corpus or the 17000 programming challenge description2code pairs (original was just 7000"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9944484218006108
      ],
      "excerpt": "-Hindsight Experience Replay https://arxiv.org/abs/1707.01495 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ethancaballero/neural-engineers-first-attempt",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-09-04T22:12:56Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-12-03T11:45:17Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.970559844934006,
        0.8840061284064856
      ],
      "excerpt": "NE implementation in TensorFlow for learning to engineer. \nThis model is a decription2code task baseline (rnn-based seq2seq with AST decoder & adaptive number of attention hops per decode step) (with two stage SL then RL training) that yielded underwhelming results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8365433238270057
      ],
      "excerpt": "| dmn_plus.py | contains the DMN+ model | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8650101873701009
      ],
      "excerpt": "outputs always overfit to simplistic incorrect answers such as:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8715945169890352
      ],
      "excerpt": "Interestingly, model learned dynamic adaptation of number attention hops (per each decode step) that seems to correlate with complexity of each decode step: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.844938620058394
      ],
      "excerpt": "The two lines are aligned below for visualization purposes: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.846359818268815
      ],
      "excerpt": "-Use a Differentiable Programming Language as decribed in \"Differentiable Functional Program Interpreters\" https://arxiv.org/abs/1611.01988 so that you can scrap all score/value estimators from RL and just get the exact gradient of the reward with respect to the parameters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "first attempt at description2code from 2016",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ethancaballero/neural-engineers-first-attempt/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Sun, 26 Dec 2021 08:43:16 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ethancaballero/neural-engineers-first-attempt/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ethancaballero/neural-engineers-first-attempt",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ethancaballero/neural-engineers-first-attempt/master/get_data.sh",
      "https://raw.githubusercontent.com/ethancaballero/neural-engineers-first-attempt/master/load_d2c_data/tokenize_desc2code.sh"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8177238437001959,
        0.8534552821161705,
        0.9054678461072408
      ],
      "excerpt": "| dmn_plus.py | contains the DMN+ model | \n| dmn_train.py | trains the model on a specified task| \n| dmn_test.py | tests the model on a specified task | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936606094659785
      ],
      "excerpt": "a=raw_input(); print(2-a) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8005439077139056
      ],
      "excerpt": "values in 2nd line are output of each decode step. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8058999077906702
      ],
      "excerpt": "num of attn hops per dec step: array([ 1., 1., 6.,          1., 2., 1., 3.,       6., 2., 7.,  2.,  3.]) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ethancaballero/neural-engineers-first-attempt/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License (MIT)\\n\\nCopyright (c) 2016 Neural-Engineer Team  (Ethan Caballero, Yad Faeq, Andy Zhang, & Alex Skidanov)\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Neural Engineers TF",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "neural-engineers-first-attempt",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ethancaballero",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ethancaballero/neural-engineers-first-attempt/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. The full problems dataset can be downloaded and pre-processed can be generated through:\n\n```\n  sh get_data.sh\n```\n\nTo tweak for new directories:\n\n2. The root directories can be set for the coding problems in `yads_data_loader.py` :\n\n```\n  rootdir1 = './description2code_current/codeforces_delete'\n  rootdir2 = './description2code_current/hackerearth/problems_college'\n  rootdir3 = './description2code_current/hackerearth/problems_normal'\n```\n\n3. Then tweak these parameters per needed experiment:\n\n```\nquestions_count = 3000\nanswers_count = 50\nmax_len_words = 800\nregular_desc = True\n```\n4. to run the model:\n\n```\n python dmn_train.py\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Sun, 26 Dec 2021 08:43:16 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "attention",
      "seq2seq",
      "policy-gradient",
      "tensorflow",
      "adaptive-computation-time"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. The full problems dataset can be downloaded and pre-processed can be generated through:\n\n```\n  sh get_data.sh\n```\n\nTo tweak for new directories:\n\n2. The root directories can be set for the coding problems in `yads_data_loader.py` :\n\n```\n  rootdir1 = './description2code_current/codeforces_delete'\n  rootdir2 = './description2code_current/hackerearth/problems_college'\n  rootdir3 = './description2code_current/hackerearth/problems_normal'\n```\n\n3. Then tweak these parameters per needed experiment:\n\n```\nquestions_count = 3000\nanswers_count = 50\nmax_len_words = 800\nregular_desc = True\n```\n4. to run the model:\n\n```\n python dmn_train.py\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
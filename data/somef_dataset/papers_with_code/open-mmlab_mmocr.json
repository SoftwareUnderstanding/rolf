{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "MMOCR is an open-source project that is contributed by researchers and engineers from various colleges and companies. We appreciate all the contributors who implement their methods or add new features, as well as users who give valuable feedbacks.\nWe hope the toolbox and benchmark could serve the growing research community by providing a flexible toolkit to reimplement existing methods and develop their own new OCR methods.\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2108.06543"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this project useful in your research, please consider cite:\n\n```bibtex\n@article{mmocr2021,\n    title={MMOCR:  A Comprehensive Toolbox for Text Detection, Recognition and Understanding},\n    author={Kuang, Zhanghui and Sun, Hongbin and Li, Zhizhong and Yue, Xiaoyu and Lin, Tsui Hin and Chen, Jianyong and Wei, Huaqiang and Zhu, Yiqin and Gao, Tong and Zhang, Wenwei and Chen, Kai and Zhang, Wayne and Lin, Dahua},\n    journal= {arXiv preprint arXiv:2108.06543},\n    year={2021}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "cff-version: 1.2.0\nmessage: \"If you use this software, please cite it as below.\"\ntitle: \"OpenMMLab Text Detection, Recognition and Understanding Toolbox\"\nauthors:\n  - name: \"MMOCR Contributors\"\nversion: 0.3.0\ndate-released: 2020-08-15\nrepository-code: \"https://github.com/open-mmlab/mmocr\"\nlicense: Apache-2.0",
      "technique": "File Exploration"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{mmocr2021,\n    title={MMOCR:  A Comprehensive Toolbox for Text Detection, Recognition and Understanding},\n    author={Kuang, Zhanghui and Sun, Hongbin and Li, Zhizhong and Yue, Xiaoyu and Lin, Tsui Hin and Chen, Jianyong and Wei, Huaqiang and Zhu, Yiqin and Gao, Tong and Zhang, Wenwei and Chen, Kai and Zhang, Wayne and Lin, Dahua},\n    journal= {arXiv preprint arXiv:2108.06543},\n    year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8444342525991423,
        0.8184658499669879,
        0.9782759268835692,
        0.9868512987915664,
        0.9884759456492003,
        0.8944178096468923,
        0.8944178096468923
      ],
      "excerpt": "- [x] [DBNet](configs/textdet/dbnet/README.md) (AAAI'2020) \n- [x] [Mask R-CNN](configs/textdet/maskrcnn/README.md) (ICCV'2017) \n- [x] [PANet](configs/textdet/panet/README.md) (ICCV'2019) \n- [x] [PSENet](configs/textdet/psenet/README.md) (CVPR'2019) \n- [x] [TextSnake](configs/textdet/textsnake/README.md) (ECCV'2018) \n- [x] [DRRG](configs/textdet/drrg/README.md) (CVPR'2020) \n- [x] [FCENet](configs/textdet/fcenet/README.md) (CVPR'2021) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.959546310417776,
        0.8944178096468923,
        0.9104388306336967,
        0.9222383658450612,
        0.9104388306336967,
        0.9677640385174676,
        0.959314148796126
      ],
      "excerpt": "<summary>Text Recognition</summary> \n- [x] [ABINet](configs/textrecog/abinet/README.md) (CVPR'2021) \n- [x] [CRNN](configs/textrecog/crnn/README.md) (TPAMI'2016) \n- [x] [NRTR](configs/textrecog/nrtr/README.md) (ICDAR'2019) \n- [x] [RobustScanner](configs/textrecog/robust_scanner/README.md) (ECCV'2020) \n- [x] [SAR](configs/textrecog/sar/README.md) (AAAI'2019) \n- [x] [SATRN](configs/textrecog/satrn/README.md) (CVPR'2020 Workshop on Text and Documents in the Deep Learning Era) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8305495299082459,
        0.9490753289412834
      ],
      "excerpt": "<summary>Key Information Extraction</summary> \n- [x] [SDMG-R](configs/kie/sdmgr/README.md) (ArXiv'2021) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.959546310417776,
        0.9222383658450612
      ],
      "excerpt": "<summary>Named Entity Recognition</summary> \n- [x] [Bert-Softmax](configs/ner/bert_softmax/README.md) (NAACL'2019) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9485358500871338
      ],
      "excerpt": "MMCV: OpenMMLab foundational library for computer vision. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9829315454255052
      ],
      "excerpt": "MMDetection3D: OpenMMLab's next-generation platform for general 3D object detection. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.910226687696363,
        0.9530038435323631,
        0.9712620773557584
      ],
      "excerpt": "MMAction2: OpenMMLab's next-generation action understanding toolbox and benchmark. \nMMPose: OpenMMLab's pose estimation toolbox and benchmark. \nMMTracking: OpenMMLab video perception toolbox and benchmark. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9887678291751212
      ],
      "excerpt": "MMOCR: A Comprehensive Toolbox for Text Detection, Recognition and Understanding. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/open-mmlab/mmocr/main/code_of_conduct.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/open-mmlab/mmocr",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to mmocr\nAll kinds of contributions are welcome, including but not limited to the following.\n\nFixes (typo, bugs)\nNew features and components\n\nContents\n\nWorkflow\nMain Steps\nDetailed Steps\nStep 1: Create a Fork\nStep 2: Develop a new feature\nStep 2.1: Keep your fork up to date\nStep 2.2: Create a feature branch\n\n\nStep 3: Commit your changes\nStep 4: Prepare to Pull Request\nStep 4.1: Merge official repo updates to your fork\nStep 4.2: Push <your_feature_branch> branch to your remote forked repo,\nStep 4.3: Create a Pull Request\nStep 4.4: Review code\nStep 4.5: Revise <your_feature_branch>  (optional)\nStep 4.6: Delete <your_feature_branch> branch if your PR is accepted.\n\n\n\n\n\n\nCode style\nPython\nC++ and CUDA\n\n\n\nWorkflow\nMain Steps\n\nfork and pull the latest mmocr\ncheckout a new branch (do not use main branch for PRs)\ncommit your changes\ncreate a PR\n\nNote\n- If you plan to add some new features that involve large changes, it is encouraged to open an issue for discussion first.\n- If you are the author of some papers and would like to include your method to mmocr, please let us know (open an issue or contact the maintainers). We will much appreciate your contribution.\n- For new features and new modules, unit tests are required to improve the code's robustness.\nDetailed Steps\nThe official public repository holds only one branch with an infinite lifetime: main\nThe main branch is the main branch where the source code of HEAD always reflects a state with the latest development changes for the next release.\nFeature branches are used to develop new features for the upcoming or a distant future release.\nAll new developers to MMOCR need to follow the following steps:\nStep 1: Create a Fork\n\n\nFork the repo on GitHub or GitLab to your personal account. Click the Fork button on the project page.\n\n\nClone your new forked repo to your computer.\ngit clone https://github.com/&lt;your name&gt;/mmocr.git\n\nAdd the official repo as an upstream:\ngit remote add upstream https://github.com/open-mmlab/mmocr.git\n\nStep 2: Develop a new feature\nStep 2.1: Keep your fork up to date\nWhenever you want to update your fork with the latest upstream changes, you need to fetch the upstream repo's branches and latest commits to bring them into your repository:\n```\nFetch from upstream remote\ngit fetch upstream\nUpdate your main branch\ngit checkout main\ngit rebase upstream/main\ngit push origin main\n```\nStep 2.2: Create a feature branch\n\n\nCreate an issue on github\n\n\nCreate a feature branch\n\ngit checkout -b feature/iss_&lt;index&gt; main\n  # index is the issue index on github above\n\nStep 3: Commit your changes\nDevelop your new feature and test it to make sure it works well, then commit.\nPlease run\npre-commit run --all-files\npytest tests\nand fix all failures before every git commit.\ngit commit -m \"fix #&lt;issue_index&gt;: &lt;commit_message&gt;\"\nStep 4: Prepare to Pull Request\n\nMake sure to link your pull request to the related issue. Please refer to the instructon\n\nStep 4.1: Merge official repo updates to your fork\n```\nfetch from upstream remote. i.e., the official repo\ngit fetch upstream\nupdate the main branch of your fork\ngit checkout main\ngit rebase upstream/main\ngit push origin main\nupdate the <your_feature_branch> branch\ngit checkout <your_feature_branch>\ngit rebase main\nsolve conflicts if any and Test\n```\nStep 4.2: Push <your_feature_branch> branch to your remote forked repo,\ngit checkout &lt;your_feature_branch&gt;\ngit push origin &lt;your_feature_branch&gt;\nStep 4.3: Create a Pull Request\nGo to the page for your fork on GitHub, select your new feature branch, and click the pull request button to integrate your feature branch into the upstream remote\u2019s develop branch.\nStep 4.4: Review code\nStep 4.5: Revise <your_feature_branch>  (optional)\nIf PR is not accepted, pls follow steps above till your PR is accepted.\nStep 4.6: Delete <your_feature_branch> branch if your PR is accepted.\ngit branch -d &lt;your_feature_branch&gt;\ngit push origin :&lt;your_feature_branch&gt;\nCode style\nPython\nWe adopt PEP8 as the preferred code style.\nWe use the following tools for linting and formatting:\n\nflake8: linter\nyapf: formatter\nisort: sort imports\n\nStyle configurations of yapf and isort can be found in setup.cfg.\nWe use pre-commit hook that checks and formats for flake8, yapf, isort, trailing whitespaces,\n fixes end-of-files, sorts requirments.txt automatically on every commit.\nThe config for a pre-commit hook is stored in .pre-commit-config.\nAfter you clone the repository, you will need to install initialize pre-commit hook.\nshell\npip install -U pre-commit\nFrom the repository folder\nshell\npre-commit install\nIf you are facing issue when installing markdown lint, you may install ruby for markdown lint by following\n```shell\ninstall rvm\ncurl -L https://get.rvm.io | bash -s -- --autolibs=read-fail\nset up environment\nNote that you might need to edit ~/.bashrc, ~/.bash_profile.\nrvm autolibs disable\ninstall ruby\nrvm install 2.7.1\n```\nAfter this on every commit check code linters and formatter will be enforced.\n\nBefore you create a PR, make sure that your code lints and is formatted by yapf.\n\nC++ and CUDA\nWe follow the Google C++ Style Guide.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-07T13:40:21Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-27T15:49:06Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "English | [\u7b80\u4f53\u4e2d\u6587](README_zh-CN.md)\n\n[![build](https://github.com/open-mmlab/mmocr/workflows/build/badge.svg)](https://github.com/open-mmlab/mmocr/actions)\n[![docs](https://readthedocs.org/projects/mmocr/badge/?version=latest)](https://mmocr.readthedocs.io/en/latest/?badge=latest)\n[![codecov](https://codecov.io/gh/open-mmlab/mmocr/branch/main/graph/badge.svg)](https://codecov.io/gh/open-mmlab/mmocr)\n[![license](https://img.shields.io/github/license/open-mmlab/mmocr.svg)](https://github.com/open-mmlab/mmocr/blob/main/LICENSE)\n[![PyPI](https://badge.fury.io/py/mmocr.svg)](https://pypi.org/project/mmocr/)\n[![Average time to resolve an issue](https://isitmaintained.com/badge/resolution/open-mmlab/mmocr.svg)](https://github.com/open-mmlab/mmocr/issues)\n[![Percentage of issues still open](https://isitmaintained.com/badge/open/open-mmlab/mmocr.svg)](https://github.com/open-mmlab/mmocr/issues)\n\nMMOCR is an open-source toolbox based on PyTorch and mmdetection for text detection, text recognition, and the corresponding downstream tasks including key information extraction. It is part of the [OpenMMLab](https://openmmlab.com/) project.\n\nThe main branch works with **PyTorch 1.6+**.\n\nDocumentation: https://mmocr.readthedocs.io/en/latest/.\n\n<div align=\"left\">\n  <img src=\"resources/illustration.jpg\"/>\n</div>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8938820878726396
      ],
      "excerpt": "The toolbox supports not only text detection and text recognition, but also their downstream tasks such as key information extraction. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9537694382241939
      ],
      "excerpt": "The toolbox supports a wide variety of state-of-the-art models for text detection, text recognition and key information extraction. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9949004642916136
      ],
      "excerpt": "The modular design of MMOCR enables users to define their own optimizers, data preprocessors, and model components such as backbones, necks and heads as well as losses. Please refer to Getting Started for how to construct a customized model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9967967946876679
      ],
      "excerpt": "The toolbox provides a comprehensive set of utilities which can help users assess the performance of models. It includes visualizers which allow visualization of images, ground truths as well as predicted bounding boxes, and a validation tool for evaluating checkpoints during training.  It also includes data converters to demonstrate how to convert your own data to the annotation files which the toolbox supports. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8574071360030013
      ],
      "excerpt": "- [x] [SATRN](configs/textrecog/satrn/README.md) (CVPR'2020 Workshop on Text and Documents in the Deep Learning Era) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9532481375967841
      ],
      "excerpt": "Please refer to model_zoo for more details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9452847062966504
      ],
      "excerpt": "We appreciate all contributions to improve MMOCR. Please refer to CONTRIBUTING.md for the contributing guidelines. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "OpenMMLab Text Detection, Recognition and Understanding Toolbox",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://mmocr.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/open-mmlab/mmocr/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 320,
      "date": "Mon, 27 Dec 2021 20:42:48 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/open-mmlab/mmocr/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "open-mmlab/mmocr",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/open-mmlab/mmocr/main/docker/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/open-mmlab/mmocr/tree/main/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/open-mmlab/mmocr/main/demo/MMOCR_Tutorial.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/open-mmlab/mmocr/main/tools/slurm_train.sh",
      "https://raw.githubusercontent.com/open-mmlab/mmocr/main/tools/slurm_test.sh",
      "https://raw.githubusercontent.com/open-mmlab/mmocr/main/tools/dist_test.sh",
      "https://raw.githubusercontent.com/open-mmlab/mmocr/main/tools/dist_train.sh",
      "https://raw.githubusercontent.com/open-mmlab/mmocr/main/docs/zh_cn/merge_docs.sh",
      "https://raw.githubusercontent.com/open-mmlab/mmocr/main/docs/zh_cn/cp_origin_docs.sh",
      "https://raw.githubusercontent.com/open-mmlab/mmocr/main/docs/en/merge_docs.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please refer to our [Install Guide](https://mmocr.readthedocs.io/en/latest/install.html).\n\n",
      "technique": "Header extraction"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/open-mmlab/mmocr/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Apache License 2.0",
      "url": "https://api.github.com/licenses/apache-2.0"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Copyright (c) MMOCR Authors. All rights reserved.\\n\\n                                 Apache License\\n                           Version 2.0, January 2004\\n                        http://www.apache.org/licenses/\\n\\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\\n\\n   1. Definitions.\\n\\n      \"License\" shall mean the terms and conditions for use, reproduction,\\n      and distribution as defined by Sections 1 through 9 of this document.\\n\\n      \"Licensor\" shall mean the copyright owner or entity authorized by\\n      the copyright owner that is granting the License.\\n\\n      \"Legal Entity\" shall mean the union of the acting entity and all\\n      other entities that control, are controlled by, or are under common\\n      control with that entity. For the purposes of this definition,\\n      \"control\" means (i) the power, direct or indirect, to cause the\\n      direction or management of such entity, whether by contract or\\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\\n      outstanding shares, or (iii) beneficial ownership of such entity.\\n\\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\\n      exercising permissions granted by this License.\\n\\n      \"Source\" form shall mean the preferred form for making modifications,\\n      including but not limited to software source code, documentation\\n      source, and configuration files.\\n\\n      \"Object\" form shall mean any form resulting from mechanical\\n      transformation or translation of a Source form, including but\\n      not limited to compiled object code, generated documentation,\\n      and conversions to other media types.\\n\\n      \"Work\" shall mean the work of authorship, whether in Source or\\n      Object form, made available under the License, as indicated by a\\n      copyright notice that is included in or attached to the work\\n      (an example is provided in the Appendix below).\\n\\n      \"Derivative Works\" shall mean any work, whether in Source or Object\\n      form, that is based on (or derived from) the Work and for which the\\n      editorial revisions, annotations, elaborations, or other modifications\\n      represent, as a whole, an original work of authorship. For the purposes\\n      of this License, Derivative Works shall not include works that remain\\n      separable from, or merely link (or bind by name) to the interfaces of,\\n      the Work and Derivative Works thereof.\\n\\n      \"Contribution\" shall mean any work of authorship, including\\n      the original version of the Work and any modifications or additions\\n      to that Work or Derivative Works thereof, that is intentionally\\n      submitted to Licensor for inclusion in the Work by the copyright owner\\n      or by an individual or Legal Entity authorized to submit on behalf of\\n      the copyright owner. For the purposes of this definition, \"submitted\"\\n      means any form of electronic, verbal, or written communication sent\\n      to the Licensor or its representatives, including but not limited to\\n      communication on electronic mailing lists, source code control systems,\\n      and issue tracking systems that are managed by, or on behalf of, the\\n      Licensor for the purpose of discussing and improving the Work, but\\n      excluding communication that is conspicuously marked or otherwise\\n      designated in writing by the copyright owner as \"Not a Contribution.\"\\n\\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\\n      on behalf of whom a Contribution has been received by Licensor and\\n      subsequently incorporated within the Work.\\n\\n   2. Grant of Copyright License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      copyright license to reproduce, prepare Derivative Works of,\\n      publicly display, publicly perform, sublicense, and distribute the\\n      Work and such Derivative Works in Source or Object form.\\n\\n   3. Grant of Patent License. Subject to the terms and conditions of\\n      this License, each Contributor hereby grants to You a perpetual,\\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\\n      (except as stated in this section) patent license to make, have made,\\n      use, offer to sell, sell, import, and otherwise transfer the Work,\\n      where such license applies only to those patent claims licensable\\n      by such Contributor that are necessarily infringed by their\\n      Contribution(s) alone or by combination of their Contribution(s)\\n      with the Work to which such Contribution(s) was submitted. If You\\n      institute patent litigation against any entity (including a\\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\\n      or a Contribution incorporated within the Work constitutes direct\\n      or contributory patent infringement, then any patent licenses\\n      granted to You under this License for that Work shall terminate\\n      as of the date such litigation is filed.\\n\\n   4. Redistribution. You may reproduce and distribute copies of the\\n      Work or Derivative Works thereof in any medium, with or without\\n      modifications, and in Source or Object form, provided that You\\n      meet the following conditions:\\n\\n      (a) You must give any other recipients of the Work or\\n          Derivative Works a copy of this License; and\\n\\n      (b) You must cause any modified files to carry prominent notices\\n          stating that You changed the files; and\\n\\n      (c) You must retain, in the Source form of any Derivative Works\\n          that You distribute, all copyright, patent, trademark, and\\n          attribution notices from the Source form of the Work,\\n          excluding those notices that do not pertain to any part of\\n          the Derivative Works; and\\n\\n      (d) If the Work includes a \"NOTICE\" text file as part of its\\n          distribution, then any Derivative Works that You distribute must\\n          include a readable copy of the attribution notices contained\\n          within such NOTICE file, excluding those notices that do not\\n          pertain to any part of the Derivative Works, in at least one\\n          of the following places: within a NOTICE text file distributed\\n          as part of the Derivative Works; within the Source form or\\n          documentation, if provided along with the Derivative Works; or,\\n          within a display generated by the Derivative Works, if and\\n          wherever such third-party notices normally appear. The contents\\n          of the NOTICE file are for informational purposes only and\\n          do not modify the License. You may add Your own attribution\\n          notices within Derivative Works that You distribute, alongside\\n          or as an addendum to the NOTICE text from the Work, provided\\n          that such additional attribution notices cannot be construed\\n          as modifying the License.\\n\\n      You may add Your own copyright statement to Your modifications and\\n      may provide additional or different license terms and conditions\\n      for use, reproduction, or distribution of Your modifications, or\\n      for any such Derivative Works as a whole, provided Your use,\\n      reproduction, and distribution of the Work otherwise complies with\\n      the conditions stated in this License.\\n\\n   5. Submission of Contributions. Unless You explicitly state otherwise,\\n      any Contribution intentionally submitted for inclusion in the Work\\n      by You to the Licensor shall be under the terms and conditions of\\n      this License, without any additional terms or conditions.\\n      Notwithstanding the above, nothing herein shall supersede or modify\\n      the terms of any separate license agreement you may have executed\\n      with Licensor regarding such Contributions.\\n\\n   6. Trademarks. This License does not grant permission to use the trade\\n      names, trademarks, service marks, or product names of the Licensor,\\n      except as required for reasonable and customary use in describing the\\n      origin of the Work and reproducing the content of the NOTICE file.\\n\\n   7. Disclaimer of Warranty. Unless required by applicable law or\\n      agreed to in writing, Licensor provides the Work (and each\\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\\n      implied, including, without limitation, any warranties or conditions\\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\\n      PARTICULAR PURPOSE. You are solely responsible for determining the\\n      appropriateness of using or redistributing the Work and assume any\\n      risks associated with Your exercise of permissions under this License.\\n\\n   8. Limitation of Liability. In no event and under no legal theory,\\n      whether in tort (including negligence), contract, or otherwise,\\n      unless required by applicable law (such as deliberate and grossly\\n      negligent acts) or agreed to in writing, shall any Contributor be\\n      liable to You for damages, including any direct, indirect, special,\\n      incidental, or consequential damages of any character arising as a\\n      result of this License or out of the use or inability to use the\\n      Work (including but not limited to damages for loss of goodwill,\\n      work stoppage, computer failure or malfunction, or any and all\\n      other commercial damages or losses), even if such Contributor\\n      has been advised of the possibility of such damages.\\n\\n   9. Accepting Warranty or Additional Liability. While redistributing\\n      the Work or Derivative Works thereof, You may choose to offer,\\n      and charge a fee for, acceptance of support, warranty, indemnity,\\n      or other liability obligations and/or rights consistent with this\\n      License. However, in accepting such obligations, You may act only\\n      on Your own behalf and on Your sole responsibility, not on behalf\\n      of any other Contributor, and only if You agree to indemnify,\\n      defend, and hold each Contributor harmless for any liability\\n      incurred by, or claims asserted against, such Contributor by reason\\n      of your accepting any such warranty or additional liability.\\n\\n   END OF TERMS AND CONDITIONS\\n\\n   APPENDIX: How to apply the Apache License to your work.\\n\\n      To apply the Apache License to your work, attach the following\\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\\n      replaced with your own identifying information. (Don\\'t include\\n      the brackets!)  The text should be enclosed in the appropriate\\n      comment syntax for the file format. We also recommend that a\\n      file or class name and description of purpose be included on the\\n      same \"printed page\" as the copyright notice for easier\\n      identification within third-party archives.\\n\\n   Copyright 2021 MMOCR Authors. All rights reserved.\\n\\n   Licensed under the Apache License, Version 2.0 (the \"License\");\\n   you may not use this file except in compliance with the License.\\n   You may obtain a copy of the License at\\n\\n       http://www.apache.org/licenses/LICENSE-2.0\\n\\n   Unless required by applicable law or agreed to in writing, software\\n   distributed under the License is distributed on an \"AS IS\" BASIS,\\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n   See the License for the specific language governing permissions and\\n   limitations under the License.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Introduction",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "mmocr",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "open-mmlab",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/open-mmlab/mmocr/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "gaotongxiao",
        "body": "## Highlights\r\n\r\n1. We release a new text recognition model - [ABINet](https://arxiv.org/pdf/2103.06495.pdf) (CVPR 2021, Oral). With dedicated model design and useful data augmentation transforms, ABINet achieves the best performance on irregular text recognition tasks. [Check it out!](https://mmocr.readthedocs.io/en/latest/textrecog_models.html#read-like-humans-autonomous-bidirectional-and-iterative-language-modeling-for-scene-text-recognition)\r\n2. We are also working hard to fulfill the requests from our community. [OpenSet KIE](https://mmocr.readthedocs.io/en/latest/kie_models.html#wildreceiptopenset) is one of the achievements, which extends the application of SDMGR from text node classification to node-pair relation extraction. We also provide a demo script to convert WildReceipt to open set domain, though it may not take full advantage of the OpenSet format. For more information, read our [tutorial](https://mmocr.readthedocs.io/en/latest/tutorials/kie_closeset_openset.html).\r\n3. APIs of models can be exposed through TorchServe. [Docs](https://mmocr.readthedocs.io/en/latest/model_serving.html)\r\n\r\n## Breaking Changes & Migration Guide\r\n\r\n### Postprocessor\r\n\r\nSome refactoring processes are still going on. For all text detection models, we unified their `decode` implementations into a new module category, `POSTPROCESSOR`, which is responsible for decoding different raw outputs into boundary instances. In all text detection configs, the `text_repr_type` argument in `bbox_head` is deprecated and will be removed in the future release.\r\n\r\n**Migration Guide**: Find a similar line from detection model's config:\r\n```\r\ntext_repr_type=xxx,\r\n```\r\nAnd replace it with\r\n```\r\npostprocessor=dict(type='{MODEL_NAME}Postprocessor', text_repr_type=xxx)),\r\n```\r\nTake a snippet of PANet's config as an example. Before the change, its config for `bbox_head` looks like:\r\n```\r\n    bbox_head=dict(\r\n        type='PANHead',\r\n        text_repr_type='poly',\r\n        in_channels=[128, 128, 128, 128],\r\n        out_channels=6,\r\n        loss=dict(type='PANLoss')),\r\n```\r\nAfterwards:\r\n```\r\n    bbox_head=dict(\r\n    type='PANHead',\r\n    in_channels=[128, 128, 128, 128],\r\n    out_channels=6,\r\n    loss=dict(type='PANLoss'),\r\n    postprocessor=dict(type='PANPostprocessor', text_repr_type='poly')),\r\n```\r\nThere are other postprocessors and each takes different arguments. Interested users can find their interfaces or implementations in `mmocr/models/textdet/postprocess` or through our [api docs](https://mmocr.readthedocs.io/en/latest/api.html#textdet-postprocess).\r\n\r\n### New Config Structure\r\n\r\nWe reorganized the `configs/` directory by extracting reusable sections into `configs/_base_`. Now the directory tree of `configs/_base_` is organized as follows:\r\n\r\n```\r\n_base_\r\n\u251c\u2500\u2500 det_datasets\r\n\u251c\u2500\u2500 det_models\r\n\u251c\u2500\u2500 det_pipelines\r\n\u251c\u2500\u2500 recog_datasets\r\n\u251c\u2500\u2500 recog_models\r\n\u251c\u2500\u2500 recog_pipelines\r\n\u2514\u2500\u2500 schedules\r\n```\r\n\r\nMost of model configs are making full use of base configs now, which makes the overall structural clearer and facilitates fair comparison across models. Despite the seemingly significant hierarchical difference, **these changes would not break the backward compatibility** as the names of model configs remain the same.\r\n\r\n## New Features\r\n* Support openset kie by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/498\r\n* Add converter for the Open Images v5 text annotations by Krylov et al. by @baudm in https://github.com/open-mmlab/mmocr/pull/497\r\n* Support Chinese for kie show result by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/464\r\n* Add TorchServe support for text detection and recognition by @Harold-lkk in https://github.com/open-mmlab/mmocr/pull/522\r\n* Save filename in text detection test results by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/570\r\n* Add codespell pre-commit hook and fix typos by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/520\r\n* Avoid duplicate placeholder docs in CN by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/582\r\n* Save results to json file for kie. by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/589\r\n* Add SAR_CN to ocr.py by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/579\r\n* mim extension for windows by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/641\r\n* Support muitiple pipelines for different datasets by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/657\r\n* ABINet Framework by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/651\r\n\r\n## Refactoring\r\n* Refactor textrecog config structure by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/617\r\n* Refactor text detection config by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/626\r\n* refactor transformer modules by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/618\r\n* refactor textdet postprocess by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/640\r\n\r\n## Docs\r\n* C++ example section by @apiaccess21 in https://github.com/open-mmlab/mmocr/pull/593\r\n* install.md Chinese section by @A465539338 in https://github.com/open-mmlab/mmocr/pull/364\r\n* Add Chinese Translation of deployment.md. by @fatfishZhao in https://github.com/open-mmlab/mmocr/pull/506\r\n* Fix a model link and add the metafile for SATRN by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/473\r\n* Improve docs style by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/474\r\n* Enhancement & sync Chinese docs by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/492\r\n* TorchServe docs by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/539\r\n* Update docs menu by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/564\r\n* Docs for KIE CloseSet & OpenSet by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/573\r\n* Fix broken links by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/576\r\n* Docstring for text recognition models by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/562\r\n* Add MMFlow & MIM by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/597\r\n* Add MMFewShot by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/621\r\n* Update model readme by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/604\r\n* Add input size check to model_inference by @mpena-vina in https://github.com/open-mmlab/mmocr/pull/633\r\n* Docstring for textdet models by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/561\r\n* Add MMHuman3D in readme by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/644\r\n* Use shared menu from theme instead by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/655\r\n* Refactor docs structure by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/662\r\n* Docs fix by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/664\r\n\r\n## Enhancements\r\n* Use bounding box around polygon instead of within polygon by @alexander-soare in https://github.com/open-mmlab/mmocr/pull/469\r\n* Add CITATION.cff by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/476\r\n* Add py3.9 CI by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/475\r\n* update model-index.yml by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/484\r\n* Use container in CI by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/502\r\n* CircleCI Setup by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/611\r\n* Remove unnecessary custom_import from train.py by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/603\r\n* Change the upper version of mmcv to 1.5.0 by @zhouzaida in https://github.com/open-mmlab/mmocr/pull/628\r\n* Update CircleCI by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/631\r\n* Pass custom_hooks to MMCV by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/609\r\n* Skip CI when some specific files were changed by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/642\r\n* Add markdown linter in pre-commit hook by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/643\r\n* Use shape from loaded image by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/652\r\n* Cancel previous runs that are not completed by @Harold-lkk in https://github.com/open-mmlab/mmocr/pull/666\r\n\r\n## Bug Fixes\r\n* Modify algorithm \"sar\" weights path in metafile by @ShoupingShan in https://github.com/open-mmlab/mmocr/pull/581\r\n* Fix Cuda CI by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/472\r\n* Fix image export in test.py for KIE models by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/486\r\n* Allow invalid polygons in intersection and union by default  by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/471\r\n* Update checkpoints' links for SATRN by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/518\r\n* Fix converting to onnx bug because of changing key from img_shape to resize_shape by @Harold-lkk in https://github.com/open-mmlab/mmocr/pull/523\r\n* Fix PyTorch 1.6 incompatible checkpoints by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/540\r\n* Fix paper field in metafiles by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/550\r\n* Unify recognition task names in metafiles by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/548\r\n* Fix py3.9 CI by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/563\r\n* Always map location to cpu when loading checkpoint by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/567\r\n* Fix wrong model builder in recog_test_imgs by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/574\r\n* Improve dbnet r50 by fixing img std by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/578\r\n* Fix resource warning: unclosed file by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/577\r\n* Fix bug that same start_point for different texts in draw_texts_by_pil by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/587\r\n* Keep original texts for kie by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/588\r\n* Fix random seed by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/600\r\n* Fix DBNet_r50 config by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/625\r\n* Change SBC case to DBC case by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/632\r\n* Fix kie demo by @innerlee in https://github.com/open-mmlab/mmocr/pull/610\r\n* fix type check by @cuhk-hbsun in https://github.com/open-mmlab/mmocr/pull/650\r\n* Remove depreciated image validator in totaltext converter by @gaotongxiao in https://github.com/open-mmlab/mmocr/pull/661\r\n* Fix change locals() dict by @Fei-Wang in https://github.com/open-mmlab/mmocr/pull/663\r\n* fix #614: textsnake targets by @HolyCrap96 in https://github.com/open-mmlab/mmocr/pull/660\r\n\r\n## New Contributors\r\n* @alexander-soare made their first contribution in https://github.com/open-mmlab/mmocr/pull/469\r\n* @A465539338 made their first contribution in https://github.com/open-mmlab/mmocr/pull/364\r\n* @fatfishZhao made their first contribution in https://github.com/open-mmlab/mmocr/pull/506\r\n* @baudm made their first contribution in https://github.com/open-mmlab/mmocr/pull/497\r\n* @ShoupingShan made their first contribution in https://github.com/open-mmlab/mmocr/pull/581\r\n* @apiaccess21 made their first contribution in https://github.com/open-mmlab/mmocr/pull/593\r\n* @zhouzaida made their first contribution in https://github.com/open-mmlab/mmocr/pull/628\r\n* @mpena-vina made their first contribution in https://github.com/open-mmlab/mmocr/pull/633\r\n* @Fei-Wang made their first contribution in https://github.com/open-mmlab/mmocr/pull/663\r\n\r\n**Full Changelog**: https://github.com/open-mmlab/mmocr/compare/v0.3.0...v0.4.0",
        "dateCreated": "2021-12-15T03:34:56Z",
        "datePublished": "2021-12-15T03:40:06Z",
        "html_url": "https://github.com/open-mmlab/mmocr/releases/tag/v0.4.0",
        "name": "MMOCR Release v0.4.0",
        "tag_name": "v0.4.0",
        "tarball_url": "https://api.github.com/repos/open-mmlab/mmocr/tarball/v0.4.0",
        "url": "https://api.github.com/repos/open-mmlab/mmocr/releases/55331456",
        "zipball_url": "https://api.github.com/repos/open-mmlab/mmocr/zipball/v0.4.0"
      },
      {
        "authorType": "User",
        "author_name": "gaotongxiao",
        "body": "## Highlights\r\n1. We add a new text recognition model -- SATRN! Its pretrained checkpoint achieves the best performance over other provided text recognition models. A lighter version of SATRN is also released which can obtain ~98% of the performance of the original model with only 45 MB in size. (@2793145003) #405\r\n2. Improve the demo script, `ocr.py`, which supports applying end-to-end text detection, text recognition and key information extraction models on images with easy-to-use commands. Users can find its full documentation in the demo section. (@samayala22, @manjrekarom) #371, #386, #400, #374, #428\r\n3. Our documentation is reorganized into a clearer structure. More useful contents are on the way! #409, #454\r\n4. The requirement of `Polygon3` is removed since this project is no longer maintained or distributed. We unified all its references to equivalent substitutions in `shapely` instead. #448\r\n\r\n## Breaking Changes & Migration Guide\r\n1. Upgrade version requirement of MMDetection to 2.14.0 to avoid bugs #382\r\n2. MMOCR now has its own model and layer registries inherited from MMDetection's or MMCV's counterparts. (#436) The modified hierarchical structure of the model registries are now organized as follows.\r\n```text\r\nmmcv.MODELS -> mmdet.BACKBONES -> BACKBONES\r\nmmcv.MODELS -> mmdet.NECKS -> NECKS\r\nmmcv.MODELS -> mmdet.ROI_EXTRACTORS -> ROI_EXTRACTORS\r\nmmcv.MODELS -> mmdet.HEADS -> HEADS\r\nmmcv.MODELS -> mmdet.LOSSES -> LOSSES\r\nmmcv.MODELS -> mmdet.DETECTORS -> DETECTORS\r\nmmcv.ACTIVATION_LAYERS -> ACTIVATION_LAYERS\r\nmmcv.UPSAMPLE_LAYERS -> UPSAMPLE_LAYERS\r\n````\r\nTo migrate your old implementation to our new backend, you need to change the import path of any registries and their corresponding builder functions (including `build_detectors`) from `mmdet.models.builder` to `mmocr.models.builder`. If you have referred to any model or layer of MMDetection or MMCV in your model config, you need to add `mmdet.` or `mmcv.` prefix to its name to inform the model builder of the right namespace to work on.\r\n\r\nInterested users may check out [MMCV's tutorial on Registry](https://mmcv.readthedocs.io/en/latest/understand_mmcv/registry.html) for in-depth explanations on its mechanism.\r\n \r\n## New Features\r\n- Automatically replace SyncBN with BN for inference #420, #453\r\n- Support batch inference for CRNN and SegOCR #407\r\n- Support exporting documentation in pdf or epub format #406\r\n- Support `persistent_workers` option in data loader #459\r\n\r\n## Bug Fixes\r\n- Remove depreciated key in kie_test_imgs.py #381\r\n- Fix dimension mismatch in batch testing/inference of DBNet #383\r\n- Fix the problem of dice loss which stays at 1 with an empty target given #408\r\n- Fix a wrong link in ocr.py (@naarkhoo) #417\r\n- Fix undesired assignment to \"pretrained\" in test.py #418\r\n- Fix a problem in polygon generation of DBNet #421, #443\r\n- Skip invalid annotations in totaltext_converter #438\r\n- Add zero division handler in poly utils, remove Polygon3 #448\r\n\r\n## Improvements\r\n- Replace lanms-proper with lanms-neo to support installation on Windows (with special thanks to @gen-ko who has re-distributed this package!)\r\n- Support MIM #394\r\n- Add tests for PyTorch 1.9 in CI #401\r\n- Enables fullscreen layout in readthedocs #413\r\n- General documentation enhancement #395\r\n- Update version checker #427\r\n- Add copyright info #439\r\n- Update citation information #440\r\n\r\n## Contributors\r\nWe thank @2793145003, @samayala22, @manjrekarom, @naarkhoo, @gen-ko, @duanjiaqi, @gaotongxiao, @cuhk-hbsun, @innerlee, @wdsd641417025 for their contribution to this release!",
        "dateCreated": "2021-08-25T08:43:31Z",
        "datePublished": "2021-08-25T08:52:47Z",
        "html_url": "https://github.com/open-mmlab/mmocr/releases/tag/v0.3.0",
        "name": "MMOCR Release v0.3.0",
        "tag_name": "v0.3.0",
        "tarball_url": "https://api.github.com/repos/open-mmlab/mmocr/tarball/v0.3.0",
        "url": "https://api.github.com/repos/open-mmlab/mmocr/releases/48411740",
        "zipball_url": "https://api.github.com/repos/open-mmlab/mmocr/zipball/v0.3.0"
      },
      {
        "authorType": "User",
        "author_name": "gaotongxiao",
        "body": "**Highlights**\r\n1. Upgrade to use MMCV-full **>= 1.3.8** and MMDetection **>= 2.13.0** for latest features\r\n2. Add ONNX and TensorRT export tool, supporting the deployment of DBNet, PSENet, PANet and CRNN (experimental) [#278](https://github.com/open-mmlab/mmocr/pull/278), [#291](https://github.com/open-mmlab/mmocr/pull/291), [#300](https://github.com/open-mmlab/mmocr/pull/300), [#328](https://github.com/open-mmlab/mmocr/pull/328)\r\n3. Unified parameter initialization method which uses init_cfg in config files [#365](https://github.com/open-mmlab/mmocr/pull/365)\r\n\r\n**New Features**\r\n\r\n- Support TextOCR dataset [#293](https://github.com/open-mmlab/mmocr/pull/293)\r\n- Support Total-Text dataset [#266](https://github.com/open-mmlab/mmocr/pull/266), [#273](https://github.com/open-mmlab/mmocr/pull/273), [#357](https://github.com/open-mmlab/mmocr/pull/357)\r\n- Support grouping text detection box into lines [#290](https://github.com/open-mmlab/mmocr/pull/290), [#304](https://github.com/open-mmlab/mmocr/pull/304)\r\n- Add benchmark_processing script that benchmarks data loading process [#261](https://github.com/open-mmlab/mmocr/pull/261)\r\n- Add SynthText preprocessor for text recognition models [#351](https://github.com/open-mmlab/mmocr/pull/351), [#361](https://github.com/open-mmlab/mmocr/pull/361)\r\n- Support batch inference during testing [#310](https://github.com/open-mmlab/mmocr/pull/310)\r\n- Add user-friendly OCR inference script [#366](https://github.com/open-mmlab/mmocr/pull/366)\r\n\r\n**Bug Fixes**\r\n\r\n- Fix improper class ignorance in SDMGR Loss [#221](https://github.com/open-mmlab/mmocr/pull/221)\r\n- Fix potential numerical zero division error in DRRG [#224](https://github.com/open-mmlab/mmocr/pull/224)\r\n- Fix installing requirements with pip and mim [#242](https://github.com/open-mmlab/mmocr/pull/242)\r\n- Fix dynamic input error of DBNet [#269](https://github.com/open-mmlab/mmocr/pull/269)\r\n- Fix space parsing error in LineStrParser [#285](https://github.com/open-mmlab/mmocr/pull/285)\r\n- Fix textsnake decode error [#264](https://github.com/open-mmlab/mmocr/pull/264)\r\n- Correct isort setup [#288](https://github.com/open-mmlab/mmocr/pull/288)\r\n- Fix a bug in SDMGR config [#316](https://github.com/open-mmlab/mmocr/pull/316)\r\n- Fix kie_test_img for KIE nonvisual [#319](https://github.com/open-mmlab/mmocr/pull/319)\r\n- Fix metafiles [#342](https://github.com/open-mmlab/mmocr/pull/342)\r\n- Fix different device problem in FCENet [#334](https://github.com/open-mmlab/mmocr/pull/334)\r\n- Ignore improper tailing empty characters in annotation files [#358](https://github.com/open-mmlab/mmocr/pull/358)\r\n- Docs fixes [#247](https://github.com/open-mmlab/mmocr/pull/247), [#255](https://github.com/open-mmlab/mmocr/pull/255), [#265](https://github.com/open-mmlab/mmocr/pull/265), [#267](https://github.com/open-mmlab/mmocr/pull/267), [#268](https://github.com/open-mmlab/mmocr/pull/268), [#270](https://github.com/open-mmlab/mmocr/pull/270), [#276](https://github.com/open-mmlab/mmocr/pull/276), [#287](https://github.com/open-mmlab/mmocr/pull/287), [#330](https://github.com/open-mmlab/mmocr/pull/330), [#355](https://github.com/open-mmlab/mmocr/pull/355), [#367](https://github.com/open-mmlab/mmocr/pull/367)\r\n- Fix NRTR config [#356](https://github.com/open-mmlab/mmocr/pull/356), [#370](https://github.com/open-mmlab/mmocr/pull/370)\r\n\r\n**Improvements**\r\n\r\n- Add backend for resizeocr [#244](https://github.com/open-mmlab/mmocr/pull/244)\r\n- Skip image processing pipelines in SDMGR novisual [#260](https://github.com/open-mmlab/mmocr/pull/260)\r\n- Speedup DBNet [#263](https://github.com/open-mmlab/mmocr/pull/263)\r\n- Update mmcv installation method in workflow [#323](https://github.com/open-mmlab/mmocr/pull/323)\r\n- Add part of Chinese documentations [#353](https://github.com/open-mmlab/mmocr/pull/353), [#362](https://github.com/open-mmlab/mmocr/pull/362)\r\n- Add support for ConcatDataset with two workflows [#348](https://github.com/open-mmlab/mmocr/pull/348)\r\n- Add list_from_file and list_to_file utils [#226](https://github.com/open-mmlab/mmocr/pull/226)\r\n- Speed up sort_vertex [#239](https://github.com/open-mmlab/mmocr/pull/239)\r\n- Support distributed evaluation of KIE [#234](https://github.com/open-mmlab/mmocr/pull/234)\r\n- Add pretrained FCENet on IC15 [#258](https://github.com/open-mmlab/mmocr/pull/258)\r\n- Support CPU for OCR demo [#227](https://github.com/open-mmlab/mmocr/pull/227)\r\n- Avoid extra image pre-processing steps [#375](https://github.com/open-mmlab/mmocr/pull/375)",
        "dateCreated": "2021-07-20T15:19:07Z",
        "datePublished": "2021-07-20T15:30:41Z",
        "html_url": "https://github.com/open-mmlab/mmocr/releases/tag/v0.2.1",
        "name": "MMOCR Release v0.2.1",
        "tag_name": "v0.2.1",
        "tarball_url": "https://api.github.com/repos/open-mmlab/mmocr/tarball/v0.2.1",
        "url": "https://api.github.com/repos/open-mmlab/mmocr/releases/46483159",
        "zipball_url": "https://api.github.com/repos/open-mmlab/mmocr/zipball/v0.2.1"
      },
      {
        "authorType": "User",
        "author_name": "cuhk-hbsun",
        "body": "**Highlights**\r\n\r\n1. Add the NER approach Bert-softmax (NAACL'2019)\r\n2. Add the text detection method DRRG (CVPR'2020)\r\n3. Add the text detection method FCENet (CVPR'2021)\r\n4. Increase the ease of use via adding text detection and recognition end-to-end demo, and colab online demo.\r\n5. Simplify the installation.\r\n\r\n**New Features**\r\n\r\n- Add Bert-softmax for Ner task [#148](https://github.com/open-mmlab/mmocr/pull/148)\r\n- Add DRRG [#189](https://github.com/open-mmlab/mmocr/pull/189)\r\n- Add FCENet [#133](https://github.com/open-mmlab/mmocr/pull/133)\r\n- Add end-to-end demo [#105](https://github.com/open-mmlab/mmocr/pull/105)\r\n- Support batch inference [#86](https://github.com/open-mmlab/mmocr/pull/86) [#87](https://github.com/open-mmlab/mmocr/pull/87) [#178](https://github.com/open-mmlab/mmocr/pull/178)\r\n- Add TPS preprocessor for text recognition [#117](https://github.com/open-mmlab/mmocr/pull/117) [#135](https://github.com/open-mmlab/mmocr/pull/135)\r\n- Add demo documentation [#151](https://github.com/open-mmlab/mmocr/pull/151) [#166](https://github.com/open-mmlab/mmocr/pull/166) [#168](https://github.com/open-mmlab/mmocr/pull/168) [#170](https://github.com/open-mmlab/mmocr/pull/170) [#171](https://github.com/open-mmlab/mmocr/pull/171)\r\n- Add checkpoint for Chinese recognition [#156](https://github.com/open-mmlab/mmocr/pull/156)\r\n- Add metafile [#175](https://github.com/open-mmlab/mmocr/pull/175) [#176](https://github.com/open-mmlab/mmocr/pull/176) [#177](https://github.com/open-mmlab/mmocr/pull/177) [#182](https://github.com/open-mmlab/mmocr/pull/182) [#183](https://github.com/open-mmlab/mmocr/pull/183)\r\n- Add support for numpy array inference [#74](https://github.com/open-mmlab/mmocr/pull/74)\r\n\r\n**Bug Fixes**\r\n\r\n- Fix the duplicated point bug due to transform for textsnake [#130](https://github.com/open-mmlab/mmocr/pull/130)\r\n- Fix CTC loss NaN [#159](https://github.com/open-mmlab/mmocr/pull/159)\r\n- Fix error raised if result is empty in demo [#144](https://github.com/open-mmlab/mmocr/pull/141)\r\n- Fix results missing if one image has a large number of boxes [#98](https://github.com/open-mmlab/mmocr/pull/98)\r\n- Fix package missing in dockerfile [#109](https://github.com/open-mmlab/mmocr/pull/109)\r\n\r\n**Improvements**\r\n\r\n- Simplify installation procedure via removing compiling [#188](https://github.com/open-mmlab/mmocr/pull/188)\r\n- Speed up panet post processing so that it can detect dense texts [#188](https://github.com/open-mmlab/mmocr/pull/188)\r\n- Add zh-CN README [#70](https://github.com/open-mmlab/mmocr/pull/70) [#95](https://github.com/open-mmlab/mmocr/pull/95)\r\n- Support windows [#89](https://github.com/open-mmlab/mmocr/pull/89)\r\n- Add Colab [#147](https://github.com/open-mmlab/mmocr/pull/147) [#199](https://github.com/open-mmlab/mmocr/pull/199)\r\n- Add 1-step installation using conda environment [#193](https://github.com/open-mmlab/mmocr/pull/193) [#194](https://github.com/open-mmlab/mmocr/pull/194) [#195](https://github.com/open-mmlab/mmocr/pull/195)",
        "dateCreated": "2021-05-18T14:58:21Z",
        "datePublished": "2021-05-18T15:24:28Z",
        "html_url": "https://github.com/open-mmlab/mmocr/releases/tag/v0.2.0",
        "name": "MMOCR Release v0.2.0",
        "tag_name": "v0.2.0",
        "tarball_url": "https://api.github.com/repos/open-mmlab/mmocr/tarball/v0.2.0",
        "url": "https://api.github.com/repos/open-mmlab/mmocr/releases/43149683",
        "zipball_url": "https://api.github.com/repos/open-mmlab/mmocr/zipball/v0.2.0"
      },
      {
        "authorType": "User",
        "author_name": "jeffreykuang",
        "body": "**Main Features**\r\n\r\n- Support text detection, text recognition and the corresponding downstream tasks such as key information extraction.\r\n- For text detection, support both single-step (`PSENet`, `PANet`, `DBNet`, `TextSnake`) and two-step (`MaskRCNN`) methods.\r\n- For text recognition, support CTC-loss based method `CRNN`; Encoder-decoder (with attention) based methods `SAR`, `Robustscanner`; Segmentation based method `SegOCR`; Transformer based method `NRTR`.\r\n- For key information extraction, support GCN based method `SDMG-R`.\r\n- Provide checkpoints and log files for all of the methods above.",
        "dateCreated": "2021-04-13T13:59:19Z",
        "datePublished": "2021-04-13T14:05:20Z",
        "html_url": "https://github.com/open-mmlab/mmocr/releases/tag/v0.1.0",
        "name": "MMOCR Release v0.1.0",
        "tag_name": "v0.1.0",
        "tarball_url": "https://api.github.com/repos/open-mmlab/mmocr/tarball/v0.1.0",
        "url": "https://api.github.com/repos/open-mmlab/mmocr/releases/41357031",
        "zipball_url": "https://api.github.com/repos/open-mmlab/mmocr/zipball/v0.1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1935,
      "date": "Mon, 27 Dec 2021 20:42:48 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "pytorch",
      "ocr",
      "deep-learning",
      "text-detection",
      "text-recognition",
      "sar",
      "psenet",
      "panet",
      "maskrcnn",
      "key-information-extraction",
      "pan",
      "dbnet",
      "sdmg-r",
      "textsnake",
      "crnn",
      "robustscanner",
      "segmentation-based-text-recognition",
      "fcenet",
      "satrn",
      "abinet"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please see [Getting Started](https://mmocr.readthedocs.io/en/latest/getting_started.html) for the basic usage of MMOCR.\n\n",
      "technique": "Header extraction"
    }
  ]
}
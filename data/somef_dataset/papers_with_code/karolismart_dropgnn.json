{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2111.06283",
      "https://arxiv.org/abs/1810.00826"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@InProceedings{papp2021dropgnn,\n  title={DropGNN: Random Dropouts Increase the Expressiveness of Graph Neural Networks}, \n  author={Papp, P{\\'a}l Andr{\\'a}s and Martinkus, Karolis and Faber, Lukas and Wattenhofer, Roger}, \n  booktitle={35th Conference on Neural Information Processing Systems (NeurIPS)},\n  year={2021}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KarolisMart/DropGNN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-26T19:45:06Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-19T16:48:05Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9965380618844079
      ],
      "excerpt": "This is the official implementation of DropGNN: Random Dropouts Increase the Expressiveness of Graph Neural Networks \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9804852151347202
      ],
      "excerpt": "Synthetic datasets and the GIN model with the corresponding augmentations is implemented in gin-synthetic.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8402670155892594
      ],
      "excerpt": "DropGNN model version (dropout augmentation) should be run with --use_aux_loss flag, for other augmentations this option is ignored. For SkipCircles (skipcircles) dataset we use --num_layers 9 flag with all augmentations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594813099188733
      ],
      "excerpt": "To perform the grid search as done in the orginal GIN paper add --grid_search option. To run the grid search on SLURM cluster using GPUs use --slurm and --gpu_jobs options. The code is currently setup for grid search on the bio datasets. To run grid search on social IMDB datasets as described in the paper (with fixed number of hidden units) set tunable=False for the hidden_units option on line 323. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/karolismart/dropgnn/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 30 Dec 2021 09:10:58 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/KarolisMart/DropGNN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "KarolisMart/DropGNN",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8016543880121839
      ],
      "excerpt": "The number of runs and dropout probability ablations can be run using the following commands: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.978202922284948
      ],
      "excerpt": "You can run the DropGNN experiments using the following commands: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8510463369722493
      ],
      "excerpt": "python gin-synthetic.py --augmentation 'dropout' --use_aux_loss --dataset 'lcc' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8510463369722493,
        0.8510463369722493
      ],
      "excerpt": "python gin-synthetic.py --augmentation 'dropout' --use_aux_loss --dataset 'limitsone' --num_runs_ablation \npython gin-synthetic.py --augmentation 'dropout' --use_aux_loss --dataset 'limitsone' --prob_ablation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.921108411272225,
        0.8397241399011908
      ],
      "excerpt": "python gin-graph_classification.py --drop_gnn --use_aux_loss --dataset 'MUTAG' \nTo perform the grid search as done in the orginal GIN paper add --grid_search option. To run the grid search on SLURM cluster using GPUs use --slurm and --gpu_jobs options. The code is currently setup for grid search on the bio datasets. To run grid search on social IMDB datasets as described in the paper (with fixed number of hidden units) set tunable=False for the hidden_units option on line 323. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8396245022425406,
        0.8396245022425406
      ],
      "excerpt": "python mpnn-qm9.py --drop_gnn --aux_loss --target 0 \npython 1-gnn-qm9.py --drop_gnn --aux_loss --target 0 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/KarolisMart/DropGNN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "DropGNN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DropGNN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "KarolisMart",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KarolisMart/DropGNN/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The implementation uses Python (3.8), PyTorch (1.9) and PyTorch Geometric (1.7).\nYou can create a conda environment with all of the required packages:  \n`conda env create -f environment.yml`  \n`conda activate DropGNN`\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Each experiment and base model are in an individual Python file and can be run individaully from the command line.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 9,
      "date": "Thu, 30 Dec 2021 09:10:58 GMT"
    },
    "technique": "GitHub API"
  }
}
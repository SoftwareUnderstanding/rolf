{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AlexIoannides/lime-interpretable-ml",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-02-05T22:22:47Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-02-13T23:11:05Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9830803283734485,
        0.9882241249287862,
        0.9268216879067434
      ],
      "excerpt": "We have often found that Machine Learning (ML) algorithms capable of capturing structural non-linearities in training data - models that are sometimes referred to as 'black box' (e.g. Random Forests, Deep Neural Networks, etc.) - perform far better at prediction than their linear counterparts (e.g. Generalised Linear Models). They are, however, much harder to interpret - in fact, quite often it is not possible to gain any insight into why a particular prediction has been produced, when given an instance of input data (i.e. the model features). Consequently, it has not been possible to use 'black box' ML algorithms in situations where clients have sought cause-and-effect explanations for model predictions, with end-results being that sub-optimal predictive models have been used in their place, as their explanatory power has been more valuable, in relative terms. \nThis repository contains an example project for an alternative approach - we train a 'black box' ML model to the best of our abilities and then apply an ancillary algorithm to generate explanations for the predictions. More specifically, we will test the ability of the Local Interpretable Model-agnostic Explanations (LIME) algorithm, recently described by Ribiero et al (2016), to provide explanations for a Random Forest regressor trained on multiple-lot on-line auction data. \nFor reference, the paper that describes the LIME algorithm can be found here: https://arxiv.org/pdf/1602.04938v1.pdf (a version is also included as part of this repository); details of its implementation in Python (as used in this notebook), can be found here: https://github.com/marcotcr/lime/; while a more general discussion of ML algorithm interpretation (that includes LIME), can be found in the eBook by Christoph Molnar, which can be found here: https://christophm.github.io/interpretable-ml-book/. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "An example of how the LIME algorithm can be used to provide real-world insight into the decision processes of a 'black-box' machine learning algorithm - in this case a Radom Forest regressor.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AlexIoannides/lime-interpretable-ml/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Mon, 27 Dec 2021 08:36:59 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/AlexIoannides/lime-interpretable-ml/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "AlexIoannides/lime-interpretable-ml",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/AlexIoannides/lime-interpretable-ml/master/LIME-regression-example.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Make sure that you're in the project's root directory (the same one in which the `Pipfile` resides), and then run,\n\n```bash\npipenv install --dev\n```\n\nThis will install all of the direct project dependencies as well as the development dependencies (the latter a consequence of the `--dev` flag).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "To get started with Pipenv, first of all download it - assuming that there is a global version of Python available on your system and on the PATH, then this can be achieved by running the following command,\n\n```bash\npip3 install pipenv\n```\n\nPipenv is also available to install from many non-Python package managers. For example, on OS X it can be installed using the [Homebrew](https://brew.sh) package manager, with the following terminal command,\n\n```bash\nbrew install pipenv\n```\n\nFor more information, including advanced configuration options, see the [official pipenv documentation](https://docs.pipenv.org).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8277239364138216
      ],
      "excerpt": "Prepending pipenv to every command you want to run within the context of your Pipenv-managed virtual environment, can get very tedious. This can be avoided by entering into a Pipenv-managed shell, \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/AlexIoannides/lime-interpretable-ml/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Interpreting Machine Learning Algorithms with LIME",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "lime-interpretable-ml",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "AlexIoannides",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AlexIoannides/lime-interpretable-ml/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We use [pipenv](https://docs.pipenv.org) for managing project dependencies and Python environments (i.e. virtual environments). All of the direct packages dependencies required to run the code (e.g. NumPy for arrays/tensors and Pandas for DataFrames), as well as all the packages used during development (e.g. IPython and JupyterLab as the chosen development environment), are described in the `Pipfile`. Their **precise** downstream dependencies are described in `Pipfile.lock`.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Make sure that you're in the project's root directory (the same one in which the `Pipfile` resides), and then run,\n\n```bash\npipenv install --dev\n```\n\nThis will install all of the direct project dependencies as well as the development dependencies (the latter a consequence of the `--dev` flag).\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "In order to continue development in a Python environment that precisely mimics the one the project was initially developed with, use Pipenv from the command line as follows,\n\n```bash\npipenv run python3\n```\n\nThe `python3` command could just as well be `ipython3` or the JupterLab, for example,\n\n```bash\npipenv run jupyter lab\n```\n\nThis will fire-up JupyterLab *where the default Python 3 kernel includes all of the direct and development project dependencies*. This is how we advise that the notebooks within this project are used.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 10,
      "date": "Mon, 27 Dec 2021 08:36:59 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "lime",
      "python",
      "scikit-learn",
      "machine-learning",
      "data-science",
      "pydata",
      "numpy",
      "pandas",
      "interpretability"
    ],
    "technique": "GitHub API"
  }
}
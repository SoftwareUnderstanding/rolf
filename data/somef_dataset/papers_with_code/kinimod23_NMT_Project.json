{
  "citation": [
    {
      "confidence": [
        0.9277083556744742,
        0.8727076911040745
      ],
      "excerpt": "preprocessing steps and hyperparameter settings http://www.aclweb.org/anthology/Q15-1016 \nWMT 2017 Translation Task http://www.statmt.org/wmt17/translation-task.html \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490817347094297
      ],
      "excerpt": "finish, smooth and polish seminar paper \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8842332779824053
      ],
      "excerpt": "Literature survey on Research Questions \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kinimod23/NMT_Project",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-12-16T13:55:55Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-08T13:15:51Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8556377648551956
      ],
      "excerpt": "Clone this repository in the desired place: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8647595766844339
      ],
      "excerpt": "Preprocess the data used: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.801618847738906
      ],
      "excerpt": "Doing a recheck if the initially used vectors of the sockeye-nmt-system are actually conform with the pre-trained vectors (and not Zero as being the usual \"sockeye way\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8406738318612182
      ],
      "excerpt": "[2] on local machine \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8140975807714469
      ],
      "excerpt": "finish, smooth and polish seminar paper \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9215786330237629
      ],
      "excerpt": "sockeye NMT model trained with glove embeddings on the wmt'17 corpus \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.977266478556226,
        0.9935314617540053
      ],
      "excerpt": "for all there are still some challenges to overcome except of glove \nwritten Expos\u00e9 with goals of this project \n",
      "technique": "Supervised classification"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    bash signi_env.sh\n\nExecute significance test with:\\\n<sub>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;arg1 = *give a name for the model*\\\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;arg2 = gold standard\\\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;arg3 = translated test sentences of System 1\\\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;arg4 = translated test sentences of System 2\n</sub>\n\n    bash signi_test.sh basel.sglove test.gold.de test.transl.basel.de test.transl.small.glove.de\n\n    bash signi_test.sh basel.lglove test.gold.de test.transl.basel.de test.transl.large.glove.de\n\n----------------------------------------------------------------------------------------------\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kinimod23/NMT_Project/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To categorise distinct approaches (character/word/sentence/thought input) for generating word embeddings.\nBy using a translation task (from English to German), it's clear to see which approach performs best.\n\nResearch Questions:\na) Which is the best lexical input (character, word, sentence, thought) to generate language representations for a translation task?\nb) Which is the best Language Model (bi-directional, one-directional, etc.) to use for generating language representations applied to a translation task?\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Natural language Representations (NLRs) might ignore key features of distributional semantics! A new NLR model is typically evaluated across several tasks, and is considered an improvement if it achieves better accuracy than its predecessors. However, different applications rely on different aspects of word embeddings, and good performance in one application does not necessarily imply equally good performance on another.\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 10:18:28 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kinimod23/NMT_Project/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "kinimod23/NMT_Project",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/Signifikanztests/signi_env.sh",
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/Signifikanztests/signi_test.sh",
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/NLR_pre-training/glove/glove_small.training.sh",
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/NLR_pre-training/glove/glove_large.training.sh",
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/NMT_environment/shell_scripts/sockeye_wmt_env.sh",
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/NMT_environment/shell_scripts/sockeye_wmt_train_small.prembs.sh",
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/NMT_environment/shell_scripts/sockeye_wmt_create.large.embs.sh",
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/NMT_environment/shell_scripts/sockeye_wmt_prep.sh",
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/NMT_environment/shell_scripts/sockeye_wmt_eval.sh",
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/NMT_environment/shell_scripts/sockeye_wmt_prembs.recheck.sh",
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/NMT_environment/shell_scripts/sockeye_wmt_prep_add.data.sh",
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/NMT_environment/shell_scripts/sockeye_wmt_train_basel.sh",
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/NMT_environment/shell_scripts/sockeye_wmt_train_large.prembs.sh",
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/NMT_environment/shell_scripts/sockeye_wmt_create.small.embs.sh",
      "https://raw.githubusercontent.com/kinimod23/NMT_Project/master/NMT_environment/tools/recheck_embs.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9893272198983933,
        0.9906248903846466,
        0.8629920167409489,
        0.9465718491881494
      ],
      "excerpt": "git clone https://github.com/kinimod23/NMT_Project.git \ncd ~/NMT_Project/NMT_environment/shell_scripts \nSet up the NMT environment: \nbash sockeye_wmt_env.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9465718491881494
      ],
      "excerpt": "bash sockeye_wmt_prep.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8066134127892272
      ],
      "excerpt": "cd ~/NMT_Project/NLR_pre-training/glove \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8075004293796461,
        0.8331493469675801,
        0.925194063462346
      ],
      "excerpt": "git init . \ngit remote add -t \\* -f origin http://github.com/stanfordnlp/glove \ngit checkout master \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466,
        0.8039020633921791
      ],
      "excerpt": "cd ~/NMT_Project/NMT_environment/shell_scripts \nbash sockeye_wmt_create.small.embs.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9465718491881494
      ],
      "excerpt": "bash sockeye_wmt_train_basel.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9465718491881494
      ],
      "excerpt": "bash sockeye_wmt_train_small.prembs.sh model_wmt17_small.glove \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466,
        0.8740330539296483
      ],
      "excerpt": "cd ~/NMT_Project/NMT_environment/shell_scripts \nbash sockeye_wmt_create.large.embs.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9465718491881494
      ],
      "excerpt": "bash sockeye_wmt_train_large.prembs.sh model_wmt17_large.glove \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466,
        0.9465718491881494,
        0.9465718491881494,
        0.9465718491881494
      ],
      "excerpt": "cd ~/NMT_Project/NMT_environment/shell_scripts \nbash sockeye_wmt_eval.sh model_wmt17_basel \nbash sockeye_wmt_eval.sh model_wmt17_small.glove \nbash sockeye_wmt_eval.sh model_wmt17_large.glove \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9153016980352982,
        0.9153016980352982
      ],
      "excerpt": "bash sockeye_wmt_prembs.recheck.sh model_wmt17_small.glove &amp;&amp; exit \nbash sockeye_wmt_prembs.recheck.sh model_wmt17_large.glove &amp;&amp; exit \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.838313210285419,
        0.946456379888361,
        0.8316532510441815
      ],
      "excerpt": "mkdir ~/Desktop/recheck_embs \ncd ~/Desktop/recheck_embs \nwget https://raw.githubusercontent.com/kinimod23/NMT_Project/master/NMT_environment/tools/recheck_embs.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9465718491881494,
        0.9465718491881494
      ],
      "excerpt": "bash recheck_embs.sh model_wmt17_basel \nbash recheck_embs.sh model_wmt17_large.glove \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd ~/NMT_Project/Signifikanztests \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.807574999095134
      ],
      "excerpt": "Pre-train glove embeddings: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8466952431531092,
        0.8865522754288513,
        0.8239262043586657
      ],
      "excerpt": "Train glove embeddings with previously generated BPE training data: \nbash glove_small.training.sh ~/NMT_Project/NMT_environment/data/train.BPE.en \nbash glove_small.training.sh ~/NMT_Project/NMT_environment/data/train.BPE.de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8469366087605692,
        0.8021682612579353
      ],
      "excerpt": "bash glove_large.training.sh ~/NMT_Project/NMT_environment/data/pre-train_data/pre-train.BPE.en \nbash glove_large.training.sh ~/NMT_Project/NMT_environment/data/pre-train_data/pre-train.BPE.de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8086105100961638,
        0.8086105100961638
      ],
      "excerpt": "python recheck_cosines.py basel.src_init.txt best.basel.src_init.txt  \npython recheck_cosines.py basel.trg_init.txt best.basel.trg_init.txt \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kinimod23/NMT_Project/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Shell",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Neural Machine Translation Project Module",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "NMT_Project",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "kinimod23",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kinimod23/NMT_Project/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 10:18:28 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    cd ~/NMT_Project/NMT_environment/shell_scripts\n    bash sockeye_wmt_prep_add.data\n\nTrain glove embeddings with previously generated additional BPE training data:\n\n    cd ~/NMT_Project/NLR_pre-training/glove\n    ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "&nbsp;\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Natural language Representations (NLRs) might ignore key features of distributional semantics! A new NLR model is typically evaluated across several tasks, and is considered an improvement if it achieves better accuracy than its predecessors. However, different applications rely on different aspects of word embeddings, and good performance in one application does not necessarily imply equally good performance on another.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "WMT 2017 Translation Task http://data.statmt.org/wmt17/translation-task/preprocessed/de-en/\n\n------------------------------------------------------------------------------------------\n",
      "technique": "Header extraction"
    }
  ]
}
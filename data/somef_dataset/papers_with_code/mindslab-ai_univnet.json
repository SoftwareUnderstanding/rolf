{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2106.07889",
      "https://arxiv.org/abs/2106.07889",
      "https://arxiv.org/abs/2106.07889",
      "https://arxiv.org/abs/2102.10815",
      "https://arxiv.org/abs/2010.05646"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Papers\n\n- *Jang et al.*, [UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation](https://arxiv.org/abs/2106.07889)\n- *Zeng et al.*, [LVCNet: Efficient Condition-Dependent Modeling Network for Waveform Generation](https://arxiv.org/abs/2102.10815)\n- *Kong et al.*, [HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis](https://arxiv.org/abs/2010.05646)\n\nDatasets\n\n- [LibriTTS](https://openslr.org/60/)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8112878271991959
      ],
      "excerpt": "See audio samples at https://mindslab-ai.github.io/univnet/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9177057452649137
      ],
      "excerpt": "The orange and blue graphs indicate c16 and c32, respectively. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Kuan Chen \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mindslab-ai/univnet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-02T09:26:41Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-10T01:34:52Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9671890393950138
      ],
      "excerpt": "This is an unofficial PyTorch implementation of Jang et al. (Kakao), UnivNet. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.983361122248681
      ],
      "excerpt": "For both models, our implementation matches the objective scores (PESQ and RMSE) of the original paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9799791226183205,
        0.9645166594262982,
        0.9270463256050087
      ],
      "excerpt": "According to the authors of the paper, UnivNet obtained the best objective results among the recent GAN-based neural vocoders (including HiFi-GAN) as well as outperforming HiFi-GAN in a subjective evaluation. Also its inference speed is 1.5 times faster than HiFi-GAN. \nThis repository uses the same mel-spectrogram function as the Official HiFi-GAN, which is compatible with NVIDIA/tacotron2. \nOur default mel calculation hyperparameters are as below, following the original paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9017497372847478,
        0.8979411005071259
      ],
      "excerpt": "You can modify the hyperparameters to be compatible with your acoustic model. \nPreparing Data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9285410389826244
      ],
      "excerpt": "Since this model is a vocoder, the transcripts are NOT used during training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "  data: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8047721057242548
      ],
      "excerpt": "    val_dir: 'datasets/'        #: root path of validation data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8700012656833023
      ],
      "excerpt": "Modify channel_size in gen to switch between UnivNet-c16 and c32. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9550736187296571,
        0.8466471015589472
      ],
      "excerpt": "We evaluated our model with validation set. \n| Model                | PESQ(\u2191)   | RMSE(\u2193)   | Model Size | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9571345502582065
      ],
      "excerpt": "| Our UnivNet-c16  | 3.60  | 0.317 | 4.00M  | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8294866982543485,
        0.8373772002328652
      ],
      "excerpt": "| Our UnivNet-c32  | 3.68  | 0.304 | 14.87M | \nThe loss graphs of UnivNet are listed below. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "Special thanks to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Unofficial PyTorch Implementation of UnivNet Vocoder (https://arxiv.org/abs/2106.07889)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mindslab-ai/univnet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 13,
      "date": "Wed, 22 Dec 2021 11:18:07 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mindslab-ai/univnet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "mindslab-ai/univnet",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/mindslab-ai/univnet/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8139098950560248
      ],
      "excerpt": "LibriTTS train-clean-360 split tar.gz link \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8160826700677519
      ],
      "excerpt": "Following the format from NVIDIA/tacotron2, the metadata should be formatted as: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8975333695326541
      ],
      "excerpt": "<img src=\"docs/model_architecture.png\" width=\"100%\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8618850876971303
      ],
      "excerpt": "Unzip and place its contents under datasets/LibriTTS/train-clean-360. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8110122186248223
      ],
      "excerpt": "Note: The mel-spectrograms calculated from audio file will be saved as **.mel at first, and then loaded from disk afterwards. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8183889268910404
      ],
      "excerpt": "5% of the train-clean-360 utterances were randomly sampled for validation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8510822795984749
      ],
      "excerpt": "python trainer.py -c CONFIG_YAML_FILE -n NAME_OF_THE_RUN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8121665894611723
      ],
      "excerpt": "You can download the pre-trained models from the Google Drive link below. The models were trained on LibriTTS train-clean-360 split. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8830235457280963
      ],
      "excerpt": "<img src=\"docs/loss.png\" width=\"100%\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mindslab-ai/univnet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'BSD 3-Clause License\\n\\nCopyright (c) 2019, Seungwon Park \\xeb\\xb0\\x95\\xec\\x8a\\xb9\\xec\\x9b\\x90\\nAll rights reserved.\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions are met:\\n\\n1. Redistributions of source code must retain the above copyright notice, this\\n   list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright notice,\\n   this list of conditions and the following disclaimer in the documentation\\n   and/or other materials provided with the distribution.\\n\\n3. Neither the name of the copyright holder nor the names of its\\n   contributors may be used to endorse or promote products derived from\\n   this software without specific prior written permission.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "UnivNet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "univnet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "mindslab-ai",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mindslab-ai/univnet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The implementation needs following dependencies.\n\n0. Python 3.6\n1. [PyTorch](https://pytorch.org/) 1.6.0\n2. [NumPy](https://numpy.org/) 1.17.4 and [SciPy](https://www.scipy.org/) 1.5.4\n3. Install other dependencies in [requirements.txt](./requirements.txt).\n    ```bash\n    pip install -r requirements.txt\n    ```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 98,
      "date": "Wed, 22 Dec 2021 11:18:07 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "text-to-speech",
      "vocoder",
      "gan",
      "deep-learning",
      "pytorch",
      "tts",
      "speech-synthesis"
    ],
    "technique": "GitHub API"
  }
}
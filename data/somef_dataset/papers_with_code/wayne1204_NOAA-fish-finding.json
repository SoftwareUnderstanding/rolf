{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1506.01497\n\n[2] SSD: Single Shot MultiBox Detector: https://arxiv.org/abs/1512.02325\n\n[3] tf-faster-RCNN: https://github.com/endernewton/tf-faster-rcnn\n\n[4] ssd.pytorch: https://github.com/amdegroot/ssd.pytorch",
      "https://arxiv.org/abs/1512.02325\n\n[3] tf-faster-RCNN: https://github.com/endernewton/tf-faster-rcnn\n\n[4] ssd.pytorch: https://github.com/amdegroot/ssd.pytorch"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] Faster-RCNN: https://arxiv.org/abs/1506.01497\n\n[2] SSD: Single Shot MultiBox Detector: https://arxiv.org/abs/1512.02325\n\n[3] tf-faster-RCNN: https://github.com/endernewton/tf-faster-rcnn\n\n[4] ssd.pytorch: https://github.com/amdegroot/ssd.pytorch\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9986955473408947
      ],
      "excerpt": "Perform object detection technique like faster-RCNN and SSD to the 2018 CVPR workshop and challenge: Automated Analysis of Marine Video for Environmental Monitoring \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wayne1204/NOAA-fish-finding",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-08-29T04:26:09Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-07T06:59:23Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.879404401835238
      ],
      "excerpt": "<a href='#introduction'>Introduction</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8389728485897757
      ],
      "excerpt": "<a href='#prepare-data'>Prepare Data</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9671602672714507,
        0.8119541910778083,
        0.9167142324876368
      ],
      "excerpt": "This data challenge is a workshop in 2018 CVPR, with large amounts of image data have been collected and annotated by the National Oceanic and Atmospheric Administration (NOAA) from a a variety of image and video underwater. \nworkshop website \nThe data releases are comprised of images and annotations from five different data sources, with six datasets in total. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9487654586447688
      ],
      "excerpt": "Each dataset contains different lighting conditions, camera angles, and wildlife. The data released depends on the nature of the data in the entire dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8211393920255088
      ],
      "excerpt": "The annotations for scoring are bounding boxes around every animal, with a species classification label for each. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.965651939988263
      ],
      "excerpt": ": NET in {vgg16, res50, res101, res152} is the network arch to use \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "- for SSD 300/512 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8553911937548293,
        0.8979411005071259,
        0.8979411005071259
      ],
      "excerpt": "before testing, remember to remove cache of last predict \n$ rm data/cache/* \n$ rm data/VOCdevkit2007/annotations_cache/* \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.965651939988263
      ],
      "excerpt": ": NET in {vgg16, res50, res101, res152} is the network arch to use \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "for SSD 300/512 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Intern project at Institude of Information Science, Academia Sinica ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wayne1204/NOAA-fish-finding/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Thu, 23 Dec 2021 20:37:46 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/wayne1204/NOAA-fish-finding/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "wayne1204/NOAA-fish-finding",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/wayne1204/NOAA-fish-finding/master/experiments/scripts/convert_vgg16.sh",
      "https://raw.githubusercontent.com/wayne1204/NOAA-fish-finding/master/experiments/scripts/test_faster_rcnn.sh",
      "https://raw.githubusercontent.com/wayne1204/NOAA-fish-finding/master/experiments/scripts/train_faster_rcnn.sh",
      "https://raw.githubusercontent.com/wayne1204/NOAA-fish-finding/master/data/scripts/setModel.sh",
      "https://raw.githubusercontent.com/wayne1204/NOAA-fish-finding/master/data/scripts/fetch_faster_rcnn_models.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. download training and testing data \n\n- [Training data](https://challenge.kitware.com/girder#collection/5a722b2c56357d621cd46c22/folder/5ada227756357d4ff856f54d) (270.7 GB)\n\n- [Testing data](https://challenge.kitware.com/girder#item/5af21e0f56357d4ff85723d6) (272.1 GB)\n\n2. unzip both tars, it should have this basic structure\n```\n$annotations/             #: annotation root directory\n$annotations/habcam_seq0_training.mscoco.json\n$annotations/mbari_seq0_training.mscoco.json\n$annotations/mouss_seq0_training.mscoco.json\n$annotations/mouss_seq1_training.mscoco.json\n$annotations/...\n```\n\n```\n$imagery/                  #: image root directory\n$imagery/habcam_seq0/\n$imagery/mbari_seq0/\n$imagery/mouss_seq0/\n$imagery/mouss_seq1/\n$imagery/...\n```\n3. Create symlinks for the NOAA dataset\n```\ncd $NOAA-fish-finding/data/VOCdevkit2007\nmkdir -p [DATASET]\ncd [DATASET]\nln -s $imagery/[DATASET]/ PNGImages\n\n#: DATASET {mouss_seq0, mouss_seq1, mbari_seq0, habcam_seq0}\n```\n\n4. Prepare training images & annotations\n```\npython3 preprocess/jsonParser.py --dataset [DATASET] --anno_path [PATH] --mode [MODE]\n\n#: DATASET {mouss_seq0, mouss_seq1, mbari_seq0, habcam_seq0}\n#: PATH: training annotation path root directory\n#: MODE: image preprocess mode\noriginal: only conver png to jpg\ncontrast: enhance constrst\nequal: preform CLAHE(Contrast Limit Adaptive Histogram Equalization)\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Clone the repository\n```\ngit clone https://github.com/wayne1204/NOAA-fish-finding.git\n```\n\n2. Download Pre-trained model\n```\ncd $NOAA-fish-finding\nsh data/scripts/setModel.sh\n```\n\n3. Update GPU arch\n\nUpdate your -arch in setup script to match your GPU\n\ncheck [this](http://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/) to match GPU architecture\n  ```\n  cd lib\n  #: Change the GPU architecture (-arch) if necessary\n  vim setup.py\n  ```\n\n4. bulid Faster-RCNN Cython modules\n  ```\n  make clean && make\n  cd ..\n  ```\n\n5. Install the Python COCO API. The code requires the API to access COCO dataset.\n```\ncd data\ngit clone https://github.com/pdollar/coco.git\ncd coco/PythonAPI\nmake\ncd ../../..\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8002631542792215,
        0.9287467277036058
      ],
      "excerpt": "<a href='#prerequisites'>Prerequisites</a> \n<a href='#installation'>Installation</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.884067387307346,
        0.9069687384322455
      ],
      "excerpt": "./experiments/scripts/train_faster_rcnn.sh [GPU_ID] [DATASET] [NET] \n: GPU_ID is the GPU you want to test on \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9050628422249402
      ],
      "excerpt": "./experiments/scripts/train_faster_rcnn.sh 1 mbari_seq0 res101 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.884067387307346,
        0.9069687384322455
      ],
      "excerpt": "./experiments/scripts/test_faster_rcnn.sh [GPU_ID] [DATASET] [NET] \n: GPU_ID is the GPU you want to test on \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": "<a href='#training'>Training</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.810094876824159
      ],
      "excerpt": "<a href='#demo'>Demo</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8838148168639296
      ],
      "excerpt": ": Examples: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9150949912405066
      ],
      "excerpt": "$ python3 SSD/train.py --dataset [DATASET] --ssd_size [300/512] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8732583901288532
      ],
      "excerpt": "python SSD/eval.py --dataset [DATASET] --ssd_size [300/512] --path [PATH] \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/wayne1204/NOAA-fish-finding/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "Cuda",
      "MATLAB",
      "C++",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "NOAA Fish Finding",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "NOAA-fish-finding",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "wayne1204",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wayne1204/NOAA-fish-finding/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Python 3+\n- Tensorflow >= 1.6.0\n- pytorch == 0.3.0\n- Python package `cython`, `opencv-python`, `easydict`\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 23 Dec 2021 20:37:46 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "object-detection",
      "faster-rcnn",
      "ssd300",
      "ssd512",
      "classification"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "put the tested image in the data/demo folder\n- for Faster RCNN\n```\npython3 tools/demo.py --net [NET] --train_set [TRAIN]--test_set [TEST] --mode [predict/ both]\n\n#: NET {VGG16/ResNet101}\n#: TRAIN {mouss_seq0, mouss_seq1, mbari_seq0, habcam_seq0}\n#: TEST {mouss1/2/3/4/5, mbari1, habcam}\n#: MODE: \npredict: only plot prediction\nboth: ground truth and prediction\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1312.5602\n\n--------------\n\n<div style=\"text-align:center\"><img src=\"images/rl-agent.gif\" /></div>\n<div style=\"text-align:center\">(our agent is green"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* [@MatMarkiewicz](https://github.com/MatMarkiewicz)\n* [@mdragula](https://github.com/mdragula)\n* [@TheFebrin](https://github.com/TheFebrin)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9927844469561101
      ],
      "excerpt": "Deep Reinforcement Learning bot playing Pong game based on: https://arxiv.org/abs/1312.5602 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.938572062540381
      ],
      "excerpt": "export COMET_ML_API_KEY=your-comet-api-key \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TheFebrin/DeepRL-Pong",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-01T12:23:51Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-22T09:30:19Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9632429317659796
      ],
      "excerpt": "<div style=\"text-align:center\">(our agent is green)</div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8464329800418905
      ],
      "excerpt": "Using docker \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9049503835115682
      ],
      "excerpt": "In /models/saved_models we keep our models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9196327589456155
      ],
      "excerpt": "Then we trained it for more games using SGD and gained slightly better results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8505499582439019,
        0.9190885498639405
      ],
      "excerpt": "We changed the architecture. Now the DQN model consists of two models, standard one and a target model. \nMore info here: https://towardsdatascience.com/getting-an-ai-to-play-atari-pong-with-deep-reinforcement-learning-47b0c56e78ae \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8852196969182511
      ],
      "excerpt": "Final dual model after 6200 games performed worst than the one before. Although the winning ratio is not the best the model was doing about 1300-2200 steps per game. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Deep Reinforcement Learning bot playing Pong game.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TheFebrin/DeepRL-Pong/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Wed, 29 Dec 2021 17:59:12 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/TheFebrin/DeepRL-Pong/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "TheFebrin/DeepRL-Pong",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/TheFebrin/DeepRL-Pong/master/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.982640186418709
      ],
      "excerpt": "You can run the environment using provided Dockerfile, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9729586773105764
      ],
      "excerpt": "You can also build the environment locally. All packages needed to run our code are listed in the requirements.txt file. It's convenient to use virtualenv, nice virtualenv tutorial here \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9958776959782978,
        0.9979947896609701
      ],
      "excerpt": "pip install --upgrade pip \npip install -r requirements.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "python -m atari_py.import_roms ROMS \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8747328333903754
      ],
      "excerpt": "We're using the YAML config file config.yml. You can set there both network parameters and environment settings, like the device on which you want to run the code or CometML settings. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.871984573687572
      ],
      "excerpt": "<div style=\"text-align:center\"><img src=\"images/rl-agent.gif\" /></div> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8606280910157142
      ],
      "excerpt": "Quick start \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": "Training statistics \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8082022887640018
      ],
      "excerpt": "unzip ROMS.zip \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8638150272269783
      ],
      "excerpt": "If you want to use a pre-trained model you have to specify the LOAD_MODEL parameter as a name of the model_dump.pth file in models/saved_models directory, for example: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8580062552943244
      ],
      "excerpt": "During the training model logs all useful statistics to the CometML. You should set up the workspace, project name, tag, and name in the config file. Example of training statistics look like this: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8963907825685717,
        0.8386755008950799
      ],
      "excerpt": "(rl) febrin@laptop:~/Desktop/DeepRL-Pong(master)$ python eval_saved_model.py --model-name model_episode_5700.pth --n-games 100 --frame-skipping 4 \nEvaluating model: model_episode_5700.pth on 100 games. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8963907825685717,
        0.8386755008950799
      ],
      "excerpt": "(rl) febrin@laptop:~/Desktop/DeepRL-Pong(master)$ python eval_saved_model.py --model-name model_episode_6350_sgd.pth --n-games 100 --frame-skipping 4 \nEvaluating model: model_episode_6350_sgd.pth on 100 games. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003972407468292
      ],
      "excerpt": "Model: model_episode_6350_sgd.pth | n_games: 100 | Average score: -11.83 | Min: -20.0 | Max: 2.0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8963907825685717,
        0.8386755008950799
      ],
      "excerpt": "(rl) febrin@laptop:~/Desktop/DeepRL-Pong(master)$ python eval_saved_model.py --model-name model_dual_4500.pth --n-games 100 --frame-skipping 3 \nEvaluating model: model_dual_4500.pth on 100 games. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8750543423383125
      ],
      "excerpt": "Model: model_dual_4500.pth | n_games: 100 | Average score: -8.15 | Min: -19.0 | Max: 9.0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8963907825685717,
        0.8386755008950799
      ],
      "excerpt": "(rl) febrin@laptop:~/Desktop/DeepRL-Pong(master)$ python eval_saved_model.py --model-name model_dual_6200.pth --n-games 100 --frame-skipping 3 \nEvaluating model: model_dual_6200.pth on 100 games. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/TheFebrin/DeepRL-Pong/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Dawid Dieu\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "DeepRL-Pong",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DeepRL-Pong",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "TheFebrin",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TheFebrin/DeepRL-Pong/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Python - version 3.8.10\n* gym[atari]\n* PyTorch - version 1.8.1\n* numpy\n* comet-ml\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To test if your environment is set correctly you can run a simple demo:\n```bash\npython gym_demo.py\n```\n\nTo run the training you have to modify the `config.yml` file and then run.\n```\npython main.py --mode train\n```\n\nTo test your model you can speficy `LOAD_MODEL` parameter as described [here](#confing), and the run:\n```\npython main.py --mode test\n```\n\nYou can also observe a single game played by your model by running:\n```\npython main.py --mode demo\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Wed, 29 Dec 2021 17:59:12 GMT"
    },
    "technique": "GitHub API"
  }
}
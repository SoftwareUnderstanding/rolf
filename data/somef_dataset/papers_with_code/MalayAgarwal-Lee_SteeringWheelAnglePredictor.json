{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1604.07316",
      "https://arxiv.org/abs/1511.07289"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* <a  id=\"ref-1\">[1]</a> Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D. Jackel, Mathew Monfort, Urs Muller, Jiakai Zhang, Xin Zhang, Jake Zhao, and Karol Zieba. (2016). [End to End Learning for Self-Driving Cars](https://arxiv.org/abs/1604.07316).\n* <a  id=\"ref-2\">[2]</a> Djork-Arn\u00e9 Clevert, Thomas Unterthiner, & Sepp Hochreiter. (2015). [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)](https://arxiv.org/abs/1511.07289).\n* <a  id=\"ref-3\">[3]</a> Andrew L. Maas. (2013). [Rectifier Nonlinearities Improve Neural Network Acoustic Models](https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf).\n* <a  id=\"ref-4\">[4]</a> Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, & Ruslan Salakhutdinov (2014). [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://jmlr.org/papers/v15/srivastava14a.html). Journal of Machine Learning Research, 15(56), 1929-1958.\n\n\n\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "<div align=\"center\" style=\"padding: 10px;\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.900589252295798
      ],
      "excerpt": "<table style=\"border-collapse:collapse;border-spacing:0;margin-left:auto;margin-right:auto\" class=\"tg\"><thead><tr><th style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\"><img src=\"img/track1.gif\"></th><th style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\"><img src=\"img/track2.gif\"></th></tr></thead></table> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MalayAgr/SteeringWheelAnglePredictor",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-29T12:10:52Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-31T22:06:49Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9980637891207004,
        0.8822309931961808
      ],
      "excerpt": "Subham Dasgupta and I set out to build a model which is capable of predicting the steering angle for a car given an image of the road as input, as part of our summer internship project at MyWBUT. \nThis document highlights the steps we took to achieve that goal. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9302287581602335,
        0.951232532257774
      ],
      "excerpt": "The Model \nThe Data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8494200696814652
      ],
      "excerpt": "Building the Model (Module: model) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9954838949994312,
        0.8897548291020638
      ],
      "excerpt": "Our approach was to make the code as modular as possible, thereby making customization to the model as easy as possible. With that in mind, we attempted to create an API-like code structure where different modules can call functions of other modules without exactly being aware of how those functions are implemented. All in all, our project is divided into the following four files: \ndata.py - Responsible for all data-related tasks such as loading, cleaning, etc. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8693647400340742
      ],
      "excerpt": "model.py - Responsible for building and training the model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9105666707714831
      ],
      "excerpt": "We used TensorFlow's Keras API to build the model, strictly adhering to the functional API for greater flexibility. NumPy, Pandas, OpenCV and scikit-learn were used for data processing. Matplotlib was used at one place to generate a plot. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9774089240696162,
        0.9886487508157021
      ],
      "excerpt": "Our approach was based on a seminal paper published by NVIDIA in 2016 [1]. The paper suggests using a Convolutional Neural Network (CNN) model trained on images of roads with the steering angle as a training signal, learning to predict the angle when given new images of roads. \nThe architecture of the CNN model is as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9094645517382046,
        0.934965446493198,
        0.9246565436965007,
        0.860909411465583
      ],
      "excerpt": "A convolutional layer with 24 kernels, 5 X 5 in size and stride of 2 \nA convolutional layer with 36 kernels, 5 X 5 in size and stride of 2 \nA convolutional layers with 48 kernels, 5 X 5 in size and stride of 2 \nTwo convolutional layers with 64 kernels each, 3 X 3 in size and stride of 1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9295594991071844,
        0.9929713343324207,
        0.992436051421262,
        0.9430922401052639
      ],
      "excerpt": "This leads to ~2,50,000 trainable parameters in the model. \nWhile we have followed this architecture closely, we have experimented with various activation functions and have also designed the code such that it is extremely convenient to switch the activation function for the entire model. Specifically, in addition to using the standard ReLU activation with He Normal initialization and a small constant bias, we have experimented with ELU [2] and LeakyReLU [3] as our activation functions. \nELU helps with dealing with dying neurons and exploding gradients better than ReLU and in the end, became the activation function of choice for our model. LeakyReLU was found to perform worse than both ELU and ReLU, and now exists only as an API feature. \nIn addition to this, we have also added some modern-day conventional practices to the model. Specifically, the following two practices have been adopted: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9151095441036212,
        0.9857954295748613,
        0.9425344687620468,
        0.9690139793157642,
        0.9576829512428873
      ],
      "excerpt": "Dropout [4] - Dropout is added between the convolutional block and the fully-connected block to combat overfitting \n[1] used a physical vehicle mounted with cameras to take images of roads and to record steering angles as the vehicle is driven. They are NVIDIA and we are college students. Clearly, this sort of luxury wasn't available to us. Instead, we used Udacity's open-source self-driving car simulator to generate data to train the model. \nThe simulator comes with two modes of operation, training and autonomous: \nTraining Mode - In this mode, a human is supposed to drive a car on a track. In the background, the simulator will automatically take images of the road and record the corresponding steering angle, among other things. Rather than taking one picture for each angle, the simulator takes 3 images from three different angles (center, left, right) for each angle. This gives your model the ability to learn the angle for different views of the same road and thus, leads to more accuracy. Though three images are taken, only one steering angle is recorded, from the perspective of the center angle. \nThe final output is a CSV file with m rows (number of steering angles) and  7 columns. The first three columns correspond to the file paths of the center, left and right images for the angle. The fourth column corresponds to the steering angle. The last three columns correspond to throttle, reverse and speed (a model can be built which predicts these values as well) respectively. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9883783602257687,
        0.9582677918959426,
        0.962203852648867
      ],
      "excerpt": "It is also equipped with two tracks and more tracks can be added with a bit of hacking (refer to link above). \nOur model was trained to be able to drive on the two default tracks available in the simulator. \nHere are the results of building, training and running the model on the simulator. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9816887189229327,
        0.9907746871574197,
        0.9641814240238333,
        0.9540494175311078
      ],
      "excerpt": "This section documents the complete API available to the user for processing data, building the model and training it. \nNOTE: Having this API is not enough to actually enable the simulator to drive the car using the model. There needs to be a script in between which relays data to and fro between the model and the simulator. Refer to the link to the simulator. The repository has such a script. \n\"Flattens\" the CSV files so that the the three columns containing the three angles become rows in themselves and the steering angle gets repeated for them. It also shifts the steering angle for right (subtracting shift) and left images (adding shift) as all angles are with respect to center image. \nAs stated above, the simulator outputs a CSV file where each row has paths to images from three different angles and the steering angle. A standard CNN can take as input only one image at a time and therefore, for each row, we are forced to select one of the three angles. While a good model can be obtained by randomly selecting any one of the angles, a better model can be obtained by feeding it all the angles. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8217194761999203
      ],
      "excerpt": "| usecols         | list: The index of columns to be used in the CSV. Last item should always be for the column containing the labels. Defaults to [0, 1, 2, 3], using first four columns of the file.    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9874338849642579,
        0.996011977771731
      ],
      "excerpt": "| test_size                                           | float: The proportion of data to be kept aside as the test set. Defaults to 0.15, reserving 15% of the data.          | \n| val_size                                            | float: The proportion of data to be kept aside as the validation set. Defaults to 0.15, reserving 15% of the data.    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8397159221577195,
        0.9529020243241928
      ],
      "excerpt": "A vectorized implementation of OpenCV's imread() function developed using numpy.vectorize(), used to obtain a 4D array of images from a list of image paths in a single call. \nNOTE: This doesn't have, most of the times, any performance gains. The internal implementation is essentially a loop. It exists purely for conciseness. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9529020243241928
      ],
      "excerpt": "NOTE: This doesn't have, most of the times, any performance gains. The internal implementation is essentially a loop. It exists purely for conciseness. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8745339370909049,
        0.9529020243241928
      ],
      "excerpt": "A vectorized implementation of OpenCV's cvtColor() function developed using numpy.vectorize(), used to change the colorspace of a bunch of images in a single call. \nNOTE: This doesn't have, most of the times, any performance gains. The internal implementation is essentially a loop. It exists purely for conciseness. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9372140671711631
      ],
      "excerpt": "Combines resizing, colorspace conversion and standardization into one single function, becoming the preprocessor in the pipeline. It uses processing.vectorized_imresize(), processing.vectorized_cvtColor() and processing.channelwise_standardization() to perform these tasks. Additionally, the function changes the data type used for the images from float64 (NumPy's default) to float32 to reduce amount of memory occupied by the images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589540845397795
      ],
      "excerpt": "| colorspace      | cv2.ColorConversionCode: A code representing the target colorspace. Defaults to cv2.COLOR_BGR2YUV.     | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.938985258917093
      ],
      "excerpt": "Augments images according to the given threshold. It currently supports only random left/right flipping according to the given flip threshold. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9279688858925946,
        0.9451020170888658
      ],
      "excerpt": "| aug_threshold   | float: The minimum probability for an image to not be augmented. Defaults to 0.6.     | \n| flip_threshold  | float: The minimum probability for an image to not be flipped. Defaults to 0.5.       | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8158027282310149
      ],
      "excerpt": "Note: processing.augment_images() calls this function and passes mask based on aug_threshold to ensure that flipped images are among the images that are to be augmented. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9451020170888658
      ],
      "excerpt": "| threshold       | float: The minimum probability for an image to not be flipped. Defaults to 0.5.                                                                   | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9049170824752113
      ],
      "excerpt": "Initializes a ReLU, ELU or LeakyReLU activation layer with the given input layer based on activation. This function can be used in place of the activation keyword argument in all Keras layers to mix-match activations for different layers and easily use ELU, LeakyReLU, which otherwise need to be imported separately. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.881274317219377
      ],
      "excerpt": "| KeyError        | When activation is not one of the specified values.                                                                                 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9166988226350049,
        0.8589935820069996,
        0.9333060922689793
      ],
      "excerpt": "| filters             | int: The number of filters to be used in the Conv2D layer.                                                                                                                        | \n| kernel_size         | tuple: The size of each filter in the Conv2D layer.                                                                                                                               | \n| strides             | strides: The size of the stride for each filter in the Conv2D layer.                                                                                                              | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9121954849814422
      ],
      "excerpt": "| kernel_initializer  | str: The weight initializer for each filter. Defaults to he_uniform.                                                                                                              | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9557700823444386
      ],
      "excerpt": "Helper function which builds the fully-connected block of the model with the specified activation using three Dense layers with  100, 50 and 10 units respectively, where the first Dense layer is initialized with the given input. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9005074151348771,
        0.8005335361806523
      ],
      "excerpt": "| initializer     | str: The weight initializer for each Dense layer. Defaults to he_uniform.                                                                                                                                                       | \n| bias_val        | float: The initial bias value to be used for each Dense layer. Defaults to 0.01.                                                                                                                                                | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9529507646447665
      ],
      "excerpt": "A shortcut function which builds the model as specified in the paper. It calls model.conv2d() and model.fullyconnected_layers(), using their default values for the parameters.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8288444429682535,
        0.8195737604366188,
        0.8695359216640816,
        0.9190500162428226,
        0.8780561144385897
      ],
      "excerpt": "| ip              | keras.layers.Layer: Any Keras layer such as Input, Conv2D, Dense, etc., which will be used as the input for the first layer in the model. Defaults to a Input layer with the industry standard shape of (128, 128, 3).    | \n| activation      | str: The activation layer to be used. Can be relu, elu or lrelu. Defaults to industry standard of relu.                                                                                                                     | \n| dropout         | float: The dropout ratio to be used for the Dropout layer between the convolutional block and fully connected block.                                                                                                              | \n| compile_model   | bool: Designates whether the model should be complied or not. Defaults to True. Setting it as False will allow the user more control over parameters like loss and optimizer.                                                   | \n| lr              | float: The learning rate to be used in the optimizer. Defaults to 1e-3.                                                                                                                                                           | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9299723150392758
      ],
      "excerpt": "Helper function which works as an infinite generator, yielding random batches of images according to the specified batch size and the given list of image paths. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9631004676659367,
        0.9178476967225748
      ],
      "excerpt": "| batch_size      | int: The size of the batch to be generated.                                                                                 | \n| is_training     | bool: Designates whether the model is currently training. When the model is training, the function augments the images.     | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8412115392304034
      ],
      "excerpt": "Helper function which plots the train and validation loss curve of the model against the number of epochs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9559976763464374
      ],
      "excerpt": "Helper function which trains a model given the training and validation sets, the batch size and the number of epochs by calling model.get_batch() inside keras.Model.fit_generator(). It determines the steps_per_epoch by dividing the length of the training set by batch size and validation_steps by dividing the length of the validation set by batch_size.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860318599876298
      ],
      "excerpt": "| model           | keras.Model: The model to be trained                                                                                    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9622638367591411,
        0.9027415455143809
      ],
      "excerpt": "| batch_size      | int: The size of the batches which will be used when training the model. Defaults to 64.                              | \n| epochs          | int: The number of epochs the model will be trained for. Defaults to 50.                                              | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A CNN-based deep learning model to predict steering wheel angles for a car, replicated from a 2016 paper available at https://arxiv.org/abs/1604.07316",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MalayAgarwal-Lee/SteeringWheelAnglePredictor/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 30 Dec 2021 07:44:09 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/MalayAgr/SteeringWheelAnglePredictor/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "MalayAgr/SteeringWheelAnglePredictor",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8373264968337445,
        0.829759811234927
      ],
      "excerpt": "model.py - Responsible for building and training the model \nmain.py - Main driver program which uses the above modules to obtain a trained model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8843652374390215
      ],
      "excerpt": "    <img src=\"img/model_diagram.png\" width=\"500\" height=\"500\" alt=\"Model\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.852722344036734
      ],
      "excerpt": "<table style=\"border-collapse:collapse;border-spacing:0;margin-left:auto;margin-right:auto\" class=\"tg\"><thead><tr><th style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\"><img src=\"img/track1.gif\"></th><th style=\"border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal\"><img src=\"img/track2.gif\"></th></tr></thead></table> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8546890435870833
      ],
      "excerpt": "| path            |                                                                                str: Path to CSV file.                                                                                   | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8602402279174399
      ],
      "excerpt": "| header          |                                                  bool: Indicates whether the CSV file contains a header or not. Defaults to None.                                                     | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.80435290038529
      ],
      "excerpt": "| images      | numpy.array: A 1D numpy array with the flattened image paths            | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8547819692938502,
        0.8834934680709491
      ],
      "excerpt": "Shortcut function which can be used to load the data from a specified CSV file and split it into train, test and validation sets according to the specified sizes.  \nNote: The function calls data.flatten_csv() to load the data from the CSV file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8563136493248976,
        0.8375056549799537
      ],
      "excerpt": "| test_size                                           | float: The proportion of data to be kept aside as the test set. Defaults to 0.15, reserving 15% of the data.          | \n| val_size                                            | float: The proportion of data to be kept aside as the validation set. Defaults to 0.15, reserving 15% of the data.    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8936877097853128
      ],
      "excerpt": "| split data                                          | tuple: A sextuple in the order of training, validation, test images, training, validation, test labels.                 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8631518925933803
      ],
      "excerpt": "| images                                              | numpy.array: A 4D array of images as (N X height X width X channels).                                                        | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8333927360446926
      ],
      "excerpt": "| images                                              | numpy.array: A 4D array of images as (N X height x width X channels). This necessarily needs to be the first argument.     | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.832327463962962
      ],
      "excerpt": "| images                                              | numpy.array: The resized images as a 4D array.                                          | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8333927360446926
      ],
      "excerpt": "| images                                              | numpy.array: A 4D array of images as (N X height x width X channels). This necessarily needs to be the first argument.     | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.832327463962962
      ],
      "excerpt": "| images                                              | numpy.array: The converted images as a 4D array.                                    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8631518925933803
      ],
      "excerpt": "| images          | numpy.array: A 4D array of images as (N X height x width X channels).                                                    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.832327463962962
      ],
      "excerpt": "| images      | numpy.array: The standardized images as a 4D array.   | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8631518925933803,
        0.828584769804431
      ],
      "excerpt": "| images          | numpy.array: A 4D array of images as (N X height x width X channels).              | \n| size            | tuple: The target size of the images as (width X height). Defaults to (200, 66).   | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.832327463962962
      ],
      "excerpt": "| images      | numpy.array: The preprocessed images as a 4D array.   | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8631518925933803
      ],
      "excerpt": "| images          | numpy.array: A 4D array of images as (N X height x width X channels).                   | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8631518925933803
      ],
      "excerpt": "| images          | numpy.array: A 4D array of images as (N X height x width X channels).                                                                               | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8176336547337856
      ],
      "excerpt": "| images      | numpy.array: Flipped and normal images as a 4D array.    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8040756249151182
      ],
      "excerpt": "| layer_num           | int: An index value for the layer which will be used in the naming of the layer.                                                                                                    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8178851860723203
      ],
      "excerpt": "| bias_val        | float: The initial bias value to be used for each Dense layer. Defaults to 0.01.                                                                                                                                                | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8071286611945241
      ],
      "excerpt": "Note: The function uses the Adam optimizer and mse as its loss when compile_model = True. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8173676506445293
      ],
      "excerpt": "| ip              | keras.layers.Layer: Any Keras layer such as Input, Conv2D, Dense, etc., which will be used as the input for the first layer in the model. Defaults to a Input layer with the industry standard shape of (128, 128, 3).    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8197728084758696
      ],
      "excerpt": "| model           | keras.Model: The model put together completely from the first input layer to the final output layer, which may also be compiled.                                                                                                    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8624992012936425
      ],
      "excerpt": "Note: The function calls model.plot_model_history() when plot_history = True. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.815625949323579
      ],
      "excerpt": "| batch_size      | int: The size of the batches which will be used when training the model. Defaults to 64.                              | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/MalayAgr/SteeringWheelAnglePredictor/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Building a Self-Driving Car Using Deep Learning and Python",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SteeringWheelAnglePredictor",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "MalayAgr",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MalayAgr/SteeringWheelAnglePredictor/blob/master/readme.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 30 Dec 2021 07:44:09 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deeplearning",
      "artificial-intelligence",
      "cnn",
      "self-driving-car",
      "python",
      "keras",
      "numpy",
      "pandas",
      "opencv",
      "matplotlib",
      "scikit-learn",
      "nvidia"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Say this is our CSV file:\n\n|      center       |      left         |      right        | angle     |\n|:---------------:  |:-------------:    |:--------------:   |:-----:    |\n| img1_center.png   | img1_left.png     | img1_right.png    | 0.5       |\n| img2_center.png   | img2_left.png     | img2_right.png    | -0.5      |\n\nCalling the function with `shift` as its default value on this file will return:\n\n```python\n images = ['img1_center.png', 'img1_left.png', 'img1_right.png', 'img2_center.png', 'img2_left.png', 'img2_right.png']\n labels = [0.5, 0.7, 0.3, -0.5, -0.3, -0.7]\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
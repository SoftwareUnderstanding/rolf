{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [1] A. van den Oord, S. Dieleman, H. Zen, K. Simonyan, O. Vinyals, A. Graves, N. Kalchbrenner, A. Senior & K. Kavukcuoglu, \"WaveNet: A Generative Model for Raw Audio\", in CoRR, 2016, http://arxiv.org/abs/1609.03499.\n- [2] R. Bittner, J. Salamon, M. Tierney, M. Mauch, C. Cannam & J. P. Bello, \"MedleyDB: A Multitrack Dataset for Annotation-Intensive MIR Research\", in 15th International Society for Music Information Retrieval Conference, Taipei, Taiwan, 2014, https://medleydb.weebly.com/.\n\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pbrandl/aNN_Audio",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-21T08:33:23Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-21T15:27:17Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9178794615352863,
        0.9234430484844143
      ],
      "excerpt": "Modelling a digital twin of an analog harmonic distortion device for audio signals as shown in the image below. <img src=\"https://render.githubusercontent.com/render/math?math=x, y\"> are audio signals, i.e., 16-bit wav files. Based on these files the neural network is trained to minimize prediction errors. \nEssentially, the device adds overtones to the signal. The current implementation uses a modified version of WaveNet [1]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9869634171750674
      ],
      "excerpt": "Due to computational complexity of the project is mostly implemented in as Python notebook in Google Colab (WaveNet.ipynb). Due to the large training data set (currently 4 GB) the data is stored in Google Drive. (If interested just contact me.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9590363459629363,
        0.9731537722005819
      ],
      "excerpt": "Note that the input and target files are starting and ending with a loud click sound. This helps for synchronization of the files after recording (recording may start or end with arbitrary offset before or after the actual audio signal). To synchronize the two files are trimmed according to the loud click sound. This results in equal length of both files. This is done in preprocessing.py. \nThe model is implemented in a Python notebook in Google Colab (WaveNet.ipynb). Input and target files have to be uploaded to Google Drive. Once loaded as tensors of shape (channels, num_samples) in the notebook, the fit function in the notebook can be called and training starts. Once trained, a predict_sequence function is implemented, that takes an arbitrary length of audio file as tensor and predicts the harmonic distortion. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Digital twin of analog audio distortion devices (WavNet based).",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pbrandl/aNN_Audio/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 26 Dec 2021 02:23:26 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/pbrandl/aNN_Audio/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "pbrandl/aNN_Audio",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/pbrandl/aNN_Audio/master/WaveNet.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8096722856414249
      ],
      "excerpt": "The model is implemented in a Python notebook in Google Colab (WaveNet.ipynb). Input and target files have to be uploaded to Google Drive. Once loaded as tensors of shape (channels, num_samples) in the notebook, the fit function in the notebook can be called and training starts. Once trained, a predict_sequence function is implemented, that takes an arbitrary length of audio file as tensor and predicts the harmonic distortion. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/pbrandl/aNN_Audio/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "aNN_Audio",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "aNN_Audio",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "pbrandl",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/pbrandl/aNN_Audio/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 02:23:26 GMT"
    },
    "technique": "GitHub API"
  }
}
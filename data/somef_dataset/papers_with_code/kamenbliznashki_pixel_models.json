{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1601.06759",
      "https://arxiv.org/abs/1606.05328",
      "https://arxiv.org/abs/1701.05517",
      "https://arxiv.org/abs/1712.09763"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kamenbliznashki/pixel_models",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-12-13T17:06:08Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-10T23:02:37Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8035369821346402
      ],
      "excerpt": "Implementations of autoregressive algorithms from: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925770764634926,
        0.8058024045253104,
        0.9800640594769272
      ],
      "excerpt": "* PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications \n* PixelSNAIL: An Improved Autoregressive Generative Model \nAutoregressive models are particularly computationally intensive. I tested the above on a single batch of CIFAR10 and MNIST. I have not tried to replicate the published results since I only needed these as building blocks in other models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9631428688159882
      ],
      "excerpt": "Tensorflow implementations by the authors of PixelCNN++ and PixelSNAIL \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Pytorch implementations of autoregressive pixel models - PixelCNN, PixelCNN++, PixelSNAIL",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kamenbliznashki/pixel_models/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Thu, 30 Dec 2021 07:45:03 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kamenbliznashki/pixel_models/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "kamenbliznashki/pixel_models",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8710179365661463
      ],
      "excerpt": "For colored MNIST see Berkeley's CS294-158; the dataset can be downloaded here. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/kamenbliznashki/pixel_models/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Pixel models",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pixel_models",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "kamenbliznashki",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/kamenbliznashki/pixel_models/blob/master/readme.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* python 3.7\n* pytorch 1.1\n* numpy\n* tensorboardX\n* tqdm\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 19,
      "date": "Thu, 30 Dec 2021 07:45:03 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "autoregressive",
      "generative-models",
      "pytorch"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The architecture files `pixelcnn.py`, `pixelcnnpp.py`, and `pixelsnail.py` contain model classes, loss function and generation function; `optim.py` implements an exponential moving average wrapper around torch optimizers; `main.py` contains the common logic around training, evaluation, and generation.\n\nTo train a model:\n```\npython main.py --train\n               --dataset      #: choice from cifar10, mnist, colored-mnist\n               --data_path    #: path to dataset\n               --[add'l options]\n               --model        #: choice from pixelcnn, pixelcnnpp, pixelsnail;\n                              #: activates subparser for specific model params\n```\nAdditional options are in the `main.py` parser arguments:\n* training options - e.g. number of epochs, learning rate, learning rate decay, polyak averaging, cuda device id, batch_size.\n* model specific options - e.g. number of channels, number of residual layers, kernel size, etc.\n* dataset options - e.g. number of bits, number of conditional classes, data location, etc.\n\nTo evaluate a model or generate from a model:\n```\npython main.py --generate     #: [evaluate]; if evaluate, need to specify dataset and data_path\n               --restore_file #: path to .pt checkpoint\n               --model        #: choice from pixelcnn, pixelcnnpp, pixelsnail\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
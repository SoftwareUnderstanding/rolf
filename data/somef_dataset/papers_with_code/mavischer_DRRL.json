{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1602.01783"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mavischer/DRRL",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-13T18:49:46Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-19T14:23:27Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Torch implementation of the deep relational architecture from the paper [\"Relational Deep Reinforcement Learning\"](https://arxiv.org/pdf/1806.01830.pdf) together with (synchronous) advantage-actor-critic training as discussed for example [here](https://arxiv.org/abs/1602.01783).\n\nThe Box-World environment used in this script can be found at [this repo](https://github.com/mavischer/Box-World).\n\nTraining is performed in `a2c_fast.py`. The implementation is based on [this repo](https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail) which turned out to be more clever and substantially faster than my own implementation `a2c_dist.py`.\nHowever this latter file contains routines to plot the gradients in the network and the computation graph.\n\nThe relational module and general architecture are both implemented as `torch.nn.Module` in `attention_module.py`. However, `a2c_fast.py` uses almost identical adaptations of these classes in `helper/a2c_ppo_acktr/model.yml` that comply with the training algorithm's `Policy` class.\n\nAn example YAML config file parsed from the arguments is `configs/exmpl_config.yml`. Training, the environment and network can be parameterized there. A copy of the loaded configuration file will be saved with checkpoints and logs for documentation.\n\nA suitable environment can be created e.g. by  `conda env create -f environment.yml` or \n `pip install -r requirements.txt`. Afterwards install and register the [Box-World environment](https://github.com/mavischer/Box-World) by cloning the repo and `pip install -e gym-boxworld`.\n*Remember that after changing the code you need to re-register the environment before the changes become effective.*\nYou can find the details of state space, action space and reward structure there.\n\n`visualize_results.ipynb` contains some plotting functionality.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A2C training of Relational Deep Reinforcement Learning Architecture",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mavischer/DRRL/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 26 Dec 2021 15:58:54 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mavischer/DRRL/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "mavischer/DRRL",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/mavischer/DRRL/master/visualize_results.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mavischer/DRRL/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "A2C training of Relational Deep Reinforcement Learning Architecture",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DRRL",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "mavischer",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mavischer/DRRL/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\npython a2c.py -c configs/exmpl_config.yml -s example_run\n```",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Sun, 26 Dec 2021 15:58:54 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\npython a2c.py -c configs/exmpl_config.yml -s example_run\n```",
      "technique": "Header extraction"
    }
  ]
}
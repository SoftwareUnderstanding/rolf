{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1609.04802\n\n## Metrics:\n\nThe network is implemented as the paper suggests using perceptual loss as metric to measure the performance of the network.\n<p align=\"center\">\n    <img src=\"https://github.com/calebemonteiro/AIDL_Project/blob/master/resources/percep_loss.JPG\" width=\"350\"\\>\n</p>\n\nTo Extract the the content loss, the paper suggests to use the VGG-19 to calculate the pixel-loss MSE between the features of the Hi-Res image \nand fake Hi-Res image, as it follows:\n\n<p align=\"center\">\n    <img src=\"https://github.com/calebemonteiro/AIDL_Project/blob/master/resources/content_loss.JPG\" width=\"350\"\\>\n</p>\n\n## Dataset:\n    For SRGAN training we opted to used the CelebA dataset with can be found here: http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\n\n\n## Requirements:\n    You will need the following to run the above:\n    Keras==2.3.1\n    tensorflow==2.1.0\n    opencv-python==4.3.0\n\tmatplotlib==3.3.0\n\targparse==1.4.0\n\tnumpy==1.19.1\n\n## File Structure:\n    Model.py   : Contains Generator and Discriminator Network\n    Utils.py   : Contains utilities to process images\n    train.py   : Used for training the model\n\n## Usage:\n    \n    Note : During the training the images generated and model will be saved into the directories \"images\" \n\tand \"model\" following the \"sample_interval\" parameter. all output folders are automatically created.\n    \n     * Training (due to my hardware specs, im training with default settings"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "Paper: https://arxiv.org/abs/1609.04802 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/calebemonteiro/AIDL_Project",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-18T08:24:34Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-09-29T11:02:25Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9659356186489563
      ],
      "excerpt": "Implementation of Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network using Keras (tf) for my postgraduate project in Universitat Polit\u00e8cnica de Catalunya. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9796658753546895
      ],
      "excerpt": "The network is implemented as the paper suggests using perceptual loss as metric to measure the performance of the network. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9557236249645755
      ],
      "excerpt": "To Extract the the content loss, the paper suggests to use the VGG-19 to calculate the pixel-loss MSE between the features of the Hi-Res image  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8184043153553526,
        0.8089487531611942
      ],
      "excerpt": "For SRGAN training we opted to used the CelebA dataset with can be found here: http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html \nModel.py   : Contains Generator and Discriminator Network \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9593290097493038,
        0.8721385879967656,
        0.9197814757624105,
        0.8798867854731198
      ],
      "excerpt": "The architecture suggested by the paper, even with very limited computational resources, is able to archieve some very good results. \nWe observed that the network really improves the image quality while applying the upscaling factor by 4 (as suggested by the paper) \nEven when the images are \"glitched\" the network tries to improve the pixel area of the glitch. \nFor some reason, the generator performs badly when dealing with glasses (suggests of samples in the training set/uneven train set or not enough training time) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "SRGAN Project for Postgraduate program.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/calebemonteiro/AIDL_Project/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 27 Dec 2021 18:35:36 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/calebemonteiro/AIDL_Project/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "calebemonteiro/AIDL_Project",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8166977296313789,
        0.9258314066098505
      ],
      "excerpt": "Utils.py   : Contains utilities to process images \ntrain.py   : Used for training the model \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/calebemonteiro/AIDL_Project/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# SRGAN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "AIDL_Project",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "calebemonteiro",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/calebemonteiro/AIDL_Project/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    You will need the following to run the above:\n    Keras==2.3.1\n    tensorflow==2.1.0\n    opencv-python==4.3.0\n\tmatplotlib==3.3.0\n\targparse==1.4.0\n\tnumpy==1.19.1\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 18:35:36 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "keras-tensorflow",
      "gan",
      "opencv"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    \n    Note : During the training the images generated and model will be saved into the directories \"images\" \n\tand \"model\" following the \"sample_interval\" parameter. all output folders are automatically created.\n    \n     * Training (due to my hardware specs, im training with default settings):\n        Run below command to start the training process. this script will also download the dataset and prepare the folders needed.\n        > python train.py --train_folder='./data/train/' --batch_size=12 --epochs=500 --sample_interval=25\n\n\n\t\n\n",
      "technique": "Header extraction"
    }
  ]
}
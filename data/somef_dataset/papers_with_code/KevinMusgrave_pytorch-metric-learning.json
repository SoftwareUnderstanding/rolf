{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you'd like to cite pytorch-metric-learning in your paper, you can use this bibtex:\n```latex\n@misc{musgrave2020pytorch,\n    title={PyTorch Metric Learning},\n    author={Kevin Musgrave and Serge Belongie and Ser-Nam Lim},\n    year={2020},\n    eprint={2008.09164},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{musgrave2020pytorch,\n    title={PyTorch Metric Learning},\n    author={Kevin Musgrave and Serge Belongie and Ser-Nam Lim},\n    year={2020},\n    eprint={2008.09164},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9105368110547479
      ],
      "excerpt": "- https://github.com/bnu-wangxun/Deep_Metric \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9626356225854676,
        0.9105368110547479,
        0.9105368110547479,
        0.9449813035477502,
        0.9105368110547479,
        0.9105368110547479,
        0.8283216015784888
      ],
      "excerpt": "- https://github.com/facebookresearch/deepcluster \n- https://github.com/geonm/proxy-anchor-loss \n- https://github.com/idstcv/SoftTriple \n- https://github.com/kunhe/FastAP-metric-learning \n- https://github.com/ronekko/deep_metric_learning \n- https://github.com/tjddus9597/Proxy-Anchor-CVPR2020 \n- http://kaizhao.net/regularface \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KevinMusgrave/pytorch-metric-learning",
    "technique": "GitHub API"
  },
  "contributor": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Thanks to the contributors who made pull requests!\n\n| Contributor | Highlights |\n| -- | -- |\n|[marijnl](https://github.com/marijnl)| - [BatchEasyHardMiner](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#batcheasyhardminer) <br/> - [TwoStreamMetricLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/trainers/#twostreammetricloss) <br/> - [GlobalTwoStreamEmbeddingSpaceTester](https://kevinmusgrave.github.io/pytorch-metric-learning/testers/#globaltwostreamembeddingspacetester) <br/> - [Example using trainers.TwoStreamMetricLoss](https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/examples/notebooks/TwoStreamMetricLoss.ipynb) |\n|[mlopezantequera](https://github.com/mlopezantequera) | - Made the [testers](https://kevinmusgrave.github.io/pytorch-metric-learning/testers) work on any combination of query and reference sets <br/> - Made [AccuracyCalculator](https://kevinmusgrave.github.io/pytorch-metric-learning/accuracy_calculation/) work with arbitrary label comparisons |\n| [elias-ramzi](https://github.com/elias-ramzi) | [HierarchicalSampler](https://kevinmusgrave.github.io/pytorch-metric-learning/samplers/#hierarchicalsampler) |\n| [fjsj](https://github.com/fjsj) | [SupConLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#supconloss) |\n| [AlenUbuntu](https://github.com/AlenUbuntu) | [CircleLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#circleloss) |\n| [wconnell](https://github.com/wconnell) | [Learning a scRNAseq Metric Embedding](https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/examples/notebooks/scRNAseq_MetricEmbedding.ipynb) |\n| [AlexSchuy](https://github.com/AlexSchuy) | optimized ```utils.loss_and_miner_utils.get_random_triplet_indices``` |\n| [JohnGiorgi](https://github.com/JohnGiorgi) | ```all_gather``` in [utils.distributed](https://kevinmusgrave.github.io/pytorch-metric-learning/distributed) |\n| [Hummer12007](https://github.com/Hummer12007) | ```utils.key_checker``` |\n| [vltanh](https://github.com/vltanh) | Made ```InferenceModel.train_indexer``` accept datasets |\n| [btseytlin](https://github.com/btseytlin) | ```get_nearest_neighbors``` in [InferenceModel](https://kevinmusgrave.github.io/pytorch-metric-learning/inference_models) |\n| [z1w](https://github.com/z1w) | |\n| [thinline72](https://github.com/thinline72) | |\n| [tpanum](https://github.com/tpanum) | |\n| [fralik](https://github.com/fralik) | |\n| [joaqo](https://github.com/joaqo) | |\n| [JoOkuma](https://github.com/JoOkuma) | |\n| [gkouros](https://github.com/gkouros) | |\n| [yutanakamura-tky](https://github.com/yutanakamura-tky) | |\n| [KinglittleQ](https://github.com/KinglittleQ) | |\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-23T17:20:35Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-25T02:49:19Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8741510824094357
      ],
      "excerpt": "- See the release notes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8741510824094357
      ],
      "excerpt": "- See the release notes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9872591595398047,
        0.9794659031594146,
        0.8741510824094357
      ],
      "excerpt": "- A bug fix for compatibility with autocast \n- New behavior for the k parameter of AccuracyCalculator. (Apologies for the breaking change. I'm hoping to have things stable and following semantic versioning when v1.0 arrives.) \n- See the release notes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9239906250875748
      ],
      "excerpt": "To compute the loss in your training loop, pass in the embeddings computed by your model, and the corresponding labels. The embeddings should have size (N, embedding_size), and the labels should have size (N), where N is the batch size. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8978285935052309
      ],
      "excerpt": "for i, (data, labels) in enumerate(dataloader): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9518602519746595
      ],
      "excerpt": "    embeddings = model(data) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9136653266005408
      ],
      "excerpt": "The TripletMarginLoss computes all possible triplets within the batch, based on the labels you pass into it. Anchor-positive pairs are formed by embeddings that share the same label, and anchor-negative pairs are formed by embeddings that have different labels.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8978285935052309
      ],
      "excerpt": "for i, (data, labels) in enumerate(dataloader): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9518602519746595
      ],
      "excerpt": "    embeddings = model(data) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9829231957186424,
        0.9664548106434362
      ],
      "excerpt": "In the above code, the miner finds positive and negative pairs that it thinks are particularly difficult. Note that even though the TripletMarginLoss operates on triplets, it\u2019s still possible to pass in pairs. This is because the library automatically converts pairs to triplets and triplets to pairs, when necessary. \nLoss functions can be customized using distances, reducers, and regularizers. In the diagram below, a miner finds the indices of hard pairs within a batch. These are used to index into the distance matrix, computed by the distance object. For this diagram, the loss function is pair-based, so it computes a loss per pair. In addition, a regularizer has been supplied, so a regularization loss is computed for each embedding in the batch. The per-pair and per-element losses are passed to the reducer, which (in this diagram) only keeps losses with a high value. The averages are computed for the high-valued pair and element losses, and are then added together to obtain the final loss. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9928381663487837,
        0.9519364865643376
      ],
      "excerpt": "The TripletMarginLoss is an embedding-based or tuple-based loss. This means that internally, there is no real notion of \"classes\". Tuples (pairs or triplets) are formed at each iteration, based on the labels it receives. The labels don't have to represent classes. They simply need to indicate the positive and negative relationships between the embeddings. Thus, it is easy to use these loss functions for unsupervised or self-supervised learning.  \nFor example, the code below is a simplified version of the augmentation strategy commonly used in self-supervision. The dataset does not come with any labels. Instead, the labels are created in the training loop, solely to indicate which embeddings are positive pairs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9813385508298789
      ],
      "excerpt": "for i, data in enumerate(dataloader): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "    embeddings = your_model(data) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9236345501967175
      ],
      "excerpt": "To compute the accuracy of an embedding space directly, use AccuracyCalculator. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9960126263436702
      ],
      "excerpt": "To learn more about all of the above, see the documentation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8508628761559929,
        0.93546629391903
      ],
      "excerpt": "See powerful-benchmarker to view benchmark results and to use the benchmarking tool. \nDevelopment is done on the dev branch: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860203902355468
      ],
      "excerpt": "Code is formatted using black and isort: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9791536035068348
      ],
      "excerpt": "Thank you to Ser-Nam Lim at Facebook AI, and my research advisor, Professor Serge Belongie. This project began during my internship at Facebook AI where I received valuable feedback from Ser-Nam, and his team of computer vision and machine learning engineers and research scientists. In particular, thanks to Ashish Shah and Austin Reiter for reviewing my code during its early stages of development. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "The easiest way to use deep metric learning in your application. Modular, flexible, and extensible. Written in PyTorch.",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [**View the documentation here**](https://kevinmusgrave.github.io/pytorch-metric-learning/)\n- [**View the installation instructions here**](https://github.com/KevinMusgrave/pytorch-metric-learning#installation)\n- [**View the available losses, miners etc. here**](https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/CONTENTS.md) \n\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 495,
      "date": "Sun, 26 Dec 2021 02:13:40 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "KevinMusgrave/pytorch-metric-learning",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/KevinMusgrave/pytorch-metric-learning/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/examples/notebooks/TripletMarginLossMNIST.ipynb",
      "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/examples/notebooks/scRNAseq_MetricEmbedding.ipynb",
      "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/examples/notebooks/TrainWithClassifier.ipynb",
      "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/examples/notebooks/TwoStreamMetricLoss.ipynb",
      "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/examples/notebooks/MetricLossOnly.ipynb",
      "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/examples/notebooks/MoCoCIFAR10.ipynb",
      "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/examples/notebooks/Inference.ipynb",
      "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/examples/notebooks/DeepAdversarialMetricLearning.ipynb",
      "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/examples/notebooks/DistributedTripletMarginLossMNIST.ipynb",
      "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/examples/notebooks/CascadedEmbeddings.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/format_code.sh",
      "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/run_linter.sh",
      "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/build_script.sh",
      "https://raw.githubusercontent.com/KevinMusgrave/pytorch-metric-learning/master/conda_build/build-conda-package.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8129294503358236
      ],
      "excerpt": "- See the release notes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8129294503358236
      ],
      "excerpt": "- See the release notes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8129294503358236
      ],
      "excerpt": "- See the release notes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8046581051557958,
        0.8553133683029048,
        0.9945769513671279
      ],
      "excerpt": "pytorch-metric-learning &lt; v0.9.90 doesn't have a version requirement, but was tested with torch &gt;= 1.2 \nOther dependencies: numpy, scikit-learn, tqdm, torchvision \npip install pytorch-metric-learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9639150279042925
      ],
      "excerpt": "**To get the latest dev version**: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9910563315648471
      ],
      "excerpt": "pip install pytorch-metric-learning --pre \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9968453487016813
      ],
      "excerpt": "**To install on Windows**: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.983740791831395,
        0.9945769513671279
      ],
      "excerpt": "pip install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html \npip install pytorch-metric-learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9753683992835133
      ],
      "excerpt": "(This will install the unofficial pypi version of faiss-gpu, plus record-keeper and tensorboard): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9942149876020039
      ],
      "excerpt": "pip install pytorch-metric-learning[with-hooks] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9391239492505502
      ],
      "excerpt": "(This will install the unofficial pypi version of faiss-cpu, plus record-keeper and tensorboard): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9924424639191908
      ],
      "excerpt": "pip install pytorch-metric-learning[with-hooks-cpu] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9686385995081078,
        0.9791791740860556
      ],
      "excerpt": "conda install pytorch-metric-learning -c metric-learning -c pytorch \nTo use the testing module, you'll need faiss, which can be installed via conda as well. See the installation instructions for faiss. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9132396647081804
      ],
      "excerpt": "git checkout dev \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9715455482099228
      ],
      "excerpt": "pip install black isort \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8918974083095406,
        0.9268010257834752,
        0.825406370458964
      ],
      "excerpt": "- https://github.com/bnu-wangxun/Deep_Metric \n- https://github.com/chaoyuaw/incubator-mxnet/blob/master/example/gluon/embedding_learning \n- https://github.com/facebookresearch/deepcluster \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8918974083095406
      ],
      "excerpt": "- https://github.com/idstcv/SoftTriple \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8918974083095406,
        0.8918974083095406
      ],
      "excerpt": "- https://github.com/ronekko/deep_metric_learning \n- https://github.com/tjddus9597/Proxy-Anchor-CVPR2020 \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8361406602442122
      ],
      "excerpt": "from pytorch_metric_learning import losses \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8248328724624491
      ],
      "excerpt": "    embeddings = model(data) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8361406602442122
      ],
      "excerpt": "from pytorch_metric_learning import miners, losses \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8248328724624491
      ],
      "excerpt": "    embeddings = model(data) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661687897966859
      ],
      "excerpt": "Now here's an example of a customized TripletMarginLoss: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516,
        0.8801854956928516,
        0.8801854956928516,
        0.8361406602442122
      ],
      "excerpt": "from pytorch_metric_learning.distances import CosineSimilarity \nfrom pytorch_metric_learning.reducers import ThresholdReducer \nfrom pytorch_metric_learning.regularizers import LpRegularizer \nfrom pytorch_metric_learning import losses \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8084442207102762
      ],
      "excerpt": "Want to test your model's accuracy on a dataset? Try the testers. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8563945280014043
      ],
      "excerpt": "Unit tests can be run with the default unittest library: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9038065954923875
      ],
      "excerpt": "To run a single test file instead of the entire test suite, specify the file name: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9170998533847409
      ],
      "excerpt": "python -m unittest tests/losses/test_angular_loss.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "Batchfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\r\\n\\r\\nCopyright (c) 2019 Kevin Musgrave\\r\\n\\r\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\r\\nof this software and associated documentation files (the \"Software\"), to deal\\r\\nin the Software without restriction, including without limitation the rights\\r\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\r\\ncopies of the Software, and to permit persons to whom the Software is\\r\\nfurnished to do so, subject to the following conditions:\\r\\n\\r\\nThe above copyright notice and this permission notice shall be included in all\\r\\ncopies or substantial portions of the Software.\\r\\n\\r\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\r\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\r\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\r\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\r\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\r\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\r\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# News",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pytorch-metric-learning",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "KevinMusgrave",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "## Reference embeddings for tuple losses\r\nYou can separate the source of anchors and positive/negatives. In the example below, anchors will be selected from ```embeddings``` and positives/negatives will be selected from ```ref_emb```.\r\n\r\n```python\r\nloss_fn = TripletMarginLoss()\r\nloss = loss_fn(embeddings, labels, ref_emb=ref_emb, ref_labels=ref_labels)\r\n```\r\n\r\n## Efficient mode for DistributedLossWrapper\r\n- ```efficient=True```: each process uses its own embeddings for anchors, and the gathered embeddings for positives/negatives. Gradients will **not** be equal to those in non-distributed code, but the benefit is reduced memory and faster training.\r\n- ```efficient=False```: each process uses gathered embeddings for both anchors and positives/negatives. Gradients will be equal to those in non-distributed code, but at the cost of doing unnecessary operations (i.e. doing computations where both anchors and positives/negatives have no gradient).\r\n\r\nThe default is ```False```. You can set it to ```True``` like this:\r\n\r\n```python\r\nfrom pytorch_metric_learning import losses\r\nfrom pytorch_metric_learning.utils import distributed as pml_dist\r\n\r\nloss_func = losses.ContrastiveLoss()\r\nloss_func = pml_dist.DistributedLossWrapper(loss_func, efficient=True)\r\n```\r\nDocumentation: https://kevinmusgrave.github.io/pytorch-metric-learning/distributed/\r\n\r\n## Customizing k-nearest-neighbors for AccuracyCalculator\r\nYou can use a different type of faiss index:\r\n```python\r\nimport faiss\r\nfrom pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\r\nfrom pytorch_metric_learning.utils.inference import FaissKNN\r\n\r\nknn_func = FaissKNN(index_init_fn=faiss.IndexFlatIP, gpus=[0,1,2])\r\nac = AccuracyCalculator(knn_func=knn_func)\r\n```\r\n\r\nYou can also use a custom distance function:\r\n```python\r\nfrom pytorch_metric_learning.distances import SNRDistance\r\nfrom pytorch_metric_learning.utils.inference import CustomKNN\r\n\r\nknn_func = CustomKNN(SNRDistance())\r\nac = AccuracyCalculator(knn_func=knn_func)\r\n```\r\n\r\nRelevant docs:\r\n- [Accuracy Calculation](https://kevinmusgrave.github.io/pytorch-metric-learning/accuracy_calculation/)\r\n- [FaissKNN](https://kevinmusgrave.github.io/pytorch-metric-learning/inference_models/#faissknn)\r\n- [CustomKNN](https://kevinmusgrave.github.io/pytorch-metric-learning/inference_models/#customknn)\r\n\r\n\r\n## Issues resolved\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/204\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/251\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/256\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/292\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/330\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/337\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/345\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/347\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/349\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/353\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/359\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/361\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/362\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/363\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/368\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/376\r\nhttps://github.com/KevinMusgrave/pytorch-metric-learning/issues/380\r\n\r\n## Contributors\r\nThanks to @yutanakamura-tky and @KinglittleQ for pull requests, and @mensaochun for providing helpful code in #380\r\n",
        "dateCreated": "2021-11-28T19:41:07Z",
        "datePublished": "2021-11-28T20:20:55Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v1.0.0",
        "name": "v1.0.0",
        "tag_name": "v1.0.0",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v1.0.0",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/54199920",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v1.0.0"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "## Bug fixes\r\n\r\n- Accuracy Calculation bug in GlobalTwoStreamEmbeddingSpaceTester (#301)\r\n- Mixed precision bug in ```convert_to_weights``` (#300)\r\n\r\n## Features\r\n\r\n- [HierarchicalSampler](https://kevinmusgrave.github.io/pytorch-metric-learning/samplers/#hierarchicalsampler)\r\n- Improved functionality for [InferenceModel](https://kevinmusgrave.github.io/pytorch-metric-learning/inference_models/#inferencemodel) (#296 and #304)\r\n  - ```train_indexer``` now accepts a dataset\r\n  - also added functions ```save_index```, ```load_index```, and ```add_to_indexer```\r\n- Added ```power``` argument to LpRegularizer (#299)\r\n- Return exception if ```labels``` has more than 1 dimension (#307)\r\n- [Added a global flag](https://kevinmusgrave.github.io/pytorch-metric-learning/common_functions/#collect_stats) for turning on/off ```collect_stats``` (#311)\r\n- TripletMarginLoss smooth variant uses the input margin now (#315)\r\n- [Use package-specific logger, \"PML\"](https://kevinmusgrave.github.io/pytorch-metric-learning/common_functions/#logger), instead of root logger (#318)\r\n- Cleaner key verification in the trainers (#102)\r\n\r\nThanks to @elias-ramzi, @gkouros, @vltanh, and @Hummer12007",
        "dateCreated": "2021-05-10T02:50:39Z",
        "datePublished": "2021-05-10T02:52:47Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.99",
        "name": "v0.9.99",
        "tag_name": "v0.9.99",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.99",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/42676779",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.99"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "# AccuracyCalculator breaking change (issue #290)\r\nThe ```k``` parameter in AccuracyCalculator has a new behavior. The allowed values are:\r\n\r\n * ```None```. This means k will be set to the total number of reference embeddings.\r\n * An integer greater than 0. This means k will be set to the input integer.\r\n * ```\"max_bin_count\"```. This means k will be set to ```max(bincount(reference_labels)) - self_count``` where ```self_count == 1``` if the query and reference embeddings come from the same source.\r\n\r\nThe old behavior is described [here](https://kevinmusgrave.github.io/pytorch-metric-learning/accuracy_calculation/#warning-for-versions-0997).\r\n\r\nIf your dataset is large, you might find the k-nn search is now very slow. This is because the new default behavior is to set k to ```len(reference_embeddings)```. To avoid this, you can set k to a number, like ```k = 1000``` or try ```k = \"max_bin_count\"``` to get behavior similar (though not identical) to the old default.\r\n\r\nApologies for the drastic change. I'm hoping to have things stable and following semantic versioning when v1.0 arrives.\r\n\r\n\r\n# Bug fixes\r\n* ```lmu.convert_to_triplets``` has been fixed (#291)\r\n* Losses and miners should now be compatible with autocast (#293)\r\n\r\n# New features / improvements\r\n* The loss used in [Supervised Contrastive Learning](https://arxiv.org/abs/2004.11362). Documentation: [SupConLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#supconloss). By @fjsj (#281, #288)\r\n* Vectorized ```convert_to_triplets``` (#279)",
        "dateCreated": "2021-04-03T00:11:57Z",
        "datePublished": "2021-04-03T00:20:04Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.98",
        "name": "v0.9.98",
        "tag_name": "v0.9.98",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.98",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/40889426",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.98"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "# Bug fixes\r\n - Small fix for NTXentLoss with no negative pairs #272\r\n - Fixed .detach() bug in NTXentLoss #282 \r\n - Fixed parameter override bug in MatchFinder.get_matching_pairs() #286 by @joaqo \r\n\r\n# New features and improvements\r\n\r\n## AccuracyCalculator now uses torch instead of numpy\r\n- All the calculations (except for NMI and AMI) are done with torch. Calculations will be done on the same device and dtype as the input query tensor.\r\n- You can still pass numpy arrays into ```AccuracyCalculator.get_accuracy```, but the arrays will be immediately converted to torch tensors.\r\n\r\n## Faster custom label comparisons in AccuracyCalculator\r\n- See #264 by @mlopezantequera\r\n\r\n## Numerical stability improvement for DistanceWeightedMiner\r\nSee #278 by @z1w \r\n\r\n## UniformHistogramMiner\r\nThis is like DistanceWeightedMiner, except that it works well with high dimension embeddings, and works with any distance metric (not just L2 normalized distance). [Documentation](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#uniformhistogramminer)\r\n\r\n## PerAnchorReducer\r\nThis converts unreduced pairs to unreduced elements. For example, NTXentLoss returns losses per positive pair. If you used PerAnchorReducer with NTXentLoss, then the losses per pair would first be converted to losses per batch element, before being passed to the inner reducer. See the [documentation](https://kevinmusgrave.github.io/pytorch-metric-learning/reducers/#peranchorreducer)\r\n\r\n## BaseTester no longer converts embeddings from torch to numpy\r\nThis includes the ```get_all_embeddings``` function. If you want ```get_all_embeddings``` to return numpy arrays, you can set the ```return_as_numpy``` flag to True:\r\n```python\r\nembeddings, labels = tester.get_all_embeddings(dataset, model, return_as_numpy=True)\r\n```\r\nThe embeddings are converted to numpy only for the ```visualizer``` and ```visualizer_hook```, if specified.\r\n\r\n## Reduced usage of .to(device) and .type(dtype) \r\nTensors are initialized on device and with the necessary dtype, and they are moved to device and cast to dtypes only when necessary. See [this code snippet](https://github.com/KevinMusgrave/pytorch-metric-learning/blob/3c354998a218409d3ac6f00a9662696acf97ff96/src/pytorch_metric_learning/utils/common_functions.py#L460-L473) for details.\r\n\r\n## Simplified DivisorReducer\r\nReplaced \"divisor_summands\" with \"divisor\".",
        "dateCreated": "2021-03-04T00:45:23Z",
        "datePublished": "2021-03-04T00:46:21Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.97",
        "name": "v0.9.97",
        "tag_name": "v0.9.97",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.97",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/39236049",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.97"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "# New Features\r\n\r\nThanks to @mlopezantequera for adding the following features!\r\n\r\n## Testers: allow any combination of query and reference sets (#250)\r\nTo evaluate different combinations of query and reference sets, use the ```splits_to_eval``` argument for ```tester.test()```.\r\n\r\nFor example, let's say your ```dataset_dict``` has two keys: ```\"dataset_a\"``` and ```\"train\"```.\r\n\r\n- The default ```splits_to_eval = None``` is equivalent to: \r\n```python\r\nsplits_to_eval = [('dataset_a', ['dataset_a']), ('train', ['train'])]\r\n```\r\n- ```dataset_a``` as the query, and ```train``` as the reference: \r\n```python\r\nsplits_to_eval = [('dataset_a', ['train'])]\r\n```\r\n- ```dataset_a``` as the query, and ```dataset_a``` + ```train``` as the reference: \r\n```python\r\nsplits_to_eval = [('dataset_a', ['dataset_a', 'train'])]\r\n```\r\n\r\nThen pass ```splits_to_eval``` to ```tester.test```:\r\n```python\r\ntester.test(dataset_dict, epoch, model, splits_to_eval = splits_to_eval)\r\n```\r\n\r\nNote that this new feature makes the old ```reference_set``` init argument obsolete, so ```reference_set``` has been removed. \r\n\r\n\r\n\r\n## AccuracyCalculator: allow arbitrary label comparion functions (#254)\r\nAccuracyCalculator now has an optional init argument, ```label_comparison_fn```, which is a function that compares two numpy arrays of labels and returns a boolean array. The default is ```numpy.equal```. If a custom function is used, then you must exclude clustering based metrics (\"NMI\" and \"AMI\"). The following is an example of a custom function for two-dimensional labels. It returns ```True``` if the 0th column matches, and the 1st column does **not** match:\r\n```python\r\ndef example_label_comparison_fn(x, y):\r\n    return (x[:, 0] == y[:, 0]) & (x[:, 1] != y[:, 1])\r\n\r\nAccuracyCalculator(exclude=(\"NMI\", \"AMI\"), \r\n                    label_comparison_fn=example_label_comparison_fn)\r\n```\r\n\r\n# Other Changes\r\n\r\n- BaseTrainer and BaseTester now take in an optional ```dtype``` argument. This is the type that the dataset output will be converted to, e.g. ```torch.float16```. If set to the default value of ```None```, then no type casting will be done.\r\n- Removed ```self.dim_reduced_embeddings``` from BaseTester and the associated code in ```HookContainer```, due to lack of use.\r\n- ```tester.test()``` now returns ```all_accuracies```, whereas before, it returned nothing and you'd have to access ```all_accuracies``` either through the ```end_of_testing_hook``` or by accessing ```tester.all_accuracies```.\r\n- ```tester.embeddings_and_labels``` is deleted at the end of ```tester.test()``` to free up memory.",
        "dateCreated": "2021-01-12T13:46:34Z",
        "datePublished": "2021-01-12T14:49:11Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.96",
        "name": "v0.9.96",
        "tag_name": "v0.9.96",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.96",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/36151002",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.96"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "# New\r\n\r\n## BatchEasyHardMiner\r\nThis new miner is an implementation of [Improved Embeddings with Easy Positive Triplet Mining](https://openaccess.thecvf.com/content_WACV_2020/papers/Xuan_Improved_Embeddings_with_Easy_Positive_Triplet_Mining_WACV_2020_paper.pdf). See [the documentation](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/#batcheasyhardminer). Thanks @marijnl!\r\n\r\n##  New metric added to AccuracyCalculator\r\nThe new metric is ```mean_average_precision```, which is the commonly used k-nn based mAP in information retrieval. \r\nNote that this differs from the already existing metric, ```mean_average_precision_at_r```.\r\n\r\n# Bug fixes\r\n\r\n- dtype casting in MultiSimilarityMiner changed to work with autocast. See #233 by @thinline72 \r\n- Added logic for dealing with zero rows in the weight matrix in DistanceWeightedMiner by ignoring them. For example, if the entire weight matrix is 0, then no triplets will be returned. Previously, the zero rows would cause a RuntimeError. See #230 by @tpanum\r\n",
        "dateCreated": "2020-12-11T04:58:11Z",
        "datePublished": "2020-12-11T05:13:08Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.95",
        "name": "v0.9.95",
        "tag_name": "v0.9.95",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.95",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/35135849",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.95"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "## Various bug fixes and improvements\r\n\r\n- A list or dictionary of miners can be passed into MultipleLosses. #212\r\n- Fixed bug where MultipleLosses failed in list mode. #213 \r\n- Fixed bug where IntraPairVarianceLoss and MarginLoss were overriding ```sub_loss_names``` instead of ```_sub_loss_names```. This likely caused embedding regularizers to have no effect for these two losses. #215\r\n- ModuleWithRecordsAndReducer now creates copies of the input reducer when necessary. #216 \r\n- Moved ```cos.clone()``` inside ```torch.no_grad()``` in RegularFaceRegularizer. Should be more efficient? #219 \r\n- In utils.inference, moved faiss import inside of FaissIndexer since that is the only class that requires it. #222\r\n- Added a ```copy_weights``` init argument to LogitGetter, to make copying optional #223\r\n",
        "dateCreated": "2020-11-06T22:43:13Z",
        "datePublished": "2020-11-06T22:51:18Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.94",
        "name": "v0.9.94",
        "tag_name": "v0.9.94",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.94",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/33588457",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.94"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "# Small update\r\n\r\n- Optimized ```get_random_triplet_indices```, so if you were using DistanceWeightedMiner, or if you ever set the ```triplets_per_anchor``` argument to something other than ```\"all\"``` anywhere in your code, it should run a lot faster now. Thanks @AlexSchuy ",
        "dateCreated": "2020-10-06T08:30:01Z",
        "datePublished": "2020-10-06T08:46:14Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.93",
        "name": "v0.9.93",
        "tag_name": "v0.9.93",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.93",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/32204515",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.93"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "# New Features\r\n\r\n### DistributedLossWrapper and DistributedMinerWrapper\r\nAdded [DistributedLossWrapper and DistributedMinerWrapper](https://kevinmusgrave.github.io/pytorch-metric-learning/distributed). Wrap a loss or miner with these when using PyTorch's DistributedDataParallel (i.e. multiprocessing). Most of the code is by @JohnGiorgi (https://github.com/JohnGiorgi/DeCLUTR).\r\n\r\n```python\r\nfrom pytorch_metric_learning import losses, miners\r\nfrom pytorch_metric_learning.utils import distributed as pml_dist\r\nloss_func = pml_dist.DistributedLossWrapper(loss = losses.ContrastiveLoss())\r\nminer = pml_dist.DistributedMinerWrapper(miner = miners.MultiSimilarityMiner())\r\n```\r\n\r\nFor a working example, see the [\"Multiprocessing with DistributedDataParallel\"](https://github.com/KevinMusgrave/pytorch-metric-learning/tree/master/examples#simple-examples) notebook.\r\n\r\n### Added ```enqueue_idx``` to CrossBatchMemory \r\nNow you can make CrossBatchMemory work with [MoCo](https://arxiv.org/pdf/1911.05722.pdf). This adds a great deal of flexibility to the MoCo framework, because you can use any tuple loss and tuple miner in CrossBatchMemory. \r\n\r\nPreviously this wasn't possible because all embeddings passed into CrossBatchMemory would go into the memory queue. In contrast, MoCo only queues the momentum encoder's embeddings. \r\n\r\nThe new ```enqueue_idx``` argument lets you do this, by specifying which embeddings should be added to memory. Here's a modified snippet from the [MoCo on CIFAR10](https://github.com/KevinMusgrave/pytorch-metric-learning/tree/master/examples#simple-examples) notebook:\r\n```python\r\nfrom pytorch_metric_learning.losses import CrossBatchMemory, NTXentLoss\r\n\r\nloss_fn = CrossBatchMemory(loss = NTXentLoss(), embedding_size = 64, memory_size = 16384)\r\n\r\n### snippet from the training loop ###\r\nfor images, _ in train_loader:\r\n  ...\r\n  previous_max_label = torch.max(loss_fn.label_memory)\r\n  num_pos_pairs = encQ_out.size(0)\r\n  labels = torch.arange(0, num_pos_pairs)\r\n  labels = torch.cat((labels , labels)).to(device)\r\n\r\n  ### add an offset so that the labels do not overlap with any labels in the memory queue ###\r\n  labels += previous_max_label + 1\r\n\r\n  ### we want to enqueue the output of encK, which is the 2nd half of the batch ###\r\n  enqueue_idx = torch.arange(num_pos_pairs, num_pos_pairs*2)\r\n\r\n  all_enc = torch.cat([encQ_out, encK_out], dim=0)\r\n\r\n  ### now only encK_out will be added to the memory queue ###\r\n  loss = loss_fn(all_enc, labels, enqueue_idx = enqueue_idx)\r\n  ...\r\n```\r\n\r\nCheck out the [MoCo on CIFAR10](https://github.com/KevinMusgrave/pytorch-metric-learning/tree/master/examples#simple-examples) notebook to see the entire script.\r\n\r\n\r\n### TuplesToWeightsSampler\r\nThis is a [simple offline miner](https://kevinmusgrave.github.io/pytorch-metric-learning/samplers/#tuplestoweightssampler). It does the following:\r\n1. Take a random subset of your dataset, if you provide ```subset_size```\r\n2. Use a specified miner to mine tuples from the subset dataset.\r\n3. Compute weights based on how often an element appears in the mined tuples.\r\n4. Randomly sample, using the weights as probabilities.\r\n\r\n```python\r\nfrom pytorch_metric_learning.samplers import TuplesToWeightsSampler\r\nfrom pytorch_metric_learning.miners import MultiSimilarityMiner\r\n\r\nminer = MultiSimilarityMiner(epsilon=-0.2)\r\nsampler = TuplesToWeightsSampler(model, miner, dataset, subset_size = 5000)\r\n# then pass the sampler into your Dataloader\r\n```\r\n\r\n### LogitGetter\r\nAdded [utils.inference.LogitGetter](https://kevinmusgrave.github.io/pytorch-metric-learning/inference_models/#logitgetter) to make it easier to compute logits of classifier loss functions.\r\n```python\r\nfrom pytorch_metric_learning.losses import ArcFaceLoss\r\nfrom pytorch_metric_learning.utils.inference import LogitGetter\r\n\r\nloss_fn = ArcFaceLoss(num_classes = 100, embedding_size = 512)\r\nLG = LogitGetter(loss_fn)\r\nlogits = LG(embeddings)\r\n```\r\n\r\n### Other\r\n - Added optional ```batch_size``` argument to MPerClassSampler. If you pass in this argument, then each batch is guaranteed to have ```m``` samples per class. Otherwise, most batches will have ```m``` samples per class, but it's not guaranteed for every batch. Note there restrictions on the values of ```m``` and ```batch_size```. For example, ```batch_size``` must be a multiple of ```m```. For all the restrictions, see [the documentation](https://kevinmusgrave.github.io/pytorch-metric-learning/samplers/#mperclasssampler).\r\n\r\n - Added ```trainable_attributes``` to BaseTrainer and to standardize the ```set_to_train``` and ```set_to_eval``` functions.\r\n\r\n - Added ```save_models``` init argument to HookContainer. If set to ```False``` then models will not be saved.\r\n\r\n - Added ```losses_sizes``` as a stat for BaseReducer\r\n\r\n - Added a type check and conversion in ```common_functions.labels_to_indices``` to go from torch tensor to numpy\r\n\r\n\r\n",
        "dateCreated": "2020-09-14T09:53:12Z",
        "datePublished": "2020-09-14T09:53:59Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.92",
        "name": "v0.9.92",
        "tag_name": "v0.9.92",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.92",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/31227968",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.92"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "# Bug Fixes and Improvements\r\n- Fixed CircleLoss bug, by improving the ```logsumexp``` ```keep_mask``` implementation. See https://github.com/KevinMusgrave/pytorch-metric-learning/issues/173\r\n- Fixed convert_to_weights bug, which caused a runtime error when an empty ```indices_tuple``` was passed in. See https://github.com/KevinMusgrave/pytorch-metric-learning/issues/174\r\n- ProxyAnchorLoss now adds miner weights to the exponents which are fed to ```logsumexp```. This is equivalent to scaling each loss component by ```e^(miner_weight)```. The previous behavior was to scale each loss component by just ```miner_weight```. \r\n\r\n# Other updates\r\n- Added an [example notebook](https://github.com/KevinMusgrave/pytorch-metric-learning/tree/master/examples#simple-examples) which shows how to use a customized loss + miner in a simple training loop.\r\n- A new [arxiv paper](https://arxiv.org/abs/2008.09164) and an improved Readme give a better high level explanation of the library.\r\n- Added better explanations for the [testers](https://kevinmusgrave.github.io/pytorch-metric-learning/testers/) and the [default accuracy metrics](https://kevinmusgrave.github.io/pytorch-metric-learning/accuracy_calculation/#explanations-of-the-default-accuracy-metrics)",
        "dateCreated": "2020-08-31T12:52:25Z",
        "datePublished": "2020-08-31T13:04:57Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.91",
        "name": "v0.9.91",
        "tag_name": "v0.9.91",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.91",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/30433674",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.91"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "# ********** Summary **********\r\nThe main update is the new distances module, which adds an extra level of modularity to loss functions. It is a pretty big design change, which is why so many arguments have become obsolete. See [the documentation](https://kevinmusgrave.github.io/pytorch-metric-learning/distances/) for a description of the new module.\r\n\r\nOther updates  include support for half-precision, new regularizers and mixins, improved documentation, and default values for most initialization parameters.\r\n\r\n\r\n# ********** Breaking Changes **********\r\n\r\n## Dependencies\r\nThis library now requires PyTorch >= 1.6.0. Previously there was no explicit version requirement.\r\n\r\n## Losses and Miners\r\n### All loss functions\r\n#### ```normalize_embeddings``` has been removed\r\n - If you never used this argument, nothing needs to be done.\r\n - ```normalize_embeddings = True```: just remove the argument.\r\n - ```normalize_embeddings = False```: remove the argument and instead pass it into a ```distance``` object. For example:\r\n```python\r\nfrom pytorch_metric_learning.distances import LpDistance\r\nloss_func = TripletMarginLoss(distance=LpDistance(normalize_embeddings=False))\r\n```\r\n\r\n### ContrastiveLoss, GenericPairLoss, BatchHardMiner, HDCMiner, PairMarginMiner\r\n#### ```use_similarity``` has been removed\r\n - If you never used this argument, nothing needs to be done.\r\n - ```use_similarity = True```: remove the argument and:\r\n```python\r\n### if you had set normalize_embeddings = False ###\r\nfrom pytorch_metric_learning.distances import DotProductSimilarity\r\nloss_func = ContrastiveLoss(distance=DotProductSimilarity(normalize_embeddings=False))\r\n\r\n#### otherwise ###\r\nfrom pytorch_metric_learning.distances import CosineSimilarity\r\nloss_func = ContrastiveLoss(distance=CosineSimilarity())\r\n```\r\n\r\n#### ```squared_distances``` has been removed\r\n - If you never used this argument, nothing needs to be done.\r\n - ```squared_distances = True```: remove the argument and instead pass ```power=2``` into a ```distance``` object. For example:\r\n```python\r\nfrom pytorch_metric_learning.distances import LpDistance\r\nloss_func = ContrastiveLoss(distance=LpDistance(power=2))\r\n```\r\n - ```squared_distances = False```: just remove the argument.\r\n\r\n### ContrastiveLoss, TripletMarginLoss\r\n#### ```power``` has been removed\r\n - If you never used this argument, nothing needs to be done.\r\n - ```power = 1```: just remove the argument\r\n - ```power = X, where X != 1```: remove the argument and instead pass it into a ```distance``` object. For example:\r\n```python\r\nfrom pytorch_metric_learning.distances import LpDistance\r\nloss_func = TripletMarginLoss(distance=LpDistance(power=2))\r\n```\r\n\r\n### TripletMarginLoss\r\n#### ```distance_norm``` has been removed\r\n - If you never used this argument, nothing needs to be done.\r\n - ```distance_norm = 2```: just remove the argument\r\n - ```distance_norm = X, where X != 2```: remove the argument and instead pass it as ```p``` into a ```distance``` object. For example:\r\n```python\r\nfrom pytorch_metric_learning.distances import LpDistance\r\nloss_func = TripletMarginLoss(distance=LpDistance(p=1))\r\n```\r\n\r\n### NPairsLoss\r\n#### ```l2_reg_weight``` has been removed\r\n - If you never used this argument, nothing needs to be done.\r\n - ```l2_reg_weight = 0```: just remove the argument\r\n - ```l2_reg_weight = X, where X > 0```: remove the argument and instead pass in an ```LpRegularizer``` and weight:\r\n```python\r\nfrom pytorch_metric_learning.regularizers import LpRegularizer\r\nloss_func = NPairsLoss(embedding_regularizer=LpRegularizer(), embedding_reg_weight=0.123)\r\n```\r\n\r\n### SignalToNoiseRatioContrastiveLoss\r\n#### ```regularizer_weight``` has been removed\r\n - If you never used this argument, nothing needs to be done.\r\n - ```regularizer_weight = 0```: just remove the argument\r\n - ```regularizer_weight = X, where X > 0```: remove the argument and instead pass in a ```ZeroMeanRegularizer``` and weight:\r\n```python\r\nfrom pytorch_metric_learning.regularizers import LpRegularizer\r\nloss_func = SignalToNoiseRatioContrastiveLoss(embedding_regularizer=ZeroMeanRegularizer(), embedding_reg_weight=0.123)\r\n```\r\n\r\n### SoftTripleLoss\r\n#### ```reg_weight``` has been removed\r\n - If you never used this argument, do the following to obtain the same default behavior:\r\n```python\r\nfrom pytorch_metric_learning.regularizers import SparseCentersRegularizer\r\nweight_regularizer = SparseCentersRegularizer(num_classes, centers_per_class)\r\nSoftTripleLoss(..., weight_regularizer=weight_regularizer, weight_reg_weight=0.2)\r\n```\r\n - ```reg_weight = X```: remove the argument, and use the ```SparseCenterRegularizer``` as shown above.\r\n\r\n### WeightRegularizerMixin and all classification loss functions\r\n- If you never specified ```regularizer``` or ```reg_weight```, nothing needs to be done.\r\n- ```regularizer = X```: replace with ```weight_regularizer = X```\r\n- ```reg_weight = X```: replace with ```weight_reg_weight = X```\r\n\r\n### Classification losses\r\n- For all losses and miners, default values have been set for as many arguments as possible. This has caused a change in ordering in positional arguments for several of the classification losses. The typical form is now:\r\n```python\r\nloss_func = SomeClassificatinLoss(num_classes, embedding_loss, <keyword arguments>)\r\n```\r\nSee the documentation for specifics\r\n\r\n## Reducers\r\n### ThresholdReducer\r\n```threshold``` has been replaced by ```low``` and ```high```\r\n- Replace ```threshold = X``` with ```low = X```\r\n\r\n## Regularizers\r\n### All regularizers\r\n#### ```normalize_weights``` has been removed\r\n - If you never used this argument, nothing needs to be done.\r\n - ```normalize_weights = True```: just remove the argument.\r\n - ```normalize_weights = False```: remove the argument and instead pass ```normalize_embeddings = False``` into a ```distance``` object. For example:\r\n```python\r\nfrom pytorch_metric_learning.distances import DotProductSimilarity\r\nloss_func = RegularFaceRegularizer(distance=DotProductSimilarity(normalize_embeddings=False))\r\n```\r\n\r\n## Inference\r\n\r\n### MatchFinder\r\n#### ```mode``` has been removed\r\n- Replace ```mode=\"sim\"``` with either ```distance=CosineSimilarity()``` or ```distance=DotProductSimilarity()```\r\n- Replace ```mode=\"dist\"``` with ```distance=LpDistance()```\r\n- Replace ```mode=\"squared_dist\"``` with ```distance=LpDistance(power=2)```\r\n\r\n\r\n\r\n# ********** New Features **********\r\n## Distances \r\nDistances bring an additional level of modularity to building loss functions. Here's an example of how they work. \r\n\r\nConsider the TripletMarginLoss in its default form:\r\n```python\r\nfrom pytorch_metric_learning.losses import TripletMarginLoss\r\nloss_func = TripletMarginLoss(margin=0.2)\r\n```\r\nThis loss function attempts to minimize [d<sub>ap</sub> - d<sub>an</sub> + margin]<sub>+</sub>.\r\n\r\nIn other words, it tries to make the anchor-positive distances (d<sub>ap</sub>) smaller than the anchor-negative distances (d<sub>an</sub>).\r\n\r\nTypically, d<sub>ap</sub> and d<sub>an</sub> represent Euclidean or L2 distances. But what if we want to use a squared L2 distance, or an unnormalized L1 distance, or completely different distance measure like signal-to-noise ratio? With the distances module, you can try out these ideas easily:\r\n```python\r\n### TripletMarginLoss with squared L2 distance ###\r\nfrom pytorch_metric_learning.distances import LpDistance\r\nloss_func = TripletMarginLoss(margin=0.2, distance=LpDistance(power=2))\r\n\r\n### TripletMarginLoss with unnormalized L1 distance ###\r\nloss_func = TripletMarginLoss(margin=0.2, distance=LpDistance(normalize_embeddings=False, p=1))\r\n\r\n### TripletMarginLoss with signal-to-noise ratio###\r\nfrom pytorch_metric_learning.distances import SNRDistance\r\nloss_func = TripletMarginLoss(margin=0.2, distance=SNRDistance())\r\n```\r\n\r\nYou can also use similarity measures rather than distances, and the loss function will make the necessary adjustments:\r\n```python\r\n### TripletMarginLoss with cosine similarity##\r\nfrom pytorch_metric_learning.distances import CosineSimilarity\r\nloss_func = TripletMarginLoss(margin=0.2, distance=CosineSimilarity())\r\n```\r\nWith a similarity measure, the TripletMarginLoss internally swaps the anchor-positive and anchor-negative terms: [s<sub>an</sub> - s<sub>ap</sub> + margin]<sub>+</sub>. In other words, it will try to make the anchor-negative similarities smaller than the anchor-positive similarities.\r\n\r\nAll **losses, miners, and regularizers** accept a ```distance``` argument. So you can try out the ```MultiSimilarityMiner``` using ```SNRDistance```, or the ```NTXentLoss``` using ```LpDistance(p=1)``` and so on. Note that some losses/miners/regularizers have restrictions on the type of distances they can accept. For example, some classification losses only allow ```CosineSimilarity``` or ```DotProductSimilarity``` as their distance measure between embeddings and weights. To view restrictions for specific loss functions, see [the documentation](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/)\r\n\r\nThere are four distances implemented (LpDistance, SNRDistance, CosineSimilarity, DotProductSimilarity), but of course you can extend the BaseDistance class and write a custom distance measure if you want. See [the documentation](https://kevinmusgrave.github.io/pytorch-metric-learning/distances/) for more.\r\n\r\n## EmbeddingRegularizerMixin\r\nAll loss functions now extend ```EmbeddingRegularizerMixin```, which means you can optionally pass in (to any loss function) an embedding regularizer and its weight. The embedding regularizer will compute some loss based on the embeddings alone, ignoring labels and tuples. For example:\r\n```python\r\nfrom pytorch_metric_learning.regularizers import LpRegularizer\r\nloss_func = MultiSimilarityLoss(embedding_regularizer=LpRegularizer(), embedding_reg_weight=0.123)\r\n```\r\n\r\n## WeightRegularizerMixin is now a subclass of WeightMixin\r\nAs in previous versions, classification losses extend ```WeightRegularizerMixin```, which which means you can optionally pass in a weight matrix regularizer. Now that ```WeightRegularizerMixin``` extends ```WeightMixin```, you can also specify the weight initialization function [in object form](https://kevinmusgrave.github.io/pytorch-metric-learning/common_functions/#torchinitwrapper):\r\n```python\r\nfrom ..utils import common_functions as c_f\r\nimport torch\r\n\r\n# use kaiming_uniform, with a=1 and mode='fan_out'\r\nweight_init_func = c_f.TorchInitWrapper(torch.nn.kaiming_uniform_, a=1, mode='fan_out')\r\nloss_func = SomeClassificationLoss(..., weight_init_func=weight_init_func)\r\n```\r\n\r\n## New Regularizers\r\nFor increased modularity, the regularizers hard-coded in several loss functions were separated into their own classes. The new regularizers are:\r\n- LpRegularizer\r\n- SparseCentersRegularizer\r\n- ZeroMeanRegularizer\r\n\r\n## Support for half-precision\r\nIn previous versions, various functions would break in half-precision (float16) mode. Now all distances, losses, miners, regularizers, and reducers work with half-precision, float32, and double (float64).\r\n\r\n## New collect_stats argument\r\nAll distances, losses, miners, regularizers, and reducers now have a ```collect_stats``` argument, which is True by default. This means that various statistics are collected in each forward pass, and these statistics can be useful to look at during experiments. However, if you don't care about collecting stats, you can set ```collect_stats=False```, and the stat computations will be skipped. \r\n\r\n## Other updates\r\n\r\n- You no longer have to explicitly call ```.to(device)``` on classification losses, because their weight matrices will be moved to the correct device during the forward pass if necessary. See issue https://github.com/KevinMusgrave/pytorch-metric-learning/issues/139\r\n\r\n- Reasonable default values have been set for all losses and miners, to make these classes easier to try out. In addition, equations have been added to many of the class descriptions in the documentation. See issue https://github.com/KevinMusgrave/pytorch-metric-learning/issues/140\r\n\r\n- Calls to torch.nonzero have been replaced by torch.where.\r\n\r\n- The documentation for ArcFaceLoss and CosFaceLoss have been fixed to reflect the actual usage. (The documentation previously indicated that some arguments are positional, when they are actually keyword arguments.)\r\n\r\n- The ```tensorboard_folder``` argument for ```utils.logging_presets.get_record_keeper``` is now optional. If you don't specify it, then there will be no tensorboard logs, which can be useful if speed is a concern.\r\n\r\n- The loss dictionary in ```BaseTrainer``` is now cleared at the end of each epoch, to free up GPU memory. See issue https://github.com/KevinMusgrave/pytorch-metric-learning/issues/171\r\n",
        "dateCreated": "2020-08-08T00:19:37Z",
        "datePublished": "2020-08-08T00:24:34Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.90",
        "name": "v0.9.90",
        "tag_name": "v0.9.90",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.90",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/29433630",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.90"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "## CrossBatchMemory\r\n  - Fixed bug where CrossBatchMemory would use self-comparisons as positive pairs. This was uniquely a CrossBatchMemory problem because of the nature of adding each current batch to the queue.\r\n  - Fixed bug where DistanceWeightedMiner would not work with CrossBatchMemory due to missing ```ref_label```\r\n  - Changed 3rd keyword argument of forward() from ```input_indices_tuple``` to ```indices_tuple``` to be consistent with all other losses.\r\n\r\n## AccuracyCalculator\r\n  - Fixed bug in AccuracyCalculator where it would return NaN if the reference set contained none of query set labels. Now it will log a warning and return 0.\r\n\r\n## BaseTester\r\n  - Fixed bug where \"compared_to_training_set\" mode of BaseTester fails due to list(None) bug.\r\n\r\n## InferenceModel\r\n  - New ```get_nearest_neighbors``` function will return nearest neighbors of a query. By @btseytlin \r\n\r\n## Loss and miner utils\r\n  - Switched to ```fill_diagonal_``` in the ```get_all_pairs_indices``` and ```get_all_triplets_indices``` code, instead of creating ```torch.eye```.\r\n\r\n\r\n",
        "dateCreated": "2020-07-25T14:15:25Z",
        "datePublished": "2020-07-25T14:40:04Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.89",
        "name": "v0.9.89",
        "tag_name": "v0.9.89",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.89",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/28939154",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.89"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "# Bug fix\r\nRemoved the circular import which caused an ImportError when the reducers module was imported before anything else. See #125 ",
        "dateCreated": "2020-06-20T08:04:17Z",
        "datePublished": "2020-06-20T08:12:30Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.88",
        "name": "v0.9.88",
        "tag_name": "v0.9.88",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.88",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/27747432",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.88"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "v0.9.87 comes with some major changes that may cause your existing code to break.\r\n\r\n# **BREAKING CHANGES**\r\n## Losses\r\n  - The ```avg_non_zero_only``` init argument has been removed from ```ContrastiveLoss```, ```TripletMarginLoss```, and ```SignalToNoiseRatioContrastiveLoss```. Here's how to translate from old to new code:\r\n    - ```avg_non_zero_only=True```: Just remove this input parameter. Nothing else needs to be done as this is the default behavior.\r\n    - ```avg_non_zero_only=False```: Remove this input parameter and replace it with ```reducer=reducers.MeanReducer()```. You'll need to add this to your imports: ```from pytorch_metric_learning import reducers```\r\n- ```learnable_param_names``` and ```num_class_per_param``` has been removed from ```BaseMetricLossFunction``` due to lack of use. \r\n  - MarginLoss is the only built-in loss function that is affected by this. Here's how to translate from old to new code:\r\n    - ```learnable_param_names=[\"beta\"]```: Remove this input parameter and instead pass in ```learn_beta=True```.\r\n    - ```num_class_per_param=N```: Remove this input parameter and instead pass in ```num_classes=N```.\r\n\r\n## AccuracyCalculator\r\n  - The ```average_per_class``` init argument is now ```avg_of_avgs```. The new name better reflects the functionality.\r\n  - The old way to import was: ```from pytorch_metric_learning.utils import AccuracyCalculator```. This will no longer work. The new way is: ```from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator```. The reason for this change is to avoid an unnecessary import of the Faiss library, especially when this library is used in other packages.\r\n\r\n\r\n# **New feature: Reducers**\r\nReducers specify how to go from many loss values to a single loss value. For example, the ContrastiveLoss computes a loss for every positive and negative pair in a batch. A reducer will take all these per-pair losses, and reduce them to a single value. Here's where reducers fit in this library's flow of filters and computations:\r\n\r\n```Your Data --> Sampler --> Miner --> Loss --> Reducer --> Final loss value```\r\n\r\nReducers are passed into loss functions like this:\r\n```python\r\nfrom pytorch_metric_learning import losses, reducers\r\nreducer = reducers.SomeReducer()\r\nloss_func = losses.SomeLoss(reducer=reducer)\r\nloss = loss_func(embeddings, labels) # in your training for-loop\r\n```\r\nInternally, the loss function creates a dictionary that contains the losses and other information. The reducer takes this dictionary, performs the reduction, and returns a single value on which ```.backward()``` can be called. Most reducers are written such that they can be passed into any loss function.\r\n\r\nSee [the documentation](https://kevinmusgrave.github.io/pytorch-metric-learning/reducers/) for details.\r\n\r\n\r\n# **Other updates**\r\n## Utils\r\n### Inference\r\n- ```InferenceModel``` has been added to the library. It is a model wrapper that makes it convenient to find matching pairs within a batch, or from a set of pairs. Take a look at [this notebook](https://colab.research.google.com/github/KevinMusgrave/pytorch-metric-learning/blob/master/examples/notebooks/Inference.ipynb) to see example usage.\r\n\r\n### AccuracyCalculator\r\n- The ```k``` value for k-nearest neighbors can optionally be specified as an init argument.\r\n- k-nn based metrics now receive knn distances in their kwargs. See #118 by @marijnl\r\n\r\n## Other stuff\r\nUnit tests were added for almost all losses, miners, regularizers, and reducers.\r\n\r\n# **Bug fixes**\r\n## Trainers\r\n- Fixed a labels related bug in TwoStreamMetricLoss. See #112 by @marijnl\r\n\r\n## Loss and miner utils\r\n- Fixed bug where ```convert_to_triplets``` could encounter a RuntimeError. See #95 \r\n\r\n\r\n",
        "dateCreated": "2020-06-20T05:00:44Z",
        "datePublished": "2020-06-20T05:05:17Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.87",
        "name": "v0.9.87",
        "tag_name": "v0.9.87",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.87",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/27746021",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.87"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "**Losses + miners**\r\n- Added assertions to make sure the number of input embeddings is equal to the number of input labels.\r\n- MarginLoss\r\n  - Fixed bug where loss explodes if self.nu > 0 and number of active pairs is 0. See https://github.com/KevinMusgrave/pytorch-metric-learning/issues/98#issue-618347291\r\n\r\n\r\n**Trainers**\r\n- Added ```freeze_these``` to the init arguments of BaseTrainer. This optional argument takes a list or tuple of strings as input. The strings must correspond to the names of models or loss functions, and these models/losses will have their parameters frozen during training. Their corresponding optimizers will also not be stepped.\r\n- Fixed indices shifting bug in the TwoStreamMetricLoss trainer. By @marijnl \r\n\r\n**Testers**\r\n- BaseTester\r\n  - Pass in epoch to ```visualizer_hook```\r\n  - Added ```eval``` option to ```get_all_embeddings```. By default it is True, and will set the input trunk and embedder to eval() mode.\r\n\r\n**Utils**\r\n- HookContainer\r\n  - Allow training to resume from best model, rather than just the latest model.\r\n- **The best models are now saved as ```<model_name>_best<epoch>.pth``` rather than ```<model_name>_best.pth```.** To easily get the new suffix for loading the best model you can do:\r\n```python\r\nfrom pytorch_metric_learning.utils import common_functions as c_f\r\n_, best_model_suffix = c_f.latest_version(your_model_folder, best=True)\r\nbest_trunk = \"trunk_{}.pth\".format(best_model_suffix)\r\nbest_embedder = \"embedder_{}.pth\".format(best_model_suffix)\r\n```",
        "dateCreated": "2020-05-15T18:42:25Z",
        "datePublished": "2020-05-15T18:53:14Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.86",
        "name": "v0.9.86",
        "tag_name": "v0.9.86",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.86",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/26571868",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.86"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "**Trainers**\r\n- Added [TwoStreamMetricLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/trainers/#twostreammetricloss). By @marijnl.\r\n- All ```BaseTrainer``` child classes now accept ```*args``` and pass it to ```BaseTrainer```, so that you can use positional arguments when you init those child classes, rather than just keyword arguments.\r\n- Fixed a key verification bug in CascadedEmbeddings that made it impossible to pass in an optimizer for the metric loss.\r\n\r\n**Testers**\r\n- Added [GlobalTwoStreamEmbeddingSpaceTester](https://kevinmusgrave.github.io/pytorch-metric-learning/testers/#globaltwostreamembeddingspacetester). By @marijnl\r\n- BaseTester\r\n  - The input visualizer should now implement the ```fit_transform``` method, rather than ```fit``` and ```transform``` separately.\r\n  - Fixed various bugs related to ```label_hierarchy_level```\r\n- WithSameParentLabelTester\r\n  - Fixed bugs that were causing this tester to encounter a runtime error.\r\n\r\n**Utils**\r\n- HookContainer\r\n  - Added methods for retrieving loss and accuracy history.\r\n  - Fixed bug where the value for ```best_epoch``` could be ```None```.\r\n- AccuracyCalculator\r\n  - Got rid of bug that returned NaN when dealing with classes containing only one sample.\r\n  - Added ```average_per_class``` option, which computes the average accuracy per class, and then returns the average of those averages. This can be useful when evaluating datasets with unbalanced classes.\r\n\r\n**Other stuff**\r\n- Added the ```with-hooks``` and ```with-hooks-cpu``` pip install options. The following will install record-keeper, faiss-gpu, and tensorboard, in addition to pytorch-metric-learning\r\n```\r\npip install pytorch-metric-learning[with-hooks]\r\n```\r\nIf you don't have a GPU you can do:\r\n```\r\npip install pytorch-metric-learning[with-hooks-cpu]\r\n```\r\n- Added more tests for AccuracyCalculator",
        "dateCreated": "2020-05-03T14:14:49Z",
        "datePublished": "2020-05-03T15:01:27Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.85",
        "name": "v0.9.85",
        "tag_name": "v0.9.85",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.85",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/26119505",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.85"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "**Testers**\r\n- BaseTester\r\n  - Removed ```size_of_tsne``` and added ```visualizer``` and ```visualizer_hook``` to BaseTester. The visualizer needs to implement the ```fit``` and ```transform``` functions. (In the next version, I'll allow fit_transform as well.) For example:\r\n```python\r\n# UMAP is the dimensionality reducer we will pass in as the visualizer\r\nimport umap\r\nimport umap.plot\r\n# For plotting the embeddings\r\ndef visualizer_hook(umapper, umap_embeddings, labels, split_name, keyname):\r\n    logging.info(\"UMAP plot for the {} split and label set {}\".format(split_name, keyname))\r\n    umap.plot.points(umapper, labels=labels, show_legend=False)\r\n    plt.show()\r\n\r\nGlobalEmbeddingSpaceTester(visualizer=umap.UMAP(), visualizer_hook=visualizer_hook)\r\n```\r\n\r\n**Utils**\r\n- AccuracyCalculator\r\n  - Added ```include``` to the init arguments.\r\n  - Renamed ```exclude_metrics``` to ```exclude```.\r\n  - Added the ```requires_knn``` method. \r\n  - Added ```check_primary_metrics``` to AccuracyCalculator, which validates the metrics specified in ```include``` and ```exclude```. By @wconnell \r\n- HookContainer\r\n  - Check if ```primary_metric``` is in ```tester.AccuracyCalculator```. By @wconnell\r\n- logging_presets\r\n  - Added ```**kwargs``` to ```get_hook_container```, so that, for example, you can do ```get_hook_container(record_keeper, primary_metric=\"AMI\")```\r\n\r\n**Other stuff**\r\n - Added an [example Google Colab notebook](https://colab.research.google.com/drive/1fwTC-GRW3X6QiJq6_abJ47On2f3s9e5e) which goes through the entire training/testing workflow.\r\n",
        "dateCreated": "2020-04-18T04:13:28Z",
        "datePublished": "2020-04-18T04:26:23Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.84",
        "name": "v0.9.84",
        "tag_name": "v0.9.84",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.84",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/25634915",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.84"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "**Losses**\r\n- Added [CircleLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#circleloss), implemented by @AlenUbuntu\r\n- Changes to ProxyAnchorLoss:\r\n    - Fixed bug that caused it to break when ```normalize_embeddings=False```\r\n    - Made it extend WeightRegularizerMixin\r\n- Fixed/improved application of ```miner_weights``` in ProxyAnchorLoss, NCALoss, and FastAPLoss\r\n\r\n\r\n**Utils**\r\n- Added [AccuracyCalculator](https://kevinmusgrave.github.io/pytorch-metric-learning/utils/#accuracycalculator)\r\n- Changes to loss_and_miner_utils\r\n    - Made ```convert_to_weights``` return values between 0 and 1, where 1 represents the most frequently occuring sample. Before, it was scaling the probability by size of batch.\r\n\r\n**Other stuff**\r\n- Added a test for ```convert_to_weights```\r\n",
        "dateCreated": "2020-04-13T22:36:47Z",
        "datePublished": "2020-04-13T22:46:55Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.83",
        "name": "v0.9.83",
        "tag_name": "v0.9.83",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.83",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/25465816",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.83"
      },
      {
        "authorType": "User",
        "author_name": "KevinMusgrave",
        "body": "**Losses**\r\n* Added ProxyAnchorLoss\r\n\r\n**Trainers**\r\n* BaseTrainer\r\n  * Made ```iterations_per_epoch``` optional. See the [new documentation](https://kevinmusgrave.github.io/pytorch-metric-learning/trainers/#basetrainer) \r\n  * Changed keys for ```lr_schedulers``` to allow for end of iteration, end of epoch, and plateau schedulers to all be used at the same time. \r\n  * Fixed a key verification bug in BaseTrainer.\r\n\r\n**Utils**\r\n* HookContainer\r\n  * Added ```skip_eval_if_already_done``` flag to ```run_tester_separately```.\r\n  * Made ```ignore_epoch``` a tuple.\r\n  * Added ```save_custom_figures``` flag.\r\n  * Made records get saved before models.\r\n\r\n* common_functions\r\n  *  Removed ```pass_data_to_model``` and ```autograd.Variable``` usage.\r\n\r\n**Other stuff**\r\n* Fixed bug where ```__version__``` was not accessible.\r\n* Added test for pair and triplet index computation\r\n",
        "dateCreated": "2020-04-11T08:46:39Z",
        "datePublished": "2020-04-11T09:02:45Z",
        "html_url": "https://github.com/KevinMusgrave/pytorch-metric-learning/releases/tag/v0.9.82",
        "name": "v0.9.82",
        "tag_name": "v0.9.82",
        "tarball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/tarball/v0.9.82",
        "url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/releases/25412299",
        "zipball_url": "https://api.github.com/repos/KevinMusgrave/pytorch-metric-learning/zipball/v0.9.82"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3970,
      "date": "Sun, 26 Dec 2021 02:13:40 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "metric-learning",
      "deep-learning",
      "computer-vision",
      "machine-learning",
      "pytorch",
      "deep-metric-learning",
      "image-retrieval",
      "self-supervised-learning",
      "contrastive-learning"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "See the [examples folder](https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/examples/README.md) for notebooks you can download or run on Google Colab.\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
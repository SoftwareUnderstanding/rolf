{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1406.2661<br>"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "http://redwood.psych.cornell.edu/papers/olshausen_field_1997.pdf<br>\nhttps://cs.nyu.edu/~yann/research/deep/<br>\nhttps://cs.stanford.edu/~acoates/papers/coatesng_nntot2012.pdf<br>\nhttps://arxiv.org/abs/1406.2661<br>\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9514314316651814
      ],
      "excerpt": "Introduction of computer vision \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Yiming-Miao/Miniproject2",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-16T01:02:46Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-22T02:41:03Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Today's deep learning models need to be trained on large-scale surveillance data sets. This means that for each data, there will be a corresponding label. In the popular ImageNet dataset, there are one million images with manual annotations, that is, 1000 of each of the 1000 categories. Creating such a data set requires a lot of effort, and it may take a lot of people to spend months working on it. Assuming that you now have to create a data set of one million classes, you must label each frame in a total of 100 million frames of video data, which is basically impossible.\n\nIdeally, we want to have a model that runs more like our brain. It requires only a few tags to understand many things in the real world. In the real world, I refer to classes that are object categories, action categories, environment categories, categories of objects, and many more.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8584859062969982,
        0.9947520928872731
      ],
      "excerpt": "The main goal of unsupervised learning research is to pre-train models that can be used for other tasks (i.e., discriminators or encoders). The characteristics of the encoder should be as generic as possible so that it can be used in classification tasks (such as training on ImageNet) and provide as good a result as possible as a supervised model. \nThe latest monitoring models always perform better than unsupervised pre-training models. That's because supervision allows the model to better encode features on the data set. But when the model is applied to other data sets, the supervision will decay. In this regard, unsupervised training promises to provide more general features to perform any task. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9800531571046561,
        0.9515361591017222,
        0.940579349948631
      ],
      "excerpt": "Bruno Olshausen of UC Davis and David Field of Cornell University published a paper \"Sparse Coding with an Overcomplete Basis Set: A Strategy by V1?\" in 1996 shows that coding theory can be used in the receiving domain of the visual cortex. They demonstrate that the basic visual vortex (V1) in our brain uses the sparsity principle to create a minimal set of basic functions that can be used to reconstruct an input image. \nYann LeCun's team is also engaged in research in this area. In the demo in the linked page, you can see how the filter like V1 learns.  \nBy repeating the process of greedy layer-by-layer training, a stacked self-encoder (Stacked-auto encoder) is also used.The autoencoder method is also known as the direct mapping method. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8904705522279819
      ],
      "excerpt": "Intuitive and based on neuroscience research<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8371976015239603,
        0.9961891902636744,
        0.9979255321937325,
        0.8307555786862741
      ],
      "excerpt": "Reconstruction of input may not be ideal metric for learning a general-purpose representation \nClass analysis or clustering is in the same group (called a group of objects called a task cluster in such a way), rather than those in other groups (clusters) that are more similar (in a sense) to each other. It is the main task of exploratory data mining and a common technique for statistical data analysis. It has been used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, bioinformatics, data compression and computer graphics. \nCluster analysis itself is not a specific algorithm, but a general task to be solved. It can be implemented by a variety of algorithms that differ greatly in understanding what constitutes a cluster and how to find them efficiently. Popular cluster concepts include small distances between cluster members, dense areas of data space, intervals, or groups of specific statistical distributions. Therefore, clustering can be formulated as a multi-objective optimization problem. Appropriate clustering algorithms and parameter settings (including parameters such as distance functions) density thresholds or the number of expected clusters depend on the individual data set and the intended use of the results. Such cluster analysis is not an automated task, but an iterative process involving knowledge discovery or interactive multi-objective optimization of discovery and experimentation. It is often necessary to modify the data preprocessing and model parameters until the result gets the required attributes. \nSimple technique: get the output of a similar cluster<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8137114423107836
      ],
      "excerpt": "Intuitive and neuroscience-based research<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9429412508903826
      ],
      "excerpt": "In some cases, it can compete with the performance of supervised learning<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9435021800987529,
        0.9653779786786203,
        0.9641113207061729
      ],
      "excerpt": "Generative Adversarial Networks  to achieve an excellent generation model through the confrontation of the discriminator and the generator, the network hopes to be able to generate realistic images sufficient to fool the discriminator. Generating models In this area, the excellent generation of confrontation networks in recent years was proposed by Ian Goodfellow and Yoshua Bengio in the paper \"Generative Adversarial Nets\".  \nA generated confrontation model called DCGAN, instantiated by Alec Radford, Luke Metz, and Soumith Chintala, yielded very good results. Their research is published in the paper: Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. \nThe DCGAN discriminator is designed to determine whether an input picture is real (from a real picture of a data set) or false (from a generator). The generator takes a random noise vector (for example, 1024 values) as input and generates a picture. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.858176659802899
      ],
      "excerpt": "Easy to program and implement \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341120408081055,
        0.9180765636471776,
        0.9968916941263354,
        0.964097138115036,
        0.9473233094432398,
        0.9772389881432005,
        0.9006736108466098,
        0.9936237836955628,
        0.925232909500617,
        0.9700881790743644
      ],
      "excerpt": "In some cases, it can match the performance of supervised learning \nNeed to improve usability (this is a problem for all unsupervised learning algorithms) \nUnsupervised learning does not require sample data, and models can be built directly to cluster data. For unclassified things, the machine will classify the items according to certain characteristics according to their own judgment. If the robot is treated as a child, supervised learning allows him to classify the item under known rules to produce more accurate results; unsupervised learning allows the child to use the item in his or her desired way according to his or her own preference. The classification is performed to infer the internal structure of the data. When faced with unlabeled data, people can also apply unsupervised learning to allow the machine to estimate the internal structure of the item, and then label the data based on existing estimates, so that the application of supervised learning is more accurate. Classification results. \nUnsupervised algorithms only deal with \"features\" and do not operate supervisory signals. The distinction between supervised and unsupervised algorithms is not standardized, strictly defined, because there is no objective judgment to distinguish whether the value provided by the supervisor is a feature or a goal. \nIn layman's terms, unsupervised learning is the majority of attempts to extract information from a distribution that does not require human annotation samples. The term is usually related to density estimation, learning to sample from distribution, learning to denoise from distribution, manifolds that require data distribution, or clustering related samples in the data. \nUnsupervised learning is an important branch of machine learning. It plays an important role in machine learning, data mining, biomedical big data analysis, and data science. \nIn recent years, many research results have been obtained in the field of unsupervised learning, including the second winner's penalty competition learning algorithm, K-means learning algorithm, K-medoids learning algorithm, density learning algorithm, and spectral clustering algorithm; especially in gene selection. It has been widely used in the diagnosis of diseases. \nIntroduction of object detection model based on deep learning and CNN, including R-CNN, Fast R-CNN, Faster R-CNN, YOLO, YOLOv2, YOLOv3. R-CNN family is more based on static object detection. Faster R-CNN is the fastest among them. YOLO family is more useful in real time object detection which means that the input can be a video. \nIntroduction of R-CNN specific four parts: Regional suggestion algorithm(ss), Feature Extraction Algorithm (AlexNet), Linear classifier (linear SVM) and Bounding box correction regression model (Bounding box). Also gives us a procedure of using R-CNN to run an object detection. \nIntroduction of supervised learning and unsupervised learning in machine learning. Also gives us an introduction of TensorFlow. TensorFlow offers a supervised machine learning beginners guide to classify images, train the neural network and test the accuracy of the model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9466447931502523,
        0.8755338430729315,
        0.9688173656977382
      ],
      "excerpt": "Introduction of objection detection \nDifference between R-CNN family algorithms and YOLO family \nRecommendations of using different models \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Yiming-Miao/Miniproject2/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 14:43:41 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Yiming-Miao/Miniproject2/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Yiming-Miao/Miniproject2",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Yiming-Miao/Miniproject2/issues{/number}",
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Yiming-Miao\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Miniproject2",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Miniproject2",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Yiming-Miao",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Yiming-Miao/Miniproject2/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 14:43:41 GMT"
    },
    "technique": "GitHub API"
  }
}
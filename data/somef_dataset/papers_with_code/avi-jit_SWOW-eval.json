{
  "citation": [
    {
      "confidence": [
        0.9612518189229063,
        0.9994899410294296
      ],
      "excerpt": "BTech and MTech in Computer Science and Engineering, Indian Institute of Technology (BHU) Varanasi. <br> \nPhD student, Department of Computer Science, Viterbi School of Engineering, University of Southern California. <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.939701387002656
      ],
      "excerpt": "Associate Professor, Department of Computer Science and Engineering, Indian Institute of Technology (BHU) Varanasi. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9597355913535887,
        0.9958714229630268
      ],
      "excerpt": "* Word2Vec Skip Gram (Mikolov et al. 2013a ; Mikolov et al. 2013b) trained on Google News. [Download]  \n* GloVe (Pennington et al. 2014) trained on Wikipedia 2014 and Gigaword 5. [Download] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9575198524616838
      ],
      "excerpt": "* ConceptNet Numberbatch (Speer et al. 2017) trained on a knowledge graph and some text corpora. [Download] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8255971719045668
      ],
      "excerpt": "ACL SOTA: maintains benchmark pages for word similarity. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/avi-jit/SWOW-eval",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-04T19:17:06Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-03T10:15:33Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9502399883600805,
        0.9829135921243546,
        0.8743402649908549,
        0.958112450036705
      ],
      "excerpt": "This project describes a new task for evaluating pre-trained word embeddings. In particular, we present the intrinsic evaluation task originally named SWOW-8500, and employs a large word association dataset called the Small World of Words (SWOW).  \nThis repository also serves as the go-to page regarding our paper titled SWOW-8500: Word Association Task for Intrinsic Evaluation of Word Embeddings, accepted at the RepEval2019 workshop, collocated with the 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2019 June 2\u20137, 2019, at Minneapolis, United States. \nBTech and MTech in Computer Science and Engineering, Indian Institute of Technology (BHU) Varanasi. <br> \nPhD student, Department of Computer Science, Viterbi School of Engineering, University of Southern California. <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837749234247144,
        0.9132038440052166
      ],
      "excerpt": "Distinguished Data Scientist and Master Inventor, IBM New York. \nAssociate Professor, Department of Computer Science and Engineering, Indian Institute of Technology (BHU) Varanasi. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9734708336899223,
        0.9762926924418932
      ],
      "excerpt": "Word Association games are those wherein a participant is asked to utter the first (or first few) words that occur to him/her when given a trigger / cue / stimulus word. For example, given the cue KING, one could respond with RULE, QUEEN, KINGDOM, or even KONG (from the film King Kong). Word associations have long intrigued psychologists including Carl Jung and hence large studies have been conducted in this direction. Some prominent datasets which collect user responses to word association games are enumerated as follows:<br> \nUSF-FA: University of Southern Florida Free Association norms have single-word association responses from an average of 149 participants per cue for a set of 5,019 cue words. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9626533484515126,
        0.9519057501744039,
        0.9852675948589806
      ],
      "excerpt": "SWOW (Small World of Words): lists word association and participant data for 100 primary, secondary and tertiary responses to 12,292 cues, collected from over 90,000 participants.  \nBirkbeck norms: contain 40 to 50 responses for over 2,600 cues in British English. \nWord Embeddings are vector representation of words, i.e. an array of floating point numbers for each word. This helps computers make more sense out of the mystical natural langauge we humans use, and has been fairly helpful in recent developments in Natural Language Processing (think Machine Translation), Information Retrieval (think Search Engines), and Image Captioning (think Google Images or GIF search). In layman terms, the secret lies in letting related words have similar vectors, but there have been a slew of approaches to come up with such word embeddings. We list down some of the most popular, as well as the most effective ones so far. We have used the pretrained versions of these in our experimentation and you shall find them in the folder WordVectors: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9926470285196111,
        0.9823892987494597
      ],
      "excerpt": "It is of natural interest to the NLP community to identify evaluation metrics for word embeddings. Besides direct performance measurement on downstream tasks (also called Extrinsic Evaluation) like Sentiment Classification, Question Answering, and Chunking, there have also been proposed several Intrinsic Evaluation measures such as WordSim-353 and SimLex. While Extrinsic Evaluations use word embeddings as input features to a downstream task and measure changes in performance metrics specific to that task, Intrinsic Evaluations directly test for syntactic or semantic relationships between word (Schnabel et al. 2015. Another way to tell apart Intrinsic from Extrinsic evaluations is the lack of any trainable parameters in the former.  \nIntrinsic tasks are useful as long as they can accurately predict a model's performance on Extrinsic evaluations, since at the end of the day, the ability to solve downstream tasks is all that matters. Here are a few resources and existing projects that aim to bridge the gap between the two, by experimenting thoroughly with multiple tasks and multiple embeddings: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9389522430293097,
        0.9515855238573888,
        0.9800588821679675,
        0.8372396012058242
      ],
      "excerpt": "Vecto AI: an exhaustive collection of Intrinsic tasks, beyond word similarity and relatedness. Vecto is also a library to help run experiments in distributional semantics. \nWE Benchmarks: another collection of benchmarks for intrinsic evaluation of pretrained embeddings. \nWe found that with the new Word Association tasks, we not only save up on a lot of (expensive and time-consuming) human annotation process, but also report much better confidence intervals on intrinsic evaluation tasks. Performance on SWOW-8500 has been shown to correlate with both (1) existing Word Similarity/Relatedness tasks (Intrinsic Evaluation), as well as (2) multiple Downstream tasks (Extrinsic Evaluation). For further details, please refer to our paper (link shall be posted upon publication). \nCarl Jung on word associations \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9338102380428972
      ],
      "excerpt": "NLP-progress: Repository to track the progress in Natural Language Processing (NLP), including the datasets and the current state-of-the-art for the most common NLP tasks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Intrinsic Evaluation of pre-trained word embeddings, using large Word Association Dataset: SWOW (Small World of Words)",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://vecto.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/avi-jit/SWOW-eval/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 11:24:04 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/avi-jit/SWOW-eval/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "avi-jit/SWOW-eval",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/avi-jit/SWOW-eval/master/SWOW%20subset.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8304211836008462
      ],
      "excerpt": "EAT: Edinburgh Association Thesaurus collects 100 responses per cue for a total of 8,400 cues.  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/avi-jit/SWOW-eval/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Avijit Thawani\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SWOW-eval",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SWOW-eval",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "avi-jit",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/avi-jit/SWOW-eval/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "There are two fairly interactive and easy-to-read scripts (Python 3) in this repository:\n* `SWOW subset.ipynb`: A Jupyter Notebook that takes you from the original Small World of Words dataset, to a specific format of SWOW-NNNN subset in the form of cue: response. You could set different conditions like modifying the minimum count (frequency) of a cue-response pair, to be acceptable into your custom word association dataset. This results in a simple pickle file, used by the following script.\n* `SWOW_eval.py`: This reads one or more pretrained embeddings (in FastText .txt format), and an evaluation file (which is the output of the above Jupyter Notebook). It then displays the Precision, Recall, Accuracy, Confidence Interval, OOV (out-of-vocabulary) words for the word association task.\n\nTo evaluate a single word embedding file: \n\n`python SWOW_eval.py 1 Apr_3_cr_dict_min20.pkl numberbatch_65876.txt` <br>\n`python SWOW_eval.py <debug> <evalFile> <vecFile>`\n\nTo evaluate multiple embedding files (saved within a specific folder):\n\n`python SWOW_eval.py <debug> <evalFile> _ <vecFolder>` <br>\n`python SWOW_eval.py 0 Apr_3_cr_dict_min20.pkl _ wordVectors/`\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Mon, 27 Dec 2021 11:24:04 GMT"
    },
    "technique": "GitHub API"
  }
}
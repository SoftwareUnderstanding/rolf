{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This code is partly based on the open-source implementations from the following sources:\n[OpenLongTailRecognition](https://github.com/zhmiao/OpenLongTailRecognition-OLTR), [classifier-balancing](https://github.com/facebookresearch/classifier-balancing), [LDAM-DRW](https://github.com/kaidic/LDAM-DRW), [MoCo](https://github.com/facebookresearch/moco), and [semisup-adv](https://github.com/yaircarmon/semisup-adv).\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2006.07529",
      "https://arxiv.org/abs/1911.05722"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{yang2020rethinking,\n  title={Rethinking the Value of Labels for Improving Class-Imbalanced Learning},\n  author={Yang, Yuzhe and Xu, Zhi},\n  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},\n  year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8940583111730483,
        0.9966798951421628,
        0.9947349587724232,
        0.9999535207832192
      ],
      "excerpt": "Yuzhe Yang, and Zhi Xu <br> \n34th Conference on Neural Information Processing Systems (NeurIPS), 2020 <br> \n[Website] [arXiv] [Paper] [Slides] [Video] \nIf you find this code or idea useful, please consider citing our work: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8709314592066142
      ],
      "excerpt": "Train on ImageNet-LT / iNaturalist 2018 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9659166110223061
      ],
      "excerpt": "  |CE(Uniform) + SSP| 10 |  12.28 | ResNet-32 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9497315756634387
      ],
      "excerpt": "  |CE(Balanced) + SSP| 10 |  11.57 | ResNet-32 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.881848456479086
      ],
      "excerpt": "  |CE(Uniform) + SSP| 10 |  42.93 | ResNet-32 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.881848456479086
      ],
      "excerpt": "  |CE(Balanced) + SSP| 10 |  41.94 | ResNet-32 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8390406170334995
      ],
      "excerpt": ": test on CIFAR-10 / CIFAR-100 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8709314592066142
      ],
      "excerpt": ": test on ImageNet-LT / iNaturalist 2018 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/YyzHarry/imbalanced-semi-self",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you have any questions, feel free to contact us through email (yuzhe@mit.edu & zhixu@mit.edu) or Github issues. Enjoy!\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-09-04T15:06:22Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T14:17:57Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9818474335444658
      ],
      "excerpt": "This repository contains the implementation code for paper: <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "Yuzhe Yang, and Zhi Xu <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9485904490952572
      ],
      "excerpt": "In this work, we show theoretically and empirically that, both semi-supervised learning (using unlabeled data) and self-supervised pre-training (first pre-train the model with self-supervision) can substantially improve the performance on imbalanced (long-tailed) datasets, regardless of the imbalanceness on labeled/unlabeled data and the base training techniques. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9082246561315965
      ],
      "excerpt": "Using unlabeled data helps to shape clearer class boundaries and results in better class separation, especially for the tail classes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8050242608439414
      ],
      "excerpt": "Self-supervised pre-training (SSP) helps mitigate the tail classes leakage during testing, which results in better learned boundaries and representations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8402426883922056
      ],
      "excerpt": "--imb_factor_unlabel: imbalance factor for unlabeled data (inverse value of unlabel imbalance ratio \\rho_U) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8483335664820975
      ],
      "excerpt": "CIFAR-10-LT: CIFAR-10 unlabeled data is prepared following this repo using the 80M TinyImages. In short, a data sourcing model is trained to distinguish CIFAR-10 classes and an \"non-CIFAR\" class. For each class, images are then ranked based on the prediction confidence, and unlabeled (imbalanced) datasets are constructed accordingly. Use the following link to download the prepared unlabeled data, and place in your data_path: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9845359896838641
      ],
      "excerpt": "Note that the class imbalance in unlabeled data is also considered, which is controlled by --imb_factor_unlabel (\\rho_U in the paper). See imbalance_cifar.py and imbalance_svhn.py for details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594448638324115,
        0.8359972863033691
      ],
      "excerpt": "- Generated pseudo labels for SVHN-LT with \\rho=50 \nTo train with unlabeled data, for example, on CIFAR-10-LT with \\rho=50 and \\rho_U=50 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8758537990976523
      ],
      "excerpt": "All related data and checkpoints can be found via this link. Individual results and checkpoints are detailed as follows. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8448853539036782,
        0.8448853539036782
      ],
      "excerpt": "|CE + D_U@5x (\\rho=50 and \\rho_U=1) |  13.07 | ResNet-32 | \n|CE + D_U@5x (\\rho=50 and \\rho_U=25) |  13.36 | ResNet-32 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "[NeurIPS 2020] Semi-Supervision (Unlabeled Data) & Self-Supervision Improve Class-Imbalanced / Long-Tailed Learning",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/YyzHarry/imbalanced-semi-self/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 94,
      "date": "Mon, 27 Dec 2021 00:31:42 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/YyzHarry/imbalanced-semi-self/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "YyzHarry/imbalanced-semi-self",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8526268374497808
      ],
      "excerpt": "pretrain_rot.py & pretrain_moco.py: self-supervised pre-training using Rotation prediction or MoCo \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.809376877692394
      ],
      "excerpt": "--imb_factor_unlabel: imbalance factor for unlabeled data (inverse value of unlabel imbalance ratio \\rho_U) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9126921437653545
      ],
      "excerpt": "python train_semi.py --dataset cifar10 --imb_factor 0.02 --imb_factor_unlabel 0.02 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9504923318633114
      ],
      "excerpt": "python pretrain_rot.py --dataset cifar10 --imb_factor 0.01 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8862046824927127
      ],
      "excerpt": "python train.py --dataset cifar10 --imb_factor 0.01 --pretrained_model &lt;path_to_ssp_model&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8525779204761423
      ],
      "excerpt": "|  Dataset Setting  |  \\rho=100 | \\rho=50 | \\rho=10 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8049246179000294
      ],
      "excerpt": "  |CE(Balanced) + SSP| 100 |  23.47 | ResNet-32 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8525779204761423
      ],
      "excerpt": "|  Dataset Setting  |  \\rho=100 | \\rho=50 | \\rho=10 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8098283254039146,
        0.9251539964053576
      ],
      "excerpt": ": test on CIFAR-10 / CIFAR-100 \npython train.py --dataset cifar10 --resume <ckpt-path> -e \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.91545244156875
      ],
      "excerpt": "python -m imagenet_inat.main --cfg <path_to_ssp_config> --model_dir <path_to_model> --test \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/YyzHarry/imbalanced-semi-self/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Yuzhe Yang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Rethinking the Value of Labels for Improving Class-Imbalanced Learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "imbalanced-semi-self",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "YyzHarry",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/YyzHarry/imbalanced-semi-self/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Download [CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html) & [SVHN](http://ufldl.stanford.edu/housenumbers/) dataset, and place them in your `data_path`. Original data will be converted by [`imbalance_cifar.py`](dataset/imbalance_cifar.py) and [`imbalance_svhn.py`](dataset/imbalance_svhn.py)\n- Download [ImageNet](http://image-net.org/download) & [iNaturalist 2018](https://github.com/visipedia/inat_comp/tree/master/2018) dataset, and place them in your `data_path`. Long-tailed version will be created using train/val splits (.txt files) in corresponding subfolders under `imagenet_inat/data/`\n- Change the `data_root` in [`imagenet_inat/main.py`](./imagenet_inat/main.py) accordingly for ImageNet-LT & iNaturalist 2018\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- PyTorch (>= 1.2, tested on 1.4)\n- yaml\n- scikit-learn\n- TensorboardX\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 544,
      "date": "Mon, 27 Dec 2021 00:31:42 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "imbalanced-learning",
      "imbalanced-classification",
      "semi-supervised-learning",
      "unlabeled-data",
      "self-supervised-learning",
      "long-tail",
      "long-tailed-recognition",
      "class-imbalance",
      "neurips",
      "neurips-2020",
      "imbalanced-data"
    ],
    "technique": "GitHub API"
  }
}
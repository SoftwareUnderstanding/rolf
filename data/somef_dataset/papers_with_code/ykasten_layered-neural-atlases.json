{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.06870",
      "https://arxiv.org/abs/1703.06870",
      "https://arxiv.org/abs/2003.12039",
      "https://arxiv.org/abs/2109.11418"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find our work useful in your research, please consider citing:\n```\n@article{kasten2021layered,\n  title={Layered Neural Atlases for Consistent Video Editing},\n  author={Kasten, Yoni and Ofri, Dolev and Wang, Oliver and Dekel, Tali},\n  journal={arXiv preprint arXiv:2109.11418},\n  year={2021}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{kasten2021layered,\n  title={Layered Neural Atlases for Consistent Video Editing},\n  author={Kasten, Yoni and Ofri, Dolev and Wang, Oliver and Dekel, Tali},\n  journal={arXiv preprint arXiv:2109.11418},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8486174771641112
      ],
      "excerpt": "This repository contains an implementation for the SIGGRAPH Asia 2021 paper <a href=\"https://arxiv.org/pdf/2109.11418.pdf\">Layered Neural Atlases for Consistent Video Editing</a>. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ykasten/layered-neural-atlases",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-23T18:06:15Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-24T10:34:17Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8563204881570153,
        0.9481047276697773
      ],
      "excerpt": "This repository contains an implementation for the SIGGRAPH Asia 2021 paper <a href=\"https://arxiv.org/pdf/2109.11418.pdf\">Layered Neural Atlases for Consistent Video Editing</a>. \nThe paper introduces the first approach for neural video unwrapping using an end-to-end optimized interpretable and semantic atlas-based representation, which facilitates easy and intuitive editing in the atlas domain. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8735062486818598
      ],
      "excerpt": "3. data/blackswan_maskrcnn: A folder with rough masks (created by Mask-RCNN or any other way) containing files in the following convention: blackswan_maskrcnn/00000.jpg,blackswan_maskrcnn/00001.jpg,...,blackswan_maskrcnn/00049.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8080031301564514
      ],
      "excerpt": "unzip data.zip \nGiven only the video frames folder data/blackswan it is possible to extract the Mask-RCNN masks (and create the required folder data/blackswan_maskrcnn) by running:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8859977225162202
      ],
      "excerpt": "where --class_name determines the COCO class name of the sought foreground object. It is also possible to choose the first instance retrieved by Mask-RCNN by using --class_name anything. This is usefull for cases where Mask-RCNN gets correct masks with wrong classes as in the \"libby\" video: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8384517522283783
      ],
      "excerpt": "For linking RAFT into the current project run: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560832534359587
      ],
      "excerpt": "Note that in order to reduce the training time it is possible to reduce the evaluation frequency controlled by the parameter \"evaluate_every\" (e.g. by changing it to 10000). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8582736730372835
      ],
      "excerpt": "where trained_model_folder is the path to a folder that contains the config.json and checkpoint files of the trained model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.847410513706816,
        0.9403315444390348
      ],
      "excerpt": "Where edit_foreground_path and edit_background_path specify the paths to 1000x1000 images of the RGBA atlas edits. \nFor applying an edit that was done on a frame (e.g. for the pretrained \"libby\"): \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ykasten/layered-neural-atlases/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Mon, 27 Dec 2021 09:59:01 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ykasten/layered-neural-atlases/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ykasten/layered-neural-atlases",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The code is compatible with Python 3.7 and PyTorch 1.6. \n\nYou can create an anaconda environment called `neural_atlases` with the required dependencies by running:\n```\nconda create --name neural_atlases python=3.7 \nconda activate neural_atlases \nconda install pytorch=1.6.0 torchvision=0.7.0 cudatoolkit=10.1 matplotlib tensorboard scipy  scikit-image tqdm  opencv -c pytorch\npip install imageio-ffmpeg gdown\npython -m pip install detectron2 -f   https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8660756266539105,
        0.9906248903846466,
        0.9906248903846466
      ],
      "excerpt": "git submodule update --init \ncd thirdparty/RAFT/ \ncd ../.. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8568652385383668
      ],
      "excerpt": "  <img width=\"100%\" src=\"media/teaser_lucia.gif\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8599853951740495,
        0.8241031880016153,
        0.8185688410692376
      ],
      "excerpt": "1. data/blackswan: A folder of video frames containing image files in the following convention: blackswan/00000.jpg,blackswan/00001.jpg,...,blackswan/00049.jpg  (as in the  DAVIS  dataset). \n2. data/blackswan_flow: A folder with forward and backward optical flow files in the following convention: blackswan_flow/00000.jpg_00001.jpg.npy,blackswan_flow/00001.jpg_00000.jpg,...,blackswan_flow/00049.jpg_00048.jpg.npy. \n3. data/blackswan_maskrcnn: A folder with rough masks (created by Mask-RCNN or any other way) containing files in the following convention: blackswan_maskrcnn/00000.jpg,blackswan_maskrcnn/00001.jpg,...,blackswan_maskrcnn/00049.jpg \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8505159152472684
      ],
      "excerpt": "unzip data.zip \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9238926712827894
      ],
      "excerpt": "python preprocess_mask_rcnn.py --vid-path data/blackswan --class_name bird \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.894678930873013
      ],
      "excerpt": "python preprocess_mask_rcnn.py --vid-path data/libby --class_name anything \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9238926712827894
      ],
      "excerpt": "python preprocess_optical_flow.py --vid-path data/blackswan --max_long_edge 768 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8082022887640018
      ],
      "excerpt": "unzip pretrained_models.zip \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9109426385148628
      ],
      "excerpt": "python train.py config/config.json \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8549490715548445,
        0.8542284544092361,
        0.8543074962483785
      ],
      "excerpt": "The other configurable parameters are documented inside the file train.py. \nDuring training, the model is evaluated. For running only evaluation on a trained folder run: \npython only_evaluate.py --trained_model_folder=pretrained_models/checkpoints/blackswan --video_name=blackswan --data_folder=data --output_folder=evaluation_outputs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.86606232202729,
        0.8689607014858974,
        0.8689607014858974
      ],
      "excerpt": "To apply editing, run the script only_edit.py. Examples for the supplied pretrained models for \"blackswan\" and \"boat\": \npython only_edit.py --trained_model_folder=pretrained_models/checkpoints/blackswan --video_name=blackswan --data_folder=data --output_folder=editing_outputs --edit_foreground_path=pretrained_models/edit_inputs/blackswan/edit_blackswan_foreground.png --edit_background_path=pretrained_models/edit_inputs/blackswan/edit_blackswan_background.png \npython only_edit.py --trained_model_folder=pretrained_models/checkpoints/boat --video_name=boat --data_folder=data --output_folder=editing_outputs --edit_foreground_path=pretrained_models/edit_inputs/boat/edit_boat_foreground.png --edit_background_path=pretrained_models/edit_inputs/boat/edit_boat_backgound.png \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ykasten/layered-neural-atlases/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Yoni Kasten\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Layered Neural Atlases for Consistent Video Editing",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "layered-neural-atlases",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ykasten",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ykasten/layered-neural-atlases/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The code is compatible with Python 3.7 and PyTorch 1.6. \n\nYou can create an anaconda environment called `neural_atlases` with the required dependencies by running:\n```\nconda create --name neural_atlases python=3.7 \nconda activate neural_atlases \nconda install pytorch=1.6.0 torchvision=0.7.0 cudatoolkit=10.1 matplotlib tensorboard scipy  scikit-image tqdm  opencv -c pytorch\npip install imageio-ffmpeg gdown\npython -m pip install detectron2 -f   https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 90,
      "date": "Mon, 27 Dec 2021 09:59:01 GMT"
    },
    "technique": "GitHub API"
  }
}
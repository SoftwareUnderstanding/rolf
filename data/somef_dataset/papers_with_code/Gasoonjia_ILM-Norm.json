{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1904.03516"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this helps your research, please consider citing:\n\n```\n@conference{Jia2019,\ntitle = {Instance-Level Meta Normalization},\nauthor = {Songhao Jia and Ding-Jie Chen and Hwann-Tzong Chen},\nyear = {2019},\njournal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@conference{Jia2019,\ntitle = {Instance-Level Meta Normalization},\nauthor = {Songhao Jia and Ding-Jie Chen and Hwann-Tzong Chen},\nyear = {2019},\njournal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Gasoonjia/ILM-Norm",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-04T12:54:45Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-26T06:57:54Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This paper presents a normalization mechanism called Instance-Level Meta Normalization (ILM-Norm) to address a learning-to-normalize problem. ILM-Norm learns to predict the normalization parameters via both the feature feed-forward and the gradient back-propagation paths.\nILM-Norm provides a meta normalization mechanism and has several good properties. It can be easily plugged into existing instance-level normalization schemes such as Instance Normalization, Layer Normalization, or Group Normalization. ILM-Norm normalizes each instance individually and therefore maintains high performance even when small mini-batch is used. The experimental results show that ILM-Norm well adapts to different network architectures and tasks, and it consistently improves the performance of the original models.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9418377311732664,
        0.9449170380937894
      ],
      "excerpt": "This repository contains the implementation of the paper Instance-Level Meta Normalization presented at CVPR 2019.  \nThe code is based on the PyTorch example for training ResNet on Imagenet and Train CIFAR10 with PyTorch. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Gasoonjia/ILM-Norm/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Sat, 25 Dec 2021 12:45:43 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Gasoonjia/ILM-Norm/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Gasoonjia/ILM-Norm",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8004579755240048
      ],
      "excerpt": "The network can be simply trained with python train.py or with optional arguments for different hyperparameters: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9280851906109326
      ],
      "excerpt": "The network can be also simply infered with the following command: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9568421979842983
      ],
      "excerpt": "You can also infer the network with the following command: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9252038045117789
      ],
      "excerpt": "python train.py --data [cifar-10/cifar-100 folder] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9389726417030043
      ],
      "excerpt": "python train.py --infer [checkpoint folder] --data [cifar-10/cifar-100 folder] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8828631866016543
      ],
      "excerpt": "python imageNet.py --data [imagenet folder] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9079065188485428
      ],
      "excerpt": "python imageNet.py --infer [checkpoint folder] --data [imagenet folder] \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Gasoonjia/ILM-Norm/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Instance-Level Meta Normalization (ILM-Norm)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ILM-Norm",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Gasoonjia",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Gasoonjia/ILM-Norm/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This implementation is developed for \n\n0. Python 3.6.5\n0. PyTorch 1.0.1\n0. CUDA 9.1\n\nFor compatibility to newer versions, please make a pull request.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 14,
      "date": "Sat, 25 Dec 2021 12:45:43 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "There are two training files. One for CIFAR-10 and Cifar-100 `train.py` and the other for ImageNet `imageNet.py`.\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2111.08819",
      "https://arxiv.org/abs/2111.08819"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use CleanRL in your work, please cite our technical [paper](https://arxiv.org/abs/2111.08819):\n\n```bibtex\n@article{huang2021cleanrl,\n    title={CleanRL: High-quality Single-file Implementations of Deep Reinforcement Learning Algorithms}, \n    author={Shengyi Huang and Rousslan Fernand Julien Dossa and Chang Ye and Jeff Braga},\n    year={2021},\n    eprint={2111.08819},\n    archivePrefix={arXiv},\n    primaryClass={cs.LG}\n}\n```",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{huang2021cleanrl,\n    title={CleanRL: High-quality Single-file Implementations of Deep Reinforcement Learning Algorithms}, \n    author={Shengyi Huang and Rousslan Fernand Julien Dossa and Chang Ye and Jeff Braga},\n    year={2021},\n    eprint={2111.08819},\n    archivePrefix={arXiv},\n    primaryClass={cs.LG}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vwxyzjn/cleanrl",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to CleanRL\nThank you for being interested in contributing to our project. All kinds of contribution are welcome. \nBelow are some steps to help you get started:\n\n\ud83d\udc4b Join our discord channel at https://discord.gg/D6RCjA6sVT\nto say hi!!\n\ud83d\udd28 Pick something you want to work at and let us know on slack. You could\nTackle issues with the help wanted flag \nBug fixes and various improvements on existing algorithms.\nContribute to the Open RL Benchmark\nYou could add new algorithms or new games to be featured in the Open RL Benchmark (http://benchmark.cleanrl.dev/)\nIn this case, please contact me (Costa) directly on slack. I will add you to the CleanRL's Team at Weight and Biases (https://wandb.ai/cleanrl). \n  So if you would like, your experiments can be featured on the Open RL Benchmark (http://benchmark.cleanrl.dev/)\n\n\n\n\n\ud83c\udf87 Submit an PR and get marged!\n\nGood luck and have fun!",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-07T16:31:50Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T03:37:31Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9956208153719737
      ],
      "excerpt": "CleanRL is a Deep Reinforcement Learning library that provides high-quality single-file implementation with research-friendly features. The implementation is clean and simple, yet we can scale it to run thousands of experiments using AWS Batch. The highlight features of CleanRL are: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9661406490390344
      ],
      "excerpt": "Every detail about an algorithm is put into the algorithm's own file. It is therefore easier to fully understand an algorithm and do research with. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8930438924692913
      ],
      "excerpt": "\ud83c\udfae Videos of Gameplay Capturing \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8792820591651209,
        0.8393187998063558
      ],
      "excerpt": "\ud83d\udcb8 Cloud Integration with docker and AWS  \nYou can read more about CleanRL in our technical paper and documentation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8503829381739865
      ],
      "excerpt": "[x] Deep Q-Learning (DQN) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "High-quality single file implementation of Deep Reinforcement Learning algorithms with research-friendly features (PPO, DQN, C51, Ape-X DQN, DDPG, TD3, SAC)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vwxyzjn/cleanrl/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 77,
      "date": "Thu, 23 Dec 2021 13:34:10 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/vwxyzjn/cleanrl/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "vwxyzjn/cleanrl",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/vwxyzjn/cleanrl/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/entrypoint.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/terminate_all.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/experimentals.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/submit_exp.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/c51_other.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/ppo_mujoco.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/dqn_other.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/sac_pybullet.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/ppo_pybullet.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/offline_dqn_cql_atari_visual.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/td3_pybullet.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/offline_dqn_atari_visual.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/ddpg_mujoco.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/ppo_atari.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/ppo_other.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/apex_dqn_atari.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/td3_mujoco.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/c51_atari.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/ddpg_pybullet.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/dqn_atari.sh",
      "https://raw.githubusercontent.com/vwxyzjn/cleanrl/master/cloud/examples/scripts/sac_mujoco.sh"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8647354795712904
      ],
      "excerpt": "<img src=\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8191397560471069
      ],
      "excerpt": "<img src=\"https://badge.fury.io/py/cleanrl.svg\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/vwxyzjn/cleanrl/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "HCL",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Costa Huang\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "CleanRL (Clean Implementation of RL Algorithms)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "cleanrl",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "vwxyzjn",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vwxyzjn/cleanrl/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "vwxyzjn",
        "body": "## What's Changed\r\n* Use Poetry as the package manager by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/50\r\n* Remove links to deleted code on README algorithms by @FelipeMartins96 in https://github.com/vwxyzjn/cleanrl/pull/54\r\n* Add paper plotting utilities  by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/55\r\n* Reorganization of files. by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/56\r\n* Bump Gym's version to 0.21.0 by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/61\r\n* Automatically Download Atari Roms by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/62\r\n* Make Spyder Editor Optional by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/66\r\n* Support Python 3.7.1+ by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/67\r\n* ddpg_continuous: Addded env argument to actor and target actor by @dosssman in https://github.com/vwxyzjn/cleanrl/pull/69\r\n* Add pytest as an optional dependency by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/71\r\n* Remove SB3 dependency in ppo_continuous_action.py by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/72\r\n* Add e2e tests by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/70\r\n* Fix #74 SAC consistency in logging and training to match other scripts by @dosssman in https://github.com/vwxyzjn/cleanrl/pull/75\r\n* Add MuJoCo environments support. by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/76\r\n* Only run tests given changes to the `cleanrl` directory by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/77\r\n* Prototype Documentation Site by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/64\r\n* Cloud Utilities Improvement  by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/65\r\n* Import built docker image to local registry by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/80\r\n* Remove docker dummy cache by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/81\r\n* Allow buildx to save to local and push by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/82\r\n* Rollback back PyTorch version for better compatibility by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/84\r\n* Cloud utilities refactor by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/85\r\n* Prepare for 0.5.0 release by @vwxyzjn in https://github.com/vwxyzjn/cleanrl/pull/88\r\n\r\n## New Contributors\r\n* @FelipeMartins96 made their first contribution in https://github.com/vwxyzjn/cleanrl/pull/54\r\n\r\n**Full Changelog**: https://github.com/vwxyzjn/cleanrl/compare/v0.4.8...v0.5.0",
        "dateCreated": "2021-11-12T16:00:01Z",
        "datePublished": "2021-11-12T16:01:05Z",
        "html_url": "https://github.com/vwxyzjn/cleanrl/releases/tag/v0.5.0",
        "name": "v0.5.0",
        "tag_name": "v0.5.0",
        "tarball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/tarball/v0.5.0",
        "url": "https://api.github.com/repos/vwxyzjn/cleanrl/releases/53254892",
        "zipball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/zipball/v0.5.0"
      },
      {
        "authorType": "User",
        "author_name": "vwxyzjn",
        "body": "",
        "dateCreated": "2021-05-15T15:36:01Z",
        "datePublished": "2021-05-16T02:41:43Z",
        "html_url": "https://github.com/vwxyzjn/cleanrl/releases/tag/v0.4.8",
        "name": "",
        "tag_name": "v0.4.8",
        "tarball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/tarball/v0.4.8",
        "url": "https://api.github.com/repos/vwxyzjn/cleanrl/releases/43008503",
        "zipball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/zipball/v0.4.8"
      },
      {
        "authorType": "User",
        "author_name": "vwxyzjn",
        "body": "",
        "dateCreated": "2021-05-12T14:25:44Z",
        "datePublished": "2021-05-12T14:26:18Z",
        "html_url": "https://github.com/vwxyzjn/cleanrl/releases/tag/v0.4.7",
        "name": "",
        "tag_name": "v0.4.7",
        "tarball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/tarball/v0.4.7",
        "url": "https://api.github.com/repos/vwxyzjn/cleanrl/releases/42844770",
        "zipball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/zipball/v0.4.7"
      },
      {
        "authorType": "User",
        "author_name": "vwxyzjn",
        "body": "",
        "dateCreated": "2021-05-12T13:37:18Z",
        "datePublished": "2021-05-12T13:39:15Z",
        "html_url": "https://github.com/vwxyzjn/cleanrl/releases/tag/v0.4.6",
        "name": "",
        "tag_name": "v0.4.6",
        "tarball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/tarball/v0.4.6",
        "url": "https://api.github.com/repos/vwxyzjn/cleanrl/releases/42841523",
        "zipball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/zipball/v0.4.6"
      },
      {
        "authorType": "User",
        "author_name": "vwxyzjn",
        "body": "",
        "dateCreated": "2021-04-19T04:31:41Z",
        "datePublished": "2021-04-19T04:32:05Z",
        "html_url": "https://github.com/vwxyzjn/cleanrl/releases/tag/v0.4.5",
        "name": "",
        "tag_name": "v0.4.5",
        "tarball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/tarball/v0.4.5",
        "url": "https://api.github.com/repos/vwxyzjn/cleanrl/releases/41620715",
        "zipball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/zipball/v0.4.5"
      },
      {
        "authorType": "User",
        "author_name": "vwxyzjn",
        "body": "",
        "dateCreated": "2021-04-16T16:27:08Z",
        "datePublished": "2021-04-16T16:28:29Z",
        "html_url": "https://github.com/vwxyzjn/cleanrl/releases/tag/v0.4.4",
        "name": "",
        "tag_name": "v0.4.4",
        "tarball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/tarball/v0.4.4",
        "url": "https://api.github.com/repos/vwxyzjn/cleanrl/releases/41554608",
        "zipball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/zipball/v0.4.4"
      },
      {
        "authorType": "User",
        "author_name": "vwxyzjn",
        "body": "",
        "dateCreated": "2021-04-12T02:52:11Z",
        "datePublished": "2021-04-13T18:24:40Z",
        "html_url": "https://github.com/vwxyzjn/cleanrl/releases/tag/v0.2.1",
        "name": "",
        "tag_name": "v0.2.1",
        "tarball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/tarball/v0.2.1",
        "url": "https://api.github.com/repos/vwxyzjn/cleanrl/releases/41372241",
        "zipball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/zipball/v0.2.1"
      },
      {
        "authorType": "User",
        "author_name": "vwxyzjn",
        "body": "",
        "dateCreated": "2021-04-11T22:40:23Z",
        "datePublished": "2021-04-11T22:40:47Z",
        "html_url": "https://github.com/vwxyzjn/cleanrl/releases/tag/v0.4.3",
        "name": "",
        "tag_name": "v0.4.3",
        "tarball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/tarball/v0.4.3",
        "url": "https://api.github.com/repos/vwxyzjn/cleanrl/releases/41249743",
        "zipball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/zipball/v0.4.3"
      },
      {
        "authorType": "User",
        "author_name": "vwxyzjn",
        "body": "",
        "dateCreated": "2021-04-11T22:30:00Z",
        "datePublished": "2021-04-11T22:30:20Z",
        "html_url": "https://github.com/vwxyzjn/cleanrl/releases/tag/v0.4.2",
        "name": "",
        "tag_name": "v0.4.2",
        "tarball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/tarball/v0.4.2",
        "url": "https://api.github.com/repos/vwxyzjn/cleanrl/releases/41249613",
        "zipball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/zipball/v0.4.2"
      },
      {
        "authorType": "User",
        "author_name": "vwxyzjn",
        "body": "",
        "dateCreated": "2021-04-11T22:27:15Z",
        "datePublished": "2021-04-11T22:28:24Z",
        "html_url": "https://github.com/vwxyzjn/cleanrl/releases/tag/v0.4.1",
        "name": "v0.4.1",
        "tag_name": "v0.4.1",
        "tarball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/tarball/v0.4.1",
        "url": "https://api.github.com/repos/vwxyzjn/cleanrl/releases/41249577",
        "zipball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/zipball/v0.4.1"
      },
      {
        "authorType": "User",
        "author_name": "vwxyzjn",
        "body": "# What's new in the 0.4.0 release\r\n* Added contribution guide here https://github.com/vwxyzjn/cleanrl/blob/master/CONTRIBUTING.md. We welcome contribution of new algorithms and new games to be added to the Open RL Benchmark (http://benchmark.cleanrl.dev/)\r\n* Added tables for the benchmark results with standard deviations created by (https://github.com/vwxyzjn/cleanrl/blob/master/benchmark/plots.py)\r\n\r\n## Atari Results\r\n\r\n\r\n| gym_id                      | apex_dqn_atari_visual   | c51_atari_visual   | dqn_atari_visual   | ppo_atari_visual   |\r\n|:----------------------------|:------------------------|:-------------------|:-------------------|:-------------------|\r\n| BeamRiderNoFrameskip-v4     | 2936.93 \u00b1 362.18        | 13380.67 \u00b1 0.00    | 7139.11 \u00b1 479.11   | 2053.08 \u00b1 83.37    |\r\n| QbertNoFrameskip-v4         | 3565.00 \u00b1 690.00        | 16286.11 \u00b1 0.00    | 11586.11 \u00b1 0.00    | 17919.44 \u00b1 383.33  |\r\n| SpaceInvadersNoFrameskip-v4 | 1019.17 \u00b1 356.94        | 1099.72 \u00b1 14.72    | 935.40 \u00b1 93.17     | 1089.44 \u00b1 67.22    |\r\n| PongNoFrameskip-v4          | 19.06 \u00b1 0.83            | 18.00 \u00b1 0.00       | 19.78 \u00b1 0.22       | 20.72 \u00b1 0.28       |\r\n| BreakoutNoFrameskip-v4      | 364.97 \u00b1 58.36          | 386.10 \u00b1 21.77     | 353.39 \u00b1 30.61     | 380.67 \u00b1 35.29     |\r\n\r\n## Mujoco Results\r\n\r\n| gym_id              | ddpg_continuous_action   | td3_continuous_action   | ppo_continuous_action   |\r\n|:--------------------|:-------------------------|:------------------------|:------------------------|\r\n| Reacher-v2          | -6.25 \u00b1 0.54             | -6.65 \u00b1 0.04            | -7.86 \u00b1 1.47            |\r\n| Pusher-v2           | -44.84 \u00b1 5.54            | -59.69 \u00b1 3.84           | -44.10 \u00b1 6.49           |\r\n| Thrower-v2          | -137.18 \u00b1 47.98          | -80.75 \u00b1 12.92          | -58.76 \u00b1 1.42           |\r\n| Striker-v2          | -193.43 \u00b1 27.22          | -269.63 \u00b1 22.14         | -112.03 \u00b1 9.43          |\r\n| InvertedPendulum-v2 | 1000.00 \u00b1 0.00           | 443.33 \u00b1 249.78         | 968.33 \u00b1 31.67          |\r\n| HalfCheetah-v2      | 10386.46 \u00b1 265.09        | 9265.25 \u00b1 1290.73       | 1717.42 \u00b1 20.25         |\r\n| Hopper-v2           | 1128.75 \u00b1 9.61           | 3095.89 \u00b1 590.92        | 2276.30 \u00b1 418.94        |\r\n| Swimmer-v2          | 114.93 \u00b1 29.09           | 103.89 \u00b1 30.72          | 111.74 \u00b1 7.06           |\r\n| Walker2d-v2         | 1946.23 \u00b1 223.65         | 3059.69 \u00b1 1014.05       | 3142.06 \u00b1 1041.17       |\r\n| Ant-v2              | 243.25 \u00b1 129.70          | 5586.91 \u00b1 476.27        | 2785.98 \u00b1 1265.03       |\r\n| Humanoid-v2         | 877.90 \u00b1 3.46            | 6342.99 \u00b1 247.26        | 786.83 \u00b1 95.66          |\r\n\r\n## Pybullet Results\r\n\r\n| gym_id                             | ddpg_continuous_action   | td3_continuous_action   | ppo_continuous_action   |\r\n|:-----------------------------------|:-------------------------|:------------------------|:------------------------|\r\n| MinitaurBulletEnv-v0               | -0.17 \u00b1 0.02             | 7.73 \u00b1 5.13             | 23.20 \u00b1 2.23            |\r\n| MinitaurBulletDuckEnv-v0           | -0.31 \u00b1 0.03             | 0.88 \u00b1 0.34             | 11.09 \u00b1 1.50            |\r\n| InvertedPendulumBulletEnv-v0       | 742.22 \u00b1 47.33           | 1000.00 \u00b1 0.00          | 1000.00 \u00b1 0.00          |\r\n| InvertedDoublePendulumBulletEnv-v0 | 5847.31 \u00b1 843.53         | 5085.57 \u00b1 4272.17       | 6970.72 \u00b1 2386.46       |\r\n| Walker2DBulletEnv-v0               | 567.61 \u00b1 15.01           | 2177.57 \u00b1 65.49         | 1377.68 \u00b1 51.96         |\r\n| HalfCheetahBulletEnv-v0            | 2847.63 \u00b1 212.31         | 2537.34 \u00b1 347.20        | 2347.64 \u00b1 51.56         |\r\n| AntBulletEnv-v0                    | 2094.62 \u00b1 952.21         | 3253.93 \u00b1 106.96        | 1775.50 \u00b1 50.19         |\r\n| HopperBulletEnv-v0                 | 1262.70 \u00b1 424.95         | 2271.89 \u00b1 24.26         | 2311.20 \u00b1 45.28         |\r\n| HumanoidBulletEnv-v0               | -54.45 \u00b1 13.99           | 937.37 \u00b1 161.05         | 204.47 \u00b1 1.00           |\r\n| BipedalWalker-v3                   | 66.01 \u00b1 127.82           | 78.91 \u00b1 232.51          | 272.08 \u00b1 10.29          |\r\n| LunarLanderContinuous-v2           | 162.96 \u00b1 65.60           | 281.88 \u00b1 0.91           | 215.27 \u00b1 10.17          |\r\n| Pendulum-v0                        | -238.65 \u00b1 14.13          | -345.29 \u00b1 47.40         | -1255.62 \u00b1 28.37        |\r\n| MountainCarContinuous-v0           | -1.01 \u00b1 0.01             | -1.12 \u00b1 0.12            | 93.89 \u00b1 0.06            |\r\n\r\n## Other Results\r\n\r\n| gym_id         | ppo            | dqn             |\r\n|:---------------|:---------------|:----------------|\r\n| CartPole-v1    | 500.00 \u00b1 0.00  | 182.93 \u00b1 47.82  |\r\n| Acrobot-v1     | -80.10 \u00b1 6.77  | -81.50 \u00b1 4.72   |\r\n| MountainCar-v0 | -200.00 \u00b1 0.00 | -142.56 \u00b1 15.89 |\r\n| LunarLander-v2 | 46.18 \u00b1 53.04  | 144.52 \u00b1 1.75   |\r\n\r\n* Added experimental support for Apex-DQN that is significantly faster than DQN. See https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/apex_dqn_atari_visual.py. In the game of breakout, Apex-DQN takes less than 4 hours to achieve around 360 episode reward. In contrast, it took 25 hours for DQN to reach 360 episode rewards.\r\n    * Our implementation is a little different from the original. First, in pytorch's ecosystem there isn't a well-mainained distributed prioritized experience buffer such as https://github.com/deepmind/reverb. So instead we split a single prioritized replay buffer of size 100000 to two prioritized replay of size 50000 in different `data-processors` in sub-processes to prepare data for the `worker`. This is kind of a work around and a hack but according to our [benchmark](https://app.wandb.ai/cleanrl/cleanrl.benchmark/reports/Atari--VmlldzoxMTExNTI), it works empirically **good and fast enough**.\r\n\r\nBenchmarked Learning Curves             |  Atari\r\n:-------------------------:|:-------------------------:\r\nMetrics, logs, and recorded videos are at  |  [cleanrl.benchmark/reports/Atari](https://app.wandb.ai/cleanrl/cleanrl.benchmark/reports/Atari--VmlldzoxMTExNTI)\r\n![](https://microrts.s3.amazonaws.com/microrts/cleanrl/open-rl-benchmark/0.3/plots/QbertNoFrameskip-v4.svg)  |  ![](https://microrts.s3.amazonaws.com/microrts/cleanrl/open-rl-benchmark/0.3/plots/BeamRiderNoFrameskip-v4.svg)\r\n![](https://microrts.s3.amazonaws.com/microrts/cleanrl/open-rl-benchmark/0.3/plots/SpaceInvadersNoFrameskip-v4.svg)  |  ![](https://microrts.s3.amazonaws.com/microrts/cleanrl/open-rl-benchmark/0.3/plots/PongNoFrameskip-v4.svg)\r\n![](https://microrts.s3.amazonaws.com/microrts/cleanrl/open-rl-benchmark/0.3/plots/BreakoutNoFrameskip-v4.svg)  |  &nbsp;\r\n\r\n* Supported `CarRacing-v0` by PPO in the Experimental Domains. It is our first example with pixel observation space and continuous action space. See https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/experiments/ppo_car_racing.py. \r\n    * During our experiments, we found the normalization of observation and reward seems to have a huge impact on PPO's performance, probably due to the large range of rewards provided by `CarRacing-v0` (e.g. if dies you get -100 reward, but PPO is anecdotally sensitive to this kind of large rewards).\r\n\r\n![image](https://user-images.githubusercontent.com/5555347/94094740-403ced80-fdee-11ea-884d-d6ef2b7b6608.png)\r\n\r\n",
        "dateCreated": "2020-09-24T02:33:32Z",
        "datePublished": "2020-09-24T02:50:29Z",
        "html_url": "https://github.com/vwxyzjn/cleanrl/releases/tag/0.4.0",
        "name": "CleanRL v0.4.0",
        "tag_name": "0.4.0",
        "tarball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/tarball/0.4.0",
        "url": "https://api.github.com/repos/vwxyzjn/cleanrl/releases/31738166",
        "zipball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/zipball/0.4.0"
      },
      {
        "authorType": "User",
        "author_name": "vwxyzjn",
        "body": "See https://streamable.com/cq8e62 for a demo\r\n\r\nSignificant amount of effort was put into the making of Open RL Benchmark (http://benchmark.cleanrl.dev/). It provides benchmark of popular Deep Reinforcement Learning algorithms in 34+ games with unprecedented level of transparency, openness, and reproducibility.\r\n\r\nIn addition, the legacy `common.py` is depreciated in favor of using single-file implementations.\r\n",
        "dateCreated": "2020-08-01T22:25:13Z",
        "datePublished": "2020-08-01T22:57:05Z",
        "html_url": "https://github.com/vwxyzjn/cleanrl/releases/tag/0.3.0",
        "name": "Release of Open RL Benchmark @ 0.3.0",
        "tag_name": "0.3.0",
        "tarball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/tarball/0.3.0",
        "url": "https://api.github.com/repos/vwxyzjn/cleanrl/releases/29197077",
        "zipball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/zipball/0.3.0"
      },
      {
        "authorType": "User",
        "author_name": "vwxyzjn",
        "body": "We've made the SAC algorithm works for both continuous and discrete action spaces, with primary references from the following papers:\r\n\r\nhttps://arxiv.org/abs/1801.01290\r\nhttps://arxiv.org/abs/1812.05905\r\nhttps://arxiv.org/abs/1910.07207\r\n\r\nMy personal thanks to everyone who participated in the monthly dev cycle and, in particular, @dosssman who implemented the SAC with discrete action spaces.\r\n\r\nAdditional improvement include\r\nsupport gym.wrappers.Monitor to automatically record agent\u2019s performance at certain episodes (default is 1, 2, 9, 28, 65, ... 1000, 2000, 3000) and integrate with wandb. (so cool, see screenshot below) #4 \r\nUse the same replay buffer from minimalRL for DQN and SAC #5\r\n\r\nhttps://app.wandb.ai/cleanrl/cleanrl.benchmark\r\n\r\n![image](https://user-images.githubusercontent.com/5555347/72108416-8f46ff00-3301-11ea-91d7-04c611f28ee7.png)\r\n\r\n",
        "dateCreated": "2020-01-09T22:27:12Z",
        "datePublished": "2020-01-09T22:00:57Z",
        "html_url": "https://github.com/vwxyzjn/cleanrl/releases/tag/0.2.1",
        "name": "CleanRL 0.2.1 with SAC added and video recording feature.",
        "tag_name": "0.2.1",
        "tarball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/tarball/0.2.1",
        "url": "https://api.github.com/repos/vwxyzjn/cleanrl/releases/22726879",
        "zipball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/zipball/0.2.1"
      },
      {
        "authorType": "User",
        "author_name": "vwxyzjn",
        "body": "This is the initial release \ud83d\ude4c\ud83d\ude4c\r\n\r\nWorking on more algorithms and where and bug fixes for the 1.0 release :) Comments and PR are more than welcome.",
        "dateCreated": "2019-10-07T01:17:33Z",
        "datePublished": "2019-10-07T03:13:15Z",
        "html_url": "https://github.com/vwxyzjn/cleanrl/releases/tag/V0.1",
        "name": "Initial Release",
        "tag_name": "V0.1",
        "tarball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/tarball/V0.1",
        "url": "https://api.github.com/repos/vwxyzjn/cleanrl/releases/20505863",
        "zipball_url": "https://api.github.com/repos/vwxyzjn/cleanrl/zipball/V0.1"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 584,
      "date": "Thu, 23 Dec 2021 13:34:10 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We have a [Discord Community](https://discord.gg/D6RCjA6sVT) for support. Feel free to ask questions. Posting in [Github Issues](https://github.com/vwxyzjn/cleanrl/issues) and PRs are also welcome. Also our past video recordings are available at [YouTube](https://www.youtube.com/watch?v=dm4HdGujpPs&list=PLQpKd36nzSuMynZLU2soIpNSMeXMplnKP&index=2)\n\n",
      "technique": "Header extraction"
    }
  ],
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "wandb",
      "reinforcement-learning",
      "pytorch",
      "python",
      "gym",
      "machine-learning",
      "deep-reinforcement-learning",
      "deep-learning",
      "atari",
      "ale",
      "a2c",
      "proximal-policy-optimization",
      "ppo",
      "advantage-actor-critic",
      "actor-critic"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Prerequisites:\n* Python 3.8+\n* [Poetry](https://python-poetry.org)\n\nTo run experiments locally, give the following a try:\n\n```bash\ngit clone https://github.com/vwxyzjn/cleanrl.git && cd cleanrl\npoetry install\n\n#: alternatively, you could use `poetry shell` and do\n#: `python run cleanrl/ppo.py`\npoetry run python cleanrl/ppo.py \\\n    --seed 1 \\\n    --gym-id CartPole-v0 \\\n    --total-timesteps 50000\n\n#: open another temrminal and enter `cd cleanrl/cleanrl`\ntensorboard --logdir runs\n```\n\nTo use experiment tracking with wandb, run\n```bash\nwandb login #: only required for the first time\npoetry run python cleanrl/ppo.py \\\n    --seed 1 \\\n    --gym-id CartPole-v0 \\\n    --total-timesteps 50000 \\\n    --track \\\n    --wandb-project-name cleanrltest\n```\n\nTo run training scripts in other games:\n```\npoetry shell\n\n#: classic control\npython cleanrl/dqn.py --gym-id CartPole-v1\npython cleanrl/ppo.py --gym-id CartPole-v1\npython cleanrl/c51.py --gym-id CartPole-v1\n\n#: atari\npoetry install -E atari\npython cleanrl/dqn_atari.py --gym-id BreakoutNoFrameskip-v4\npython cleanrl/c51_atari.py --gym-id BreakoutNoFrameskip-v4\npython cleanrl/ppo_atari.py --gym-id BreakoutNoFrameskip-v4\npython cleanrl/apex_dqn_atari.py --gym-id BreakoutNoFrameskip-v4\n\n#: pybullet\npoetry install -E pybullet\npython cleanrl/td3_continuous_action.py --gym-id MinitaurBulletDuckEnv-v0\npython cleanrl/ddpg_continuous_action.py --gym-id MinitaurBulletDuckEnv-v0\npython cleanrl/sac_continuous_action.py --gym-id MinitaurBulletDuckEnv-v0\n\n#: procgen\npoetry install -E procgen\npython cleanrl/ppo_procgen.py --gym-id starpilot\npython cleanrl/ppo_procgen_impala_cnn.py --gym-id starpilot\npython cleanrl/ppg_procgen.py --gym-id starpilot\npython cleanrl/ppg_procgen_impala_cnn.py --gym-id starpilot\n```\n\nYou may also use a prebuilt development environment hosted in Gitpod:\n\n[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/vwxyzjn/cleanrl/tree/gitpod)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "We have a [Discord Community](https://discord.gg/D6RCjA6sVT) for support. Feel free to ask questions. Posting in [Github Issues](https://github.com/vwxyzjn/cleanrl/issues) and PRs are also welcome. Also our past video recordings are available at [YouTube](https://www.youtube.com/watch?v=dm4HdGujpPs&list=PLQpKd36nzSuMynZLU2soIpNSMeXMplnKP&index=2)\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Our code is based on [CornetNets](https://github.com/princeton-vl/CornerNet)\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1908.04646",
      "https://arxiv.org/abs/2001.03194"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9686679014285212,
        0.8906174419333412
      ],
      "excerpt": "Matrix Nets (ICCV'19) (short paper) \nMatrix Nets (long paper) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/arashwan/matrixnet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-01-08T17:11:52Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T11:20:15Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9660961451822401
      ],
      "excerpt": "MatrixNetis a scale and aspect ratio aware deep learning architecture for object detection. We implemented matrixnets anchors (centers) and corners. For more details, please refer to the papers linked below. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9197401320531927
      ],
      "excerpt": "We have two implementations based on Corners and Anchor (Centers): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9131873759692358
      ],
      "excerpt": "Code for reproducing the results in the following paper: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9815310161392529
      ],
      "excerpt": "One of the capabilities offered by MatrixNets is to be able to choose which layers to use for training and inference. Although we used 19 layers matrixnet in the paper, we implemented matrixnet here such that any matrixnet design can be specified by setting the layer_range variable in the config file. The layer_range is defined as a 3D matrix were the outer matrix is 5x5, and each entry of this matrix is either a 1D matrix of [y_min, y_max, x_min, x_max] or -1 if we do not want to include this layer. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9112253164455408
      ],
      "excerpt": "In the paper, we use a 19-layer MatrixNet by ignoring the left top and bottom right corners of the 5x5 matrix. The range for the base layer (top left) is [24,48,24,48]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9622278953475406,
        0.9386867028721486
      ],
      "excerpt": "Note that we extended the range for the layers on the boundary to include any objects that are out of range. \nFollowing table gives the AP for Corners and Anchors with different backbones (from the paper): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8590024379855875
      ],
      "excerpt": "You also need to compile the NMS code (originally from Faster R-CNN and Soft-NMS). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8418471502970342
      ],
      "excerpt": "To evaluate the trained model: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9010581478798815
      ],
      "excerpt": "We provide pre-trained models for Resnet-50 and Resnet-152 for both Anchors and Corners. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9640498506057966,
        0.8504710528799249
      ],
      "excerpt": "Note that the results might be slightly different from the paper (+/- 0.2 MAP) since we reproduced all experiments using only 4 GPUs. We could not fit the batch size of 23 for the anchors' experiments, so we ran the experiments for longer iterations to compensate for the smaller batch size. \nList of avialble configuration options: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9487943984173833
      ],
      "excerpt": "|chunk_sizes| Size of chunk as a array of dim #GPU that sums to batch_size| | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9013892949663327
      ],
      "excerpt": "|output_kernel_size| This helps smoothing the heatmaps to get the max detections | | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8939693810161974,
        0.8442264680480955
      ],
      "excerpt": "|layers_range| 3D matrix of Layer Range -1 inbdicating which layer to ignore| | \n|test_image_max_dim| max dim of input image | | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8547930948887938,
        0.8853446863258779
      ],
      "excerpt": "|backbone|  Backbone for Matrix Nets| resnet50, resnet100, resnet152, resnext101 \nContributions to this project are welcome. Please make a pull request and we will attend to it as soon as possible.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "PyTorch implementation for MatrixNet object detection architecture.",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Download the training/validation split we use in our paper from [here](http://images.cocodataset.org/annotations/annotations_trainval2017.zip) \n- Unzip the file and place `annotations` under `<MatrixNets dir>/data/coco`\n- Download the images (2017 Train and 2017 Val) from [here](http://cocodataset.org/#download)\n- Create 2 directories, `train2017` and `val2017`, under `<MatrixNets dir>/data/coco/images/`\n- Copy the training/validation/testing images to the corresponding directories according to the annotation files\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/arashwan/matrixnet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 32,
      "date": "Fri, 24 Dec 2021 03:42:26 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/arashwan/matrixnet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "arashwan/matrixnet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8105838603073406,
        0.8528319635721288,
        0.9284405280859939,
        0.9554169436001461,
        0.9907503432104107,
        0.9979947896609701,
        0.9600162711695286
      ],
      "excerpt": "Please first install Anaconda and create an Anaconda environment using the provided package list. \nconda create --name matrixnets --file packagelist_conda.txt \nAfter one creates the environment, activate it. \nsource activate matrixnets \nAlternatively, one can use pip and install all packages from the requirements file. Note we are using python 3.6+. Torch 1.2.0 and torchvision 0.4.0 \npip install -r requirements.txt \nOur current implementation only supports GPU, so one needs a GPU and need to have CUDA(9+)  installed on your machine. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8778487586960795
      ],
      "excerpt": "Example 1: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8576591754281959
      ],
      "excerpt": "To train a model: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8303798559955017,
        0.9503189345333785
      ],
      "excerpt": "To train MatrixNets: \npython train.py MatrixNetsCornersResnet50 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8553935792823001
      ],
      "excerpt": "--debug flag can be used to save the first 200 images with detections under results directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8185590166492436
      ],
      "excerpt": "Here cache_name is the name of the directory specified in config.json and name should be in the format &lt;model_iters.pkl&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.81260763509323
      ],
      "excerpt": "| train_split |Spcify train set|  | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8555068879917942,
        0.8596867505096984
      ],
      "excerpt": "|test_flip_images| flip flag | True, False | \n|cutout| cutout flag| True, False|  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8719087906524823
      ],
      "excerpt": "|merge_bbox| Merge bbox flag| True, False| \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/arashwan/matrixnet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 \\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# MatrixNets",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "matrixnet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "arashwan",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/arashwan/matrixnet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 171,
      "date": "Fri, 24 Dec 2021 03:42:26 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        0.8971187077988846
      ],
      "excerpt": "intelligence which seemed unthinkable 10 years ago. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944484218006108
      ],
      "excerpt": " https://arxiv.org/pdf/1509.06461.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9203562573642668
      ],
      "excerpt": "2.) Alpha Zero  (See also Wickipedia-Article:   https://en.wikipedia.org/wiki/AlphaZero)  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/NikolausBerl/Udacity_DRLN_Navigation_Project",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-10T16:03:43Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-23T09:13:55Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9972200762393191,
        0.9448633518507967
      ],
      "excerpt": "The \"Navigation\" Project is part of the \"Deep Reinforcement Learning\" Nanodegree study of Udacity. \nTo get the Nanodegree-Diploma, students have to realize several software projects in a given time. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8147994932834178,
        0.9564398153658729,
        0.8490037945672047
      ],
      "excerpt": "In the following picture you can see the  principle structure of a \"Reinforcement Learning\"-System: \nSuch a system is composed of the following componends: \nthe agent  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490037945672047
      ],
      "excerpt": "the reward \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490037945672047
      ],
      "excerpt": "the actions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9346095341968703,
        0.8524486612723243
      ],
      "excerpt": "on his own and often finds better and faster solutions as human beings. \nAt the beginning to solve his task, the agent knows nothing about the environment. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8946791693245914,
        0.8330642615643449
      ],
      "excerpt": "Actions can be e.g. moving forward, backward, left and right, as used in this project.  \nOne move is one action and the agent gets back an information about the state and he  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8765393451679518,
        0.8903541360260754
      ],
      "excerpt": "for solving the agents task. \nWe will have a look in detail on the here applied Deep Q-Learning-algorithm  in the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8862211899576243
      ],
      "excerpt": "In recent the years, there have been some crucial technical breakthroughs in the field of artificial \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8839129116308115,
        0.9390830842448861,
        0.9798168031260938,
        0.9629962971611608
      ],
      "excerpt": "In this science work from 2015 the scientists developed an algorithm which was applied on 57-Atari-Plays. \nThe Agent took the role of a human player and got impressive results mostly far better  then human players. \nThe special Deep-Q-Learning-Algorithm (Double-Q-Learning) of this science paper is applied in the given Navigation \nproject.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9550024581335042
      ],
      "excerpt": "This Software was able to learn to play chess and reached a world champion level in 4 hours. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8688200200977895,
        0.9517949260432786,
        0.9653823968172746,
        0.9787311557866409
      ],
      "excerpt": "Breakehroughs in Neural Network Structures like CNN, RNN, GAN, RL etc. as well as the improved computational CPU-power played an importand role in this progress. \nThe goal of the agent is to collect in his environment as many yellow bananas as possible while avoiding blue bananas. \nA reward of +1 is provided for collecting a yellow banana, and a reward of -1 is provided for collecting a blue banana.  \nThe state space has 37 dimensions and contains the agent's velocity, along with ray-based perception of objects around the agent's forward direction. Given this information, the agent has to learn how to best select actions. Four discrete actions are available, corresponding to: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Navigation-Project: Project Nr 1 of the Deep-Reinforcement-Learning-Nanodegree of Udacity",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://jupyter.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/NikolausBerl/Udacity_DRLN_Navigation_Project/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 10:39:11 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/NikolausBerl/Udacity_DRLN_Navigation_Project/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "NikolausBerl/Udacity_DRLN_Navigation_Project",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/NikolausBerl/Udacity_DRLN_Navigation_Project/master/Navigation.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9612719626527538
      ],
      "excerpt": "the environment \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8621882743635256
      ],
      "excerpt": "file repord.md. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/NikolausBerl/Udacity_DRLN_Navigation_Project/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "### Preliminary remark:",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Udacity_DRLN_Navigation_Project",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "NikolausBerl",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/NikolausBerl/Udacity_DRLN_Navigation_Project/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 10:39:11 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Step 1:  \nFirst, please follow the instructions of the part dependencies on the Link below.\nhttps://github.com/udacity/deep-reinforcement-learning\n\nStep 2: \nInstall the Unity-Banana-Environment for your operating system.  \n\nhttps://github.com/udacity/deep-reinforcement-learning/tree/master/p1_navigation\n\nStep 3:   \nCopy the files of my Github-Project-Directory in your local project-directory.\n\nStep 4:  \nStart your jupyter Notebook and call the \"navigation.ipynb\"-File in the working directory.\n(If jupyter notebook is not available on your computer, install it:    \nhttps://jupyter.readthedocs.io/en/latest/install.html)\n\ngood luck \u263a\ufe0f\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1502.03167\n  \"\"\"\n  with tf.variable_scope(name, default_name=\"batch_normalization\""
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9156566588472104
      ],
      "excerpt": "prefixo ! antes do comando de shell. (e.g. para listar os arquivos da pasta \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "* Por\u00e9m aumenta a complexidade, o que o torna de mais dif\u00edcil \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123719142248591,
        0.8123719142248591
      ],
      "excerpt": "x = np.random.normal(size=[10, 10]) \ny = np.random.normal(size=[10, 10]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9535428095058772,
        0.9535428095058772
      ],
      "excerpt": "x = tf.random_normal([10, 10]) \ny = tf.random_normal([10, 10]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Se tentarmos escrever o valor de z \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9535428095058772,
        0.9535428095058772
      ],
      "excerpt": "x = tf.random_normal([10, 10]) \ny = tf.random_normal([10, 10]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9629329729245205
      ],
      "excerpt": "  \"text\": \"Tensor(\\\"MatMul:0\\\", shape=(10, 10), dtype=float32)\\n\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066,
        0.8356013927728488,
        0.8109194328925066
      ],
      "excerpt": "inferir o formato do tensor de sa\u00edda, assim como seu tipo. \nA fim de computar o \nvalor do tensor, faz-se necess\u00e1rio criar uma sess\u00e3o e avali\u00e1-la usando o m\u00e9todo \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Assuma que tenhamos amostras de uma curva (digamos $f(x) = 5x^2 + \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Isso pode ser feito minimizando a seguinte fun\u00e7\u00e3o de perda $L(w) = \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Apesar de que haja uma solu\u00e7\u00e3o fechada para este \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Simplesmente calcula-se o gradiente m\u00e9dio de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123719142248591
      ],
      "excerpt": "    x_val = np.random.uniform(-10.0, 10.0, size=100) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8028046190715653
      ],
      "excerpt": "tais como otimizar uma grande rede neural com milh\u00f5es de par\u00e2metros pode ser \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "suporta uma variedade de plataformas. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "* a primeira dimens\u00e3o pode ser de qualquer tamanho e ser\u00e1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8283216015784888
      ],
      "excerpt": "O formato est\u00e1tico de um tensor pode ser definido com o m\u00e9todo \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "  \"text\": \"('static_shape1 = ', [32, 128])\\n('static_shape2 = ', [32, 128])\\n\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "  \"text\": \"('a_shape = ', [32, 128])\\n('a_shape = ', [128, 32])\\n\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9507374082549614
      ],
      "excerpt": "Imaginemos que se queira converter um Tensor de dimens\u00e3o 3 para um um de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9507374082549614,
        0.8356013927728488
      ],
      "excerpt": "Pode-se escrever uma fun\u00e7\u00e3o de redimensionamento de prop\u00f3sito geral para \ncolapsar qualquer lista de qualquer dimens\u00e3o: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "    if isinstance(dims, int): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "* Utilizando-se de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Isso se faz \u00fatil por exemplo quando se utiliza camadas de redes neurais \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "contr\u00e1rio reutiliz\u00e1-la: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Caso queira-se fazer muitos compartilhamento de vari\u00e1veis mantendo-se o controle \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "o risco de compartilhar vari\u00e1veis que supostamente n\u00e3o deveriam ser \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9482401847497453
      ],
      "excerpt": "de acordo, por exemplo, n\u00e3o se pode adicionar um tensor de dimens\u00e3o [3,2] com \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9482401847497453
      ],
      "excerpt": "tensor de dimens\u00e3o [3, 2] com um tensor de dimens\u00e3o [3, 1]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278824608274014
      ],
      "excerpt": "da opera\u00e7\u00e3o de agrupamento. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8028046190715653,
        0.8356013927728488
      ],
      "excerpt": "A fim de concatenar features de \ntamanhos diferentes normalmente agrupa-se os tensores de entrada, concatena o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "entre v\u00e1rias arquiteturas de redes neurais. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9788914761692258,
        0.8356013927728488
      ],
      "excerpt": "Por\u00e9m isso pode ser feito de maneira mais eficiente com uso de difus\u00e3o. Usa-se o \nfato de que f(m(x+y)) \u00e9 igual a f(mx+my). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "tensores de dimens\u00f5es arbitr\u00e1rias contanto que seja poss\u00edvel fazer a difus\u00e3o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "  \"text\": \"12.0\\n\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Qual voc\u00ea pensaria que seria o valor de c? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.8356013927728488
      ],
      "excerpt": "Ser\u00e1 12. \nIsso porque quando o rank de dois tensores n\u00e3o combinam, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278824608274014,
        0.9507374082549614
      ],
      "excerpt": "antes de fazer a opera\u00e7\u00e3o elemento a elemento, portanto o resultado da adi\u00e7\u00e3o \nseria [[2,3],[3,4]], e a redu\u00e7\u00e3o de todos os par\u00e2metros daria 12. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "de evitar esse problema \u00e9 ser t\u00e3o expl\u00edcito quanto se poda. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "especificado qual a dimens\u00e3o n\u00f3s gostar\u00edamos de reduzir, encontrar esse bug \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9482401847497453
      ],
      "excerpt": "de maneira eficiente com grandes quantidades de dados. Portanto \u00e9 importante n\u00e3o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "t\u00eam-se que carregar todos os dados na mem\u00f3ria de uma vez a mant\u00ea-los na mem\u00f3ria, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "O operador de espa\u00e7os reservados retora um tensor cujo vajor \u00e9 capturado a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Caso voc\u00ea tenha que ler seus dados a partir de um arquivo pode ser mais \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "usando pipelines de maneira f\u00e1cil. Por exemplo, assim processamos nossos dados \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9507374082549614
      ],
      "excerpt": "mem\u00f3ria a fim de aumentar a efici\u00eancia. Durante o modo de treino, repetimos o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.9507374082549614
      ],
      "excerpt": "grafos e tornar o c\u00f3digo mais f\u00e1cil de ler. \nA opera\u00e7\u00e3o de reparti\u00e7\u00e3o \u00e9 um dos operadores que pode facilitar a indexa\u00e7\u00e3o de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8592871015078041,
        0.9865374311292784
      ],
      "excerpt": "z = x[begin:end]  #: z = tf.slice(x, [begin], [end-begin]) \nPor\u00e9m h\u00e1 de ser cuidadoso ao utilizar a opera\u00e7\u00e3o de reparti\u00e7\u00e3o. A opera\u00e7\u00e3o de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278824608274014
      ],
      "excerpt": "n\u00famero de reparti\u00e7\u00f5es \u00e9 alto. Para entender qu\u00e3o ineficiente tal opera\u00e7\u00e3o pode \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9243188970772274
      ],
      "excerpt": "para separar a matriz em uma lista de vetores de uma s\u00f3 vez: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9243188970772274
      ],
      "excerpt": "Essa opera\u00e7\u00e3o demorou 0.18 segundos. Com certeza, a maeira correta de fazer essa \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "l\u00f3gicas de maneira mais eficiente: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9243188970772274
      ],
      "excerpt": "suportadas \u00e9 a de igual(==) e de diferente(!=), operadores que s\u00e3o permitidos em \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9865374311292784
      ],
      "excerpt": "tempo de execu\u00e7\u00e3o para determinar a ordem de execu\u00e7\u00e3o \u00f3tima e poss\u00edvel corte de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "que n\u00e3o se pode sobrescrever o valor de um tensor. Caso queira-se modificar o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Diferente de tensores, vari\u00e1veis podem ser atualizadas. Portanto vejamos como \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8088275851153562
      ],
      "excerpt": "for i in range(10): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "dependendo de qual adi\u00e7\u00e3o ou atribui\u00e7\u00e3o \u00e9 executada primeiro. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8592871015078071
      ],
      "excerpt": "TensorFlow. A \u00fanica coisa que importa \u00e9 o controle de depend\u00eancias. Controle de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8088275851153562
      ],
      "excerpt": "for i in range(10): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8592871015078041,
        0.8356013927728488
      ],
      "excerpt": "fluxo de opera\u00e7\u00f5es a partir de condicionais e loops. Nesta se\u00e7\u00e3o introduzimos as \nopera\u00e7\u00f5es mais comumente utilizada para controle de fluxo. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9088460908939341
      ],
      "excerpt": "tf.cond que atua como o condicional if if: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8592871015078071
      ],
      "excerpt": "Outro m\u00e9todo de controle de fluxo bastante utilizado \u00e9 tf.while_loop. Que \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8283216015784888
      ],
      "excerpt": "tamanho vari\u00e1vel. Vejamos como gerar a sequencia de Fibonacci com \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9507374082549614
      ],
      "excerpt": "de loop s\u00e3o ent\u00e3o atualizadas por m\u00faltiplas chamadas na fun\u00e7\u00e3o de corpo at\u00e9 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9702105236373249
      ],
      "excerpt": "sequ\u00eancia da s\u00e9rie de Fibonacci. Teremos que atualizar o corpo da fun\u00e7\u00e3o para \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9243188970772274
      ],
      "excerpt": "tem uma  melhor forma de solucionar esse tipo de arrays crescentes. Conhe\u00e7a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "antes de passar horas implementando seu kernel, voc\u00ea pode querer prototipar algo \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Por exemplo, assim pode-se implementar uma simples kernel de n\u00e3o linearidade \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8964737401288927
      ],
      "excerpt": "    diff = tf.test.compute_gradient_error(x, [10], y, [10]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8592871015078041
      ],
      "excerpt": "construindo um modelo de classificador de imagem e queira vizualizar as \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.8356013927728488
      ],
      "excerpt": "Por\u00e9m visualiza-se comente a imagem de entrada. Para que se possa visualizar a \npredi\u00e7\u00e3o, tem-se que encontrar uma maneira de adicionar anota\u00e7\u00f5es \u00e0s imagens, o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8834756699654108
      ],
      "excerpt": "    img = PIL.Image.open(buf) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9243188970772274
      ],
      "excerpt": "Comecemos por um exemplo simples de adi\u00e7\u00e3o de dois vetores em uma CPU: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.8356013927728488
      ],
      "excerpt": "Vamos escrever isso de uma maneira mais generalizada para que possamos \nsubstituir a opera\u00e7\u00e3o de adi\u00e7\u00e3o por qualquer outra opera\u00e7\u00e3o: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8283216015784888
      ],
      "excerpt": "s\u00e9rie de tensores e retorne um tensor como resultado com a condi\u00e7\u00e3o que ambps, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "quer\u00edamos treinar um polin\u00f4mio de segunda ordem para algumas amostras. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123719142248591
      ],
      "excerpt": "    x_val = np.random.uniform(-10.0, 10.0, size=100) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "modificar somente duas linhas de c\u00f3digo do c\u00f3digo acima: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "A unica coisa que precisamos para mudar para paralelizar o backpropagation de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "tarefa de debugar mais f\u00e1cil. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8283216015784888
      ],
      "excerpt": "podem operar com tensores de ranks e tamanhos diferentes. Isso pode ser \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9507374082549614
      ],
      "excerpt": "Outro exemplo que discutimos antes na se\u00e7\u00e3o de difus\u00e3o \u00e9 a opera\u00e7\u00e3o de adi\u00e7\u00e3o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8592871015078041,
        0.8283216015784888
      ],
      "excerpt": "Uma maneira de reduzir as chances de comportamento indesejado \u00e9 verificar \nexplicitamente o rank ou dimens\u00e3o de tensores intermedi\u00e1rios com opera\u00e7\u00f5es \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "Lembre-se que n\u00f3s de afirma\u00e7\u00e3o, assim como outras opera\u00e7\u00f5es s\u00e3o parte do grafo e \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9507374082549614
      ],
      "excerpt": "de criar depend\u00eancias expl\u00edcitas para opera\u00e7\u00f5es de afirma\u00e7\u00e3o, para for\u00e7ar o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Voc\u00ea pode tamb\u00e9m  afirma\u00e7\u00f5es para validar o valore de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9507374082549614
      ],
      "excerpt": "Veja os documentos oficiais para lista completa de opera\u00e7\u00f5es de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "b antes de adicionar ent\u00e3o poderiamos fazer algo assim: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Alternativamente podemos manualmente definir o controle de depend\u00eancia. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8528714716777485
      ],
      "excerpt": "de TensorFlow v\u00eam com gradientes, e \u00e9 facil construir graphs (n\u00e3o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.9243188970772274
      ],
      "excerpt": "entropia de uma distribui\u00e7\u00e3o categ\u00f3rica. E por fim utilizamos o otimizador Adam \npara encontrar os pesos com m\u00e1xima entropia. Se voc\u00ea fez um curso de teoria da \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Ao utilizar qualquer m\u00f3dulo de computa\u00e7\u00e3o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9507374082549614
      ],
      "excerpt": "x*y/y \u00e9 igual a x para qualquer valor de x diferente de zero. Por\u00e9m vejamos se \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "acima de 3.40282e+38 \u00e9 guardado como infinito. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.8356013927728488
      ],
      "excerpt": "pequeno ou muito grandes. Isso pode soar um pouco \u00f3bvio, por\u00e9m esse tipo de \nproblema pode ser extremamente dif\u00edcil de debugar, especialmente quando se est\u00e1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Mas como podemos faz\u00ea-la mais \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278824608274014
      ],
      "excerpt": "m\u00e1ximo de logits. Dessa forma o dom\u00ednio da fun\u00e7\u00e3o exponencial seria limitado a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Vejamos um caso mais complicado. Considere que temos um problema de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "logits. Definimos a fun\u00e7\u00e3o de perda ara ser a entropia cruzada entre a predi\u00e7\u00e3o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9507374082549614
      ],
      "excerpt": "zero, o regristo de sa\u00edda se aproxima de infinito o que causa instabilidade na \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.9278824608274014
      ],
      "excerpt": "Deixe-me lebrar-lhes outra vez que cuidado extra tem de ser \ntomado quando se usa gradiente descendente para se assegurar que o intervalo de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "camada est\u00e3o dentro do intervalo de estabilidade. Fun\u00e7\u00f5es exponencial e \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "podem variar de valores muito pequenos a valores muito grandes rapidamente. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8028046190715653,
        0.9962282006245561
      ],
      "excerpt": "trabalhar com modelos de redes neurais normalmente tem-se uma separa\u00e7\u00e3o do \nconjunto de treino e de teste. Treina-se o modelo com o conjunto de treion, e de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9507374082549614
      ],
      "excerpt": "idealmente espera-se ser capaz de parar e retomar o treinamento de qualquer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9964189199332645
      ],
      "excerpt": "opera\u00e7\u00e3o de treino, um ou um conjunto de predi\u00e7\u00f5es, e um conjunto de m\u00e9tricas de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "inserindo uma fun\u00e7\u00e3o de entrada para leitura dos dados: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8028046190715653
      ],
      "excerpt": "TensorFlow fornece um objeto de maior hierarquia chamado Experiment que \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278824608274014
      ],
      "excerpt": "Uma maneira ainda mais alto n\u00edvel de rodar experimento \u00e9 usando a fun\u00e7\u00e3o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.8356013927728488
      ],
      "excerpt": "A fun\u00e7\u00e3o de entrada retorna \ndois tensores (ou dicion\u00e1rio de tensores) fornecendo os recursos e r\u00f3tulos a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Essa se\u00e7\u00e3o inclui a implementa\u00e7\u00e3o de v\u00e1rias opera\u00e7\u00f5es \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    end_token_id: End token id. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "if activation: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156566588472104,
        0.9156566588472104
      ],
      "excerpt": "    q: A tuple (mu, log(sigma^2)) representing a multi-variatie Gaussian. \n    p: A tuple (mu, log(sigma^2)) representing a multi-variatie Gaussian. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9933909519512236
      ],
      "excerpt": "Based on: https://arxiv.org/abs/1502.03167 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8456806903995955,
        0.8665716475375693
      ],
      "excerpt": "if training: \n  if fused_batch_norm: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "if fused_batch_norm: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8456806903995955
      ],
      "excerpt": "if training: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/gmouzella/Efective_TensorFlow",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-12-05T13:34:37Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-12-05T13:57:36Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9499859891647274,
        0.8694656888893336
      ],
      "excerpt": ": Assuming we know that the desired function is a polynomial of 2nd degree, we \n: allocate a vector of size 3 to hold the coefficients. The variable will be \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9815564764605631
      ],
      "excerpt": ": We define yhat to be our estimate of y. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9735600665986454
      ],
      "excerpt": ": The loss is defined to be the l2 distance between our estimate of y and its \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8867486711166445
      ],
      "excerpt": ": We use the Adam optimizer with learning rate set to 0.1 to minimize the loss. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9683628829998558
      ],
      "excerpt": "a.set_shape([32, 128])  #: static shape of a is [32, 128] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8447324112877723
      ],
      "excerpt": "  dims = [s[1] if s[0] is None else s[0] for s in zip(static_shape, dynamic_shape)] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "  for dims in dims_list: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8883144673933896
      ],
      "excerpt": "    elif all([isinstance(shape[d], int) for d in dims]): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "with tf.name_scope(\"scope\"): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "with tf.variable_scope(\"scope\"): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "with tf.variable_scope(\"scope\"): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "with tf.variable_scope(\"scope\"): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "with tf.variable_scope('my_scope'): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "with tf.variable_scope(\"scope\", reuse=tf.AUTO_REUSE): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9319708861235405
      ],
      "excerpt": "with tf.Session() as session: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": ": concat a and b and apply nonlinearity \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9319708861235405
      ],
      "excerpt": "with tf.Session() as session: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9319708861235405
      ],
      "excerpt": "with tf.Session() as session: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9319708861235405
      ],
      "excerpt": "with tf.Session() as session: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9598110173139803,
        0.9863662160139922,
        0.831509636393395
      ],
      "excerpt": "TensorFlow is designed to \nwork efficiently with large amount of data. So it's important not to starve your \nTensorFlow model in order to maximize its performance. There are various ways \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "data = tf.constant(actual_data) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "data = tf.placeholder(tf.float32) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "data = tf.py_func(py_input_fn, [], (tf.float32)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "for x_i in tf.unstack(x): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8209932844645412
      ],
      "excerpt": "palavras-chave \"and\", \"or\" e \"not\".  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9891785691729262
      ],
      "excerpt": "x is None\" para checar o valor da vari\u00e1vel. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "with tf.control_dependencies([c]): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9186278120029062
      ],
      "excerpt": "#: An adapter that defines a gradient op compatible with TensorFlow \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9300728786907689
      ],
      "excerpt": "#: Override the gradient of the custom op \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "with g.gradient_override_map({\"PyFunc\": grad_name}): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "with tf.Session(): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "    for k, v in kwargs.items(): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127,
        0.9560187895509076
      ],
      "excerpt": "        with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE): \n            out_split.append(fn(**{k : v[i] for k, v in in_splits.items()})) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "def model(a, b): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "c = make_parallel(model, 2, a=a, b=b) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "def model(x, y): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9683628829998558
      ],
      "excerpt": "c = tf.matmul(a, b)  #: c is a tensor of shape [2, 4] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8314260173495172
      ],
      "excerpt": "tf.matmul(a, b)  #: c is a tensor of shape [10, 2, 4] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9683628829998558
      ],
      "excerpt": "c = a + b  #: c is a tensor of shape [2, 2] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127,
        0.9683628829998558
      ],
      "excerpt": "with tf.control_dependencies([check_a, check_b]): \n    c = a + b  #: c is a tensor of shape [2, 2] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "with tf.Session(): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9319708861235405
      ],
      "excerpt": "with tf.Session() as sess: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8467028407714631
      ],
      "excerpt": "We can also verify that the gradients are also computed correctly: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8930901044020226
      ],
      "excerpt": "    features = ... \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8930901044020226
      ],
      "excerpt": "    features = ... \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "          for s in zip(static_shape, dynamic_shape)] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.876435390332058
      ],
      "excerpt": "  \"\"\"Gather in batch from a tensor of arbitrary size. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.881391860375911
      ],
      "excerpt": "    tensor: Tensor of arbitrary size. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.9001316668053994
      ],
      "excerpt": "    initial_state: Recurrent model states. \n    sequence_length: Length of the generated sequence. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9461990097094981,
        0.935875307775975,
        0.8743206852319123
      ],
      "excerpt": "  \"\"\"Merge features with broadcasting support. \nThis operation concatenates multiple features of varying length and applies \n  non-linear transformation to the outcome. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8896419387768021
      ],
      "excerpt": "    tensors: A list of tensor with the same rank. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "for proj in projs: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8195689456505549
      ],
      "excerpt": "To ensure numerical stability, this op uses mu, log(sigma^2) to represent \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9293719285711296
      ],
      "excerpt": "    **kwargs: Keyword arguments to be passed to the model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "  for k, v in kwargs.items(): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127,
        0.9560187895509076
      ],
      "excerpt": "      with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE): \n        out_split.append(fn(**{k : v[i] for k, v in in_splits.items()})) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9014869908511918
      ],
      "excerpt": "The features are assumed to be in NHWC format. Noe that you need to  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Aqui se encontra a tradu\u00e7\u00e3o para o portugu\u00eas do artigo originalmente escrito por Vahid Kazemi (vahidk) \"Tutorial Efective TensorFlow\"",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/gmouzella/Efective_TensorFlow/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 13:13:03 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/gmouzella/Efective_TensorFlow/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "gmouzella/Efective_TensorFlow",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/gmouzella/Efective_TensorFlow/master/Tutorial_EfectiveTensorFlow%28portugu%C3%AAs%29.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8233588558014837
      ],
      "excerpt": "como o NumPy. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233588558014837
      ],
      "excerpt": "vejamos a implementa\u00e7\u00e3o feita em NumPy: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233588558014837
      ],
      "excerpt": "* NumPy: imediatamente executa o c\u00e1lculo e gera o resultado, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8244453191770256
      ],
      "excerpt": "Note que isso funciona independente se o formato \u00e9 estaticamente especificado ou \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8098496874684212
      ],
      "excerpt": "b = tf.Variable(1, name=\"b\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8098496874684212
      ],
      "excerpt": "b = tf.Variable(1, name=\"b\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8098496874684212
      ],
      "excerpt": "b = tf.Variable(1, name=\"b\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "Python ops \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "Python ops: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "Python ops permite converter uma fun\u00e7\u00e3o Python normal em uma opera\u00e7\u00e3o em \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9304288912681888
      ],
      "excerpt": "Note que Python n\u00e3o permite a sobrecarga das \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8244453191770256
      ],
      "excerpt": "Avaliar \"a\" retornar\u00e1 o valor 3 como esperado. Note que criou-se 3 tensores, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8244453191770256
      ],
      "excerpt": "Note que o tensor c n\u00e3o tem um valor determin\u00edstico. Esse valor pode ser 3 ou 7 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8244453191770256
      ],
      "excerpt": "Note que a ordem \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8244453191770256
      ],
      "excerpt": "Isso n\u00e3o est\u00e1 somente ficando feio, mas tamb\u00e9m ineficiente. Note que estamos \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "ReLU em TensorFlowem python: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8244453191770256,
        0.8837680365796365,
        0.9748709027320682
      ],
      "excerpt": "Note que essa \u00e9 uma implementa\u00e7\u00e3o bastante ineficiente, e \u00e9 utiliz\u00e1vel \nsomente para prototipagem, uma vez que c\u00f3digo Python n\u00e3o \u00e9 paraleliz\u00e1vel e n\u00e3o \nir\u00e1 rodar na GPU. Uma vez verificada a ideia, voc\u00ea definitivamente ir\u00e1 querer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "Na pr\u00e1tica utilizamos opera\u00e7\u00f5es em python \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.921083585584348
      ],
      "excerpt": "#: Run the python op. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8245448462755121
      ],
      "excerpt": "A mesma opera\u00e7\u00e3o pode ser feita de maneira simples em uma GPU: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9534256985106694
      ],
      "excerpt": "separar os dados e usar uma GPU separada para precessar cada metade: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8244453191770256
      ],
      "excerpt": "entrada e sa\u00edda estejam em batchs. Note que n\u00f3s tamb\u00e9m adicionamos um alcance \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8149245938106291
      ],
      "excerpt": "  with tf.variable_scope(name, default_name=\"merge\"): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "          name=\"proj_%d\" % i, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8149245938106291
      ],
      "excerpt": "  with tf.variable_scope(name, default_name=\"batch_normalization\"): \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.925671696398174,
        0.9457175861910134
      ],
      "excerpt": "import tensorflow as tf \nimport numpy as np \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9010661426549688,
        0.9010661426549688
      ],
      "excerpt": "x = np.random.normal(size=[10, 10]) \ny = np.random.normal(size=[10, 10]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8451432842966251,
        0.8451432842966251
      ],
      "excerpt": "x = tf.random_normal([10, 10]) \ny = tf.random_normal([10, 10]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "z = tf.matmul(x, y) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8036206378907308,
        0.8008331685760428
      ],
      "excerpt": "sess = tf.Session() \nz_val = sess.run(z) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8451432842966251,
        0.8451432842966251
      ],
      "excerpt": "x = tf.random_normal([10, 10]) \ny = tf.random_normal([10, 10]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "z = tf.matmul(x, y) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772530931407262
      ],
      "excerpt": "{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8916348859260621
      ],
      "excerpt": "  \"text\": \"Tensor(\\\"MatMul:0\\\", shape=(10, 10), dtype=float32)\\n\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8128131768734507,
        0.8128131768734507
      ],
      "excerpt": "x = tf.placeholder(tf.float32) \ny = tf.placeholder(tf.float32) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589102878178917
      ],
      "excerpt": "w = tf.get_variable(\"w\", shape=[3, 1]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8305232021727986
      ],
      "excerpt": "f = tf.stack([tf.square(x), x, tf.ones_like(x)], 1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8446434232000626
      ],
      "excerpt": "train_op = tf.train.AdamOptimizer(0.1).minimize(loss) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9181737742647199,
        0.8528486646543201
      ],
      "excerpt": "    x_val = np.random.uniform(-10.0, 10.0, size=100) \n    y_val = 5 * np.square(x_val) + 3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8036206378907308
      ],
      "excerpt": "sess = tf.Session() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936606094659785,
        0.8008331685760428,
        0.936606094659785
      ],
      "excerpt": "    #:print(loss_val) \nw_val = sess.run([w]) \nprint('w = ',w_val) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772530931407262
      ],
      "excerpt": "{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860416810884047
      ],
      "excerpt": "a = tf.placeholder(tf.float32, [None, 128]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8062489193074337,
        0.936606094659785,
        0.8772530931407262
      ],
      "excerpt": "static_shape = a.shape.as_list()  #: returns [None, 128] \nprint('static_shape = ',static_shape) \n{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8194325932561092
      ],
      "excerpt": "  \"text\": \"('static_shape = ', [32, 128])\\n\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589102878178917,
        0.936606094659785,
        0.8772530931407262
      ],
      "excerpt": "dynamic_shape = tf.shape(a) \nprint('dynamic_shape = ',dynamic_shape) \n{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8004889185131009
      ],
      "excerpt": "  \"text\": \"('dynamic_shape = ', &lt;tf.Tensor 'Shape:0' shape=(2,) dtype=int32&gt;)\\n\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9312650322969277
      ],
      "excerpt": "print('static_shape1 = ',a.shape.as_list()) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9312650322969277,
        0.8772530931407262
      ],
      "excerpt": "print('static_shape2 = ',a.shape.as_list()) \n{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8394965883403953
      ],
      "excerpt": "Pode-se modificar um dado tensor dinamicamente usando tf.reshape function: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9312650322969277,
        0.8073337298752988,
        0.9312650322969277,
        0.8772530931407262
      ],
      "excerpt": "print('a_shape = ',a.shape.as_list()) \na =  tf.reshape(a, [128, 32]) \nprint('a_shape = ',a.shape.as_list()) \n{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8517437249086434
      ],
      "excerpt": "  dynamic_shape = tf.unstack(tf.shape(tensor)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8381158044243161
      ],
      "excerpt": "b = tf.placeholder(tf.float32, [None, 10, 32]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936606094659785,
        0.8378069801229581,
        0.936606094659785,
        0.8772530931407262
      ],
      "excerpt": "print('shape_before = ',get_shape(b)) \nb = tf.reshape(b, [shape[0], shape[1] * shape[2]]) \nprint('shape_after = ',get_shape(b)) \n{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8142580305560206
      ],
      "excerpt": "      dims_prod.append(np.prod([shape[d] for d in dims])) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8381158044243161,
        0.936606094659785
      ],
      "excerpt": "b = tf.placeholder(tf.float32, [None, 10, 32]) \nprint('shape_before = ',get_shape(b)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936606094659785,
        0.8772530931407262
      ],
      "excerpt": "print('shape_after = ',get_shape(b)) \n{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.950820698882835
      ],
      "excerpt": "print(a.name)   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772530931407262
      ],
      "excerpt": "{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "  \"text\": \"Const_2:0\\nVariable_2:0\\n\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8629003275206988,
        0.950820698882835
      ],
      "excerpt": "a = tf.constant(1, name=\"a\") \nprint(a.name)   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772530931407262
      ],
      "excerpt": "{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "  \"text\": \"a:0\\nb:0\\n\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "primeiro \u00e9 tf.name_scope: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8629003275206988,
        0.950820698882835
      ],
      "excerpt": "  a = tf.constant(1, name=\"a\") \n  print(a.name)   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.950820698882835,
        0.908886678552816,
        0.950820698882835
      ],
      "excerpt": "  print(b.name)   \nc = tf.get_variable(name=\"c\", shape=[]) \n  print(c.name) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772530931407262
      ],
      "excerpt": "{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "  \"text\": \"scope/a:0\\nscope/b:0\\nc:0\\n\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "* tf.name_scope afeta o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8629003275206988,
        0.9080129711969567
      ],
      "excerpt": "  a = tf.constant(1, name=\"a\") \n  print(a.name)  #: prints \"scope/a:0\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9080129711969567,
        0.908886678552816,
        0.9080129711969567
      ],
      "excerpt": "  print(b.name)  #: prints \"scope/b:0\" \nc = tf.get_variable(name=\"c\", shape=[]) \n  print(c.name)  #: prints \"scope/c:0\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772530931407262
      ],
      "excerpt": "{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "  \"text\": \"scope/a:0\\nscope/b:0\\nscope/c:0\\n\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908886678552816,
        0.908886678552816
      ],
      "excerpt": "  a1 = tf.get_variable(name=\"a\", shape=[]) \n  a2 = tf.get_variable(name=\"a\", shape=[])  #: Disallowed \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "tf.variable_scope tamb\u00e9m apresenta uma funcionalidade para faz\u00ea-lo: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908886678552816,
        0.8883260696661613,
        0.8295167278331617
      ],
      "excerpt": "  a1 = tf.get_variable(name=\"a\", shape=[]) \nwith tf.variable_scope(\"scope\", reuse=True): \n  a2 = tf.get_variable(name=\"a\", shape=[])  #: OK \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8883260696661613
      ],
      "excerpt": "with tf.variable_scope('my_scope', reuse=True): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8420227656543805
      ],
      "excerpt": "Alternativamente pode-se usar reuse para tf.AUTO_REUSE que diz ao TensorFlow \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8098308255451723
      ],
      "excerpt": "with tf.variable_scope(\"scope\", reuse=tf.AUTO_REUSE): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "tf.AUTO_REUSE simplifica a tarefa por\u00e9m adiciona \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8350929247755378
      ],
      "excerpt": ": c = a + tf.tile(b, [1, 2]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8724251689113336,
        0.9399752851367198
      ],
      "excerpt": "  result  = session.run(c)  #:result = v.eval() #:forma equivalente \n  print(result) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772530931407262
      ],
      "excerpt": "{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "  \"text\": \"[[2. 3.]\\n [5. 6.]]\\n\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432
      ],
      "excerpt": "a = tf.random_uniform([5, 3, 5]) \nb = tf.random_uniform([5, 1, 6]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8350929247755378,
        0.8123763140827432
      ],
      "excerpt": "tiled_b = tf.tile(b, [1, 3, 1]) \nc = tf.concat([a, tiled_b], 2) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9104313787772969,
        0.9104313787772969,
        0.9104313787772969
      ],
      "excerpt": "  #:print(session.run(tiled_b)) \n  print(session.run(c)) \n  #:print(session.run(d))  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772530931407262
      ],
      "excerpt": "{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "  \"text\": \"[[[0.6937026  0.15428507 0.2800038  0.08377886 0.12188792 0.5092124\\n   0.695078   0.4601586  0.82269514 0.7481663  0.7347907 ]\\n  [0.16978633 0.36053598 0.16227639 0.7982862  0.6463525  0.5092124\\n   0.695078   0.4601586  0.82269514 0.7481663  0.7347907 ]\\n  [0.6232879  0.43789756 0.80180585 0.6007143  0.54549825 0.5092124\\n   0.695078   0.4601586  0.82269514 0.7481663  0.7347907 ]]\\n\\n [[0.22090471 0.31535435 0.5629263  0.3793478  0.60918427 0.68534255\\n   0.6267303  0.71711516 0.5630053  0.6170057  0.5886011 ]\\n  [0.5502802  0.55038464 0.07872856 0.8033217  0.83834624 0.68534255\\n   0.6267303  0.71711516 0.5630053  0.6170057  0.5886011 ]\\n  [0.4749012  0.43129456 0.61200035 0.7015667  0.90547967 0.68534255\\n   0.6267303  0.71711516 0.5630053  0.6170057  0.5886011 ]]\\n\\n [[0.51492727 0.49063408 0.6472235  0.42694485 0.9332788  0.94186914\\n   0.09389567 0.76210356 0.00971448 0.85871506 0.03518164]\\n  [0.0576483  0.06008446 0.15991223 0.6457871  0.30569184 0.94186914\\n   0.09389567 0.76210356 0.00971448 0.85871506 0.03518164]\\n  [0.7202405  0.23647058 0.6942618  0.62667763 0.4135698  0.94186914\\n   0.09389567 0.76210356 0.00971448 0.85871506 0.03518164]]\\n\\n [[0.17352045 0.14470255 0.1059376  0.46654844 0.48657966 0.4362011\\n   0.90611553 0.76159    0.47261274 0.36685407 0.7907051 ]\\n  [0.5611588  0.10189164 0.53168106 0.3823582  0.95938146 0.4362011\\n   0.90611553 0.76159    0.47261274 0.36685407 0.7907051 ]\\n  [0.5209532  0.5431979  0.327083   0.95845103 0.13369536 0.4362011\\n   0.90611553 0.76159    0.47261274 0.36685407 0.7907051 ]]\\n\\n [[0.27793443 0.02233255 0.59707713 0.54039264 0.4431789  0.418213\\n   0.234949   0.6185926  0.31132996 0.88933694 0.9839337 ]\\n  [0.8138777  0.42909408 0.63658106 0.52854526 0.68817234 0.418213\\n   0.234949   0.6185926  0.31132996 0.88933694 0.9839337 ]\\n  [0.2202568  0.55266035 0.5153638  0.01934719 0.3002057  0.418213\\n   0.234949   0.6185926  0.31132996 0.88933694 0.9839337 ]]]\\n\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "d = tf.nn.relu(pa + pb) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "c = tf.reduce_sum(a + b) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9104313787772969
      ],
      "excerpt": "  print(session.run(c)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772530931407262
      ],
      "excerpt": "{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "c = tf.reduce_sum(a + b, 0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9104313787772969
      ],
      "excerpt": "  print(session.run(c)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772530931407262
      ],
      "excerpt": "{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  \"name\": \"stdout\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "  \"text\": \"[5. 7.]\\n\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174,
        0.9457175861910134,
        0.9069630468273892,
        0.8317106583254321
      ],
      "excerpt": "import tensorflow as tf \nimport numpy as np \nactual_data = np.random.normal(size=[100]) \ndata = tf.constant(actual_data) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174,
        0.9457175861910134,
        0.8412454418309304,
        0.8163907034894899,
        0.9069630468273892,
        0.8603690286358254
      ],
      "excerpt": "import tensorflow as tf \nimport numpy as np \ndata = tf.placeholder(tf.float32) \nprediction = tf.square(data) + 1 \nactual_data = np.random.normal(size=[100]) \ntf.Session().run(prediction, feed_dict={data: actual_data}) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9069630468273892
      ],
      "excerpt": "    actual_data = np.random.normal(size=[100]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8436995560506239
      ],
      "excerpt": "data = tf.py_func(py_input_fn, [], (tf.float32)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9069630468273892,
        0.864861331957199,
        0.8260169322483399
      ],
      "excerpt": "actual_data = np.random.normal(size=[100]) \ndataset = tf.contrib.data.Dataset.from_tensor_slices(actual_data) \ndata = dataset.make_one_shot_iterator().get_next() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8822085801831991
      ],
      "excerpt": "dataset = tf.contrib.data.TFRecordDataset(path_to_data) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8593959902401773
      ],
      "excerpt": "if mode == tf.estimator.ModeKeys.TRAIN: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8191162518592582
      ],
      "excerpt": "dataset = dataset.batch(batch_size) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174,
        0.8396948529258378,
        0.8539700055015806,
        0.8648024730903081
      ],
      "excerpt": "import tensorflow as tf \nimport time \nx = tf.random_uniform([500, 10]) \nz = tf.zeros([10]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8036206378907308
      ],
      "excerpt": "sess = tf.Session() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8089593039685631
      ],
      "excerpt": "print(\"Took %f seconds.\" % (time.time() - start)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "lento para rodar. Uma melhor alternatica seria usar a oprera\u00e7\u00e3o tf.unstack \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8648024730903081
      ],
      "excerpt": "z = tf.zeros([10]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "simples redu\u00e7\u00e3o \u00e9 usando a opera\u00e7\u00e3o tf.reduce_sum: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.84760898352076
      ],
      "excerpt": "z = tf.reduce_sum(x, axis=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8292651357740108,
        0.8123763140827432,
        0.8123763140827432,
        0.8168264101660633,
        0.8123763140827432,
        0.8123763140827432,
        0.8123763140827432,
        0.8123763140827432
      ],
      "excerpt": "z = -x  #: z = tf.negative(x) \nz = x + y  #: z = tf.add(x, y) \nz = x - y  #: z = tf.subtract(x, y) \nz = x * y  #: z = tf.mul(x, y) \nz = x / y  #: z = tf.div(x, y) \nz = x // y  #: z = tf.floordiv(x, y) \nz = x % y  #: z = tf.mod(x, y) \nz = x ** y  #: z = tf.pow(x, y) \nz = x @ y  #: z = tf.matmul(x, y) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432,
        0.8123763140827432,
        0.8123763140827432,
        0.8123763140827432
      ],
      "excerpt": "z = abs(x)  #: z = tf.abs(x) \nz = x &amp; y  #: z = tf.logical_and(x, y) \nz = x | y  #: z = tf.logical_or(x, y) \nz = x ^ y  #: z = tf.logical_xor(x, y) \nz = ~x  #: z = tf.logical_not(x) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "e tf.not_equal. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174
      ],
      "excerpt": "import tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8292859081577882
      ],
      "excerpt": "grafo por default . Pode-se usar tf.get_default_graph() para acessar o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772530931407262
      ],
      "excerpt": "{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8036206378907308
      ],
      "excerpt": "sess = tf.Session() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8036206378907308
      ],
      "excerpt": "sess = tf.Session() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8670539095623045,
        0.9086077167752371
      ],
      "excerpt": "    sess.run(tf.global_variables_initializer()) \n    print(sess.run([assign, c])) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8248441365242358
      ],
      "excerpt": "explicitamente as depend\u00eancias usando tf.control_dependencies() como a seguir: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8036206378907308
      ],
      "excerpt": "sess = tf.Session() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8670539095623045,
        0.9086077167752371
      ],
      "excerpt": "    sess.run(tf.global_variables_initializer()) \n    print(sess.run([assign, c])) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8738942630780011,
        0.8123763140827432
      ],
      "excerpt": "p = tf.constant(True) \nx = tf.cond(p, lambda: a + b, lambda: a * b) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.896677202744846
      ],
      "excerpt": "p = tf.constant([True, False]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8069275751695314
      ],
      "excerpt": "    return i + 1, b, a + b, tf.concat([c, [a + b]], 0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "i, a, b, c = tf.while_loop( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432,
        0.8123763140827432,
        0.8141593417041636
      ],
      "excerpt": "    shape_invariants=(tf.TensorShape([]), \n                      tf.TensorShape([]), \n                      tf.TensorShape([]), \n                      tf.TensorShape([None]))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8230254167766119,
        0.8230254167766119
      ],
      "excerpt": "c = tf.TensorArray(tf.int32, n) \nc = c.write(0, 1) \nc = c.write(1, 1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8230254167766119
      ],
      "excerpt": "    c = c.write(i, a + b) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9457175861910134,
        0.925671696398174,
        0.9133368656218674
      ],
      "excerpt": "import numpy as np \nimport tensorflow as tf \nimport uuid \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8429633022618321
      ],
      "excerpt": "        return np.maximum(x, 0.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "    x_grad = grad * tf.py_func(_relu_grad, [x], tf.float32) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "g = tf.get_default_graph() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.821932611958033,
        0.8113404775112109
      ],
      "excerpt": "    output = tf.py_func(_relu, [inputs], tf.float32) \nreturn output \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8539700055015806
      ],
      "excerpt": "x = tf.random_normal([10]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8983433481041191,
        0.936606094659785
      ],
      "excerpt": "    diff = tf.test.compute_gradient_error(x, [10], y, [10]) \n    print(diff) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8596521807794544,
        0.9068127677393759,
        0.9457175861910134,
        0.9133368656218674,
        0.925671696398174
      ],
      "excerpt": "import io \nimport matplotlib.pyplot as plt \nimport numpy as np \nimport PIL \nimport tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.872668862270142,
        0.8755350789916541,
        0.8214220056347302,
        0.9111186171957313
      ],
      "excerpt": "        fig = plt.figure(figsize=(3, 3), dpi=80) \n        ax = fig.add_subplot(111) \n        ax.imshow(image[::-1,...]) \n        ax.text(0, 0, str(label), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9165969638423818
      ],
      "excerpt": "    #: Write the plot as a memory file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8968711354474823
      ],
      "excerpt": "    data = fig.savefig(buf, format=\"png\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8335257374850991
      ],
      "excerpt": "    #: Read the image and convert to numpy array \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8494971553319522
      ],
      "excerpt": "    return np.array(img.getdata()).reshape(img.size[0], img.size[1], -1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9197489141922003,
        0.8089493041949173,
        0.841014133923283,
        0.842387370744256
      ],
      "excerpt": "    return np.array(outputs, dtype=np.uint8) \n#: Run the python op. \nfigs = tf.py_func(_visualize_images, [images, labels], tf.uint8) \nreturn tf.summary.image(name, figs) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174
      ],
      "excerpt": "import tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8541838558006466,
        0.8541838558006466
      ],
      "excerpt": "   a = tf.random_uniform([1000, 100]) \n   b = tf.random_uniform([1000, 100]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8373259594041014,
        0.8541838558006466,
        0.8541838558006466
      ],
      "excerpt": "with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=0)): \n    a = tf.random_uniform([1000, 100]) \n    b = tf.random_uniform([1000, 100]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432
      ],
      "excerpt": "split_a = tf.split(a, 2) \nsplit_b = tf.split(b, 2) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8373259594041014
      ],
      "excerpt": "    with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=i)): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.84760898352076
      ],
      "excerpt": "c = tf.concat(split_c, axis=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "        in_splits[k] = tf.split(v, num_gpus) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8373259594041014,
        0.8119089628744033
      ],
      "excerpt": "    with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=i)): \n        with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8463579979869013
      ],
      "excerpt": "return tf.concat(out_split, axis=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9457175861910134,
        0.925671696398174
      ],
      "excerpt": "import numpy as np \nimport tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589102878178917,
        0.8305232021727986
      ],
      "excerpt": "    w = tf.get_variable(\"w\", shape=[3, 1]) \nf = tf.stack([tf.square(x), x, tf.ones_like(x)], 1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8128131768734507,
        0.8128131768734507
      ],
      "excerpt": "x = tf.placeholder(tf.float32) \ny = tf.placeholder(tf.float32) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8936954105699045
      ],
      "excerpt": "train_op = tf.train.AdamOptimizer(0.1).minimize( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9181737742647199,
        0.8528486646543201
      ],
      "excerpt": "    x_val = np.random.uniform(-10.0, 10.0, size=100) \n    y_val = 5 * np.square(x_val) + 3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8036206378907308
      ],
      "excerpt": "sess = tf.Session() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8936954105699045
      ],
      "excerpt": "train_op = tf.train.AdamOptimizer(0.1).minimize( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "    colocate_gradients_with_ops=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "Por exemplo, considere a opera\u00e7\u00e3o tf.matmul, que \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432
      ],
      "excerpt": "a = tf.random_uniform([2, 3]) \nb = tf.random_uniform([3, 4]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8539700055015806,
        0.8539700055015806,
        0.8352358310238829
      ],
      "excerpt": "a = tf.random_uniform([10, 2, 3]) \nb = tf.random_uniform([10, 3, 4]) \ntf.matmul(a, b)  #: c is a tensor of shape [10, 2, 4] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "check_b = tf.assert_rank(b, 1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "check_pos = tf.assert_positive(a) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9087652064146219
      ],
      "excerpt": "Outra fun\u00e7\u00e3o inerente \u00fatil para debugar \u00e9 tf.Print que registra os tensores \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9356961955849917,
        0.8424309321019093,
        0.8582724262804933
      ],
      "excerpt": "input_copy = tf.Print(input, tensors_to_print_list) \nNote que tf.Print retorna a c\u00f3pia de seu primeiro argumento como uma sa\u00edda. \nUma maneira de for\u00e7ar tf.Print a rodar \u00e9 passar sua sa\u00edda para outra opera\u00e7\u00e3o \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9361993341006366
      ],
      "excerpt": "a = tf.Print(a, [a, b]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174
      ],
      "excerpt": "import tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "    probs = tf.nn.softmax(logits) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589102878178917
      ],
      "excerpt": "w = tf.get_variable(\"w\", shape=[5]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8712595579064647
      ],
      "excerpt": "opt = tf.train.AdamOptimizer() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8036206378907308
      ],
      "excerpt": "sess = tf.Session() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008331685760428
      ],
      "excerpt": "    sess.run(train_op) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "Estamos utilizando tf.softmax_cross_entropy_with_logits para definier a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "Acontece que tf.nn.softmax_cross_entropy_with_logits tem gradiente indefinido \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8954292540692544,
        0.936606094659785
      ],
      "excerpt": "    diff = tf.test.compute_gradient_error(w, [5], y, []) \n    print(diff) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174,
        0.9457175861910134
      ],
      "excerpt": "import tensorflow as tf \nimport numpy as np \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8069275751695314,
        0.8589102878178917
      ],
      "excerpt": "    plogp = tf.nn.softmax(logits, dim) * tf.nn.log_softmax(logits, dim) \n    return -tf.reduce_sum(plogp, dim) \nw = tf.get_variable(\"w\", shape=[5]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8135654125968134,
        0.8954292540692544,
        0.936606094659785
      ],
      "excerpt": "with tf.Session() as sess: \n    diff = tf.test.compute_gradient_error(w, [5], y, []) \n    print(diff) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9457175861910134,
        0.8997243352845468,
        0.8061844772354758
      ],
      "excerpt": "import numpy as np \nx = np.float32(1) \ny = np.float32(1e-50)  #: y would be stored as zero \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8584797252368701
      ],
      "excerpt": "print(z)  #: prints nan \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8584797252368701
      ],
      "excerpt": "print(z)  #: prints 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8702815774991463
      ],
      "excerpt": "O menor n\u00famero positivo que o tipo float32 pode representar \u00e9 1.4013e-45 e \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9551706935709048,
        0.964817624104083
      ],
      "excerpt": "print(np.nextafter(np.float32(0), np.float32(1)))  #: prints 1.4013e-45 \nprint(np.finfo(np.float32).max)  #: print 3.40282e+38 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174
      ],
      "excerpt": "import tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8017814736524004,
        0.8330189362588655
      ],
      "excerpt": "    return exp / tf.reduce_sum(exp) \ntf.Session().run(unstable_softmax([1000., 0.]))  #: prints [ nan, 0.] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174
      ],
      "excerpt": "import tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.818613911854245,
        0.8017814736524004,
        0.8330189362588655
      ],
      "excerpt": "    exp = tf.exp(logits - tf.reduce_max(logits)) \n    return exp / tf.reduce_sum(exp) \ntf.Session().run(softmax([1000., 0.]))  #: prints [ 1., 0.] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8172569145964618
      ],
      "excerpt": "    logits = tf.log(softmax(logits)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9058837629592024
      ],
      "excerpt": "print(tf.Session().run(xe))  #: prints inf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772530931407262
      ],
      "excerpt": "{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432
      ],
      "excerpt": "    scaled_logits = logits - tf.reduce_max(logits) \n    normalized_logits = scaled_logits - tf.reduce_logsumexp(scaled_logits) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9154039527638999
      ],
      "excerpt": "print(tf.Session().run(xe))  #: prints 500.0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9154039527638999
      ],
      "excerpt": "print(tf.Session().run(g))  #: prints [0.5, -0.5] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174
      ],
      "excerpt": "import tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8069275751695314
      ],
      "excerpt": "    return tf.estimator.EstimatorSpec( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8060372108626078
      ],
      "excerpt": "params = ... \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.819768282684361
      ],
      "excerpt": "estimator = tf.estimator.Estimator( \n    model_fn=model_fn, config=run_config, params=params) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "Para treinar o modelo basta simplesmente chamar a fun\u00e7\u00e3o Estimator.train() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "estimator.train(input_fn=input_fn, max_steps=...) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8772530931407262
      ],
      "excerpt": "{.json .output n=0} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174,
        0.8699330028252333,
        0.8123763140827432
      ],
      "excerpt": "import tensorflow as tf \ntf.flags.DEFINE_string(\"output_dir\", \"\", \"Optional output dir.\") \ntf.flags.DEFINE_string(\"schedule\", \"train_and_evaluate\", \"Schedule.\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "FLAGS = tf.flags.FLAGS \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "  estimator = tf.estimator.Estimator( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8060372108626078
      ],
      "excerpt": "    params=hparams) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8936954105699045,
        0.8285001940814389
      ],
      "excerpt": "    train_input_fn=make_input_fn(tf.estimator.ModeKeys.TRAIN, hparams), \n    eval_input_fn=make_input_fn(tf.estimator.ModeKeys.EVAL, hparams)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8766312876385063
      ],
      "excerpt": "  hparams = tf.contrib.training.HParams() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8458751354831934
      ],
      "excerpt": "if name == \"main\": \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8517437249086434
      ],
      "excerpt": "  dynamic_shape = tf.unstack(tf.shape(tensor)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8478290137707425
      ],
      "excerpt": "  output[i] = tf.gather(tensor[i], indices[i]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8059741847912978
      ],
      "excerpt": "    output: A tensor of gathered values. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8378069801229581
      ],
      "excerpt": "  flat_first = tf.reshape(tensor, [shape[0] * shape[1]] + shape[2:]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9053681892629175,
        0.8971327588135817,
        0.8113404775112109
      ],
      "excerpt": "  offset = tf.reshape(tf.range(shape[0]) * shape[1], offset_shape) \n  output = tf.gather(flat_first, indices + offset) \n  return output \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174
      ],
      "excerpt": "import tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "                    begin_token_id, end_token_id, name=\"rnn\"): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8235905730414957
      ],
      "excerpt": "    logprobs: Output log probabilities probabilities. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.80897680582524,
        0.831148195248894,
        0.8172569145964618,
        0.8550586125634494,
        0.8417461682847911,
        0.851108916161228
      ],
      "excerpt": "  batch_size = initial_state.shape.as_list()[0] \nstate = tf.tile(tf.expand_dims(initial_state, axis=1), [1, beam_width, 1]) \nsel_sum_logprobs = tf.log([[1.] + [0.] * (beam_width - 1)]) \nids = tf.tile([[begin_token_id]], [batch_size, beam_width]) \n  sel_ids = tf.zeros([batch_size, beam_width, 0], dtype=ids.dtype) \nmask = tf.ones([batch_size, beam_width], dtype=tf.float32) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8879165925839141
      ],
      "excerpt": "    with tf.variable_scope(name, reuse=True if i > 0 else None): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "  logits = tf.nn.log_softmax(logits) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.84760898352076,
        0.8692465353884022
      ],
      "excerpt": "      tf.expand_dims(sel_sum_logprobs, axis=2) + \n      (logits * tf.expand_dims(mask, axis=2))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8240043342711671
      ],
      "excerpt": "      tf.reshape(sum_logprobs, [batch_size, num_classes * beam_width]), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8274878406259352
      ],
      "excerpt": "  sel_ids = tf.concat([batch_gather(sel_ids, beam_ids), \n                       tf.expand_dims(ids, axis=2)], axis=2) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "          tf.to_float(tf.not_equal(ids, end_token_id))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174,
        0.8126836262192068
      ],
      "excerpt": "import tensorflow as tf \ndef merge(tensors, units, activation=tf.nn.relu, name=None, **kwargs): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8315489210996131,
        0.8315489210996131
      ],
      "excerpt": "    a = tf.zeros([m, 1, d1]) \n    b = tf.zeros([1, n, d2]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8775252701110471
      ],
      "excerpt": "  with tf.variable_scope(name, default_name=\"merge\"): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "          name=\"proj_%d\" % i, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8102780086823556
      ],
      "excerpt": "result = projs.pop() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8102780086823556
      ],
      "excerpt": "  result = result + proj \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925671696398174
      ],
      "excerpt": "import tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8069275751695314
      ],
      "excerpt": "  plogp = tf.nn.softmax(logits, dim) * tf.nn.log_softmax(logits, dim) \n  return -tf.reduce_sum(plogp, dim) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8069275751695314
      ],
      "excerpt": "  return tf.reduce_sum( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.818613911854245,
        0.8362053122763834
      ],
      "excerpt": "           tf.exp(log_sigma1_sq - log_sigma2_sq) + \n           tf.square(mu1 - mu2) / tf.exp(log_sigma2_sq) - \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "    in_splits[k] = tf.split(v, num_gpus) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8373259594041014,
        0.8119089628744033
      ],
      "excerpt": "    with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=i)): \n      with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8463579979869013
      ],
      "excerpt": "return tf.concat(out_split, axis=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8145024301249764,
        0.860157100998311
      ],
      "excerpt": "def batch_normalization(tensor, training=False, epsilon=0.001, momentum=0.9,  \n                        fused_batch_norm=False, name=None): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8119089628744033
      ],
      "excerpt": "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8775252701110471
      ],
      "excerpt": "  with tf.variable_scope(name, default_name=\"batch_normalization\"): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432,
        0.8123763140827432,
        0.8123763140827432
      ],
      "excerpt": "gamma = tf.get_variable( \n  'gamma', channels, initializer=tf.ones_initializer()) \navg_mean = tf.get_variable( \n  \"avg_mean\", channels, initializer=tf.zeros_initializer(), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432
      ],
      "excerpt": "avg_variance = tf.get_variable( \n  \"avg_variance\", channels, initializer=tf.ones_initializer(), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8282124443735625
      ],
      "excerpt": "  tensor, mean, variance = tf.nn.fused_batch_norm( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": "    epsilon=epsilon, is_training=training) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "  tensor = tf.nn.batch_normalization( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432
      ],
      "excerpt": "  tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, update_mean) \n  tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, update_variance) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/gmouzella/Efective_TensorFlow/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Effective TensorFlow",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Efective_TensorFlow",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "gmouzella",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/gmouzella/Efective_TensorFlow/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 13:13:03 GMT"
    },
    "technique": "GitHub API"
  }
}
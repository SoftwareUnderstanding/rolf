{
  "citation": [
    {
      "confidence": [
        0.8121586466473046
      ],
      "excerpt": "Image-Annotation Mobile-Net TDIDF Mixed Learning Algorithm \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/keenborder786/Image-Annotation-Research",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-01-16T20:37:48Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-02-23T04:28:29Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9150897157586518
      ],
      "excerpt": "My Research on Implementing an algorithm of  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9937195413674056,
        0.9665010884094313,
        0.8314283745894693
      ],
      "excerpt": "I was fascinated by the concept of Image Annotation and therefore wanted to try it,consequently this repository is an  \nopen source implementation of my own Image Annotation Algorithm which uses the Mobile Net as it core Deep Neural Network Architecture and \nTDIDF for word processing( this is just the alpha stage , I will be working to use more sophiscated techniques) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9575065379658912,
        0.9652629725053892
      ],
      "excerpt": "To get started,simply clone the repository into a folder. There are seven scripts since this is work in progress, Preprocessing-Counter(BOWs) \nis empty(An Different Apporach which I am trying). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.975533801710729
      ],
      "excerpt": "accordingly in newly created folder named data)-the main purpose of this script is to generate new data for training in addition to the data  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9261468602558961,
        0.8259771254804544
      ],
      "excerpt": "sparse tdidf matrix from the generated corpus(please note so far I have only tried TD-IDF, as time moves on I will be using other kind of \nmore sophiscated embedding methods as well): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8105870403607146,
        0.834194392254071
      ],
      "excerpt": "into MobileNetArchitecture(https://arxiv.org/pdf/1704.04861.pdf) and gets the output of Middle Layer. The ouput of all images is again stored in two newly  \ncreated folders : dic_filker30k_images--encoded and dic_my_images--encoded. The images are stored in the same way i.e chunks of pickles in dictonary format \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9384214445072535
      ],
      "excerpt": "<h3>Built With</h3> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "My Research on Implementing an algorithm of Image Annotation",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/keenborder786/Image-Annotation-Research/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Fri, 24 Dec 2021 16:42:04 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/keenborder786/Image-Annotation-Research/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "keenborder786/Image-Annotation-Research",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8609664299294902,
        0.9937277378642407,
        0.9960643983256529
      ],
      "excerpt": "<h2> Prerequisites </h2> \n1-Install the following latest version of the following packages: \ninstall all of the following packages through simple pip install command \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.999746712887969
      ],
      "excerpt": "pip install --- \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9438872461187292
      ],
      "excerpt": "Anaconda/Spyder - Environment \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8304512103771577,
        0.818643935209173,
        0.8026905535837091
      ],
      "excerpt": "1-Scrapper.py-Download images from google images from the user query(Open it and type in your query and this will download the image  \naccordingly in newly created folder named data)-the main purpose of this script is to generate new data for training in addition to the data  \nI have used to train the model i.e Filker30k Image DataSet \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8547282262127736
      ],
      "excerpt": "python Preprocessing-Images.py -p \"enter the path of data folder\" -i \"how many images into each chunk(an integer from 1 to inf)\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8355619338917498
      ],
      "excerpt": "This will divide the data into number of dictionary pickled file with each consisting ith images. The Pickle File would be stored \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8689637015512001
      ],
      "excerpt": "PLEASE NOTE WHEN YOU WILL DOWNLOAD THE FILKER30K DATA ,THERER WILL BE RESULT.CSV FILE-KEEP IT IN THE MAIN DIRECTORY TO AVOID ANY ERRORS. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8586035771728405
      ],
      "excerpt": "5- Now finally run the Deep_Net to train the model: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.846361516086928
      ],
      "excerpt": "python Deep_Net.py -p \"The path for dic_filker30k_images--encoded folder\"  -c \"The path for dic_my_images--encoded\" -c \"How many chunks of dic_filker30k_images--encoded folder you want to train on\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8146354237128678
      ],
      "excerpt": "6- Run Check_Deep_Net after creating a new folder named test and put some images there for testing the prediction of my algorithm \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9171166979298815
      ],
      "excerpt": "python Check_Deep_Net.py -p \"The Path for images that you want to test\" -d \"Name of h5 file which must have been created after running Deep_Net.py\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8584515142505658
      ],
      "excerpt": "to keep results.csv into the main directory which consist the meta data about the images.   \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/keenborder786/Image-Annotation-Research/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Image-Annotation-Research",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Image-Annotation-Research",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "keenborder786",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/keenborder786/Image-Annotation-Research/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Fri, 24 Dec 2021 16:42:04 GMT"
    },
    "technique": "GitHub API"
  }
}
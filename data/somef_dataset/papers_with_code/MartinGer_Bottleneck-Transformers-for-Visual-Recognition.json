{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2101.11605 \"Bottleneck Transformers for Visual Recognition\"",
      "https://arxiv.org/abs/1904.09925 \"Attention Augmented Convolutional Networks\""
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9175622893674981
      ],
      "excerpt": "This is a pytorch implementation of the paper Bottleneck Transformers for Visual Recognition by Aravind Srinivas, Tsung-Yi Lin, Niki Parmar, Jonathon Shlens, Pieter Abbeel and Ashish Vaswani. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MartinGer/Bottleneck-Transformers-for-Visual-Recognition",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-27T11:31:26Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-15T14:00:39Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9558181448482929,
        0.9049064072518492,
        0.8413207598172175,
        0.9811126961587034,
        0.9100970655663569
      ],
      "excerpt": "This is a pytorch implementation of the paper Bottleneck Transformers for Visual Recognition by Aravind Srinivas, Tsung-Yi Lin, Niki Parmar, Jonathon Shlens, Pieter Abbeel and Ashish Vaswani. \nThis paper implements the attention mechanism into different ResNet architectures. The used design of one attention layer can be displayed as shown \nGlobal Self-Attention on images is subject to the problem, that it can only be applied after significant \nspatial downsampling of the input. Every pixels relation is calculated to every other pixel so learning gets computationally very expensive, which prevents its usage across all layers in a fully attentional model. \nConsequently in this paper the authors only apply their attention mechanism in the last stage of the respective architecture, here ResNet50: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9164542848568512
      ],
      "excerpt": "The implemented memory efficient version of Relative Self-Attention is adapted with slight changes from the paper Attention Augmented Convolutional Networks \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Pytorch implementation of the paper Attention Augmented Convolutional Networks",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MartinGer/Bottleneck-Transformers-for-Visual-Recognition/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 01:51:31 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/MartinGer/Bottleneck-Transformers-for-Visual-Recognition/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "MartinGer/Bottleneck-Transformers-for-Visual-Recognition",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/MartinGer/Bottleneck-Transformers-for-Visual-Recognition/master/example.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9083657406301109
      ],
      "excerpt": "I only tested the implementation with ResNet50 for now. The used ResNet V1.5 architectures are adapted from https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/MartinGer/Bottleneck-Transformers-for-Visual-Recognition/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Bottleneck-Transformers-for-Visual-Recognition",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Bottleneck-Transformers-for-Visual-Recognition",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "MartinGer",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/MartinGer/Bottleneck-Transformers-for-Visual-Recognition/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- pytorch\n- I use [fast.ai](https://www.fast.ai/) and the [imagenette](https://github.com/fastai/imagenette) dataset for the examples\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 01:51:31 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "See the jupyter notebook or the example training script\n\n",
      "technique": "Header extraction"
    }
  ]
}
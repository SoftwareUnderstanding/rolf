{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2106.03153",
      "https://arxiv.org/abs/2103.09474",
      "https://arxiv.org/abs/2106.03153",
      "https://arxiv.org/abs/1812.04948",
      "https://arxiv.org/abs/1606.04080",
      "https://arxiv.org/abs/1805.10123"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation](https://arxiv.org/abs/2106.03153)\n- [A Style-Based Generator Architecture for Generative Adversarial Networks](https://arxiv.org/abs/1812.04948)\n- [Matching Networks for One Shot Learning](https://arxiv.org/abs/1606.04080)\n- [Prototypical Networks for Few-shot Learning](https://arxiv.org/pdf/1703.05175v2.pdf)\n- [TADAM: Task dependent adaptive metric for improved few-shot learning](https://arxiv.org/abs/1805.10123)\n- [ming024's FastSpeech2](https://github.com/ming024/FastSpeech2)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@misc{lee2021stylespeech,\n  author = {Lee, Keon},\n  title = {StyleSpeech},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/keonlee9420/StyleSpeech}}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{lee2021stylespeech,\n  author = {Lee, Keon},\n  title = {StyleSpeech},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/keonlee9420/StyleSpeech}}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "./montreal-forced-aligner/bin/mfa_align raw_data/LibriTTS/ lexicon/librispeech-lexicon.txt english preprocessed_data/LibriTTS \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "./montreal-forced-aligner/bin/mfa_train_and_align raw_data/LibriTTS/ lexicon/librispeech-lexicon.txt preprocessed_data/LibriTTS \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/keonlee9420/StyleSpeech",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-09T07:15:07Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-13T01:06:48Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9243717878618372
      ],
      "excerpt": "Batch inference is also supported, try \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9601977483275688
      ],
      "excerpt": "to synthesize all utterances in preprocessed_data/LibriTTS/val.txt. This can be viewed as a reconstruction of validation datasets referring to themselves for the reference style. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9743605529812186,
        0.8605590358331859
      ],
      "excerpt": "Note that the controllability is originated from FastSpeech2 and not a vital interest of StyleSpeech. Please refer to STYLER [demo, code] for the controllability of each style factor. \nThe supported datasets are \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8868845803163208,
        0.977262866277615
      ],
      "excerpt": "for some preparations. \nIn this implementation, Montreal Forced Aligner (MFA) is used to obtain the alignments between the utterances and the phoneme sequences. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8117746109290663,
        0.96786166513148,
        0.9482835573473772
      ],
      "excerpt": "Add one fully connected layer at the beginning of Mel-Style Encoder to upsample input mel-spectrogram from 80 to 128. \nThe model size including meta-learner is 28.197M. \nUse a maximum 16 batch size on training instead of 48 or 20 mainly due to the lack of memory capacity with a single 24GiB TITAN-RTX. This can be achieved by the following script to filter out data longer than max_seq_len: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "PyTorch Implementation of Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/keonlee9420/StyleSpeech/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 16,
      "date": "Mon, 27 Dec 2021 07:27:23 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/keonlee9420/StyleSpeech/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "keonlee9420/StyleSpeech",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8673805446708356
      ],
      "excerpt": "    <img src=\"img/model_1.png\" width=\"80%\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8673805446708356
      ],
      "excerpt": "    <img src=\"img/model_2.png\" width=\"80%\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8785185216297821
      ],
      "excerpt": "You have to download pretrained models and put them in output/ckpt/LibriTTS_meta_learner/. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9093908198169909,
        0.825175845634664
      ],
      "excerpt": "python3 synthesize.py --text \"YOUR_DESIRED_TEXT\" --ref_audio path/to/reference_audio.wav --restore_step 200000 --mode single -p config/LibriTTS/preprocess.yaml -m config/LibriTTS/model.yaml -t config/LibriTTS/train.yaml \nThe generated utterances will be put in output/result/. Your synthesized speech will have ref_audio's style. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9008340221033896
      ],
      "excerpt": "python3 synthesize.py --source preprocessed_data/LibriTTS/val.txt --restore_step 200000 --mode batch -p config/LibriTTS/preprocess.yaml -m config/LibriTTS/model.yaml -t config/LibriTTS/train.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9077393228626486
      ],
      "excerpt": "python3 synthesize.py --text \"YOUR_DESIRED_TEXT\" --restore_step 200000 --mode single -p config/LibriTTS/preprocess.yaml -m config/LibriTTS/model.yaml -t config/LibriTTS/train.yaml --duration_control 0.8 --energy_control 0.8 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8898963314049357,
        0.8925035593013155
      ],
      "excerpt": "First, run  \npython3 prepare_align.py config/LibriTTS/preprocess.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8925035593013155,
        0.8287974015137436,
        0.8924227954990515
      ],
      "excerpt": "python3 preprocess.py config/LibriTTS/preprocess.yaml \nTrain your model with \npython3 train.py -p config/LibriTTS/preprocess.yaml -m config/LibriTTS/model.yaml -t config/LibriTTS/train.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.825361263358686
      ],
      "excerpt": "tensorboard --logdir output/log/LibriTTS \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8677801113141207,
        0.8059425732683605
      ],
      "excerpt": "    python3 filelist_filtering.py -p config/LibriTTS/preprocess.yaml -m config/LibriTTS/model.yaml \n    This will generate train_filtered.txt in the same location of train.txt. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/keonlee9420/StyleSpeech/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Jungil Kong\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "StyleSpeech - PyTorch Implementation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "StyleSpeech",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "keonlee9420",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/keonlee9420/StyleSpeech/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "keonlee9420",
        "body": "fix optimizer (Disc) and update pre-trained model",
        "dateCreated": "2021-09-07T03:54:30Z",
        "datePublished": "2021-09-07T04:51:06Z",
        "html_url": "https://github.com/keonlee9420/StyleSpeech/releases/tag/v1.0.2",
        "name": "v1.0.2",
        "tag_name": "v1.0.2",
        "tarball_url": "https://api.github.com/repos/keonlee9420/StyleSpeech/tarball/v1.0.2",
        "url": "https://api.github.com/repos/keonlee9420/StyleSpeech/releases/49102102",
        "zipball_url": "https://api.github.com/repos/keonlee9420/StyleSpeech/zipball/v1.0.2"
      },
      {
        "authorType": "User",
        "author_name": "keonlee9420",
        "body": "fix duration control at inference time",
        "dateCreated": "2021-08-21T04:58:06Z",
        "datePublished": "2021-08-22T04:07:29Z",
        "html_url": "https://github.com/keonlee9420/StyleSpeech/releases/tag/v1.0.1",
        "name": "v1.0.1",
        "tag_name": "v1.0.1",
        "tarball_url": "https://api.github.com/repos/keonlee9420/StyleSpeech/tarball/v1.0.1",
        "url": "https://api.github.com/repos/keonlee9420/StyleSpeech/releases/48232599",
        "zipball_url": "https://api.github.com/repos/keonlee9420/StyleSpeech/zipball/v1.0.1"
      },
      {
        "authorType": "User",
        "author_name": "keonlee9420",
        "body": "First Official Release",
        "dateCreated": "2021-08-02T14:18:47Z",
        "datePublished": "2021-08-03T01:34:46Z",
        "html_url": "https://github.com/keonlee9420/StyleSpeech/releases/tag/v1.0.0",
        "name": "v1.0.0",
        "tag_name": "v1.0.0",
        "tarball_url": "https://api.github.com/repos/keonlee9420/StyleSpeech/tarball/v1.0.0",
        "url": "https://api.github.com/repos/keonlee9420/StyleSpeech/releases/47193934",
        "zipball_url": "https://api.github.com/repos/keonlee9420/StyleSpeech/zipball/v1.0.0"
      },
      {
        "authorType": "User",
        "author_name": "keonlee9420",
        "body": "",
        "dateCreated": "2021-06-13T11:26:38Z",
        "datePublished": "2021-06-15T13:50:29Z",
        "html_url": "https://github.com/keonlee9420/StyleSpeech/releases/tag/v0.1.1",
        "name": "Meta-learning",
        "tag_name": "v0.1.1",
        "tarball_url": "https://api.github.com/repos/keonlee9420/StyleSpeech/tarball/v0.1.1",
        "url": "https://api.github.com/repos/keonlee9420/StyleSpeech/releases/44647801",
        "zipball_url": "https://api.github.com/repos/keonlee9420/StyleSpeech/zipball/v0.1.1"
      },
      {
        "authorType": "User",
        "author_name": "keonlee9420",
        "body": "",
        "dateCreated": "2021-06-10T09:37:48Z",
        "datePublished": "2021-06-10T09:39:41Z",
        "html_url": "https://github.com/keonlee9420/StyleSpeech/releases/tag/v0.1.0",
        "name": "First Release",
        "tag_name": "v0.1.0",
        "tarball_url": "https://api.github.com/repos/keonlee9420/StyleSpeech/tarball/v0.1.0",
        "url": "https://api.github.com/repos/keonlee9420/StyleSpeech/releases/44400835",
        "zipball_url": "https://api.github.com/repos/keonlee9420/StyleSpeech/zipball/v0.1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can install the Python dependencies with\n```\npip3 install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 93,
      "date": "Mon, 27 Dec 2021 07:27:23 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "text-to-speech",
      "pytorch",
      "tts",
      "speech-synthesis",
      "english",
      "style",
      "speech-style",
      "prosody",
      "neural-tts",
      "non-autoregressive",
      "fastspeech",
      "stylespeech",
      "meta-learning",
      "speaker",
      "speaker-adaptation",
      "meta-stylespeech",
      "unseen-speaker",
      "one-shot"
    ],
    "technique": "GitHub API"
  }
}
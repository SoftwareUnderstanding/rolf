{
  "citation": [
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "class TargetClass(object): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "class C(object): \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/offscale/cdd-python",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-12T12:30:09Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-16T03:08:44Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8402763422463461
      ],
      "excerpt": "Easily create and maintain Database / ORM models and REST APIs out of existing Python SDKs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9896660253583675
      ],
      "excerpt": "This was created to aid in the ml_params project. It exposes an @abstractclass which is implemented [officially] by more than 8 projects. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9558262821558043
      ],
      "excerpt": "Accumulate the complexity of maintaining interfaces as the underlying release changes (e.g, new version of PyTorch),  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8774658023140088,
        0.9454615381620615
      ],
      "excerpt": "with no static, editable interfaces available. This means developer tooling becomes useless for debugging, introspection, and documentation. \nTo break it down, with current tooling there is no way to know: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9580227285031979
      ],
      "excerpt": "There is no code-completion, and likely the CLI parser won't provide you with the enumeration of possibilities. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8290641089746061,
        0.9607977916256939
      ],
      "excerpt": "so is added as \":param my_id: [PK] The unique identifier\". \nThe following are the different formats supported, all of which can convert betwixt eachother: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9085407521315005
      ],
      "excerpt": "Acquire from the official tensorflow_datasets model zoo, or the ophthalmology focussed ml-prepare library \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9085407521315005
      ],
      "excerpt": "    Acquire from the official tensorflow_datasets model zoo, or the ophthalmology focussed ml-prepare library \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9085407521315005
      ],
      "excerpt": "    Acquire from the official tensorflow_datasets model zoo, or the ophthalmology focussed ml-prepare library \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9085407521315005
      ],
      "excerpt": "    'Acquire from the official tensorflow_datasets model zoo, or the ophthalmology focussed ml-prepare library' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.927499916718775
      ],
      "excerpt": "    comment='Acquire from the official tensorflow_datasets model zoo, or the ophthalmology focussed ml-prepare\\n' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.927499916718775
      ],
      "excerpt": "    Acquire from the official tensorflow_datasets model zoo, or the ophthalmology focussed ml-prepare \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8171453014921944,
        0.8051650312899962
      ],
      "excerpt": "    Emit a string representation of the current instance \n    :returns: String representation of instance \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8299598582515746
      ],
      "excerpt": "IDE and console gives proper insights to function, and arguments, including on type \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8755739818147721
      ],
      "excerpt": "Verbosity of output removes the magic. It's always clear what's going on. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8386868587748249
      ],
      "excerpt": "Open API to/fro routes, models, and tests. Convert between docstrings, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8684473264041652
      ],
      "excerpt": "    sync                Force argparse, classes, and/or methods to be \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8129443929784529
      ],
      "excerpt": "                        sqlalchemy tables and/or sqlalchemy classes from the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9089714126441713
      ],
      "excerpt": "    doctrans            Convert docstring format of all classes and functions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9811817193311695
      ],
      "excerpt": "                        like `a` for `a=5` or with the `.` syntax as in \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8373866441552149,
        0.8179919960833767
      ],
      "excerpt": "                        Parameter to update. E.g., `A.F` for `class A: F`, \n                        `f.g` for `def f(g): pass` \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9512390025359413
      ],
      "excerpt": "                        Wrap all input_str params with this. E.g., \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8164180378364981
      ],
      "excerpt": "                        What type the input is. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8762492212260622
      ],
      "excerpt": "  --emit-call           Whether to place all the previous body into a new \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8999531193718416
      ],
      "excerpt": "                        List of decorators. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9716824764781705
      ],
      "excerpt": "                        What of (C)reate, (R)ead, (U)pdate, (D)elete to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8012491078883274
      ],
      "excerpt": "                        Ensure all types are in docstring (rather than a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9556729271163303
      ],
      "excerpt": "                        Where to place the generated exposed interfaces to the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490037945672047
      ],
      "excerpt": "                        the filesystem. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9165931396168284
      ],
      "excerpt": "for inclusion in the work by you, as defined in the Apache-2.0 license, shall be \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Open API to/fro routes, models, and tests. Convert between docstrings, classes, methods, argparse, and SQLalchemy.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/offscale/cdd-python/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Tue, 28 Dec 2021 11:28:12 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/offscale/cdd-python/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "offscale/cdd-python",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/offscale/cdd-python/master/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9996646107271211,
        0.9942572578159573,
        0.9636153171793423
      ],
      "excerpt": "pip install python-cdd \npip install -r https://raw.githubusercontent.com/offscale/cdd-python/master/requirements.txt \npip install https://api.github.com/repos/offscale/cdd-python/zipball#egg=cdd \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8018566057409832
      ],
      "excerpt": "as_numpy: Optional[bool] = None \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8018566057409832
      ],
      "excerpt": "    as_numpy: Optional[bool] = None, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8237080706980424
      ],
      "excerpt": "You have to run a tool to synchronise your various formats. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8002555885684034
      ],
      "excerpt": "Slow, manual duplication; or \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9270552950857611
      ],
      "excerpt": "usage: python -m cdd [-h] [--version] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  --class-name CLASS_NAMES \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8911050847984643
      ],
      "excerpt": "  --name-tpl NAME_TPL   Template for the name, e.g., `{name}Config`. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9089800547932028
      ],
      "excerpt": "usage: python -m cdd gen_routes [-h] --crud {CRUD,CR,C,R,U,D,CR,CU,CD,CRD} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8964605499923439
      ],
      "excerpt": "  --crud {CRUD,CR,C,R,U,D,CR,CU,CD,CRD} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8057675898656085
      ],
      "excerpt": "  --routes-path ROUTES_PATH \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9136183209541314
      ],
      "excerpt": "                           --output-directory OUTPUT_DIRECTORY [--dry-run] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8339042148969257
      ],
      "excerpt": "                        Modules/FQN to omit. If unspecified will emit all \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8339042148969257
      ],
      "excerpt": "                        Modules/FQN to emit. If unspecified will emit all \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.864003161007744
      ],
      "excerpt": "  --output-directory OUTPUT_DIRECTORY, -o OUTPUT_DIRECTORY \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8180394257854184,
        0.8231526254797409
      ],
      "excerpt": ":param dataset_name: name of dataset. Defaults to mnist \n:type dataset_name: str \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8201639184608793,
        0.844237442885001,
        0.9152861076249257
      ],
      "excerpt": ":type tfds_dir: Optional[str] \n:param K: backend engine, e.g., np or tf. Defaults to np \n:type K: Union[np, tf] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9465056797102493,
        0.9373901266166278
      ],
      "excerpt": ":return: Train and tests dataset splits. Defaults to (np.empty(0), np.empty(0)) \n:rtype: Union[Tuple[tf.data.Dataset, tf.data.Dataset], Tuple[np.ndarray, np.ndarray]] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9457175861910134,
        0.925671696398174
      ],
      "excerpt": "import numpy as np \nimport tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8180394257854184
      ],
      "excerpt": ":cvar dataset_name: name of dataset. Defaults to mnist \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.844237442885001
      ],
      "excerpt": ":cvar K: backend engine, e.g., `np` or `tf`. Defaults to np \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9490876187948273
      ],
      "excerpt": ":cvar return_type: Train and tests dataset splits. Defaults to (np.empty(0), np.empty(0))\"\"\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9260283779971002
      ],
      "excerpt": "K: Literal['np', 'tf'] = 'np' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9373901266166278,
        0.8997243352845468,
        0.8997243352845468
      ],
      "excerpt": "return_type: Union[Tuple[tf.data.Dataset, tf.data.Dataset], Tuple[np.ndarray, np.ndarray]] = ( \n    np.empty(0), \n    np.empty(0), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9457175861910134,
        0.925671696398174
      ],
      "excerpt": "import numpy as np \nimport tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9260283779971002
      ],
      "excerpt": "    K: Literal['np', 'tf'] = 'np', \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9206916477145011
      ],
      "excerpt": ") -&gt; Union[Tuple[tf.data.Dataset, tf.data.Dataset], Tuple[np.ndarray, np.ndarray]]: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8297973355019749
      ],
      "excerpt": "    :param dataset_name: name of dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8907372906726914
      ],
      "excerpt": "    :return: Train and tests dataset splits. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8959624559666044
      ],
      "excerpt": "    return np.empty(0), np.empty(0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8829100416208092,
        0.9457175861910134,
        0.925671696398174
      ],
      "excerpt": "from json import loads \nimport numpy as np \nimport tensorflow as tf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8907372906726914,
        0.9373901266166278
      ],
      "excerpt": ":return: argument_parser, Train and tests dataset splits. \n:rtype: ```Tuple[ArgumentParser, Union[Tuple[tf.data.Dataset, tf.data.Dataset], Tuple[np.ndarray, np.ndarray]]]``` \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9059217670156292
      ],
      "excerpt": "    '--dataset_name', type=str, help='name of dataset.', required=True, default='mnist' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8231526254797409
      ],
      "excerpt": "    type=str, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9185291611602425,
        0.8031853771971914
      ],
      "excerpt": "    choices=('np', 'tf'), \n    help='backend engine, expr.g., `np` or `tf`.', \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8882506845694146
      ],
      "excerpt": "    default='np', \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8512675751086797
      ],
      "excerpt": "argument_parser.add_argument('--as_numpy', type=bool, help='Convert to numpy ndarrays') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8032702449623945
      ],
      "excerpt": "    '--data_loader_kwargs', type=loads, help='pass this as arguments to data_loader function' \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8959624559666044
      ],
      "excerpt": "return argument_parser, (np.empty(0), np.empty(0)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8252974936452576
      ],
      "excerpt": "from sqlalchemy import JSON, Boolean, Column, Enum, MetaData, String, Table, create_engine \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8297973355019749
      ],
      "excerpt": "        doc=\"name of dataset\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "        primary_key=True, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9442925525001276
      ],
      "excerpt": "        Enum(\"np\", \"tf\", name=\"K\"), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8882506845694146
      ],
      "excerpt": "        default=\"np\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "        nullable=True, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "        nullable=True, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9353020506903496,
        0.9373901266166278
      ],
      "excerpt": "            ':returns: Train and tests dataset splits. Defaults to (np.empty(0), np.empty(0))\\n' \n            ':rtype: Union[Tuple[tf.data.Dataset, tf.data.Dataset], Tuple[np.ndarray, np.ndarray]]', \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516,
        0.8380689615612127
      ],
      "excerpt": "from sqlalchemy.orm import declarative_base \nfrom sqlalchemy import JSON, Boolean, Column, Enum, String \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9353020506903496,
        0.9373901266166278
      ],
      "excerpt": ":returns: Train and tests dataset splits. Defaults to (np.empty(0), np.empty(0)) \n:rtype: ```Union[Tuple[tf.data.Dataset, tf.data.Dataset], Tuple[np.ndarray, np.ndarray]]``` \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8297973355019749
      ],
      "excerpt": "    doc=\"name of dataset\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "    primary_key=True, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9442925525001276
      ],
      "excerpt": "    Enum(\"np\", \"tf\", name=\"K\"), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8882506845694146
      ],
      "excerpt": "    default=\"np\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "    nullable=True, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "    nullable=True, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8172263718106165
      ],
      "excerpt": "usage: python -m cdd [-h] [--version] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8451207688281708,
        0.8047664157100849
      ],
      "excerpt": "    gen_routes          Generate per model route(s) \n    openapi             Generate OpenAPI schema from specified project(s) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8953620532097932,
        0.869462072025036
      ],
      "excerpt": "usage: python -m cdd sync [-h] [--argparse-function ARGPARSE_FUNCTIONS] \n                          [--argparse-function-name ARGPARSE_FUNCTION_NAMES] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8238389539583573
      ],
      "excerpt": "                          [--function-name FUNCTION_NAMES] --truth \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.869462072025036,
        0.838481981613089
      ],
      "excerpt": "  --argparse-function-name ARGPARSE_FUNCTION_NAMES \n                        Name of argparse function. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8095220053800375
      ],
      "excerpt": "  --class-name CLASS_NAMES \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.869462072025036
      ],
      "excerpt": "  --function-name FUNCTION_NAMES \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9288955386736611
      ],
      "excerpt": "usage: python -m cdd sync_properties [-h] --input-filename INPUT_FILENAME \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9062177780981814,
        0.8289669050403863,
        0.8223576623899506
      ],
      "excerpt": "                                     --output-filename OUTPUT_FILENAME \n                                     --output-param OUTPUT_PARAMS \n                                     [--output-param-wrap OUTPUT_PARAM_WRAP] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8673343399351511
      ],
      "excerpt": "  --input-filename INPUT_FILENAME \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8289669050403863
      ],
      "excerpt": "                        `--output-param`. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9062177780981814
      ],
      "excerpt": "  --output-filename OUTPUT_FILENAME \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8289669050403863
      ],
      "excerpt": "  --output-param OUTPUT_PARAMS \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8223576623899506
      ],
      "excerpt": "  --output-param-wrap OUTPUT_PARAM_WRAP \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8811963526825138
      ],
      "excerpt": "usage: python -m cdd gen [-h] --name-tpl NAME_TPL --input-mapping \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8202971476673107
      ],
      "excerpt": "                         [--imports-from-file IMPORTS_FROM_FILE] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8425730159326575
      ],
      "excerpt": "                         --output-filename OUTPUT_FILENAME [--emit-call] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8377540554929738
      ],
      "excerpt": "  --name-tpl NAME_TPL   Template for the name, e.g., `{name}Config`. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8202971476673107,
        0.8244154692576809
      ],
      "excerpt": "  --imports-from-file IMPORTS_FROM_FILE \n                        Extract imports from file and append to `output_file`. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9062177780981814,
        0.9032988033894906
      ],
      "excerpt": "  --output-filename OUTPUT_FILENAME, -o OUTPUT_FILENAME \n                        Output file to write to. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8446643123941485,
        0.8412256355144345,
        0.8299165255990127
      ],
      "excerpt": "usage: python -m cdd gen_routes [-h] --crud {CRUD,CR,C,R,U,D,CR,CU,CD,CRD} \n                                [--app-name APP_NAME] --model-path MODEL_PATH \n                                --model-name MODEL_NAME --routes-path \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.823719961071482
      ],
      "excerpt": "  --model-path MODEL_PATH \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8141765156990655,
        0.8289959638904407,
        0.8398499113773561
      ],
      "excerpt": "                        (foo/models) \n  --model-name MODEL_NAME \n                        Name of model to generate from \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8799933091447526
      ],
      "excerpt": "usage: python -m cdd openapi [-h] [--app-name APP_NAME] --model-paths \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8141765156990655
      ],
      "excerpt": "                        (foo/models) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9326650710630215
      ],
      "excerpt": "usage: python -m cdd doctrans [-h] --filename FILENAME --format \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8935817241076595
      ],
      "excerpt": "  --filename FILENAME   Python file to convert docstrings within. Edited in \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8347547938814801
      ],
      "excerpt": "  --type-annotations    Inline the type, i.e., annotate PEP484 (outside \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.895293630564514
      ],
      "excerpt": "                           --output-directory OUTPUT_DIRECTORY [--dry-run] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8585707754631647
      ],
      "excerpt": "  --output-directory OUTPUT_DIRECTORY, -o OUTPUT_DIRECTORY \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/offscale/cdd-python/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "cdd-python",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "cdd-python",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "offscale",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/offscale/cdd-python/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Tue, 28 Dec 2021 11:28:12 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "openapi",
      "compiler",
      "sqlalchemy",
      "argparse",
      "docstrings"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To create a `class` from [`tf.keras.optimizers.Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam):\n\n```python\n>>> from cdd.source_transformer import to_code\n\n>>> from cdd import emit, parse\n\n>>> import tensorflow as tf\n\n>>> from typing import Optional\n\n>>> print(to_code(emit.class_(parse.class_(tf.keras.optimizers.Adam,\n                                           merge_inner_function=\"__init__\"),\n                              class_name=\"AdamConfig\")))\n\n\nclass AdamConfig(object):\n    \"\"\"\n    Optimizer that implements the Adam algorithm.\n\n    Adam optimization is a stochastic gradient descent method that is based on\n    adaptive estimation of first-order and second-order moments.\n\n    According to\n    [Kingma et al., 2014](http://arxiv.org/abs/1412.6980),\n    the method is \"*computationally\n    efficient, has little memory requirement, invariant to diagonal rescaling of\n    gradients, and is well suited for problems that are large in terms of\n    data/parameters*\".\n\n\n    Usage:\n\n    >>> opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n    >>> var1 = tf.Variable(10.0)\n    >>> loss = lambda: (var1 ** 2)/2.0       #: d(loss)/d(var1) == var1\n    >>> step_count = opt.minimize(loss, [var1]).numpy()\n    >>> #: The first step is `-learning_rate*sign(grad)`\n    >>> var1.numpy()\n    9.9\n\n    Reference:\n      - [Kingma et al., 2014](http://arxiv.org/abs/1412.6980)\n      - [Reddi et al., 2018](\n          https://openreview.net/pdf?id=ryQu7f-RZ) for `amsgrad`.\n\n    Notes:\n\n    The default value of 1e-7 for epsilon might not be a good default in\n    general. For example, when training an Inception network on ImageNet a\n    current good choice is 1.0 or 0.1. Note that since Adam uses the\n    formulation just before Section 2.1 of the Kingma and Ba paper rather than\n    the formulation in Algorithm 1, the \"epsilon\" referred to here is \"epsilon\n    hat\" in the paper.\n\n    The sparse implementation of this algorithm (used when the gradient is an\n    IndexedSlices object, typically because of `tf.gather` or an embedding\n    lookup in the forward pass) does apply momentum to variable slices even if\n    they were not used in the forward pass (meaning they have a gradient equal\n    to zero). Momentum decay (beta1) is also applied to the entire momentum\n    accumulator. This means that the sparse behavior is equivalent to the dense\n    behavior (in contrast to some momentum implementations which ignore momentum\n    unless a variable slice was actually used).\n\n    :cvar learning_rate: A `Tensor`, floating point value, or a schedule that is a\n        `tf.keras.optimizers.schedules.LearningRateSchedule`, or a callable that takes no arguments and\n        returns the actual value to use, The learning rate.\n    :cvar beta_1: A float value or a constant float tensor, or a callable that takes no arguments and\n        returns the actual value to use. The exponential decay rate for the 1st moment estimates.\n    :cvar beta_2: A float value or a constant float tensor, or a callable that takes no arguments and\n        returns the actual value to use, The exponential decay rate for the 2nd moment estimates.\n    :cvar epsilon: A small constant for numerical stability. This epsilon is \"epsilon hat\" in the\n        Kingma and Ba paper (in the formula just before Section 2.1), not the epsilon in Algorithm 1 of the\n        paper.\n    :cvar amsgrad: Boolean. Whether to apply AMSGrad variant of this algorithm from the paper \"On the\n        Convergence of Adam and beyond\".\n    :cvar name: Optional name for the operations created when applying gradients.\n    :cvar kwargs: Keyword arguments. Allowed to be one of `\"clipnorm\"` or `\"clipvalue\"`. `\"clipnorm\"`\n        (float) clips gradients by norm; `\"clipvalue\"` (float) clips gradients by value.\"\"\"\n    learning_rate: float = 0.001\n    beta_1: float = 0.9\n    beta_2: float = 0.999\n    epsilon: float = 1e-07\n    amsgrad: bool = False\n    name: Optional[str] = 'Adam'\n    kwargs: Optional[dict] = None\n    _HAS_AGGREGATE_GRAD: bool = True\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
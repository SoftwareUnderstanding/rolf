{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1909.09974",
      "https://arxiv.org/abs/1710.10196",
      "https://arxiv.org/abs/1704.00028"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "label_size = 10 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cedricoeldorf/ConditionalStyleGAN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-22T23:37:52Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-09T12:15:34Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.936530769624157,
        0.8568038895979644,
        0.8833286736849113
      ],
      "excerpt": "The paper of this project is available here, a poster version will appear at ICMLA 2019. \nImplementation of a conditional StyleGAN architecture based on the official source code published by NVIDIA \nResults A preview of logos generated by the conditional StyleGAN synthesis network. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9972069374470485
      ],
      "excerpt": "Domains such as logo synthesis, in which the data has a high degree of multi-modality, still pose a challenge for generative adversarial networks (GANs). Recent research shows that progressive training (ProGAN) and mapping network extensions (StyleGAN) enable both increased training stability for higher dimensional problems and better feature separation within the embedded latent space. However, these architectures leave limited control over shaping the output of the network, which is an undesirable trait in the case of logo synthesis. This thesis explores a conditional extension to the StyleGAN architecture with the aim of firstly, improving on the low resolution results of previous research and, secondly, increasing the controllability of the output through the use of synthetic class-conditions. Furthermore, methods of extracting such class conditions are explored with a focus on the human interpretability, where the challenge lies in the fact that, by nature, visual logo characteristics are hard to define. The introduced conditional style-based generator architecture is trained on the extracted class-conditions in two experiments and studied relative to the performance of an unconditional model. Results show that, whilst the unconditional model more closely matches the training distribution, high quality conditions enabled the embedding of finer details onto the latent space, leading to more diverse output. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9369280718695328,
        0.8178449605865842
      ],
      "excerpt": "As opposed to feeding a random vector straight into the generator, the input \nis projected onto an intermediate latent space w by being fed through a mapping \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8809140756659102,
        0.9195919640416079
      ],
      "excerpt": "In context of the mapping network, the intermediate vector \nw is transformed into the scale and bias of the AdaIN equation. Noting that w reflects the style, AdaIN, through its normalization process, de \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8470133436817271
      ],
      "excerpt": "AdaIN, the feature map is translated into a visual representation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9450229147107461,
        0.920123571229276,
        0.8524043860241226,
        0.9537059266447883
      ],
      "excerpt": "In order to enable control the style of the generated output, conditions are introduced. There are two major differences between the conditional and un- \nconditional StyleGAN architectures, namely the way the input to the generator \nw is produced and in how the discriminator calculates its loss. \nFirstly, noise is introduced to the one-hot encoded class conditions, which are then concatenated with the input space z before being fed into the mapping network. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8043485490381341,
        0.9559058308914706,
        0.919771365411794
      ],
      "excerpt": "for which the paper can be found here \nFor this paper we removed all text-based images from the LLD-logo dataset and extended the remaining logos with image based logos and illustrations scraped off of Google images. \nFigure 2: As seen above, the extension also included vector illustrations that were not originally intended as logos, but carry visual characteristics of such. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9167312096382821
      ],
      "excerpt": " | &boxv;&nbsp; &boxv;&nbsp; tflib | Helper for managing networks and optimization \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8621912469282011
      ],
      "excerpt": "These variables have to be adjusted according to your needs in multiple scripts before training: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8719043380607154
      ],
      "excerpt": "Set hyper-parameters for networks and other indications for the training loop \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8912422254305415
      ],
      "excerpt": "drange_net              = [-1,1],   #: Dynamic range used when feeding image data to the networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9110759749784144,
        0.8324933639354246
      ],
      "excerpt": "fmap_base           = 8192,         #: Overall multiplier for the number of feature maps. \nfmap_decay          = 1.0,          #: log2 feature map reduction when doubling the resolution. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8605150367027061
      ],
      "excerpt": "dtype               = 'float32',    #: Data type to use for activations and outputs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8753905461411213
      ],
      "excerpt": "blur_filter         = [1,2,1],      #: Low-pass filter to apply when resampling activations. None = no filtering. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9110759749784144,
        0.8324933639354246
      ],
      "excerpt": "fmap_base           = 8192,         #: Overall multiplier for the number of feature maps. \nfmap_decay          = 1.0,          #: log2 feature map reduction when doubling the resolution. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8494398616848972,
        0.8691851674117091
      ],
      "excerpt": "mbstd_group_size    = 4,            #: Group size for the minibatch standard deviation layer, 0 = disable. \nmbstd_num_features  = 1,            #: Number of features for the minibatch standard deviation layer. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8753905461411213
      ],
      "excerpt": "blur_filter         = [1,2,1],      #: Low-pass filter to apply when resampling activations. None = no filtering. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Conditional implementation for NVIDIA's StyleGAN architecture ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cedricoeldorf/ConditionalStyleGAN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 36,
      "date": "Sun, 26 Dec 2021 23:39:54 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/cedricoeldorf/ConditionalStyleGAN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "cedricoeldorf/ConditionalStyleGAN",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The ```dataset_tool.py``` script is responsible for turning your data into Tensorflow record files. However, each image in the data set must have the <u>exact</u> same format in terms of size, extension, colour space and bit depth. Any irregular images will automatically be kicked from the data set.\n\nWe refer you to the [imagemagick](https://imagemagick.org/index.php) library for all transformation tools.\n\nThe script takes a pickled dictionary as input with the following format:\n\n```\n#: Pickle path = '../data/mypickle.pickle'\nmypickle = {\"Filenames\": list_of_file_paths, \"Labels\": class_condition_labels}\n```\n\nThe script is run from the terminal and takes the paths to your images and the path of your TF-record directory as flags\n\n```\npython dataset_tool.py create_from_images dataset/logos ../data/my_images\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8749076941118147
      ],
      "excerpt": " | ConditionalStyleGAN | Main folder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9132566544672166
      ],
      "excerpt": " | &boxv;&nbsp; &boxvr;&nbsp; frechet_inception_distance.py | FID function \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731716804847287
      ],
      "excerpt": " | &boxv;&nbsp; &boxvr;&nbsp; perceptual_path_length.py | Perceptual path length \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": " | &boxv;&nbsp; &boxvr;&nbsp; misc.py | Misc. utility functions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9366363271653126
      ],
      "excerpt": " | &boxv;&nbsp; &boxvr;&nbsp; training_loop.py | Main training script \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8722954350006628,
        0.8146987923390707,
        0.9292896398596935
      ],
      "excerpt": " | &boxvr;&nbsp; pretrained_example.py | StyleGAN single example \n | &boxvr;&nbsp; run_metrics.py | Evaluation \n | &boxvr;&nbsp; train.py | Main entry point for training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.912986481897422
      ],
      "excerpt": "train.py line 37: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9324566002338663
      ],
      "excerpt": "./training/dataset.py line 49: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9396076756602774
      ],
      "excerpt": "- ./training/networks_stylegan.py line 388 & line 569: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8952593382546921
      ],
      "excerpt": "Starting at line 112 in training_loop.py: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8076863332829682
      ],
      "excerpt": "total_kimg              = 20000,    #: Total length of the training, measured in thousands of real images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8952593382546921
      ],
      "excerpt": "Starting at line 384 in networks_stylegan.py: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8952593382546921
      ],
      "excerpt": "Starting at line 384 in networks_stylegan.py: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8779548826208656
      ],
      "excerpt": "const_input_layer   = True,         #: First layer is a learned constant? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003168695950917
      ],
      "excerpt": "fused_scale         = 'auto',       #: True = fused convolution + scaling, False = separate ops, 'auto' = decide automatically. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8952593382546921
      ],
      "excerpt": "Starting at line 384 in networks_stylegan.py: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003168695950917
      ],
      "excerpt": "fused_scale         = 'auto',       #: True = fused convolution + scaling, False = separate ops, 'auto' = decide automatically. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503189345333785
      ],
      "excerpt": "python train.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/cedricoeldorf/ConditionalStyleGAN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Conditional Style-Based Logo Generation with Generative Adversarial Networks",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ConditionalStyleGAN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "cedricoeldorf",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cedricoeldorf/ConditionalStyleGAN/blob/master/readme.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 182,
      "date": "Sun, 26 Dec 2021 23:39:54 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This project has received funding from the European Union\u2019s Horizon 2020 research and innovation programme under grant agreement No 825292. This project is better known as the ExaMode project. The objectives of the ExaMode project are:\n1. Weakly-supervised knowledge discovery for exascale medical data.  \n2. Develop extreme scale analytic tools for heterogeneous exascale multimodal and multimedia data.  \n3. Healthcare & industry decision-making adoption of extreme-scale analysis and prediction tools.\n\nFor more information on the ExaMode project, please visit www.examode.eu. \n\n![enter image description here](https://www.examode.eu/wp-content/uploads/2018/11/horizon.jpg)  ![enter image description here](https://www.examode.eu/wp-content/uploads/2018/11/flag_yellow.png) <img src=\"https://www.examode.eu/wp-content/uploads/2018/11/cropped-ExaModeLogo_blacklines_TranspBackGround1.png\" width=\"80\">\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1911.09070 ",
      "https://arxiv.org/abs/1802.02611 "
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9944484218006108,
        0.9944484218006108
      ],
      "excerpt": "- EfficientDet ( https://arxiv.org/abs/1911.09070 ) \n- DeeplabV3+ ( https://arxiv.org/abs/1802.02611 ) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8432683736161086,
        0.8550101043698384
      ],
      "excerpt": "wget http://download.osgeo.org/libtiff/tiff-4.0.10.tar.gz \ntar -xvf tiff-4.0.10.tar.gz \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9086892148066392
      ],
      "excerpt": "cd $HOME/virtualenvs/$VENV_NAME/tiff-4.0.10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8656070203791273
      ],
      "excerpt": "wget https://github.com/uclouvain/openjpeg/archive/v2.3.1.tar.gz \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sara-nl/SURF-segmentation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-03T16:14:00Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-22T14:41:40Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9846569624165821
      ],
      "excerpt": "This repository is developed as part of the Examode EU project, and is meant for conducting experiments for large field-of-view semantic segmentation. The current codebase supports CAMELYON16 and CAMELYON17, and supports efficient execution on multi-node CPU clusters, as well as multi-node, multi-GPU clusters. Models using very large FoV (> 1024x1024) can be trained on multi-GPU cluster, using the instructions below. The models adapted for the use case of semantic segmentation of malignant tumor regions are: \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sara-nl/SURF-deeplab/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 00:08:21 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sara-nl/SURF-segmentation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "sara-nl/SURF-segmentation",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/sara-nl/SURF-deeplab/master/efficientdet/tutorial.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/sara-nl/SURF-deeplab/master/efficientdet/keras/run.sh",
      "https://raw.githubusercontent.com/sara-nl/SURF-deeplab/master/DCGMM_TF2.1%5BDeprecated%5D/train.sh",
      "https://raw.githubusercontent.com/sara-nl/SURF-deeplab/master/deeplab/run_train.sh",
      "https://raw.githubusercontent.com/sara-nl/SURF-deeplab/master/deeplab/run_endeavor.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Now export environment variables for installing Horovod w/ MPI for multiworker training, and install Python packages:\n```\nmodule purge\nmodule load 2019\nmodule load 2020\nmodule load Python/3.8.2-GCCcore-9.3.0\nmodule load OpenMPI/4.0.3-GCC-9.3.0\nmodule load cuDNN/7.6.5.32-CUDA-10.1.243\nmodule load NCCL/2.5.6-CUDA-10.1.243\nmodule unload GCCcore\nmodule unload ncurses\nmodule load CMake/3.11.4-GCCcore-8.3.0\nsource $HOME/virtualenvs/openslide-py38/bin/activate\n\nexport HOROVOD_CUDA_HOME=$CUDA_HOME\nexport HOROVOD_CUDA_INCLUDE=$CUDA_HOME/include\nexport HOROVOD_CUDA_LIB=$CUDA_HOME/lib64\nexport HOROVOD_NCCL_HOME=$EBROOTNCCL\nexport HOROVOD_GPU_ALLREDUCE=NCCL\nexport HOROVOD_GPU_BROADCAST=NCCL\nexport HOROVOD_WITHOUT_GLOO=1\nexport HOROVOD_WITH_TENSORFLOW=1\nexport PATH=/home/$USER/virtualenvs/openslide-py38/bin:$PATH\nexport LD_LIBRARY_PATH=/home/$USER/virtualenvs/openslide-py38/lib64:$LD_LIBRARY_PATH\nexport LD_LIBRARY_PATH=/home/$USER/virtualenvs/openslide-py38/lib:$LD_LIBRARY_PATH\nexport CPATH=/home/$USER/virtualenvs/openslide-py38/include:$CPATH\n#: Export MPICC\nexport MPICC=mpicc\nexport MPICXX=mpicpc\nexport HOROVOD_MPICXX_SHOW=\"mpicxx --showme:link\"\n\n#: Install Python packages\npip install -r requirements.txt\n```\n\n- Options for model training:\nFor model training two architectures are used:\n1. `DeeplabV3+`   ( ~ 41 mln parameters, 177B FLOPs)\n2. `EfficientDetD[0-7]` ( ~ 20 mln parameters for D4, 18B FLOPs)\n\nPlease look in repositories for further steps. \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "These steps ran on LISA with this module environment: \n\nModules loaded:\n```\ncd $HOME\nmodule purge\nmodule load 2019\nmodule load 2020\nmodule load Python/3.8.2-GCCcore-9.3.0\nmodule load OpenMPI/4.0.3-GCC-9.3.0\nmodule load cuDNN/7.6.5.32-CUDA-10.1.243\nmodule load NCCL/2.5.6-CUDA-10.1.243\nmodule unload GCCcore\nmodule unload ncurses\nmodule load CMake/3.11.4-GCCcore-8.3.0\n\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8613564504233543,
        0.8360317535545281,
        0.8474895321345809,
        0.999833231880651,
        0.9967888697644471,
        0.9906248903846466,
        0.9295008271591669
      ],
      "excerpt": "cd $HOME/virtualenvs/$VENV_NAME/tiff-4.0.10 \nCC=gcc CXX=g++ ./configure --prefix=$HOME/virtualenvs/$VENV_NAME \nmake -j 8 \nInstall LibTIFF \nmake install \ncd .. \nThe official install instructions are available here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9011782377426846,
        0.8644500257064217
      ],
      "excerpt": "wget https://github.com/uclouvain/openjpeg/archive/v2.3.1.tar.gz \ntar -xvf v2.3.1.tar.gz \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9667962799953682,
        0.8574891646813673,
        0.8474895321345809,
        0.9547818424216766,
        0.9967888697644471,
        0.9906248903846466
      ],
      "excerpt": "cd $HOME/virtualenvs/$VENV_NAME/openjpeg-2.3.1 \nCC=gcc CXX=g++ cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=$HOME/virtualenvs/$VENV_NAME -DBUILD_THIRDPARTY:bool=on \nmake -j 8 \n3. Install OpenJPEG (we already added the paths to the environment variables) \nmake install \ncd .. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9444575284883591,
        0.8644500257064217
      ],
      "excerpt": "wget https://github.com/openslide/openslide/releases/download/v3.4.1/openslide-3.4.1.tar.gz \ntar -xvf openslide-3.4.1.tar.gz \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9667962799953682,
        0.8186544031720834,
        0.8474895321345809,
        0.9547818424216766,
        0.9967888697644471,
        0.9906248903846466
      ],
      "excerpt": "cd $HOME/virtualenvs/$VENV_NAME/openslide-3.4.1 \nCC=gcc CXX=g++ PKG_CONFIG_PATH=$HOME/virtualenvs/$VENV_NAME/lib/pkgconfig ./configure --prefix=$HOME/virtualenvs/$VENV_NAME \nmake -j 8 \nInstall OpenSlide (we already added the paths to the environment variables) \nmake install \ncd .. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9444575284883591,
        0.8644500257064217
      ],
      "excerpt": "wget https://github.com/libvips/libvips/releases/download/v8.9.2/vips-8.9.2.tar.gz \ntar -xvf vips-8.9.2.tar.gz \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9667962799953682,
        0.8186544031720834,
        0.8474895321345809
      ],
      "excerpt": "cd $HOME/virtualenvs/$VENV_NAME/vips-8.9.2 \nCC=gcc CXX=g++ PKG_CONFIG_PATH=$HOME/virtualenvs/$VENV_NAME/lib/pkgconfig ./configure --prefix=$HOME/virtualenvs/$VENV_NAME \nmake -j 8 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9547818424216766,
        0.9967888697644471,
        0.9906248903846466
      ],
      "excerpt": "Install Libvips (we already added the paths to the environment variables) \nmake install \ncd .. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sara-nl/SURF-segmentation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Emil Zakirov\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Extended FoV Semantic Segmentation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SURF-segmentation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "sara-nl",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sara-nl/SURF-segmentation/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We will create a virtual environment with Openslide (https://openslide.org/api/python/) and libvips (https://libvips.github.io/libvips/install.html), for opening and sampling from whole-slide-images.\n\n- Pick a name for the virtual environment, and make the virtual environment folder using `virtualenv`:\n\n```\nVENV_NAME=openslide\ncd $HOME\nvirtualenv $HOME/virtualenvs/$VENV_NAME\ncd $HOME/virtualenvs/$VENV_NAME\n```\nThen add the relevant values to the environment variables:\n```\nexport PATH=$HOME/virtualenvs/$VENV_NAME/bin:$PATH\nexport LD_LIBRARY_PATH=$HOME/virtualenvs/$VENV_NAME/lib64:$LD_LIBRARY_PATH\nexport LD_LIBRARY_PATH=$HOME/virtualenvs/$VENV_NAME/lib:$LD_LIBRARY_PATH\nexport CPATH=$HOME/virtualenvs/$VENV_NAME/include:$CPATH\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Wed, 29 Dec 2021 00:08:21 GMT"
    },
    "technique": "GitHub API"
  }
}
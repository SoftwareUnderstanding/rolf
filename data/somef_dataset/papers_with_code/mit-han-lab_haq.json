{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1802.03494",
      "https://arxiv.org/abs/1812.00332"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{haq,\nauthor = {Wang, Kuan and Liu, Zhijian and Lin, Yujun and Lin, Ji and Han, Song},\ntitle = {HAQ: Hardware-Aware Automated Quantization With Mixed Precision},\nbooktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\nyear = {2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": ": preserve ratio 10% \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mit-han-lab/haq",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-14T02:06:06Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-27T01:56:36Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This repo contains PyTorch implementation for paper [HAQ: Hardware-Aware Automated Quantization with Mixed Precision](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_HAQ_Hardware-Aware_Automated_Quantization_With_Mixed_Precision_CVPR_2019_paper.pdf) (CVPR2019, oral)\n\n![overview](https://hanlab.mit.edu/projects/haq/images/overview.png)\n\n```\n@inproceedings{haq,\nauthor = {Wang, Kuan and Liu, Zhijian and Lin, Yujun and Lin, Ji and Han, Song},\ntitle = {HAQ: Hardware-Aware Automated Quantization With Mixed Precision},\nbooktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\nyear = {2019}\n}\n```\n\nOther papers related to automated model design:\n- AMC: AutoML for Model Compression and Acceleration on Mobile Devices ([ECCV 2018](https://arxiv.org/abs/1802.03494))\n\n- ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware ([ICLR 2019](https://arxiv.org/abs/1812.00332))\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9227287924157422
      ],
      "excerpt": "We use a subset of ImageNet in the linear quantizaiton search phase to save the training time, to create the link of the subset, you can use the following tool: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8880945083272718
      ],
      "excerpt": "You can run the bash file as following to search the K-Means quantization strategy, which only quantizes the weights with K-Means to compress model size of specific model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8456021192498061
      ],
      "excerpt": ": K-Means quantization, for model size \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8746109327677183
      ],
      "excerpt": ": Linear quantization, for latency/energy \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8270700839164564
      ],
      "excerpt": "- We set the default linear quantization strategy searched under preserve ratio = 0.6 like: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8051496634173332
      ],
      "excerpt": "You can follow the following bash file to finetune the linear quantized model to get a better performance: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "[CVPR 2019, Oral] HAQ: Hardware-Aware Automated Quantization with Mixed Precision",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mit-han-lab/haq/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 69,
      "date": "Wed, 29 Dec 2021 20:15:21 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mit-han-lab/haq/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "mit-han-lab/haq",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/mit-han-lab/haq/master/run/run_linear_quantize_finetune.sh",
      "https://raw.githubusercontent.com/mit-han-lab/haq/master/run/run_kmeans_quantize_search.sh",
      "https://raw.githubusercontent.com/mit-han-lab/haq/master/run/run_kmeans_quantize_finetune.sh",
      "https://raw.githubusercontent.com/mit-han-lab/haq/master/run/run_linear_quantize_search.sh",
      "https://raw.githubusercontent.com/mit-han-lab/haq/master/run/setup.sh",
      "https://raw.githubusercontent.com/mit-han-lab/haq/master/run/run_pretrain.sh",
      "https://raw.githubusercontent.com/mit-han-lab/haq/master/run/run_kmeans_quantize_eval.sh",
      "https://raw.githubusercontent.com/mit-han-lab/haq/master/run/run_linear_quantize_eval.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8013497348029985
      ],
      "excerpt": ": prepare dataset, change the path to your own \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8533583129906306
      ],
      "excerpt": "If you do not have the ImageNet yet, you can download the ImageNet dataset and move validation images to labeled subfolders. To do this, you can use the following script:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9630513359443713
      ],
      "excerpt": "bash run/run_kmeans_quantize_search.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9630513359443713
      ],
      "excerpt": "bash run/run_linear_quantize_search.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9630513359443713
      ],
      "excerpt": "bash run/run_kmeans_quantize_finetune.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9630513359443713
      ],
      "excerpt": "bash run/run_linear_quantize_finetune.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8096422022825122
      ],
      "excerpt": ": download checkpoint \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9020639017397599
      ],
      "excerpt": "cd checkpoints/resnet50/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd ../mobilenetv2/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "cd ../.. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9630513359443713
      ],
      "excerpt": "bash run/run_kmeans_quantize_eval.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9630513359443713
      ],
      "excerpt": "bash run/run_linear_quantize_eval.sh \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8806172187587361
      ],
      "excerpt": "python lib/utils/make_data.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8099757883433454,
        0.8971823465573899
      ],
      "excerpt": "- Usage details \npython rl_quantize.py --help \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8099757883433454,
        0.8971823465573899
      ],
      "excerpt": "- Usage details \npython finetune.py --help \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8383716214794231
      ],
      "excerpt": ": download checkpoint \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/mit-han-lab/haq/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 MIT HAN Lab\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "HAQ: Hardware-Aware Automated Quantization with Mixed Precision",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "haq",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "mit-han-lab",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mit-han-lab/haq/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We evaluate this code with Pytorch 1.1 (cuda10) and torchvision 0.3.0, you can install pytorch with conda:\n```\n#: install pytorch\nconda install -y pytorch torchvision cudatoolkit=10.0 -c pytorch\n```\nAnd you can use the following command to set up the environment:\n```\n#: install packages and download the pretrained model\nbash run/setup.sh\n```\n(If the server is down, you can download the pretrained model from google drive: [mobilenetv2-150.pth.tar](https://drive.google.com/open?id=1fZ1gNSzSZTQfJ0dL-bNYULNvZJxp_Y53))\n\nCurrent code base is tested under following environment:\n1. Python         3.7.3\n2. PyTorch        1.1\n3. torchvision    0.3.0\n4. numpy          1.14\n5. matplotlib     3.0.1\n6. scikit-learn   0.21.0\n7. easydict       1.8\n8. progress       1.4\n9. tensorboardX   1.7\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 277,
      "date": "Wed, 29 Dec 2021 20:15:21 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "quantization",
      "automl",
      "mixed-precision",
      "efficient-model"
    ],
    "technique": "GitHub API"
  }
}
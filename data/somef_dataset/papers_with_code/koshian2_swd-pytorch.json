{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/koshian2/swd-pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-14T06:02:20Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-24T09:23:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9508569401653578,
        0.8619385133831984,
        0.9716088510530194,
        0.8528609331923174
      ],
      "excerpt": "An implementation of Sliced Wasserstein Distance (SWD) in PyTorch. GPU acceleration is available. \nSWD is not only for GANs. SWD can measure image distribution mismatches or imbalances  without additional labels. \nOriginal idea is written in PGGAN paper. This repo is an unofficial implementation. \nOriginal code is for Numpy. But this repo's code is for PyTorch, so you can calculate SWD on CUDA devices. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8405801992456496
      ],
      "excerpt": "image1, image2 : Required 4rank PyTorch tensor. Each tensor shapes are [N, ch, H, W]. Square size(H=W) is recommended. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9675207221287987,
        0.8694544891456281
      ],
      "excerpt": "n_repeat_projection : (Optional) Number of times to calculate a random projection. Please specify this value according your GPU memory. Default is 128.  n_repeat_projection * proj_per_repeat = 512 is recommended. This product value 512 is same as paper, but official implementation uses 4 for n_repeat_projection and 128 for proj_per_repeat. (This method needs huge amount of memory...) \nproj_per_repeat : (Optional) Number of dimension to calculate a random projection on each repeat. Default is 4. Higher value needs much more GPU memory. n_repeat_projection * proj_per_repeat = 512 is recommended. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9695959775699594
      ],
      "excerpt": "In all conditions, n_repeat_projection * proj_per_repeat is fixed at 512. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8810287706159045
      ],
      "excerpt": "Changing the number of data has a huge impact on SWD (important). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.806332624861339
      ],
      "excerpt": "It is important to fix the number of samples initially. If the number of samples changes, SWD returns incorrect result. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8598011962950503,
        0.8138555406032032
      ],
      "excerpt": "Remove classes : Test data is without changing, while training data is deleting 0-8 classes. \nInbalanced classes : Test data is without changing, while training data create imbalances artificially : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9807521855846687,
        0.8022304954538002
      ],
      "excerpt": "A and B are concatenated with a size of 0-10000, and only 1 class create unbalanced data. \nExperiment 1 and 2 are also imbalanced data, but 1 produces a stronger imbalance or distribution mismatch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8824096876918232
      ],
      "excerpt": "As more classes are deleted, higher SWD are observed. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Sliced Wasserstein Distance (SWD) in PyTorch",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/koshian2/swd-pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Fri, 24 Dec 2021 18:02:14 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/koshian2/swd-pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "koshian2/swd-pytorch",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9015559522955707
      ],
      "excerpt": "device : (Optional) \"cpu\" or \"cuda\". Please specify cuda when uses gpu acceleration. Default is \"cpu\". \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9100826636291368
      ],
      "excerpt": "CIFAR-10 compares 10k training data with 10k test data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8360809354342774
      ],
      "excerpt": "Inbalanced classes : Test data is without changing, while training data create imbalances artificially : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8420086649187344
      ],
      "excerpt": "Each plot shows SWD value by index of unbalanced classes. Horizontal axis is number of inbalanced set(training A) and vertical axis is SWD. Each condition is run once. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/koshian2/swd-pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 \\xe3\\x81\\x93\\xe3\\x81\\x97\\xe3\\x81\\x82\\xe3\\x82\\x93\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Sliced Wasserstein Distance (SWD) in PyTorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "swd-pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "koshian2",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/koshian2/swd-pytorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 65,
      "date": "Fri, 24 Dec 2021 18:02:14 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "A simple example of calculating SWD on GPU.\n\n```python\nimport torch\nfrom swd import swd\n\ntorch.manual_seed(123) #: fix seed\nx1 = torch.rand(1024, 3, 128, 128)  #: 1024 images, 3 chs, 128x128 resolution\nx2 = torch.rand(1024, 3, 128, 128)\nout = swd(x1, x2, device=\"cuda\") #: Fast estimation if device=\"cuda\"\nprint(out) #: tensor(53.6950)\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
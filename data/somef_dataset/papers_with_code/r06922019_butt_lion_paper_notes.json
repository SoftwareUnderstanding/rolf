{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1707.02937",
      "https://arxiv.org/abs/1806.02658",
      "https://arxiv.org/abs/1707.02937",
      "https://arxiv.org/abs/1806.02658",
      "https://arxiv.org/abs/1707.02937",
      "https://arxiv.org/abs/1611.07004"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/r06922019/paper_notes",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-07-09T02:03:54Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-26T03:43:27Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8459575148560149,
        0.8273168224301605,
        0.9471248859710776
      ],
      "excerpt": "Make sure to try the awesome demo of the page!! Surely helps understanding. \ndeconvolutions are prone to artifacts \n    > In addition to the high frequency checkerboard-like artifacts we observed above, early deconvolutions can create lower-frequency artifacts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9165959952766094,
        0.9056425093573682,
        0.9482153741784447,
        0.8234744628977095
      ],
      "excerpt": "    > Another approach is to separate out upsampling to a higher resolution from convolution to compute features. For example, you might resize the image (using nearest-neighbor interpolation or bilinear interpolation) and then do a convolutional layer. This seems like a natural approach, and roughly similar methods have worked well in image super-resolution (eg. 9).    \nArtifacts also present in temrs of gradient &rarr; GANs also suffer \n    > We\u2019ve found that this does happen in some cases. When the generator is neither biased for or against checkerboard patterns, strided convolutions in the discriminator can cause them.    \nQuick fix is switching from deconv to NN-resize then conv, experiements show that parameters are compatible    \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9249179259371196,
        0.8001319054583211
      ],
      "excerpt": "    > The most prominent problem associated with the deconvolution layer is the presence of checkerboard artifacts in output images and dense labels as shown in Figure 1. To combat this problem, smoothness \nconstraints, post processing and different architecture designs have been proposed [6,13,24]. Odena et al. [2] highlight three sources of checkerboard artifacts: deconvolution overlap, random initialization and loss functions. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8026614741123509
      ],
      "excerpt": "1806.02658 Super-Resolution using Convolutional Neural Networks without Any Checkerboard Artifacts \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.98266577074802,
        0.8730007736914867,
        0.9830848200642828,
        0.9682937681195293,
        0.9896082114862307,
        0.9294621784094785,
        0.9825363378110012
      ],
      "excerpt": "    > On the other hand, checkerboard artifacts have been studied to design linear multirate systems including filter banks and wavelets [19\u201322]. In addition, it is well-known that checkerboard artifacts are caused by the time-variant property of interpolators in multirate systems, and the condition for avoiding these artifacts have been given [19\u201321]. However, the condition to avoid checkerboard artifacts \nfor linear systems can not be applied to CNNs due to the nonlinearity of CNNs. \nThe preparation section in the paper reviews a lot of SR techniques and overviews of checkerboard artifacts for linear systems, which seems to be way too difficult for people who is poor at signal processing...like me :( \nNot very sure about my understanding, but it seems like the checkerboard artifacts arouse from the different steady state values of channels of feature map, causing the unit step response overall has a periodic characteristic. See section 3.2 in the paper. \nDue to the non-linearity of CNN, \n    > This is a non-linear system due to the bias b.    \nIt is hard to avoid checkerboard artifacts, for the condition to avoid that is each filter has identical steady-state values. (Formulas in Section 3.3) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8045968416113651,
        0.9151341506572962
      ],
      "excerpt": "    Not really sure ... but the form of the filter H0 seems to be a box filter to me ... \n    > In this paper, we propose to add the kernel of the zero-order hold with factor U, i.e. H0 in eq.(4), after upsampling layers as shown in Fig. 6. In this structure, the output signal from H0 can be a constant value, even when an arbitrary periodic signal is inputted to H0. As a result, Fig. 6 can satisfy eq.(7). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "So many papers",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/r06922019/butt_lion_paper_notes/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 04:36:33 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/r06922019/paper_notes/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "r06922019/paper_notes",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9567171363290679
      ],
      "excerpt": "    https://github.com/pytorch/pytorch/pull/5429/files?diff=split \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/r06922019/paper_notes/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "JavaScript"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Notes",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "paper_notes",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "r06922019",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/r06922019/paper_notes/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Thu, 23 Dec 2021 04:36:33 GMT"
    },
    "technique": "GitHub API"
  }
}
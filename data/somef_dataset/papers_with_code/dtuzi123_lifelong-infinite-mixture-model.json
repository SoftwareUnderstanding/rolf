{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2108.12278\n\n# Abstract\n\nRecent research efforts in lifelong learning propose to grow a mixture or use an ensemble structure to adapt the deep model to learning a growing number of tasks. The proposed methodology shows promising results in overcoming catastrophic forgetting. However, the theory behind these successful models is still not well understood. In this paper, we perform the theoretical analysis for lifelong learning models by deriving the risk bounds based on the discrepancy distance between the probabilistic representation of data generated by the model and that corresponding to the target set. Inspired by the theoretical analysis, we introduce a new lifelong learning approach, namely the Lifelong Infinite Mixture model (LIMix"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{ye2021lifelong,\n      title={Lifelong Infinite Mixture Model Based on Knowledge-Driven Dirichlet Process}, \n      author={Fei Ye and Adrian G. Bors},\n      year={2021},\n      eprint={2108.12278},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9970763163982661
      ],
      "excerpt": "\ud83d\udccb If you use our code, please cite our paper as: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.947008780810979,
        0.9982476551833407,
        0.9664456561658856
      ],
      "excerpt": "      title={Lifelong Infinite Mixture Model Based on Knowledge-Driven Dirichlet Process},  \n      author={Fei Ye and Adrian G. Bors}, \n      year={2021}, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9490753289412834
      ],
      "excerpt": "      archivePrefix={arXiv}, \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dtuzi123/Lifelong-infinite-mixture-model",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-07T00:09:51Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-13T06:56:27Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9965682499823089
      ],
      "excerpt": "\ud83d\udccb This is the implementation of the Lifelong infinite mixture model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.998180179021961
      ],
      "excerpt": "Recent research efforts in lifelong learning propose to grow a mixture or use an ensemble structure to adapt the deep model to learning a growing number of tasks. The proposed methodology shows promising results in overcoming catastrophic forgetting. However, the theory behind these successful models is still not well understood. In this paper, we perform the theoretical analysis for lifelong learning models by deriving the risk bounds based on the discrepancy distance between the probabilistic representation of data generated by the model and that corresponding to the target set. Inspired by the theoretical analysis, we introduce a new lifelong learning approach, namely the Lifelong Infinite Mixture model (LIMix), which can automatically expand its network architectures or choose an appropriate component to adapt its parameters for learning a new task, while preserving its previously learnt information. We propose to incorporate the knowledge into the Dirichlet process by using a gating mechanism which computes the dependence between the knowledge learnt previously and stored in each component and a new set of data, benefiting the accuracy and efficiency of the selection and expansion for LIMix. Besides, we exploit to train a compact Student model which can accumulate cross-domain representations over time and make quick inferences. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9671369349270951
      ],
      "excerpt": "\ud83d\udccb We provide an easy way to train and evaluate the performance of the model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9632089022284579
      ],
      "excerpt": "\ud83d\udccb Different parameter settings of LMix would lead different results and we also provide different settings used in our experiments. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "The implementation of the lifelong infinite mixture model",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dtuzi123/lifelong-infinite-mixture-model/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Tue, 28 Dec 2021 14:25:22 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dtuzi123/Lifelong-infinite-mixture-model/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "dtuzi123/Lifelong-infinite-mixture-model",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "Python 3.6 \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8798542749121443
      ],
      "excerpt": "\ud83d\udccb Python xxx.py, the model will be automatically trained and then report the results after the training. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dtuzi123/Lifelong-infinite-mixture-model/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Lifelong infinite mixture model",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Lifelong-infinite-mixture-model",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "dtuzi123",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dtuzi123/Lifelong-infinite-mixture-model/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Tue, 28 Dec 2021 14:25:22 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1412.6980v8\u200b"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9537267708315463
      ],
      "excerpt": "che rimuove la colonna del dataset di partenza e la sostituisce con le colonne binarizzate\u2019. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9027837362477646
      ],
      "excerpt": "Per poter effettuare la fase di traning e rendere i dati di test e train identici dal punto di vista \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9101732976364455
      ],
      "excerpt": "Tramite la funzione \u200b preprocess_data \u200b presente nel source code \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9321597499656605
      ],
      "excerpt": "Tramite la funzione train_test_split ho \u200b estratto dal dataset di traning i dati di validazione, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906174419333412
      ],
      "excerpt": "Ho inoltre calcolato tramite la libreria esterna keras_metrics i valori di \u200b precision \u200b e \u200b recall \u200b per \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9559715772848645
      ],
      "excerpt": "Infatti un numero relativamente alto di record mi potrebbe consentire di apprendere tutti i \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9799411683948944,
        0.9944484218006108
      ],
      "excerpt": "La funzione di \u200b loss \u200bscelta \u00e8 la \u200b binary_crossentropy \u200b, essendo un problema binario \nL\u2019ottimizzatore scelto \u00e8 \u200b adam \u200b (\u200bhttps://arxiv.org/abs/1412.6980v8\u200b) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906174419333412,
        0.8356013927728488
      ],
      "excerpt": "circa alla \u200b 3a epoca \u200b: oltre la terza epoca la loss function della validation tende a salire e il \nmodello si ferma tramite la callback \u200b early_stop \u200b impostata su val_loss. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "codice contenenti la binarizzazione \u200b e ho potuto \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Fabrolly/DeepLearning-Experiment-on-Taiwan-Payaments-Information",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-20T20:20:00Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-02T12:32:27Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9979258305356073
      ],
      "excerpt": "history of payment, and bill statements of credit card clients in Taiwan from April 2005 to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Deep Learning experiments on Dataset about default payments of credit card clients in Taiwan from 2005",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Fabrolly/DeepLearning-Experiment-on-Taiwan-Payaments-Information/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 07:55:07 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Fabrolly/DeepLearning-Experiment-on-Taiwan-Payaments-Information/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Fabrolly/DeepLearning-Experiment-on-Taiwan-Payaments-Information",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Fabrolly/DeepLearning-Experiment-on-Taiwan-Payaments-Information/master/SourceCode.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9640629349858802
      ],
      "excerpt": "Keras_metrics (\u00e8 gi\u00e0 presente il comando pip per installarla) e Pandas. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8122736748902225
      ],
      "excerpt": "ATTENZIONE: Questo README \u00e9 una conversione automatica del file \"relazione.pdf\" che \u00e9 formattato in modo migliore e contiene immagini di esempio! Leggi quello! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.902618939087484
      ],
      "excerpt": "I Path dei due file (train.csv e test.csv) vanno modificati prima dell\u2019esecuzione: nel caso \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8659899082163807,
        0.8472764107972659,
        0.8746708654590856
      ],
      "excerpt": "\u25cf Shape del \u200b train \u200b: (27000, 24) \n\u25cf Shape del \u200b test \u200b: (3000, 23) \nStampando l\u2019header del train sembra esserci uno sbilanciamento sulla label da predire. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8733450332610028
      ],
      "excerpt": "del dataset di \u200b train \u200b. Ho quindi \u200b aggiunto manualmente \u200b le suddette colonne mancanti e ho \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8629967637875883
      ],
      "excerpt": "Per poter effettuare la fase di traning e rendere i dati di test e train identici dal punto di vista \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8978851044516092
      ],
      "excerpt": "ho standardizzato il dataset di train e il dataset di test. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8423805632841257
      ],
      "excerpt": "che ho deciso essere il 15% dei dati di train totali per non diminuire troppo quest\u2019ultimi. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9069563971593995,
        0.8379743578821011
      ],
      "excerpt": "\u25cf Train \u200b data shape: (27000, 91) \n\u25cf Test \u200b data shape: (3000, 91) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9069563971593995,
        0.843792575051017,
        0.8379743578821011
      ],
      "excerpt": "\u25cf Train data shape: (22950, 91) \n\u25cf Validation data shape: (4050, 91) \n\u25cf Test data shape: (3000, 91) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.850302460584936
      ],
      "excerpt": "L\u2019ultimo layer ha output 1 poich\u00e9 stiamo trattando un problema \u200b binario \u200b. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8102110769455417
      ],
      "excerpt": "per layer. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8152164435253624
      ],
      "excerpt": "Eseguendo il modello sul test set fornito ottengo i seguenti risultati \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "\u25cf True \u200b: 376 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Fabrolly/DeepLearning-Experiment-on-Taiwan-Payaments-Information/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Dataset of default Payments Information in Taiwan 2005",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DeepLearning-Experiment-on-Taiwan-Payaments-Information",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Fabrolly",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Fabrolly/DeepLearning-Experiment-on-Taiwan-Payaments-Information/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 07:55:07 GMT"
    },
    "technique": "GitHub API"
  }
}
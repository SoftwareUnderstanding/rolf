{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1409.1556",
      "https://arxiv.org/abs/1411.4555"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* https://arxiv.org/pdf/1609.06647.pdf\n* https://arxiv.org/abs/1411.4555\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sovit-123/Deep-Learning-Image-Captioning",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-30T07:39:23Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-30T07:54:15Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9973150842652394,
        0.9536090441459126
      ],
      "excerpt": "The project is based on automatic image captioning using Deep Learning and neural networks. \nThe Flickr8K dataset is being used for this project.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9636148231063925,
        0.9278166132590048,
        0.9362609573389792,
        0.9065663881577587
      ],
      "excerpt": "* Large enough to get started to get considerable results and approximations about the trained model. \n* Not very large like the Flickr30k or MSCOCO which require really huge amount of RAM and GPU power for getting good and reproducable results. \nThe pre-trained VGG16 model is used to extract the features from the images. \nThen the features are fed into an LSTM network for training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8046317680559756
      ],
      "excerpt": "2. Most importantly, it can help visually challenged people to know their locations easily. They can take pictures on the phone, the captions will be generated, and another machine learning model can read out those captions.(Possible future work.) \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sovit-123/Deep-Learning-Image-Captioning/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 02:38:02 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sovit-123/Deep-Learning-Image-Captioning/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "sovit-123/Deep-Learning-Image-Captioning",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/sovit-123/Deep-Learning-Image-Captioning/master/image_captioning_flickr8k.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sovit-123/Deep-Learning-Image-Captioning/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Deep-Learning-Image-Captioning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Deep-Learning-Image-Captioning",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "sovit-123",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sovit-123/Deep-Learning-Image-Captioning/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Keras\n* Matplotlib\n* VGG16\n* NLTK\n* TensorFlow \n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Fork the repository or download the jupyter notebook.\n2. Install the libraries.\n3. Make sure that you download the dataset and extract it.\n4. Run the .ipynb file\n***Make sure to run the project in a GPU enabled environment. Else the training may take hours on a CPU. If GPU is unavailable, consider using Google Colaboratory.***\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 02:38:02 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. https://www.statisticshowto.datasciencecentral.com/data-distribution/\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/voqtuyen/GAN-Intuition",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-13T15:31:47Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-24T07:06:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8090743723697469,
        0.9780346583068555
      ],
      "excerpt": "What is a distribution in statistics? \nA data distribution is a function or a listing which shows all the possible values (or intervals) of the data. It also (and this is important) tells you how often each value occurs. Often, the data in a distribution will be ordered from smallest to largest, and graphs and charts allow you to easily see both the values and the frequency with which they appear. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9910157036724688,
        0.9549196562946509
      ],
      "excerpt": "In probability theory and statistics, a probability distribution is a mathematical function that provides the probabilities of occurrence of different possible outcomes in an experiment. In more technical terms, the probability distribution is a description of a random phenomenon in terms of the probabilities of events. For instance, if the random variable X is used to denote the outcome of a coin toss (\"the experiment\"), then the probability distribution of X would take the value 0.5 for X = heads, and 0.5 for X = tails (assuming the coin is fair) \nA parametric model is a family of probability distributions that has a finite number of parameters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9512852200082269
      ],
      "excerpt": "The sample space is the complete set of all values an observation x can take \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9803877911355636
      ],
      "excerpt": "The discriminator is a binary classifier to distinguish if the input \ud835\udc65 is real (from real data) or fake (from the generator). Typically, the discriminator outputs a scalar prediction \ud835\udc5c \u2208 \u211d  for input \ud835\udc31, such as using a dense layer with hidden size 1, and then applies sigmoid function to obtain the predicted probability \ud835\udc37(\ud835\udc31) = 1 / (1+\ud835\udc52\u2212\ud835\udc5c) . Assume the label \ud835\udc66 for true data is 1 and 0 for fake data. We train the discriminator to minimize the cross entropy loss \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9819665223575792
      ],
      "excerpt": "For the generator, it first draws some parameter \ud835\udc33 \u2208 \u211d\ud835\udc51 from a source of randomness, e.g. a normal distribution \ud835\udc33\u223c(0,1). We often call \ud835\udc33 the latent variable. It then applies a function to generate \ud835\udc31\u2032 = \ud835\udc3a(\ud835\udc33). The goal of the generator is to fool the discriminator to classify \ud835\udc31\u2032 as true data. In other words, we update the parameters of the generator to maximize the cross entropy loss when \ud835\udc66 = 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8875800954646542
      ],
      "excerpt": "As shown in the graph, maximizing -log(1\u2212\ud835\udc37(\ud835\udc31\u2032)) is equivalent to minimizing log(1\u2212\ud835\udc37(\ud835\udc31\u2032)). And minimizing log(1\u2212\ud835\udc37(\ud835\udc31\u2032)) is equivalent to maximizing log(\ud835\udc37(\ud835\udc31\u2032)). So commonly we minimize the following loss \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8957147418970655
      ],
      "excerpt": "which is just feed  \ud835\udc31\u2032  into the discriminator but giving label  \ud835\udc66=1 \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/voqtuyen/GAN-Intuition/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 21:46:49 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/voqtuyen/GAN-Intuition/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "voqtuyen/GAN-Intuition",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8454585943879249
      ],
      "excerpt": "Gradient accumulation: https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/voqtuyen/GAN-Intuition/issues{/number}",
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Basic understanding",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "GAN-Intuition",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "voqtuyen",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/voqtuyen/GAN-Intuition/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Tue, 28 Dec 2021 21:46:49 GMT"
    },
    "technique": "GitHub API"
  }
}
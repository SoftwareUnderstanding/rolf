{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1910.03151 with fastglobalavgpool from https://arxiv.org/pdf/2003.13630.pdf\n - [x] Weight standartization from https://arxiv.org/abs/1903.10520 (Do not suggest to use with pretrained, could lead to an input explosion, used with track_running_stats, otherwise explosion",
      "https://arxiv.org/abs/1903.10520 (Do not suggest to use with pretrained, could lead to an input explosion, used with track_running_stats, otherwise explosion",
      "https://arxiv.org/abs/2007.12099\n - [x] NMS in Depth implementation  (not connected",
      "https://arxiv.org/abs/2007.12099 (not connected",
      "https://arxiv.org/abs/2007.12099\n - [x] Coord convolutions from https://arxiv.org/abs/2007.12099\n - [x] Self adversial training with vanila grad\n - [x] Hard mish\n - [ ] Easy mAP for your DL\n - [x] ASFF from https://arxiv.org/abs/1911.09516\n - [x] RAdam optimizer from https://arxiv.org/abs/1908.03265\n - [x] Ranger optimizer (RAdam + LookAhead",
      "https://arxiv.org/abs/2007.12099\n - [x] Self adversial training with vanila grad\n - [x] Hard mish\n - [ ] Easy mAP for your DL\n - [x] ASFF from https://arxiv.org/abs/1911.09516\n - [x] RAdam optimizer from https://arxiv.org/abs/1908.03265\n - [x] Ranger optimizer (RAdam + LookAhead",
      "https://arxiv.org/abs/1911.09516\n - [x] RAdam optimizer from https://arxiv.org/abs/1908.03265\n - [x] Ranger optimizer (RAdam + LookAhead",
      "https://arxiv.org/abs/1908.03265\n - [x] Ranger optimizer (RAdam + LookAhead",
      "https://arxiv.org/abs/1711.07752v2\n - [ ] Soft IoU Loss from https://arxiv.org/abs/1904.00853v3\n    - [x] Learning IoU (as in IoU, just use IoU aware",
      "https://arxiv.org/abs/1904.00853v3\n    - [x] Learning IoU (as in IoU, just use IoU aware",
      "https://arxiv.org/abs/1812.05262\n - [x] BN microbatching\n - [x] BCN from https://arxiv.org/pdf/1903.10520.pdf\n - [ ] AdamP from https://arxiv.org/abs/2006.08217v1\n - [x] Channel-wise feature fusion by me",
      "https://arxiv.org/abs/2006.08217v1\n - [x] Channel-wise feature fusion by me",
      "https://arxiv.org/abs/2004.10934\\\nOriginal repo: https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects\n```\n@article{yolov4,\n  title={YOLOv4: YOLOv4: Optimal Speed and Accuracy of Object Detection},\n  author={Alexey Bochkovskiy, Chien-Yao Wang, Hong-Yuan Mark Liao},\n  journal = {arXiv},\n  year={2020}\n}\n```"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "In case if you missed:\\\nPaper Yolo v4: https://arxiv.org/abs/2004.10934\\\nOriginal repo: https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects\n```\n@article{yolov4,\n  title={YOLOv4: YOLOv4: Optimal Speed and Accuracy of Object Detection},\n  author={Alexey Bochkovskiy, Chien-Yao Wang, Hong-Yuan Mark Liao},\n  journal = {arXiv},\n  year={2020}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{yolov4,\n  title={YOLOv4: YOLOv4: Optimal Speed and Accuracy of Object Detection},\n  author={Alexey Bochkovskiy, Chien-Yao Wang, Hong-Yuan Mark Liao},\n  journal = {arXiv},\n  year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9963917985789968
      ],
      "excerpt": "[x] ECA attention block from https://arxiv.org/abs/1910.03151 with fastglobalavgpool from https://arxiv.org/pdf/2003.13630.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9945233369203008
      ],
      "excerpt": "[x] IoU Aware from https://arxiv.org/abs/2007.12099 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9583530309190973,
        0.9918074393277366,
        0.9918074393277366
      ],
      "excerpt": "[x] Matrix NMS algorithm from https://arxiv.org/abs/2007.12099 (not connected) \n[ ] Deformable convolutions from https://arxiv.org/abs/2007.12099 \n[x] Coord convolutions from https://arxiv.org/abs/2007.12099 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9869405348645832,
        0.9869405348645832
      ],
      "excerpt": "[x] ASFF from https://arxiv.org/abs/1911.09516 \n[x] RAdam optimizer from https://arxiv.org/abs/1908.03265 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9869405348645832,
        0.9869405348645832
      ],
      "excerpt": "[x] Repulsion Loss from https://arxiv.org/abs/1711.07752v2 \n[ ] Soft IoU Loss from https://arxiv.org/abs/1904.00853v3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9869405348645832
      ],
      "excerpt": "[ ] Elastic from https://arxiv.org/abs/1812.05262 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9869405348645832,
        0.9869405348645832
      ],
      "excerpt": "[x] BCN from https://arxiv.org/pdf/1903.10520.pdf \n[ ] AdamP from https://arxiv.org/abs/2006.08217v1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8478629327024715
      ],
      "excerpt": "If you set train=True -> HSV augmentations and mosaic \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/VCasecnikovs/Yet-Another-YOLOv4-Pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-05-24T10:29:10Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-15T12:19:06Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.992802736819897,
        0.860059181823877
      ],
      "excerpt": "This is implementation of YOLOv4 object detection neural network on pytorch. I'll try to implement all features of original paper. \n[x] Model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "[x] Letterbox for validation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9069235145752237
      ],
      "excerpt": "[x] Notebook with guide \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8417612801308588
      ],
      "excerpt": "[ ] Easy mAP for your DL \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8835326890013954
      ],
      "excerpt": "You can train your own model with mosaic augmentation for training. Guides how to do this are written below. Borders of images on some datasets are even hard to find. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9742634959275516
      ],
      "excerpt": "Is a tensor of size (B, 6), where B is amount of boxes in all batch images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8673904585542278,
        0.9891785691729262
      ],
      "excerpt": "!!! y_hat is already resized anchors to image size bboxes \ny_hat,  _ = m(img_batch) #_ is (0, 0, 0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "YOLOv4 Pytorch implementation with all freebies and specials and 15+ more exclusive improvements. Easy to use!",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can use torch hub\nor you can download weights using from this link: https://drive.google.com/open?id=12AaR4fvIQPZ468vhm0ZYZSLgWac2HBnq\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/VCasecnikovs/Yet-Another-YOLOv4-Pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 19,
      "date": "Tue, 28 Dec 2021 07:54:59 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/VCasecnikovs/Yet-Another-YOLOv4-Pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "VCasecnikovs/Yet-Another-YOLOv4-Pytorch",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/VCasecnikovs/Yet-Another-YOLOv4-Pytorch/master/Training%20YOLOv4%20.ipynb",
      "https://raw.githubusercontent.com/VCasecnikovs/Yet-Another-YOLOv4-Pytorch/master/SplitDataset.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9943373861552001
      ],
      "excerpt": "!!! For the jupyter notebook please install pytorch-lightning version 0.7.6 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9322609392449874
      ],
      "excerpt": "[x] Pytorch lightning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8882022946481789
      ],
      "excerpt": "[ ] EM-Merger (TODO: use https://github.com/eg4000/SKU110K_CVPR19 to do postprocessing util) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8253524597837022
      ],
      "excerpt": "You can make inference, guide bellow. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8057675898656085
      ],
      "excerpt": "path, img, bboxes = d[0] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8057675898656085
      ],
      "excerpt": "path, img, bboxes = d[0] \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8027601783300778
      ],
      "excerpt": "[x] MOSAIC for train \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9115085605547046
      ],
      "excerpt": "import model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8072054423831488,
        0.8254387897580059,
        0.8966489006879416,
        0.909289576587693,
        0.9416717498362354
      ],
      "excerpt": "m = model.YOLOv4(n_classes=1, weights_path=\"weights/yolov4.pth\") \n#AUTOMATICALLY DOWNLOAD PRETRAINED \nm = model.YOLOv4(n_classes=1, pretrained=True) \nimport dataset \nd = dataset.ListDataset(\"train.txt\", img_dir='images', labels_dir='labels', img_extensions=['.JPG'], train=True) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.842557403963851,
        0.827724075157898,
        0.8211289888096527
      ],
      "excerpt": "\"train.txt\" is file which consists with filepaths to image (images\\primula\\DSC02542.JPG) \nimg_dir - Folder with images \nlabels_dir - Folder with txt files for annotation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9535879515266492,
        0.8044146895679722
      ],
      "excerpt": "import utils \nfrom PIL import Image \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8722292510489007
      ],
      "excerpt": "img_with_bboxes = utils.get_img_with_bboxes(img, bboxes[:, 2:]) #Returns numpy array \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/VCasecnikovs/Yet-Another-YOLOv4-Pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 VCasecnikovs\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Yet-Another-YOLOv4-Pytorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Yet-Another-YOLOv4-Pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "VCasecnikovs",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/VCasecnikovs/Yet-Another-YOLOv4-Pytorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "VCasecnikovs",
        "body": "",
        "dateCreated": "2020-05-30T15:15:53Z",
        "datePublished": "2020-05-31T15:02:09Z",
        "html_url": "https://github.com/VCasecnikovs/Yet-Another-YOLOv4-Pytorch/releases/tag/V1.0",
        "name": "",
        "tag_name": "V1.0",
        "tarball_url": "https://api.github.com/repos/VCasecnikovs/Yet-Another-YOLOv4-Pytorch/tarball/V1.0",
        "url": "https://api.github.com/repos/VCasecnikovs/Yet-Another-YOLOv4-Pytorch/releases/27075275",
        "zipball_url": "https://api.github.com/repos/VCasecnikovs/Yet-Another-YOLOv4-Pytorch/zipball/V1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 117,
      "date": "Tue, 28 Dec 2021 07:54:59 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "yolov4-pytorch",
      "eca",
      "loss",
      "mosaic"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    y1 = d[0]\n    y2 = d[1]\n    paths_b, xb, yb = d.collate_fn((y1, y2))\n\t",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "    anchors, loss = m(xb.cuda(), yb.cuda())\n    confidence_threshold = 0.05\n    iou_threshold = 0.5\n    bboxes, labels = utils.get_bboxes_from_anchors(anchors, confidence_threshold, iou_threshold, coco_dict) #COCO dict is id->class dictionary (f.e. 0->person)\n    #For first img\n    arr = utils.get_img_with_bboxes(xb[0].cpu(), bboxes[0].cpu(), resize=False, labels=labels[0])\n    Image.fromarray(arr)\n\n",
      "technique": "Header extraction"
    }
  ]
}
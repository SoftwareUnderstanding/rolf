{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1301.3781\n\n15.\tQuoc Le and Tomas Mikolov. Distributed Representations of Sentences and Documents. http://arxiv.org/pdf/1405.4053v2.pdf\n\n16.\tSepp Hochreiter; J\u00fcrgen Schmidhuber (1997",
      "https://arxiv.org/abs/1409.0473"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1.\tIain J. Marshall, Anna Noel-Storr, Jo\u00ebl Kuiper, James Thomas,  Byron C. Wallace, (2017) Machine learning for identifying Randomized Controlled Trials: An evaluation and practitioner's guide. https://onlinelibrary.wiley.com/doi/full/10.1002/jrsm.1287\n\n2.\tFranck Dernoncourt, Frank, Lee Ji Young (2017),  PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts. Retrieved from https://arxiv.org/pdf/1710.06071.pdf\n\n3.\tEfsun Sarioglu, Kabir Yadav, Topic Modeling Based Classification of Clinical Reports, http://www.aclweb.org/anthology/P13-3010\n\n4.\tTing, S. L., Ip, W. H., Tsang, A. H. (2011). Is Naive Bayes a good classifier for document classification, https://www.researchgate.net/publication/266463703_Is_Naive_Bayes_a_Good_Classifier_for_Document_Classification\n\n5.\tSida Wang and Christopher D. Manning, Baselines and Bigrams: Simple, Good Sentiment and Topic Classification,  https://www.aclweb.org/anthology/P12-2018\n\n6.\tMengen Chen, Xiaoming Jin, Short Text Classification Improved by Learning Multi-Granularity Topics, http://www.ijcai.org/Proceedings/11/Papers/298.pdf\n\n7.\tKunlun Li, Jing Xie, Multi-class text categorization based on LDA and SVM, https://www.sciencedirect.com/science/article/pii/S1877705811018674\n\n8.\tQiuxing Chen, Lixiu Yao, 2016, Short text classification based on LDA topic model, https://ieeexplore.ieee.org/document/7846525/\n\n9.\tEugene Nho, Andrew Ng., Paragraph Topic Classification \n\n10.\thttp://cs229.stanford.edu/proj2016/report/NhoNg-ParagraphTopicClassification-report.pdf\n\n11.\tAndrew Ng. Sequence Models, https://www.coursera.org/learn/nlp-sequence-models\n\n12.\t Sp\u00e4rck Jones, K. (1972). \"A Statistical Interpretation of Term Specificity and Its Application in Retrieval\". Journal of Documentation. 28: 11\u201321. doi:10.1108/eb026526.\n\n13.\tLuhn, Hans Peter (1957). \"A Statistical Approach to Mechanized Encoding and Searching of Literary Information\" (PDF). IBM Journal of research and development. IBM. 1 (4): 315. doi:10.1147/rd.14.0309.\n\n14.\tMikolov, Tomas; et al. \"Efficient Estimation of Word Representations in Vector Space\". https://arxiv.org/abs/1301.3781\n\n15.\tQuoc Le and Tomas Mikolov. Distributed Representations of Sentences and Documents. http://arxiv.org/pdf/1405.4053v2.pdf\n\n16.\tSepp Hochreiter; J\u00fcrgen Schmidhuber (1997). \"Long short-term memory\". Neural Computation. 9 (8): 1735\u20131780. doi:10.1162/neco.1997.9.8.1735. PMID 9377276.\n\n17.\tDzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, Neural Machine Translation by Jointly Learning to Align and Translate, https://arxiv.org/abs/1409.0473\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DCYN/Ramdomized-Clinical-Trail-Classification",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-04-15T04:00:32Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-07-30T23:23:12Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9961826120490189,
        0.9956755960199701,
        0.9983353270802647,
        0.9704258040744169,
        0.9852254396533879,
        0.9899004392336449,
        0.9722277138893253
      ],
      "excerpt": "This is the RCT classification part of our Capstone Project at Harvard 599 course. I am the major contributor of this part, from literature review, data preparation, designing models, coding, training model, to tuning models. \nRandomized clinical trials (RCTs) are imperative to the progress of medical research, with thousands being published on an annual basis. Currently, the number of published RCTs is over one million, and half of those RCTs are found in PubMed, a freely accessible search engine primarily accessing the MEDLINE database of biomedical literature. While these RCTs are freely available to the public, there is currently no straightforward way to identify RCTs amongst the multitude of article types in the database. Identifying RCTs efficiently presents itself as an ongoing challenge for medical researchers. \nIn this project, various deep learning models are tested to identify and classify RCTs. Unlike other related work which use the abstract portions of the papers only, our work is based on experiments using both the full text documents and their abstracts. The selected deep learning model combines a long short-term memory (LSTM ) model and one-dimension convolution together to process the vectors generated from Doc2Vec. This model can classify articles with a relatively high accuracy and low computational requirement.  \nThe majority deelp learning models are developed on MXNET, Keras, and Tensorflow. Transfer learning is also used to compare results. \nPrevious work on RCT classification were based on the abstracts [Marshal et al. 2017] of RCT and other medical documents. This approach has two limitations. First, not all the articles have abstract in the PMC database. Second, medical researchers usually are more interested to have a tool to separate RCTs from other clinical trials. This work is more challenging.  \nBelow figure illustrates the difference between our work and other works. It is a two-dimension projection of the TFIDF of 300 articles randomly selected from PMC, which contain 100 RCT, 100 non-randomized clinical trials, and 100 other medical documents. The yellow circles represent RCTs; the blue rectangles represent nonRCTs; the red triangles represent other medical documents. Even an unsupervised machine learning model can separate the RCTs from other documents well; however, to separate the highly overlapping RCTs and nonRCTs is more challenging. \nThe entire process of developing an RCT classification tool can be separated into four distinct steps: prepare the dataset and extract data, tokenize of sentences, vectorize of tokens, and finally classification. These parts are illustrated as below: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9348157465764797,
        0.969617720500829,
        0.9910353230766149,
        0.875262383839426,
        0.8796898830704966,
        0.9657847682979709,
        0.8432027654684635,
        0.9951532493514924,
        0.9780643138857069,
        0.9752934373422698,
        0.8619097367225877,
        0.9758321666820573,
        0.9855686687401951,
        0.9290396796919755
      ],
      "excerpt": "SVM, SVM+DNN, SVM+CNN, 1dCNN, 1dCNN+ LSTM are tested as classifiers. Below are a few samples of the classifiers. \nTFIDF-Na\u00efve Bayes outperform the other models on abstracts only data. \nNa\u00efve Bayes model performs better on abstracts only data. It yields a F1-score of 81%. This combination also yields the best results when only using the abstract portions of the articles. The results validate the findings of Wang [Wang, Sida, 2012] that Naive Bayes can yield better results on snippets. \nThe vectorization for all the other classifiers are Doc2Vec with following hyper-parameters: size = 1024, Window = 3, Iter = 30, Min Count =2. \nDoc2Vec + Inception batch normalization outperforms the other models for the dataset excluding the nonRCT provided by PubMiner. SMOTE is used to do unbalanced sampling. \nDoc2Vec can generate the vectors to fed the SVM and the deep learning models we tested. If we only use the labeled data gotten from clinicaltrails.gov,  the whole dataset contains 10,216 full text articles, 1,627 Non-RCTs and 8,589 RCTs. Since the dataset is highly unbalanced, the models other than the LSTM tends to give all positive prediction if unbalanced sampling is not used.  \nWe can use SMOTE to solve the all positive prediction issue, but the results indicate overfitting. \nIn order to compare our research with others\u2019 work. We apply the CNN model [Marshal et al. 2017] on our data set. The pre-trained vectors generated from Word2Vec For Word2Vec, a pre-trained RCT sentence vectors [Dernoncourt, Franck, 2017]  is used, and the sequence is set to 1000. This model did not outperform the model using Doc2Vec vectors in the experiments. One potential explanation may be that this vector was trained using sentences from the abstract portions of the articles only. Another possible reason is that semantics is important for a classifier to evaluate the possibility of a document to be RCT, while Doc2Vec processes semantics better than Word2Vec [Mikolov, Tomas 2014].   \nThe 1-D convolutional layer is important with the long word sequences used. This was in order to reduce the dimensions of the vectors to use in an LSTM model and therefore to maintain performance while reducing both training time and resource needs. \nWe also feed a 1dCNN model and the 1dCNN + LSTM model with the pre-trained vectors generated by word2vec. Both model outperform the CNN model by Ian Marshall. \nSmaller vector size with better optimized hyper-parameters for Doc2Vec. \nAlthough Doc2Vec can help to get better performance, it\u2019s still time consuming to generate the vectors with big size. During the experiments, we find that, instead of increasing the vector size, adjusting other hyperparameters such as window, min_count, and epoch can yield good results with fewer time a memory resource consumption. \nA vector size of 256 can generate the favorable results as long as other parameters are set appropriately. Setting a min_window of 1 can help the Doc2Vec vectors capture information more sensitively while increasing the window of context length to 21 helps to preserve more syntax information. The epochs were set to 50 in the final solution. \nDetailed configuration of models can be found in the subfolders. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Applying deeplearning + svm classifier to get randomized clinical trails",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DCYN/Ramdomized-Clinical-Trail-Classification/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 20:41:29 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/DCYN/Ramdomized-Clinical-Trail-Classification/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "DCYN/Ramdomized-Clinical-Trail-Classification",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V1_More_Non_RCT/RCT_Classification-w_LSTM.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V1_More_Non_RCT/RCT_Vectorization.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V1_More_Non_RCT/RCT_Classification-w_Confusion-No_over_sampling.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V1_More_Non_RCT/RCT_Creating_Dataset_Including_Other_NonRCT.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V1_More_Non_RCT/RCT_Classification-w_LSTM-with_metrics.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V10_RCT_Vector/PMC_Vectorization_LSTM-Small.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V10_RCT_Vector/PMC_Vectorization_1d_CNN.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V10_RCT_Vector/PMC_Vectorization_LSTM.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V10_RCT_Vector/PMC_Vectorization_LSTM-w_metrics_100_vectors.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V10_RCT_Vector/PMC_Vectorization_LSTM-Mid-w-metrics.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V10_RCT_Vector/PMC_Vectorization_cnn_ROBOT.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V10_RCT_Vector/PMC_Vectorization_LSTM-w_metrics.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V10_RCT_Vector/PMC_Vectorization_LSTM-Mid.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V10_RCT_Vector/PMC_Vectorization_LSTM-Small-w-metrics.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V10_RCT_Vector/PMC_Vectorization_1d_CNN-With%20Metrics.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V10_RCT_Vector/.ipynb_checkpoints/PMC_Vectorization_LSTM-checkpoint.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V10_RCT_Vector/.ipynb_checkpoints/PMC_Vectorization_1d_CNN-checkpoint.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V10_RCT_Vector/.ipynb_checkpoints/PMC_Vectorization_LSTM-Small-checkpoint.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V7_Transfer_Learning/RCT_Classification_transfer_learning.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V5_new_vectors/RCT_Classification-w_LSTM.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V5_new_vectors/RCT_Classification_new_vectors.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V5_new_vectors/RCT_Vectorization.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V5_new_vectors/RCT_Classification-w_LSTM-with_metrics.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V6_Bigger_Vectors/RCT_Classification-w_LSTM.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V6_Bigger_Vectors/RCT_Classification-w_Confusion-No_over_sampling.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V6_Bigger_Vectors/RCT_Classification-w_LSTM-with_metrics.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V6_Bigger_Vectors/RCT_Vectorization_bigger.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V6_Bigger_Vectors/.ipynb_checkpoints/RCT_Classification-w_Confusion-No_over_sampling-checkpoint.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V8_Smaller_Vectors/RCT_Classification-w_LSTM.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V8_Smaller_Vectors/RCT_Classification-w_Confusion-No_over_sampling.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V8_Smaller_Vectors/RCT_Vectorization_smaller.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V8_Smaller_Vectors/RCT_Classification-w_LSTM-with_metrics.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V3_NB/NB_Classification.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V3_NB/.ipynb_checkpoints/NB_Classification_on_vectors-checkpoint.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V3_NB/.ipynb_checkpoints/NB_Classification-checkpoint.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V0_Baseline/RCT_Classification-w_LSTM.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V0_Baseline/RCT_Classification-w_Confusion.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V0_Baseline/RCT_Classification-w_LSTM-no-SMOTE-Metrics.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V0_Baseline/RCT_Classification-w_Confusion-Over_Sampling.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V0_Baseline/RCT_Classification-w_LSTM-SMOTE-Metrics.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V0_Baseline/RCT_Classification.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V2_Abstract_only/RCT_Vec_Abstracts.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V2_Abstract_only/RCT_Classification-w_LSTM.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V2_Abstract_only/RCT_Classification-w_Confusion-No_over_sampling.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V2_Abstract_only/RCT_Classification-w_LSTM-with_metrics.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V2_Abstract_only/.ipynb_checkpoints/RCT_Classification-w_LSTM-checkpoint.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V2_Abstract_only/.ipynb_checkpoints/RCT_Classification-w_Confusion-No_over_sampling-checkpoint.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V4_NB_Abstract/NB_Classification_Abstract.ipynb",
      "https://raw.githubusercontent.com/DCYN/Ramdomized-Clinical-Trail-Classification/master/V4_NB_Abstract/.ipynb_checkpoints/NB_Classification_Abstract-checkpoint.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Doc2Vec + 1dCNN + LSTM outperforms the other models for the dataset including the nonRCT provided by PubMiner. \n\nAlthough training a model using unbalanced sampling results in higher F1 score, further verification using real world data is desirable. After incorporating the nonRCTs provided by PubMiner, we get below results.\n\n![alt text](https://github.com/DCYN/Ramdomized-Clinical-Trail-Classification/blob/master/w_pubminer.png)\n\n",
      "technique": "Header extraction"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/DCYN/Ramdomized-Clinical-Trail-Classification/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Roff"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Ramdomized-Clinical-Trail-Classification",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Ramdomized-Clinical-Trail-Classification",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "DCYN",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/DCYN/Ramdomized-Clinical-Trail-Classification/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 20:41:29 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1710.03957",
      "https://arxiv.org/abs/1706.03762",
      "https://arxiv.org/abs/1710.03957",
      "https://arxiv.org/abs/1706.03762"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{Csaky:2019,\n    title = \"Improving Neural Conversational Models with Entropy-Based Data Filtering\",\n    author = \"Cs{\\'a}ky, Rich{\\'a}rd and Purgai, Patrik and Recski, G{\\'a}bor\",\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P19-1567\",\n    pages = \"5650--5669\",\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ricsinaruto/NeuralChatbots-DataFiltering",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-20T14:03:59Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-13T10:03:33Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9801798290644322,
        0.9154260954403062
      ],
      "excerpt": "A lightweight repo for filtering dialog data with entropy-based methods.   \nThe program reads the dataset, runs clustering if needed, computes the entropy of individual utterances, and then removes high entropy utterances based on the threshold, and saves the filtered dataset to the output directory. See the paper or the poster for more details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8463761595418957,
        0.996385756867846
      ],
      "excerpt": "  :movie_camera: &nbsp; Visualize clustering and filtering results \nidentity: In this method there is basically no clustering, the entropy of utterances is calculated based on the conditional probability of utterance pairs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8501893522728482,
        0.9347077622477643,
        0.9061232910674513,
        0.9907703379531689
      ],
      "excerpt": "source: Filters utterance pairs in which the source utterance's entropy is above the threshold. \ntarget: Filters utterance pairs in which the target utterance's entropy is above the threshold. \nboth: Filters utterance pairs in which either the source or target utterance's entropy is above the threshold. \nIn this jupyter notebook you can easily try out the identity filtering method implemented in less than 40 lines, and it filters DailyDialog in a couple of seconds (you only need to provide a sources and targets file). In the second part of the notebook there are some cool visualizations for entropy, frequency and sentence length. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8675823613369219
      ],
      "excerpt": "Visualize clustering and filtering results by running the visualization jupyter notebook. The notebook is pretty self-explanatory, you just have to provide the directory containing the clustering files. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9813423228438732
      ],
      "excerpt": "For an explanation of the metrics please check this repo or the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8687348810501733,
        0.9813423228438732
      ],
      "excerpt": "More examples can be found in the appendix of the paper. \nFor an explanation of the metrics please check this repo or the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8440124550850749,
        0.9714886641205319
      ],
      "excerpt": "New clustering methods can be added, by subclassing the FilterProblem class, check Identity for a minimal example. Normally you only have to redefine the clustering function, which does the clustering of sentences.   \nLoading and saving data is taken care of, and you should use the Cluster and DataPoint objects. Use the data_point list to get the sentences for your clustering algorithm, and use the clusters list to save the results of your clustering. These can also be subclassed if you want to add extra data to your DataPoint and Cluster objects (like a vector).   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Filter dialog data with a simple entropy-based method (see ACL paper)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ricsinaruto/NeuralChatbots-DataFiltering/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Tue, 28 Dec 2021 20:25:08 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ricsinaruto/NeuralChatbots-DataFiltering/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ricsinaruto/NeuralChatbots-DataFiltering",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/ricsinaruto/NeuralChatbots-DataFiltering/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ricsinaruto/NeuralChatbots-DataFiltering/master/code/utils/visualization.ipynb",
      "https://raw.githubusercontent.com/ricsinaruto/NeuralChatbots-DataFiltering/master/code/utils/filtering_demo.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Run setup.py which installs required packages and steps you through downloading additional data:\n```\npython setup.py\n```\nYou can download all trained models used in [this](https://www.aclweb.org/anthology/P19-1567) paper from [here](https://mega.nz/#!mI0iDCTI!qhKoBiQRY3rLg3K6nxAmd4ZMNEX4utFRvSby_0q2dwU). Each training contains two checkpoints, one for the validation loss minimum and another after 150 epochs. The data and the trainings folder structure match each other exactly.\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8140922540813307
      ],
      "excerpt": "Richard Csaky (If you need any help with running the code: ricsinaruto@hotmail.com) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8329705001470745
      ],
      "excerpt": "Finally add your class to the dictionary in main, and to the command-line argument choices. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ricsinaruto/NeuralChatbots-DataFiltering/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Richard Krisztian Csaky\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "NeuralChatbots-DataFiltering &middot;",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "NeuralChatbots-DataFiltering",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ricsinaruto",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ricsinaruto/NeuralChatbots-DataFiltering/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 13,
      "date": "Tue, 28 Dec 2021 20:25:08 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "dialog",
      "chatbot",
      "filtering",
      "neural-networks",
      "entropy",
      "conversation",
      "clustering"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The main file can be called from anywhere, but when specifying paths to directories you should give them from the root of the repository.\n```\npython code/main.py -h\n```\n<a><img src=\"https://github.com/ricsinaruto/NeuralChatbots-DataFiltering/blob/master/docs/help.png\" align=\"top\" height=\"800\" ></a>    \nFor the complete **documentation** visit the [wiki](https://github.com/ricsinaruto/NeuralChatbots-DataFiltering/wiki).\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2109.04901",
      "https://arxiv.org/abs/2008.09249"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bibtex\n@inproceedings{huang-etal-2021-tempgen,\n    title = \"Document-level Entity-based Extraction as Template Generation\",\n    author = \"Huang, Kung-Hsiang  and\n      Tang, Sam  and\n      Peng, Nanyun\",\n    booktitle = \"The 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{huang-etal-2021-tempgen,\n    title = \"Document-level Entity-based Extraction as Template Generation\",\n    author = \"Huang, Kung-Hsiang  and\n      Tang, Sam  and\n      Peng, Nanyun\",\n    booktitle = \"The 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    year = \"2021\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/PlusLabNLP/TempGen",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-03T19:31:46Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-27T05:38:58Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8913966600833269
      ],
      "excerpt": "All data lies in directory ./data. The processed REE output can be found at data/muc34/proc_output/. Files name with patterns ree_*.json refers to the train, dev, and test set data for role-filler entity extraction in our in-house representation. These files are converted from grit_*.json, which are the train, dev, and test copied from GRIT's repo. The conversion script is convert_grit.py. An example of converting GRIT data into our in-house format is: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9706858003190819,
        0.9441859959620851
      ],
      "excerpt": "As for SciREX, we downloaded the original dataset data/scirex/release_data.tar.gz from the original SciREX repo. The extracted train, dev, and test files are located in data/scirex/release_data. These original data are transformed into our internal representations using raw_scripts/process_scirex.sh and stored in data/scirex/proc_output. The binary RE data does not have any post-fix, while the 4-ary RE data are post-fixxed with _4ary. \nWe adpated some of the pre-processing code from Du et al. 2021. To produce our training data, you need to navigate to raw_script and extract documents by running \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9805180799656524,
        0.8389440189650368
      ],
      "excerpt": "Please refer to the raw_script/READMD.md for more details about the data format. \nOur formulation of document-level IE as template generation tasks allows the same model architecture applicable for role-filler entity extraction, binary relation extraction, and 4-ary relation extraction. Therefore, the same script train.py can be used for training models for all three tasks. The only difference in training models each task task is the config file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8273063585480942
      ],
      "excerpt": "The evaluation scripts for MUC-4 REE and SciREX RE are ree_eval.py and scirex_eval.py, which are copied over from the GRIT repo and the SciREX repo. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code for Document-level Entity-based Extraction as Template Generation (EMNLP 2021)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/PlusLabNLP/TempGen/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Thu, 23 Dec 2021 03:06:46 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/PlusLabNLP/TempGen/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "PlusLabNLP/TempGen",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/PlusLabNLP/TempGen/master/raw_scripts/process_all_keys.sh",
      "https://raw.githubusercontent.com/PlusLabNLP/TempGen/master/raw_scripts/process_scirex.sh",
      "https://raw.githubusercontent.com/PlusLabNLP/TempGen/master/raw_scripts/go_proc_doc.sh",
      "https://raw.githubusercontent.com/PlusLabNLP/TempGen/master/raw_scripts/go_proc_keys.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9465718491881494
      ],
      "excerpt": "bash go_proc_doc.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9465718491881494
      ],
      "excerpt": "bash process_all_keys.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8126900234250098
      ],
      "excerpt": "passing --gpu -1 can run evaluation on CPUs. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8826004696428329,
        0.9345469112864984
      ],
      "excerpt": "All data lies in directory ./data. The processed REE output can be found at data/muc34/proc_output/. Files name with patterns ree_*.json refers to the train, dev, and test set data for role-filler entity extraction in our in-house representation. These files are converted from grit_*.json, which are the train, dev, and test copied from GRIT's repo. The conversion script is convert_grit.py. An example of converting GRIT data into our in-house format is: \npython convert_grit.py --input_path data/muc34/proc_output/grit_train.json --output_path data/muc34/proc_output/ree_train.json \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9442880486633762
      ],
      "excerpt": "python train.py -c config/ree_generative_model.json \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9442880486633762
      ],
      "excerpt": "python train.py -c config/bre_generative_model.json \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9442880486633762
      ],
      "excerpt": "python train.py -c config/4re_generative_model.json \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8468848227104723,
        0.8585834053030608
      ],
      "excerpt": "To run evaluation on trained models, execute the evaluate.py script as follows: \npython evaluate.py --gpu 0 --checkpoint $PATH_TO_MODEL/best.mdl \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/PlusLabNLP/TempGen/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Kung-hsiang, Huang (Steeve)\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "TempGen",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "TempGen",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "PlusLabNLP",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/PlusLabNLP/TempGen/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "All the required packages are listed in `requirements.txt`. To install all the dependencies, run\n\n```\nconda create -n tg python=3.7\nconda activate tg\npip install -r requirements.txt\n```\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 11,
      "date": "Thu, 23 Dec 2021 03:06:46 GMT"
    },
    "technique": "GitHub API"
  }
}
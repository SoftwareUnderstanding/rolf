{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/titu1994/DenseNet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-11-08T11:53:02Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T02:51:06Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9227065302788499,
        0.9620666144760108,
        0.8785567298285468,
        0.968758898517301,
        0.8947875449131754,
        0.8624097246069952,
        0.9165220331876247,
        0.9405963622911844,
        0.8359778624388774
      ],
      "excerpt": "DenseNet implementation of the paper Densely Connected Convolutional Networks in Keras \nNow supports the more efficient DenseNet-BC (DenseNet-Bottleneck-Compressed) networks. Using the DenseNet-BC-190-40 model,  \nit obtaines state of the art performance on CIFAR-10 and CIFAR-100 \nDenseNet is an extention to Wide Residual Networks. According to the paper: <br> \nThe lth layer has l inputs, consisting of the feature maps of all preceding convolutional blocks.  \nIts own feature maps are passed on to all L \u2212 l subsequent layers. This introduces L(L+1) / 2 connections  \nin an L-layer network, instead of just L, as in traditional feed-forward architectures.  \nBecause of its dense connectivity pattern, we refer to our approach as Dense Convolutional Network (DenseNet). \nIt features several improvements such as : \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8797044879465132,
        0.8852986183077867,
        0.9118308657976707,
        0.8976620238369282
      ],
      "excerpt": "Growth Rate parameter Which dictates how fast the number of features increase as the network becomes deeper. \nConsecutive functions : BatchNorm - Relu - Conv which is from the Wide ResNet paper and improvement from the ResNet paper. \nThe Bottleneck - Compressed DenseNets offer further performance benefits, such as reduced number of parameters, with similar or better performance.  \nTake into consideration the DenseNet-100-12 model, with nearly 7 million parameters against with the DenseNet-BC-100-12, with just 0.8 million parameters. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9546952767387693,
        0.8063659344238598
      ],
      "excerpt": "3.46 % error which is a new state of the art performance on CIFAR-10. \nDense Nets have an architecture which can be shown in the following image from the paper: <br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "DenseNet implementation in Keras",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/titu1994/DenseNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 296,
      "date": "Tue, 28 Dec 2021 02:13:14 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/titu1994/DenseNet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "titu1994/DenseNet",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/titu1994/DenseNet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2017 Somshubra Majumdar\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Dense Net in Keras",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DenseNet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "titu1994",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/titu1994/DenseNet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "titu1994",
        "body": "Contains the weights for DenseNetImageNet121, DenseNetImageNet161 and DenseNetImageNet169",
        "dateCreated": "2017-09-01T23:06:42Z",
        "datePublished": "2017-09-06T02:33:22Z",
        "html_url": "https://github.com/titu1994/DenseNet/releases/tag/v3.0",
        "name": "DenseNet ImageNet 121, 161, 169 Weights",
        "tag_name": "v3.0",
        "tarball_url": "https://api.github.com/repos/titu1994/DenseNet/tarball/v3.0",
        "url": "https://api.github.com/repos/titu1994/DenseNet/releases/7646725",
        "zipball_url": "https://api.github.com/repos/titu1994/DenseNet/zipball/v3.0"
      },
      {
        "authorType": "User",
        "author_name": "titu1994",
        "body": "Contains the weights of DenseNet-40-12 model trained on CIFAR 10 dataset.\n",
        "dateCreated": "2017-02-12T01:13:08Z",
        "datePublished": "2017-02-12T07:26:47Z",
        "html_url": "https://github.com/titu1994/DenseNet/releases/tag/v2.0",
        "name": "DenseNet-40-12 CIFAR 10 Weights (H5)",
        "tag_name": "v2.0",
        "tarball_url": "https://api.github.com/repos/titu1994/DenseNet/tarball/v2.0",
        "url": "https://api.github.com/repos/titu1994/DenseNet/releases/5431438",
        "zipball_url": "https://api.github.com/repos/titu1994/DenseNet/zipball/v2.0"
      },
      {
        "authorType": "User",
        "author_name": "titu1994",
        "body": "Contains the weights of DenseNet-40-12 model trained on CIFAR 10 dataset. \n\nPlease choose the zip files and extract them if you are using them in the script provided. If you simply want the weights, then please choose the correct h5 file.\n\nNote : There are 4 different weights, choose the correct weight file for the correct backend [theano, tensorflow] and the correct dim ordering [th, tf]\n",
        "dateCreated": "2016-12-10T07:13:43Z",
        "datePublished": "2017-02-03T22:25:57Z",
        "html_url": "https://github.com/titu1994/DenseNet/releases/tag/v1.0",
        "name": "DenseNet-40-12 CIFAR 10 Weights",
        "tag_name": "v1.0",
        "tarball_url": "https://api.github.com/repos/titu1994/DenseNet/tarball/v1.0",
        "url": "https://api.github.com/repos/titu1994/DenseNet/releases/5357274",
        "zipball_url": "https://api.github.com/repos/titu1994/DenseNet/zipball/v1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Keras\n- Theano (weights not tested) / Tensorflow (tested) / CNTK (weights not tested)\n- h5Py\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 710,
      "date": "Tue, 28 Dec 2021 02:13:14 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "densenet",
      "densenet-model",
      "paper",
      "bottleneck",
      "deep-learning",
      "keras"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Import the `densenet.py` script and use the `DenseNet(...)` method to create a custom DenseNet model with a variety of parameters.\n\nExamples : \n\n```\nimport densenet\n\n#: 'th' dim-ordering or 'tf' dim-ordering\nimage_dim = (3, 32, 32) or image_dim = (32, 32, 3)\n\nmodel = densenet.DenseNet(classes=10, input_shape=image_dim, depth=40, growth_rate=12, \n\t\t\t  bottleneck=True, reduction=0.5)\n```\n\nOr, Import a pre-built DenseNet model for ImageNet, with some of these models having pre-trained weights (121, 161 and 169).\n\nExample : \n```\nimport densenet\n\n#: 'th' dim-ordering or 'tf' dim-ordering\nimage_dim = (3, 224, 224) or image_dim = (224, 224, 3)\n\nmodel = densenet.DenseNetImageNet121(input_shape=image_dim)\n```\n\nWeights for the DenseNetImageNet121, DenseNetImageNet161 and DenseNetImageNet169 models are provided ([in the release tab](https://github.com/titu1994/DenseNet/releases)) and will be automatically downloaded when first called. They have been trained on ImageNet. The weights were ported from the repository https://github.com/flyyufelix/DenseNet-Keras.\n\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
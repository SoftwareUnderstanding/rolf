{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<br>[1] http://senseable.mit.edu/papers/pdf/20180920_Cai-etal_Treepedia-2_IEEE-Conference.pdf\n<br>[2] https://arxiv.org/pdf/1505.04597.pdf\n<br>[3] https://arxiv.org/pdf/1704.04861.pdf\n<br>[4] https://towardsdatascience.com/review-mobilenetv1-depthwise-separable-convolution-light-Weight-model-a382df364b69\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.860790182961324
      ],
      "excerpt": "| Machine Type        | GPUs                | UNet        | Mobile Net V2 | Number of image | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/anant1203/Applying-Deep-Learning-for-Large-scale-Quantification-of-Urban-Tree-Cover",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-11-13T07:53:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-10-20T00:49:48Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Recent advancement in deep learning has become one of the most powerful tools to solve the\nimage classification and segmentation problem.Deep learning model learn the filter that helps\nin extraction and learning of the important feature form the images. These feature helps to find\ndifferences as well as similarities amongst the image. Deep learning models require large\ndataset to learn the complex data representation.In the paper[1] the authors have used DCNN\nmodel to find the green cover in the cities using Cityscapes dataset. Cityscapes dataset has\n2975 images and mask of green cover of different cities around the world which was used as\nthe training data and 500 image with masks were used as testing dataset. The images were\ngoogle street view images. The DCNN model has an IOU of 61.2 percent. In this approach I\nused state of the art unet model and mobile net v2 model. Unet gave an IOU of 74.5 percent\nand mobile net v2 model gave an IOU of 64.3 percent which were better and lighter model than\npreviously used DCNN model. The model were even tested on different machine type with\ndifferent configuration to check their performance.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9297963685034214,
        0.9174237710431725
      ],
      "excerpt": "To find out vegetation cover using deep learning model that can be deployed on the edge device. Dataset used to train the model is cityscape dataset. Model used are Unet and Mobile net V2 model. \nUnet[2] is a state of the art image segmentation model,the architecture looks like a U. It has 3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8867286039691671
      ],
      "excerpt": "\u25cf Bottleneck: It mediate between contraction and expansion.It uses two 3X3 CNN layers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9691309549885384
      ],
      "excerpt": "Mobile Net V2[3] is small size model made by google to use in mobile/edge devices. It is \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8876234259246024
      ],
      "excerpt": "by the mobile net v2 model while the upsampling layer remained the same. Mobile net is small \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9538358832139299
      ],
      "excerpt": "|               | Number of parameters | Size of the model | Training and Calibration               | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9868245366767711,
        0.821730642141532
      ],
      "excerpt": "Table 1: Show comparison of Unet and mobilenet  model \nCityscapes dataset is used which has a total of 2975 image and mask as shown in figure 1. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8396969586049507,
        0.9373440103690945
      ],
      "excerpt": "dimension. As we can see that the mask had multiple class but since this problem deals with \nvegetation cover so we converted the mask to black and white with vegetation cover as white \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8920039269021516
      ],
      "excerpt": "classes(objects), was used to convert mask as per our usage as shown in figure 2. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9310560174966743,
        0.9454965985360719
      ],
      "excerpt": "Figure 2: Example of mask with vegetation cover and image with size 512x512. \nMean IoU was used for measuring the accuracy of the location of labelled vegetation labels. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9431236352286565,
        0.8957034582955339,
        0.9738760664226362,
        0.9721842683704668
      ],
      "excerpt": "Both the model outperform the DCNN model mentioned in [1]. The number of parameters in the \nUnet model was almost half of what was mentioned in DCNN but still it was able to outperform it \nwith the IoU of 74.5 percent. The mobile net v2 model had almost one tenth of the number of \nparameters as in DCNN model but still it out perform it with the IoU of 64.3. Figure 3 shows the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9205218324974866
      ],
      "excerpt": "The model were tested on different environment to check the scalability of the model. The result \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8997630876406019
      ],
      "excerpt": "| Number of Parameter in mobile net = 6,504,227        Size: 9.79 MB <br> Number of Parameter in Unet = 33,480,577            Size: 50.25 MB | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8458635826187376
      ],
      "excerpt": "Table 2: Show Unet and Mobile net performance on different environment.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.869346842780219
      ],
      "excerpt": "RAM and NVIDIA Tesla T4 x 1. The Unet model took almost 5 hrs to train 50 epoch with batch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "To find out vegetation cover using deep learning model that can be deployed on the edge device. Dataset used to train the model is cityscape dataset. Model used are Unet and Mobile net V2 model.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/anant1203/Applying-Deep-Learning-for-Large-scale-Quantification-of-Urban-Tree-Cover/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 12:23:29 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/anant1203/Applying-Deep-Learning-for-Large-scale-Quantification-of-Urban-Tree-Cover/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "anant1203/Applying-Deep-Learning-for-Large-scale-Quantification-of-Urban-Tree-Cover",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/anant1203/Applying-Deep-Learning-for-Large-scale-Quantification-of-Urban-Tree-Cover/master/test/testingscript.ipynb",
      "https://raw.githubusercontent.com/anant1203/Applying-Deep-Learning-for-Large-scale-Quantification-of-Urban-Tree-Cover/master/test/unet_implementation.ipynb",
      "https://raw.githubusercontent.com/anant1203/Applying-Deep-Learning-for-Large-scale-Quantification-of-Urban-Tree-Cover/master/test/mobilenet_final.ipynb",
      "https://raw.githubusercontent.com/anant1203/Applying-Deep-Learning-for-Large-scale-Quantification-of-Urban-Tree-Cover/master/test/test_image_code.ipynb",
      "https://raw.githubusercontent.com/anant1203/Applying-Deep-Learning-for-Large-scale-Quantification-of-Urban-Tree-Cover/master/src/unet_script.ipynb",
      "https://raw.githubusercontent.com/anant1203/Applying-Deep-Learning-for-Large-scale-Quantification-of-Urban-Tree-Cover/master/src/mobile_net_script.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8617202442872431
      ],
      "excerpt": "Figure 1: Examples of mask and image used to train the model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8331009722651971
      ],
      "excerpt": "<br> n = number of images in test set \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/anant1203/Applying-Deep-Learning-for-Large-scale-Quantification-of-Urban-Tree-Cover/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Anant Tripathi\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Applying-Deep-Learning-for-Large-scale-Quantification-of-Urban-Tree-Cover",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Applying-Deep-Learning-for-Large-scale-Quantification-of-Urban-Tree-Cover",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "anant1203",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/anant1203/Applying-Deep-Learning-for-Large-scale-Quantification-of-Urban-Tree-Cover/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Wed, 29 Dec 2021 12:23:29 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "dcnn-model",
      "unet-model",
      "cityscape-dataset",
      "deep-learning",
      "xception-net",
      "mobile-nets",
      "python",
      "pandas",
      "numpy",
      "matplotlib-pyplot",
      "keras-tensorflow",
      "keras-neural-networks"
    ],
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n[1] AutoAugment: Learning Augmentation Policies from Data - 2019\n    Ekin Dogus Cubuk and Barret Zoph and Dandelion Mane and Vijay Vasudevan and Quoc V. Le\n    https://arxiv.org/pdf/1805.09501.pdf\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TillBeemelmanns/auto-augment-tf2-operations",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-04-20T20:26:33Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-29T08:18:09Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9754748143513788
      ],
      "excerpt": "Exemplary implementation for learning augmentation policies from your training data distribution. The principle for the augmentation relies on Google's AutoAugment paper \"Learning Augmentation Policies from Data\" [1]. This repository  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9190921906149621,
        0.9138059370428919,
        0.9584290507507249,
        0.9672550214854755
      ],
      "excerpt": "The augmentation operations rely on Tensorflow 2.6.0 operations which allow scalability and high computational throughput even with large images. Furthermore, the augmentation pipeline can be easily integrated into the tf.data API. \nA list of all implemented augmentation techniques is given here. Additional, methods will be implemented in the near  \nfuture. Performance is measured with the test_image.jpg which has size 2048 x 1024. All augmentation methods are  \nexecuted with level=5. Averaged over 500 samples on the Intel Core i7 Prozessor 8665U. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8352370827177169
      ],
      "excerpt": "[ ] More Augmentation Methods \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.953026075102781,
        0.9567588029116127
      ],
      "excerpt": "[ ] Implement augmentation policies identical to these in [1] \n[ ] Implement augmentation policy search with Ray Tune \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation of Google's Auto Augment paper. All augmentations as efficient Tensorflow 2.6.0 operations. Easy integration into a tf.data API pipeline. ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TillBeemelmanns/auto-augment-tf2-operations/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 07:52:15 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/TillBeemelmanns/auto-augment-tf2-operations/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "TillBeemelmanns/auto-augment-tf2-operations",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/TillBeemelmanns/auto-augment-tf2-operations/master/docker/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/TillBeemelmanns/auto-augment-tf2-operations/master/docker/docker_build.sh",
      "https://raw.githubusercontent.com/TillBeemelmanns/auto-augment-tf2-operations/master/docker/docker_train.sh"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/TillBeemelmanns/auto-augment-tf2-operations/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Implementation of Google's Auto-Augmentation based on TF2 OPS",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "auto-augment-tf2-operations",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "TillBeemelmanns",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/TillBeemelmanns/auto-augment-tf2-operations/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Fri, 24 Dec 2021 07:52:15 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "augmentation-policy",
      "google-autoaugment",
      "augmentation-methods",
      "augmentation-operation",
      "tf2",
      "augmentation-libraries",
      "keras"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\npolicy = {'sub_policy0': {'op0': ['adjust_saturation', 0.2, 2],\n                          'op1': ['equalize', 0.1, 6],\n                          'op2': ['add_noise', 0.9, 6]},\n          'sub_policy1': {'op0': ['adjust_contrast', 0.1, 7],\n                          'op1': ['add_noise', 0.0, 10]},\n          'sub_policy2': {'op0': ['posterize', 0.9, 6],\n                          'op1': ['unbiased_gamma_sampling', 0.5, 1]},\n          'sub_policy3': {'op0': ['adjust_brightness', 0.3, 1],\n                          'op1': ['adjust_hue', 0.4, 5]},\n          'sub_policy4': {'op0': ['adjust_saturation', 0.2, 9],\n                          'op1': ['add_noise', 0.1, 0]},\n          'sub_policy5': {'op0': ['adjust_contrast', 1.0, 1],\n                          'op1': ['unbiased_gamma_sampling', 0.4, 9]},\n          'sub_policy6': {'op0': ['unbiased_gamma_sampling', 0.3, 0],\n                          'op1': ['adjust_hue', 0.1, 6]},\n          'sub_policy7': {'op0': ['solarize', 0.6, 0],\n                          'op1': ['adjust_gamma', 0.3, 6]},\n          'sub_policy8': {'op0': ['adjust_jpeg_quality', 0.7, 10],\n                          'op1': ['adjust_hue', 0.1, 2]},\n          'sub_policy9': {'op0': ['equalize', 0.6, 0],\n                          'op1': ['solarize', 0.0, 6]}}\n```\nSimilar to Google's AutoAugment, a single augmentation policy consists of several subpolicies, which inturn consists of one or more \naugmentation operation. Each operation is defined as a tuple of **augmentation method**, \n**probability** and **intensity**. Several operations within one subpolicy are applied in sequence. \nThe augmentation policy from above would result in the following:\n \n![](assets/augmentation_policy.gif)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "A full example script for image classification can be found in [classification_example.py](classification_example.py).\nThis excerpt demonstrates the simplicity for the usage of the augmentation methods:\n```python\nimport tensorflow as tf\nfrom augmentation_operations import apply_augmentation_policy\n\ndef augmentor_func(img, label):\n    img = apply_augmentation_policy(img, policy)\n    return img, label\n\ntrain_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    \"PetImages\",\n    subset=\"training\",\n    image_size=(180, 180),\n    batch_size=1\n).unbatch()\n\ntrain_dataset = train_dataset.map(augmentor_func).batch(32).prefetch(32)\n```\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
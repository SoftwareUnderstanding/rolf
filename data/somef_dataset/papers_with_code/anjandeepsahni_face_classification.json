{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- **MobileNetV2: Inverted Residuals and Linear Bottlenecks**: https://arxiv.org/pdf/1801.04381.pdf\n- **Deep Residual Learning for Image Recognition**: https://arxiv.org/pdf/1512.03385.pdf\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/anjandeepsahni/face_classification",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-01T17:43:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-20T20:26:33Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Given an image of a person\u2019s face, the task of classifying the ID of the face is known as **face classification**. Whereas the problem of determining whether two face images are of the same person is known as **face verification** and this has several important applications. This mini-project uses convolutional neural networks (CNNs) to design an end-to-end system for face classification and face verification.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9765262829027452,
        0.8686294126081521,
        0.934999919252146,
        0.9236417112978759,
        0.9883989794162679,
        0.9937567705144529,
        0.9903391003445428,
        0.9717130612397051,
        0.9829923178494101
      ],
      "excerpt": "Input to the system is a face image and it predicts the ID of the face. The true face image ID is expected to be present in the training data. In this way, the network will be doing an N-way classification to get the prediction. \nInput to the system is a trial, that is, a pair of face images that may or may not belong to the same person. Given a trial, the system will output a numeric score that quantifies how similar the faces of the two images appear to be. The system uses the final convolution layer as an embedding which represents important features from a person. It uses cosine similarity to assign a confidence score to two images. A higher score indicates higher confidence that the two images belong to one and the same person. \nThe following preprocssing methods are not implemented and are left for future work. \n- Face Detection: Face detection is the automatic process for detection of human faces in digital images. This will ensure that the model you are training only sees images of humans and any noise in the images is deleted. \n- Face Alignment: Face alignment is the automatic process of identifying the geometric structure of human faces in digital images. Given the location and size of a face, it automatically determines the shape of the face components such as eyes and nose. Given the location of the face in the image, images can be cropped to include only the human faces, without any background noise. This will also reduce noise for the model training. \nTrimmed down version of ResNet50 and MobileNetV2 are supported. Model ensembling of three different MobileNetV2 implementations and a single ResNet50 implementation provides the best results. Some of my observations are listed below: \nI found that MobileNetV2 is much faster then ResNet50 and is a more suitable architecture for smaller datasets. ResNet50 takes too much time to converge, and might end up giving better results if trained for a long duration. I accounted the slower convergence to the fact that the network will take time to learn that a lot of the filters are useless. \nI used the \u201cTop 3 Highest Validation Accuracy\u201d and \u201cTop 2 Lowest Validation Loss\u201d for 4 different architectures, that is, three MobileNetV2 and one ResNet50. So total 20 models were used for final prediction in classification as well as verification. I found model ensemble to improve my results by 7-8% on validation set. \nGiven similarity scores for many trials, some threshold score is needed to actually accept or reject pairs as same-person pairs (i.e., when the similarity score is above the threshold) or different-person pairs (i.e., when the score is below the threshold), respectively. For any given threshold, there are four conditions on the results: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9257091660744146,
        0.9521810124930574
      ],
      "excerpt": "The Receiver Operating Characteristic (ROC) curve is created by plotting the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings. The Area Under the Curve (AUC) for the ROC curve is equal to the probability that a classifier will rank a randomly chosen similar pair (images of same people) higher than a randomly chosen dissimilar one (images from two different people) (assuming \u2019similar\u2019 ranks higher than \u2019dissimilar\u2019 in terms of similarity scores). This AUC is used as the evaluation metric for face verification. \nCustom/private dataset was used for this task. The results achieved were at par with the expectations. Please note that the test accuracy is much lower than the validation accuracy due to imbalance in the dataset. Best results from independent MobileNetV2 and ResNet50 models are as shown below. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9369314072506446
      ],
      "excerpt": "With model ensembling as explained in the Models section, below results were achieved: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Face classification and verification using convolution neural networks.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/anjandeepsahni/face_classification/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 23 Dec 2021 08:44:10 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/anjandeepsahni/face_classification/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "anjandeepsahni/face_classification",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/anjandeepsahni/face_classification/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Anjandeep Singh Sahni\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Face Classification and Verification",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "face_classification",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "anjandeepsahni",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/anjandeepsahni/face_classification/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 23 Dec 2021 08:44:10 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "face-classification",
      "face-verification",
      "deep-learning",
      "computer-vision"
    ],
    "technique": "GitHub API"
  }
}
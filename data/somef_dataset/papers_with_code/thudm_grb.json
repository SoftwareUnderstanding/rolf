{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2111.04314",
      "https://arxiv.org/abs/2111.04314",
      "https://arxiv.org/abs/1609.02907",
      "https://arxiv.org/abs/2111.04314"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find GRB useful for your research, please cite [our paper](https://arxiv.org/abs/2111.04314):  \n\n```\n@article{zheng2021grb,\n  title={Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of Graph Machine Learning},\n  author={Zheng, Qinkai and Zou, Xu and Dong, Yuxiao and Cen, Yukuo and Yin, Da and Xu, Jiarong and Yang, Yang and Tang, Jie},\n  journal={Neural Information Processing Systems Track on Datasets and Benchmarks 2021},\n  year={2021}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{zheng2021grb,\n  title={Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of Graph Machine Learning},\n  author={Zheng, Qinkai and Zou, Xu and Dong, Yuxiao and Cen, Yukuo and Yin, Da and Xu, Jiarong and Yang, Yang and Tang, Jie},\n  journal={Neural Information Processing Systems Track on Datasets and Benchmarks 2021},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9376277858156781
      ],
      "excerpt": "[11/10/2021] GRB is accepted by NeurIPS 2021 Datasets and Benchmarks Track! Find our paper in OpenReview. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "              n_epoch=10, \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/THUDM/grb",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "In case of any problem, please contact us via email: cogdl.grbteam@gmail.com. We also welcome researchers to join our [Google Group](https://groups.google.com/g/graph-robustness-benchmark) for further discussion on the adversarial robustness of graph machine learning.\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-10T06:35:08Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-16T22:33:18Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9857904930363701
      ],
      "excerpt": "[08/11/2021] The final version of our paper is now available in arxiv, there is also a representation video for brief introduction of GRB. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8188315432189727,
        0.9662683048064531,
        0.8240057673431258
      ],
      "excerpt": "[26/09/2021] Add support for graph classification task! See tutorials in examples/. \n[16/09/2021] Add a paper list of state-of-the-art researches about adversarial robustness in graph machine learning (Keep Updating). \n[27/08/2021] Add support for modification attacks! 7 implementations and tutorials: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8376388526482113
      ],
      "excerpt": "[17/08/2021] Add AutoML function based on optuna for training models: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8764581241500832
      ],
      "excerpt": "An example of applying Topological Defective Graph Injection Attack (TDGIA) on trained GCN model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8718664529050697
      ],
      "excerpt": "rst = tdgia.attack(model=model, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9420142483271655
      ],
      "excerpt": ": Get modified adj and features \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925925977507223
      ],
      "excerpt": "GRB maintains leaderboards that permits a fair comparision across various attacks and defenses. To ensure the reproducibility, we provide all necessary information including datasets, attack results, saved models, etc. Besides, all results on the leaderboards can be easily reproduced by running the following scripts (e.g., leaderboard for grb-cora dataset): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8791356307723457
      ],
      "excerpt": "    -n      Choose the number of an attack from 0 to 9. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9648221368557534
      ],
      "excerpt": "We welcome researchers to submit new methods including attacks, defenses, or new GML models to enrich the GRB leaderboard. For future submissions, one should follow the GRB Evaluation Rules and respect the reproducibility.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Graph Robustness Benchmark: A scalable, unified, modular, and reproducible benchmark for evaluating the adversarial robustness of Graph Machine Learning.",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://grb.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/thudm/grb/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Mon, 27 Dec 2021 07:36:48 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/THUDM/grb/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "THUDM/grb",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/thudm/grb/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/thudm/grb/master/paperlist/bibtexparser.ipynb",
      "https://raw.githubusercontent.com/thudm/grb/master/examples/node_classification/trianing_automl.ipynb",
      "https://raw.githubusercontent.com/thudm/grb/master/examples/node_classification/training.ipynb",
      "https://raw.githubusercontent.com/thudm/grb/master/examples/node_classification/injection_attack.ipynb",
      "https://raw.githubusercontent.com/thudm/grb/master/examples/node_classification/modification_attack.ipynb",
      "https://raw.githubusercontent.com/thudm/grb/master/examples/node_classification/adversarial_training.ipynb",
      "https://raw.githubusercontent.com/thudm/grb/master/examples/node_classification/load_datasets.ipynb",
      "https://raw.githubusercontent.com/thudm/grb/master/examples/graph_classification/training.ipynb",
      "https://raw.githubusercontent.com/thudm/grb/master/examples/graph_classification/modification_attack.ipynb",
      "https://raw.githubusercontent.com/thudm/grb/master/examples/graph_classification/load_datasets.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/thudm/grb/master/scripts/download_saved_models.sh",
      "https://raw.githubusercontent.com/thudm/grb/master/scripts/download_attack_results.sh",
      "https://raw.githubusercontent.com/thudm/grb/master/scripts/run_leaderboard_pipeline.sh",
      "https://raw.githubusercontent.com/thudm/grb/master/scripts/run_train_pipeline.sh",
      "https://raw.githubusercontent.com/thudm/grb/master/scripts/run_attack_pipeline.sh",
      "https://raw.githubusercontent.com/thudm/grb/master/scripts/download_dataset.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "GRB provides all necessary components to ensure the reproducibility of evaluation results.\nGet datasets from [link](https://cloud.tsinghua.edu.cn/d/c77db90e05e74a5c9b8b/) or download them by running the following script:\n```bash\ncd ./scripts\nsh download_dataset.sh\n```\nGet attack results (adversarial adjacency matrix and features) from [link](https://cloud.tsinghua.edu.cn/d/94b2ea104c2e457d9667/) or download them by running the following script:\n```bash\nsh download_attack_results.sh\n```\nGet saved models (model weights) from [link](https://cloud.tsinghua.edu.cn/d/8b51a6b428464340b368/) or download them by running the following script:\n```bash\nsh download_saved_models.sh\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Install grb via _pip_ (current version v0.1.0):\n```bash\npip install grb\n```\nInstall grb via _git_ (for the newest version):\n```bash\ngit clone git@github.com:THUDM/grb.git\ncd grb\npip install -e .\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9023697225149864
      ],
      "excerpt": "sh run_leaderboard_pipeline.sh -d grb-cora -g 0 -s ./leaderboard -n 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8903816776627959
      ],
      "excerpt": "    -g      Choose a GPU device. -1 for CPU. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8383948301114956
      ],
      "excerpt": "Tutorial: Training models with AutoML \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.843967211769301
      ],
      "excerpt": "Training models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8659830643096227
      ],
      "excerpt": "from grb.dataset import Dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8078145619394667
      ],
      "excerpt": "model = GCN(in_features=dataset.num_features, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8174540907975313
      ],
      "excerpt": ": Training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8425586466836605
      ],
      "excerpt": "trainer.train(model=model, n_epoch=200, dropout=0.5, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from grb.attack.injection.tdgia import TDGIA \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8612630503664754
      ],
      "excerpt": "tdgia = TDGIA(lr=0.01,  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/THUDM/grb/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell",
      "TeX",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Stanislas\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Updates",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "grb",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "THUDM",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/THUDM/grb/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "Stanislas0",
        "body": "The first release of **Graph Robustness Benchmark (GRB)**.\r\n- API based on pure PyTorch, CogDL, and DGL.\r\n- Include five graph [datasets](https://cogdl.ai/grb/datasets) of different scales.\r\n- Support graph injection attacks (e.g., RND, FGSM, PGS, SPEIT, TDGIA).\r\n- Support adversarial defenses (e.g., layer normalization, adversarial training, GNNSVD, GNNGuard).\r\n- Provide [homepage](https://cogdl.ai/grb/home).\r\n- Provide [leaderboards](https://cogdl.ai/grb/leaderboard/) of all datasets.\r\n- Provide basic [documentation](https://grb.readthedocs.io/en/latest/).\r\n- Provide scripts for reproducing results.\r\n",
        "dateCreated": "2021-08-04T13:13:07Z",
        "datePublished": "2021-08-05T16:47:11Z",
        "html_url": "https://github.com/THUDM/grb/releases/tag/v0.1.0",
        "name": "v0.1.0",
        "tag_name": "v0.1.0",
        "tarball_url": "https://api.github.com/repos/THUDM/grb/tarball/v0.1.0",
        "url": "https://api.github.com/repos/THUDM/grb/releases/47377126",
        "zipball_url": "https://api.github.com/repos/THUDM/grb/zipball/v0.1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* scipy==1.5.2\n* numpy==1.19.1\n* torch==1.8.0\n* networkx==2.5\n* pandas~=1.2.3\n* cogdl~=0.3.0.post1\n* scikit-learn~=0.24.1\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 45,
      "date": "Mon, 27 Dec 2021 07:36:48 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "adversarial-attacks",
      "graph-neural-networks",
      "machine-learning",
      "deep-learning",
      "pytorch"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "![GRB](https://github.com/THUDM/grb/blob/master/docs/source/_static/grb_scenario.png)\n\nGRB provides unified evaluation scenarios for fair comparisons between attacks and defenses. The example scenario is **Black-box**, **Evasion**, **Inductive**, **Injection**. \n\n* **Black-box**: Both the attacker and the defender have no knowledge about the applied methods each other uses.\n* **Evasion**: Models are already trained in trusted data (e.g. authenticated users), which are untouched by the attackers but might have natural noises. Thus, attacks will only happen during the inference phase. \n* **Inductive**: Models are used to classify unseen data (e.g. new users), i.e. validation or test data are unseen during training, which requires models to generalize to out of distribution data.\n* **Injection**: The attackers can only inject new nodes but not modify the target nodes directly. Since it is usually hard to hack into users' accounts and modify their profiles. However, it is easier to create fake accounts and connect them to existing users.\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1704.00028"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8356013927728488,
        0.9030859728368266
      ],
      "excerpt": "| biphenylene  | biphenylene | C<sub>12</sub>H<sub>8</sub> || \n|1-Phenylpropene | [(E)-prop-1-enyl]benzene | C<sub>9</sub>H<sub>10</sub>|   | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.9030859728368266
      ],
      "excerpt": "| biphenylene  | biphenylene | C<sub>12</sub>H<sub>8</sub> || C1=CC2=C3C=CC=CC3=C2C=C1| \n|1-Phenylpropene | [(E)-prop-1-enyl]benzene | C<sub>9</sub>H<sub>10</sub>|   | CC=CC1=CC=CC=C1| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8348362997093185
      ],
      "excerpt": "| SMILES      | Image URL |  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8348362997093185
      ],
      "excerpt": "| SMILES      | Image URL |  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "|  |  |     96.4 |  |    0.80 |  |    0.30 | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/carlytaylor0017/csk",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-07-24T21:31:09Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-01-15T19:35:26Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8831879819025994
      ],
      "excerpt": "Small-Data Problem and Image Augmentation using Keras \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "Model Hyperparameters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9849353487011091
      ],
      "excerpt": "The skeletal formula of a chemical species is a type of molecular structural formula that serves as a shorthand representation of a molecule's bonding and contains some information about its molecular geometry. It is represented in two dimensions, and is usually hand-drawn as a shorthand representation for sketching species or reactions. This shorthand representation is particularly useful in that carbons and hydrogens, the two most common atoms in organic chemistry, don't need to be explicitly drawn. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9562207409372443,
        0.9879946302039421,
        0.9567588029116127
      ],
      "excerpt": "SMILES is a line notation for describing the structure of chemical elements or compounds using short ASCII strings. These strings can be thought of as a language, where atoms and bond symbols make up the vocabulary.  The SMILES strings contain the same information as the structural images, but are depicted in a different way. \nSMILES strings use atoms and bond symbols to describe physical properties of chemical species in the same way that a drawing of the structure conveys information about elements and bonding orientation. This means that the SMILES string for each molecule is synonymous with its structure and since the strings are unique, the name is universal. These strings can be imported by most molecule editors for conversion into other chemical representations, including structural drawings and spectral predictions.  \nTable 2: SMILES strings contrasted with skeletal formulas \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9907317404040709,
        0.9696623120658616
      ],
      "excerpt": "Perhaps the most important property of SMILES, as it relates to data science, is that the datatype is quite compact. SMILES structures average around 1.6 bytes per atom, compared to skeletal image files, which have an averge size of 4.0 kilobytes. \nSince all chemical structures are unique, this means that there is only one correct way to represent every chemical species. This presents an interesting problem when trying to train a neural network to predict the name of a structure - by convention the datasets are going to be sparse. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.965932133518216,
        0.8978126266306448
      ],
      "excerpt": "Generating the image URLs required URL encoding the SMILES strings, since the strings can contain characters which are not safe for URLs. This had the added benefit of making the SMILES strings safe for filenames as well. The final training dataset was in a directory architected based on this blog post from the Keras website, where the filenames are URL encoded SMILES strings. \nThis dataset has 9,691 rows, each with a unique name and link to a 300 x 300 pixel structural image, as shown in Table 4. It includes all of the classes from the hydrocarbon dataset, as well as new short-chain images which can include substituent atoms, such as oxygen and nitrogen. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9685787340580491,
        0.916425131958553
      ],
      "excerpt": "CNNs take advantage of the fact that the input consists of images and they constrain the architecture in a more sensible way. In particular, unlike a regular Neural Network, the layers of a CNN have neurons arranged in 3 dimensions: width, height, depth. \nKeras allows for many image augmentation parameters which can be found here. The parameters used, both for initial model building and for the final architecture, are described below:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9014472933174742,
        0.8565903798423439
      ],
      "excerpt": "fill_mode = points nearest the outside the boundaries of the input are filled by the chosen mode \nWhen creating the initial small dataset for model building, the following image augmentation parameters were used: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "model optimizer = Adam \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.892619193387957,
        0.9870288194417439,
        0.8941384854448179
      ],
      "excerpt": "The categorical crossentropy loss function is used for single label categorization, where each image belongs to only one class. The categorical crossentropy loss function compares the distribution of the predictions (the activations in the output layer, one for each class) with the true distribution, where the probability of the true class is 1 and 0 for all other classes. \nThe Adam optimization algorithm is different to classical stochastic gradient descent, where gradient descent maintains a single learning rate for all weight updates. Specifically, the Adam algorithm calculates an exponential moving average of the gradient and the squared gradient, and the parameters beta1 and beta2 control the decay rates of these moving averages. \nThe ELU activation function, or \"exponential linear unit\", avoids a vanishing gradient similar to ReLUs, but ELUs have improved learning characteristics compared to the other activation functions. In contrast to ReLUs, ELUs don't have a slope of 0 for negative values. This allows the ELU function to push mean unit activations closer to zero; zero means speed up learning because they bring the gradient closer to the unit natural gradient. A comparison between ReLU and ELU activation functions can be seen in Figure 3. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8049778525068404,
        0.8946480167021552,
        0.9522006597537994,
        0.8124617148754936
      ],
      "excerpt": "The softmax function highlights the largest values and suppresses values which are significantly below the maximum value. The function normalizes the distribution of the predictions, so that they can be directly treated as probabilities. \nSample layer of a simple CNN:  \nINPUT [50x50x3] will hold the raw pixel values of the image, in this case an image of width 50, height 50, and with three color channels R,G,B. \nCONV layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and a small region they are connected to in the input volume. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9485851273608903
      ],
      "excerpt": "The code snippet below is the architecture for the model - a stack of 4 convolution layers with an ELU activation followed by max-pooling layers: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877,
        0.8339712143426485,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501,
        0.8341589559722501
      ],
      "excerpt": "model = Sequential() \nmodel.add(Conv2D(32, (3, 3), input_shape=(50, 50, 1))) \nmodel.add(MaxPooling2D(pool_size=(2, 2))) \nmodel.add(Conv2D(32, (3, 3))) \nmodel.add(MaxPooling2D(pool_size=(2, 2))) \nmodel.add(Conv2D(64, (3, 3))) \nmodel.add(MaxPooling2D(pool_size=(2, 2))) \nmodel.add(Conv2D(64, (3, 3))) \nmodel.add(MaxPooling2D(pool_size=(2, 2))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9869828538820122
      ],
      "excerpt": "On top of this stack are two fully-connected layers. The model is finished withsoftmaxactivation, which is used in conjunction witheluandcategorical crossentropy` loss to train our model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9635102186434588,
        0.8393963605101055,
        0.8035838913610446,
        0.9575664097478853,
        0.8427660116625393,
        0.8513375066418586,
        0.8212953480155029
      ],
      "excerpt": "In order to create a model with appropriately tuned hyperparameters, I started training on a smaller dataset; the initial training set had 2,028 classes, specifically chosen due to the simplicity of the structures. For each of the 2,028 classes, I used the image augmentation parameters shown in Figure 1 and Parameters 1 to train on 250 batch images per class. The accuracy and loss for this model can be seen in Figure 4 and Figure 5. \nFigure 5: Model accuracy for hydrocarbon model trained using simpler augmentation parameters \nFigure 6: Model loss for hydrocarbon model trained using simpler augmentation parameters \nUsing the hyperparameters and weights from this training model, I started training using more difficult augmentation parameters. Since structural images are valid, even when they are flipped horizontally or vertically, the model must learn to reognize these changes. The augmented parameters can be seen in Figure 2 and Parameters 2. \nThe accuracy and loss for this model can be seen in Figure 7 and Figure 8. \nFigure 7: Model accuracy for model trained using wider augmentation parameters (including horizontal/vertical flipping) \nFigure 8: Model loss for model trained using wider augmentation parameters (including horizontal/vertical flipping) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9741765517038666,
        0.88823519084173
      ],
      "excerpt": "Using the hyperparameters for the 2,028 class training model, I started training the 9,691 class model. Initially, I continued using the simpler augmentation parameters. This allowed me to generate and save model weights, with the intention of eventually increasing the difficulty of the training set. The accuracy and loss for this model can be seen in Figure 9 and Figure 10. \nFigure 9: Model accuracy for full model trained using simpler augmentation parameters \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9205454049535552,
        0.8513375066418586,
        0.8212953480155029,
        0.9962242525858389
      ],
      "excerpt": "I was finally able to increase the difficulty of the training set, using the augmentation parameters outlined in Parameters 2.  \nFigure 11: Model accuracy for model trained using wider augmentation parameters (including horizontal/vertical flipping) \nFigure 12: Model loss for model trained using wider augmentation parameters (including horizontal/vertical flipping) \nWhile it is far from perfect, this model can predict the correct class for any molecule with upwards of 80% accuracy. Given the limitations of the datase, this is well beyond the bounds of what was expected and is a pleasant surprise. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9767153595090156
      ],
      "excerpt": "Many of the difficulties with training my CNN could have been avoided had my dataset been larger. While the above process works, and the model has satisfactory results (can predict an image name with around 80% accuracy), the model is not generalizable. In particular, the model does not perform well (or at all) with hand-drawn structures. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9051715947309635,
        0.922326598310127
      ],
      "excerpt": "Thanks to the Keras team for this Wasserstein Generative Adversarial Network (WGAN) code, which can be found here. \nThe code is described as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9137805716798162,
        0.9102225506049068,
        0.8534795136036407,
        0.9448341973327358,
        0.964777085130738,
        0.9282569123963943,
        0.9637175465073041,
        0.9784420619529162
      ],
      "excerpt": "used in WGANs is only easy to calculate for 1-Lipschitz functions (i.e. functions where the gradient norm has a constant \nupper bound of 1). The original WGAN paper enforced this by clipping weights to very small values [-0.01, 0.01]. However, \nthis drastically reduced network capacity. Penalizing the gradient norm is more natural, but this requires second-order \ngradients. These are not supported for some tensorflow ops (particularly MaxPool and AveragePool) in the current \nrelease (1.0.x), but they are supported in the current nightly builds (1.1.0-rc1 and higher). To avoid this, this model uses \nstrided convolutions instead of Average/Maxpooling for downsampling. \nFurthermore, the loss function in a WGAN is not a normal sigmoid output, constrained to [0, 1] and representing the probability that the samples are either real or generated. It is actually a Wasserstein loss function, where the output is linear (so no activation function) and the discriminator wants to make the distance between its output for real and generated samples as large as possible. The easiest way to achieve this is to constrain the output to [-1, 1], where generated samples are -1 and real samples are 1. This means that multiplying the outputs by the labels will yield the loss directly. \nPerhaps the most important part of a WGAN is the gradient penalty loss. The authors of this code describe it very succinctly: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8259573058807618,
        0.9599634556042187,
        0.9885980700105443,
        0.9702006739374702
      ],
      "excerpt": "In Improved WGANs, the 1-Lipschitz constraint is enforced by adding a term to the loss function that penalizes the network if \nthe gradient norm moves away from 1. However, it is impossible to evaluate this function at all points in the input space. \nThe compromise used in the paper is to choose random points on the lines between real and generated samples, and check the \ngradients at these points. Note that it is the gradient w.r.t. the input averaged samples, not the weights of the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8269548206600229
      ],
      "excerpt": "gradients of the discriminator w.r.t. the input averaged samples. The l2 norm and penalty can then be calculated for this \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8672325034183359,
        0.9241108337921535,
        0.892238922239572
      ],
      "excerpt": "Note that this loss function requires the original averaged samples as input, but Keras only supports passing y_true and \ny_pred to loss functions. To get around this, we make a partial() of the function with the averaged_samples argument, and use \nthat for model training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9607801573672973
      ],
      "excerpt": "I started training the WGAN on a very easy short-chain hydrocarbon - propane. Theoretically, if the WGAN is able to recreate a believable training image of propane, it will be able to reproduce longer and more complicated chains. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "utilizing deep learning techniques for chemical identification",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cwolfbrandt/csk/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "There has been a recent explosion in research of modeling methods geared towards \"big-data.\" Certainly, data science as a discipline has an obsession with big-data, as focus has shifted towards development of specialty methods to effectively analyze large datasets. However, an often overlooked problem in data science is small-data. It is generally (and perhaps incorrectly) believed that deep-learning is only applicable to big-data. \n\nIt is true that deep-learning does usually require large amounts of training data in order to learn high-dimensional features of input samples. However, convolutional neural networks are one of the best models available for image classification, even when they have very little data from which to learn. Even so, Keras documentation defines small-data as 1000 images per class. This presents a particular challenge for the hydrocarbon dataset, where there is 1 image per class. \n\nIn order to make the most of the small dataset, more images must be generated. In Keras this can be done via the `keras.preprocessing.image.ImageDataGenerator` class. This method is used to augment each image, generating a new image that has been randomly transformed. This ensures that the model should never see the same picture twice, which helps prevent overfitting and helps the model generalize better.\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 30 Dec 2021 01:23:01 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/carlytaylor0017/csk/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "carlytaylor0017/csk",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8204277686137342
      ],
      "excerpt": "Table 3: Sample rows from the hydrocarbon dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8224608874658778,
        0.8398336512870205
      ],
      "excerpt": "width_shift_range = fraction of total width \nheight_shift_range = fraction of total height \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8247260962876941
      ],
      "excerpt": "Table 5: Sample predictions from hydrocarbon model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.811854372964597
      ],
      "excerpt": "|  |  |     22.0 |   |   21.4   |   |   15.3   | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/carlytaylor0017/csk/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "HTML",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "## Table of Contents",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "csk",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "carlytaylor0017",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/carlytaylor0017/csk/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 30 Dec 2021 01:23:01 GMT"
    },
    "technique": "GitHub API"
  }
}
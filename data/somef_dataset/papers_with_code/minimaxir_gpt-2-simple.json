{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/minimaxir/gpt-2-simple",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-13T20:00:52Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-29T03:27:23Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8972590824986034,
        0.8322610781741927,
        0.8804761989908197,
        0.9291559206320062
      ],
      "excerpt": "A simple Python package that wraps existing model fine-tuning and generation scripts for OpenAI's GPT-2 text generation model (specifically the \"small\" 124M and \"medium\" 355M hyperparameter versions). Additionally, this package allows easier generation of text, generating to a file for easy curation, allowing for prefixes to force the text to start with a given phrase. \nThis package incorporates and makes minimal low-level changes to: \nModel management from OpenAI's official GPT-2 repo (MIT License) \nModel finetuning from Neil Shepperd's fork of GPT-2 (MIT License) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9785606458338432,
        0.9771458969956509
      ],
      "excerpt": "For finetuning, it is strongly recommended to use a GPU, although you can generate using a CPU (albeit much more slowly). If you are training in the cloud, using a Colaboratory notebook or a Google Compute Engine VM w/ the TensorFlow Deep Learning image is strongly recommended. (as the GPT-2 model is hosted on GCP) \nYou can use gpt-2-simple to retrain a model using a GPU for free in this Colaboratory notebook, which also demos additional features of the package. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9789654508343415,
        0.9473626922010148,
        0.9586798479334747,
        0.9506349988188355,
        0.8160539326413832,
        0.9423564989998067,
        0.8487246798327494
      ],
      "excerpt": "The method GPT-2 uses to generate text is slightly different than those like other packages like textgenrnn (specifically, generating the full text sequence purely in the GPU and decoding it later), which cannot easily be fixed without hacking the underlying model code. As a result: \nIn general, GPT-2 is better at maintaining context over its entire generation length, making it good for generating conversational text. The text is also generally gramatically correct, with proper capitalization and few typoes. \nThe original GPT-2 model was trained on a very large variety of sources, allowing the model to incorporate idioms not seen in the input text. \nGPT-2 can only generate a maximum of 1024 tokens per request (about 3-4 paragraphs of English text). \nGPT-2 cannot stop early upon reaching a specific end token. (workaround: pass the truncate parameter to a generate function to only collect text until a specified end token. You may want to reduce length appropriately.) \nHigher temperatures work better (e.g. 0.7 - 1.0) to generate more interesting text, while other frameworks work better between 0.2 - 0.5. \nWhen finetuning GPT-2, it has no sense of the beginning or end of a document within a larger text. You'll need to use a bespoke character sequence to indicate the beginning and end of a document. Then while generating, you can specify a prefix targeting the beginning token sequences, and a truncate targeting the end token sequence. You can also set include_prefix=False to discard the prefix token while generating (e.g. if it's something unwanted like &lt;|startoftext|&gt;). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8784568605430112,
        0.9889201134784773
      ],
      "excerpt": "GPT-2 allows you to generate texts in parallel by setting a batch_size that is divisible into nsamples, resulting in much faster generation. Works very well with a GPU (can set batch_size up to 20 on Colaboratory's K80)! \nDue to GPT-2's architecture, it scales up nicely with more powerful GPUs. For the 124M model, if you want to train for longer periods of time, GCP's P100 GPU is about 3x faster than a K80/T4 for only 3x the price, making it price-comparable (the V100 is about 1.5x faster than the P100 but about 2x the price). The P100 uses 100% of the GPU even with batch_size=1, and about 88% of the V100 GPU. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9757656511129297,
        0.8541655471518256,
        0.8749734206913667
      ],
      "excerpt": "The 1558M \"extra large\", true model, may not work out-of-the-box with the GPU included with the Colaboratory Notebook. More testing is needed to identify optimial configurations for it. \ngpt2-small \u2014 App using the default GPT-2 124M pretrained model \ngpt2-reddit \u2014 App to generate Reddit titles based on a specified subreddit and/or keyword(s) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Python package to easily retrain OpenAI's GPT-2 text-generating model on new texts",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/minimaxir/gpt-2-simple/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 603,
      "date": "Wed, 29 Dec 2021 23:20:32 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/minimaxir/gpt-2-simple/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "minimaxir/gpt-2-simple",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/minimaxir/gpt-2-simple/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "gpt-2-simple can be installed [via PyPI](https://pypi.org/project/gpt_2_simple/):\n\n```shell\npip3 install gpt-2-simple\n```\n\nYou will also need to install the corresponding TensorFlow 2.X version (min 2.5.1) for your system (e.g. `tensorflow` or `tensorflow-gpu`).\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8658180905571831
      ],
      "excerpt": "If your input text dataset is massive (>100 MB), you may want to preencode and compress the dataset using gpt2.encode_dataset(file_path). THe output is a compressed .npz file which will load much faster into the GPU for finetuning. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/minimaxir/gpt-2-simple/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/minimaxir/gpt-2-simple/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019-2020 Max Woolf\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n\\n---\\n\\nMIT License\\n\\nCopyright (c) 2019 OpenAI\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "gpt-2-simple",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "gpt-2-simple",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "minimaxir",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/minimaxir/gpt-2-simple/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "Thanks to https://github.com/YaleDHLab via https://github.com/minimaxir/gpt-2-simple/pull/275, gpt-2-simple now supports TensorFlow 2 by default, and the minimum TensorFlow version is now 2.5.1! The Colab Notebook has also been update to no longer use TensorFlow 1.X.\r\n\r\nNote: Development on gpt-2-simple has mostly been superceded by [aitextgen](https://github.com/minimaxir/aitextgen), which has similar AI text generation capabilities with more efficient training time and resource usage. If you do not require using TensorFlow, I recommend using aitextgen instead. Checkpoints trained using gpt-2-simple can be [loaded using aitextgen](https://docs.aitextgen.io/gpt-2-simple/) as well.\r\n\r\n",
        "dateCreated": "2021-10-18T01:45:21Z",
        "datePublished": "2021-10-18T02:38:39Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.8.1",
        "name": "v0.8.1: TensorFlow 2 support",
        "tag_name": "v0.8.1",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.8.1",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/51509235",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.8.1"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "* Switched the model URL from GCP to Azure. (#253) \r\n* Pin TensorFlow 1.15 (#200)\r\n* Add checkpoint loading from other checkpoints (#175)",
        "dateCreated": "2021-02-14T19:39:38Z",
        "datePublished": "2021-02-14T21:13:20Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.7.2",
        "name": "Fix model URL",
        "tag_name": "v0.7.2",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.7.2",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/38035947",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.7.2"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "Some have successfully finetuned 774M/1558M, so the assert has been removed.",
        "dateCreated": "2019-12-28T04:00:46Z",
        "datePublished": "2019-12-28T04:05:21Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.7.1",
        "name": "Remove finetuning asserts",
        "tag_name": "v0.7.1",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.7.1",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/22493389",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.7.1"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "* Multi-GPU support (#127) (not fully tested; will add some docs when done)\r\n* Fixed checkpoint dir bug (#134)\r\n* Added a hard assert of a TensorFlow version >= 2.0 is used (#137)",
        "dateCreated": "2019-12-01T18:29:25Z",
        "datePublished": "2019-12-01T18:39:34Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.7",
        "name": "Multi-GPU support + TF 2.0 assert",
        "tag_name": "v0.7",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.7",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/21880561",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.7"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "* 774M is explicitly blocked from being fine-tuned and will trigger an assert if attempted. If a way to finetune it without being super-painful is added, the ability to finetune it will be restored.\r\n* Allow ability to generate text from the default pretrained models by passing `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()` (this _will_ work with 774M.\r\n* Add`sgd` as an `optimizer` parameter to `finetune` (default: `adam`)\r\n* Support for changed model names, w/ changes more prominent in the README.",
        "dateCreated": "2019-08-28T17:07:19Z",
        "datePublished": "2019-08-28T17:11:35Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.6",
        "name": "Handle 774M (large)",
        "tag_name": "v0.6",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.6",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/19599669",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.6"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "Merged a few PRs:\r\n\r\nFixed generate cmd run name: #78 \r\nResolved most depreciation warnings: #83 \r\nOptional model parameters: #90 \r\n\r\nThis does not make the package fully TF 2.0 compatible, but it's a big step!\r\n\r\n",
        "dateCreated": "2019-07-28T23:58:54Z",
        "datePublished": "2019-07-29T00:07:52Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.5.4",
        "name": "Polish before TF 2.0",
        "tag_name": "v0.5.4",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.5.4",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/18915422",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.5.4"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "Assertion was triggering false positives, so removing it.",
        "dateCreated": "2019-06-19T05:31:25Z",
        "datePublished": "2019-06-19T05:35:46Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.5.3",
        "name": "Remove assertion",
        "tag_name": "v0.5.3",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.5.3",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/18081952",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.5.3"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "Minor fix to prevent issue hit with gpt-2-cloud-run.\r\n\r\nA goal of the release was to allow a graph reset without resetting the parameters; that did not seem to work, so holding off on that release.",
        "dateCreated": "2019-06-16T17:18:09Z",
        "datePublished": "2019-06-18T04:00:18Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.5.2",
        "name": "Prevent OOB + Cap Gen Length",
        "tag_name": "v0.5.2",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.5.2",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/18052430",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.5.2"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "Merged PRs (including fix for prefix issue). (see commits for more info)",
        "dateCreated": "2019-06-16T03:12:04Z",
        "datePublished": "2019-06-16T03:16:49Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.5.1",
        "name": "Fixed prefix + miscellaneous bug fixes",
        "tag_name": "v0.5.1",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.5.1",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/18019576",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.5.1"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "## Adapted a few functions from Neil Shepperd's fork:\r\n\t\r\n* Nucleus Sampling (`top_p`) when generating text, which results in surprisingly different results. (setting `top_p=0.9` works well). Supercedes `top_k` when used. (#51)\r\n* An `encode_dataset()` function to preencode and compress a large dataset before loading it for finetuning. (#19, #54)\r\n\r\n## Improvements to continuing model training:\r\n\r\n* `overwrite` argument for `finetune`: with `restore_from=\"latest\"`, this continues model training without creating a duplicate copy of the model, and is therefore good for transfer learning using multiple datasets (#20)\r\n* You can continue to `finetune` a model without having the original GPT-2 model present.\r\n\t\r\n## Improvements with I/O involving Colaboratory\r\n* Checkpoint folders are now packaged into a `.tar` file when copying to Google Drive, and when copying from Google Drive, the '.tar' file is automatically unpackaged into the correct checkpoint format. (you can pass `copy_folder=True` to the `copy_checkpoint` function to revert to the old behavior). (#37: thanks @woctezuma !)\r\n* `copy_checkpoint_to_gdrive` and `copy_checkpoint_from_gdrive` now take a `run_name` argument instead of a `checkpoint_folder` argument.\r\n\r\n## Miscellaneous\r\n\r\n* Added CLI arguments for `top_k`, `top_p`, `overwrite`.\r\n* Cleaned up redundant function parameters (#39)",
        "dateCreated": "2019-05-20T03:45:08Z",
        "datePublished": "2019-05-20T03:53:44Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.5",
        "name": "A bunch of highly-requested features",
        "tag_name": "v0.5",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.5",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/17452596",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.5"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "* `load_gpt2()` in a fresh session is much faster and uses much less memory when loaded. (for the 117M model, the system will stay under <2 GB RAM which is the critical point for cloud services)\r\n* `start_tf_sess()` now accepts a `threads` parameter, which is useful if you know exactly how many threads will be used.",
        "dateCreated": "2019-05-05T22:47:02Z",
        "datePublished": "2019-05-05T22:51:19Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.4.2",
        "name": "load_gpt2() improvements",
        "tag_name": "v0.4.2",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.4.2",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/17159911",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.4.2"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "Number of CSV tokens was inadvertently doubled. (#25)",
        "dateCreated": "2019-05-05T16:30:09Z",
        "datePublished": "2019-05-05T16:35:39Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.4.1",
        "name": "Fix CSV Finetuning ",
        "tag_name": "v0.4.1",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.4.1",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/17157660",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.4.1"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "* Support the 345M model (thanks to Neil Shepperd for the [gradient checkpointing](https://github.com/nshepperd/gpt-2/commit/47df6da611716b4826e3397cd68d711c6951c8e5) implementation!)\r\n* Support model_name in the CLI for above support\r\n* Support run_name in the CLI\r\n* Support `.csv` files as an input dataset to `finetune` (will parse the CSV as if it was done via `encode_csv()`).\r\n* Fix one off issues (#21)\r\n",
        "dateCreated": "2019-05-05T05:33:33Z",
        "datePublished": "2019-05-05T05:39:39Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.4",
        "name": "345M model support",
        "tag_name": "v0.4",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.4",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/17153830",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.4"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "* Fix one-off error where checkpoint saved a step early.\r\n* Fix issue where `restore_from='fresh` uses the counter from a previously-trained checkpoint.\r\n* If `restore_from='latest` , `steps` will now train for the specified amount of steps, instead of the training until the specified number of steps. (#13, #14)",
        "dateCreated": "2019-04-23T03:30:12Z",
        "datePublished": "2019-04-23T03:36:14Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.3.1",
        "name": "Better restore and checkpoint behavior",
        "tag_name": "v0.3.1",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.3.1",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/16910699",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.3.1"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "* Added a basic CLI.\r\n* Added a `include_prefix` parameter to give an option to exclude the input prefix.\r\n* Improved regex for truncation.",
        "dateCreated": "2019-04-21T17:17:50Z",
        "datePublished": "2019-04-21T17:20:52Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.3",
        "name": "CLI",
        "tag_name": "v0.3",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.3",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/16888254",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.3"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "* `is_gpt2_downloaded`: Check if the model is downloaded.\r\n* `encode_csv`: Convert a CSV to a format suitable for GPT-2.",
        "dateCreated": "2019-04-20T17:40:20Z",
        "datePublished": "2019-04-20T17:43:16Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.2",
        "name": "More utility functions",
        "tag_name": "v0.2",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.2",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/16881866",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.2"
      },
      {
        "authorType": "User",
        "author_name": "minimaxir",
        "body": "",
        "dateCreated": "2019-04-18T23:35:48Z",
        "datePublished": "2019-04-19T00:19:44Z",
        "html_url": "https://github.com/minimaxir/gpt-2-simple/releases/tag/v0.1",
        "name": "Initial release",
        "tag_name": "v0.1",
        "tarball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/tarball/v0.1",
        "url": "https://api.github.com/repos/minimaxir/gpt-2-simple/releases/16861487",
        "zipball_url": "https://api.github.com/repos/minimaxir/gpt-2-simple/zipball/v0.1"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2840,
      "date": "Wed, 29 Dec 2021 23:20:32 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "text-generation",
      "tensorflow",
      "openai",
      "textgenrnn"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "An example for downloading the model to the local system, finetuning it on a dataset. and generating some text.\n\nWarning: the pretrained 124M model, and thus any finetuned model, is 500 MB! (the pretrained 355M model is 1.5 GB)\n\n```python\nimport gpt_2_simple as gpt2\nimport os\nimport requests\n\nmodel_name = \"124M\"\nif not os.path.isdir(os.path.join(\"models\", model_name)):\n\tprint(f\"Downloading {model_name} model...\")\n\tgpt2.download_gpt2(model_name=model_name)   #: model is saved into current directory under /models/124M/\n\n\nfile_name = \"shakespeare.txt\"\nif not os.path.isfile(file_name):\n\turl = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n\tdata = requests.get(url)\n\n\twith open(file_name, 'w') as f:\n\t\tf.write(data.text)\n\n\nsess = gpt2.start_tf_sess()\ngpt2.finetune(sess,\n              file_name,\n              model_name=model_name,\n              steps=1000)   #: steps is max number of training steps\n\ngpt2.generate(sess)\n```\n\nThe generated model checkpoints are by default in `/checkpoint/run1`. If you want to load a model from that folder and generate text from it:\n\n```python\nimport gpt_2_simple as gpt2\n\nsess = gpt2.start_tf_sess()\ngpt2.load_gpt2(sess)\n\ngpt2.generate(sess)\n```\n\nAs with textgenrnn, you can generate and save text for later use (e.g. an API or a bot) by using the `return_as_list` parameter.\n\n```python\nsingle_text = gpt2.generate(sess, return_as_list=True)[0]\nprint(single_text)\n```\n\nYou can pass a `run_name` parameter to `finetune` and `load_gpt2` if you want to store/load multiple models in a `checkpoint` folder.\n\nThere is also a command-line interface for both finetuning and generation with strong defaults for just running on a Cloud VM w/ GPU. For finetuning (which will also download the model if not present):\n\n```shell\ngpt_2_simple finetune shakespeare.txt\n```\n\nAnd for generation, which generates texts to files in a `gen` folder:\n\n```shell\ngpt_2_simple generate\n```\n\nMost of the same parameters available in the functions are available as CLI arguments, e.g.:\n\n```shell\ngpt_2_simple generate --temperature 1.0 --nsamples 20 --batch_size 20 --length 50 --prefix \"<|startoftext|>\" --truncate \"<|endoftext|>\" --include_prefix False --nfiles 5\n```\n\nSee below to see what some of the CLI arguments do.\n\nNB: _Restart the Python session first_ if you want to finetune on another dataset or load another model.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- [ResetEra](https://www.resetera.com/threads/i-trained-an-ai-on-thousands-of-resetera-thread-conversations-and-it-created-hot-gaming-shitposts.112167/) \u2014 Generated video game forum discussions ([GitHub w/ dumps](https://github.com/minimaxir/resetera-gpt-2))\n- [/r/legaladvice](https://www.reddit.com/r/legaladviceofftopic/comments/bfqf22/i_trained_a_moreadvanced_ai_on_rlegaladvice/) \u2014 Title generation ([GitHub w/ dumps](https://github.com/minimaxir/legaladvice-gpt2))\n- [Hacker News](https://github.com/minimaxir/hacker-news-gpt-2) \u2014 Tens of thousands of generated Hacker News submission titles\n\n",
      "technique": "Header extraction"
    }
  ]
}
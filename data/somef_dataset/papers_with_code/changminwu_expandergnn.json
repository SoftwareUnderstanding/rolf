{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2109.00909",
      "https://arxiv.org/abs/2003.00982",
      "https://arxiv.org/abs/2004.05718",
      "https://arxiv.org/abs/2003.00982",
      "https://arxiv.org/abs/2003.00982",
      "https://arxiv.org/abs/2003.00982",
      "https://arxiv.org/abs/2003.00982",
      "https://arxiv.org/abs/1902.07153"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{lutzeyer2021sparsifying,\n      title={Sparsifying the Update Step in Graph Neural Networks}, \n      author={Johannes F. Lutzeyer and Changmin Wu and Michalis Vazirgiannis},\n      year={2021},\n      eprint={2109.00909},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8794478376855441,
        0.8565478440117127
      ],
      "excerpt": "Accuracy for Graph (ENZYMES/Proteins) and Node (ogbn-arxiv) Classification  \n| Methods\\Datasets | ENZYMES | Proteins | ogbn-arxiv | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488,
        0.9222383658450612
      ],
      "excerpt": "Johannes F. Lutzeyer* \nChangmin Wu* \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ChangminWu/ExpanderGNN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-31T14:57:28Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-05T22:15:24Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9948465589545633
      ],
      "excerpt": "This repository is the official implementation of Sparsifying the Update Step in Graph Neural Networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9836117783875962
      ],
      "excerpt": "Our implementation follows the pipeline proposed in Dwivedi et al. 2020. We modify the code from their original repo to add expander and activation-only implementations in the layers and nets folders. Note that for the Principal Neighbourhood Aggregation (PNA) model, which was not initially included in Dwivedi et al. 2020, we have included the code from the official implementation with small modifications to adjust to the Dwivedi et al. 2020 pipeline. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "expander layer embedded with graph neural network for better efficiency and generality ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/changminwu/expandergnn/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 18:28:32 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ChangminWu/ExpanderGNN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ChangminWu/ExpanderGNN",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/changminwu/expandergnn/public/scripts/citations.sh",
      "https://raw.githubusercontent.com/changminwu/expandergnn/public/scripts/tus.sh"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ChangminWu/ExpanderGNN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Sparsifying the Update Step in Graph Neural Networks",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ExpanderGNN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ChangminWu",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ChangminWu/ExpanderGNN/blob/public/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "An appropriate virtual environment can be created by `conda`  using the provided environments file,\n```\nconda env create -f environments.yml\n```\n\nNotice that the [deep graph library](https://www.dgl.ai/) (dgl) is required to be the latest release(>=0.6.0). It thus needs to be installed separately via\n```\npip install dgl-cu101\n``` \n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Sun, 26 Dec 2021 18:28:32 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To run the full batch of experiments shown in the paper, simply execute the bash file in `scripts`, e.g. to run the experiments comparing the expander model, activation-only model, SGC and vanilla model on the TU datasets, execute\n```\nbash scripts/tus.sh\n```\n\nTo replicate the result of a specific model on a single dataset, for example, the experiment of the expander model with 10% density on the arxiv dataset can be reproduced by\n\n```\npython main_arxiv_node_classification.py --dataset arxiv --out_dir ./example/ --experiment \"expander-density-0.1\" --model GCN --linear_type expander --density 0.1 --activations relu --config ./configs/citation_node_classification/GCN_citation_100k.json --mlp_layers 1 --use_gpu True\n```\n\nDifferent model types can be experimented with by choosing the input to the parameter `linear_type` from `expander`/`regular` and to the parameter `model` from `GCN`/`ActivationGCN`/`SimpleGCN`.\n\nThis repository contains code for reproducing experiments on four TU datasets (ENZYMES/DD/Proteins-full/IMDB-Binary integrated in [deep graph library](https://www.dgl.ai/)) and four Citation Datasets (Cora/Citeseer/Pubmed integrated in [deep graph library](https://www.dgl.ai/), ogbn-arxiv integrated in [open graph benchmark](https://ogb.stanford.edu/)).\n\nHyperparameters for model training of each dataset are stored in the `configs` folder. We take hyperparameters settings from the benchmark paper [Dwivedi et al. 2020](https://arxiv.org/abs/2003.00982), where they share the sets of hyperparameters that give their benchmark results. For the citation datasets which are not included in [Dwivedi et al. 2020](https://arxiv.org/abs/2003.00982), we take hyperparameters settings that are shared by their official implementations in [SGC](https://arxiv.org/abs/1902.07153) and [open graph benchmark](https://ogb.stanford.edu/).\n\n",
      "technique": "Header extraction"
    }
  ]
}
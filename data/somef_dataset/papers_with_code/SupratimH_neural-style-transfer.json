{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1508.06576",
      "https://arxiv.org/abs/1508.06576\n* TensorFlow Implementation of Neural Style Painting by Log0: http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style\n* Karen Simonyan and Andrew Zisserman (2015"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Leon A. Gatys, Alexander S. Ecker, Matthias Bethge, (2015). A Neural Algorithm of Artistic Style: https://arxiv.org/abs/1508.06576\n* TensorFlow Implementation of Neural Style Painting by Log0: http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style\n* Karen Simonyan and Andrew Zisserman (2015). Very deep convolutional networks for large-scale image recognition: https://arxiv.org/pdf/1409.1556.pdf\n* MatConvNet: http://www.vlfeat.org/matconvnet/pretrained/\n* Course on \"Convolution Neural Network\" by https://www.deeplearning.ai/ on Coursera.\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SupratimH/neural-style-transfer",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-22T10:58:53Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-11T09:36:31Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9457903110856587
      ],
      "excerpt": "Introduction and Explanation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9824573800372804,
        0.9858701722704198
      ],
      "excerpt": "This is an implementation of Neural Style Transfer algorithm using Tensorflow. The NST algorithm was created by Leon A. Gatys, Alexander S. Ecker and Matthias Bethge, as described in the famous paper A Neural Algorithm of Artistic Style. \nThe core idea is to use the filter responses from different layers of a CNN (i.e. the activation values of the layers) of a convolutional network to build the style. Filter responses from different layers (ranging from lower to higher) captures from low level details (strokes, points, corners) to high level details (patterns, objects, etc) is used to modify the content image, i.e. apply the style on content image, and thus \"generate\" the final \"painted\" image. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This is an implementation of Neural Style Transfer algorithm using Tensorflow, to programatically paint an image following the style of another image using Neural Style Transfer algorithm.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SupratimH/neural-style-transfer/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 03:53:26 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/SupratimH/neural-style-transfer/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "SupratimH/neural-style-transfer",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/SupratimH/neural-style-transfer/master/art-generation-with-nst.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8615664156311618
      ],
      "excerpt": "<b>Here's an example:</b> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9323293186995936
      ],
      "excerpt": "<img src=\"samples/RRV-the-milkmaid.jpg\" width=\"400px\" height=\"600px\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9192470667383308
      ],
      "excerpt": "<img src=\"samples/Van_Gogh-Style-400x600.jpg\" width=\"400px\" height=\"600px\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9323293186995936
      ],
      "excerpt": "<img src=\"samples/RRV-the-milkmaid_to_VanGogh.jpg\" width=\"400px\" height=\"600px\"/> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/SupratimH/neural-style-transfer/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Supratim Haldar\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Neural Style Transfer : Generating art using Deep Learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "neural-style-transfer",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "SupratimH",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SupratimH/neural-style-transfer/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Python3\n- TensorFlow\n- Scipy\n- Numpy\n- Matplotlib\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Close this repository in your local system - `git clone https://github.com/SupratimH/neural-style-transfer.git` or `git clone git@github.com:SupratimH/neural-style-transfer.git`.\n2. Copy your content and style images into `images` directory.\n3. Make sure both are of exactly same dimensions (dim of 400 x 600 have been used in this code).\n4. Update the image file names in `content_image` and `style_image` variables in `art-generation-with-nst.ipynb`.\n5. Update the dimensions in `IMAGE_WIDTH` and `IMAGE_HEIGHT` variables in `nst_utils.py`.\n6. Download the pre-trained VGG-19 model from http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat and save into `pretrained-model` directory.\n7. Run the notebook.\n8. Experiment with content and style loss hyperparamters, activation layers from which to extract style and number of epochs.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 03:53:26 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "neural-style-transfer",
      "deep-learning",
      "convolutional-neural-networks",
      "tensorflow"
    ],
    "technique": "GitHub API"
  }
}
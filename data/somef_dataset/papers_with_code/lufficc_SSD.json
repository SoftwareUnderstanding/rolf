{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1512.02325",
      "https://arxiv.org/abs/1706.02677"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use this project in your research, please cite this project.\n```text\n@misc{lufficc2018ssd,\n    author = {Congcong Li},\n    title = {{High quality, fast, modular reference implementation of SSD in PyTorch}},\n    year = {2018},\n    howpublished = {\\url{https://github.com/lufficc/SSD}}\n}\n```",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "This repository implements [SSD (Single Shot MultiBox Detector)](https://arxiv.org/abs/1512.02325). The implementation is heavily influenced by the projects [ssd.pytorch](https://github.com/amdegroot/ssd.pytorch), [pytorch-ssd](https://github.com/qfgaohao/pytorch-ssd) and [maskrcnn-benchmark](https://github.com/facebookresearch/maskrcnn-benchmark). This repository aims to be the code base for researches based on SSD.\n\n<div align=\"center\">\n  <img src=\"figures/004545.jpg\" width=\"500px\" />\n  <p>Example SSD output (vgg_ssd300_voc0712).</p>\n</div>\n\n| Losses        | Learning rate | Metrics |\n| :-----------: |:-------------:| :------:|\n| ![losses](figures/losses.png) | ![lr](figures/lr.png) | ![metric](figures/metrics.png) |\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{lufficc2018ssd,\n    author = {Congcong Li},\n    title = {{High quality, fast, modular reference implementation of SSD in PyTorch}},\n    year = {2018},\n    howpublished = {\\url{https://github.com/lufficc/SSD}}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lufficc/SSD",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-12-06T20:19:33Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-29T15:00:01Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8342514600536364,
        0.8385420605236519
      ],
      "excerpt": "Modular: Add your own modules without pain. We abstract backbone,Detector, BoxHead, BoxPredictor, etc. You can replace every component with your own code without change the code base. For example, You can add EfficientNet as backbone, just add efficient_net.py (ALREADY ADDED) and register it, specific it in the config file, It's done! \nCPU support for inference: runs on CPU in inference time. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8263183245020543,
        0.8679979622619757
      ],
      "excerpt": "Evaluating during training: eval you model every eval_step to check performance improving or not. \nMetrics Visualization: visualize metrics details in tensorboard, like AP, APl, APm and APs for COCO dataset or mAP and 20 categories' AP for VOC dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9497833143719322
      ],
      "excerpt": "The configuration files that I provide assume that we are running on single GPU. When changing number of GPUs, hyper-parameter (lr, max_iter, ...) will also changed according to this paper: Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503994816348221,
        0.9503994816348221
      ],
      "excerpt": "|  VGG16         |     300     |          25.2                    |  262MB     | model   | \n|  VGG16         |     512     |          29.0                    |  275MB     | model   | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "High quality, fast, modular reference implementation of SSD in PyTorch",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lufficc/SSD/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 340,
      "date": "Wed, 29 Dec 2021 21:41:03 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lufficc/SSD/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "lufficc/SSD",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you want to add your custom components, please see [DEVELOP_GUIDE.md](DEVELOP_GUIDE.md) for more details.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\ngit clone https://github.com/lufficc/SSD.git\ncd SSD\n#: Required packages: torch torchvision yacs tqdm opencv-python vizer\npip install -r requirements.txt\n\n#: Done! That's ALL! No BUILD! No bothering SETUP!\n\n#: It's recommended to install the latest release of torch and torchvision.\n```\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9337081600027858
      ],
      "excerpt": "PyTorch 1.0: Support PyTorch 1.0 or higher. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9080995630111424
      ],
      "excerpt": "For COCO dataset, make the folder structure like this: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.805368058816112
      ],
      "excerpt": "Multi-GPU training and inference: We use DistributedDataParallel, you can train or test with arbitrary GPU(s), the training schema will change accordingly. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8186108976554061
      ],
      "excerpt": "Smooth and enjoyable training procedure: we save the state of model, optimizer, scheduler, training iter, you can stop your training and resume training exactly from the save point without change your training CMD. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9017476345090184,
        0.9416108394108788
      ],
      "excerpt": ": for example, train SSD300: \npython train.py --config-file configs/vgg_ssd300_voc0712.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8812328809377157
      ],
      "excerpt": ": for example, train SSD300 with 4 GPUs: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.870708452099263
      ],
      "excerpt": "python -m torch.distributed.launch --nproc_per_node=$NGPUS train.py --config-file configs/vgg_ssd300_voc0712.yaml SOLVER.WARMUP_FACTOR 0.03333 SOLVER.WARMUP_ITERS 1000 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9421349442707512
      ],
      "excerpt": "python test.py --config-file configs/vgg_ssd300_voc0712.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8924011283878642
      ],
      "excerpt": "python -m torch.distributed.launch --nproc_per_node=$NGPUS test.py --config-file configs/vgg_ssd300_voc0712.yaml \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lufficc/SSD/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 lufficc\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "High quality, fast, modular reference implementation of SSD in PyTorch 1.0",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SSD",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "lufficc",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lufficc/SSD/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "lufficc",
        "body": "- **PyTorch 1.0**: Support PyTorch 1.0 or higher.\r\n- **Multi-GPU training and inference**: We use `DistributedDataParallel`, you can train or test with arbitrary GPU(s), the training schema will change accordingly.\r\n- **Modular**: Add your own modules without pain. We abstract `backbone`,`Detector`, `BoxHead`, `BoxPredictor`, etc. You can replace every component with your own code without change the code base. For example, You can add [EfficientNet](https://github.com/lukemelas/EfficientNet-PyTorch) as backbone, just add `efficient_net.py` (ALREADY ADDED) and register it, specific it in the config file, It's done!\r\n- **CPU support for inference**: runs on CPU in inference time.\r\n- **Smooth and enjoyable training procedure**: we save the state of model, optimizer, scheduler, training iter, you can stop your training and resume training exactly from the save point without change your training `CMD`.\r\n- **Batched inference**: can perform inference using multiple images per batch per GPU.\r\n- **Evaluating during training**: eval you model every `eval_step` to check performance improving or not.\r\n- **Metrics Visualization**: visualize metrics details in tensorboard, like AP, APl, APm and APs for COCO dataset or mAP and 20 categories' AP for VOC dataset.\r\n- **Auto download**: load pre-trained weights from URL and cache it.",
        "dateCreated": "2019-07-01T17:06:51Z",
        "datePublished": "2019-07-01T17:09:05Z",
        "html_url": "https://github.com/lufficc/SSD/releases/tag/1.2",
        "name": "More modular!",
        "tag_name": "1.2",
        "tarball_url": "https://api.github.com/repos/lufficc/SSD/tarball/1.2",
        "url": "https://api.github.com/repos/lufficc/SSD/releases/18337919",
        "zipball_url": "https://api.github.com/repos/lufficc/SSD/zipball/1.2"
      },
      {
        "authorType": "User",
        "author_name": "lufficc",
        "body": "",
        "dateCreated": "2019-05-22T17:09:28Z",
        "datePublished": "2019-06-24T02:51:37Z",
        "html_url": "https://github.com/lufficc/SSD/releases/tag/1.1",
        "name": "Bug fix release.",
        "tag_name": "1.1",
        "tarball_url": "https://api.github.com/repos/lufficc/SSD/tarball/1.1",
        "url": "https://api.github.com/repos/lufficc/SSD/releases/18170818",
        "zipball_url": "https://api.github.com/repos/lufficc/SSD/zipball/1.1"
      },
      {
        "authorType": "User",
        "author_name": "lufficc",
        "body": "- PyTorch 1.0\r\n- GPU/CPU NMS\r\n- Multi-GPU training and inference\r\n- Modular\r\n- Visualization(Support Tensorboard)\r\n- CPU support for inference\r\n- Evaluating during training\r\n\r\n",
        "dateCreated": "2018-12-20T07:18:10Z",
        "datePublished": "2018-12-07T20:41:50Z",
        "html_url": "https://github.com/lufficc/SSD/releases/tag/v1.0.1",
        "name": "Second Release",
        "tag_name": "v1.0.1",
        "tarball_url": "https://api.github.com/repos/lufficc/SSD/tarball/v1.0.1",
        "url": "https://api.github.com/repos/lufficc/SSD/releases/14417098",
        "zipball_url": "https://api.github.com/repos/lufficc/SSD/zipball/v1.0.1"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Python3\n1. PyTorch 1.0 or higher\n1. yacs\n1. [Vizer](https://github.com/lufficc/Vizer)\n1. GCC >= 4.9\n1. OpenCV\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1197,
      "date": "Wed, 29 Dec 2021 21:41:03 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "ssd",
      "pytorch",
      "computer-vision",
      "deep-learning",
      "object-detection"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Predicting image in a folder is simple:\n```bash\npython demo.py --config-file configs/vgg_ssd300_voc0712.yaml --images_dir demo --ckpt https://github.com/lufficc/SSD/releases/download/1.2/vgg_ssd300_voc0712.pth\n```\nThen it will download and cache `vgg_ssd300_voc0712.pth` automatically and predicted images with boxes, scores and label names will saved to `demo/result` folder by default.\n\nYou will see a similar output:\n```text\n(0001/0005) 004101.jpg: objects 01 | load 010ms | inference 033ms | FPS 31\n(0002/0005) 003123.jpg: objects 05 | load 009ms | inference 019ms | FPS 53\n(0003/0005) 000342.jpg: objects 02 | load 009ms | inference 019ms | FPS 51\n(0004/0005) 008591.jpg: objects 02 | load 008ms | inference 020ms | FPS 50\n(0005/0005) 000542.jpg: objects 01 | load 011ms | inference 019ms | FPS 53\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
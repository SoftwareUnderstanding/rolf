{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nIf you find this useful in your research, please consider citing:\r\n\r\n    @inproceedings{shrivastavaCVPR16ohem,\r\n        Author = {Abhinav Shrivastava and Abhinav Gupta and Ross Girshick},\r\n        Title = {Training Region-based Object Detectors with Online Hard Example Mining},\r\n        Booktitle = {Conference on Computer Vision and Pattern Recognition ({CVPR})},\r\n        Year = {2016}\r\n    }\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{shrivastavaCVPR16ohem,\n    Author = {Abhinav Shrivastava and Abhinav Gupta and Ross Girshick},\n    Title = {Training Region-based Object Detectors with Online Hard Example Mining},\n    Booktitle = {Conference on Computer Vision and Pattern Recognition ({CVPR})},\n    Year = {2016}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8906174419333412
      ],
      "excerpt": "|FRCN                    | VOC 12 trainval                     | VOC 12 test  | 65.7   |  | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8747944513936825
      ],
      "excerpt": "Legend: +M: using multi-scale for training and testing, +B: multi-stage bounding box regression. See the paper for details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8291560749894474
      ],
      "excerpt": "[ ] Support for Multi-stage bounding box regression \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/abhi2610/ohem",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-06-23T18:33:08Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-29T10:53:45Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Online Hard Example Mining (OHEM) is an online bootstrapping algorithm for training region-based ConvNet object detectors like [Fast R-CNN](https://github.com/rbgirshick/fast-rcnn). OHEM \r\n- works nicely in the Stochastic Gradient Descent (SGD) paradigm,\r\n- simplifies training by removing some heuristics and hyperparameters,\r\n- leads to better convergence (lower training set loss),\r\n- consistently gives significanlty higher mAP on PASCAL VOC and MS COCO.\r\n\r\nOHEM was initially presented at CVPR 2016 as an Oral Presentation. For more details, see the [arXiv tech report](http://arxiv.org/abs/1604.03540).\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9938900060656993
      ],
      "excerpt": "This implementation is built on a fork of Faster R-CNN Python code (here), which in turn builds on Fast R-CNN (here). Please cite the appropriate papers depending on which part of the code and/or model you are using. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9388327024746866
      ],
      "excerpt": "Note: All methods above use the VGG16 network. mAP (paper) is the mAP reported in the paper. mAP (this repo) is the mAP reproduced by this codebase. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8579211235531208,
        0.9566821816132794
      ],
      "excerpt": "[ ] Scripts/models for results in this Table \n[ ] Support for Faster R-CNN (see below) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "OHEM support for Fast R-CNN",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nPre-trained ImageNet models can be downloaded for the two networks described in the paper: VGG_CNN_M_1024 and VGG16.\r\n\r\n```Shell\r\ncd $OHEM_ROOT\r\n./data/scripts/fetch_imagenet_models.sh\r\n```\r\nModels come from the [Caffe Model Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo), but are provided here for your convenience..\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/abhi2610/ohem/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nI have received a lot of queries regarding using OHEM with Faster R-CNN. I have not spent too much time combining OHEM with Faster R-CNN yet. Some researchers have informed me that OHEM works well in the 'alternating optimization' setup, but not so much with the 'end to end learning' setup. I hope to try and release the support for Faster R-CNN in the coming months. If you would like an update when I release it, send me an email. \r\n\r\nAlso, the authors of [R-FCN](https://github.com/daijifeng001/R-FCN) succesfully used OHEM with R-FCN and Faster R-CNN; you might find their codebase helpful.\r\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 154,
      "date": "Thu, 30 Dec 2021 10:47:44 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/abhi2610/ohem/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "abhi2610/ohem",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/abhi2610/ohem/master/experiments/scripts/fast_rcnn.sh",
      "https://raw.githubusercontent.com/abhi2610/ohem/master/experiments/scripts/fast_rcnn_ohem.sh",
      "https://raw.githubusercontent.com/abhi2610/ohem/master/experiments/scripts/fast_rcnn_ohem_07tv12tv.sh",
      "https://raw.githubusercontent.com/abhi2610/ohem/master/data/scripts/fetch_selective_search_data.sh",
      "https://raw.githubusercontent.com/abhi2610/ohem/master/data/scripts/fetch_fast_rcnn_ohem_models.sh",
      "https://raw.githubusercontent.com/abhi2610/ohem/master/data/scripts/fetch_imagenet_models.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Download the training, validation, test data and VOCdevkit\r\n\r\n  ```Shell\r\n  wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\r\n  wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\r\n  wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCdevkit_08-Jun-2007.tar\r\n  ```\r\n\r\n2. Extract all of these tars into one directory named `VOCdevkit`\r\n\r\n  ```Shell\r\n  tar xvf VOCtrainval_06-Nov-2007.tar\r\n  tar xvf VOCtest_06-Nov-2007.tar\r\n  tar xvf VOCdevkit_08-Jun-2007.tar\r\n  ```\r\n\r\n3. It should have this basic structure\r\n\r\n  ```Shell\r\n    $VOCdevkit/                           #: development kit\r\n    $VOCdevkit/VOCcode/                   #: VOC utility code\r\n    $VOCdevkit/VOC2007                    #: image sets, annotations, etc.\r\n    #: ... and several other directories ...\r\n    ```\r\n\r\n4. Create symlinks for the PASCAL VOC dataset\r\n\r\n  ```Shell\r\n    cd $OHEM_ROOT/data\r\n    ln -s $VOCdevkit VOCdevkit2007\r\n    ```\r\n    Using symlinks is a good idea because you will likely want to share the same PASCAL dataset installation between multiple projects.\r\n5. [Optional] follow similar steps to get PASCAL VOC 2010 and 2012\r\n6. Follow the next sections to download pre-trained ImageNet models\r\n\r\n*COCO instructions and models will be released soon.*\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n1. Clone the OHEM repository\r\n  ```Shell\r\n  #: Make sure to clone with --recursive\r\n  git clone --recursive https://github.com/abhi2610/ohem.git\r\n  ```\r\n\r\n2. We'll call the directory that you cloned OHEM into `OHEM_ROOT`\r\n\r\n   *Ignore notes 1 and 2 if you followed step 1 above.*\r\n\r\n   **Note 1:** If you didn't clone OHEM with the `--recursive` flag, then you'll need to manually clone the `caffe-fast-rcnn` submodule:\r\n    ```Shell\r\n    git submodule update --init --recursive\r\n    ```\r\n    **Note 2:** The `caffe-fast-rcnn` submodule needs to be on the `faster-rcnn` branch (or equivalent detached state). This will happen automatically *if you followed step 1 instructions*.\r\n\r\n3. Build the Cython modules\r\n    ```Shell\r\n    cd $OHEM_ROOT/lib\r\n    make\r\n    ```\r\n\r\n4. Build Caffe and pycaffe\r\n    ```Shell\r\n    cd $OHEM_ROOT/caffe-fast-rcnn\r\n    #: Now follow the Caffe installation instructions here:\r\n    #:   http://caffe.berkeleyvision.org/installation.html\r\n\r\n    #: If you're experienced with Caffe and have all of the requirements installed\r\n    #: and your Makefile.config in place, then simply do:\r\n    make -j8 && make pycaffe\r\n    ```\r\n\r\n5. Download pre-computed Fast R-CNN detector trained with OHEM using VGG16 and VGG_CNN_M_1024 networks.\r\n    ```Shell\r\n    cd $OHEM_ROOT\r\n    ./data/scripts/fetch_fast_rcnn_ohem_models.sh\r\n    ```\r\n    This will populate the `$OHEM_ROOT/data` folder with a `fast_rcnn_ohem_models` folder which contains VGG16 and VGG_CNN_M_1024 models (Fast R-CNN detectors trained with OHEM). \r\n    The format will be `fast_rcnn_ohem_models/TRAINING_SET/MODEL_FILE`.\r\n\r\n*These models were re-trained using this codebase and achieve slightly better performance (see [this Table](#results)). In particular, on the standard split, VGG_CNN_M_1024 model gets 62.8 mAP (compared to 62.0 mAP reported in paper) and VGG16 model gets 71.5 mAP (compared to 69.9 mAP). All models from the paper will be released soon.*\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8864574716181884,
        0.8028459453632889
      ],
      "excerpt": "Requirements: hardware \nBasic installation \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/abhi2610/ohem/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C",
      "Shell",
      "Cuda",
      "MATLAB",
      "C++",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/abhi2610/ohem/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Online Hard Example Mining (OHEM)\\n\\nCopyright (c) 2016, Abhinav Shrivastava\\n\\nThe MIT License (MIT)\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\nTHE SOFTWARE.\\n\\n**********\\n\\nTHIRD-PARTY SOFTWARE NOTICES AND INFORMATION\\n\\nThis project, OHEM, incorporates material from the project(s)\\nlisted below (collectively, \"Third Party Code\"). The original copyright \\nnotice and license of such Third Party Code are set out below. This \\nThird Party Code is licensed to you under their original license terms \\nset forth below.\\n\\n1. Fast R-CNN (https://github.com/rbgirshick/fast-rcnn)\\n\\nCopyright (c) Microsoft Corporation\\n\\nAll rights reserved.\\n\\nMIT License\\n\\nPermission is hereby granted, free of charge, to any person obtaining a\\ncopy of this software and associated documentation files (the \"Software\"),\\nto deal in the Software without restriction, including without limitation\\nthe rights to use, copy, modify, merge, publish, distribute, sublicense,\\nand/or sell copies of the Software, and to permit persons to whom the\\nSoftware is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included\\nin all copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED AS IS*, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\\nTHE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR\\nOTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\\nARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\\nOTHER DEALINGS IN THE SOFTWARE.\\n\\n\\n2. Faster R-CNN (https://github.com/rbgirshick/py-faster-rcnn)\\n\\nThe MIT License (MIT)\\n\\nCopyright (c) 2015 Microsoft Corporation\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\nTHE SOFTWARE.\\n\\n3.\\tCaffe, (https://github.com/BVLC/caffe/)\\n\\nCOPYRIGHT\\n\\nAll contributions by the University of California:\\nCopyright (c) 2014, 2015, The Regents of the University of California (Regents)\\nAll rights reserved.\\n\\nAll other contributions:\\nCopyright (c) 2014, 2015, the respective contributors\\nAll rights reserved.\\n\\nCaffe uses a shared copyright model: each contributor holds copyright\\nover their contributions to Caffe. The project versioning records all\\nsuch contribution and copyright details. If a contributor wants to\\nfurther mark their specific copyright on a particular contribution,\\nthey should indicate their copyright solely in the commit message of\\nthe change when it is committed.\\n\\nThe BSD 2-Clause License\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions\\nare met:\\n\\n1. Redistributions of source code must retain the above copyright notice,\\nthis list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright\\nnotice, this list of conditions and the following disclaimer in the\\ndocumentation and/or other materials provided with the distribution.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\\nTO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\\nPROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\\nLIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\\nNEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n\\n*END OF THIRD-PARTY SOFTWARE NOTICES AND INFORMATION**\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Training Region-based Object Detectors with Online Hard Example Mining",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ohem",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "abhi2610",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/abhi2610/ohem/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n1. Requirements for `Caffe` and `pycaffe` (see: [Caffe installation instructions](http://caffe.berkeleyvision.org/installation.html))\r\n\r\n  **Note:** Caffe *must* be built with support for Python layers!\r\n\r\n  ```make\r\n  #: In your Makefile.config, make sure to have this line uncommented\r\n  WITH_PYTHON_LAYER := 1\r\n  #: Unrelatedly, it's also recommended that you use CUDNN\r\n  USE_CUDNN := 1\r\n  ```\r\n\r\n  You can download Ross's [Makefile.config](http://www.cs.berkeley.edu/~rbg/fast-rcnn-data/Makefile.config) for reference.\r\n2. Python packages you might not have: `cython`, `python-opencv`, `easydict`, `yaaml'\r\n3. [Optional] MATLAB is required for **official** PASCAL VOC evaluation only. The code now includes unofficial Python evaluation code.\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\n1. For training smaller networks (VGG_CNN_M_1024) a good GPU (e.g., Titan, K20, K40, ...) with at least 4G of memory suffices\r\n2. For training VGG16, you'll need a K40 or Titan X (or better).\r\n\r\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 410,
      "date": "Thu, 30 Dec 2021 10:47:44 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nI have received a lot of queries regarding using OHEM with Faster R-CNN. I have not spent too much time combining OHEM with Faster R-CNN yet. Some researchers have informed me that OHEM works well in the 'alternating optimization' setup, but not so much with the 'end to end learning' setup. I hope to try and release the support for Faster R-CNN in the coming months. If you would like an update when I release it, send me an email. \r\n\r\nAlso, the authors of [R-FCN](https://github.com/daijifeng001/R-FCN) succesfully used OHEM with R-FCN and Faster R-CNN; you might find their codebase helpful.\r\n",
      "technique": "Header extraction"
    }
  ],
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "By Abhinav Shrivastava, Abhinav Gupta, Ross Girshick\r\n\r\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "\r\nTo train a Fast R-CNN detector using the **OHEM** algorithm on voc_2007_trainval, use `experiments/scripts/fast_rcnn_ohem.sh`. See `experiments/scripts/` directory for other scripts. Output is written underneath `$OHEM_ROOT/output`.\r\n\r\n```Shell\r\ncd $OHEM_ROOT\r\n./experiments/scripts/fast_rcnn_ohem.sh [GPU_ID] [NET] [--set ...]\r\n#: GPU_ID is the GPU you want to train on\r\n#: NET in {VGG16, VGG_CNN_M_1024} is the network arch to use\r\n#: --set ... allows you to specify fast_rcnn.config options, e.g.\r\n#:   --set EXP_DIR seed_rng1701 RNG_SEED 1701\r\n```\r\n\r\nArtifacts generated by the scripts in `tools` are written in this directory.\r\n\r\nTrained Fast R-CNN networks with OHEM are saved under:\r\n\r\n```\r\noutput/<experiment directory>/<dataset name>/\r\n```\r\n\r\nTest outputs are saved under:\r\n\r\n```\r\noutput/<experiment directory>/<dataset name>/<network snapshot name>/\r\n```\r\n\r\n*The VGG_CNN_M_1024 model should get ~62.8 mAP and VGG16 model should get ~71.5 mAP. For reference, you can download my logs from [here](http://graphics.cs.cmu.edu/projects/ohem/data/logs.tgz).*\r\n\r\n",
      "technique": "Header extraction"
    }
  ]
}
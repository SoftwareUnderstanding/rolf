{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. elastic. 2017. Elasticsearch: RESTful, Distributed Search & Analytics. (2017). https://www.elastic.co/ [Online; accessed 19-June-2017].\n2. ImageNet. 2014. Large Scale Visual Recognition Challenge (ILSVRC). (2014). http://www.image-net.org/challenges/LSVRC/\n3. Jupyter. 2017. The Jupyter Notebook. (2017). h p://jupyter.org/ [Online; ac- cessed 19-June-2017].\n4. Kaggle. 2014. Dogs vs. Cats. (2014). https://www.kaggle.com/c/dogs-vs-cats\n5. keras. 2014. Keras: The Python Deep Learning library. (2014). h ps://keras.io/ [Online; accessed 19-June-2017].\n6. Karen Simonyan and Andrew Zisserman. 2014. Very Deep Convolutional Networks for Large-Scale Image Recognition. CoRR abs/1409.1556 (2014). http://arxiv.org/abs/1409.1556\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9717062456100941
      ],
      "excerpt": "Introduction of Deep Learning for Information Retrieval Researchers in LIARR 2017. (11, Aug. 2017) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9813161029725735,
        0.8834756699654108
      ],
      "excerpt": "def showimg(filename, title, i): \n    im = Image.open(filename) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9992337828809199
      ],
      "excerpt": "    plt.title(title) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9515897314631402
      ],
      "excerpt": "results = predict(filename, 10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8043073075947367
      ],
      "excerpt": "    if es.indices.exists(index=indexname): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "searchimg(filename, 10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "searchimg(filename, 10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "searchimg(filename, 10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "searchimg(filename, 10) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/taniokah/liarr2017",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-07-28T10:32:01Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-13T20:20:51Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9395224566614687,
        0.9967154860679994,
        0.9856597996656631,
        0.994372668916281
      ],
      "excerpt": "Introduction of Deep Learning for Information Retrieval Researchers in LIARR 2017. (11, Aug. 2017) \nThis paper provides detailed suggestions to create an Image Search Engine with Deep Learning. There are still few attempts with Deep Learning on a search engine. Here is a good idea of an extremely easy way of building an image search with Elasticsearch and Keras on Jupyter Notebook. So, it is demonstrated how an image search engine can be created where Keras is used to extract features from images, and Elasticsearch is used for indexing and retrieval.  \nTo demonstrate how easily this can be achieved, Jupyter Notebook is used with two open source libraries, Keras and Elasticsearch. Then, the image search engine can search relevant images by images or keywords. In our approach, keras is regarded as analysis which is a process of converting an image into tokens or terms which are added to the inverted index for searching. \nImage features are extracted by VGG16 [6] model on Keras. VGG team achieved an excellent result with VGG16 model in ILSVRC- 2014 [2] competition. Image features are 1, 000 kinds of ImageNet classes(synsets) which are employed by VGG16 model. Image features which really mean ImageNet class tags are used as word features. Therefore, it is easy to modify using deep image representations or other deep features. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9976223237223371,
        0.995995711533153
      ],
      "excerpt": "The VGG16 model for Keras is pre-trained, which model of the 16-leyers network is used by the VGG team in the ILSVRC-2014. Keras with the VGG16 model calculates and returns tuple of class(synset) and probability from an image. There are pre-defined 1,000 classes. These classes are used as features for a feature vector on Elasticsearch. \nBag-of-Visual-Words is employed for an index of a full-text search engine. Similarity is based on inner product of two vectors. A vector is query image vector is constituted of image features. Another vector is indexed image vector is also constituted of image features. A document contains filename and synset which consists of wind, words, and score from predicted information by Keras. Then, search engine calculates relevance scores based on inner product as similarity between images. So, relevance score is as follows, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9893335819354206,
        0.9175375706804877
      ],
      "excerpt": "where j is the number of synset feature and n is 1,000 as the amount of synset feature. \u03b7<sub>j</sub> is the j th synset feature score of a query image. \u03be<sub>i,j</sub> is the j th synset feature score of an indexed image. \nPython is a programming language that lets you work quickly and integrate systems more effectively.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8834000628464156
      ],
      "excerpt": "Elasticsearch is an open source search engine based on Lucene. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9236392834199408,
        0.9373577151273044
      ],
      "excerpt": "Keras is the Python deep learning library. Keras is compatible with: Python 2.7-3.5 now. \nInstalation is written in the following URL. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9557130574347111
      ],
      "excerpt": "The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9489624095206113
      ],
      "excerpt": "TensorFlow is an open-source software library for Machine Intelligence, which can be used for backend of Keras. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8446487178133608
      ],
      "excerpt": "The indexing function is composed of Keras and Elasticsearch, which indexes dog and cat images as a search target. Keras plays a role of feature extraction. Then, Elasticsearch has an index for image file retrieval. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.869900994786336
      ],
      "excerpt": "model = VGG16(weights='imagenet') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "    for synset in synsets: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "for hit in res['hits']['hits'][0:num]: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8720232529055016
      ],
      "excerpt": "A dog image is the second query. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Introduction of Deep Learning for Information Retrieval Researchers in LIARR 2017. (11, Aug. 2017)",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "It's a competition to classify whether images contain either a dog or a cat. This is easy for humans, dogs, and cats, but computers will find it a bit more difficult.\nThe training archive contains 25,000 images of dogs and cats. Train your algorithm on these files and predict the labels for test1.zip.\n\nhttps://www.kaggle.com/c/dogs-vs-cats/data\n\nYou can download and unzip test1.zip and train.zip. Unzipped files are under 'test1' and 'train' directories.\n\n    $ unzip test1.zip\n \u00a0 \u00a0inflating: test1/1.jpg\n    inflating: test1/2.jpg\n    .\n    .\n    inflating: test1/9998.jpg          \n    inflating: test1/9998.jpg          \n    inflating: test1/9999.jpg      \n\n    $ unzip train.zip\n \u00a0 \u00a0inflating: train/cat.0.jpg\n    inflating: train/cat.1.jpg\n    .\n    .\n    inflating: train/dog.9997.jpg      \n    inflating: train/dog.9998.jpg      \n    inflating: train/dog.9999.jpg      \n\nFor shorter indexing time, 220 images (110 dogs and 110 cats) are copied under 'train/mini' directory.\n\n    $ cd train\n    $ mkdir mini\n    $ for i in `seq 1 110`; do cp cat.$i.jpg mini; done\n    $ for i in `seq 12390 12499`; do cp dog.$i.jpg mini; done\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/taniokah/liarr2017/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Tue, 28 Dec 2021 03:57:40 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/taniokah/liarr2017/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "taniokah/liarr2017",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/taniokah/liarr2017/master/dogs-vs-cats.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We have to install some libraries: Python, Elasticsearch, Keras, Jupyter Notebook, and TensorFlow. Jupyter Notebook and TensorFlow are optional, because Jupyter Notebook is used for my demonstration and Theano or CNTK is available for Kearas instead of TensorFlow.\n\nMy demo environment is MacBook Pro (Retina, 15-inch, Mid 2015). OS X El Capitan (version 10.11), Python 2.7.13 <Anaconda 4.3.1 (x86_64)>, Elasticsearch 5.4.1, Keras 2.0.4, Jupyter Notebook 4.2.1, and TensorFlow 1.1.0 are installed. I guess Python 3+ is OK and Elasticsearch 2+ is also OK. Of course, Linux and Windows are both OK.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9862697345149104,
        0.8840603293480626,
        0.8837680365796365,
        0.9044260868105803
      ],
      "excerpt": "You can download the latest version Python 3.6.2 or Python 2.7.13. Also, Python source code and installers are available for download for all versions. \nIf you want to check the version, just type 'python -V'. \n$ python -V \nPython 2.7.13 :: Anaconda 4.3.1 (x86_64) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9766063803378209
      ],
      "excerpt": "Download package for your platform. Extract .zip or tar.gz file cd into extracted folder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.905040654573603,
        0.999746712887969
      ],
      "excerpt": "Additionally, we need a python client of Elasticsearch. So, just type 'pip install elasticsearch' \n$ pip install elasticsearch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8285424526085812
      ],
      "excerpt": "If you want to check the version, just type 'python -c \"import keras; print keras.version\"'. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.963589796708019,
        0.9602473602275048,
        0.9454578335404602,
        0.9756877052706688
      ],
      "excerpt": "Python is a requirement (Python 3.3 or greater, or Python 2.7) for installing the Jupyter Notebook. \nAnaconda distribution is recommended for using to install Python and Jupyter. \nIf you want to check the version, just type 'jupyter --version'. \n$ jupyter --version \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8326336347188953
      ],
      "excerpt": "The following URL explains how to install a version of TensorFlow that enables you to write applications in Python. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8397331684428114
      ],
      "excerpt": "def loadimages(directory): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8397331684428114
      ],
      "excerpt": "    imagefiles = loadimages(directory) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8881457168851331,
        0.8397331684428114
      ],
      "excerpt": "directory = \"dogs-vs-cats/train/\" \nindexfiles(directory, 1000) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8890818307099057
      ],
      "excerpt": "  <img src=\"similarity.png\" width=\"300\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8839251445637343,
        0.9420309043733238
      ],
      "excerpt": "If you want to check the version, just type 'python -c \"import keras; print keras.version\"'. \n$ python -c \"import keras; print keras.__version__\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9279976281606084,
        0.9495388812970145
      ],
      "excerpt": "If you want to check the version, just type 'python -c \"import tensorflow as tf; print(tf.version)\"'. \n$ python -c \"import tensorflow as tf; print(tf.__version__)\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8044146895679722,
        0.9068127677393759,
        0.9457175861910134
      ],
      "excerpt": "from PIL import Image \nimport matplotlib.pyplot as plt \nimport numpy as np \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8650137126660441
      ],
      "excerpt": "def predict(filename, featuresize): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8973933083440926,
        0.8525645461651434
      ],
      "excerpt": "    x = np.expand_dims(x, axis=0) \n    preds = model.predict(preprocess_input(x)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8156008391576737,
        0.8893671507898273,
        0.8310159060815993
      ],
      "excerpt": "    im = Image.open(filename) \n    im_list = np.asarray(im) \n    plt.subplot(2, 5, i) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8310159060815993
      ],
      "excerpt": "    plt.imshow(im_list) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.895298993124766,
        0.8739810223964998
      ],
      "excerpt": "filename = \"dogs-vs-cats/train/mini/cat.6.jpg\" \nplt.figure(figsize=(20, 10)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8575435024620189,
        0.9170458716584421
      ],
      "excerpt": "    showimg(filename, \"query\", i+1) \nresults = predict(filename, 10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9399752851367198
      ],
      "excerpt": "    print(result) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9022318366644686
      ],
      "excerpt": "  <img src=\"predict-image.png\" width=\"600\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401558704798054,
        0.8027317256616688,
        0.8801854956928516
      ],
      "excerpt": "import os \nfrom path import Path \nfrom elasticsearch import Elasticsearch \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8575435024620189,
        0.8575435024620189
      ],
      "excerpt": "        filename = imagefiles[i] \n        indexfile(filename, i, featuresize) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8575435024620189,
        0.9006478884825081
      ],
      "excerpt": "    doc = {'filename': filename, 'synset':{}} \n    results = predict(filename, featuresize)  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8102780086823556,
        0.8102780086823556
      ],
      "excerpt": "        synset[result[1]] = { \n            'wnid': result[0],  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8225818228136078
      ],
      "excerpt": "            'score': float(str(result[2])) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8465855916248094
      ],
      "excerpt": "directory = \"dogs-vs-cats/train/\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8464627073003755,
        0.8739810223964998
      ],
      "excerpt": "def searchimg(filename, num): \n    plt.figure(figsize=(20, 10)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8575435024620189,
        0.8668258580770863,
        0.9169550246118371
      ],
      "excerpt": "        showimg(filename, \"query\", i+1) \n    plt.show() \n    results = predict(filename, num) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8417635598631673
      ],
      "excerpt": "        inline += \" + doc['synset.\" + words + \".score'].value * \" + str(score) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8139212126865949
      ],
      "excerpt": "                \"script_score\" : {\"script\" : {\"inline\": inline}} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9111089575010028
      ],
      "excerpt": "print(\"Got %d Hits:\" % res['hits']['total']) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9523923426447968,
        0.8739810223964998,
        0.8386836806331507
      ],
      "excerpt": "    print \"%s: %s [%s]\" % (hit[\"_id\"], hit[\"_source\"][\"filename\"], hit[\"_score\"]) \nplt.figure(figsize=(20, 10)) \nfor i in range(len(res['hits']['hits'][0:num])): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8575435024620189
      ],
      "excerpt": "    showimg(hit[\"_source\"][\"filename\"], hit[\"_id\"], i+1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.897212413217231,
        0.8833562960440429
      ],
      "excerpt": "filename = \"dogs-vs-cats/test1/4.jpg\" \nsearchimg(filename, 10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8890818307099057
      ],
      "excerpt": "  <img src=\"search-cat.png\" width=\"600\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.897212413217231,
        0.8833562960440429
      ],
      "excerpt": "filename = \"dogs-vs-cats/test1/38.jpg\" \nsearchimg(filename, 10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8890818307099057
      ],
      "excerpt": "  <img src=\"search-dog.png\" width=\"600\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.895298993124766,
        0.8833562960440429
      ],
      "excerpt": "filename = \"dogs-vs-cats/train/mini/cat.7.jpg\" \nsearchimg(filename, 10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8815004121525252
      ],
      "excerpt": "  <img src=\"search-cat-in.png\" width=\"600\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.895298993124766,
        0.8833562960440429
      ],
      "excerpt": "filename = \"dogs-vs-cats/train/mini/dog.12466.jpg\" \nsearchimg(filename, 10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8815004121525252
      ],
      "excerpt": "  <img src=\"search-dog-in.png\" width=\"600\"/> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/taniokah/liarr2017/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Super Easy Way of Building Image Search with Keras",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "liarr2017",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "taniokah",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/taniokah/liarr2017/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Tue, 28 Dec 2021 03:57:40 GMT"
    },
    "technique": "GitHub API"
  }
}
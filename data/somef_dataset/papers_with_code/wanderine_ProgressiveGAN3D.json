{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1710.10196"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9104388306336967
      ],
      "excerpt": "Anders Eklund, Link\u00f6ping University \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9792428879788975
      ],
      "excerpt": "Paper (arXiv) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9792428879788975
      ],
      "excerpt": "Paper (arXiv) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wanderine/ProgressiveGAN3D",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-26T07:14:03Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-14T07:59:53Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9948150683849982
      ],
      "excerpt": "Deep learning requires large datasets for training (convolutional) networks with millions of parameters. In neuroimaging, there are few open datasets with more than 100 subjects, which makes it difficult to, for example, train a classifier to discriminate controls from diseased persons. Generative adversarial networks (GANs) can be used to synthesize data, but virtually all research is focused on 2D images. In medical imaging, and especially in neuroimaging, most datasets are 3D or 4D. Here we therefore present preliminary results showing that a 3D progressive growing GAN can be used to synthesize MR brain volumes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9536039723150844,
        0.925409452754589
      ],
      "excerpt": "All the material, including source code, is made freely available for non-commercial use under the Creative Commons CC BY-NC 4.0 license. Feel free to use any of the material in your own work, as long as you give us appropriate credit by mentioning the title and author list of our paper. \nThis 3D version is based on the original 2D version presented here \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Progressive Growing of GANs for Improved Quality, Stability, and Variation",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wanderine/ProgressiveGAN3D/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Wed, 22 Dec 2021 19:25:06 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/wanderine/ProgressiveGAN3D/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "wanderine/ProgressiveGAN3D",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/wanderine/ProgressiveGAN3D/master/run_gan_nohup.sh",
      "https://raw.githubusercontent.com/wanderine/ProgressiveGAN3D/master/run_gan.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Use the `create_from_nifti` option in dataset_tool.py, which was added to the original 2D implementation.\n\n```\nusage: dataset_tool.py [-h] <command> ...\n\n    display             Display images in dataset.\n    extract             Extract images from dataset.\n    compare             Compare two datasets.\n    create_mnist        Create dataset for MNIST.\n    create_mnistrgb     Create dataset for MNIST-RGB.\n    create_cifar10      Create dataset for CIFAR-10.\n    create_cifar100     Create dataset for CIFAR-100.\n    create_svhn         Create dataset for SVHN.\n    create_lsun         Create dataset for single LSUN category.\n    create_celeba       Create dataset for CelebA.\n    create_celebahq     Create dataset for CelebA-HQ.\n    create_from_images  Create dataset from a directory full of images.\n    create_from_hdf5    Create dataset from legacy HDF5 archive.\n    create_from_nifti   Create dataset from nifti files\n\nType \"dataset_tool.py <command> -h\" for more information.\n```\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9523651689170409
      ],
      "excerpt": "Run the training script with python train.py. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/wanderine/ProgressiveGAN3D/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Feeding the zombies: Synthesizing brain volumes using a 3D progressive growing GAN<br>",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ProgressiveGAN3D",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "wanderine",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wanderine/ProgressiveGAN3D/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Linux with Anaconda, use environment.yml for setting up the conda environment.\n* One or more high-end NVIDIA Pascal or Volta GPUs with 16GB of DRAM. We recommend NVIDIA DGX station or better (4 Tesla V100 GPUs).\n* NVIDIA driver 418.87 or newer, CUDA toolkit 10.1 or newer\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Wed, 22 Dec 2021 19:25:06 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.06870"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/multimodallearning/pytorch-mask-rcnn",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-02-02T17:47:18Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-27T12:57:09Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9981190999622875,
        0.9912578102959372,
        0.838388358886386,
        0.9791373307242561,
        0.965938698781325,
        0.8982853999737883
      ],
      "excerpt": "This is a Pytorch implementation of Mask R-CNN that is in large parts based on Matterport's \nMask_RCNN. Matterport's repository is an implementation on Keras and TensorFlow. \nThe following parts of the README are excerpts from the Matterport README. Details on the requirements, training on MS COCO \nand detection results for this repository can be found at the end of the document. \nThe Mask R-CNN model generates bounding boxes and segmentation masks for each instance of an object in the image. It's based \non Feature Pyramid Network (FPN) and a ResNet101 backbone. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8503598096379662
      ],
      "excerpt": "The Region Proposal Network proposes bounding boxes that are likely to belong to an object. Positive and negative anchors \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8676484940430731,
        0.9170834915849713
      ],
      "excerpt": "This is an example of final detection boxes (dotted lines) and the refinement applied to them (solid lines) in the second stage. \nExamples of generated masks. These then get scaled and placed on the image in the right location. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9755414827277891,
        0.8738238551377288
      ],
      "excerpt": "with the default configuration and backbone initialized with pretrained \nImageNet weights. Used metric is AP on IoU=0.50:0.95. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/multimodallearning/pytorch-mask-rcnn/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 513,
      "date": "Mon, 27 Dec 2021 19:49:28 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/multimodallearning/pytorch-mask-rcnn/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "multimodallearning/pytorch-mask-rcnn",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Clone this repository.\n\n        git clone https://github.com/multimodallearning/pytorch-mask-rcnn.git\n\n    \n2. We use functions from two more repositories that need to be build with the right `--arch` option for cuda support.\nThe two functions are Non-Maximum Suppression from ruotianluo's [pytorch-faster-rcnn](https://github.com/ruotianluo/pytorch-faster-rcnn)\nrepository and longcw's [RoiAlign](https://github.com/longcw/RoIAlign.pytorch).\n\n    | GPU | arch |\n    | --- | --- |\n    | TitanX | sm_52 |\n    | GTX 960M | sm_50 |\n    | GTX 1070 | sm_61 |\n    | GTX 1080 (Ti) | sm_61 |\n\n        cd nms/src/cuda/\n        nvcc -c -o nms_kernel.cu.o nms_kernel.cu -x cu -Xcompiler -fPIC -arch=[arch]\n        cd ../../\n        python build.py\n        cd ../\n\n        cd roialign/roi_align/src/cuda/\n        nvcc -c -o crop_and_resize_kernel.cu.o crop_and_resize_kernel.cu -x cu -Xcompiler -fPIC -arch=[arch]\n        cd ../../\n        python build.py\n        cd ../../\n\n3. As we use the [COCO dataset](http://cocodataset.org/#home) install the [Python COCO API](https://github.com/cocodataset/cocoapi) and\ncreate a symlink.\n\n        ln -s /path/to/coco/cocoapi/PythonAPI/pycocotools/ pycocotools\n    \n4. Download the pretrained models on COCO and ImageNet from [Google Drive](https://drive.google.com/open?id=1LXUgC2IZUYNEoXr05tdqyKFZY0pZyPDc).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8560738863425049,
        0.8294794385645151,
        0.9612883214240583
      ],
      "excerpt": "python coco.py train --dataset=/path/to/coco/ --model=/path/to/weights.h5 \npython coco.py train --dataset=/path/to/coco/ --model=last \nIf you have not yet downloaded the COCO dataset you should run the command \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8026801564191167
      ],
      "excerpt": "python coco.py train --dataset=/path/to/coco/ --model=last \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/multimodallearning/pytorch-mask-rcnn/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C",
      "Cuda",
      "C++"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/multimodallearning/pytorch-mask-rcnn/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Mask R-CNN\\n\\nThe MIT License (MIT)\\n\\nCopyright (c) 2017 Matterport, Inc.\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\nTHE SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "pytorch-mask-rcnn",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pytorch-mask-rcnn",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "multimodallearning",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/multimodallearning/pytorch-mask-rcnn/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Python 3\n* Pytorch 0.3\n* matplotlib, scipy, skimage, h5py\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    python coco.py evaluate --dataset=/path/to/coco/ --model=last\n\nThe training schedule, learning rate, and other parameters can be set in coco.py.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1702,
      "date": "Mon, 27 Dec 2021 19:49:28 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To test your installation simply run the demo with\n\n    python demo.py\n\nIt works on CPU or GPU and the result should look like this:\n\n![](assets/park.png)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "    python coco.py train --dataset=/path/to/coco/ --model=coco\n\n    ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "    python coco.py train --dataset=/path/to/coco/ --model=imagenet\n\n    ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "    python coco.py train --dataset=/path/to/coco/ --model=coco --download=true\n\nYou can also run the COCO evaluation code with:\n\n    ",
      "technique": "Header extraction"
    }
  ]
}
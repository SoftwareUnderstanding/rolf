{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The author would like to thank Ryuichi Yamamoto ([@r9y9](https://github.com/r9y9)) for his great repository, paper, and valuable discussions.\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1910.11480",
      "https://arxiv.org/abs/1910.06711",
      "https://arxiv.org/abs/2005.05106",
      "https://arxiv.org/abs/2005.05106",
      "https://arxiv.org/abs/1910.06711",
      "https://arxiv.org/abs/1910.06711",
      "https://arxiv.org/abs/1904.02882",
      "https://arxiv.org/abs/1904.02882",
      "https://arxiv.org/abs/1910.11480",
      "https://arxiv.org/abs/1910.06711",
      "https://arxiv.org/abs/2005.05106"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [Parallel WaveGAN](https://arxiv.org/abs/1910.11480)\n- [r9y9/wavenet_vocoder](https://github.com/r9y9/wavenet_vocoder)\n- [LiyuanLucasLiu/RAdam](https://github.com/LiyuanLucasLiu/RAdam)\n- [MelGAN](https://arxiv.org/abs/1910.06711)\n- [descriptinc/melgan-neurips](https://github.com/descriptinc/melgan-neurips)\n- [Multi-band MelGAN](https://arxiv.org/abs/2005.05106)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.980992113017595
      ],
      "excerpt": "Source of the figure: https://arxiv.org/pdf/1910.11480.pdf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8714162992508173,
        0.8714162992508173,
        0.8714162992508173
      ],
      "excerpt": "JNAS: Japanese multi-speaker \nVCTK: English multi-speaker \nLibriTTS: English multi-speaker \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066,
        0.9898919935623748
      ],
      "excerpt": "[decode]: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 250/250 [00:30&lt;00:00,  8.31it/s, RTF=0.0156] \n2019-11-03 09:07:40,480 (decode:127) INFO: finished generation of 250 utterances (RTF = 0.016). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.976368480140478
      ],
      "excerpt": "2019-11-06 09:04:56,697 (decode:129) INFO: finished generation of 250 utterances (RTF = 0.734). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9535826298136971
      ],
      "excerpt": "2020-02-08 10:45:14,111 (decode:142) INFO: Finished generation of 250 utterances (RTF = 0.137). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9170371404255441
      ],
      "excerpt": "2020-02-08 05:44:42,231 (decode:142) INFO: Finished generation of 250 utterances (RTF = 0.002). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9431184070818162
      ],
      "excerpt": "2020-05-22 15:37:19,771 (decode:151) INFO: Finished generation of 250 utterances (RTF = 0.059). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9170371404255441
      ],
      "excerpt": "2020-05-22 15:35:13,302 (decode:151) INFO: Finished generation of 250 utterances (RTF = 0.001). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.920297378401946
      ],
      "excerpt": "2019-11-13 13:44:29,574 (normalize:87) INFO: the number of files = 1. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9973179366981118
      ],
      "excerpt": "2019-11-13 13:44:37,132 (decode:129) INFO: finished generation of 1 utterances (RTF = 0.015). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9384147558669678
      ],
      "excerpt": ": If you use ESPnet2, move on egs2/ \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/deciding/ParallelWaveGAN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-09-23T11:06:35Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-05T16:42:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9782744189467502,
        0.8277559324142909,
        0.9460213478787691
      ],
      "excerpt": "This repository provides UNOFFICIAL PWG, MelGAN, and MB-MelGAN implementations with Pytorch. \nYou can combine these state-of-the-art non-autoregressive models to build your own great vocoder! \nPlease check our samples in our demo HP. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.998118335481549,
        0.9295988551858942,
        0.9210743398170712,
        0.9030741389954979,
        0.9030741389954979,
        0.9528536896396512,
        0.8768518681285077,
        0.8784563063479789,
        0.9135491419965585,
        0.8156546387133435
      ],
      "excerpt": "The goal of this repository is to provide real-time neural vocoder, which is compatible with ESPnet-TTS. \nAlso, this repository can be combined with NVIDIA/tacotron2-based implementation (See this comment). \nYou can try the real-time end-to-end text-to-speech demonstration in Google Colab! \n- Real-time demonstration with ESPnet2   \n- Real-time demonstration with ESPnet1 \n2020/08/19 (New!) Real-time demo with ESPnet2 is available! \n2020/05/29 VCTK, JSUT, and CSMSC multi-band MelGAN pretrained model is available! \n2020/05/27 New LJSpeech multi-band MelGAN pretrained model is available! \n2020/05/24 LJSpeech full-band MelGAN pretrained model is available! \n2020/05/22 LJSpeech multi-band MelGAN pretrained model is available! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8331743132233405
      ],
      "excerpt": "2020/03/17 Tensorflow conversion example notebook is available (Thanks, @dathudeptrai)! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8659496182058252,
        0.8594374023861839
      ],
      "excerpt": "This repository provides Kaldi-style recipes, as the same as ESPnet. \nCurrently, the following recipes are supported. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "YesNo: English speaker (For debugging) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9770354714514167,
        0.94110545148495
      ],
      "excerpt": "See more info about the recipes in this README. \nThe decoding speed is RTF = 0.016 with TITAN V, much faster than the real-time. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9355467547820258,
        0.925171793800163,
        0.8871935951954927
      ],
      "excerpt": "If you want to accelerate the inference more, it is worthwhile to try the conversion from pytorch to tensorflow. \nThe example of the conversion is available in the notebook (Provided by @dathudeptrai). \nHere the results are summarized in the table. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9805522093727046,
        0.9449709401842388
      ],
      "excerpt": "Please access at our google drive to check more results. \nHere the minimal code is shown to perform analysis-synthesis using the pretrained model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8196907329750899
      ],
      "excerpt": ": You can get all of available pretrained models as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8780706006386698
      ],
      "excerpt": "2019-11-13 13:44:31,229 (decode:91) INFO: the number of features to be decoded = 1. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9771923352963764
      ],
      "excerpt": "Here, I show the procedure to generate waveforms with features generated by ESPnet-TTS models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8196907329750899
      ],
      "excerpt": ": You can get all of available pretrained models as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9568067260490233
      ],
      "excerpt": ": it is de-normalized features (the input for PWG is normalized features). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9231391265099159
      ],
      "excerpt": ": In the case of ESPnet2, the generated feature can be found in \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9231391265099159
      ],
      "excerpt": ": In the case of ESPnet2, the denormalized generated feature can be found in \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8249995408255852
      ],
      "excerpt": ": Normalized features dumped in <path_to_dumpdir>/. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9577955879186645
      ],
      "excerpt": ": Then, decode normalzied features with the pretrained model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030741389954979,
        0.9030741389954979
      ],
      "excerpt": "- Real-time demonstration with ESPnet2   \n- Real-time demonstration with ESPnet1 \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/deciding/ParallelWaveGAN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Fri, 24 Dec 2021 18:07:03 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/deciding/ParallelWaveGAN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "deciding/ParallelWaveGAN",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/notebooks/convert_melgan_from_pytorch_to_tensorflow.ipynb",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/notebooks/filter_design_example.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/utils/split_data.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/utils/parse_options.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/utils/make_subset_data.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/utils/combine_data.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/yesno/voc1/path.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/yesno/voc1/cmd.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/yesno/voc1/run.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/yesno/voc1/local/data_download.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/yesno/voc1/local/data_prep.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/jsut/voc1/path.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/jsut/voc1/cmd.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/jsut/voc1/run.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/jsut/voc1/local/data_download.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/jsut/voc1/local/data_prep.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/csmsc/voc1/path.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/csmsc/voc1/cmd.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/csmsc/voc1/run.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/csmsc/voc1/local/data_download.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/csmsc/voc1/local/data_prep.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/csmsc/kuangfei/path.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/csmsc/kuangfei/cmd.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/csmsc/kuangfei/run.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/csmsc/kuangfei/local/data_download.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/csmsc/kuangfei/local/data_prep.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/arctic/voc1/path.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/arctic/voc1/cmd.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/arctic/voc1/run.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/arctic/voc1/local/data_download.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/arctic/voc1/local/data_prep.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/template_single_spk/voc1/path.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/template_single_spk/voc1/cmd.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/template_single_spk/voc1/run.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/template_single_spk/voc1/local/data_prep.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/ljspeech/voc1/path.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/ljspeech/voc1/cmd.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/ljspeech/voc1/run.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/ljspeech/voc1/local/data_download.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/ljspeech/voc1/local/data_prep.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/jnas/voc1/path.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/jnas/voc1/cmd.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/jnas/voc1/run.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/jnas/voc1/local/data_prep.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/libritts/voc1/path.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/libritts/voc1/cmd.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/libritts/voc1/run.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/libritts/voc1/local/data_download.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/libritts/voc1/local/data_prep.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/vctk/voc1/path.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/vctk/voc1/cmd.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/vctk/voc1/run.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/vctk/voc1/local/data_download.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/vctk/voc1/local/data_prep.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/template_multi_spk/voc1/path.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/template_multi_spk/voc1/cmd.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/template_multi_spk/voc1/run.sh",
      "https://raw.githubusercontent.com/deciding/ParallelWaveGAN/master/egs/template_multi_spk/voc1/local/data_prep.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can select the installation method from two alternatives.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9893272198983933,
        0.9223334315953018,
        0.8474895321345809
      ],
      "excerpt": "$ git clone https://github.com/kan-bayashi/ParallelWaveGAN.git \n$ cd ParallelWaveGAN/tools \n$ make \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9922728809240362,
        0.8474895321345809
      ],
      "excerpt": ": command to install apex. \n$ make apex \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9855282968473015,
        0.9239741139367359
      ],
      "excerpt": "Note that we specify cuda version used to compile pytorch wheel. \nIf you want to use different cuda version, please check tools/Makefile to change the pytorch wheel to be installed. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466
      ],
      "excerpt": "$ cd egs/ljspeech/voc1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9349326232967055,
        0.8302012509539201,
        0.9349326232967055
      ],
      "excerpt": "$ ./run.sh \n: You can change config via command line \n$ ./run.sh --conf <your_customized_yaml_config> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8352236542947944,
        0.8996597883265001,
        0.8352236542947944
      ],
      "excerpt": "$ ./run.sh --stage 2 --stop_stage 2 \n: If you want to specify the gpu \n$ CUDA_VISIBLE_DEVICES=1 ./run.sh --stage 2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.898779401401522
      ],
      "excerpt": "$ ./run.sh --stage 2 --resume <path>/<to>/checkpoint-10000steps.pkl \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8269713977462313
      ],
      "excerpt": ": On GPU (TITAN V) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8269713977462313
      ],
      "excerpt": ": On GPU (TITAN V) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9294186960211862,
        0.999746712887969,
        0.9377448123342547,
        0.8837680365796365
      ],
      "excerpt": ": If not, please install via pip \n$ pip install parallel_wavegan \n: You can download the pretrained model from terminal \n$ python << EOF \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "$ python << EOF \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8004415774844514
      ],
      "excerpt": ": These files can also be downloaded manually from the above results \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9842172039800472
      ],
      "excerpt": "$ cd /path/to/espnet/egs/<recipe_name>/tts1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9842172039800472
      ],
      "excerpt": "$ cd /path/to/espnet/egs2/<recipe_name>/tts1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9638629577900975,
        0.9989407589118213,
        0.9377448123342547,
        0.8837680365796365
      ],
      "excerpt": ": Please install this repository in ESPnet conda (or virtualenv) environment \n$ . ./path.sh && pip install -U parallel_wavegan \n: You can download the pretrained model from terminal \n$ python << EOF \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "$ python << EOF \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8004415774844514
      ],
      "excerpt": ": These files can also be downloaded manually from the above results \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8196675697383518
      ],
      "excerpt": "2020/05/24 LJSpeech full-band MelGAN pretrained model is available! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8199251669384747
      ],
      "excerpt": "[decode]: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 250/250 [01:47<00:00,  2.95it/s, RTF=0.048] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9416522774131079
      ],
      "excerpt": "from parallel_wavegan.utils import download_pretrained_model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9416522774131079
      ],
      "excerpt": "from parallel_wavegan.utils import PRETRAINED_MODEL_LIST \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003751159116907,
        0.8003751159116907
      ],
      "excerpt": "$ ls sample/ \n\uf001  sample.wav \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003751159116907
      ],
      "excerpt": "    --rootdir sample \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003751159116907
      ],
      "excerpt": "    --dumpdir dump/sample/norm \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003751159116907,
        0.8003751159116907
      ],
      "excerpt": "    --dumpdir dump/sample/norm \\ \n    --outdir sample \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003751159116907,
        0.8003751159116907
      ],
      "excerpt": "$ ls sample \n\uf001  sample.wav  \uf001  sample_gen.wav \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9416522774131079
      ],
      "excerpt": "from parallel_wavegan.utils import download_pretrained_model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9416522774131079
      ],
      "excerpt": "from parallel_wavegan.utils import PRETRAINED_MODEL_LIST \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/deciding/ParallelWaveGAN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Shell",
      "Perl",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License (MIT)\\n\\nCopyright (c) 2020 Tomoki Hayashi &#104;&#97;&#121;&#97;&#115;&#104;&#105;&#46;&#116;&#111;&#109;&#111;&#107;&#105;&#64;&#103;&#46;&#115;&#112;&#46;&#109;&#46;&#105;&#115;&#46;&#110;&#97;&#103;&#111;&#121;&#97;&#45;&#117;&#46;&#97;&#99;&#46;&#106;&#112;\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\nTHE SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Parallel WaveGAN (+ MelGAN & Multi-band MelGAN) implementation with Pytorch",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ParallelWaveGAN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "deciding",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/deciding/ParallelWaveGAN/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This repository is tested on Ubuntu 16.04 with a GPU Titan V.\n\n- Python 3.6+\n- Cuda 10.0\n- CuDNN 7+\n- NCCL 2+ (for distributed multi-gpu training)\n- libsndfile (you can install via `sudo apt install libsndfile-dev` in ubuntu)\n- jq (you can install via `sudo apt install jq` in ubuntu)\n- sox (you can install via `sudo apt install sox` in ubuntu)\n\nDifferent cuda version should be working but not explicitly tested.  \nAll of the codes are tested on Pytorch 1.0.1, 1.1, 1.2, 1.3.1, 1.4, and 1.5.1.\n\nPytorch 1.6 works but there are some issues in cpu mode (See #198).\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Fri, 24 Dec 2021 18:07:03 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\n$ git clone https://github.com/kan-bayashi/ParallelWaveGAN.git\n$ cd ParallelWaveGAN\n$ pip install -e .\n#: If you want to use distributed training, please install\n#: apex manually by following https://github.com/NVIDIA/apex\n$ ...\n```\nNote that your cuda version must be exactly matched with the version used for the pytorch binary to install apex.  \nTo install pytorch compiled with different cuda version, see `tools/Makefile`.\n\n",
      "technique": "Header extraction"
    }
  ]
}
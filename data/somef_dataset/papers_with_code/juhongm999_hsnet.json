{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2104.01538"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@InProceedings{min2021hypercorrelation,\n    title={Hypercorrelation Squeeze for Few-Shot Segmentation},\n    author={Juhong Min and Dahyun Kang and Minsu Cho},\n    booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},\n    year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8028046190715653
      ],
      "excerpt": "wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999858461696091
      ],
      "excerpt": "If you use this code for your research, please consider citing: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/juhongm999/hsnet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-06T03:37:26Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-25T10:00:46Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9802586888672271
      ],
      "excerpt": "This is the implementation of the paper \"Hypercorrelation Squeeze for Few-Shot Segmentation\" by Juhong Min, Dahyun Kang, and Minsu Cho. Implemented on Python 3.7 and Pytorch 1.5.1. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9779493386929273
      ],
      "excerpt": "For more information, check out project [website] and the paper on [arXiv]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.860059181823877
      ],
      "excerpt": "\u2502   \u251c\u2500\u2500 data/ \n\u2502   \u251c\u2500\u2500 model/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9220091418248707,
        0.9456988652554645
      ],
      "excerpt": "- Choose the best model when the validation (mIoU) curve starts to saturate. \nPretrained models with tensorboard logs are available on our [Google Drive]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9456988652554645
      ],
      "excerpt": "Pretrained models with tensorboard logs are available on our [Google Drive]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9456988652554645
      ],
      "excerpt": "Pretrained models with tensorboard logs are available on our [Google Drive]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Official PyTorch Implementation of Hypercorrelation Squeeze for Few-Shot Segmentation, ICCV 2021",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/juhongm999/hsnet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 18,
      "date": "Sun, 26 Dec 2021 17:21:03 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/juhongm999/hsnet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "juhongm999/hsnet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Download following datasets:\n\n> ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8550996757124075
      ],
      "excerpt": "Create a directory '../Datasets_HSN' for the above three few-shot segmentation datasets and appropriately place each dataset to have following directory structure: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8443566928207841
      ],
      "excerpt": "- From terminal, run 'tensorboard --logdir logs/' to monitor the training progress. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833114516308531
      ],
      "excerpt": "bash  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.849461924698997
      ],
      "excerpt": "    <img src=\"data/assets/architecture.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8976601697412768
      ],
      "excerpt": "Download PASCAL VOC2012 devkit (train/val data): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8011423710281018,
        0.8591975385204749
      ],
      "excerpt": "Download PASCAL VOC2012 SDS extended mask annotations from our [Google Drive]. \nDownload COCO2014 train/val images and annotations:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8513459750393717
      ],
      "excerpt": "Download COCO2014 train/val annotations from our Google Drive: [train2014.zip], [val2014.zip]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.950563948951535,
        0.9521174821235511
      ],
      "excerpt": "\u2502   \u251c\u2500\u2500 train.py \n\u2502   \u2514\u2500\u2500 test.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8537441747778175
      ],
      "excerpt": "python train.py --backbone {resnet50, resnet101}  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8553381290339905
      ],
      "excerpt": "python test.py --backbone {resnet50, resnet101}  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8440260808513772
      ],
      "excerpt": "  python test.py '...other arguments...' --visualize \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/juhongm999/hsnet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Hypercorrelation Squeeze for Few-Shot Segmentation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "hsnet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "juhongm999",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/juhongm999/hsnet/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Python 3.7\n- PyTorch 1.5.1\n- cuda 10.1\n- tensorboard 1.14\n\nConda environment settings:\n```bash\nconda create -n hsnet python=3.7\nconda activate hsnet\n\nconda install pytorch=1.5.1 torchvision cudatoolkit=10.1 -c pytorch\nconda install -c conda-forge tensorflow\npip install tensorboardX\n```\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 94,
      "date": "Sun, 26 Dec 2021 17:21:03 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "> * To reproduce the results in Tab.1 of our main paper, **COMMENT OUT line 51 in hsnet.py**: support_feats = self.mask_feature(support_feats, support_mask.clone())\n> \n> Pretrained models with tensorboard logs are available on our [[Google Drive](https://drive.google.com/drive/folders/18YWMCePIrza194pZvVMqQBuYqhwBmJwd?usp=sharing)].\n> ```bash\n> python test.py --backbone resnet101 \n>                --fold {0, 1, 2, 3} \n>                --benchmark pascal\n>                --nshot {1, 5} \n>                --load \"path_to_trained_model/best_model.pt\"\n> ```\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "few-shot-segmentation",
      "computer-vision"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "<p align=\"middle\">\n    <img src=\"data/assets/qualitative_results.png\">\n</p>\n   \n",
      "technique": "Header extraction"
    }
  ]
}
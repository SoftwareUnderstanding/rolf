{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1605.06211"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Use this bibtex to cite this repository:\n```\n@misc{fmahoudeau_fcn_2019,\n  title={FCN methods for semantic image segmentation on TensorFlow},\n  author={Florent Mahoudeau},\n  year={2019},\n  publisher={Github},\n  journal={GitHub repository},\n  howpublished={\\url{https://github.com/fmahoudeau/fcn}},\n}\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{fmahoudeau_fcn_2019,\n  title={FCN methods for semantic image segmentation on TensorFlow},\n  author={Florent Mahoudeau},\n  year={2019},\n  publisher={Github},\n  journal={GitHub repository},\n  howpublished={\\url{https://github.com/fmahoudeau/fcn}},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "| FCN-32s                      | 91.3        | 79.3        | 64.5        | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fmahoudeau/FCN-Segmentation-TensorFlow",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-02-12T18:15:43Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-02T15:36:28Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9976238227968076,
        0.9328830280660902,
        0.9841494491889514,
        0.8170777381233109
      ],
      "excerpt": "This is an implementation of Fully Convolutional Networks (FCN) achieving 68.5 mIoU on PASCAL VOC2012 validation set. The model generates semantic masks for each object class in the image using a VGG16 backbone. It is based on the work by E. Shelhamer, J. Long and T. Darrell described in the PAMI FCN and CVPR FCN papers (achieving 67.2 mIoU). \nThe repository includes: \nSource code of FCN built on VGG16 \nTraining code for PASCAL VOC \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.869695245969937,
        0.9694553081003588,
        0.8984591163039228
      ],
      "excerpt": "Data augmentation code based on OpenCV \nJupyter notebook to visualize the data augmentation pipeline with PASCAL VOC 2012 \nOther examples of training with the Kitty Road and CamVid datasets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8408448325670727,
        0.9759194543761511,
        0.9597433090112559,
        0.9597433090112559,
        0.953162663561252,
        0.953162663561252,
        0.833747049526646,
        0.8996016839398909
      ],
      "excerpt": "This section reports validation results for several datasets on the following experiments: \n * One-off end to end training of the FCN-32s model starting from the pre-trained weights of VGG16. \n * One-off end to end training of FCN-16s starting from the pre-trained weights of VGG16. \n * One-off end to end training of FCN-8s starting from the pre-trained weights of VGG16. \n * Staged training of FCN-16s using the pre-trained weights of FCN-32s. \n * Staged training of FCN-8s using the pre-trained weights of FCN-16s-staged.  \nThe models are evaluated against standard metrics, including pixel accuracy (PixAcc), mean class accuracy (MeanAcc), and mean intersection over union (MeanIoU). All training experiments were done with the Adam optimizer. Learning rate and weight decay parameters were selected using grid search. \nKitty Road is a road and lane prediction task consisting of 289 training and 290 test images. It belongs to the KITTI Vision Benchmark Suite. As test images are not labelled, 20% of the images in the training set have been isolated to evaluate the model. The best result of 96.2 mIoU was obtained with one-off training of FCN-8s.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8877191392810879,
        0.8877191392810879,
        0.8877191392810879,
        0.8877191392810879,
        0.8877191392810879,
        0.961401520816042
      ],
      "excerpt": "| FCN-32s                       | 98.1        | 97.3        | 93.8        | \n| FCN-16s-oneoff         | 98.6        | 97.9        | 95.6        | \n| FCN-8s-oneoff           | 98.8    | 98.5    | 96.2    | \n| FCN-16s-staged         | 98.8    | 98.0        | 96.0        | \n| FCN-8s-staged           | 98.6        | 98.2        | 95.3        | \nThe Cambridge-driving Labeled Video Database (CamVid) is the first collection of videos with object class semantic labels, complete with metadata. The database provides ground truth labels that associate each pixel with one of 32 semantic classes. I have used a modified version of CamVid with 11 semantic classes and all images reshaped to 480x360. The training set has 367 images, the validation set 101 images and is known as CamSeq01. The best result of 73.2 mIoU was also obtained with one-off training of FCN-8s. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8877191392810879
      ],
      "excerpt": "| FCN-32s                          | 92.6        | 73.4        | 65.0        | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8877191392810879,
        0.8877191392810879,
        0.8877191392810879,
        0.9448780295628597
      ],
      "excerpt": "| FCN-8s-oneoff              | 94.5        | 81.0        | 73.2    | \n| FCN-16s-staged            | 93.8        | 77.9        | 69.7        | \n| FCN-8s-staged              | 94.6    | 81.5    | 72.9        | \nThe PASCAL Visual Object Classes Challenge includes a segmentation challenge with the objective of generating pixel-wise segmentations giving the class of the object visible at each pixel, or \"background\" otherwise. There are 20 different object classes in the dataset. It is one of the most widely used datasets for research. Again, the best result of 62.5 mIoU was obtained with one-off training of FCN-8s. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8877191392810879,
        0.8877191392810879,
        0.8877191392810879,
        0.8877191392810879,
        0.8877191392810879,
        0.9412343967319752
      ],
      "excerpt": "| FCN-32s                  | 90.7        | 69.3        | 60.0        | \n| FCN-16s-oneoff    | 91.0        | 72.9    | 61.9        | \n| FCN-8s-oneoff      | 91.2    | 72.2        | 62.5    | \n| FCN-16s-staged    | 91.1        | 72.3        | 61.9        | \n| FCN-8s-staged      | 91.0        | 72.1        | 61.7        | \nPASCAL Plus refers to the PASCAL VOC 2012 dataset augmented with the annotations from Hariharan et al. Again, the best result of 68.5 mIoU was obtained with one-off training of FCN-8s. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8877191392810879,
        0.8877191392810879,
        0.8877191392810879,
        0.8877191392810879,
        0.8877191392810879,
        0.8234376855181225,
        0.9929525106898703,
        0.9783934902456173,
        0.8438419315774985,
        0.9723551097521361
      ],
      "excerpt": "| FCN-32s                      | 91.3        | 79.3        | 64.5        | \n| FCN-16s-oneoff        | 92.4        | 78.1        | 67.3        | \n| FCN-8s-oneoff          | 92.7    | 78.5    | 68.5    | \n| FCN-16s-staged        | 92.3        | 78.5    | 67.5        | \n| FCN-8s-staged          | 92.4        | 77.9        | 67.2        | \nThis implementation follows the FCN paper for the most part, but there are a few differences. Please let me know if I missed anything important. \nOptimizer: The paper uses SGD with momentum and weight decay. This implementation uses Adam with a batch size of 12 images, a learning rate of 1e-5 and weight decay of 1e-6 for all training experiments with PASCAL VOC data. I did not double the learning rate for biases in the final solution. \nData Augmentation: The authors chose not to augment the data after finding no noticeable improvement with horizontal flipping and jittering. I find that more complex transformations such as zoom, rotation and color saturation improve the learning while also reducing overfitting. However, for PASCAL VOC, I was never able to completly eliminate overfitting. \nExtra Data: The train and test sets in the additional labels were merged to obtain a larger training set of 10582 images, compared to the 8498 used in the paper. The validation set has 1449 images. This larger number of training images is arguably the main reason for obtaining a better mIoU than the one reported in the second version of the paper (67.2). \nImage Resizing: To support training multiple images per batch we resize all images to the same size. For example, 512x512px on PASCAL VOC. As the largest side of any PASCAL VOC image is 500px, all images are center padded with zeros. I find this approach more convinient than having to pad or crop features after each up-sampling layer to re-instate their initial shape before the skip connection. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8592175798780919
      ],
      "excerpt": "You can also evaluate the model with: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8699233790021956
      ],
      "excerpt": ": Evaluate FCN8 model on PASCAL Plus validation set \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.847280497496395
      ],
      "excerpt": ": Predict PASCAL Plus validation set using an FCN8 model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": ": Unzip and prepare TFRecordDatasets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8434776901248903
      ],
      "excerpt": "I'm providing a prepared version of CamVid with 11 object classes. You can also go to the Cambridge-driving Labeled Video Database to make your own. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": ": Unzip and prepare TFRecordDatasets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": ": Untar and prepare TFRecordDatasets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "FCN for Semantic Image Segmentation achieving 68.5 mIoU on PASCAL VOC",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fmahoudeau/fcn/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Thu, 23 Dec 2021 05:50:52 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/fmahoudeau/FCN-Segmentation-TensorFlow/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "fmahoudeau/FCN-Segmentation-TensorFlow",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/fmahoudeau/fcn/master/fcn_training.ipynb",
      "https://raw.githubusercontent.com/fmahoudeau/fcn/master/data_augmentation.ipynb",
      "https://raw.githubusercontent.com/fmahoudeau/fcn/master/demo.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8726027711978084
      ],
      "excerpt": "I'm providing a prepared version of CamVid with 11 object classes. You can also go to the Cambridge-driving Labeled Video Database to make your own. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9287243213896447
      ],
      "excerpt": "mkdir /path/to/pascal_voc_data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9287243213896447
      ],
      "excerpt": "mkdir /path/to/pascal_plus_data \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8070465084019256
      ],
      "excerpt": "Other examples of training with the Kitty Road and CamVid datasets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9461880308722437
      ],
      "excerpt": "python fcn_run_loop.py train --fcn_version=FCN8 --dataset=pascal_plus --model_name=<your model's name>  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9461880308722437
      ],
      "excerpt": "python fcn_run_loop.py train --fcn_version=FCN16 --dataset=pascal_plus --model_name=<your model's name> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9148700203373664
      ],
      "excerpt": "python fcn_run_loop.py evaluate --fcn_version=FCN8 --dataset=pascal_plus --model_name=<your model's name>  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.822509208644793,
        0.9425576963349451
      ],
      "excerpt": ": Predict PASCAL Plus validation set using an FCN8 model \npython fcn_run_loop.py predict --fcn_version=FCN8 --dataset=pascal_voc_2012 --model_name=<your model's name> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8971823465573899
      ],
      "excerpt": "python fcn_run_loop.py --help \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9076604979061941
      ],
      "excerpt": "python kitty_road_dataset.py --data_dir=<path to data_road.zip> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9076604979061941
      ],
      "excerpt": "python cam_vid_dataset.py --data_dir=<path to cam_vid_prepped.zip> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8309391638231081,
        0.8755501736047567
      ],
      "excerpt": ": Download the dataset \npython pascal_voc_downloader.py --data_dir=</path/to/pascal_voc_data> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8727770017330696
      ],
      "excerpt": "python pascal_voc_dataset.py --data_dir=</path/to/pascal_voc_data/VOCdevkit/VOC2012> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8755501736047567,
        0.8945113896999972
      ],
      "excerpt": "python pascal_plus_downloader.py --data_dir=</path/to/pascal_plus_data> \npython pascal_plus_dataset.py --contours_dir=</path/to/pascal_plus_data/benchmark_RELEASE/dataset/> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/fmahoudeau/FCN-Segmentation-TensorFlow/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "CSS"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Florent Mahoudeau\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "FCN for Semantic Image Segmentation on TensorFlow",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "FCN-Segmentation-TensorFlow",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "fmahoudeau",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/fmahoudeau/FCN-Segmentation-TensorFlow/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Python 3.6, TensorFlow 1.12, OpenCV, and other common packages listed in `environment.yml`.\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 34,
      "date": "Thu, 23 Dec 2021 05:50:52 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "tensorflow",
      "cnn",
      "image-segmentation",
      "fcn",
      "fcn-8s",
      "fcn-16s",
      "fcn-paper",
      "semantic-segmentation",
      "pascal-voc",
      "fcn-model",
      "kitty-road",
      "camvid",
      "segmentation",
      "fcn-training"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* [demo.ipynb](demo.ipynb): This notebook is the recommended way to get started. It provides examples of using a FCN model pre-trained on PASCAL VOC to segment object classes in your own images. It includes code to run object class segmentation on arbitrary images.\n\n* [data_augmentation.ipynb](data_augmentation.ipynb): This notebook visualizes the data augmentation process using PASCAL VOC 2012 as example. Image transformations are built on OpenCV.\n\n* ([fcn_run_loop.py](fcn_run_loop.py), [fcn_model.py](fcn_model.py)): These files contain the main VGG16 FCN implementation details.\n\n* [fcn_training.ipynb](fcn_training.ipynb): This notebook reports training results for several datasets and can be used to reproduce them on your own.\n\n \n\n",
      "technique": "Header extraction"
    }
  ]
}
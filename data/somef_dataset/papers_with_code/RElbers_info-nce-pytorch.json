{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1807.03748>`__.\nIn contrastive learning, we want to learn how to map high dimensional data to a lower dimensional embedding space.\nThis mapping should place semantically similar samples close together in the embedding space, whilst placing semantically distinct samples further apart.\nThe InfoNCE loss function can be used for the purpose of contrastive learning.\n\n\nThis package is `available on PyPI <https://pypi.org/project/info-nce-pytorch/>`__ and can be installed via:\n\n.. code::\n\n    pip install info-nce-pytorch\n\n\nExample usage\n-------------\n\nCan be used without explicit negative keys, whereby each sample is compared with the other samples in the batch.\n\n.. code:: python\n\n    loss = InfoNCE("
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RElbers/info-nce-pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-13T23:07:56Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-20T12:38:34Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9681782309763429,
        0.8199177282576999,
        0.8083128289529151
      ],
      "excerpt": "In contrastive learning, we want to learn how to map high dimensional data to a lower dimensional embedding space. \nThis mapping should place semantically similar samples close together in the embedding space, whilst placing semantically distinct samples further apart. \nThe InfoNCE loss function can be used for the purpose of contrastive learning. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8631480737368062,
        0.9010631473641222,
        0.97813234985042
      ],
      "excerpt": "Given interpolation weights \u03b1 and \u03b2, we define the distribution Q ~ N(\u00b5_q, \u03a3) for the query samples, the distribution  P_\u03b1 ~ N(\u03b1\u00b5_q + (1-\u03b1)\u00b5_p, \u03a3) for the positive samples \nand the distribution N_\u03b2 ~ N(\u03b2\u00b5_q + (1-\u03b2)\u00b5_n, \u03a3) for the negative samples. \nShown below is the value of the loss with inputs sampled from the distributions defined above for different values of \u03b1 and \u03b2. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "PyTorch implementation of the InfoNCE loss for self-supervised learning.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RElbers/info-nce-pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Thu, 23 Dec 2021 04:23:44 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/RElbers/info-nce-pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "RElbers/info-nce-pytorch",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9302161899638313
      ],
      "excerpt": "This package is available on PyPI &lt;https://pypi.org/project/info-nce-pytorch/&gt;__ and can be installed via: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9925168928635874
      ],
      "excerpt": "pip install info-nce-pytorch \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/RElbers/info-nce-pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 RElbers\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "InfoNCE",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "info-nce-pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "RElbers",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/RElbers/info-nce-pytorch/blob/main/README.rst",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 34,
      "date": "Thu, 23 Dec 2021 04:23:44 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "contrastive-learning",
      "contrastive-loss",
      "self-supervised-learning"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Can be used without explicit negative keys, whereby each sample is compared with the other samples in the batch.\n\n.. code:: python\n\n    loss = InfoNCE()\n    batch_size, embedding_size = 32, 128\n    query = torch.randn(batch_size, embedding_size)\n    positive_key = torch.randn(batch_size, embedding_size)\n    output = loss(query, positive_key)\n\nCan be used with negative keys, whereby every combination between query and negative key is compared.\n\n.. code:: python\n\n    loss = InfoNCE(negative_mode='unpaired') # negative_mode='unpaired' is the default value\n    batch_size, num_negative, embedding_size = 32, 48, 128\n    query = torch.randn(batch_size, embedding_size)\n    positive_key = torch.randn(batch_size, embedding_size)\n    negative_keys = torch.randn(num_negative, embedding_size)\n    output = loss(query, positive_key, negative_keys)\n\n\nCan be used with negative keys, whereby each query sample is compared with only the negative keys it is paired with.\n\n.. code:: python\n\n    loss = InfoNCE(negative_mode='paired')\n    batch_size, num_negative, embedding_size = 32, 6, 128\n    query = torch.randn(batch_size, embedding_size)\n    positive_key = torch.randn(batch_size, embedding_size)\n    negative_keys = torch.randn(batch_size, num_negative, embedding_size)\n    output = loss(query, positive_key, negative_keys)\n\n\n\n\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
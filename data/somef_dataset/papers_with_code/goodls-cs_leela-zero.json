{
  "citation": [
    {
      "confidence": [
        0.82000071191569
      ],
      "excerpt": "Head to the Github releases page at https://github.com/leela-zero/leela-zero/releases, \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/goodls-cs/leela-zero",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to Leela Zero\nC++ Usage\nLeela Zero is written in C++14, and generally encourages writing in modern C++ style.\nThis means that:\n\nThe code overwhelmingly uses Almost Always Auto style, and so should you.\nPrefer range based for and non-member (c)begin/(c)end.\nYou can rely on boost 1.58.0 or later being present.\nManipulation of raw pointers is to be avoided as much as possible.\nPrefer constexpr over defines or constants.\nPrefer \"using\" over typedefs.\nPrefer uniform initialization.\nPrefer default initializers for member variables.\nPrefer emplace_back and making use of move assignment.\nAim for const-correctness. Prefer passing non-trivial parameters by const reference.\nUse header include guards, not #pragma once (pragma once is non-standard, has issues with detecting identical files, and is slower https://gcc.gnu.org/bugzilla/show_bug.cgi?id=58770)\nconfig.h is always the first file included.\nFeel free to use templates, but remember that debugging obscure template metaprogramming bugs is not something people enjoy doing in their spare time.\nUsing exceptions is allowed.\n\nCode Style\n\nLook at the surrounding code and the rest of the project!\nIndentation is 4 spaces. No tabs.\npublic/private/protected access modifiers are de-indented\nMaximum line length is 80 characters. There are rare exceptions in the code, usually involving user-visible text strings.\nIfs are always braced, with very rare exceptions when everything fits on one line and doing it properly makes the code less readable.\nThe code generally avoids any pointer passing and allows non-const references for parameters. Still, for new code it should be preferred to a) put input parameters first b) use return values over output parameters.\nFunction arguments that wrap are aligned.\nMember variables in a class have an m_ prefix and are private. Members of POD structs don't and aren't.\nConstants and enum values are ALL_CAPS.\nVariables are lowercase.\nFunction names are underscore_case.\nClasses are CamelCase.\nComments are preferably full sentences with proper capitalization and a period.\nSplit the includes list into config.h, standard headers and our headers.\n\nIf something is not addressed here or there is no similar code, the Google C++ Style Guide is always a good reference.\nWe might move to enforce clang-format at some point.\nAdding dependencies\nC++ does not quite have the package systems JavaScript and Rust have, so some restraint should be excercised when adding dependencies. Dependencies typically complicate the build for new contributors, especially on Windows, and reliance on specific, new versions can be a nuisance on Unix based systems.\nThe restraints on modern header-only libraries are significantly less because they avoid most of the above problems.\nIf a library is not mature and well-supported on Windows, Linux and macOS, you do not want it.\nThis is not an excuse to re-invent the wheel.\nUpgrading dependencies\nThe code and dependencies should target the latest stable versions of Visual Studio/MSVC, and the latest stable/LTS releases of common Linux distros, with some additional delay as not everyone will be able to upgrade to a new stable/LTS right away.\nFor example, upgrading to C++17 or boost 1.62.0 (oldest version in a Debian stable or Ubuntu LTS release) can be considered if there's a compelling use case and/or we can confirm it is supported on all platforms we reasonably target.\nMerging contributions\nContributions come in the form of pull requests against the \"next\" branch.\nThey are rebased or squashed on top of the next branch, so the history will stay linear, i.e. no merge commits.\nCommit messages follow Linux kernel style: a summary phrase that is no more than 70-75 characters (but preferably <50) and describes both what the patch changes, as well as why the patch might be necessary.\nIf the patch is to a specific subsystem (AutoGTP, Validation, ...) then prefix the summary by that subsystem (e.g. AutoGTP: ...).\nThis is followed by a blank line, and a description that is wrapped at 72 characters. Good patch descriptions can be large time savers when someone has to bugfix the code afterwards.\nThe end of the commit message should mention which (github) issue the patch fixes, if any, and the pull request it belongs to.\nPatches need to be reviewed before merging. Try to find the person who worked on the code last, or who has done work in nearby code (git blame is your friend, and this is why we write proper commit messages...). With some luck that is someone with write access to the repository. If not, you'll have to ping someone who does.\nExperience says that the majority of the pull requests won't live up to this ideal, which means that maintainers will have to squash patch series and clean up the commit message to be coherent before merging.\nIf you are a person with write access to the repo, and are about to merge a commit, ask yourself the following question: am I confident enough that I understand this code, so that I can and am willing to go in and fix it if it turns out to be necessary? If the answer to this question is no, then do not merge the code. Not merging a contribution (quickly) is annoying for the individual contributor. Merging a bad contribution is annoying for everyone who wants to contribute now and in the future.\nIf a contributor can't be bothered to fix up the trailing whitespace in their patch, odds are they aren't going to be willing to fix the threading bug it introduces either.\n\"Improvements\" and Automagic\nImprovements to the engine that can affect strength should include supporting data. This means no-regression tests for functional changes, and a proof of strength improvement for things which are supposed to increase strength.\nThe tools in the validation directory are well-fit for this purpose, as\nis the python tool \"ringmaster\".\nThe number of configurable options should be limited where possible. If it is not possible for the author to make rules of thumb for suitable values for those options, then the majority of users have no hope of getting them right, and may mistakenly make the engine weaker. If you must introduce new ones, consider limiting their exposure to developers only via USE_TUNER and set a good default for them.\nGTP Extensions\nGTP makes it possible to connect arbitrary engines to arbitrary interfaces.\nUnfortunately GTP 2 isn't extensive enough to realistically fit all needs of analysis GUIs, which means we have had to extend it. The lack of standardization here means that Go software is continously catching up to the chess world, especially after UCI was introduced. We should aim to make this situation better, not worse.\nThis means that extensions have the possibility of outliving Leela Zero (or any GUIs) provided they are well thought out.\nIt makes sense to be thoughtful here, consider the responsibilities of both GUI and engine, and try to come up with flexible building blocks rather than a plethora of commands for very specific use cases.\nExperience and previous discussions can help understanding:\n\nlz-analyze \"avoid\" and \"allow\" were added in pull request #1949.\nlz-analyze got a side-to-move option in pull request #1872 and #1642.\nlz-analyze got a \"prior\" tag in pull request #1836.\nlz-analyze was added in pull request #1388.\nlz-setoption was added in pull request #1741.\nPull request #2170 has some discussion regarding how to navigate SGF\n  files that were parsed by the engine via GTP.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-19T17:23:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-02-19T17:25:13Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.979219551298523,
        0.9173765602124146,
        0.9531983271841112
      ],
      "excerpt": "This is a fairly faithful reimplementation of the system described \nin the Alpha Go Zero paper \"Mastering the Game of Go without Human Knowledge\". \nFor all intents and purposes, it is an open source AlphaGo Zero. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8965561406895736
      ],
      "excerpt": "be an engine that is far stronger than the top humans. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8363207968336344,
        0.8861790690159256,
        0.8635575203630618
      ],
      "excerpt": "One reason for publishing this program is that we are running a public, \ndistributed effort to repeat the work. Working together, and especially \nwhen starting on a smaller scale, it will take less than 1700 years to get \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8818572653162655
      ],
      "excerpt": "the server automatically and do its work in the background, uploading results \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.921510810536201
      ],
      "excerpt": "Follow the instructions below to compile the leelaz and autogtp binaries in \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9922776317749896
      ],
      "excerpt": "that are usable for helping the leela-zero project. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9794727350874087
      ],
      "excerpt": "section of this README. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9877238155879763,
        0.877617903499411,
        0.8591719591674217
      ],
      "excerpt": "The layout of the network is as in the AlphaGo Zero paper, but any number of \nresidual blocks is allowed, and any number of outputs (filters) per layer, \nas long as the latter is the same for all layers. The program will autodetect \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9495743027549155,
        0.9151633939648772,
        0.8592780487879873,
        0.9410046557775178
      ],
      "excerpt": "head. All convolution filters are 3x3 except for the ones at the start of the policy and value head, which are 1x1 (as in the paper). \nThere are 18 inputs to the first layer, instead of 17 as in the paper. The \noriginal AlphaGo Zero design has a slight imbalance in that it is easier \nfor the black player to see the board edge (due to how padding works in \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8068953168871238
      ],
      "excerpt": "1) Side to move stones at time T=0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8256387107811768
      ],
      "excerpt": "18) All 1 if white is to move, 0 otherwise \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9189749338775963
      ],
      "excerpt": "description of the full 40 residual block design, in (NVIDIA)-Caffe protobuff \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9330386999014089
      ],
      "excerpt": "because they are followed by a batchnorm layer, which is supposed to normalize \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9094219622414114,
        0.9488671820622203
      ],
      "excerpt": "operation in the batchnorm layer, corrected for the effect of the batchnorm mean/variance adjustment. At inference time, Leela Zero will fuse the channel \nbias into the batchnorm mean, thereby offsetting it and performing the center operation. This roundabout construction exists solely for backwards \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.916311975937522,
        0.9025586935682142
      ],
      "excerpt": "Leela can convert a database of concatenated SGF games into a datafile suitable \nfor learning: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9684473347564445
      ],
      "excerpt": "The training data consists of files with the following data, all in text \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8096892841717471
      ],
      "excerpt": "16 lines of hexadecimal strings, each 361 bits longs, corresponding to the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9742557693696156,
        0.9398384857726668,
        0.9538663115488041,
        0.9693233393948762
      ],
      "excerpt": "(visit counts) at the end of the search for the move in question. The last \nnumber is the probability of passing. \n1 line with either 1 or -1, corresponding to the outcome of the game for the \nplayer to move \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9235253062837733
      ],
      "excerpt": "well as snapshots of the learning state numbered by the batch number. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8821926934974886,
        0.8886034359529978
      ],
      "excerpt": "[ ] Root filtering for handicap play. \nMore backends: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8789339176452443
      ],
      "excerpt": "Status page of the distributed effort: \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/goodls-cs/leela-zero/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 22 Dec 2021 23:29:35 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/goodls-cs/leela-zero/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "goodls-cs/leela-zero",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    brew install boost cmake zlib\n\n    ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "    sudo apt install libboost-dev libboost-program-options-dev libboost-filesystem-dev opencl-headers ocl-icd-libopencl1 ocl-icd-opencl-dev zlib1g-dev\n\n    ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9518582487054953
      ],
      "excerpt": "You need a PC with a GPU, i.e. a discrete graphics card made by NVIDIA or AMD, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9102482877835224
      ],
      "excerpt": "Follow the instructions below to compile the leelaz and autogtp binaries in \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8926967135767734,
        0.8484005262332075
      ],
      "excerpt": "contributing instructions below. \nContributing will start when you run autogtp. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9711445397715621
      ],
      "excerpt": "If you are on Unix or macOS, you have to compile the program yourself. Follow \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9879863063452118,
        0.9906248903846466,
        0.8270538936472002
      ],
      "excerpt": "git clone https://github.com/leela-zero/leela-zero \ncd leela-zero \ngit submodule update --init --recursive \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8698200166289988
      ],
      "excerpt": "cmake --build . \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9879863063452118,
        0.9906248903846466,
        0.8270538936472002
      ],
      "excerpt": "git clone https://github.com/leela-zero/leela-zero \ncd leela-zero \ngit submodule update --init --recursive \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8698200166289988
      ],
      "excerpt": "cmake --build . \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9879863063452118,
        0.9906248903846466,
        0.8270538936472002,
        0.9906248903846466
      ],
      "excerpt": "git clone https://github.com/leela-zero/leela-zero \ncd leela-zero \ngit submodule update --init --recursive \ncd msvc \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9304772622292063,
        0.9501251230111366
      ],
      "excerpt": "to the Visual Studio version you have. \nFor Windows, you can use a release package, see \"I want to help\". \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8229637852726345
      ],
      "excerpt": "This requires a working installation of TensorFlow 1.4 or later: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8051851037317995
      ],
      "excerpt": "[ ] Improve GPU batching in the search. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9532312362739296
      ],
      "excerpt": "[ ] CUDA specific version using cuDNN or cuBLAS. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8615764604075481
      ],
      "excerpt": "The weights file is a text file with each line containing a row of coefficients. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8289669050403863
      ],
      "excerpt": "    2) output biases \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9221361021541947
      ],
      "excerpt": "in the tfprocess.py file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8454553703666403
      ],
      "excerpt": "dump_supervised sgffile.sgf train.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8866584713902795
      ],
      "excerpt": "starting with the name train.txt and containing training data generated from \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8090460578397023
      ],
      "excerpt": "The training data consists of files with the following data, all in text \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8142829148706594
      ],
      "excerpt": "first 16 input planes from the previous section \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8612138100060728
      ],
      "excerpt": "1 line with 362 (19x19 + 1) floating point numbers, indicating the search probabilities \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8522043822775097,
        0.8291400007888242
      ],
      "excerpt": "src/leelaz -w weights.txt \ndump_supervised bigsgf.sgf train.out \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9231761409144816
      ],
      "excerpt": "training/tf/parse.py train.out \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9323578162161054
      ],
      "excerpt": "training/tf/parse.py train.out leelaz-model-batchnumber \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/goodls-cs/leela-zero/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "C++",
      "Python",
      "C",
      "CMake",
      "Makefile",
      "Batchfile",
      "QMake"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "GNU General Public License v3.0",
      "url": "https://api.github.com/licenses/gpl-3.0"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "What",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "leela-zero",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "goodls-cs",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/goodls-cs/leela-zero/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* GCC, Clang or MSVC, any C++14 compiler\n* Boost 1.58.x or later, headers and program_options, filesystem and system libraries (libboost-dev, libboost-program-options-dev and libboost-filesystem-dev on Debian/Ubuntu)\n* zlib library (zlib1g & zlib1g-dev on Debian/Ubuntu)\n* Standard OpenCL C headers (opencl-headers on Debian/Ubuntu, or at\nhttps://github.com/KhronosGroup/OpenCL-Headers/tree/master/CL)\n* OpenCL ICD loader (ocl-icd-libopencl1 on Debian/Ubuntu, or reference implementation at https://github.com/KhronosGroup/OpenCL-ICD-Loader)\n* An OpenCL capable device, preferably a very, very fast GPU, with recent\ndrivers is strongly recommended (OpenCL 1.1 support is enough). Don't\nforget to install the OpenCL driver if this part is packaged seperately\nby the Linux distribution (e.g. nvidia-opencl-icd).\nIf you do not have a GPU, add the define \"USE_CPU_ONLY\", for example\nby adding -DUSE_CPU_ONLY=1 to the cmake command line.\n* Optional: BLAS Library: OpenBLAS (libopenblas-dev) or Intel MKL\n* The program has been tested on Windows, Linux and macOS.\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    ./autogtp/autogtp\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "For training a new network, you can use an existing framework (Caffe,\nTensorFlow, PyTorch, Theano), with a set of training data as described above.\nYou still need to contruct a model description (2 examples are provided for\nCaffe), parse the input file format, and outputs weights in the proper format.\n\nThere is a complete implementation for TensorFlow in the training/tf directory.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 22 Dec 2021 23:29:35 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    sudo apt install clinfo && clinfo\n\n    ",
      "technique": "Header extraction"
    }
  ],
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "    ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "    mkdir build && cd build\n\n    ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "    ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "    mkdir build && cd build\n\n    ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "    ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "    ./autogtp/autogtp\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Leela Zero is not meant to be used directly. You need a graphical interface\nfor it, which will interface with Leela Zero through the GTP protocol.\n\nThe engine supports the [GTP protocol, version 2](https://www.lysator.liu.se/~gunnar/gtp/gtp2-spec-draft2/gtp2-spec.html).\n\n[Lizzie](https://github.com/featurecat/lizzie/releases) is a client specifically\nfor Leela Zero which shows live search probilities, a win rate graph, and has\nan automatic game analysis mode. Has binaries for Windows, Mac, and Linux.\n\n[Sabaki](http://sabaki.yichuanshen.de/) is a very nice looking GUI with GTP 2\ncapability.\n\n[LeelaSabaki](https://github.com/SabakiHQ/LeelaSabaki) is modified to\nshow variations and winning statistics in the game tree, as well as a heatmap\non the game board.\n\n[GoReviewPartner](https://github.com/pnprog/goreviewpartner) is a tool for\nautomated review and analysis of games using bots (saved as .rsgf files),\nLeela Zero is supported.\n\nA lot of go software can interface to an engine via GTP,\nso look around.\n\nAdd the --gtp commandline option on the engine command line to enable Leela\nZero's GTP support. You will need a weights file, specify that with the -w option.\n\nAll required commands are supported, as well as the tournament subset, and\n\"loadsgf\". The full set can be seen with \"list_commands\". The time control\ncan be specified over GTP via the time\\_settings command. The kgs-time\\_settings\nextension is also supported. These have to be supplied by the GTP 2 interface,\nnot via the command line!\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "At the end of the game, you can send Leela Zero a \"dump\\_training\" command,\nfollowed by the winner of the game (either \"white\" or \"black\") and a filename,\ne.g:\n\n    dump_training white train.txt\n\nThis will save (append) the training data to disk, in the format described below,\nand compressed with gzip.\n\nTraining data is reset on a new game.\n\n",
      "technique": "Header extraction"
    }
  ]
}
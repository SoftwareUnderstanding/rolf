{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2009.12547",
      "https://arxiv.org/abs/1904.05044",
      "https://arxiv.org/abs/1606.00915",
      "https://arxiv.org/abs/1904.05044"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, A. L. Yuille. DeepLab: Semantic Image\nSegmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs. *IEEE TPAMI*,\n2018.<br>\n[Project](http://liangchiehchen.com/projects/DeepLab.html) /\n[Code](https://bitbucket.org/aquariusjay/deeplab-public-ver2) / \n[Paper](https://arxiv.org/abs/1606.00915)\n\n2. M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, A. Zisserman. The PASCAL Visual Object\nClasses (VOC) Challenge. *IJCV*, 2010.<br>\n[Project](http://host.robots.ox.ac.uk/pascal/VOC) /\n[Paper](http://host.robots.ox.ac.uk/pascal/VOC/pubs/everingham10.pdf)\n\n3. Ahn, Jiwoon and Cho, Sunghyun and Kwak, Suha. Weakly Supervised Learning of Instance Segmentation with Inter-pixel Relations. *CVPR*, 2019.<br>\n[Project](https://github.com/jiwoon-ahn/irn) /\n[Paper](https://arxiv.org/abs/1904.05044)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find the code useful, please consider citing our paper using the following BibTeX entry.\n```\n@InProceedings{dong_2020_conta,\nauthor = {Dong, Zhang and Hanwang, Zhang and Jinhui, Tang and Xiansheng, Hua and Qianru, Sun},\ntitle = {Causal Intervention for Weakly Supervised Semantic Segmentation},\nbooktitle = {NeurIPS},\nyear = 2020\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@InProceedings{dong_2020_conta,\nauthor = {Dong, Zhang and Hanwang, Zhang and Jinhui, Tang and Xiansheng, Hua and Qianru, Sun},\ntitle = {Causal Intervention for Weakly Supervised Semantic Segmentation},\nbooktitle = {NeurIPS},\nyear = 2020\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9997717563011415,
        0.8356013927728488
      ],
      "excerpt": "Dong Zhang, Hanwang Zhang, Jinhui Tang, Xiansheng Hua, and Qianru Sun. \nNeurIPS, 2020. [CONTA] \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dongzhang89/CONTA",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-09-26T00:47:20Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T07:52:04Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9319593666235452
      ],
      "excerpt": "For pseudo-mask generaction, we follow the method in IRNet without the instance-wise step. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9785492424137093
      ],
      "excerpt": "* Remember to replace the ground_truth annotation in PASCAL VOC 2012 with the generated pseudo_mask. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation for paper: Causal Intervention for Weakly-Supervised Semantic Segmentation",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* PASCAL VOC 2012 in http://host.robots.ox.ac.uk/pascal/VOC/voc2012/#devkit\n* COCO 2014 in https://cocodataset.org/\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ZHANGDONG-NJUST/CONTA/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 21,
      "date": "Thu, 23 Dec 2021 23:32:26 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dongzhang89/CONTA/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "dongzhang89/CONTA",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ZHANGDONG-NJUST/CONTA/master/pseudo_mask/docker/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ZHANGDONG-NJUST/CONTA/master/segmentation/scripts/setup_voc12.sh",
      "https://raw.githubusercontent.com/ZHANGDONG-NJUST/CONTA/master/segmentation/scripts/train_eval.sh",
      "https://raw.githubusercontent.com/ZHANGDONG-NJUST/CONTA/master/pseudo_mask/docker/build_push_docker.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Model: DeepLab v2 with ResNet-101 backbone. Dilated rates of ASPP are (6, 12, 18, 24). Output stride is 8 times.\n* GPU: All the GPUs visible to the process are used. Please specify the scope with CUDA_VISIBLE_DEVICES=0,1,2,3.\n* Multi-scale loss: Loss is defined as a sum of responses from multi-scale inputs (1x, 0.75x, 0.5x) and element-wise max across the scales. The unlabeled class is ignored in the loss computation.\n* Learning rate: Stochastic gradient descent (SGD) is used with momentum of 0.9 and initial learning rate of 2.5e-4. Polynomial learning rate decay is employed; the learning rate is multiplied by ```(1-iter/iter_max)**power``` at every 10 iterations.\n* Monitoring: Moving average loss (average_loss in Caffe) can be monitored in TensorBoard.\n* Preprocessing: Input images are randomly re-scaled by factors ranging from 0.5 to 1.5, padded if needed, and randomly cropped to 321x321.\n* You can find more useful tools in /tools/xxx.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npython main.py test --config-path configs/voc12.yaml \\\n    --model-path data/models/voc12/deeplabv2_resnet101_msc/train_aug/final_model.pth\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9292883486333005
      ],
      "excerpt": "cd pseudo_mask &amp; python run_sample.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9073444634367622
      ],
      "excerpt": "cd segmentation &amp; python main.py train --config-path configs/voc12.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9224681492906003,
        0.9853723880054749
      ],
      "excerpt": "install the extra library below. \npip install torch-encoding \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8704879567092751
      ],
      "excerpt": "cd pseudo_mask &amp; python run_sample.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9315063762228553,
        0.9113837945568138
      ],
      "excerpt": "cd segmentation &amp; python main.py train --config-path configs/voc12.yaml \npython main.py crf --config-path configs/voc12.yaml \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8018910732275644
      ],
      "excerpt": "Batch normalization layers in a model are automatically switched in libs/models/resnet.py. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "    from encoding.nn import SyncBatchNorm \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dongzhang89/CONTA/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Dockerfile",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Dong ZHANG\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Causal Intervention for Weakly Supervised Semantic Segmentation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "CONTA",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "dongzhang89",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dongzhang89/CONTA/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* PyTorch 1.2.0, torchvision 0.4.0, and more in requirements.txt\n* PASCAL VOC 2012 devkit and COCO 2014\n* 8 NVIDIA GPUs, and each has more than 1024MB of memory\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 137,
      "date": "Thu, 23 Dec 2021 23:32:26 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To process a single image:\n\n```\npython tools/demo.py single \\\n    --config-path configs/voc12.yaml \\\n    --model-path model.pth \\\n    --image-path image.jpg\n```\n\nTo run on a webcam:\n\n```\npython tools/demo.py live \\\n    --config-path configs/voc12.yaml \\\n    --model-path model.pth\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "I found these repos useful (while developing this one):\n* [gans](https://github.com/diegoalejogm/gans) (PyTorch & TensorFlow)\n* [PyTorch-GAN](https://github.com/eriklindernoren/PyTorch-GAN) (PyTorch)\n\n",
      "technique": "Header extraction"
    }
  ],
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this code useful for your research, please cite the following:\n\n```\n@misc{Gordi\u01072020PyTorchGANs,\n  author = {Gordi\u0107, Aleksa},\n  title = {pytorch-gans},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/gordicaleksa/pytorch-gans}},\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{Gordi\u01072020PyTorchGANs,\n  author = {Gordi\u0107, Aleksa},\n  title = {pytorch-gans},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/gordicaleksa/pytorch-gans}},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9620956807773079
      ],
      "excerpt": "GANs were originally proposed by Ian Goodfellow et al. in a seminal paper called Generative Adversarial Nets. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/gordicaleksa/pytorch-GANs",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-09-01T07:29:57Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-19T04:53:15Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9534305970666268,
        0.940620173595664,
        0.9530646798102907
      ],
      "excerpt": "This repo contains PyTorch implementation of various GAN architectures. <br/> \nIt's aimed at making it easy for beginners to start playing and learning about GANs. <br/> \nAll of the repos I found do obscure things like setting bias in some network layer to False without explaining <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9940110517580746,
        0.9946618186368507,
        0.9309019852695842
      ],
      "excerpt": "The generator is trying to learn the distribution of real data and is the network which we're usually interested in. \nDuring the game the goal of the generator is to trick the discriminator into \"thinking\" that the data it generates is real. \nThe goal of the discriminator, on the other hand, is to correctly discriminate between the generated (fake) images and real images coming from some dataset (e.g. MNIST). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9825581981079187,
        0.9310881766255029
      ],
      "excerpt": "Vanilla GAN is my implementation of the original GAN paper (Goodfellow et al.) with certain modifications mostly in the model architecture, \nlike the usage of LeakyReLU and 1D batch normalization (it didn't even exist back then) instead of the maxout activation and dropout. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8513230134058168
      ],
      "excerpt": "* Dump intermediate generated imagery into data/debug_imagery/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.976281395441896
      ],
      "excerpt": "It will display and dump the generated image into data/generated_imagery/ using checked-in generator model. <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8165121818365132,
        0.9661185878853465,
        0.8601200665394556
      ],
      "excerpt": "Finally it will start displaying interpolated imagery and dump the results to data/interpolated_imagery. \nConditional GAN (cGAN) is my implementation of the cGAN paper (Mehdi et al.).<br/> \nIt basically just adds conditioning vectors (one hot encoding of digit labels) to the vanilla GAN above. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9425919319033303
      ],
      "excerpt": "There is no interpolation support for cGAN, it's the same as for vanilla GAN feel free to use that. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9661185878853465,
        0.8071486914707056,
        0.9329209737477044
      ],
      "excerpt": "DCGAN is my implementation of the DCGAN paper (Radford et al.).<br/> \nThe main contribution of the paper was that they were the first who made CNNs successfully work in the GAN setup.<br/> \nBatch normalization was invented in the meanwhile and that's what got CNNs to work basically. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "My implementation of various GAN (generative adversarial networks) architectures like vanilla GAN (Goodfellow et al.), cGAN (Mirza et al.), DCGAN (Radford et al.), etc.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/gordicaleksa/pytorch-gans/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 37,
      "date": "Sun, 26 Dec 2021 15:24:03 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/gordicaleksa/pytorch-GANs/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "gordicaleksa/pytorch-GANs",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/gordicaleksa/pytorch-gans/master/Vanilla%20GAN%20%28PyTorch%29.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. `git clone https://github.com/gordicaleksa/pytorch-gans`\n2. Open Anaconda console and navigate into project directory `cd path_to_repo`\n3. Run `conda env create` from project directory (this will create a brand new conda environment).\n4. Run `activate pytorch-gans` (for running scripts from your console or set the interpreter in your IDE)\n\nThat's it! It should work out-of-the-box executing environment.yml file which deals with dependencies.\n\n-----\n\nPyTorch package will pull some version of CUDA with it, but it is highly recommended that you install system-wide CUDA beforehand, mostly because of GPU drivers. I also recommend using Miniconda installer as a way to get conda on your system. \n\nFollow through points 1 and 2 of [this setup](https://github.com/Petlja/PSIML/blob/master/docs/MachineSetup.md) and use the most up-to-date versions of Miniconda and CUDA/cuDNN.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9738186407692239
      ],
      "excerpt": "If you created the env before I added jupyter just do pip install jupyter==1.0.0 and you're ready. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9927186821877624
      ],
      "excerpt": "Just do pip uninstall pywin32 and then either pip install pywin32 or conda install pywin32 should fix it! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8162740945022658
      ],
      "excerpt": "python train_vanilla_gan.py --batch_size &lt;number which won't break your GPU's VRAM&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8118186214819434
      ],
      "excerpt": "You have 3 options you can set the generation_mode to: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8210266215504783
      ],
      "excerpt": "* Dump checkpoint .pth models into models/checkpoints/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8511222646116613
      ],
      "excerpt": "* Download MNIST (~100 MB) the first time you run it and place it into data/MNIST/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.946495524180117,
        0.939492524023384
      ],
      "excerpt": "<img src=\"data/examples/intermediate_imagery.PNG\" height=\"250\"/> \n<img src=\"data/examples/losses.PNG\" height=\"250\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python generate_imagery.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8054844045196046
      ],
      "excerpt": "The first time you run it in this mode the script will start generating images, <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8391724846108043
      ],
      "excerpt": "Again just use the generate_imagery.py script. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/gordicaleksa/pytorch-GANs/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# PyTorch GANs :computer: vs :computer: = :heart:",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "pytorch-GANs",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "gordicaleksa",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/gordicaleksa/pytorch-GANs/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 302,
      "date": "Sun, 26 Dec 2021 15:24:03 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "gans",
      "generative-adversarial-nets",
      "generative-adversarial-networks",
      "vanilla-gan",
      "conditional-gan",
      "dc-gan",
      "pytorch",
      "python",
      "machine-learning",
      "deep-learning",
      "deep-learning-tutorial",
      "gan-tutorial"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "GAN was trained on data from MNIST dataset. Here is how the digits from the dataset look like:\n\n<p align=\"center\">\n<img src=\"data/examples/real_samples/mnist.jpg\" width=\"850\"/>\n</p>\n\nYou can see how the network is slowly learning to capture the data distribution during training:\n\n<p align=\"center\">\n<img src=\"data/examples/training_progress/training_progress_vgan.gif\" />\n</p>\n\nAfter the generator is trained we can use it to generate all 10 digits! Looks like it's coming directly from MNIST, right!?\n\n<p align=\"center\">\n<img src=\"data/examples/generated_samples/generated_vgan.jpg\" width=\"850\"/>\n</p>\n\nWe can also pick 2 generated numbers that we like, save their latent vectors, and subsequently [linearly](https://en.wikipedia.org/wiki/Linear_interpolation) or [spherically](https://en.wikipedia.org/wiki/Slerp)<br/>\ninterpolate between them to generate new images and understand how the latent space (z-space) is structured:\n\n<p align=\"center\">\n<img src=\"data/examples/interpolation/vgan_interpolated.jpg\" width=\"850\"/>\n</p>\n\nWe can see how the number 4 is slowly morphing into 9 and then into the number 3. <br/>\n\nThe idea behind spherical interpolation is super easy - instead of moving over the shortest possible path<br/>\n(line i.e. linear interpolation) from the first vector (p0) to the second (p1), you take the sphere's arc path: \n\n<p align=\"center\">\n<img src=\"data/examples/interpolation/slerp.png\" width=\"330\"/>\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "In addition to everything that we could do with the original GAN, here we can exactly control which digit we want to generate!\nWe make it dump 10x10 grid where each column is a single digit and this is how the learning proceeds:\n\n<p align=\"center\">\n<img src=\"data/examples/training_progress/training_progress_cgan.gif\" />\n</p>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "For training just check out [vanilla GAN](#training) (just make sure to use `train_cgan.py` instead).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "I trained DCGAN on preprocessed [CelebA dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html). Here are some samples from the dataset:\n\n<p align=\"center\">\n<img src=\"data/examples/real_samples/celeba.jpg\" width=\"850\"/>\n</p>\n\nAgain, you can see how the network is slowly learning to capture the data distribution during training:\n\n<p align=\"center\">\n<img src=\"data/examples/training_progress/training_progress_dcgan.gif\" />\n</p>\n\nAfter the generator is trained we can use it to generate new faces! This problem is much harder than generating MNIST digits,\nso generated faces are not indistinguishable from the real ones.\n\n<p align=\"center\">\n<img src=\"data/examples/generated_samples/generated_dcgan.jpg\" width=\"850\"/>\n</p>\n\nSome SOTA GAN papers did a much better job at generating faces, currently the best model is [StyleGAN2](https://github.com/NVlabs/stylegan2).\n\nSimilarly we can explore the structure of the latent space via interpolations:\n\n<p align=\"center\">\n<img src=\"data/examples/interpolation/dcgan_interpolated.jpg\" width=\"850\"/>\n</p>\n\nWe can see how the man's face is slowly morphing into woman's face and also the skin tan is changing gradually.\n\nFinally, because the latent space has some nice properties (linear structure) we can do some interesting things.<br/>\nSubtracting neutral woman's latent vector from smiling woman's latent vector gives us the \"smile vector\". <br/>\nAdding that vector to neutral man's latent vector, we hopefully get smiling man's latent vector. And so it is!\n\n<p align=\"center\">\n<img src=\"data/examples/vector_arithmetic/vector_arithmetic.jpg\" />\n</p>\n\nYou can also create the \"sunglasses vector\" and use it to add sunglasses to other faces, etc.\n\n*Note: I've created an interactive script so you can play with this check out `GenerationMode.VECTOR_ARITHMETIC`.*\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "For training just check out [vanilla GAN](#training) (just make sure to use `train_dcgan.py` instead). <br/>\nThe only difference is that this script will download [pre-processed CelebA dataset](https://s3.amazonaws.com/video.udacity-data.com/topher/2018/November/5be7eb6f_processed-celeba-small/processed-celeba-small.zip) instead of MNIST.\n\n",
      "technique": "Header extraction"
    }
  ]
}
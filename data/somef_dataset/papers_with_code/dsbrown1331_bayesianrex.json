{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2002.09089\">View on ArXiv</a> |\n  <a href=\"https://sites.google.com/view/bayesianrex/\">Project Website</a>\n</p>\n\n\nBayesian REX pipeline:\n<p align=center>\n  <img src='assets/BREXslide.png' width=1000>\n</p>\n\n\n\nThis repository contains code used to conduct the Atari experiments reported in the paper \"Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences\" published at ICML 2020. \n\nIf you are interested in the gridworld experiments reported in the Appendix, please see this repo [brex_gridworld_cpp](https://github.com/dsbrown1331/brex_gridworld_cpp"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@InProceedings{brown2020safe,\n  title = {Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences},\n  author = {Brown, Daniel S. and  Coleman, Russell and Srinivasan, Ravi and Niekum, Scott},\n  booktitle = {Proceedings of the 37th International Conference on Machine Learning (ICML)},\n  year = {2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9992837163399597
      ],
      "excerpt": "  <a href=\"https://arxiv.org/abs/2002.09089\">View on ArXiv</a> | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9997904330613038
      ],
      "excerpt": "If you find this repository is useful in your research, please cite the paper: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dsbrown1331/bayesianrex",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-23T16:58:29Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-23T02:54:16Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9314137424765941
      ],
      "excerpt": "This repository contains code used to conduct the Atari experiments reported in the paper \"Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences\" published at ICML 2020.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8567477396747055
      ],
      "excerpt": "This will generate a text file \"breakout_mcmcm.txt\" of the weights and loglikelihoods from MCMC. It will also produce a file \"breakout_map.params\" with the parameters of the MAP reward function found via MCMC. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9705944601824906,
        0.8276122148087647
      ],
      "excerpt": "to compute the mean and standard deviation of the policy performance on the ground truth reward. \nFirst perform policy evaluation to get the expected feature counts of the policy using \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.818272206932785
      ],
      "excerpt": "To evalute the performance of a policy under the posterior distribution simply run \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9525492774354177,
        0.9768339003500855
      ],
      "excerpt": "See the following files in the code/ directory for reproducing the visualizations of the latent space found in the Appendix. \nGenerates demonstration videos from pretrained RL agents, and plots the encoding into the latent space as well as the decoding over time. Takes one argument, which is a pretrained network. \n",
      "technique": "Supervised classification"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "For demonstrations we used the data from Brown et al. \"Extrapolating beyond suboptimal demonstrations via inverse reinforcement learning from observations\", ICML, 2019.\nTo download the demonstration data, download from here (https://github.com/dsbrown1331/learning-rewards-of-learners/releases/), and extract the files in a directory called models.\n\n\nFor simplicity, in the following examples we have used Breakout as the environment, but this can be replaced with any of the other environments in the ALE.\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dsbrown1331/bayesianrex/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Wed, 29 Dec 2021 04:36:27 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dsbrown1331/bayesianrex/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "dsbrown1331/bayesianrex",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/dsbrown1331/bayesianrex/master/code/baselines/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/dsbrown1331/bayesianrex/tree/master/code/baselines/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/dsbrown1331/bayesianrex/master/code/baselines/docs/viz/viz.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/dsbrown1331/bayesianrex/master/code/scripts/strip_to_embedding_networks.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Follow the instructions in `code/baselines/README.md`\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```conda env create -f environment.yml```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.959748597937764,
        0.9770335174395833
      ],
      "excerpt": "cd code/ \nconda activate bayesianrex \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9467586318593582,
        0.8459557886237692
      ],
      "excerpt": "cd code/scripts/ \nbash strip_to_embedding_networks.sh ../../pretrained_networks/ breakout_pretrained.params \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.959748597937764
      ],
      "excerpt": "cd code/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.959748597937764
      ],
      "excerpt": "cd code/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9467586318593582
      ],
      "excerpt": "cd code/scripts/ \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8890818307099057
      ],
      "excerpt": "  <img src='assets/BREXslide.png' width=1000> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278802297796007
      ],
      "excerpt": "python LearnAtariRewardLinear.py --env_name breakout --reward_model_path ../pretrained_networks/breakout_pretrained.params --models_dir ../ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9370578944475804
      ],
      "excerpt": "The main file to run is: LinearFeatureMCMC_auxiliary.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8429763161332972
      ],
      "excerpt": "Here's an example of how to run it: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9154952117013955
      ],
      "excerpt": "python LinearFeatureMCMC_auxiliary.py --env_name breakout --models_dir ../models/ --weight_outputfile ../mcmc_data/breakout_mcmc.txt --num_mcmc_steps 200000 --map_reward_model_path ../mcmc_data/breakout_map.params --pretrained_network ../pretrained_networks/breakout_pretrained.params_stripped.params --encoding_dims 64 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8461290029422484,
        0.8444672124726323,
        0.9057141576228696
      ],
      "excerpt": "python evaluateLearnedPolicy.py --checkpointpath ~/tflogs/breakout_mean/checkpoints/43000 \nThis will write the output to the code/eval/ folder. You can then run the helper script \npython compute_mean_std.py [name of generated file] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python computePolicyExpectedFeatureCountsNetwork.py --env_name breakout --checkpointpath \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8975732807828887
      ],
      "excerpt": "python computePolicyExpectedFeatureCountsNetwork.py --env_name breakout --checkpointpath ~/tflogs/breakout_map/checkpoints/43000 --pretrained_network ../pretrained_networks/breakout_pretrained.params_stripped.params --fcount_file ../policy_evals/breakout_map_fcounts.txt \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dsbrown1331/bayesianrex/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "HTML",
      "Jupyter Notebook",
      "Shell",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License\\n\\nCopyright (c) 2017 OpenAI (http://openai.com)\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\nTHE SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "bayesianrex",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "dsbrown1331",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dsbrown1331/bayesianrex/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```conda env create -f environment.yml```\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\nconda activate bayesianrex\nOPENAI_LOG_FORMAT='stdout,log,csv,tensorboard' OPENAI_LOGDIR=~/tflogs/breakout_mean python -m baselines.run --alg=ppo2 --env=BreakoutNoFrameskip-v4 --custom_reward mcmc_mean --custom_reward_path ../mcmc_data/breakout_map.params --mcmc_chain_path ../mcmc_data/breakout_mcmc.txt --seed 0 --num_timesteps=5e7  --save_interval=43000 --num_env 9 --embedding_dim 64\n```\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\nconda activate bayesianrex\nOPENAI_LOG_FORMAT='stdout,log,csv,tensorboard' OPENAI_LOGDIR=~/tflogs/breakout_mean python -m baselines.run --alg=ppo2 --env=BreakoutNoFrameskip-v4 --custom_reward mcmc_map --custom_reward_path ../mcmc_data/breakout_map.params --seed 0 --num_timesteps=5e7  --save_interval=43000 --num_env 9 --embedding_dim 64\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Wed, 29 Dec 2021 04:36:27 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npython run_test.py --env_id BreakoutNoFrameskip-v4 --env_type atari --model_path ../models/breakout/checkpoints/03600 --record_video --episode_count 1 --render\n```\n\nYou can omit the last flag --record_video. When it is turned on, then the videos will be recorded in a videos/ directory below the current directory. If --render is omitted then it will simply print returns to the command line.\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@inproceedings{HeICLR2017,\n  author = {F.~S. He, Y. Liu, A.~G. Schwing and J. Peng},\n  title = {{Learning to Play in a Day: Faster Deep Reinforcement Learning by Optimality Tightening}},\n  booktitle = {Proc. ICLR},\n  year = {2017},\n}\n```\n\n[frostbite_cl2_1]: figures/frostbite_cl2_1.png\n[frostbite_cl2_2]: figures/frostbite_cl2_2.png\n[frostbite_r15_1]: figures/frostbite_r15_1.png\n[frostbite_r15_2]: figures/frostbite_r15_2.png\n[gopher]: figures/gopher.png\n[hero]: figures/hero.png\n[star_gunner]: figures/star_gunner.png\n[zaxxon]: figures/zaxxon.png\n[A3C]: figures/a3c_fig.png\n[beam_rider]: figures/beam_rider_time.png\n[breakout]: figures/breakout_time.png\n[pong]: figures/pong_time.png\n[qbert]: figures/qbert_time.png\n[space_invaders]: figures/space_invaders_time.png\n[rescale]: figures/rescale.png\n[frame]: figures/frame.png\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{HeICLR2017,\n  author = {F.~S. He, Y. Liu, A.~G. Schwing and J. Peng},\n  title = {{Learning to Play in a Day: Faster Deep Reinforcement Learning by Optimality Tightening}},\n  booktitle = {Proc. ICLR},\n  year = {2017},\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ShibiHe/Q-Optimality-Tightening",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-03-08T23:21:41Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-23T08:59:30Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.985355570432353
      ],
      "excerpt": "This is my implementation to paper Learning to Play in a Day: Faster Deep Reinforcement Learning by Optimality Tightening. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9448246037369588
      ],
      "excerpt": "Two other figures runned with sampling 4 bounds out of 15 are below: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9842429520243545
      ],
      "excerpt": "Finally, we can roughly compare our method with state-of-art method A3C. Our method is using 1 CPU thread and 1 GPU (GPU Occupation is 30%) while A3C is using multiple CPU threads. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.926912729474105
      ],
      "excerpt": "Our results: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9884032675166756
      ],
      "excerpt": "From the observations, our method almost always outperforms 1,2 and 4 threads A3C and achieves similar results as 8 threads A3C. To be noticed, these five games chosen by A3C paper are not our method's specialties. Our method would definitely achieve much better performance if we run tests on games that our method is good at. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This is my implementation of the Optimality Tightening",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ShibiHe/Q-Optimality-Tightening/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Mon, 20 Dec 2021 15:19:25 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ShibiHe/Q-Optimality-Tightening/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ShibiHe/Q-Optimality-Tightening",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8173734319249142
      ],
      "excerpt": "First I will show two figures runned on frostbite with --close2: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ShibiHe/Q-Optimality-Tightening/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Q-Optimality-Tightening",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Q-Optimality-Tightening",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ShibiHe",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ShibiHe/Q-Optimality-Tightening/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Numpy\n* Scipy\n* Pillow\n* Matplotlib\n* Theano\n* Lasagne\n* ALE or gym\n\nReaders might refer to <https://github.com/spragunr/deep_q_rl> for installation information. However, I suggest readers installing all the packages using virtual environment. Please make sure the version of Theano is compatible with the one of Lasagne.\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\nTHEANO_FLAGS='deivce=gpu0, allow_gc=False' python run_OT -r frostbite --close2\n```\nRunning frostbite with close boundes.\n\n```\nTHEANO_FLAGS='device=gpu1, allow_gc=False' python run_OT -r gopher\n```\n\nRunning gopher with randomly sampled bounds. Default: 4 out of 10 upper bounds are selected as U\\_{j,k}. 4 out of 10 lower bounds are selected as L\\_{j,l}.\n\nI have already provided 62 game roms.\n\nIf everything is configured correctly, the running should be like this:\n\n<img src=\"figures/gopher_running.png\" width=\"320\" height=\"450\" />\n<img src=\"figures/star_gunner_running.png\" width=\"320\" height=\"450\" />\n\nsteps per second is usually between 105 to 140 using one Titan X. The GPU Occupation is about 30 percent which means our code still has huge space of improvement.\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 35,
      "date": "Mon, 20 Dec 2021 15:19:25 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2001.09522"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jmshen1994/TaxoExpan",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-01-20T17:15:01Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-29T06:32:30Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8239202838038562
      ],
      "excerpt": "Finally, it saves the generated dataset (along with all initial node features) in one pickle file for fast loading next time. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8249525053233322
      ],
      "excerpt": "For example, you can indicate the architectures of graph propagation module, graph readout module, and matching module as follow: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9501331111708056,
        0.9968029537584643,
        0.9968029537584643,
        0.9968029537584643
      ],
      "excerpt": "We assume the input taxon list is of the following format: \nterm1 \\t embeddings of term1 \nterm2 \\t embeddings of term2 \nterm3 \\t embeddings of term3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9858384820243684
      ],
      "excerpt": "The embedding is space-sperated and of the same dimension of trained model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9148759538992439,
        0.8211385461855366
      ],
      "excerpt": "The model prediction results are saved in OUTPUT_RESULT.tsv. \nPretained models for MAG-CS and MAG-Full datasets can be downloaded from Google Drive. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9544104283316981
      ],
      "excerpt": "bert_base_uncased_defonly: the embedding obtained based on definition sentences based on BERT_base_uncased model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8135642387338621,
        0.8073968990552102
      ],
      "excerpt": "fasttext_mode4: the average of (1) average fasttext word embedding in definition sentences, (2) average fasttext word embedding in lemma names, and (3) average fasttext word embedding of the first word in definition sentence that has the same part-of-speech tag as the lemma's part-of-speech tag. If this same POS word cannot be found, we simply double the weight of definition sentence embedding \nThe detailed preprocessing code please refer to ./data_preprocessing/semeval-task14.ipython. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "The source code used for self-supervised taxonomy expansion method TaxoExpan, published in WWW 2020",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/mickeystroller/TaxoExpan/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 11,
      "date": "Wed, 29 Dec 2021 10:38:50 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/jmshen1994/TaxoExpan/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "jmshen1994/TaxoExpan",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/mickeystroller/TaxoExpan/master/data_preprocessing/mag-cs-fos.ipynb",
      "https://raw.githubusercontent.com/mickeystroller/TaxoExpan/master/data_preprocessing/semeval-task14.ipynb",
      "https://raw.githubusercontent.com/mickeystroller/TaxoExpan/master/data_preprocessing/mag-all-fos.ipynb",
      "https://raw.githubusercontent.com/mickeystroller/TaxoExpan/master/baselines/simple_MLP/test_simple_MLP.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/mickeystroller/TaxoExpan/master/baselines/simple_structure.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "For dataset used in our WWW paper, you can directly download all input files from [Google Drive](https://drive.google.com/drive/folders/1-_yaDYDbivAW_ZA3em8WTbxDSnfIZfV9?usp=sharing) and skip this section.\n\nFor expanding new input taxonomies, you need to read this section and format your datasets accordingly.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "From following page: [https://www.dgl.ai/pages/start.html](https://www.dgl.ai/pages/start.html)\n\n```\nconda install -c dglteam dgl-cuda10.0\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.892870354853123
      ],
      "excerpt": "You can generate your desired train/validation/test parition files by creating another 3 separated files (named <TAXONOMY_NAME>.terms.train, <TAXONOMY_NAME>.terms.validation, as well as <TAXONOMY_NAME>.terms.test) and puting them in the same directory as the above three required files. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8415347187714453
      ],
      "excerpt": "create a folder \"./data/{DATASET_NAME}\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python generate_dataset_binary.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.902349471256931
      ],
      "excerpt": "Then, if existing_partition is 0, it will generate a random train/validation/test partitions, otherwise, it will load the existing train/validation/test partition files. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.833053081225945,
        0.8717399063841372
      ],
      "excerpt": "Write all the parameters in ./config_files/config.universal.json and start training. \npython train.py --config config_files/config.universal.json \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8676246386227282
      ],
      "excerpt": "python train.py --config config_files/config.universal.json --pm PGAT --rm WMR --mm LBM --device 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.857992959857679,
        0.8614920799784626
      ],
      "excerpt": "An input example is provided: ./data/mag_cs_new637.txt. \nAn output example is provided: ./case_studies/infer_results_637_20191111.txt. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8834466297274138
      ],
      "excerpt": "For SemEval data, after training the model and running the test script with case study output, you need to read the script /scripts/parse_to_semeval_format.py to generate a tsv that satisfies the format requirements in original SemEval completition as follows: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/jmshen1994/TaxoExpan/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Apache License 2.0",
      "url": "https://api.github.com/licenses/apache-2.0"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "TaxoExpan",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "TaxoExpan",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "jmshen1994",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/jmshen1994/TaxoExpan/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 58,
      "date": "Wed, 29 Dec 2021 10:38:50 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npython test_fast.py --resume <MODEL_CHECKPOINT.pth> --case <OUTPUT_CASE_FILE.tsv> --device 0\n```\n\nNote: test with case study saving will almost double the running time, so if you don't really need to see the predicted parents, disable this functionality.\n\n",
      "technique": "Header extraction"
    }
  ],
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "taxonomy",
      "self-supervised-learning",
      "graph-neural-network"
    ],
    "technique": "GitHub API"
  }
}
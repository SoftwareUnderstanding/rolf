{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.06870"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find Faster R-CNN useful in your research, please consider citing:\n\n    @inproceedings{renNIPS15fasterrcnn,\n        Author = {Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun},\n        Title = {Faster {R-CNN}: Towards Real-Time Object Detection\n                 with Region Proposal Networks},\n        Booktitle = {Advances in Neural Information Processing Systems ({NIPS})},\n        Year = {2015}\n    }\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{renNIPS15fasterrcnn,\n    Author = {Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun},\n    Title = {Faster {R-CNN}: Towards Real-Time Object Detection\n             with Region Proposal Networks},\n    Booktitle = {Advances in Neural Information Processing Systems ({NIPS})},\n    Year = {2015}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9540798979593713
      ],
      "excerpt": "If your goal is to reproduce the results in our NIPS 2015 paper, please use the official code. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999491505988155
      ],
      "excerpt": "By Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun (Microsoft Research) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yj-littlesky/py-faster-rcnn",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-10T02:06:50Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-10T02:07:17Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9704793885583791,
        0.9341285711573113,
        0.9455531164947442,
        0.9871634136065554
      ],
      "excerpt": "The official Faster R-CNN code (written in MATLAB) is available here. \nIf your goal is to reproduce the results in our NIPS 2015 paper, please use the official code. \nThis repository contains a Python reimplementation of the MATLAB code. \nThis Python implementation is built on a fork of Fast R-CNN. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8159034167670202
      ],
      "excerpt": " - is ~10% slower at test-time, because some operations execute on the CPU in Python layers (e.g., 220ms / image vs. 200ms / image for VGG16) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9619390388808967,
        0.9905793234340708
      ],
      "excerpt": " - is not compatible with models trained using the MATLAB code due to the minor implementation differences \n - includes approximate joint training that is 1.5x faster than alternating optimization (for VGG16) -- see these slides for more information \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9777589556803118,
        0.8503523529798234
      ],
      "excerpt": "Please see the official README.md for more details. \nFaster R-CNN was initially described in an arXiv tech report and was subsequently published in NIPS 2015. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "fasterrcnn  \u7684\u4ee3\u7801",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Pre-trained ImageNet models can be downloaded for the three networks described in the paper: ZF and VGG16.\n\n```Shell\ncd $FRCN_ROOT\n./data/scripts/fetch_imagenet_models.sh\n```\nVGG16 comes from the [Caffe Model Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo), but is provided here for your convenience.\nZF was trained at MSRA.\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yj-littlesky/py-faster-rcnn/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 03:41:04 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yj-littlesky/py-faster-rcnn/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "yj-littlesky/py-faster-rcnn",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/yj-littlesky/py-faster-rcnn/master/experiments/scripts/fast_rcnn.sh",
      "https://raw.githubusercontent.com/yj-littlesky/py-faster-rcnn/master/experiments/scripts/faster_rcnn_end2end.sh",
      "https://raw.githubusercontent.com/yj-littlesky/py-faster-rcnn/master/experiments/scripts/faster_rcnn_alt_opt.sh",
      "https://raw.githubusercontent.com/yj-littlesky/py-faster-rcnn/master/data/scripts/fetch_faster_rcnn_models.sh",
      "https://raw.githubusercontent.com/yj-littlesky/py-faster-rcnn/master/data/scripts/fetch_selective_search_data.sh",
      "https://raw.githubusercontent.com/yj-littlesky/py-faster-rcnn/master/data/scripts/fetch_imagenet_models.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Download the training, validation, test data and VOCdevkit\n\n\t```Shell\n\twget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n\twget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n\twget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCdevkit_08-Jun-2007.tar\n\t```\n\n2. Extract all of these tars into one directory named `VOCdevkit`\n\n\t```Shell\n\ttar xvf VOCtrainval_06-Nov-2007.tar\n\ttar xvf VOCtest_06-Nov-2007.tar\n\ttar xvf VOCdevkit_08-Jun-2007.tar\n\t```\n\n3. It should have this basic structure\n\n\t```Shell\n  \t$VOCdevkit/                           #: development kit\n  \t$VOCdevkit/VOCcode/                   #: VOC utility code\n  \t$VOCdevkit/VOC2007                    #: image sets, annotations, etc.\n  \t#: ... and several other directories ...\n  \t```\n\n4. Create symlinks for the PASCAL VOC dataset\n\n\t```Shell\n    cd $FRCN_ROOT/data\n    ln -s $VOCdevkit VOCdevkit2007\n    ```\n    Using symlinks is a good idea because you will likely want to share the same PASCAL dataset installation between multiple projects.\n5. [Optional] follow similar steps to get PASCAL VOC 2010 and 2012\n6. [Optional] If you want to use COCO, please see some notes under `data/README.md`\n7. Follow the next sections to download pre-trained ImageNet models\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Clone the Faster R-CNN repository\n  ```Shell\n  #: Make sure to clone with --recursive\n  git clone --recursive https://github.com/rbgirshick/py-faster-rcnn.git\n  ```\n\n2. We'll call the directory that you cloned Faster R-CNN into `FRCN_ROOT`\n\n   *Ignore notes 1 and 2 if you followed step 1 above.*\n\n   **Note 1:** If you didn't clone Faster R-CNN with the `--recursive` flag, then you'll need to manually clone the `caffe-fast-rcnn` submodule:\n    ```Shell\n    git submodule update --init --recursive\n    ```\n    **Note 2:** The `caffe-fast-rcnn` submodule needs to be on the `faster-rcnn` branch (or equivalent detached state). This will happen automatically *if you followed step 1 instructions*.\n\n3. Build the Cython modules\n    ```Shell\n    cd $FRCN_ROOT/lib\n    make\n    ```\n\n4. Build Caffe and pycaffe\n    ```Shell\n    cd $FRCN_ROOT/caffe-fast-rcnn\n    #: Now follow the Caffe installation instructions here:\n    #:   http://caffe.berkeleyvision.org/installation.html\n\n    #: If you're experienced with Caffe and have all of the requirements installed\n    #: and your Makefile.config in place, then simply do:\n    make -j8 && make pycaffe\n    ```\n\n5. Download pre-computed Faster R-CNN detectors\n    ```Shell\n    cd $FRCN_ROOT\n    ./data/scripts/fetch_faster_rcnn_models.sh\n    ```\n\n    This will populate the `$FRCN_ROOT/data` folder with `faster_rcnn_models`. See `data/README.md` for details.\n    These models were trained on VOC 2007 trainval.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8864574716181884,
        0.8028459453632889
      ],
      "excerpt": "Requirements: hardware \nBasic installation \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/yj-littlesky/py-faster-rcnn/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C",
      "Shell",
      "Cuda",
      "MATLAB",
      "C++",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/yj-littlesky/py-faster-rcnn/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'Faster R-CNN\\n\\nThe MIT License (MIT)\\n\\nCopyright (c) 2015 Microsoft Corporation\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\nTHE SOFTWARE.\\n\\n**********\\n\\nTHIRD-PARTY SOFTWARE NOTICES AND INFORMATION\\n\\nThis project, Faster R-CNN, incorporates material from the project(s)\\nlisted below (collectively, \"Third Party Code\").  Microsoft is not the\\noriginal author of the Third Party Code.  The original copyright notice\\nand license under which Microsoft received such Third Party Code are set\\nout below. This Third Party Code is licensed to you under their original\\nlicense terms set forth below.  Microsoft reserves all other rights not\\nexpressly granted, whether by implication, estoppel or otherwise.\\n\\n1.\\tCaffe, (https://github.com/BVLC/caffe/)\\n\\nCOPYRIGHT\\n\\nAll contributions by the University of California:\\nCopyright (c) 2014, 2015, The Regents of the University of California (Regents)\\nAll rights reserved.\\n\\nAll other contributions:\\nCopyright (c) 2014, 2015, the respective contributors\\nAll rights reserved.\\n\\nCaffe uses a shared copyright model: each contributor holds copyright\\nover their contributions to Caffe. The project versioning records all\\nsuch contribution and copyright details. If a contributor wants to\\nfurther mark their specific copyright on a particular contribution,\\nthey should indicate their copyright solely in the commit message of\\nthe change when it is committed.\\n\\nThe BSD 2-Clause License\\n\\nRedistribution and use in source and binary forms, with or without\\nmodification, are permitted provided that the following conditions\\nare met:\\n\\n1. Redistributions of source code must retain the above copyright notice,\\nthis list of conditions and the following disclaimer.\\n\\n2. Redistributions in binary form must reproduce the above copyright\\nnotice, this list of conditions and the following disclaimer in the\\ndocumentation and/or other materials provided with the distribution.\\n\\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\\nTO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\\nPROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\\nLIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\\nNEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\n\\n*END OF THIRD-PARTY SOFTWARE NOTICES AND INFORMATION*\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "py-faster-rcnn has been deprecated. Please see [Detectron](https://github.com/facebookresearch/Detectron), which includes an implementation of [Mask R-CNN](https://arxiv.org/abs/1703.06870).",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "py-faster-rcnn",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "yj-littlesky",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/yj-littlesky/py-faster-rcnn/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "**NOTE** If you are having issues compiling and you are using a recent version of CUDA/cuDNN, please consult [this issue](https://github.com/rbgirshick/py-faster-rcnn/issues/509?_pjax=%23js-repo-pjax-container#issuecomment-284133868) for a workaround\n\n1. Requirements for `Caffe` and `pycaffe` (see: [Caffe installation instructions](http://caffe.berkeleyvision.org/installation.html))\n\n  **Note:** Caffe *must* be built with support for Python layers!\n\n  ```make\n  #: In your Makefile.config, make sure to have this line uncommented\n  WITH_PYTHON_LAYER := 1\n  #: Unrelatedly, it's also recommended that you use CUDNN\n  USE_CUDNN := 1\n  ```\n\n  You can download my [Makefile.config](https://dl.dropboxusercontent.com/s/6joa55k64xo2h68/Makefile.config?dl=0) for reference.\n2. Python packages you might not have: `cython`, `python-opencv`, `easydict`\n3. [Optional] MATLAB is required for **official** PASCAL VOC evaluation only. The code now includes unofficial Python evaluation code.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. For training smaller networks (ZF, VGG_CNN_M_1024) a good GPU (e.g., Titan, K20, K40, ...) with at least 3G of memory suffices\n2. For training Fast R-CNN with VGG16, you'll need a K40 (~11G of memory)\n3. For training the end-to-end version of Faster R-CNN with VGG16, 3G of GPU memory is sufficient (using CUDNN)\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 03:41:04 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Clone the Faster R-CNN repository\n  ```Shell\n  #: Make sure to clone with --recursive\n  git clone --recursive https://github.com/rbgirshick/py-faster-rcnn.git\n  ```\n\n2. We'll call the directory that you cloned Faster R-CNN into `FRCN_ROOT`\n\n   *Ignore notes 1 and 2 if you followed step 1 above.*\n\n   **Note 1:** If you didn't clone Faster R-CNN with the `--recursive` flag, then you'll need to manually clone the `caffe-fast-rcnn` submodule:\n    ```Shell\n    git submodule update --init --recursive\n    ```\n    **Note 2:** The `caffe-fast-rcnn` submodule needs to be on the `faster-rcnn` branch (or equivalent detached state). This will happen automatically *if you followed step 1 instructions*.\n\n3. Build the Cython modules\n    ```Shell\n    cd $FRCN_ROOT/lib\n    make\n    ```\n\n4. Build Caffe and pycaffe\n    ```Shell\n    cd $FRCN_ROOT/caffe-fast-rcnn\n    #: Now follow the Caffe installation instructions here:\n    #:   http://caffe.berkeleyvision.org/installation.html\n\n    #: If you're experienced with Caffe and have all of the requirements installed\n    #: and your Makefile.config in place, then simply do:\n    make -j8 && make pycaffe\n    ```\n\n5. Download pre-computed Faster R-CNN detectors\n    ```Shell\n    cd $FRCN_ROOT\n    ./data/scripts/fetch_faster_rcnn_models.sh\n    ```\n\n    This will populate the `$FRCN_ROOT/data` folder with `faster_rcnn_models`. See `data/README.md` for details.\n    These models were trained on VOC 2007 trainval.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "*After successfully completing [basic installation](#installation-sufficient-for-the-demo)*, you'll be ready to run the demo.\n\nTo run the demo\n```Shell\ncd $FRCN_ROOT\n./tools/demo.py\n```\nThe demo performs detection using a VGG16 network trained for detection on PASCAL VOC 2007.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Download the training, validation, test data and VOCdevkit\n\n\t```Shell\n\twget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n\twget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n\twget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCdevkit_08-Jun-2007.tar\n\t```\n\n2. Extract all of these tars into one directory named `VOCdevkit`\n\n\t```Shell\n\ttar xvf VOCtrainval_06-Nov-2007.tar\n\ttar xvf VOCtest_06-Nov-2007.tar\n\ttar xvf VOCdevkit_08-Jun-2007.tar\n\t```\n\n3. It should have this basic structure\n\n\t```Shell\n  \t$VOCdevkit/                           #: development kit\n  \t$VOCdevkit/VOCcode/                   #: VOC utility code\n  \t$VOCdevkit/VOC2007                    #: image sets, annotations, etc.\n  \t#: ... and several other directories ...\n  \t```\n\n4. Create symlinks for the PASCAL VOC dataset\n\n\t```Shell\n    cd $FRCN_ROOT/data\n    ln -s $VOCdevkit VOCdevkit2007\n    ```\n    Using symlinks is a good idea because you will likely want to share the same PASCAL dataset installation between multiple projects.\n5. [Optional] follow similar steps to get PASCAL VOC 2010 and 2012\n6. [Optional] If you want to use COCO, please see some notes under `data/README.md`\n7. Follow the next sections to download pre-trained ImageNet models\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "To train and test a Faster R-CNN detector using the **alternating optimization** algorithm from our NIPS 2015 paper, use `experiments/scripts/faster_rcnn_alt_opt.sh`.\nOutput is written underneath `$FRCN_ROOT/output`.\n\n```Shell\ncd $FRCN_ROOT\n./experiments/scripts/faster_rcnn_alt_opt.sh [GPU_ID] [NET] [--set ...]\n#: GPU_ID is the GPU you want to train on\n#: NET in {ZF, VGG_CNN_M_1024, VGG16} is the network arch to use\n#: --set ... allows you to specify fast_rcnn.config options, e.g.\n#:   --set EXP_DIR seed_rng1701 RNG_SEED 1701\n```\n\n(\"alt opt\" refers to the alternating optimization training algorithm described in the NIPS paper.)\n\nTo train and test a Faster R-CNN detector using the **approximate joint training** method, use `experiments/scripts/faster_rcnn_end2end.sh`.\nOutput is written underneath `$FRCN_ROOT/output`.\n\n```Shell\ncd $FRCN_ROOT\n./experiments/scripts/faster_rcnn_end2end.sh [GPU_ID] [NET] [--set ...]\n#: GPU_ID is the GPU you want to train on\n#: NET in {ZF, VGG_CNN_M_1024, VGG16} is the network arch to use\n#: --set ... allows you to specify fast_rcnn.config options, e.g.\n#:   --set EXP_DIR seed_rng1701 RNG_SEED 1701\n```\n\nThis method trains the RPN module jointly with the Fast R-CNN network, rather than alternating between training the two. It results in faster (~ 1.5x speedup) training times and similar detection accuracy. See these [slides](https://www.dropbox.com/s/xtr4yd4i5e0vw8g/iccv15_tutorial_training_rbg.pdf?dl=0) for more details.\n\nArtifacts generated by the scripts in `tools` are written in this directory.\n\nTrained Fast R-CNN networks are saved under:\n\n```\noutput/<experiment directory>/<dataset name>/\n```\n\nTest outputs are saved under:\n\n```\noutput/<experiment directory>/<dataset name>/<network snapshot name>/\n```\n",
      "technique": "Header extraction"
    }
  ]
}
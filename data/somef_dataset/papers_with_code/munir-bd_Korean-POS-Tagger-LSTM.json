{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1409.3215.\n\n[2] K. Cho, and et al., \"Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation.\u201c, https://arxiv.org/pdf/1406.1078.pdf\n\n[3] https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py\n\nModel is same as [3] but diffrent application. \n\nCharacter-Level Sequence to Sequence Model:\n\n  Input sequences\n  \n    Korean text\n    \n    Corresponding Korean POS-tag text\n    \n  An encoder LSTM turns input sequences to 2 state vectors\n  \n    Preserve the last LSTM state and discard the outputs   \n    \n  A decoder LSTM is trained to the target POS-tag into the same sequence \n  \n    Keep offset by one time-step for future\n    \n    The offset uses as initial state the state vectors from encoder\n    \n    The decoder learns to generate POS-tag [t+1] by a given POS-tag [t]\n    \n    \nInference from trained model:\n\n  Encoder input sequences\n  \n    Encode the Korean text sequence into state vectors\n    \n    Start with a target sequence of size 1 (sequence of characters"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/munir-bd/Korean-POS-Tagger-LSTM",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-01T10:03:12Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-01T10:50:43Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9244315347492909
      ],
      "excerpt": "LSTM_KR_PoS.py :  Character embedding model for Korean part of speech tagging \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9353745318424702
      ],
      "excerpt": "For testing with already train model put all of the saved model files in a  \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/munir-bd/Korean-POS-Tagger-LSTM/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 14:01:44 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/munir-bd/Korean-POS-Tagger-LSTM/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "munir-bd/Korean-POS-Tagger-LSTM",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.9356639835568359,
        0.9616533163261319
      ],
      "excerpt": "python train.py --train_file train.txt \npython test.py --input_file test.txt --output_file result.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9463108787557137,
        0.937439645127337,
        0.8276975204192389,
        0.9368201495134494
      ],
      "excerpt": "train.py : Training script  \ntest.py: Testing script \nFor testing with already train model put all of the saved model files in a  \nsame directory as test.py  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8641715112094356,
        0.9429964871349448,
        0.8570875252364237
      ],
      "excerpt": "Train with train.txt: \n\"Train_Save_Model_10000\" folder contain all learned model using train.txt with a first 10000 data point.  \nModel files Names: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/munir-bd/Korean-POS-Tagger-LSTM/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 MD SHIRAJUM MUNIR\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Korean-POS-Tagger-LSTM\nKorean POS Tagger Using Character-Level Sequence to Sequence Model \n\n[1] I. Sutskever, O. Vinyals, and Q. V. Le, \"Sequence to sequence learning with neural networks.\" Advances in NIPS (2014), https://arxiv.org/abs/1409.3215.\n\n[2] K. Cho, and et al., \"Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation.\u201c, https://arxiv.org/pdf/1406.1078.pdf\n\n[3] https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py\n\nModel is same as [3] but diffrent application. \n\nCharacter-Level Sequence to Sequence Model:\n\n  Input sequences\n  \n    Korean text\n    \n    Corresponding Korean POS-tag text\n    \n  An encoder LSTM turns input sequences to 2 state vectors\n  \n    Preserve the last LSTM state and discard the outputs   \n    \n  A decoder LSTM is trained to the target POS-tag into the same sequence \n  \n    Keep offset by one time-step for future\n    \n    The offset uses as initial state the state vectors from encoder\n    \n    The decoder learns to generate POS-tag [t+1] by a given POS-tag [t]\n    \n    \nInference from trained model:\n\n  Encoder input sequences\n  \n    Encode the Korean text sequence into state vectors\n    \n    Start with a target sequence of size 1 (sequence of characters)\n    \n  Feed the state vectors and each character target sequence to the decoder\n  \n    To produce predictions for the next character\n    \n  Sample the next character using these predictions\n  \n    Apply argmax\n    \n    Append the sampled character to the target sequence\n    \n  Repeating until to reach the end-of-sequence character\n  \n\nPrerequisite:",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Korean-POS-Tagger-LSTM",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "munir-bd",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/munir-bd/Korean-POS-Tagger-LSTM/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "keras\n\nnumpy\n\npickle\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 14:01:44 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "postagging",
      "lstm-neural-networks",
      "lstm-model",
      "sequence-to-sequence",
      "korean-nlp"
    ],
    "technique": "GitHub API"
  }
}
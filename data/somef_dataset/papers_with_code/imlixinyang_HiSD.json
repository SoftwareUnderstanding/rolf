{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2103.01456"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If our paper helps your research, please cite it in your publications:\n```\n@InProceedings{Li_2021_CVPR,\n    author    = {Li, Xinyang and Zhang, Shengchuan and Hu, Jie and Cao, Liujuan and Hong, Xiaopeng and Mao, Xudong and Huang, Feiyue and Wu, Yongjian and Ji, Rongrong},\n    title     = {Image-to-Image Translation via Hierarchical Style Disentanglement},\n    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n    month     = {June},\n    year      = {2021},\n    pages     = {8639-8648}\n}\n```\n\nI try my best to make the code easy to understand or further modified because I feel very lucky to start with the clear and readily comprehensible code of [MUNIT](https://github.com/NVlabs/MUNIT) when I'm a beginner.\n\nIf you have any problem, please feel free to contact me at [imlixinyang@gmail.com](mailto:imlixinyang@gmail.com) or raise an issue.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@InProceedings{Li_2021_CVPR,\n    author    = {Li, Xinyang and Zhang, Shengchuan and Hu, Jie and Cao, Liujuan and Hong, Xiaopeng and Mao, Xudong and Huang, Feiyue and Wu, Yongjian and Ji, Rongrong},\n    title     = {Image-to-Image Translation via Hierarchical Style Disentanglement},\n    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n    month     = {June},\n    year      = {2021},\n    pages     = {8639-8648}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/imlixinyang/HiSD",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-02T02:59:58Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T06:18:04Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9219560860535626,
        0.9765921032998365,
        0.8872703109556431
      ],
      "excerpt": "Official pytorch implementation of paper \"Image-to-image Translation via Hierarchical Style Disentanglement\". \nHiSD is the SOTA image-to-image translation method for both *Scalability for multiple labels and Controllable Diversity* with impressive disentanglement. \nThe styles to manipolate each tag in our method can be not only generated by random noise but also extracted from images! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9193067570639056
      ],
      "excerpt": "All tranlsations are producted be a unified HiSD model and trained end-to-end. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8747238584873532
      ],
      "excerpt": "Carefully check the fisrt few (always two) lines in the label file which is not like the others. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8889118821931529
      ],
      "excerpt": "Allmost all custom datasets can be converted into special cases of HiSD. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9241385524715086
      ],
      "excerpt": "The samples and checkpoints are in the \"outputs/\" dir. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8717842355291842,
        0.9805547757015364
      ],
      "excerpt": "Default 'steps' make every image to be with bangs and glasses using random latent-guided styles. \nWe use FID of StarGANv2 for quantitative comparison. For more details, please refer to the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Official pytorch implementation of paper \"Image-to-image Translation via Hierarchical Style Disentanglement\" (CVPR 2021 Oral).",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We recommend you to download CelebA-HQ from [CelebAMask-HQ](https://github.com/switchablenorms/CelebAMask-HQ).\nAnyway you shound get the dataset folder like:\n```\nceleba_or_celebahq\n - img_dir\n   - img0\n   - img1\n   - ...\n - train_label.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/imlixinyang/HiSD/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 44,
      "date": "Fri, 24 Dec 2021 07:48:12 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/imlixinyang/HiSD/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "imlixinyang/HiSD",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/imlixinyang/HiSD/main/easy_use.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\nconda create -n HiSD python=3.6.6\nconda activate HiSD\nconda install -y pytorch=1.0.1 torchvision=0.2.2  cudatoolkit=10.1 -c pytorch\npip install pillow tqdm tensorboardx pyyaml\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.865963394496027
      ],
      "excerpt": "Also, the styles can be smoothly interpolated like: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9893272198983933,
        0.9906248903846466
      ],
      "excerpt": "git clone https://github.com/imlixinyang/HiSD.git \ncd HiSD/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.83628152192242
      ],
      "excerpt": "You need to organize the folder like: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9406003048906886
      ],
      "excerpt": "You can Run \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8058799406833762
      ],
      "excerpt": "Here, we provide some links for you to download other available datasets: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8136977010094208
      ],
      "excerpt": "python proprecessors/celeba-hq.py --img_path $your_image_path --label_path $your_label_path --target_path datasets --start 3002 --end 30002 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.870586227663867
      ],
      "excerpt": "For example, the AFHQ (one tag and three attributes, remember to split the training and test set first): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8333526536849322
      ],
      "excerpt": "python preprocessors/custom.py --imgs $your_training_set --target_path datasets/custom.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.863333864528206
      ],
      "excerpt": "python core/train.py --config configs/celeba-hq.yaml --gpus 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9123352487399757
      ],
      "excerpt": "python core/test.py --config configs/celeba-hq.yaml --checkpoint $your_checkpoint --input_path $your_input_path --output_path results \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/imlixinyang/HiSD/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "HiSD: Image-to-image Translation via Hierarchical Style Disentanglement",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "HiSD",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "imlixinyang",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/imlixinyang/HiSD/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\nconda create -n HiSD python=3.6.6\nconda activate HiSD\nconda install -y pytorch=1.0.1 torchvision=0.2.2  cudatoolkit=10.1 -c pytorch\npip install pillow tqdm tensorboardx pyyaml\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 326,
      "date": "Fri, 24 Dec 2021 07:48:12 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "image-to-image-translation",
      "gan",
      "disentangled-representations"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Download the pretrained checkpoint in [Baidu Drive](https://pan.baidu.com/s/1QfZ4CzXH7A7MA0MSqN1ssg) (Password:wgdx) or [Google Drive](https://drive.google.com/file/d/1KDrNWLejpo02fcalUOrAJOl1hGoccBKl/view?usp=sharing). Then put it into the root of this repo.\n\nOpen \"easy_use.ipynb\" and you can manipolate the facial attributes by yourself!\n\nIf you haven't installed Jupyter, use \"easy_use.py\". \n\nThe script will translate \"examples/input_0.jpg\" to be with bangs generated by a random noise and glasses extracted from \"examples/reference_glasses_0.jpg\"\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1611.01603",
      "https://arxiv.org/abs/1606.05250\n* Bidirectional Attention Flow for Machine Comprehension\"\nby Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi : https://arxiv.org/abs/1611.01603\n* Authors' TensorFlow implementation: https://allenai.github.io/bi-att-flow/\n* BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\nJacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova : https://arxiv.org/abs/1810.04805\n* BiDAF baseline model: https://github.com/chrischute/squad\n* PyTorch pretrained BERT: https://github.com/huggingface/pytorch-pretrained-BERT\n* GloVE: https://nlp.stanford.edu/projects/glove/",
      "https://arxiv.org/abs/1611.01603\n* Authors' TensorFlow implementation: https://allenai.github.io/bi-att-flow/\n* BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\nJacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova : https://arxiv.org/abs/1810.04805\n* BiDAF baseline model: https://github.com/chrischute/squad\n* PyTorch pretrained BERT: https://github.com/huggingface/pytorch-pretrained-BERT\n* GloVE: https://nlp.stanford.edu/projects/glove/",
      "https://arxiv.org/abs/1810.04805\n* BiDAF baseline model: https://github.com/chrischute/squad\n* PyTorch pretrained BERT: https://github.com/huggingface/pytorch-pretrained-BERT\n* GloVE: https://nlp.stanford.edu/projects/glove/"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8728059224385537
      ],
      "excerpt": "Source: BiDAF paper \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9869405348645832,
        0.8833705422112558,
        0.9942253498062291
      ],
      "excerpt": "SQuAD dataset: https://arxiv.org/abs/1606.05250 \nBidirectional Attention Flow for Machine Comprehension\" \nby Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi : https://arxiv.org/abs/1611.01603 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999773395293352
      ],
      "excerpt": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova : https://arxiv.org/abs/1810.04805 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/GauthierDmn/question_answering",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-14T23:33:40Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-20T07:35:50Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9769746705469413,
        0.9449871717903966,
        0.9329729101148492
      ],
      "excerpt": "The goal of this project was for me to get familiar with the Question Answering task, a very active topic in NLP research. \nTo this end, I implemented a Bidirectional Attention Flow neural network as a baseline, improving Chris Chute's model implementation, adding word-character inputs as described in the original paper. \nI found this project very useful from a learning perspective so I highly recommend you to dig into the code and work on improving this baseline. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8508830890397249,
        0.8750381207894962
      ],
      "excerpt": "\u251c\u2500\u2500 data_loader.py     &lt;- Define an iterator who collects batches of data to train the model \n\u251c\u2500\u2500 eval.py            &lt;- Evaluate the model on a new pair of (context, question) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8889496577048623,
        0.8018469602317619,
        0.8181704209799999,
        0.9036516078248451
      ],
      "excerpt": "- [ ] set up a variable to choose between training the model with word only VS word + characters \n- [ ] collect the moving average of the weights during training and use them during testing \n- [ ] add the ability to train the model on multiple GPUs, and offer half-precision training to speed-up the training \n- [ ] improve this baseline using pre-training encoding such as BERT, and/or set-up a multi-task learning pipeline to jointly learn to answer questions together with another closely related NLP task. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9312887985999561
      ],
      "excerpt": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Question Answering task using Deep Learning on SQuAD dataset",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/GauthierDmn/question_answering/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 25,
      "date": "Fri, 24 Dec 2021 11:13:37 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/GauthierDmn/question_answering/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "GauthierDmn/question_answering",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Clone the repository\n* Create a directory for your experiments, logs and model weights: `mkdir output`\n* Download GloVE word vectors: https://nlp.stanford.edu/projects/glove/\n* Modify the `config.py` file to set up the paths where your GloVE, SquAD and models will be located\n* Create a Python virtual environment, source to it: `mkvirualenv qa-env ; workon qa-env` if you use virtualenvwrapper\n* Install the dependencies: `pip install -r requirements.txt ; python -m spacy download en`\n* Run `python make_dataset.py` to download SquAD dataset and pre-process the data\n* Run `python train.py` to train the model with hyper-parameters found in `config.py`\n* Run `python test.py` to test the model EM and F1 scores on Dev examples\n* Play with `eval.py` to answer your own questions! :)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9698571289336496
      ],
      "excerpt": "\u251c\u2500\u2500 requirements.txt   &lt;- Required Python libraries to build the project \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9725002728977397
      ],
      "excerpt": "PyTorch pretrained BERT: https://github.com/huggingface/pytorch-pretrained-BERT \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8778942925242261
      ],
      "excerpt": "\u251c\u2500\u2500 config.py          &lt;- Configuration file with data directories and hyperparamters to train the model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8185349105968415
      ],
      "excerpt": "\u251c\u2500\u2500 make_dataset.py    &lt;- Download the SquAD dataset and pre-process the data for training \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8072644740710192,
        0.8778569076228988
      ],
      "excerpt": "\u251c\u2500\u2500 test.py            &lt;- Test the performance of a trained model on the DEV dataset \n\u251c\u2500\u2500 train.py           &lt;- Train a model using the TRAIN dataset only \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/GauthierDmn/question_answering/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Question Answering with SQuAD",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "question_answering",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "GauthierDmn",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/GauthierDmn/question_answering/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 15,
      "date": "Fri, 24 Dec 2021 11:13:37 GMT"
    },
    "technique": "GitHub API"
  }
}
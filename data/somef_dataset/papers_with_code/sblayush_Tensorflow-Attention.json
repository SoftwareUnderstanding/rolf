{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1506.03134\n- Get To The Point: Summarization with Pointer-Generator Networks:\nhttps://arxiv.org/abs/1704.04368\n- Effective Approaches to Attention-based Neural Machine Translation:\nhttps://arxiv.org/abs/1508.04025\n\n### Papers for sentiment classification:\n- Attention-based LSTM for Aspect-level Sentiment Classification:  based on semEval dataset\nhttps://aclweb.org/anthology/D16-1058\n- Recurrent Attention Network on Memory for Aspect Sentiment Analysis:\nhttp://www.cs.cmu.edu/~lbing/pub/emnlp17_aspect_sentiment.pdf\n\n### Papers for summarization:\n- Get To The Point: Summarization with Pointer-Generator Networks:\nhttps://arxiv.org/abs/1704.04368",
      "https://arxiv.org/abs/1704.04368\n- Effective Approaches to Attention-based Neural Machine Translation:\nhttps://arxiv.org/abs/1508.04025\n\n### Papers for sentiment classification:\n- Attention-based LSTM for Aspect-level Sentiment Classification:  based on semEval dataset\nhttps://aclweb.org/anthology/D16-1058\n- Recurrent Attention Network on Memory for Aspect Sentiment Analysis:\nhttp://www.cs.cmu.edu/~lbing/pub/emnlp17_aspect_sentiment.pdf\n\n### Papers for summarization:\n- Get To The Point: Summarization with Pointer-Generator Networks:\nhttps://arxiv.org/abs/1704.04368",
      "https://arxiv.org/abs/1508.04025\n\n### Papers for sentiment classification:\n- Attention-based LSTM for Aspect-level Sentiment Classification:  based on semEval dataset\nhttps://aclweb.org/anthology/D16-1058\n- Recurrent Attention Network on Memory for Aspect Sentiment Analysis:\nhttp://www.cs.cmu.edu/~lbing/pub/emnlp17_aspect_sentiment.pdf\n\n### Papers for summarization:\n- Get To The Point: Summarization with Pointer-Generator Networks:\nhttps://arxiv.org/abs/1704.04368",
      "https://arxiv.org/abs/1704.04368"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sblayush/Tensorflow-Attention",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-06-19T15:17:57Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-30T13:43:40Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9495566152851938
      ],
      "excerpt": "Get To The Point: Summarization with Pointer-Generator Networks: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8163282605194595
      ],
      "excerpt": "Effective Approaches to Attention-based Neural Machine Translation: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8377277132433383
      ],
      "excerpt": "Attention-based LSTM for Aspect-level Sentiment Classification:  based on semEval dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8667653935598881
      ],
      "excerpt": "Recurrent Attention Network on Memory for Aspect Sentiment Analysis: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9495566152851938
      ],
      "excerpt": "Get To The Point: Summarization with Pointer-Generator Networks: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This repository implementation of the Attention mechanism using Tensorflow using various examples.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sblayush/Tensorflow-Attention/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Sun, 26 Dec 2021 08:34:43 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sblayush/Tensorflow-Attention/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "sblayush/Tensorflow-Attention",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8302977013097402
      ],
      "excerpt": "Dynamic Attention model implementation using Tensorflow along with some examples. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sblayush/Tensorflow-Attention/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Tensorflow Attention",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Tensorflow-Attention",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "sblayush",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sblayush/Tensorflow-Attention/blob/master/readme.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Sun, 26 Dec 2021 08:34:43 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "attention-mechanism",
      "attention-lstm",
      "deep-neural-networks",
      "tensorflow-experiments"
    ],
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1409.1556]\n\n![vgg16 architecture](https://user-images.githubusercontent.com/35737777/69682136-5bdd4780-10a8-11ea-9079-50283f5451df.png"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9715104224169802
      ],
      "excerpt": "Very Deep Convolutional Networks for Large-Scale Image Recognition. [https://arxiv.org/abs/1409.1556] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "                           validation_steps=10, epochs=100, \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ashushekar/VGG16",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-11-26T22:09:40Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-25T15:56:26Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```sh \nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #:   \n=================================================================\nconv2d_1 (Conv2D)            (None, 224, 224, 64)      1792      \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 224, 224, 64)      36928     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 112, 112, 128)     73856     \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 112, 112, 128)     147584    \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 56, 56, 256)       295168    \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 14, 14, 512)       0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 25088)             0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 4096)              102764544 \n_________________________________________________________________\ndense_2 (Dense)              (None, 4096)              16781312  \n_________________________________________________________________\ndense_3 (Dense)              (None, 2)                 8194      \n=================================================================\nTotal params: 134,268,738\nTrainable params: 134,268,738\nNon-trainable params: 0\n_________________________________________________________________\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9294147286813356,
        0.8788649259819918,
        0.959515445833638,
        0.9719356556128929
      ],
      "excerpt": "VGG16 is a convolution neural net (CNN ) architecture which was used to win ILSVR(Imagenet) competition in 2014.  \nIt is considered to be one of the excellent vision model architecture till date. Most unique thing about VGG16  \nis that instead of having a large number of hyper-parameter they focused on having convolution layers of 3x3  \nfilter with a stride 1 and always used same padding and maxpool layer of 2x2 filter of stride 2.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8546519675498149,
        0.840373126515835
      ],
      "excerpt": "In the end it has 2 FC(fully connected layers) followed by a softmax for output. The 16 in VGG16 refers to it has  \n16 layers that have weights. This network is a pretty large network and it has about 138 million (approx) parameters. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9177265628595701
      ],
      "excerpt": "The implementation of VGG16 can be done on Cats vs Dogs dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9399384220913347,
        0.9872023142476631,
        0.8477030601967245,
        0.8741087592263742,
        0.9507601686915432
      ],
      "excerpt": "We will be using Sequential method which means that all the layers of the model will be arranged in sequence. Here we  \nhave imported ImageDataGenerator from keras.preprocessing. The objective of ImageDataGenerator is to import data with  \nlabels easily into the model. It is a very useful class as it has many function to rescale, rotate, zoom, flip etc. The  \nmost useful thing about this class is that it does not affect the data stored on the disk. This class alters the data on  \nthe go while passing it to the model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8581175034174026
      ],
      "excerpt": "data to the object trdata and similarly passing folder which has test data to the object of tsdata. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9446455884910909
      ],
      "excerpt": "this way data is easily ready to be passed to the neural network. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.842982367631185,
        0.860059181823877
      ],
      "excerpt": ": Generate the model \nmodel = Sequential() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9056111366765736
      ],
      "excerpt": "model.add(Conv2D(input_shape=(224, 224, 3), filters=64, kernel_size=(3, 3), \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8095901194064796
      ],
      "excerpt": "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501
      ],
      "excerpt": "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8095901194064796
      ],
      "excerpt": "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8095901194064796
      ],
      "excerpt": "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501
      ],
      "excerpt": "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8095901194064796
      ],
      "excerpt": "model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8095901194064796
      ],
      "excerpt": "model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8095901194064796
      ],
      "excerpt": "model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501
      ],
      "excerpt": "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8095901194064796
      ],
      "excerpt": "model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8095901194064796
      ],
      "excerpt": "model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8095901194064796
      ],
      "excerpt": "model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501
      ],
      "excerpt": "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8095901194064796
      ],
      "excerpt": "model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8095901194064796
      ],
      "excerpt": "model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8095901194064796
      ],
      "excerpt": "model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341589559722501
      ],
      "excerpt": "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8223311309099285
      ],
      "excerpt": "model.add(Dense(units=4096, activation='relu')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8223311309099285
      ],
      "excerpt": "model.add(Dense(units=4096, activation='relu')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8223311309099285
      ],
      "excerpt": "model.add(Dense(units=2, activation='softmax')) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9854516441583872
      ],
      "excerpt": "Here we have started with initialising the model by specifying that the model is a sequential model.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740370536899504
      ],
      "excerpt": "2. 1 x maxpool layer of 2x2 pool size and stride 2x2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740370536899504
      ],
      "excerpt": "4. 1 x maxpool layer of 2x2 pool size and stride 2x2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740370536899504
      ],
      "excerpt": "6. 1 x maxpool layer of 2x2 pool size and stride 2x2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740370536899504
      ],
      "excerpt": "8. 1 x maxpool layer of 2x2 pool size and stride 2x2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9260344079368187,
        0.9602798790716199
      ],
      "excerpt": "We have also add ReLU activation to each layers so that all the negative values are not passed to the next layer. \nAfter creating all the convolution we pass the data to the dense layer: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8169530924478642,
        0.9086917528123043,
        0.9575244219775879
      ],
      "excerpt": "Let us use Adam optimiser to reach to the global minima while training out model. If we stuck in local minima while  \ntraining then the adam optimiser will help us to get out of local minima and reach global minima. We will also  \nspecify the learning rate of the optimiser, here in this case it is set at 0.001. If our training is bouncing a lot on  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356089382452141
      ],
      "excerpt": ": Check model summary \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9871931765490904,
        0.8740755081594508,
        0.9692907442950919
      ],
      "excerpt": "ModelCheckpoint helps us to save the model by monitoring a specific parameter of the model. In this case we have monitoring  \nvalidation accuracy by passing val_acc to ModelCheckpoint. The model will only be saved to disk if the validation  \naccuracy of the model in current epoch is greater than what it was in the last epoch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9704112067485741,
        0.8989998458000401,
        0.8790543429754059
      ],
      "excerpt": "EarlyStopping helps us to stop the training of the model early if there is no increase in the parameter which we have set  \nto monitor in EarlyStopping. In this case we have monitoring validation accuracy by passing val_acc to EarlyStopping.  \nWe have set patience to 20 which means that the model will stop to train if it does not see any rise in validation accuracy  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9260985250604619,
        0.9705247489306034,
        0.8878919145230229
      ],
      "excerpt": "We are using model.fit_generator as we have ImageDataGenerator to pass data to the model. We will pass train and test  \ndata to fit_generator. In fit_generator, steps_per_epoch will set the batch size to pass training data to the model  \nand validation_steps will do the same for test data. We can tweak it anytime based on our system specifications. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9444685769208016,
        0.9113054659546658
      ],
      "excerpt": "To do predictions on the trained model we need to load the best saved model and pre-process the image and pass the image  \nto the model for output. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ashushekar/VGG16/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 00:41:18 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ashushekar/VGG16/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ashushekar/VGG16",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.9457175861910134,
        0.9133368656218674,
        0.925671696398174,
        0.9068127677393759
      ],
      "excerpt": "import numpy as np \nimport keras \nimport tensorflow as tf \nimport matplotlib.pyplot as plt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8900486270063179,
        0.8801854956928516
      ],
      "excerpt": "from keras.models import Sequential, load_model \nfrom keras.optimizers import Adam \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from keras.callbacks import ModelCheckpoint, EarlyStopping \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8760566315818381
      ],
      "excerpt": "traindata = trdata.flow_from_directory(directory=\"../Datasets/Cats&amp;Dogs/train\",target_size=(224,224)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8158210350846568,
        0.810226194214266
      ],
      "excerpt": "testdata = tsdata.flow_from_directory(directory=\"../Datasets/Cats&amp;Dogs/validation\", target_size=(224,224)) \nThe ImageDataGenerator will automatically label all the data inside cat folder as cat and vis-\u00e0-vis for dog folder. In  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8095176313464617
      ],
      "excerpt": ": Layer 10: MaxPooling \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "                             verbose=1, save_best_only=True,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8385014426005318
      ],
      "excerpt": "data to fit_generator. In fit_generator, steps_per_epoch will set the batch size to pass training data to the model  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003966255068399
      ],
      "excerpt": "                           validation_steps=10, epochs=100, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8037377074638782
      ],
      "excerpt": "to the model for output. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8112331702613936,
        0.827546330331657,
        0.8319657668353034
      ],
      "excerpt": "img = image.load_img(\"../Datasets/Cats&amp;Dogs/test1/39.jpg\",target_size=(224,224)) \nimg = np.asarray(img) \nimg = np.expand_dims(img, axis=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8698462110502523
      ],
      "excerpt": "output = saved_model.predict(img) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.936606094659785
      ],
      "excerpt": "    print(\"cat\") \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ashushekar/VGG16/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Step by step VGG16 implementation in Keras\n\nVGG16 is a convolution neural net (CNN ) architecture which was used to win ILSVR(Imagenet) competition in 2014. \nIt is considered to be one of the excellent vision model architecture till date. Most unique thing about VGG16 \nis that instead of having a large number of hyper-parameter they focused on having convolution layers of 3x3 \nfilter with a stride 1 and always used same padding and maxpool layer of 2x2 filter of stride 2. \nIt follows this arrangement of convolution and max pool layers consistently throughout the whole architecture. \nIn the end it has 2 FC(fully connected layers) followed by a softmax for output. The 16 in VGG16 refers to it has \n16 layers that have weights. This network is a pretty large network and it has about 138 million (approx) parameters.\n\nVery Deep Convolutional Networks for Large-Scale Image Recognition. [https://arxiv.org/abs/1409.1556]\n\n![vgg16 architecture](https://user-images.githubusercontent.com/35737777/69682136-5bdd4780-10a8-11ea-9079-50283f5451df.png)\n\nThe implementation of VGG16 can be done on Cats vs Dogs dataset.\n\n### Packages Needed\n\n```python\nimport numpy as np\nimport keras\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom keras.layers import Conv2D, Dense, Flatten, MaxPool2D\nfrom keras.models import Sequential, load_model\nfrom keras.optimizers import Adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.backend.tensorflow_backend import set_session\n```\nWe will be using Sequential method which means that all the layers of the model will be arranged in sequence. Here we \nhave imported ImageDataGenerator from _keras.preprocessing_. The objective of ImageDataGenerator is to import data with \nlabels easily into the model. It is a very useful class as it has many function to rescale, rotate, zoom, flip etc. The \nmost useful thing about this class is that it does not affect the data stored on the disk. This class alters the data on \nthe go while passing it to the model.\n\n### Image Data Generator\n\nLet us create an object of _ImageDataGenerator_ for both training and testing data and passing the folder which has train\ndata to the object _trdata_ and similarly passing folder which has test data to the object of _tsdata_.\n\n```python\ntrdata = ImageDataGenerator()\ntraindata = trdata.flow_from_directory(directory=\"../Datasets/Cats&Dogs/train\",target_size=(224,224))\ntsdata = ImageDataGenerator()\ntestdata = tsdata.flow_from_directory(directory=\"../Datasets/Cats&Dogs/validation\", target_size=(224,224))\n```\n\nThe ImageDataGenerator will automatically label all the data inside cat folder as cat and vis-\u00e0-vis for dog folder. In \nthis way data is easily ready to be passed to the neural network.\n\n### Model Structure\n```python\n# Generate the model\nmodel = Sequential()\n# Layer 1: Convolutional\nmodel.add(Conv2D(input_shape=(224, 224, 3), filters=64, kernel_size=(3, 3),\n                 padding='same', activation='relu'))\n# Layer 2: Convolutional\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\n# Layer 3: MaxPooling\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n\n# Layer 4: Convolutional\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n# Layer 5: Convolutional\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n# Layer 6: MaxPooling\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n\n# Layer 7: Convolutional\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n# Layer 8: Convolutional\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n# Layer 9: Convolutional\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n# Layer 10: MaxPooling\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n\n# Layer 11: Convolutional\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n# Layer 12: Convolutional\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n# Layer 13: Convolutional\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n# Layer 14: MaxPooling\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n\n# Layer 15: Convolutional\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n# Layer 16: Convolutional\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n# Layer 17: Convolutional\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))\n# Layer 18: MaxPooling\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n\n# Layer 19: Flatten\nmodel.add(Flatten())\n# Layer 20: Fully Connected Layer\nmodel.add(Dense(units=4096, activation='relu'))\n# Layer 21: Fully Connected Layer\nmodel.add(Dense(units=4096, activation='relu'))\n# Layer 22: Softmax Layer\nmodel.add(Dense(units=2, activation='softmax'))\n```\n\nHere we have started with initialising the model by specifying that the model is a sequential model. \nAfter initialising the model then we can add: \n1. 2 x convolution layer of 64 channel of 3x3 kernal and same padding\n2. 1 x maxpool layer of 2x2 pool size and stride 2x2\n3. 2 x convolution layer of 128 channel of 3x3 kernal and same padding\n4. 1 x maxpool layer of 2x2 pool size and stride 2x2\n5. 3 x convolution layer of 256 channel of 3x3 kernal and same padding\n6. 1 x maxpool layer of 2x2 pool size and stride 2x2\n7. 3 x convolution layer of 512 channel of 3x3 kernal and same padding\n8. 1 x maxpool layer of 2x2 pool size and stride 2x2\n9. 3 x convolution layer of 512 channel of 3x3 kernal and same padding\n10. 1 x maxpool layer of 2x2 pool size and stride 2x2\n\nWe have also add ReLU activation to each layers so that all the negative values are not passed to the next layer.\n\nAfter creating all the convolution we pass the data to the dense layer:\n\n11. 1 x Dense layer of 4096 units\n12. 1 x Dense layer of 4096 units\n13. 1 x Dense Softmax layer of 2 units\n\n#### Adam Optimizer\nLet us use Adam optimiser to reach to the global minima while training out model. If we stuck in local minima while \ntraining then the adam optimiser will help us to get out of local minima and reach global minima. We will also \nspecify the learning rate of the optimiser, here in this case it is set at 0.001. If our training is bouncing a lot on \nepochs then we need to decrease the learning rate so that we can reach global minima.\n\n```python\n# Add Optimizer\noptimizer = Adam(learning_rate=0.001)\nmodel.compile(optimizer=optimizer, loss=keras.losses.categorical_crossentropy,\n              metrics=['accuracy'])\n# Check model summary\nprint(model.summary())\n```\n\n#### Model Summary \n\n```sh \nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "VGG16",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ashushekar",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ashushekar/VGG16/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Sun, 26 Dec 2021 00:41:18 GMT"
    },
    "technique": "GitHub API"
  }
}
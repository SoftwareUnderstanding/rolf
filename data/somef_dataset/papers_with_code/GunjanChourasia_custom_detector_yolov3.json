{
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/GunjanChourasia/custom_detector_yolov3",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-26T12:16:52Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-06-27T18:27:11Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9121587426075278
      ],
      "excerpt": "This fork is a work in progress.  It will be noted here when this is ready for broader, more production, use. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9797435097136703
      ],
      "excerpt": "This project is a \"You Only Look Once\" v3 sample using PyTorch, a fork of https://github.com/ayooshkathuria/pytorch-yolo-v3, with updates and improvements specifically for the Tiny architecture on custom data labeled with VoTT (versus the classic download of VOC or COCO data and labels).  This fork allows the user to bring their own dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9443154227788182
      ],
      "excerpt": "Note:  This project is a work in progress. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.94876353896095
      ],
      "excerpt": "Custom data possibility \nClean up of several portions of code and generalizing/parameterizing \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8582416794430492
      ],
      "excerpt": "Addressed issue of detecting small objects \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8878099378808878
      ],
      "excerpt": "Performance on par with other architectures (a bit faster than SSD, even) \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/GunjanChourasia/custom_detector_yolov3/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sun, 26 Dec 2021 01:55:41 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/GunjanChourasia/custom_detector_yolov3/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "GunjanChourasia/custom_detector_yolov3",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/GunjanChourasia/custom_detector_yolov3/tree/master/data_aug/docs"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Install the required Python packages (`pip install -r requirements.txt`).\n* Download the [full YOLO v3 (237 MB)](https://pjreddie.com/media/files/yolov3.weights) or [tiny YOLO v3 (33.8 MB)](https://pjreddie.com/media/files/yolov3-tiny.weights) model.  **Fun fact:  this project utilizes the weights originating in Darknet format**.\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8262337112301398
      ],
      "excerpt": "<img src=\"imgs/id_plumeria_sml.png\" width=\"70%\" align=\"center\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8288876616508039
      ],
      "excerpt": "If you wish to train on all labeled images, make sure they are all in the train.txt file (this is read by the customloader.py). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9100576820370712
      ],
      "excerpt": "Test and Train Data \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/GunjanChourasia/custom_detector_yolov3/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "A Fork of PyTorch Implemation of YOLOv3 to Accomodate Custom Data",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "custom_detector_yolov3",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "GunjanChourasia",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/GunjanChourasia/custom_detector_yolov3/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Before startng training, change the number of classes in cfg file, in cfg folder, here yolov3.tiny.cfg is used so changes are to be made there. Also keep the batch size according to train, comment out the test section in cfg file (its on top of the file)\n\nCmd :\n\n    python train.py\n   \nThis is for yolov3-tiny weights and cfg.\n\nUsage:\n\n    python train.py --help\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Change batch size to 1 in the cfg file in cfg folder, and comment out the train section in cfg file\n\n**For detection on image**\n\nAdd the images on which the detection needs to be performed in the test folder, the output will be saved in detection folder.\nand run the following\nCmd:\n\n    python live.py --weights runs/<your trained model>.pth --confidence 0.6\n\n**For detection on video/live video**\n\nType the following, if you want to do detection on a recorded video then specify the videos destination by using the --video argument, otherwise it will run on live video.\nCmd:\n\n    python live.py --deton \"video\" --weights runs/<your trained model>.pth --confidence 0.6\n\n\nUsage:\n    \n    python live.py --help\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 01:55:41 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Here, you will use your trained model in a live video feed.  Ensure the `yolov3-tiny.cfg` is set up to test (see first lines of file).  `runs` is where trained models get saved by default.\n\n",
      "technique": "Header extraction"
    }
  ]
}
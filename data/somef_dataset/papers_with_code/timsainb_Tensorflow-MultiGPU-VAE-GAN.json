{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1312.6114\n- **D_loss** - Our descriminator loss, how good the discriminator is at telling if something is real\n- **G_loss** - essentially the opposite of the D_loss, how good the generator is a tricking the discriminator\n- ***notice we clip our values to make sure learning rates don't explode***\n\n\n```\ndef loss(x, x_tilde, z_x_log_sigma_sq, z_x_mean, d_x, d_x_p, l_x, l_x_tilde, dim1, dim2, dim3",
      "https://arxiv.org/abs/1511.06434"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8940583111730483
      ],
      "excerpt": "<font color=\"#1155cc\"><strong>Generator</strong></font>, and <font color=\"#ff0000\"><strong>Discriminator</strong></font> described above.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9912556242864674
      ],
      "excerpt": "See https://arxiv.org/abs/1312.6114 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665695068094464,
        0.8043043934907972
      ],
      "excerpt": "                               - tf.square(tf.clip_by_value(z_x_mean, -10.0, 10.0) )  \n                               - tf.exp(tf.clip_by_value(z_x_log_sigma_sq, -10.0, 10.0) ), 1))/dim1/dim2/dim3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": "fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(20,10), linewidth = 4) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": "examples = 10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906174419333412
      ],
      "excerpt": "    fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(18,12)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9645709551223568
      ],
      "excerpt": "    plt.title('This slider won\\.t work in Github') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9997213299132015
      ],
      "excerpt": "['0: 5_o_Clock_Shadow', '1: Arched_Eyebrows', '2: Attractive', '3: Bags_Under_Eyes', '4: Bald', '5: Bangs', '6: Big_Lips', '7: Big_Nose', '8: Black_Hair', '9: Blond_Hair', '10: Blurry', '11: Brown_Hair', '12: Bushy_Eyebrows', '13: Chubby', '14: Double_Chin', '15: Eyeglasses', '16: Goatee', '17: Gray_Hair', '18: Heavy_Makeup', '19: High_Cheekbones', '20: Male', '21: Mouth_Slightly_Open', '22: Mustache', '23: Narrow_Eyes', '24: No_Beard', '25: Oval_Face', '26: Pale_Skin', '27: Pointy_Nose', '28: Receding_Hairline', '29: Rosy_Cheeks', '30: Sideburns', '31: Smiling', '32: Straight_Hair', '33: Wavy_Hair', '34: Wearing_Earrings', '35: Wearing_Hat', '36: Wearing_Lipstick', '37: Wearing_Necklace', '38: Wearing_Necktie', '39: Young'] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9381991113801575
      ],
      "excerpt": "plt.title('Average Blonde Person | Average Not Blonde Person | ABP-ANBP') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8715509475085618
      ],
      "excerpt": "Autoencoding beyond pixels (Github) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8090016440670298
      ],
      "excerpt": "DCGAN (Github) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9747762585923935
      ],
      "excerpt": "Open AI improving GANS  (Github) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/timsainb/Tensorflow-MultiGPU-VAE-GAN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-09-08T21:20:36Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-10T10:08:10Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9765052646250129
      ],
      "excerpt": "This is an implementation of the VAE-GAN based on the implementation described in <a href=\"http://arxiv.org/abs/1512.09300\">Autoencoding beyond pixels using a learned similarity metric</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9254751311447194
      ],
      "excerpt": "Latent Space Algebra \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8670574890384708,
        0.8032149225492005,
        0.8916585635483456,
        0.9581891988784689,
        0.9572885490815712,
        0.8896398588631117
      ],
      "excerpt": "The <font color=\"#38761d\"><strong>Encoder</strong></font> learns to map input x onto z space (latent space) \nThe <font color=\"#1155cc\"><strong>Generator</strong></font> learns to generate x from z space \nThe <font color=\"#ff0000\"><strong>Discriminator</strong></font> learns to discriminate whether the image being put in is real, or generated \nwe train the network to minimize the difference between the high level features of x and x_tilde \nThis is basically an autoencoder that works on high level features rather than pixels \nAdding this autoencoder to a GAN helps to stabilize the GAN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8967796635585553
      ],
      "excerpt": ": Import all of our packages \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8363532604916452,
        0.8911925938271532
      ],
      "excerpt": "dim2 = 64 #: second dimension of input data \ndim3 = 3 #: third dimension of input data (colors) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8393809523171173
      ],
      "excerpt": "Set gpus to a list of the GPUs you're using. The network will then split up the work between those gpus \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8394844653774157
      ],
      "excerpt": "os.environ[\"CUDA_VISIBLE_DEVICES\"]=','.join([str(i) for i in gpus]) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8086817514702006
      ],
      "excerpt": "            #: The transformation is parametrized and can be learned. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246666367370623
      ],
      "excerpt": "        x: a batch of vectors to decode \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8567359854373466
      ],
      "excerpt": "    descrim_conv =  (pt.wrap(D_I). #: This is what we're descriminating \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8630563693371488,
        0.8896547053941967
      ],
      "excerpt": "    lth_layer= descrim_conv.fully_connected(1024, activation_fn=tf.nn.elu)#: this is the lth layer      \n    D =lth_layer.fully_connected(1, activation_fn=tf.nn.sigmoid) #: this is the actual discrimination \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016,
        0.9394449182630016,
        0.9567588029116127
      ],
      "excerpt": "    z_p =  tf.random_normal((batch_size, hidden_size), 0, 1) #: normal dist for GAN \n    eps = tf.random_normal((batch_size, hidden_size), 0, 1) #: normal dist for VAE \nwith pt.defaults_scope(activation_fn=tf.nn.elu, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "    with tf.variable_scope(\"enc\"):          \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "    with tf.variable_scope(\"gen\"): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.824647175460562
      ],
      "excerpt": "            tf.mul(tf.sqrt(tf.exp(z_x_log_sigma_sq)), eps)) #: grab our actual z \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "    with tf.variable_scope(\"dis\"):    \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8512302453267225
      ],
      "excerpt": "SSE - we don't actually use this loss (also its the MSE), its just to see how close x is to x_tilde \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9287367148954802,
        0.972526420121114,
        0.8395534231107041
      ],
      "excerpt": "D_loss - Our descriminator loss, how good the discriminator is at telling if something is real \nG_loss - essentially the opposite of the D_loss, how good the generator is a tricking the discriminator \nnotice we clip our values to make sure learning rates don't explode \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8472935843500194,
        0.9610389044746049
      ],
      "excerpt": "    SSE_loss = tf.reduce_mean(tf.square(x - x_tilde)) #: This is what a normal VAE uses \n#: We clip gradients of KL divergence to prevent NANs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8672181045951698,
        0.9091202858579028
      ],
      "excerpt": "    tower_grads: List of lists of (gradient, variable) tuples. The outer list \n      is over individual gradients. The inner list is over the gradient \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076
      ],
      "excerpt": "for grad_and_vars in zip(*tower_grads): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9560187895509076,
        0.917233190120415
      ],
      "excerpt": "    for g, _ in grad_and_vars: \n        #: Add 0 dimension to the gradients to represent the tower. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8240811693770311
      ],
      "excerpt": "    #: Keep in mind that the Variables are redundant because they are shared \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8628739040263953
      ],
      "excerpt": "fig.suptitle('Top: random points in z space | Bottom: inputs | Middle: reconstructions') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8541969530358143
      ],
      "excerpt": ": Make lists to save the losses to \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.931057316776452
      ],
      "excerpt": "with graph.as_default(): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9044364577914936
      ],
      "excerpt": "#: different optimizers are needed for different learning rates (using the same learning rate seems to work fine though) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.931057316776452
      ],
      "excerpt": "with graph.as_default(): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9588221857049815
      ],
      "excerpt": "#: apply the gradients with our optimizers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8427480291614974
      ],
      "excerpt": "we're using jupyter widgets to slide through z-space from one point to another \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8251081616608656
      ],
      "excerpt": "We take a look at what makes a neuron respond, by taking a bunch of images, and averaging them based on how much the neuron was activated.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9031603488859473
      ],
      "excerpt": ": get a bunch of images and their corresponding z points in the network \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567935001477398,
        0.8402496959194531
      ],
      "excerpt": ": for each attribute type, get the difference between the mean z-vector of faces with \n:   the attribute, and without the attribute \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8712561866477655
      ],
      "excerpt": ": show some faces which have this attribute \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8318064454139211
      ],
      "excerpt": "VAE and GAN implementations in prettytensor/tensorflow (Github) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9112755731198914
      ],
      "excerpt": ": this is just a little command to convert this as md for the github page \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A single jupyter notebook multi gpu VAE-GAN example with latent space algebra and receptive field visualizations. ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/timsainb/Tensorflow-MultiGPU-VAE-GAN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 93,
      "date": "Sun, 26 Dec 2021 07:25:40 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/timsainb/Tensorflow-MultiGPU-VAE-GAN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "timsainb/Tensorflow-MultiGPU-VAE-GAN",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/timsainb/Tensorflow-MultiGPU-VAE-GAN/master/VAE-GAN-multi-gpu-celebA.ipynb",
      "https://raw.githubusercontent.com/timsainb/Tensorflow-MultiGPU-VAE-GAN/master/celeba_make_dataset.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9490081349800514
      ],
      "excerpt": "gpus = [2] #: Here I set CUDA to only see one GPU \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8785777385478942
      ],
      "excerpt": "open `makedataset.ipynb' for instructions on how to build the dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9291255031678988
      ],
      "excerpt": "    #: Note that each grad_and_vars looks like the following: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740864954946345
      ],
      "excerpt": ": You should probably just be using tensorboard to do any visualization(or just use tensorboard...) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9048351547346696
      ],
      "excerpt": "!jupyter nbconvert --to markdown VAE-GAN-multi-gpu-celebA.ipynb \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8766624818183835
      ],
      "excerpt": "[NbConvertApp] Converting notebook VAE-GAN-multi-gpu-celebA.ipynb to markdown \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8376930984129097,
        0.8376930984129097,
        0.8376930984129097,
        0.8376930984129097,
        0.8376930984129097,
        0.8376930984129097,
        0.8376930984129097,
        0.8376930984129097,
        0.8376930984129097,
        0.8376930984129097,
        0.8376930984129097,
        0.8376930984129097
      ],
      "excerpt": "[NbConvertApp] Making directory VAE-GAN-multi-gpu-celebA_files \n[NbConvertApp] Making directory VAE-GAN-multi-gpu-celebA_files \n[NbConvertApp] Making directory VAE-GAN-multi-gpu-celebA_files \n[NbConvertApp] Making directory VAE-GAN-multi-gpu-celebA_files \n[NbConvertApp] Making directory VAE-GAN-multi-gpu-celebA_files \n[NbConvertApp] Making directory VAE-GAN-multi-gpu-celebA_files \n[NbConvertApp] Making directory VAE-GAN-multi-gpu-celebA_files \n[NbConvertApp] Making directory VAE-GAN-multi-gpu-celebA_files \n[NbConvertApp] Making directory VAE-GAN-multi-gpu-celebA_files \n[NbConvertApp] Making directory VAE-GAN-multi-gpu-celebA_files \n[NbConvertApp] Making directory VAE-GAN-multi-gpu-celebA_files \n[NbConvertApp] Making directory VAE-GAN-multi-gpu-celebA_files \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8401558704798054,
        0.9457175861910134,
        0.9012248701992861,
        0.925671696398174,
        0.9248232337838925,
        0.9068127677393759,
        0.8801854956928516
      ],
      "excerpt": "import os \nimport numpy as np \nimport prettytensor as pt \nimport tensorflow as tf \nfrom tensorflow.examples.tutorials.mnist import input_data \nimport matplotlib.pyplot as plt \nfrom deconv import deconv2d \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674
      ],
      "excerpt": "import math \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9012248701992861
      ],
      "excerpt": "import ipywidgets as widgets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8084081033814084
      ],
      "excerpt": "dim1 = 64 #: first dimension of input data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.801074172171629
      ],
      "excerpt": "num_examples = 60000 #: how many examples are in your training set \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8481995502039503,
        0.8572384028049157
      ],
      "excerpt": "    faces = hf['images'].value \n    headers = hf['headers'].value \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8314612088184035
      ],
      "excerpt": "plt.imshow(np.reshape(faces[1], (64,64,3)), interpolation='nearest') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8465316400048757
      ],
      "excerpt": "    return np.reshape(im,(dim1,dim2,dim3)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9360178186919378
      ],
      "excerpt": "fig, ax = plt.subplots(nrows=1,ncols=4, figsize=(20,8)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.809726610547402,
        0.8941609022057779,
        0.8737288687529231,
        0.8187951296341537
      ],
      "excerpt": "    while True: \n        idxs = np.arange(0, len(faces)) \n        np.random.shuffle(idxs) \n        for batch_idx in range(0, len(faces), batch_size): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9360178186919378
      ],
      "excerpt": "fig, ax = plt.subplots(nrows=1,ncols=4, figsize=(20,8)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "            deconv2d(1, dim3, stride=1, activation_fn=tf.sigmoid). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8112888101029512
      ],
      "excerpt": "        input: a batch of real images [batch, height, width, channels] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8226692071139554
      ],
      "excerpt": "    eps = tf.random_normal((batch_size, hidden_size), 0, 1) #: normal dist for VAE \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "                           batch_normalize=True, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "                           scale_after_normalization=True): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8292651357740108,
        0.8269752200293183
      ],
      "excerpt": "        z_x = tf.add(z_x_mean,  \n            tf.mul(tf.sqrt(tf.exp(z_x_log_sigma_sq)), eps)) #: grab our actual z \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8883260696661613
      ],
      "excerpt": "    with tf.variable_scope(\"gen\", reuse=True):          \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8883260696661613
      ],
      "excerpt": "    with tf.variable_scope(\"dis\", reuse=True): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8883260696661613
      ],
      "excerpt": "    with tf.variable_scope(\"dis\", reuse=True): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8500931937531586,
        0.857842686079746,
        0.866014110947714
      ],
      "excerpt": "KL_loss = tf.reduce_sum(-0.5 * tf.reduce_sum(1 + tf.clip_by_value(z_x_log_sigma_sq, -10.0, 10.0)  \n                               - tf.square(tf.clip_by_value(z_x_mean, -10.0, 10.0) )  \n                               - tf.exp(tf.clip_by_value(z_x_log_sigma_sq, -10.0, 10.0) ), 1))/dim1/dim2/dim3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8292094067172402,
        0.8255397762844684
      ],
      "excerpt": "D_loss = tf.reduce_mean(-1.*(tf.log(tf.clip_by_value(d_x,1e-5,1.0)) +  \n                                tf.log(tf.clip_by_value(1.0 - d_x_p,1e-5,1.0)))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8292094067172402,
        0.8255397762844684
      ],
      "excerpt": "G_loss = tf.reduce_mean(-1.*(tf.log(tf.clip_by_value(d_x_p,1e-5,1.0))))#: +  \n                                #:tf.log(tf.clip_by_value(1.0 - d_x,1e-5,1.0)))) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8189934579708896
      ],
      "excerpt": "LL_loss = tf.reduce_sum(tf.square(l_x - l_x_tilde))/dim1/dim2/dim3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "        expanded_g = tf.expand_dims(g, 0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432,
        0.8123763140827432
      ],
      "excerpt": "    grad = tf.concat(0, grads) \n    grad = tf.reduce_mean(grad, 0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008331685760428,
        0.8389675142579952,
        0.8008331685760428,
        0.8838148168639296
      ],
      "excerpt": "    random_x, recon_z, all_d= sess.run((x_p, z_x_mean, d_x_p), {all_input: example_data}) \n    top_d = np.argsort(np.squeeze(all_d)) \n    recon_x = sess.run((x_tilde), {z_x: recon_z}) \n    examples = 8 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9419786570197298,
        0.8100401946198035,
        0.809244161177136,
        0.809244161177136,
        0.8364646373110762,
        0.8292505407411963,
        0.8292505407411963,
        0.8292505407411963
      ],
      "excerpt": "fig, ax = plt.subplots(nrows=3,ncols=examples, figsize=(18,6)) \nfor i in xrange(examples): \n    ax[(0,i)].imshow(create_image(random_x[i]), cmap=plt.cm.gray, interpolation='nearest') \n    ax[(1,i)].imshow(create_image(recon_x[i]), cmap=plt.cm.gray, interpolation='nearest') \n    ax[(2,i)].imshow(create_image(example_data[i + (num_gpus-1)*batch_size]), cmap=plt.cm.gray, interpolation='nearest') \n    ax[(0,i)].axis('off') \n    ax[(1,i)].axis('off') \n    ax[(2,i)].axis('off') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9401346818176997
      ],
      "excerpt": "fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(20,10), linewidth = 4) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8308775501608653
      ],
      "excerpt": "leg = plt.legend(handles=[KL_plt, D_plt, G_plt, SSE_plt, LL_plt], fontsize=20) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123763140827432
      ],
      "excerpt": "    global_step = tf.get_variable( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8495735025330324,
        0.8495735025330324,
        0.8495735025330324,
        0.8936954105699045,
        0.8936954105699045,
        0.8936954105699045
      ],
      "excerpt": "lr_D = tf.placeholder(tf.float32, shape=[]) \nlr_G = tf.placeholder(tf.float32, shape=[]) \nlr_E = tf.placeholder(tf.float32, shape=[]) \nopt_D = tf.train.AdamOptimizer(lr_D, epsilon=1.0) \nopt_G = tf.train.AdamOptimizer(lr_G, epsilon=1.0) \nopt_E = tf.train.AdamOptimizer(lr_E, epsilon=1.0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9052469936890081
      ],
      "excerpt": "tf.train.Saver.restore(saver, sess, 'models/faces_multiGPU_64_0000.tfmod') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8985992779391219,
        0.8903576290604673,
        0.8836391184100474,
        0.8836391184100474
      ],
      "excerpt": "examples = 10 \nall_x_recon = np.zeros((batch_size, dim1dim2dim3,n_steps)) \nz_point_a= np.random.normal(0,1,(batch_size,hidden_size)) \nz_point_b= np.random.normal(0,1,(batch_size,hidden_size)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008331685760428,
        0.8826917448272372,
        0.9639213927211587
      ],
      "excerpt": "    all_x_recon[:,:,i] = sess.run((x_tilde), {z_x: z_point_a}) \ncanvas = np.zeros((dim1,dim2examples,dim3, n_steps)) \nprint np.shape(canvas) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8202465251075651
      ],
      "excerpt": "    for i in range(examples): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.88644399147993
      ],
      "excerpt": "    fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(18,12)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8668258580770863
      ],
      "excerpt": "    plt.show() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.889127369350261
      ],
      "excerpt": "    return (x - np.min(x)) / np.max(x - np.min(x)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8836391184100474,
        0.8008331685760428
      ],
      "excerpt": "recon_z = np.random.normal(0,1,(batch_size,hidden_size)) \nrecon_x, recon_l = sess.run((x_tilde, l_x_tilde), {z_x: recon_z}) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8836391184100474,
        0.8008331685760428,
        0.8973933083440926,
        0.8973933083440926,
        0.8973933083440926
      ],
      "excerpt": "    rz = np.random.normal(0,1,(batch_size,hidden_size)) \n    rx, rl = sess.run((x_tilde, l_x_tilde), {z_x: rz}) \n    recon_z= np.concatenate((recon_z,rz),axis = 0) \n    recon_l = np.concatenate((recon_l,rl),axis = 0) \n    recon_x = np.concatenate((recon_x,rx),axis = 0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9332375896145038,
        0.8421350226552953,
        0.8421350226552953
      ],
      "excerpt": "fig, ax = plt.subplots(nrows=int(np.sqrt(num_neurons)),ncols=int(np.sqrt(num_neurons)), figsize=(18,12)) \nfor a in range(int(np.sqrt(num_neurons))): \n    for b in range(int(np.sqrt(num_neurons))): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222385976927443,
        0.809244161177136,
        0.8292505407411963
      ],
      "excerpt": "        receptive_field = norm(np.sum(([proportions[i] * recon_x[i,:] for i in range(len(proportions))]),axis = 0)/np.sum(proportions)- np.mean(recon_x,axis = 0)) \n        ax[(a,b)].imshow(create_image(receptive_field), cmap=plt.cm.gray, interpolation='nearest') \n        ax[(a,b)].axis('off') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9332375896145038,
        0.8421350226552953,
        0.8421350226552953
      ],
      "excerpt": "fig, ax = plt.subplots(nrows=int(np.sqrt(num_neurons)),ncols=int(np.sqrt(num_neurons)), figsize=(18,12)) \nfor a in range(int(np.sqrt(num_neurons))): \n    for b in range(int(np.sqrt(num_neurons))): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222385976927443,
        0.9386387547716886,
        0.809244161177136,
        0.8292505407411963
      ],
      "excerpt": "        receptive_field = norm(np.sum(([proportions[i] * recon_x[i,:] for i in range(len(proportions))]),axis = 0)/np.sum(proportions)- np.mean(recon_x,axis = 0)) \n        #:test = norm(test/np.mean(test_list, axis = 0)) \n        ax[(a,b)].imshow(create_image(receptive_field), cmap=plt.cm.gray, interpolation='nearest') \n        ax[(a,b)].axis('off') \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9231213596508114
      ],
      "excerpt": "print [str(i) + ': ' + headers[i] for i in range(len(headers))] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008331685760428,
        0.8008331685760428
      ],
      "excerpt": "all_z = sess.run((z_x_mean), {all_input: all_batch}) \nall_recon_x = sess.run((x_tilde), {z_x: all_z}) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008331685760428,
        0.8008331685760428,
        0.8973933083440926,
        0.8973933083440926,
        0.8973933083440926,
        0.8973933083440926
      ],
      "excerpt": "    recon_z = sess.run((z_x_mean), {all_input: next_batch}) \n    recon_x = sess.run((x_tilde), {z_x: recon_z}) \nall_z = np.concatenate((all_z,recon_z),axis = 0) \nall_batch = np.concatenate((all_batch,next_batch),axis = 0) \nall_recon_x = np.concatenate((all_recon_x,recon_x),axis = 0) \nall_attrib = np.concatenate((all_attrib,next_attrib),axis = 0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8758219562973181
      ],
      "excerpt": "for i in range(np.shape(all_attrib)[1]): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8973550643270167,
        0.9138072679450079
      ],
      "excerpt": "    average_attribute = np.mean(all_z[has_attribute], axis=0) \n    average_not_attribute = np.mean(all_z[has_attribute == False], axis=0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8838148168639296,
        0.8826917448272372,
        0.8202465251075651
      ],
      "excerpt": "examples = 4 \ncanvas = np.zeros((dim12,dim2examples,dim3)) \nfor i in range(examples): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9102160419814026
      ],
      "excerpt": "fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(18,6)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8836391184100474,
        0.8008331685760428
      ],
      "excerpt": "recon_z = np.random.normal(0,1,(batch_size,hidden_size)) \nrecon_x = sess.run((x_tilde), {z_x: recon_z}) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008331685760428
      ],
      "excerpt": "recon_x_with_attribute = sess.run((x_tilde), {z_x: recon_z_with_attribute}) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9344083551468101,
        0.8202465251075651
      ],
      "excerpt": "canvas = np.zeros((dim1*2,dim2*examples,dim3)) \nfor i in range(examples): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9102160419814026
      ],
      "excerpt": "fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(18,6)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8836391184100474
      ],
      "excerpt": "recon_z = np.random.normal(0,1,(batch_size,hidden_size)) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008331685760428
      ],
      "excerpt": "recon_x = sess.run((x_tilde), {z_x: recon_z}) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8838148168639296,
        0.9344083551468101,
        0.8202465251075651
      ],
      "excerpt": "examples = 3 \ncanvas = np.zeros((dim1,dim2*examples,dim3)) \nfor i in range(examples): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9102160419814026
      ],
      "excerpt": "fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(18,6)) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/timsainb/Tensorflow-MultiGPU-VAE-GAN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# UPDATE: See [Generative Models in Tensorflow 2](https://github.com/timsainb/tensorflow2-generative-models) for a Tensorflow 2.X version of VAEGAN.",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Tensorflow-MultiGPU-VAE-GAN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "timsainb",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/timsainb/Tensorflow-MultiGPU-VAE-GAN/blob/master/readme.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- `tower_grads_e` defines the list of gradients for the encoder for each tower\n- For each GPU we grab parameters corresponding to each network, we then calculate the gradients, and add them to the twoers to be averaged\n\n\n\n```\nwith graph.as_default():\n\n    #: These are the lists of gradients for each tower \n    tower_grads_e = []\n    tower_grads_g = []\n    tower_grads_d = []\n\n    all_input = tf.placeholder(tf.float32, [batch_size*num_gpus, dim1*dim2*dim3])\n    KL_param = tf.placeholder(tf.float32)\n    LL_param = tf.placeholder(tf.float32)\n    G_param = tf.placeholder(tf.float32)\n\n\n    #: Define the network for each GPU\n    for i in xrange(num_gpus):\n          with tf.device('/gpu:%d' % i):\n                with tf.name_scope('Tower_%d' % (i)) as scope:\n                    #: grab this portion of the input\n                    next_batch = all_input[i*batch_size:(i+1)*batch_size,:]\n\n                    #: Construct the model\n                    z_x_mean, z_x_log_sigma_sq, z_x, x_tilde, l_x_tilde, x_p, d_x, l_x, d_x_p, z_p = inference(next_batch)\n\n                    #: Calculate the loss for this tower   \n                    SSE_loss, KL_loss, D_loss, G_loss, LL_loss = loss(next_batch, x_tilde, z_x_log_sigma_sq, z_x_mean, d_x, d_x_p, l_x, l_x_tilde, dim1, dim2, dim3)\n\n                    #: specify loss to parameters\n                    params = tf.trainable_variables()\n                    E_params = [i for i in params if 'enc' in i.name]\n                    G_params = [i for i in params if 'gen' in i.name]\n                    D_params = [i for i in params if 'dis' in i.name]\n\n                    #: Calculate the losses specific to encoder, generator, decoder\n                    L_e = tf.clip_by_value(KL_loss*KL_param + LL_loss, -100, 100)\n                    L_g = tf.clip_by_value(LL_loss*LL_param+G_loss*G_param, -100, 100)\n                    L_d = tf.clip_by_value(D_loss, -100, 100)\n\n\n                    #: Reuse variables for the next tower.\n                    tf.get_variable_scope().reuse_variables()\n\n                    #: Calculate the gradients for the batch of data on this CIFAR tower.\n                    grads_e = opt_E.compute_gradients(L_e, var_list = E_params)\n                    grads_g = opt_G.compute_gradients(L_g, var_list = G_params)\n                    grads_d = opt_D.compute_gradients(L_d, var_list = D_params)\n\n                    #: Keep track of the gradients across all towers.\n                    tower_grads_e.append(grads_e)\n                    tower_grads_g.append(grads_g)\n                    tower_grads_d.append(grads_d)\n\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "```\nwith graph.as_default():\n\n    #: Start the Session\n    init = tf.initialize_all_variables()\n    saver = tf.train.Saver() #: initialize network saver\n    sess = tf.InteractiveSession(graph=graph,config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n    sess.run(init)\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- Importantly, notice how we define the learning rates \n    - `e_current_lr = e_learning_rate*sigmoid(np.mean(d_real),-.5,10)`\n        - we calculate the sigmoid of how the network has been performing, and squash the learning rate using a sigmoid based on that. So if the discriminator has been winning, it's learning rate will be low, and if the generator is winning, it's learning rate will be lower on the next batch.\n\n\n```\ndef sigmoid(x,shift,mult):\n    \"\"\"\n    Using this sigmoid to discourage one network overpowering the other\n    \"\"\"\n    return 1 / (1 + math.exp(-(x+shift)*mult))\n```\n\n\n```\nfig, ax = plt.subplots(nrows=1,ncols=1, figsize=(18,4))\nplt.plot(np.arange(0,1,.01), [sigmoid(i/100.,-.5,10) for i in range(100)])\nax.set_xlabel('Mean of Discriminator(Real) or Discriminator(Fake)')\nax.set_ylabel('Multiplier for learning rate')\nplt.title('Squashing the Learning Rate to balance Discrim/Gen network performance')\n```\n\n\n\n\n    <matplotlib.text.Text at 0x7fe065bc41d0>\n\n\n\n\n![png](VAE-GAN-multi-gpu-celebA_files/VAE-GAN-multi-gpu-celebA_49_1.png)\n\n\n\n```\ntotal_batch = int(np.floor(num_examples / batch_size*num_gpus)) #: how many batches are in an epoch\n\n#: We balance of generator and discriminators learning rate by using a sigmoid function,\n#:  encouraging the generator and discriminator be about equal\nd_real = .5\nd_fake = .5\n\nwhile epoch < num_epochs:    \n    for i in tqdm.tqdm(range(total_batch)):\n        iter_ = data_iterator()\n        #: balence gen and descrim\n        e_current_lr = e_learning_rate*sigmoid(np.mean(d_real),-.5,15)\n        g_current_lr = g_learning_rate*sigmoid(np.mean(d_real),-.5,15)\n        d_current_lr = d_learning_rate*sigmoid(np.mean(d_fake),-.5,15)\n        next_batches, _ = iter_.next()\n\n        _, _, _, D_err, G_err, KL_err, SSE_err, LL_err, d_fake,d_real = sess.run([\n                train_E, train_G, train_D,\n                D_loss, G_loss, KL_loss, SSE_loss, LL_loss,\n                d_x_p, d_x,\n\n            ],\n                                        {\n                lr_E: e_current_lr,\n                lr_G: g_current_lr,\n                lr_D: d_current_lr,\n                all_input: next_batches,\n                KL_param: 1,\n                G_param: 1,\n                LL_param: 1\n            }\n       )\n        #:KL_err= SSE_err= LL_err = 1\n        #: Save our lists\n        dxp_list.append(d_fake)\n        dx_list.append(d_real)\n        G_loss_list.append(G_err)\n        D_loss_list.append(D_err)\n        KL_loss_list.append(KL_err)\n        SSE_loss_list.append(SSE_err)\n        LL_loss_list.append(LL_err)\n    \n        if i%300 == 0:\n            #: print display network output\n            IPython.display.clear_output()\n            print('Epoch: '+str(epoch))\n            plot_network_output()\n  \n    #: save network\n    saver.save(sess,''.join(['models/faces_multiGPU_64_',str(epoch).zfill(4),'.tfmod']))\n    epoch +=1\n\n```\n\n    Epoch: 46\n\n\n\n![png](VAE-GAN-multi-gpu-celebA_files/VAE-GAN-multi-gpu-celebA_50_1.png)\n\n\n\n![png](VAE-GAN-multi-gpu-celebA_files/VAE-GAN-multi-gpu-celebA_50_2.png)\n\n\n    \n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 416,
      "date": "Sun, 26 Dec 2021 07:25:40 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\nexample_data, _ = iter_.next()\nnp.shape(example_data)\n```\n\n\n\n\n    (32, 12288)\n\n\n\n",
      "technique": "Header extraction"
    }
  ]
}


### [Overview](#overview) | [Tutorials](#tutorials) | [Examples](#examples)  | [Installation](#installation) | [References](#references) 

<p align="center">
<img src="https://github.com/Vakihito/SentimentYoutube/blob/main/darkLogo.png?raw=true" width="100"/>
</p>


# Welcome to SentimentYoutube

### News and Announcements
- **2020-10-20**
    - First release of SentimentYoutube ! Version **0.0.1** cames with a simple way to analyze sentiment through out the video, it's not working properly, but defines the start of project by analysing both the frame and the caption of the video.

----

### Overview
**SentimentYoutube** is library that makes an easy way to evaluate the sentiment in a frame, by using TensorFlow Keras to judge the feeling in a frame as positive or negative. In order to do this, we analyze the frames of the video, the description of the frame generated by the pythia library and also the caption of the video.
This library uses Ktrain in order to train models and load models, and also uses pythia to describe a frame.

- In order to use this library, please take a look at it's classes :
    - 'PythiaDemo'  :
        - **PythiaDemon()** - The main utility of this class is to describe a given image, this class is called in Utils to make the process easier. 
    - 'FrameExtractor' :
        - **FrameExtractor()** - The main utility of this library, this is the class that allows to analise a given video via it's ID.
        - **do_preparation()** - This funcion preprers everything needed before using the FrameEXtractor class. 
        - **sum_the_positivity_of_vid()** - This funcion returns the posivitity of the video
        - **show_descriptions_frames_with_caption()** - This function returns the description of each frame and also it's caption
        - **extract_obj.create_caption_description_file()** - This function creates a file with the captions of the video 
        - **extract_obj.create_frame_description_file()** - This function creates a file with the description of each frame. 
        - **extract_obj.plot_caption_sentiment_during_time()** - This function plots the feeling of the captions, frames and frames descriptions over time.
        - **extract_obj.plot_caption_sentiment_during_time()** - This function plots the feeling of the captions, frames and frames descriptions over time in a line. And also the weighted average of the 3 parameters.
    - 'Utils' :
        - This module has bunch of usefull functions that allow a easier use of the library
        - **predic_face()** - This function receives a path to a images and returns the positivity of a image.
        - **predic_text()** - This function receives a path to a images and returns the positivity of the sentence using a pre-trained model of the MDB dataset
        - **show_image_url** - Shows a image given a url
        - **show_image** - Shows a image given a path
        - **show_prediction** - Shows pythia predicion of a image given by either a path or an url
        - **explain_frame** - Explain the classification of the image ( this function doesn't works with BERT, so see the example on how to use explain)
        - **explain_text** - Explain the classification of a text ( this function doesn't works with BERT, so see the example on how to use explain)

---

### Tutorials
Please see the following tutorial notebooks for a guide on how to use **SentimentYoutube** on your projects:
    
- **Tutorial 1**: [Introduction](https://colab.research.google.com/drive/1JEmHlvQ2CFP6Zwdoi1TQyu_Fjzb7J2kW?usp=sharing)

---
### Examples
Please see the following examples notebooks for a guide on how to use **SentimentYoutube** on your projects:
    
- **How to use** : [Introduction](https://colab.research.google.com/drive/1JEmHlvQ2CFP6Zwdoi1TQyu_Fjzb7J2kW?usp=sharing)
- **Using Explain** : [Explain Notebook](https://colab.research.google.com/drive/1EWV1Qss2IxqUReJe1GO4N0AyUviZGCeZ?usp=sharing)
- **Example of the application** : [Video](https://studio.youtube.com/video/eWX21QAbqNE/edit)

---

### Installation
This whole project was made in Google Colab, so Please use [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb) nootebook in order to make this operantion work, other wise you can check our install.sh an change the paths to your liking, but I wouldn't suggest doing so...
- First of all make sure that you are using *GPU* enviroment.
- Than open the file content : <code> cd /content </code>
- Clone the git repository: <code> !git clone https://github.com/Vakihito/SentimentYoutube.git </code> 
- Open the file SentimentYoutube : <code> cd SentimentYoutube/ </code> 
- Install packages requirements: <code> !pip3 install -r requirements.txt </code> 
- Install enviroment requirements: <code> !./install.sh </code> 
- Open the enviroment file : <code> cd /content/vqa-maskrcnn-benchmark </code>
- Thats all, now you are good to go !!!

---

### References
- https://github.com/amaiya/ktrain
- https://arxiv.org/abs/2004.10703
- https://arxiv.org/pdf/1803.09820.pdf
- https://arxiv.org/abs/1409.1556

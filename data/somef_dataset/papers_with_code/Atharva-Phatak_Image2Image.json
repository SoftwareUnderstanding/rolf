{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Unpaired Image to Image Translation using Cycle Consistent Adversarial Networks:https://arxiv.org/pdf/1703.10593.pdf\n* Author's Pytorch Code : https://github.com/junyanz/CycleGAN\n* ICCV talk : https://www.youtube.com/watch?v=AxrKVfjSBiA\n\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Atharva-Phatak/Image2Image",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-07-01T18:01:24Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-18T23:52:53Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9851565383897025,
        0.9513082982022446,
        0.8136091227839468
      ],
      "excerpt": "Image to Image to translation is a process whose goal is to learn mappings between input image and output images i.e it is a task which helps to convert an image from domain to another domain. A great amount of research has been done on this subject , most of it has used a supervised approach where we have corresponding pairs of images from the two domains whose mapping we want to learn. The problem with this approach is that for many a tasks there won't be such paired image data. The below image shows image to image translation tasks. \nThe researcher's at the Berkeley Artificial Intelligence Research (BAIR) published a paper Unsupervised Image-to-Image translation with cycle consistend adversarial networks in 2017 in which an approach was presented which did not required paired image data for image to image translations tasks. Yes of course still the set of images from both the domains was required they do not need to directly correspond to one another. \nCycle Gan is a generative adversarial network with two generators and two discriminators. Let's call one generator G which convert images from domain X to domain Y(G : X -> Y)  and other generator F which converts images from domain Y to domain X (F : Y -> X). Each generator has a corresponding discriminator which tries to tell apart the synthesized image and real image. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.919068073794004,
        0.8094829897909159
      ],
      "excerpt": "What does cycle consistent means? For ex : Consider you translate a sentence from English to French and translate it back , you should reach at the original sentence. This is what cycle consistent means. More formally speaking we have a genereator G:X-->Y  and another generator F:Y-->X the G and F should be inverse mappings of each other. Using this assumption both the generators G and F are trained simultaenously with a loss function that encourages F(G(x)) \u2248 x and G(F(y)) \u2248 y. The images below shows how cycle consistency looks  \nThe cycle consistency loss ensures the property that x --> G(x) --> F(G(x)) \u2248 x \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This is a Pytorch implementation of Cycle Gan's and Pix2Pix to perform unpaired and paired image to image translations.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Atharva-Phatak/Image2Image/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 14:53:11 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Atharva-Phatak/Image2Image/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Atharva-Phatak/Image2Image",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Atharva-Phatak/Image2Image/master/PyTorch_Cycle_Gan.ipynb",
      "https://raw.githubusercontent.com/Atharva-Phatak/Image2Image/master/pix2pix/Train_test_net.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Atharva-Phatak/Image2Image/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Atharva Phatak\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Season-Tranfer",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Image2Image",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Atharva-Phatak",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Atharva-Phatak/Image2Image/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Python 3.6\n* PyTorch\n* Torchvision\n* Numpy\n* Scikit-Image\n\n\n\n\n\n\n\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Thu, 23 Dec 2021 14:53:11 GMT"
    },
    "technique": "GitHub API"
  }
}
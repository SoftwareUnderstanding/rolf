{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1810.04805\n\nCitation.\n@article{devlin2018bert,\n  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},\n  journal={arXiv preprint arXiv:1810.04805},\n  year={2018}\n}\n\nHuggingface implimentation is taken as refference for the pytorch implimentation.\nhttps://github.com/huggingface/pytorch-pretrained-BERT\n\n\nUssage:: \noutput_dir set as per your directory.\ndepends on need of  accuracy change the value of num_train_epochs.\ntask_name\nDownload the data from the below websites.\n\nDatasets:: https://www.nyu.edu/projects/bowman/xnli/\n           https://sites.google.com/view/germeval2017-absa/data\n           https://sites.google.com/site/iggsahome/downloads\n  \n           \nKeep the data in data_dir. Right now script supports .tsv and .xml file formatt.\ntsv file formatt as follows\nSportBr\u00c3\u00bcche am Becken und an den Rippen so die Nachricht des Crashpiloten.\tSport\nsentence(SportBr\u00c3\u00bcche am Becken und an den Rippen so die Nachricht des Crashpiloten",
      "https://arxiv.org/abs/1810.04805"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{devlin2018bert,\n  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},\n  journal={arXiv preprint arXiv:1810.04805},\n  year={2018}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9480153800141525,
        0.9999585948758025,
        0.9999817228116282,
        0.9959021299438506
      ],
      "excerpt": "  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, \n  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina}, \n  journal={arXiv preprint arXiv:1810.04805}, \n  year={2018} \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hegebharat/sentiment-Analysis-for-German-Datasets",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-08T21:49:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-04T19:39:48Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8651211944519488
      ],
      "excerpt": "PyTorch pretrained bert model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9868452850137681
      ],
      "excerpt": "Huggingface implimentation is taken as refference for the pytorch implimentation. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8787673747431781
      ],
      "excerpt": "depends on need of  accuracy change the value of num_train_epochs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8296863750297454
      ],
      "excerpt": "Keep the data in data_dir. Right now script supports .tsv and .xml file formatt. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8981775566248748
      ],
      "excerpt": "Format of xml file is given in the data folder. Check the sampleXml.xml file for the format. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Google Bert model used for sentiment analysis for German language for various data sets.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hegebharat/sentiment-Analysis-for-German-Datasets/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 18:36:30 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hegebharat/sentiment-Analysis-for-German-Datasets/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "hegebharat/sentiment-Analysis-for-German-Datasets",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/hegebharat/sentiment-Analysis-for-German-Datasets/master/SentimentAnalysis.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9995486579735738
      ],
      "excerpt": "pip install pytorch-pretrained-bert \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8177336824426297
      ],
      "excerpt": "output_dir set as per your directory. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8111704432868972
      ],
      "excerpt": "output_dir set as per your directory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8228063458039062,
        0.8174540907975313
      ],
      "excerpt": "Format of xml file is given in the data folder. Check the sampleXml.xml file for the format. \nTraining::  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8374796438982284
      ],
      "excerpt": "set do_train as True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8953298819800729
      ],
      "excerpt": "Once the model is trained fully,it will be stred under output folder as bin file format. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8374796438982284
      ],
      "excerpt": "set MODEL_SAVED_LOAD as True  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8374796438982284
      ],
      "excerpt": "set do_eval as True \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/hegebharat/sentiment-Analysis-for-German-Datasets/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "sentiment-Analysis-for-German-Datasets",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "sentiment-Analysis-for-German-Datasets",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "hegebharat",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/hegebharat/sentiment-Analysis-for-German-Datasets/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Sun, 26 Dec 2021 18:36:30 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2102.07074\"><img src=\"https://img.shields.io/badge/Paper-Report-red\"/></a>\n  <a href=\"https://www.youtube.com/watch?v=xwrUkHiDoiY\"><img src=\"https://img.shields.io/badge/YouTube-Video-ff69b4\"/></a>\n  <a href=\"https://github.com/asarigun/TransGAN/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/thudm/cogdl\"/></a>\n</p>\n-->\n\nThis is re-implementation of [TransGAN: Two Transformers Can Make One Strong GAN, and That Can Scale Up, CVPR 2021](https://arxiv.org/abs/2102.07074",
      "https://arxiv.org/abs/2102.07074",
      "https://arxiv.org/abs/2010.11929",
      "https://arxiv.org/abs/2010.11929",
      "https://arxiv.org/abs/2102.07074",
      "https://arxiv.org/abs/2010.11929"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bibtex\n@article{jiang2021transgan,\n  title={TransGAN: Two Transformers Can Make One Strong GAN},\n  author={Jiang, Yifan and Chang, Shiyu and Wang, Zhangyang},\n  journal={arXiv preprint arXiv:2102.07074},\n  year={2021}\n}\n```\n```bibtex\n@article{dosovitskiy2020,\n  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},\n  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},\n  journal={arXiv preprint arXiv:2010.11929},\n  year={2020}\n}\n```\n```bibtex\n@inproceedings{zhao2020diffaugment,\n  title={Differentiable Augmentation for Data-Efficient GAN Training},\n  author={Zhao, Shengyu and Liu, Zhijian and Lin, Ji and Zhu, Jun-Yan and Han, Song},\n  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},\n  year={2020}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{zhao2020diffaugment,\n  title={Differentiable Augmentation for Data-Efficient GAN Training},\n  author={Zhao, Shengyu and Liu, Zhijian and Lin, Ji and Zhu, Jun-Yan and Han, Song},\n  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},\n  year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{dosovitskiy2020,\n  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},\n  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},\n  journal={arXiv preprint arXiv:2010.11929},\n  year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{jiang2021transgan,\n  title={TransGAN: Two Transformers Can Make One Strong GAN},\n  author={Jiang, Yifan and Chang, Shiyu and Wang, Zhangyang},\n  journal={arXiv preprint arXiv:2102.07074},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9313675897188715,
        0.8944178096468923
      ],
      "excerpt": "Paper Authors: Yifan Jiang, Shiyu Chang, Zhangyang Wang \nCVPR 2021 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9991413308107011,
        0.9812156089400184,
        0.9702799382612449
      ],
      "excerpt": "  <a href=\"https://arxiv.org/abs/2102.07074\"><img src=\"https://img.shields.io/badge/Paper-Report-red\"/></a> \n  <a href=\"https://www.youtube.com/watch?v=xwrUkHiDoiY\"><img src=\"https://img.shields.io/badge/YouTube-Video-ff69b4\"/></a> \n  <a href=\"https://github.com/asarigun/TransGAN/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/thudm/cogdl\"/></a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8112878271991959,
        0.8112878271991959
      ],
      "excerpt": "  <img src=\"https://github.com/asarigun/TransGAN/blob/main/results/transgan_mnist1.gif\" width=\"49%\" /> \n  <img src=\"https://github.com/asarigun/TransGAN/blob/main/results/transgan_mnist1.gif\" width=\"49%\" /> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9763709397001502,
        0.8321723088231245
      ],
      "excerpt": "<p align=\"center\"><img width=\"30%\" src=\"https://github.com/asarigun/TransGAN/blob/main/results/transgan_mnist1.gif\"></p> \n<p align=\"center\"><img width=\"30%\" src=\"https://github.com/asarigun/TransGAN/blob/main/images/atransgan_cifar.gif\"></p>--> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559,
        0.8955886365383559,
        0.8955886365383559,
        0.8955886365383559
      ],
      "excerpt": "<td style=\"text-align: center\">0 Epoch</td> \n<td style=\"text-align: center\">40 Epoch</td>  \n<td style=\"text-align: center\">100 Epoch</td> \n<td style=\"text-align: center\">200 Epoch</td>  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/asarigun/TransGAN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-31T16:07:58Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-20T14:04:19Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8429071251556864
      ],
      "excerpt": "This is re-implementation of TransGAN: Two Transformers Can Make One Strong GAN, and That Can Scale Up, CVPR 2021 in PyTorch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8618811379381098
      ],
      "excerpt": "In this implementation, as a discriminator, Vision Transformer(ViT) Block was used. In order to get more info about ViT, you can look at the original paper here \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9347075359951286
      ],
      "excerpt": "Credits for illustration of ViT: @lucidrains \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "This is a re-implementation of TransGAN: Two Pure Transformers Can Make One Strong GAN (CVPR 2021) in PyTorch.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/asarigun/TransGAN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 14,
      "date": "Fri, 24 Dec 2021 07:52:48 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/asarigun/TransGAN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "asarigun/TransGAN",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/asarigun/TransGAN/main/main.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Before running ```train.py```, check whether you have libraries in ```requirements.txt```! Also, create ```./fid_stat``` folder and download the [fid_stats_cifar10_train.npz](http://bioinf.jku.at/research/ttur/ttur_stats/fid_stats_cifar10_train.npz) file in this folder. To save your model during training, create ```./checkpoint``` folder using ```mkdir checkpoint```.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8748255093542124
      ],
      "excerpt": "You can find pretrained model here. You can download using: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.808650618923604
      ],
      "excerpt": "<p align=\"center\"><img width=\"100%\" src=\"https://github.com/asarigun/TransGAN/blob/main/images/transgan.jpg\"></p> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8011138823862579
      ],
      "excerpt": "<td style=\"text-align: center\">100 Epoch</td> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8084489861054169,
        0.8084489861054169,
        0.8418242451620064,
        0.8271350992106276
      ],
      "excerpt": "<td> <img src=\"https://raw.githubusercontent.com/asarigun/TransGAN/main/results/0.jpg\" style=\"width: 400px;\"/> </td> \n<td> <img src=\"https://raw.githubusercontent.com/asarigun/TransGAN/main/results/40.jpg\" style=\"width: 400px;\"/> </td> \n<td> <img src=\"https://raw.githubusercontent.com/asarigun/TransGAN/main/results/100.jpg\" style=\"width: 400px;\"/> </td> \n<td> <img src=\"https://raw.githubusercontent.com/asarigun/TransGAN/main/results/200.jpg\" style=\"width: 400px;\"/> </td> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9503189345333785
      ],
      "excerpt": "python train.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/asarigun/TransGAN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Ahmet Sarigun\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "TransGAN: Two Transformers Can Make One Strong GAN [[YouTube Video]](https://www.youtube.com/watch?v=xwrUkHiDoiY)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "TransGAN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "asarigun",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/asarigun/TransGAN/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "asarigun",
        "body": "More qualified generated images with TransGAN on CIFAR10 dataset.",
        "dateCreated": "2021-07-06T20:22:19Z",
        "datePublished": "2021-07-06T20:27:20Z",
        "html_url": "https://github.com/asarigun/TransGAN/releases/tag/v2.0",
        "name": "v2.0",
        "tag_name": "v2.0",
        "tarball_url": "https://api.github.com/repos/asarigun/TransGAN/tarball/v2.0",
        "url": "https://api.github.com/repos/asarigun/TransGAN/releases/45796895",
        "zipball_url": "https://api.github.com/repos/asarigun/TransGAN/zipball/v2.0"
      },
      {
        "authorType": "User",
        "author_name": "asarigun",
        "body": "In this version of re-implementation, MNIST and CIFAR-10 datasets were used for TransGAN-S. ",
        "dateCreated": "2021-05-31T16:49:45Z",
        "datePublished": "2021-05-31T16:56:37Z",
        "html_url": "https://github.com/asarigun/TransGAN/releases/tag/v1.0",
        "name": "v1.0",
        "tag_name": "v1.0",
        "tarball_url": "https://api.github.com/repos/asarigun/TransGAN/tarball/v1.0",
        "url": "https://api.github.com/repos/asarigun/TransGAN/releases/43866041",
        "zipball_url": "https://api.github.com/repos/asarigun/TransGAN/zipball/v1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 54,
      "date": "Fri, 24 Dec 2021 07:52:48 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "transgan",
      "gan",
      "pytorch"
    ],
    "technique": "GitHub API"
  }
}
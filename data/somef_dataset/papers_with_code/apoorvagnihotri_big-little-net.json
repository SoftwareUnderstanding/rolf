{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please consider citing the original authors if you find the repository useful.\n\n```\n@article{DBLP:journals/corr/abs-1807-03848,\n  author    = {Chun{-}Fu Chen and\n               Quanfu Fan and\n               Neil Mallinar and\n               Tom Sercu and\n               Rog{\\'{e}}rio Schmidt Feris},\n  title     = {Big-Little Net: An Efficient Multi-Scale Feature Representation for\n               Visual and Speech Recognition},\n  journal   = {CoRR},\n  volume    = {abs/1807.03848},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1807.03848},\n  archivePrefix = {arXiv},\n  eprint    = {1807.03848},\n  timestamp = {Mon, 13 Aug 2018 16:47:58 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1807-03848},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n```\n\nTo train on large batch sizes (train faster) we need to change the learning rate as to maintain the accuracy of the network, therefore I am using `lr=4*old_lr=0.4` since the original batch size is 1/4th of the batch size I used. Citations for the relevant work below:\n\n```\n@article{DBLP:journals/corr/GoyalDGNWKTJH17,\n  author    = {Priya Goyal and\n               Piotr Doll{\\'{a}}r and\n               Ross B. Girshick and\n               Pieter Noordhuis and\n               Lukasz Wesolowski and\n               Aapo Kyrola and\n               Andrew Tulloch and\n               Yangqing Jia and\n               Kaiming He},\n  title     = {Accurate, Large Minibatch {SGD:} Training ImageNet in 1 Hour},\n  journal   = {CoRR},\n  volume    = {abs/1706.02677},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1706.02677},\n  archivePrefix = {arXiv},\n  eprint    = {1706.02677},\n  timestamp = {Mon, 13 Aug 2018 16:49:10 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/GoyalDGNWKTJH17},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n```\n\nCode snippets taken from the following locations were extremely useful to be able to reproduce the results.\n\n- [ResNet Model in PyTorch][1]\n- [ImageNet Runner Code][2]\n- [tensorboardX][3]\n- [torchtest][5]\n\n  [1]: https://pytorch.org/docs/stable/torchvision/models.html\n  [2]: https://github.com/pytorch/examples/tree/master/imagenet\n  [3]: https://github.com/lanpa/tensorboardX\n  [4]: https://arxiv.org/pdf/1706.02677.pdf\n  [5]: https://github.com/suriyadeepan/torchtest\n  [6]: https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{DBLP:journals/corr/GoyalDGNWKTJH17,\n  author    = {Priya Goyal and\n               Piotr Doll{\\'{a}}r and\n               Ross B. Girshick and\n               Pieter Noordhuis and\n               Lukasz Wesolowski and\n               Aapo Kyrola and\n               Andrew Tulloch and\n               Yangqing Jia and\n               Kaiming He},\n  title     = {Accurate, Large Minibatch {SGD:} Training ImageNet in 1 Hour},\n  journal   = {CoRR},\n  volume    = {abs/1706.02677},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1706.02677},\n  archivePrefix = {arXiv},\n  eprint    = {1706.02677},\n  timestamp = {Mon, 13 Aug 2018 16:49:10 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/GoyalDGNWKTJH17},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{DBLP:journals/corr/abs-1807-03848,\n  author    = {Chun{-}Fu Chen and\n               Quanfu Fan and\n               Neil Mallinar and\n               Tom Sercu and\n               Rog{\\'{e}}rio Schmidt Feris},\n  title     = {Big-Little Net: An Efficient Multi-Scale Feature Representation for\n               Visual and Speech Recognition},\n  journal   = {CoRR},\n  volume    = {abs/1807.03848},\n  year      = {2018},\n  url       = {http://arxiv.org/abs/1807.03848},\n  archivePrefix = {arXiv},\n  eprint    = {1807.03848},\n  timestamp = {Mon, 13 Aug 2018 16:47:58 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1807-03848},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8920934305129954
      ],
      "excerpt": "6th March 2019 - Pytorch Basics for CNNs | Understand ResNet code \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.893482209169682
      ],
      "excerpt": "18-21th March 2019 - Waiting for GPU access. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/apoorvagnihotri/big-little-net",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-04T16:17:29Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-08-22T20:58:17Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This is an unofficial submission to ICLR 2019 Reproducibility Challenge. The central theme of the work by the authors is to reduce the computations while improving the accuracy in the case of Object Recognition and Speech Recognition by using multiple branches with different scales in the CNN architecture. This helps in feature detection at different scales. The authors claim that in the case of Object Recognition they can improve the accuracy by 1% while reducing the computations by 1/3rd of the original.\n\n**Update**: For the official code for Big Little Net, checkout [IBM's](https://github.com/IBM/BigLittleNet) Official repository. This repository is being archived.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9977963922558207
      ],
      "excerpt": "[x] Skeleton of the Project \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.93175341634257
      ],
      "excerpt": "[x] Add Nesterov SDG with Cosine LR Scheduler to the runner code \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9250672542407598
      ],
      "excerpt": "[x] Repository archived \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.958099728575859,
        0.9551886688243765,
        0.9864196257205761,
        0.9704417964460853
      ],
      "excerpt": "7th March 2019 - Plan the skeleton of implementation | Coded Block and LayerDef for BLNet which will help any architecture to be ported to Big-Little Net if is similar to ResNet. | Understand Inception Code to work out ways to implement Branches in Big-Little Net. \n8th March 2019 - Setback: The original paper doesn't always follow specific guidelines for num_branch &gt; 2. Therefore my approach to automating for num_branch &gt; 2 would not work. Currently only trying to make the automation work for num_branch=1 and num_branch=2. \n9th March 2019 - Rethought the skeleton of the Project. | <Setback> | Prepared ResBlock, and it's children ResBlockB, ResBlockL and TransitionLayer for BL-Net. \nSetback: The application approach needed the users to be informed of all the caveats of Big-Little Nets and its Network Architecture, threrfore beating the purpose of the generalized application for uninformed users. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9873808427987144
      ],
      "excerpt": "17th March 2019 - Resnet blocks when repeated don't have stride = 2 at each block, need to remove that. Also, the paper mentions that ResBlockB uses a stride of 2 in the first Conv3x3. I think again a similar thing is happening, we only need to apply the stride in the first block, this makes sense too, as the big branch has 1/2 the image resolution than the little branch, therefore, there is no point it upsampling and downsampling the image dims inside the Big Branch itself (authors were really supportive and confirmed that upsampling happens at the end, before the merging of the two branches. ~~Every ResBlockB has a stride = 3 for the conv3x3 and every one of it ends with upsampling, read in the paper.~~ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9003779259467358,
        0.9831652785625625
      ],
      "excerpt": "22th March 2019 - Correct the implementation by having upsampling at the end of the branches itself. \n25th March 2019 - Running on 8 Nvidia-V100 16GB GPUs, taking batch_size=1024 due to time and money contraint. Taking batch size as 1024 as it is the fastest I can go on 16GB cards (according to the idea that batch sizes should be multiple of 2s). Also using lr=0.4 according to the results by the paper [Accurate, Large Minibatch SGD: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9721158556128245,
        0.9555518926749706,
        0.9652011509661117
      ],
      "excerpt": "29th March 2019 - Added basic tests. Reduced memory usage by removing initilization of upsampling convs for ResBlockL other than the last block in blModule. Added Cosine Scheduler, also, the period of the cosine annealing is set to 1 by the authors, thus implicitly having no restarts. \nxx - ~~Run the model on a smaller dataset and try to see if any errors pertain further after that try to reproduce the results for bL-ResNet50.~~. Unfortunately, due to computational constraints, I am unable to move this work forward. \nThe scope of this reproducibility challenge is to reproduce the table given below. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A CNN Architecture that makes use of multi-scale features for Object Recognition.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/apoorvagnihotri/big-little-net/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 20:47:28 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/apoorvagnihotri/big-little-net/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "apoorvagnihotri/big-little-net",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/apoorvagnihotri/big-little-net/master/scripts/val_prep.sh",
      "https://raw.githubusercontent.com/apoorvagnihotri/big-little-net/master/scripts/train_prep.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8171560453295365
      ],
      "excerpt": "18-21th March 2019 - Waiting for GPU access. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8184313879065366
      ],
      "excerpt": "To have a look at the architecture you can use the following command to generate tensorboard files (by default in ./run) to view the architecture. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8225510752193319
      ],
      "excerpt": "[x] Added basic tests \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8145541725233362,
        0.8550302498568001
      ],
      "excerpt": "| bL-Resnet-50 (a=4, b=2) | 23.20           | \n| bL-Resnet-50 (a=4, b=2) | 23.15           | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8009639269710778
      ],
      "excerpt": "python3 train.py .imagenet/ --epochs 4 --lr 0.1 --alpha 2 --beta 4 --workers 4 -a bl_resnet50 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "python3 viz.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/apoorvagnihotri/big-little-net/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "[BIG-LITTLE NET: AN EFFICIENT MULTI-SCALE FEATURE REPRESENTATION FOR VISUAL AND SPEECH RECOGNITION](https://openreview.net/pdf?id=HJMHpjC9Ym)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "big-little-net",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "apoorvagnihotri",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/apoorvagnihotri/big-little-net/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This repository uses:\n- `Python 3.7`\n- `PyTorch 1.0.1`\n\nUsing GPU is _highly_ recommended, the ImageNet dataset is nearly 160GBs, and the models are deep.\n\nRecreate the environment using the following command.\n```sh\nconda create -n bln --file env.yml\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Thu, 23 Dec 2021 20:47:28 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "convolutional-neural-networks"
    ],
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1611.07004](https://arxiv.org/abs/1611.07004",
      "https://arxiv.org/abs/1611.07004"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9743938100916252
      ],
      "excerpt": "This is an implementation of Condition GAN based on a paper by Isola et al. Link : https://arxiv.org/abs/1611.07004 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "| U-Net               | 0.01834 | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sdnr1/c-gan_pix2pix",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-11-04T10:36:37Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-02T09:29:43Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8442258750833765,
        0.9457673818777359,
        0.8386242414851207,
        0.860059181823877
      ],
      "excerpt": "This is an implementation of Condition GAN based on a paper by Isola et al. Link : https://arxiv.org/abs/1611.07004 \nImplemantated using Tensorflow framework for python. This implementation has a U-Net generator as proposed by Isola et al. and also a ResNet-9 generator, of which, any one can be chosen. Optionally, noise can also added to input of generator. \nThe performance of each model was evaluated by compluting Mean Squared Error (MSE) between the predicted and expected output on test data. \n| Model               | MSE     | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Conditional GAN for pix2pix dataset",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sdnr1/c-gan_pix2pix/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Mon, 27 Dec 2021 14:33:54 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sdnr1/c-gan_pix2pix/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "sdnr1/c-gan_pix2pix",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sdnr1/c-gan_pix2pix/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 sdnr1\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Image Translation using Conditional Adversarial Network",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "c-gan_pix2pix",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "sdnr1",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sdnr1/c-gan_pix2pix/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Mon, 27 Dec 2021 14:33:54 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "generative-adversarial-network",
      "conditional-gan",
      "dcgan",
      "image-translation",
      "style-transfer"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Import required functions.\n\n```\nfrom initializeDataset import load_dataset\nfrom c_gan import C_GAN, UNetGenerator, ResNet9Generator, PatchDiscriminator\n```\n\n2. Create object of `C_GAN` class.\n\n```\n#: for U-Net generator\ngan = C_GAN(generator=UNetGenerator(), discriminator=PatchDiscriminator())\n\n#: for ResNet-9 generator\ngan = C_GAN(generator=ResNet9Generator(), discriminator=PatchDiscriminator())\n\n#: for U-Net generator with noise added to inputs\ngan = C_GAN(generator=UNetGenerator(noise=True), discriminator=PatchDiscriminator())\n\n#: for ResNet-9 generator with noise added to inputs\ngan = C_GAN(generator=UNetGenerator(noise=True), discriminator=PatchDiscriminator())\n\n#: Default training rate is 2e-4 for both generator and discriminator\n#: Use 'generator_learning_rate' and 'discriminator_learning_rate' parameters to specify different learning rates\n#: Use 'ckpt_freq' to change frequency of saving TF checkpoint, default frequency is 20 epochs\n```\n\n3. Train model.\n\n```\nEPOCHS = 200\ngan.train(train_dataset, EPOCHS)\n```\n\n4. Evaluate model (Calculate Mean Sqaured Error).\n\n```\nmse = gan.evaluate(test_dataset)\n```\n\n5. Generate samples outputs.\n\n```\nNUM_SAMPLES = 10\nfor tar, img in test_dataset.take(NUM_SAMPLES):\n    gan.generate_image(img, tar)\n```\n\n6. Predict map image from a given aerial image.\n\n```\n#: Input image can be of any size (square images are prefered)\n#: Outputs is a 3 x 256 x 256 RGB image of prediction (range of values [-1, 1])\ngan.predict(input_image) \n```\n\n7. Restoring model from checkpoint.\n\n```\ngan.restore_from_checkpoint()\n```\n\n8. Output model summary\n\n```\n#: Make sure model is compiled before this\ngan.summary()\n```",
      "technique": "Header extraction"
    }
  ]
}
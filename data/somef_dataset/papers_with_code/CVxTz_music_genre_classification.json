{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "TF2 Transformers :\n[https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8536539025170427
      ],
      "excerpt": "https://github.com/mdeff/fma/ and more \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    \"30\": [ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "|  10 | Instrumental             |        6055 | 0.056815    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "|  12 | Hip-Hop                  |        5922 | 0.055567    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "| 149 | Tango                    |          30 | 0.000281495 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "| 156 | Salsa                    |          12 | 0.000112598 | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CVxTz/music_genre_classification",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-07T14:26:08Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-13T15:36:25Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The objective of this post is to implement a music genre classification model by\ncomparing two popular architectures for sequence modeling: Recurrent Neural\nnetworks and Transformers.\n\nRNNs are popular for all sorts of 1D sequence processing tasks, they re-use the\nsame weights at each time step and pass information from a time-step to the next\nby keeping an internal state and using a gating mechanism (LSTM, GRUs \u2026 ). Since\nthey use recurrence, those models can suffer from vanishing/exploding gradients\nwhich can make training and learning long-range patterns harder.\n\n![](https://cdn-images-1.medium.com/max/800/1*3gB5yUL9lqQBuEY7qFIH2A.png)\n\n<span class=\"figcaption_hack\">[Source:\nhttps://en.wikipedia.org/wiki/Recurrent_neural_network](https://en.wikipedia.org/wiki/Recurrent_neural_network)\nby [fdeloche](https://commons.wikimedia.org/wiki/User:Ixnay) Under [CC BY-SA\n4.0](https://creativecommons.org/licenses/by-sa/4.0)</span>\n\nTransformers are a relatively newer architecture that can process sequences\nwithout using any recurrence or convolution\n[[https://arxiv.org/pdf/1706.03762.pdf](https://arxiv.org/pdf/1706.03762.pdf)].\nThe transformer layer is mostly point-wise feed-forward operations and\nself-attention. These types of networks are having some great success in natural\nlanguage processing, especially when pre-trained on a large amount of unlabeled\ndata [[https://arxiv.org/pdf/1810.04805](https://arxiv.org/pdf/1810.04805)].\n\n![](https://cdn-images-1.medium.com/max/800/1*SW0xA1VEJZd3XSqc3NvxNw.png)\n\n<span class=\"figcaption_hack\">Transformer Layer \u2014 Image by author</span>\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9363083432348037,
        0.979442885464926,
        0.8883908295614368
      ],
      "excerpt": "specifically the large version with 106,574 tracks of 30s, 161 unbalanced \ngenres, which sums to a total of 93 Gb of music data. Each track is labeled with \na set of genres that best describe it. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9737063089937403
      ],
      "excerpt": "Our target in this project is to predict those tags. Since a song can be \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9699662560731364,
        0.9240772171925253
      ],
      "excerpt": "for 22% of the data but some other classes appear very few times like Salsa \nwhere it contributes by 0.01% of the dataset. This creates an extreme imbalance \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9213221050623329,
        0.8733971594085799
      ],
      "excerpt": "under the precision-recall curve as our metric. \n|     | Genre                    |   Frequency |    Fraction | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8534640516296449
      ],
      "excerpt": "We use Mel-Spectrograms as input to our networks since its a denser \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731817147278054
      ],
      "excerpt": "better since it turns the raw audio-waves into a sequence of vectors. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9831956846217582
      ],
      "excerpt": "Each 128-D vector on the Time axis is considered an element of the input \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.800853463279414
      ],
      "excerpt": "Mel-spectrograms can take a significant amount of time, so we pre-compute and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8953704369362947
      ],
      "excerpt": "The only difference between the two models is the encoder part being either a \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.850904446598172
      ],
      "excerpt": "We will evaluate each genre using the area under the precision-recall curve and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8224961694908662
      ],
      "excerpt": "We can see that the transformer works a little better than GRU. We can improve \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9260566344730461
      ],
      "excerpt": "prediction of multiple crops of the input sequence. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8958374407135036,
        0.8674850978013962,
        0.9199608234815234
      ],
      "excerpt": "The results overall seem a little weak, it is probably due to the great number \nof classes that make the task harder or maybe due to the class imbalance. One \npossible improvement is to ditch the multi-label approach and work on a ranking \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8840992120337362,
        0.9436467426173988
      ],
      "excerpt": "In this post, we compared two popular architectures for sequence modeling RNNs \nand Transformers. We saw that transformers slightly over-performs GRUs which \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "music genre classification : LSTM vs Transformer",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CVxTz/music_genre_classification/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Sat, 25 Dec 2021 07:26:39 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/CVxTz/music_genre_classification/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "CVxTz/music_genre_classification",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/CVxTz/music_genre_classification/master/code/run.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\npython -m pip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8997243352845468
      ],
      "excerpt": "        mel_db = (librosa.power_to_db(mel_spec, ref=np.max) + 40) / 40 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.813731438120436
      ],
      "excerpt": "save them on disk as a .npy file using NumPy.save. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/CVxTz/music_genre_classification/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Mansar Youness\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "music_genre_classification",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "music_genre_classification",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "CVxTz",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CVxTz/music_genre_classification/blob/master/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Uncompress the data zips (fma_metadata.zip, fma_large.zip).\n* Run [prepare_data.py](code/prepare_data.py) with the correct paths to genrate mapping files.\n* Run [audio_processing.py](code/audio_processing.py) with the correct paths to genrate .npy files.\n* Run training with [rnn_genre_classification.py](code/rnn_genre_classification.py) or [trsf_genre_classification.py](code/trsf_genre_classification.py)\n\n* To predict on new mp3s run [predict.py](code/predict.py) with the correct paths.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 27,
      "date": "Sat, 25 Dec 2021 07:26:39 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "audio",
      "music-genre-classification",
      "music",
      "genre",
      "transformers"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Top 5 predictions:\n\n[Siesta by\nJahzzar](https://freemusicarchive.org/music/Jahzzar/Travellers_Guide/Siesta)\n\n('Folk', 0.7591149806976318)\n\n('Pop', 0.7336021065711975)\n\n('Indie-Rock', 0.6384000778198242)\n\n('Instrumental', 0.5678483843803406)\n\n('Singer-Songwriter', 0.558732271194458)\n\n[Wise Guy by Yung\nKartz](https://freemusicarchive.org/music/Jahzzar/Travellers_Guide/Siesta)\n\n('Electronic', 0.8624182939529419)\n\n('Experimental', 0.6041183471679688)\n\n('Hip-Hop', 0.369397908449173)\n\n('Glitch', 0.31879115104675293)\n\n('Techno', 0.30013027787208557)\n\n",
      "technique": "Header extraction"
    }
  ]
}
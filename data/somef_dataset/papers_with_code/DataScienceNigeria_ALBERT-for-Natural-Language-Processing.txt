# ALBERT-for-Natural-Language-Processing

Welcome ALBERT for Natural Language Processing from researchers from Google AI and Toyota Research.
It builds on BERT (Bidirectional Encoder Representations from Transformers), a popular attention model, to language modelling.

![](2.jpg)

ALBERT Is actually a lite or leaner BERT, which achieves state-of-the-art results on 3 NLP benchmark that exceed human performance, and now in top spot in multiple NLP performance benchmarks and 18x.

![](3.jpg)

Read at https://arxiv.org/pdf/1909.11942v1.pdf

#naturallanguage 

#artificialintelligence 

#machinelearning


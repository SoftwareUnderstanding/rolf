{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2102.09427\n[3]: https://tfhub.dev/google/universal-sentence-encoder/4\n[4]: https://umap-learn.readthedocs.io/en/latest/\n[5]: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n[6]: https://huggingface.co/\n[7]: https://github.com/huggingface/transformers\n[8]: https://arxiv.org/abs/1810.04805\n\n\n",
      "https://arxiv.org/abs/1810.04805\n\n\n"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JA-Bar/nlp-depression",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-04T03:44:22Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-08T06:48:32Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9971780471406917,
        0.8116484525664246,
        0.9748337326153149,
        0.8852458614367389,
        0.8061474619587322,
        0.8862626293645732,
        0.9774270444293396
      ],
      "excerpt": "Group final project of the NLP course. The purpose of this project is to attempt to \nidentify if a user shows signs of depression by analysing a piece of text or audio. \nThe nature of the topic makes it very difficult to come to a conclusion with high \ncertainty, so the scope limits itself to be a tool of potantial identification. \nIn order to accomplish this task we used a dataset scraped from subreddits, where posts are  \nlabeled as being potentially suicidal or non-suicidal. Some things to note are: this an extreme \ncase of our original aim, it's not necessarily linked with depression, and all cases are self \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8840279524150139
      ],
      "excerpt": "It's a notebook that ran in Colab, so the results should be easily reproduced. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8066912982660075,
        0.9147328429032324,
        0.9769610966046116,
        0.9116554163457128,
        0.9779424168387082,
        0.9505359004178165
      ],
      "excerpt": "Among the suicidal posts the most commonly used words appear to be related to desires, people, \nfeelings, and time. The non-suicidal posts appear to use more convertational words not related \nto anything in particular, the only recurrent topic is school related.  \nAnother thing to note is the average length of words per datapoint. After removing stopwords \nand punctuation, the average length of a suicide-related text is 236.28 words, compared to  \n70.85 from a non-suicide text. This is expected, due to the serious nature of the topic, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9152126975211899,
        0.9628620308732677,
        0.9205683965193079
      ],
      "excerpt": "The main preprocessing experiment done is attempting to remove some of the noise in the labels. \nDue to the way the dataset was obtained, the accuracy of the labels is put into question. Not  \nonly because it's self repoted by users, but mainly as a result of web scraping. Posts under \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8783671001164175,
        0.8523838294271204
      ],
      "excerpt": "etc. This is why we tried the approach used by [Haque, Reddi, and Giallanza][2], where they \nused a simple, but effective unsupervised method for noisy label correction. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8323086227490947,
        0.845645671534703,
        0.9725972551812011
      ],
      "excerpt": "Embedd each text into an n-dimensional space \nWe used [Google's universal-sentence-encoder][3] \nReduce the space dimensionality to aid with clustering performance \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9720235264934085
      ],
      "excerpt": "Compute the distance of every point to all clusters to get a soft 'confidence' score \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9573343028728528,
        0.9752129565128018
      ],
      "excerpt": "This method resulted in 11.56% of our data being re-labeled. The idea is to train a baseline \nmodel with traditional processing and another one with noisy label correction to see the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8028211632820258
      ],
      "excerpt": "Models were trained using [Huggingface][6] [transformers][7] library. The google Colab notebook \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8937123946020542,
        0.8139358611196801,
        0.8803281209505861,
        0.9644306940459756
      ],
      "excerpt": "version of [Google's BERT][8]. As mentioned in the previous section, one model was trained with \ntraditional text processing, and another one with noisy label correction applied, as well as \nsome basic reddit specific noise removed. The weights of both models are currently being hosted \non Google Drive for easier access with !gdown in a Google Colab session. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9326467046788578
      ],
      "excerpt": "- --demo: Predict the sentiment of a fixed, predefined set of sentences. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9331959019869124
      ],
      "excerpt": "  as a string argument, where sentences are separated by the set of characters '&&' e.g.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "NLP course project. Tool to potentially identify signs of depression from text and audio.",
      "technique": "GitHub API"
    }
  ],
  "download": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To download the dataset you'll need a Kaggle account. This process can be done through the\ncli, which requires a couple of extra steps if the API access is not already setup:\n\n- Install the python package with `pip3 install kaggle`\n- Go to the Account section of your Kaggle profile\n- Select 'Create API Token', this will download a `kaggle.json` file that contains your token\n- Move the `kaggle.json` file to the `~/.kaggle/` directory\n- Check the functionality with `kaggle --version` or `poetry run kaggle --version`\n- If you are using the API from Google Colab you can use the following snippet\n\n```python\n#: from: https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb\nfrom google.colab import files\n\nuploaded = files.upload()\n\nfor fn in uploaded.keys():\n  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n      name=fn, length=len(uploaded[fn])))\n  \n#: Then move kaggle.json into the folder where the API expects to find it.\n!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n```\nOnce you have the API working, you can download and unzip the dataset with:\n\n- `kaggle datasets download -d nikhileswarkomati/suicide-watch -p data/depression`\n- `unzip data/depression/suicide-watch.zip -d data/depression`\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JA-Bar/nlp-depression/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Fri, 24 Dec 2021 07:57:44 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/JA-Bar/nlp-depression/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "JA-Bar/nlp-depression",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/JA-Bar/nlp-depression/master/Showcase.ipynb",
      "https://raw.githubusercontent.com/JA-Bar/nlp-depression/master/notebooks/model_training.ipynb",
      "https://raw.githubusercontent.com/JA-Bar/nlp-depression/master/notebooks/preprocessing_visualization.ipynb",
      "https://raw.githubusercontent.com/JA-Bar/nlp-depression/master/src/glove_fastext_bert/BERT_suicidal.ipynb",
      "https://raw.githubusercontent.com/JA-Bar/nlp-depression/master/src/glove_fastext_bert/Fasttext_dataset_huggingface.ipynb",
      "https://raw.githubusercontent.com/JA-Bar/nlp-depression/master/src/glove_fastext_bert/Glove_dataset_suicidal.ipynb",
      "https://raw.githubusercontent.com/JA-Bar/nlp-depression/master/src/glove_fastext_bert/Prediction_suicidal.ipynb",
      "https://raw.githubusercontent.com/JA-Bar/nlp-depression/master/src/glove_fastext_bert/Fasttext_dataset_hugging_face.ipynb",
      "https://raw.githubusercontent.com/JA-Bar/nlp-depression/master/src/glove_fastext_bert/BERT_emotion.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8539086385298778
      ],
      "excerpt": "python3 -m src.inference --demo \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8009539817059227
      ],
      "excerpt": "- --demo: Predict the sentiment of a fixed, predefined set of sentences. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8268551150264883
      ],
      "excerpt": "- --data_path: Base path to the directory where all the pretrained models are stored, default=data/. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/JA-Bar/nlp-depression/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "NLP text and audio analysis to potentially identify depression",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "nlp-depression",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "JA-Bar",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JA-Bar/nlp-depression/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Fri, 24 Dec 2021 07:57:44 GMT"
    },
    "technique": "GitHub API"
  }
}
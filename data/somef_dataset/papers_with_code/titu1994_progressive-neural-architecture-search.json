{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Code somewhat inspired by [wallarm/nascell-automl](https://github.com/wallarm/nascell-automl)\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1712.00559"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/titu1994/progressive-neural-architecture-search",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-01-26T02:08:22Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-04T14:41:13Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9696779986046538,
        0.9649332494753047,
        0.860071685270536,
        0.9136201535687309
      ],
      "excerpt": "Uses tf.keras to define and train children / generated networks, which are found via sequential model-based optimization in Tensorflow, ranked by the Controller RNN. \nDefine a state space by using StateSpace, a manager which maintains input states and handles communication between the ControllerManager RNN and the user. \nControllerManager manages the training and evaluation of the Controller RNN \nNetworkManager handles the training and reward computation of the children models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8771530355515161
      ],
      "excerpt": ": construct a state space (the default operators are from the paper) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8769304940127091,
        0.9076713397772102
      ],
      "excerpt": ": For B number of trials \nactions = controller.get_actions(K)  #: get all the children model to train in this trial \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9292411139973592,
        0.9647009590089044,
        0.9644713196522061
      ],
      "excerpt": "In addition, if the search space is small enough, we can pass K (the maximum number of child models we want to compute) to be None. In doing so, all possible child models will be produced and scored by the Controller RNN. \nNote: There is an additional parameter INPUT_B. This is the B parameter with which the RNN was trained. Without this, \nthe Controller RNN cannot know the size of the Input Embedding to create, and defaults to the current B. This in turn causes an issue when loading the weights (as the original embedding would have dimensions [B, EMBEDDING_DIM]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8366129621052135,
        0.8850170747744933
      ],
      "excerpt": "There are many ways of calling this script : \nWhen you want to just visualize the history of the training procedure : Call it without any arguments. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9711193430627957
      ],
      "excerpt": "When you want to visualize a specific score file (to see the Controller RNN's predictions or actual evaluated model scores from training. These score files correspond to the B parameter in the paper, i.e. the width of the Cell generated. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.875270840969285
      ],
      "excerpt": "When you want to visualize not just the scored files, but also the training history - i.e. visualize everything at once: Simply pass * to the -f argument. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9842896937804463,
        0.9626744034475891,
        0.8286630720163912
      ],
      "excerpt": "This is a very limited project. \n- It is not a faithful re-implementation of the original paper. There are several small details not incorporated (like bias initialization, actually using the Hc-2 - Hcb-1 values etc) \n- It doesnt have support for skip connections via 'anchor points' etc. (though it may not be that hard to implement it as a special state) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.858796874750459,
        0.9842776132724277
      ],
      "excerpt": "- Single GPU model only. There would need to be a lot of modifications to this for multi GPU training (and I have just 1) \nI tried a toy CNN model with 2 CNN cells the a custom search space, train for just 5 epoch of training on CIFAR-10. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.955293614253683
      ],
      "excerpt": "score_architectures.py to pseudo-score all combinations of models for all values of B, and then pass these onto rank_architectures.py to approximate the scores that they would obtain. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9495120890968208
      ],
      "excerpt": "After sorting using the -sort argument in rank_architectures.py, we get the following of the same data as above. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Implementation of Progressive Neural Architecture Search in Keras and Tensorflow",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/titu1994/progressive-neural-architecture-search/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 31,
      "date": "Tue, 28 Dec 2021 17:33:06 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/titu1994/progressive-neural-architecture-search/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "titu1994/progressive-neural-architecture-search",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8071545861728154
      ],
      "excerpt": "Once the RNN Controller has been trained above the above approach, we can then score all possible model combinations. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python score_architectures.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8751928579730358
      ],
      "excerpt": "python rank_architectures.py  #: optional -sort \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9288168155218618,
        0.8066151915889843
      ],
      "excerpt": "python rank_architectures.py -f score_2.csv \n: Here we assume we want to rank the score_2.csv file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8761427986041771,
        0.8419054742396113
      ],
      "excerpt": "python rank_architectures.py -f score_5.csv score_3.csv score_2.csv \nWhen you want to visualize all score files at once: Pass the file name as score_*.csv. It uses glob internally, so all of its semantics will work here as well. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9288168155218618
      ],
      "excerpt": "python rank_architectures.py -f scores_*.csv \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9288168155218618
      ],
      "excerpt": "python rank_architectures.py -f *.csv \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/titu1994/progressive-neural-architecture-search/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 Somshubra Majumdar\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Progressive Neural Architecture Search with ControllerManager RNN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "progressive-neural-architecture-search",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "titu1994",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/titu1994/progressive-neural-architecture-search/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "titu1994",
        "body": "",
        "dateCreated": "2018-05-30T00:01:46Z",
        "datePublished": "2019-01-24T22:00:54Z",
        "html_url": "https://github.com/titu1994/progressive-neural-architecture-search/releases/tag/v1.0.0",
        "name": "Progressive NAS - Legacy",
        "tag_name": "v1.0.0",
        "tarball_url": "https://api.github.com/repos/titu1994/progressive-neural-architecture-search/tarball/v1.0.0",
        "url": "https://api.github.com/repos/titu1994/progressive-neural-architecture-search/releases/15170210",
        "zipball_url": "https://api.github.com/repos/titu1994/progressive-neural-architecture-search/zipball/v1.0.0"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Tensorflow-gpu >= 1.12\n- Scikit-learn (most recent available from pip)\n- (Optional) matplotlib - to visualize using `rank_architectures.py`\n- (Optional) mplcursors - to have annotated models when using `rank_architectures.py`.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 115,
      "date": "Tue, 28 Dec 2021 17:33:06 GMT"
    },
    "technique": "GitHub API"
  }
}
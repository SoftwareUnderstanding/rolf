{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This work was done with the support from **[OLIVES](https://ghassanalregib.info/)@GT**. <br>\nFeel free to check our lab's [Website](https://ghassanalregib.info/) and [GitHub](https://github.com/olivesgatech) for other interesting work!!!\n\n\nSome codes are borrowed from [ms-tcn](https://github.com/yabufarha/ms-tcn), [TA3N](https://github.com/cmhungsteve/TA3N), [swd_pytorch](https://github.com/krumo/swd_pytorch), and [VCOP](https://github.com/xudejing/VCOP).\n\n\n---\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2003.02824",
      "https://arxiv.org/abs/2003.02824}\n}\n\n@inproceedings{chen2020mixed,\n  title={Action Segmentation with Mixed Temporal Domain Adaptation},\n  author={Chen, Min-Hung and Li, Baopu and Bao, Yingze and AlRegib, Ghassan},\n  booktitle={IEEE Winter Conference on Applications of Computer Vision (WACV"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this repository useful, please cite our papers:\n```\n@inproceedings{chen2020action,\n  title={Action Segmentation with Joint Self-Supervised Temporal Domain Adaptation},\n  author={Chen, Min-Hung and Li, Baopu and Bao, Yingze and AlRegib, Ghassan and Kira, Zsolt},\n  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n  year={2020},\n  url={https://arxiv.org/abs/2003.02824}\n}\n\n@inproceedings{chen2020mixed,\n  title={Action Segmentation with Mixed Temporal Domain Adaptation},\n  author={Chen, Min-Hung and Li, Baopu and Bao, Yingze and AlRegib, Ghassan},\n  booktitle={IEEE Winter Conference on Applications of Computer Vision (WACV)},\n  year={2020}\n}\n```\n\n---\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{chen2020mixed,\n  title={Action Segmentation with Mixed Temporal Domain Adaptation},\n  author={Chen, Min-Hung and Li, Baopu and Bao, Yingze and AlRegib, Ghassan},\n  booktitle={IEEE Winter Conference on Applications of Computer Vision (WACV)},\n  year={2020}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{chen2020action,\n  title={Action Segmentation with Joint Self-Supervised Temporal Domain Adaptation},\n  author={Chen, Min-Hung and Li, Baopu and Bao, Yingze and AlRegib, Ghassan and Kira, Zsolt},\n  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n  year={2020},\n  url={https://arxiv.org/abs/2003.02824}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9897046034668987,
        0.9999999876730642,
        0.9997648149423749
      ],
      "excerpt": "Min-Hung Chen, Baopu Li, Yingze Bao, Ghassan AlRegib (Advisor), and Zsolt Kira <br> \nIEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020  \n[arXiv][1-min Video][5-min Video][Poster][Slides][Open Access]<br> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cmhungsteve/SSTDA",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[Min-Hung Chen](https://minhungchen.netlify.app/) <br>\ncmhungsteve AT gatech DOT edu <br>\n[<img align=\"left\" src=\"webpage/OLIVES_new.png\" width=\"15%\">](https://ghassanalregib.info/)\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-04T05:04:29Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-09T03:09:12Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9965135827183605
      ],
      "excerpt": "This is the official PyTorch implementation of our paper: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9923536833534582
      ],
      "excerpt": "Despite the recent progress of fully-supervised action segmentation techniques, the performance is still not fully satisfactory. One main challenge is the problem of spatiotemporal variations (e.g. different people may perform the same activity in various ways). Therefore, we exploit unlabeled videos to address this problem by reformulating the action segmentation task as a cross-domain problem with domain discrepancy caused by spatio-temporal variations. To reduce the discrepancy, we propose Self-Supervised Temporal Domain Adaptation (SSTDA), which contains two self-supervised auxiliary tasks (binary and sequential domain prediction) to jointly align cross-domain feature spaces embedded with local and global temporal dynamics, achieving better performance than other Domain Adaptation (DA) approaches. On three challenging benchmark datasets (GTEA, 50Salads, and Breakfast), SSTDA outperforms the current state-of-the-art method by large margins (e.g. for the F1@25 score, from 59.6% to 69.1% on Breakfast, from 73.4% to 81.5% on 50Salads, and from 83.6% to 89.1% on GTEA), and requires only 65% of the labeled training data for comparable performance, demonstrating the usefulness of adapting to unlabeled target videos across variations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9443204734225691
      ],
      "excerpt": "* `path_data` needs to be the same as the location of the input data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "[CVPR 2020] Action Segmentation with Joint Self-Supervised Temporal Domain Adaptation (PyTorch)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cmhungsteve/SSTDA/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 20,
      "date": "Tue, 21 Dec 2021 02:32:45 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/cmhungsteve/SSTDA/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "cmhungsteve/SSTDA",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/cmhungsteve/SSTDA/master/scripts/run_breakfast_SSTDA.sh",
      "https://raw.githubusercontent.com/cmhungsteve/SSTDA/master/scripts/run_breakfast_baseline.sh",
      "https://raw.githubusercontent.com/cmhungsteve/SSTDA/master/scripts/run_50salads_baseline.sh",
      "https://raw.githubusercontent.com/cmhungsteve/SSTDA/master/scripts/run_gtea_SSTDA.sh",
      "https://raw.githubusercontent.com/cmhungsteve/SSTDA/master/scripts/run_gtea_baseline.sh",
      "https://raw.githubusercontent.com/cmhungsteve/SSTDA/master/scripts/run_50salads_SSTDA.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "`); otherwise the implementation may be different.\n\n---\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "* Clone the this repository:\n```\ngit clone https://github.com/cmhungsteve/SSTDA.git\n```\n* Download the [Dataset](https://www.dropbox.com/s/kc1oyz79rr2znmh/Datasets.zip?dl=0) folder, which contains the features and the ground truth labels. (~30GB)\n * To avoid the difficulty for downloading the whole file, we also divide it into multiple files:\n    * [GTEA](https://www.dropbox.com/s/f0bxg73l62v9yo6/gtea.zip?dl=0), [50Salads](https://www.dropbox.com/s/1vzeidtkzjef7vy/50salads.zip?dl=0), [Breakfast-part1](https://www.dropbox.com/s/xgeffaqs5cbbs4l/breakfast_part1.zip?dl=0), [Breakfast-part2](https://www.dropbox.com/s/mcpj4ny85c1xgvv/breakfast_part2.zip?dl=0), [Breakfast-part3](https://www.dropbox.com/s/o8ba90n7o3rxqun/breakfast_part3.zip?dl=0), [Breakfast-part4](https://www.dropbox.com/s/v1vx55zud97x544/breakfast_part4.zip?dl=0), [Breakfast-part5](https://www.dropbox.com/s/e635tkwpd22dlt9/breakfast_part5.zip?dl=0)\n* Extract it so that you have the `Datasets` folder.\n* The default path for the dataset is `../../Datasets/action-segmentation/` if the current location is `./action-segmentation-DA/`. If you change the dataset path, you need to edit the scripts as well.\n\n---\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8276429562226255
      ],
      "excerpt": "<img src=\"webpage/Overview.png?raw=true\" width=\"70%\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8413533775422614
      ],
      "excerpt": "* `training`, `predict` and `eval` are the modes that can be switched on or off by set as `true` or `false`. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/cmhungsteve/SSTDA/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Min-Hung Chen\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Action Segmentation with Joint Self-Supervised Temporal Domain Adaptation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "SSTDA",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "cmhungsteve",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cmhungsteve/SSTDA/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Tested with:\n* Ubuntu 18.04.2 LTS\n* PyTorch 1.1.0\n* Torchvision 0.3.0\n* Python 3.7.3\n* GeForce GTX 1080Ti\n* CUDA 9.2.88\n* CuDNN 7.14\n\nOr you can directly use our environment file:\n```\nconda env create -f environment.yml\n```\n\n---\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Since there are lots of arguments, we recommend to directly run the scripts.\n* All the scripts are in the folder `scripts/` with the name `run_<dataset>_<method>.sh`.\n* You can simply copy any script to the main folder (same location as all the `.py` files), and run the script as below:\n```\n#: one example\nbash run_gtea_SSTDA.sh\n```\nThe script will do training, predicting and evaluation for all the splits on the dataset (`<dataset>`) using the method (`<method>`).\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 140,
      "date": "Tue, 21 Dec 2021 02:32:45 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "cvpr2020",
      "pytorch",
      "domain-adaptation",
      "domain-discrepancy",
      "temporal-dynamics",
      "video",
      "action-segmentation",
      "self-supervised-learning",
      "video-understanding"
    ],
    "technique": "GitHub API"
  }
}
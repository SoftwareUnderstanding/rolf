{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1708.05144\n.. _`Trust Region Policy Optimization`: http://proceedings.mlr.press/v37/schulman15.html\n.. _`Normalized Advantage Function`: http://proceedings.mlr.press/v48/gu16.html\n.. _`Stochastic Value Gradients`: http://papers.nips.cc/paper/5796-learning-continuous-control-policies-by-stochastic-value-gradients\n.. _`Soft Actor-Critic`: http://proceedings.mlr.press/v80/haarnoja18b.html\n.. _`Model-Based Policy Optimization`: http://arxiv.org/abs/1906.08253\n.. _`Streamlined Off-Policy`: https://arxiv.org/abs/1910.02208\n.. _`Model-based Action-Gradient-Estimator`: https://arxiv.org/abs/2004.14309\n\n\nCommand-line interface\n----------------------\n\n.. role:: bash(code",
      "https://arxiv.org/abs/1910.02208\n.. _`Model-based Action-Gradient-Estimator`: https://arxiv.org/abs/2004.14309\n\n\nCommand-line interface\n----------------------\n\n.. role:: bash(code",
      "https://arxiv.org/abs/2004.14309\n\n\nCommand-line interface\n----------------------\n\n.. role:: bash(code"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8090016440670298,
        0.8438610468642279
      ],
      "excerpt": "       :alt: GitHub Workflow Status \n.. |Dependabot| image:: https://api.dependabot.com/badges/status?host=github&repo=angelolovatto/raylab \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9552583288569969,
        0.8090016440670298,
        0.9308022106506542,
        0.9626356225854676
      ],
      "excerpt": ".. |License| image:: https://img.shields.io/github/license/angelolovatto/raylab?color=blueviolet&logo=github \n         :alt: GitHub \n.. |CodeStyle| image:: https://img.shields.io/badge/code%20style-black-000000.svg \n           :target: https://github.com/psf/black \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "                 num_samples=10, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "         if __name__ == \"__main__\": \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906174419333412
      ],
      "excerpt": "| Trust Region Policy Optimization                    | TRPO                    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278824608274014
      ],
      "excerpt": "| Streamlined Off-Policy (DDPG)                       | SOP                     | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.996988835456721,
        0.9909661639620052,
        0.8280298973134139,
        0.9234542065779933,
        0.9474635993655147,
        0.9451687571233693,
        0.999419518108742,
        0.9819747982998702
      ],
      "excerpt": ".. Actor Critic using Kronecker-factored Trust Region: https://arxiv.org/abs/1708.05144 \n.. Trust Region Policy Optimization: http://proceedings.mlr.press/v37/schulman15.html \n.. Normalized Advantage Function: http://proceedings.mlr.press/v48/gu16.html \n.. Stochastic Value Gradients: http://papers.nips.cc/paper/5796-learning-continuous-control-policies-by-stochastic-value-gradients \n.. Soft Actor-Critic: http://proceedings.mlr.press/v80/haarnoja18b.html \n.. Model-Based Policy Optimization: http://arxiv.org/abs/1906.08253 \n.. Streamlined Off-Policy: https://arxiv.org/abs/1910.02208 \n.. Model-based Action-Gradient-Estimator: https://arxiv.org/abs/2004.14309 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8656748794658534
      ],
      "excerpt": "|-- policy            # Extensions and customizations of RLlib's policy API \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/angelolovatto/raylab",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-09-12T13:50:53Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-03T10:16:43Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8850634729098461
      ],
      "excerpt": "Raylab provides agents and environments to be used with a normal RLlib/Tune setup. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9081110401232223,
        0.951720728415404
      ],
      "excerpt": "    Accepts arbitrary keyword arguments to pass to `wandb.init`. \n    The defaults for `wandb.init` are: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9557155312120896,
        0.9607526669878986
      ],
      "excerpt": "      * login to W&amp;B with the appropriate API key for your \n        team/project. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9153014041121382
      ],
      "excerpt": "    Check out the Quickstart for more information: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9473627623130363
      ],
      "excerpt": "You can add the :code:--rllib flag to get the descriptions for all the options common to RLlib agents \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9430561341022999
      ],
      "excerpt": "types of exploration for the NAF agent. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "                 local_dir=\"data/NAF\", \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "raylab dashboard data/NAF/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9124182776301586
      ],
      "excerpt": "Finally, you can pass a checkpoint to :code:raylab rollout to see the returns collected by the agent and \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.950420935287189
      ],
      "excerpt": "| Model-Based Policy Optimization                     | MBPO                    | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8488774965944276
      ],
      "excerpt": "  --help  Show this message and exit. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9577741320505785
      ],
      "excerpt": "The project is structured as follows \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9601085383907361
      ],
      "excerpt": "|-- policy            # Extensions and customizations of RLlib's policy API \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Reinforcement learning algorithms in RLlib",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/angelolovatto/raylab/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Wed, 29 Dec 2021 14:04:14 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/angelolovatto/raylab/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "angelolovatto/raylab",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/angelolovatto/raylab/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": ".. code:: bash\n\n          pip install raylab\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8571016692592176,
        0.933350151952
      ],
      "excerpt": ".. |PyPI| image:: https://img.shields.io/pypi/v/raylab?logo=PyPi&logoColor=white&color=blue \n      :alt: PyPI \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9976691354872286
      ],
      "excerpt": "      * install `wandb` via pip \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8255045337929869
      ],
      "excerpt": "Launching experiments can be done via the command line using :code:raylab experiment passing a file path \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9221528281523831,
        0.9426287346323968
      ],
      "excerpt": "|   |-- modules       # PyTorch neural network modules for TorchPolicy \n|-- pytorch           # PyTorch extensions \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "    * reinit: True \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9478002138863177
      ],
      "excerpt": "raylab experiment PG --name PG -s training_iteration 10 --config examples/PG/cartpole_defaults.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9133368656218674,
        0.8801854956928516,
        0.9133368656218674
      ],
      "excerpt": "         import ray \n         from ray import tune \n         import raylab \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008331685760428
      ],
      "excerpt": "             tune.run( \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8924976426181745,
        0.8924976426181745
      ],
      "excerpt": "                             \"raylab.utils.exploration.GaussianNoise\", \n                             \"raylab.utils.exploration.ParameterNoise\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8142835995138061
      ],
      "excerpt": "             main() \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8786829442168927
      ],
      "excerpt": "Usage: raylab [OPTIONS] COMMAND [ARGS]... \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8479123100060002
      ],
      "excerpt": "  test-module  Launch dashboard to test generative models from a checkpoint. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/angelolovatto/raylab/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020, \\xc3\\x82ngelo Greg\\xc3\\xb3rio Lovatto\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "raylab",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "angelolovatto",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/angelolovatto/raylab/blob/master/README.rst",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "angelolovatto",
        "body": "\r\n#### New Features\r\n* (modules): add new DDPG and MBDDPG\r\n* (modules): add new SAC and MBSAC\r\n* (modules): add stochastic models with parallelized forward pass for ensembles\r\n* (modules): add stochastic policies and actor\r\n* (agents): use new DDPG and SAC modules as defaults\r\n* (agents): use new model-based DDPG and SAC modules as defaults\r\n* (policy): check model, action dist, and exploration compatibility\r\n* (policy): check module compatibility with action dist\r\n* (policy): add model property\r\n* (policy): add stochastic and deterministic action dist wrappers\r\n* (pytorch): add reverse mode to TanhSquash\r\n* (pytorch): add no-op initializer\r\n\r\n#### Refactorings\r\n* rename `raylab.losses` to `raylab.policy.losses`\r\n* rename `raylab.modules` to `raylab.policy.modules`\r\n* (policy): remove `TargetNetworksMixin`\r\n* (tests): match test and package directory structures\r\n\r\n#### Others\r\n* (examples): use MBSAC in MBPO\r\n* (examples): use MBSAC in MAPO\r\n* (modules): rename `parameter_noise` option to `separate_behavior`\r\n* (modules): move old NNs to v0 submodule\r\n* (policy): allow subclasses to set `dist_class` before calling init\r\n\r\n",
        "dateCreated": "2020-07-04T22:35:27Z",
        "datePublished": "2020-07-04T23:46:09Z",
        "html_url": "https://github.com/angelolovatto/raylab/releases/tag/v0.8.6",
        "name": "Raylab 0.8.6",
        "tag_name": "v0.8.6",
        "tarball_url": "https://api.github.com/repos/angelolovatto/raylab/tarball/v0.8.6",
        "url": "https://api.github.com/repos/angelolovatto/raylab/releases/28224790",
        "zipball_url": "https://api.github.com/repos/angelolovatto/raylab/zipball/v0.8.6"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 27,
      "date": "Wed, 29 Dec 2021 14:04:14 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "reinforcement-learning",
      "rllib",
      "deep-learning",
      "model-based-rl",
      "machine-learning",
      "streamlit",
      "bokeh",
      "pytorch",
      "generative-models",
      "normalizing-flows"
    ],
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2010.00654",
      "https://arxiv.org/abs/2007.03898",
      "https://arxiv.org/abs/2010.00654"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{\nxiao2021vaebm,\ntitle={VAEBM: A Symbiosis between Variational Autoencoders and Energy-based Models},\nauthor={Zhisheng Xiao and Karsten Kreis and Jan Kautz and Arash Vahdat},\nbooktitle={International Conference on Learning Representations},\nyear={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9717124805508957
      ],
      "excerpt": "  <a href=\"https://xavierxiao.github.io/\" target=\"_blank\">Zhisheng&nbsp;Xiao</a> &emsp; <b>&middot;</b> &emsp; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8854398367006624
      ],
      "excerpt": "  <a href=\"http://jankautz.com/\" target=\"_blank\">Jan&nbsp;Kautz</a> &emsp; <b>&middot;</b> &emsp; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9278824608274014
      ],
      "excerpt": "      --num_preprocess_blocks 1 --num_postprocess_blocks 1 --num_groups_per_scale 30 --batch_size 32 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "      --num_channels_enc 32 --num_channels_dec 32 --epochs 200 --num_postprocess_cells 2 --num_preprocess_cells 2 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9598596565459202
      ],
      "excerpt": "--im_size 64 --lr 5e-5 --batch_size 32 --n_channel 64 --num_steps 10 --use_mu_cd --wd 3e-5 --step_size 5e-6 --total_iter 30000  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9598596565459202
      ],
      "excerpt": "--im_size 64 --batch_size 32 --n_channel 64 --num_steps 10 --use_mu_cd --wd 3e-5 --step_size 4e-6 --total_iter 30000 --alpha_s 0.2 --lr 4e-5  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/NVlabs/VAEBM",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-01T23:57:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-15T01:57:56Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9658532633537018,
        0.9761726978930719
      ],
      "excerpt": "VAEBM trains an energy network to refine the data distribution learned by an NVAE, where the enery network and the VAE jointly define an Energy-based model. \nThe NVAE is pretrained before training the energy network, and please refer to NVAE's implementation for more details about constructing and training NVAE. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9785202475312229
      ],
      "excerpt": "Note that the training of VAEBM will eventually explode (See Appendix E of our paper), and therefore it is important to save checkpoint regularly. After the training explodes, stop running the code and use the last few saved checkpoints for testing. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9073736796965352,
        0.9207512574571493
      ],
      "excerpt": "longer Langvin dynamics than training for better sample quality, see Appendix E of the paper for the step sizes and number of steps we use to obtain test samples \nfor each dataset. Other parameters that ensure successfully loading the VAE and energy network are the same as in the training codes.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "For CelebA 64,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "For LSUN Church 64,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "For CelebA HQ 256,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "The Official PyTorch Implementation of \"VAEBM: A Symbiosis between Variational Autoencoders and Energy-based Models\" (ICLR 2021 spotlight paper)",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/NVlabs/VAEBM/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Wed, 29 Dec 2021 20:15:28 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/NVlabs/VAEBM/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "NVlabs/VAEBM",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We trained on several datasets, including CIFAR10, CelebA64, LSUN Church 64 and CelebA HQ 256. \nFor large datasets, we store the data in LMDB datasets for I/O efficiency. Check [here](https://github.com/NVlabs/NVAE#set-up-file-paths-and-data) for information regarding dataset preparation.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8867036077399154
      ],
      "excerpt": "We use the following commands on each dataset for training VAEBM. Note that you need to train the NVAE on corresponding dataset before running the training command here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9217293604754502
      ],
      "excerpt": "We train VAEBM on CIFAR-10 using one 32-GB V100 GPU.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9511532696592848
      ],
      "excerpt": "We train VAEBM on CelebA 64 using one 32-GB V100 GPU.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9511532696592848
      ],
      "excerpt": "We train VAEBM on LSUN Church 64 using one 32-GB V100 GPU.  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9099274267521357
      ],
      "excerpt": "python train.py --data $DATA_DIR/cifar10 --root $CHECKPOINT_DIR --save $EXPR_ID --dataset cifar10 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9247484755892216
      ],
      "excerpt": "python train.py --data  $DATA_DIR/celeba64_lmdb --root $CHECKPOINT_DIR --save $EXPR_ID --dataset celeba_64 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9247484755892216
      ],
      "excerpt": "python train.py -data  $DATA_DIR/celeba/celeba-lmdb --root $CHECKPOINT_DIR --save $EXPR_ID --dataset celeba_256 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9247484755892216
      ],
      "excerpt": "python train.py --data $DATA_DIR/LSUN/ --root $CHECKPOINT_DIR --save $EXPR_ID --dataset lsun_church_64 \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8705268881358156,
        0.8365206244440856
      ],
      "excerpt": "python train_VAEBM.py  --checkpoint ./checkpoints/cifar10/checkpoint.pt --experiment cifar10_exp1 \n--dataset cifar10 --im_size 32 --data ./data/cifar10 --num_steps 10  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740833845460586
      ],
      "excerpt": "python train_VAEBM.py --checkpoint ./checkpoints/celeba_64/checkpoint.pt --experiment celeba64_exp1 --dataset celeba_64  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740833845460586
      ],
      "excerpt": "python train_VAEBM.py --checkpoint ./checkpoints/lsun_church/checkpoint.pt --experiment lsunchurch_exp1 --dataset lsun_church  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8740833845460586
      ],
      "excerpt": "python train_VAEBM_distributed.py --checkpoint ./checkpoints/celeba_256/checkpoint.pt --experiment celeba256_exp1 --dataset celeba_256 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.894415284874269
      ],
      "excerpt": "To generate samples from VAEBM after training, run sample_VAEBM.py, and it will generate 50000 test images in your given path. When sampling, we typically use  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8397463752735835,
        0.8859008603994282,
        0.8452516937157523
      ],
      "excerpt": "For example, the script used to sample CIFAR-10 is \npython sample_VAEBM.py --checkpoint ./checkpoints/cifar_10/checkpoint.pt --ebm_checkpoint ./saved_models/cifar_10/cifar_exp1/EBM.pth  \n--dataset cifar10 --im_size 32 --batch_size 40 --n_channel 128 --num_steps 16 --step_size 8e-5 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8859008603994282,
        0.8139821637066104
      ],
      "excerpt": "python sample_VAEBM.py --checkpoint ./checkpoints/celeba_64/checkpoint.pt --ebm_checkpoint ./saved_models/celeba_64/celeba64_exp1/EBM.pth  \n--dataset celeba_64 --im_size 64 --batch_size 40 --n_channel 64 --num_steps 20 --step_size 5e-6 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8859008603994282
      ],
      "excerpt": "python sample_VAEBM.py --checkpoint ./checkpoints/lsun_church/checkpoint.pt --ebm_checkpoint ./saved_models/lsun_chruch/lsunchurch_exp1/EBM.pth  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8859008603994282,
        0.8345832032882455
      ],
      "excerpt": "python sample_VAEBM.py --checkpoint ./checkpoints/celeba_256/checkpoint.pt --ebm_checkpoint ./saved_models/celeba_256/celeba256_exp1/EBM.pth  \n--dataset celeba_256 --im_size 256 --batch_size 10 --n_channel 64 --num_steps 24 --step_size 3e-6 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8069454488777176
      ],
      "excerpt": "python fid.py /path/to/training_images /path/to/sampled_images \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8069454488777176,
        0.8031031522299795,
        0.8755501736047567
      ],
      "excerpt": "python fid.py /path/to/sampled_images /path/to/precalculated_stats.npz \nFor the Inception Score, save samples in a single numpy array with pixel values in range [0, 255] and simply run  \npython ./thirdparty/inception_score.py --sample_dir /path/to/sampled_images \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/NVlabs/VAEBM/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/NVlabs/VAEBM/main/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'NVIDIA Source Code License for VAEBM\\n\\n1. Definitions\\n\\n\\xe2\\x80\\x9cLicensor\\xe2\\x80\\x9d means any person or entity that distributes its Work.\\n\\n\\xe2\\x80\\x9cSoftware\\xe2\\x80\\x9d means the original work of authorship made available under this License.\\n\\n\\xe2\\x80\\x9cWork\\xe2\\x80\\x9d means the Software and any additions to or derivative works of the Software that are made available under\\nthis License.\\n\\n\\xe2\\x80\\x9cNVIDIA Processors\\xe2\\x80\\x9d means any central processing unit (CPU), graphics processing unit (GPU), field-programmable\\ngate array (FPGA), application-specific integrated circuit (ASIC) or any combination thereof designed, made, sold,\\nor provided by NVIDIA or its affiliates.\\n\\nThe terms \\xe2\\x80\\x9creproduce,\\xe2\\x80\\x9d \\xe2\\x80\\x9creproduction,\\xe2\\x80\\x9d \\xe2\\x80\\x9cderivative works,\\xe2\\x80\\x9d and \\xe2\\x80\\x9cdistribution\\xe2\\x80\\x9d have the meaning as provided under\\nU.S. copyright law; provided, however, that for the purposes of this License, derivative works shall not include\\nworks that remain separable from, or merely link (or bind by name) to the interfaces of, the Work.\\n\\nWorks, including the Software, are \\xe2\\x80\\x9cmade available\\xe2\\x80\\x9d under this License by including in or with the Work either\\n(a) a copyright notice referencing the applicability of this License to the Work, or (b) a copy of this License.\\n\\n2. License Grant\\n\\n2.1 Copyright Grant. Subject to the terms and conditions of this License, each Licensor grants to you a perpetual,\\nworldwide, non-exclusive, royalty-free, copyright license to reproduce, prepare derivative works of, publicly\\ndisplay, publicly perform, sublicense and distribute its Work and any resulting derivative works in any form.\\n\\n3. Limitations\\n\\n3.1 Redistribution. You may reproduce or distribute the Work only if (a) you do so under this License, (b) you\\ninclude a complete copy of this License with your distribution, and (c) you retain without modification any\\ncopyright, patent, trademark, or attribution notices that are present in the Work.\\n\\n3.2 Derivative Works. You may specify that additional or different terms apply to the use, reproduction, and\\ndistribution of your derivative works of the Work (\\xe2\\x80\\x9cYour Terms\\xe2\\x80\\x9d) only if (a) Your Terms provide that the use\\nlimitation in Section 3.3 applies to your derivative works, and (b) you identify the specific derivative works\\nthat are subject to Your Terms. Notwithstanding Your Terms, this License (including the redistribution\\nrequirements in Section 3.1) will continue to apply to the Work itself.\\n\\n3.3 Use Limitation. The Work and any derivative works thereof only may be used or intended for use non-commercially\\nand with NVIDIA Processors. Notwithstanding the foregoing, NVIDIA and its affiliates may use the Work and any\\nderivative works commercially. As used herein, \\xe2\\x80\\x9cnon-commercially\\xe2\\x80\\x9d means for research or evaluation purposes only.\\n\\n3.4 Patent Claims. If you bring or threaten to bring a patent claim against any Licensor (including any claim,\\ncross-claim or counterclaim in a lawsuit) to enforce any patents that you allege are infringed by any Work, then\\nyour rights under this License from such Licensor (including the grant in Section 2.1) will terminate immediately.\\n\\n3.5 Trademarks. This License does not grant any rights to use any Licensor\\xe2\\x80\\x99s or its affiliates\\xe2\\x80\\x99 names, logos, or\\ntrademarks, except as necessary to reproduce the notices described in this License.\\n\\n3.6 Termination. If you violate any term of this License, then your rights under this License (including the grant\\nin Section 2.1) will terminate immediately.\\n\\n4. Disclaimer of Warranty.\\n\\nTHE WORK IS PROVIDED \\xe2\\x80\\x9cAS IS\\xe2\\x80\\x9d WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING\\nWARRANTIES OR CONDITIONS OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE OR NON-INFRINGEMENT. YOU\\nBEAR THE RISK OF UNDERTAKING ANY ACTIVITIES UNDER THIS LICENSE.\\n\\n5. Limitation of Liability.\\n\\nEXCEPT AS PROHIBITED BY APPLICABLE LAW, IN NO EVENT AND UNDER NO LEGAL THEORY, WHETHER IN TORT (INCLUDING NEGLIGENCE),\\nCONTRACT, OR OTHERWISE SHALL ANY LICENSOR BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY DIRECT, INDIRECT, SPECIAL,\\nINCIDENTAL, OR CONSEQUENTIAL DAMAGES ARISING OUT OF OR RELATED TO THIS LICENSE, THE USE OR INABILITY TO USE THE\\nWORK (INCLUDING BUT NOT LIMITED TO LOSS OF GOODWILL, BUSINESS INTERRUPTION, LOST PROFITS OR DATA, COMPUTER FAILURE\\nOR MALFUNCTION, OR ANY OTHER COMM ERCIAL DAMAGES OR LOSSES), EVEN IF THE LICENSOR HAS BEEN ADVISED OF THE POSSIBILITY\\nOF SUCH DAMAGES.\\n\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Official PyTorch implementation of \"VAEBM: A Symbiosis between Variational Autoencoders and Energy-based Models\" [(ICLR 2021 Spotlight Paper)](https://arxiv.org/abs/2010.00654) #",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "VAEBM",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "NVlabs",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/NVlabs/VAEBM/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 11,
      "date": "Wed, 29 Dec 2021 20:15:28 GMT"
    },
    "technique": "GitHub API"
  }
}
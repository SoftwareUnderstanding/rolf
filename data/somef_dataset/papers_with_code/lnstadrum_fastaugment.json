{
  "citation": [
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "Color inversion \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    lambda x, y: augment(x, y, translation=0.1, rotation=30, mixup=0.5) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "    Augment(training_only=True, translation=0.1, rotation=30, mixup=0.5), \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lnstadrum/fastaugment",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-02-10T19:32:57Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-05T09:14:27Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8925377188474961,
        0.8428805119548838,
        0.9524411109086519
      ],
      "excerpt": "A handy data augmentation toolkit for image classification put in a single efficient TensorFlow op. \nCommon image preprocessing and data augmentation scripts involve plenty processing blocks run on CPU. Depending on the hardware and number of users sharing the CPU resource, these blocks can turn the CPU load and RAM bandwidth into a bottleneck and cause GPU being underutilized. \nThis repository offers an easy-to-use replacement of some common augmentation techniques used when training image classification models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9711416341225124,
        0.9634331916641973
      ],
      "excerpt": "Every image in the output batch is sampled only once; all the augmentation transformations are applied in a single pass. \nProcessing a batch of 128 images of 224224 pixels with all features enabled takes less than 1 millisecond* on Tesla T4 GPU. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9898716091506354,
        0.898764016094967
      ],
      "excerpt": "Accurate modelling of small 3D viewpoint changes with common in-plane transformations and perspective distortions for better generalization \nPlug and play, easy to deploy \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9368806962770742
      ],
      "excerpt": "Designed to replace a big chunk of a typical data augmentation pipeline with a single call.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9523649901244978,
        0.9629275396937426
      ],
      "excerpt": "Can be used as a mapping in tf.data.Dataset processing pipeline, or as a part of a Keras model, or in any other situation as a TensorFlow operation. \nFastAugment merges some common data augmentation techniques into a single compute block. The transformations parameters are randomly sampled per image from user-defined ranges. The list of implemented transformations follows. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9363880864474491
      ],
      "excerpt": "Perspective distortions (out-of-plane rotation) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8561788633423203
      ],
      "excerpt": "For TensorFlow only (so far) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8732160271178248
      ],
      "excerpt": "Input batch datatype is restricted to uint8 for performance reasons \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "model = tf.keras.Sequential([ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661971201521145
      ],
      "excerpt": "Every image is sampled only once through a bilinear interpolator. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8781476356519389
      ],
      "excerpt": "  - in-plane image rotation and scaling, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "  - hue, saturation and brightness correction, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8478802683293593
      ],
      "excerpt": "| prescale         | A constant scaling factor applied to all images. Can be used to shift the random scaling distribution from its default average equal to 1 and crop out image borders. The default value is 1. | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8477991037989556
      ],
      "excerpt": "|                    | The image plane is rotated in 3D around X and Y axes (tilt and pan respectively) by random angles smaller than the given value(s). If one number is given, the same range applies for both axes. The default value is 15 degrees. | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9011149304332545
      ],
      "excerpt": "| hue              | Hue shift range in degrees. The image pixels color hues are shifted by a random angle smaller than hue. A hue shift of +/-120 degrees transforms green in red/blue and vice versa. The default value is 10 degrees. | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8848836221961526
      ],
      "excerpt": "| brightness       | Brightness factor range. For every input image, the intensity is scaled by a random factor sampled in range [1 - brightness, 1 + brightness]. The default value is 0.1 | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9366127660522975,
        0.8832582540899125,
        0.9740577633092029,
        0.9591792636498121,
        0.9605184684594738,
        0.83843411137768,
        0.8833851197154041
      ],
      "excerpt": "|                    | Gamma correction boosts (for factors below 1) or reduces (for factors above 1) dark image areas intensity, while bright areas are less affected. The default value is 0.2. | \n| color_inversion  | A boolean. If True, colors of all pixels in every image are inverted (negated) with 50% chance. Default: False. | \n| cutout           | Probability of CutOut being applied to a given input image. The default value is 0.5. CutOut erases a randomly placed rectangular area of an image. See the original paper for more details: https://arxiv.org/pdf/1708.04552.pdf | \n| cutout_size      | A list specifying the normalized size range CutOut area width and height are sampled from.  [0.3, 0.5] range produces a rectangle of 30% to 50% of image size on every side (default). If empty list is passed, CutOut application is disabled. | \n| mixup            | Probability of mixup being applied to a given input image. Mixup is disabled by default (mixup is set to zero). Mixup is applied across the batch. Every two mixed images undergo the same set of other transformations except flipping which can be different. Requires the input labels y. If not provided, an exception is thrown. | \n| mixup_alpha      | Mixup alpha parameter (default: 0.4). See the original paper for more details: https://arxiv.org/pdf/1710.09412.pdf | \n| seed             | Random seed. If different from 0, reproduces the same sequence of transformations for a given set of parameters and input size. | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9460230077624555
      ],
      "excerpt": "Returns a Tensor with a set of transformations applied to the input image or batch, and another Tensor containing the image labels in one-hot format. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8099971970943021
      ],
      "excerpt": "Perspective distortions (tilting and panning, up to +/-30 deg): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008775228180506
      ],
      "excerpt": "Hue shift up to +/-180 deg (unrealistic): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9068240844120881
      ],
      "excerpt": "CutOut with 40% to 50% crop side size: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A handy data augmentation toolkit for image classification put in a single efficient TensorFlow op.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lnstadrum/fastaugment/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 12:55:16 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lnstadrum/fastaugment/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "lnstadrum/fastaugment",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/lnstadrum/fastaugment/main/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Scaling up to 10%\n* In-plane rotation up to  +/-10 deg\n* Panning and tilting up to +/-15 deg\n* Translation up to 10%\n* Hue shift up to +/-15 deg\n* Gamma correction in [0.75, 1.25] range\n* Color saturation up to +/-50%\n* Brightness correction in up to +/-30%\n* CutOut for 50% of images with 40% to 50% crop side size\n* Mixup\n\n![Transformed batch](images/10_all_inclusive.jpg)\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Easily compiles from source code in few seconds, only need cmake and any standard C++ compiler. Once the code is compiled, the repository root path is to be appended to `PYTHONPATH` environment variable to enable Python to find the extension.\n\nA complete copy-paste recipe for linux (tested in ubuntu- and RHEL-based distributions):\n```bash\ngit clone https://github.com/lnstadrum/fastaugment.git\ncd fastaugment\nmkdir -p build && cd build\ncmake .. && make\ncd ..\nexport PYTHONPATH=$PYTHONPATH:$(pwd)\n```\n\nA dockerfile is also available.\n\nOnce compiled and appended to `PYTHONPATH`, FastAugment is ready for use. It is a good thing to make sure that tests are passing before going further though:\n```bash\npython3 test.py\n```\n\nYou can also run the example script to get some visuals:\n```bash\npython3 example.py\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9198207639343976
      ],
      "excerpt": "Computations are entirely run on GPU, extremely efficient \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8967264683677698
      ],
      "excerpt": "While the GPU overhead is marginal, you can keep your CPU busy with something else. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.822772914779557
      ],
      "excerpt": "Using as a tf.data.Dataset mapping: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from fast_augment import augment \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8801854956928516
      ],
      "excerpt": "from fast_augment import Augment \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8465251479594719
      ],
      "excerpt": "model = tf.keras.Sequential([ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8122340635367076,
        0.8061611893606251
      ],
      "excerpt": "| y                | A Tensor of float32 type containing input labels in one-hot format. Its outermost dimension is expected to match the batch size. Optional, can be empty. | \n| output_size      | A list [W, H] specifying the output batch width and height in pixels. If none, the input size is kept (default). | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8285596668464124,
        0.8126717236467306
      ],
      "excerpt": "| scale            | Scaling factor range along X and Y axes. 0.1 corresponds to stretching the images by a random factor of at most 10% (default). If one value given, the applied scaling keeps the aspect ratio: the same factor is used along X and Y axes. | \n| prescale         | A constant scaling factor applied to all images. Can be used to shift the random scaling distribution from its default average equal to 1 and crop out image borders. The default value is 1. | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8568585208819578,
        0.8546009132340718
      ],
      "excerpt": "| flip_horizontally | A boolean. If True, the images are flipped horizontally with 50% chance. Default: True. | \n| flip_vertically   | A boolean. If True, the images are flipped vertically with 50% chance. Default: False. | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8098121529786312
      ],
      "excerpt": "Combined (hue shift up to +/-15 deg, gamma correction in [0.75, 1.25] range, color saturation up to +/-50%, brightness correction in up to +/-30%): \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/lnstadrum/fastaugment/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "C++",
      "Cuda",
      "CMake",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 lnstadrum\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Fast Augment",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "fastaugment",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "lnstadrum",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/lnstadrum/fastaugment/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Tue, 28 Dec 2021 12:55:16 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "augmentation-transformations",
      "data-augmentation",
      "gpu",
      "cuda",
      "mixup",
      "cutout",
      "brightness-correction",
      "gamma-correction",
      "perspective-distortions",
      "tensorflow-op"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Input batch (from [tf_flowers dataset](https://www.tensorflow.org/datasets/catalog/tf_flowers)):\n\n![Input batch](images/0_source.jpg)\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.10593"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "Natural Language Processing:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9829698642002277
      ],
      "excerpt": "Computer Vision:  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SHAHBAZSIDDIQI/DataScience",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-18T13:04:16Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-09-04T15:05:06Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9949283780666194
      ],
      "excerpt": "The repository consist of multiple projects in various domains like NLP, Computer Vision, Graph Embedding, Speech Recognition. Apart from some of my work in form of code, I have also included some of my presentation for better understanding of my work along with the results obtained and my review on the algorithms.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9671825090749661
      ],
      "excerpt": "Machine Translation from English to German: Neural machine translation from English to German and again back to English from German. dataset: http://www.manythings.org/anki/deu-eng.zip \u2022 Implemented Encoder- decoder based Sequence-to-Sequence (seq2seq) model on only 20k data out of over 150,000 data due to less computational power. \u2022 For the encoder, I used an embedding layer and an LSTM layer \u2022 For the decoder, I used another LSTM layer followed by a dense layer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9611975389754005
      ],
      "excerpt": "Implementation of Pretrained models: Implementation of pre trained models like BERT, SCIBERT, CLINICAL BERT, XLNET to generate embedding and extract information from twitter data, using text extraction method powered by pretrained models.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.855121853878168
      ],
      "excerpt": "Creating dynamic Recommedation system to solve cold start problem using Joint Emedding and dual RNN. This algorithm leverage the user product interaction to simultaneously update both the product as well as user embedding.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9814410434488258
      ],
      "excerpt": "The details is incorporated in the pdf attached.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.947651550009482
      ],
      "excerpt": "Mnsit_CNN.ipynb : Dataset: http://yann.lecun.com/exdb/mnist/ The MNIST problem is a dataset developed by Yann LeCun, Corinna Cortes and Christopher Burges for evaluating machine learning models on the handwritten digit classification problem. The dataset was constructed from a number of scanned document dataset available from the National Institute of Standards and Technology (NIST). This is where the name for the dataset comes from, as the Modified NIST or MNIST dataset. Each image is a 28 by 28 pixel square (784 pixels total). A standard split of the dataset is used to evaluate and compare models, where 60,000 images are used to train a model and a separate set of 10,000 images are used to test it. It is a digit recognition task. As such there are 10 digits (0 to 9) or 10 classes to predict. Results are reported using prediction error. Convolutional Neural Networks has been used in the model to obtain prediction error of less than 1%. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8401631469305619,
        0.8787214403189879
      ],
      "excerpt": "GAN(Generative Adversarial networks) Project \nMonet2photo_cyclegan.ipynb : Dataset: https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/monet2photo.zip Studied the construct and the underlying architecture of simple GAN and CycleGAN. Implemented CycleGAN model for Painting style neural transfer using \u2018monet2photo\u2019 dataset which generated images of photos from images of Monet paintings, and vice-versa in absence of one-to-one correspondence between input and output images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Data Science, Deep Learning, Machine Learning Projects",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SHAHBAZSIDDIQI/DataScience/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 00:21:40 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/SHAHBAZSIDDIQI/DataScience/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "SHAHBAZSIDDIQI/DataScience",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Recommendation%20System/UserDoc%20and%20PosDoc%20Method%20on%20basic%20public%20dataset.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Recommendation%20System/Generation%20of%20multi%20purpose%20dynamic%20Embedding%20using%20twitter%20data%20set%20.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Recommendation%20System/Updation%20of%20Embedding%20.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Computer%20Vision/Implementation_of_Cyclic_gan_for_unpaired_data_set.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Computer%20Vision/Gan_implementation_on_simple_MNIST_dataset.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Natural%20Language%20Processing/Implementation%20of%20BiDAF%20model%20on%20SQUAD1%20data%20set.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Natural%20Language%20Processing/EDA%20on%20SQUAD1%20dataset.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Natural%20Language%20Processing/NLP%20using%20Pretrained%20Model/Generation%20of%20Embedding%20and%20its%20evaluation%20using%20pretrained%20Models.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Natural%20Language%20Processing/NLP%20using%20Pretrained%20Model/Generation%20of%20Embedding%20using%20BERT%20modelS%20Colab.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Natural%20Language%20Processing/NLP%20using%20Pretrained%20Model/Evaluation%20of%20Bert%20.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Natural%20Language%20Processing/NLP%20using%20Pretrained%20Model/Modifying%20Gensim%20models%20for%20User%20Doc%20and%20Post%20Doc%20Basic%20Implementation.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Natural%20Language%20Processing/Neural%20Machine%20Translator%20Eng%20to%20Ger/Neural%20Machine%20Translator%20Eng%20to%20Ger.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Speech/Speech_denoising.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Knowledge%20Graph%20and%20Embedding/User%20Graph%20Embedding%20from%20Network.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Knowledge%20Graph%20and%20Embedding/Node2Vec.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Knowledge%20Graph%20and%20Embedding/Link%20prediction.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Knowledge%20Graph%20and%20Embedding/Embedding%20Updation%20using%20Knowledge%20Graph.ipynb",
      "https://raw.githubusercontent.com/SHAHBAZSIDDIQI/DataScience/master/Knowledge%20Graph%20and%20Embedding/Edge%20Classification.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/SHAHBAZSIDDIQI/DataScience/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "DataScience",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DataScience",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "SHAHBAZSIDDIQI",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/SHAHBAZSIDDIQI/DataScience/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 00:21:40 GMT"
    },
    "technique": "GitHub API"
  }
}
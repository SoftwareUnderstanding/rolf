{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2009.10337",
      "https://arxiv.org/abs/1707.06347",
      "https://arxiv.org/abs/1801.01290",
      "https://arxiv.org/abs/1707.06347",
      "https://arxiv.org/abs/1801.01290"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/donamin/llc",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-03-16T08:29:42Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-02T19:44:45Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9688265835618904,
        0.9994174105834547
      ],
      "excerpt": "This repository contains the source code for the algorithm, described in this paper. \nWe propose a novel method for exploring the dynamics of physically based animated characters, and learning a task-agnostic action space that makes movement optimization easier. Like several previous papers, we parameterize actions as target states, and learn a short-horizon goal-conditioned low-level control policy that drives the agent's state towards the targets. Our novel contribution is that with our exploration data, we are able to learn the low-level policy in a generic manner and without any reference movement data. Trained once for each agent or simulation environment, the policy improves the efficiency of optimizing both trajectories and high-level policies across multiple tasks and optimization algorithms. We also contribute novel visualizations that show how using target states as actions makes optimized trajectories more robust to disturbances; this manifests as wider optima that are easy to find. Due to its simplicity and generality, our proposed approach should provide a building block that can improve a large variety of movement optimization methods and applications. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8717160655494669
      ],
      "excerpt": "ContactExplorer.py  The script for generating the exploration data using the proposed contact-based exploration algorithm \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8393942932750694
      ],
      "excerpt": "online_trajectory_optimization.py   The script for online trajectory optimization using a simplified version of Fixed-Depth Informed MCTS (FDI-MCTS) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8770164783476149
      ],
      "excerpt": "ExplorationData The folder containing the exploration data generated using naive and contact-based exploration methods. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/donamin/llc/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 12:24:33 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/donamin/llc/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "donamin/llc",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.8628495805348179
      ],
      "excerpt": "produce_llcs.py The script for training the LLCs using the exploration data \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/donamin/llc/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Learning Task-Agnostic Action Spaces for Movement Optimization",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "llc",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "donamin",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/donamin/llc/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Python 3.5 or above\n- cma\n- glfw\n- gym\n- Keras\n- mujoco-py\n- numpy\n- opencv-python\n- pandas\n- Pillow\n- stable-baselines\n- tensorflow\n\nMore detailed requirements are specified in ```requirements.txt```.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 12:24:33 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1810.04250",
      "https://arxiv.org/abs/1512.00567",
      "https://arxiv.org/abs/1602.07261",
      "https://arxiv.org/abs/1703.06870",
      "https://arxiv.org/abs/ prePrint Version: **[Bird Species Classification with Transfer Learning using Multistage Training](https://arxiv.org/abs/1810.04250)**\n## References\n[1] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna, \"[\nRethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567)\" arXiv preprint https://arxiv.org/abs/1512.00567. <br />\n[2] Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi, \"[Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/abs/1602.07261)\" arXiv preprint https://arxiv.org/abs/1602.07261. <br />\n[3] Kaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, Ross Girshick, \"[Mask R-CNN](https://arxiv.org/abs/1703.06870)\" arXiv preprint https://arxiv.org/abs/1703.06870. <br />\n[4] Mask R-CNN Github repo. \"[Link](https://github.com/matterport/Mask_RCNN)\" <br />",
      "https://arxiv.org/abs/1512.00567. <br />\n[2] Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi, \"[Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/abs/1602.07261)\" arXiv preprint https://arxiv.org/abs/1602.07261. <br />\n[3] Kaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, Ross Girshick, \"[Mask R-CNN](https://arxiv.org/abs/1703.06870)\" arXiv preprint https://arxiv.org/abs/1703.06870. <br />\n[4] Mask R-CNN Github repo. \"[Link](https://github.com/matterport/Mask_RCNN)\" <br />",
      "https://arxiv.org/abs/1602.07261. <br />\n[3] Kaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, Ross Girshick, \"[Mask R-CNN](https://arxiv.org/abs/1703.06870)\" arXiv preprint https://arxiv.org/abs/1703.06870. <br />\n[4] Mask R-CNN Github repo. \"[Link](https://github.com/matterport/Mask_RCNN)\" <br />",
      "https://arxiv.org/abs/1703.06870. <br />\n[4] Mask R-CNN Github repo. \"[Link](https://github.com/matterport/Mask_RCNN)\" <br />"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, Zbigniew Wojna, \"[\nRethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567)\" arXiv preprint arXiv:1512.00567. <br />\n[2] Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi, \"[Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/abs/1602.07261)\" arXiv preprint arXiv:1602.07261. <br />\n[3] Kaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, Ross Girshick, \"[Mask R-CNN](https://arxiv.org/abs/1703.06870)\" arXiv preprint arXiv:1703.06870. <br />\n[4] Mask R-CNN Github repo. \"[Link](https://github.com/matterport/Mask_RCNN)\" <br />\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use this repository, please use this bibtex to cite the paper:\n ```\n@InProceedings{10.1007/978-981-15-1387-9_3,\nauthor=\"Kumar, Akash\nand Das, Sourya Dipta\",\neditor=\"Arora, Chetan\nand Mitra, Kaushik\",\ntitle=\"Bird Species Classification Using Transfer Learning with Multistage Training\",\nbooktitle=\"Computer Vision Applications\",\nyear=\"2019\",\npublisher=\"Springer Singapore\",\naddress=\"Singapore\",\npages=\"28--38\",\nisbn=\"978-981-15-1387-9\"\n} \n```\n\nSome important sub-parts are discussed below:\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@InProceedings{10.1007/978-981-15-1387-9_3,\nauthor=\"Kumar, Akash\nand Das, Sourya Dipta\",\neditor=\"Arora, Chetan\nand Mitra, Kaushik\",\ntitle=\"Bird Species Classification Using Transfer Learning with Multistage Training\",\nbooktitle=\"Computer Vision Applications\",\nyear=\"2019\",\npublisher=\"Springer Singapore\",\naddress=\"Singapore\",\npages=\"28--38\",\nisbn=\"978-981-15-1387-9\"\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9987238287923713
      ],
      "excerpt": "Paper accepted at 11th ICVGIP'18 Conference, WCVA Workshop :grimacing: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9011209436043097
      ],
      "excerpt": "The code is documented and designed to be easy to extend. If you use it in your research, please consider citing this repository (bibtex below). \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AKASH2907/bird_species_classification",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-07-13T09:41:21Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-16T18:10:45Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9845349038544389,
        0.9328830280660902,
        0.924872922501105,
        0.8979411005071259,
        0.9151901877738845
      ],
      "excerpt": "This is an implementation of bird species classification challenge hosted by IIT Mandi in ICCVIP Conference'18 on Python 3 and Keras with Tensorflow backend. The architecture consists of Mask R-CNN and ImageNet models end-to-end. ImageNet models used are Inception V3 and Inception ResNet V2. \nThe repository includes: \n* Generate training data for the model \n* Data Augmentation practices \n* Generate bird crops using Mask R-CNN  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9665357160335839
      ],
      "excerpt": "* Mask R-CNN and ImageNet Model combined end-to-end for testing purpose \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9342265801974285,
        0.9404577931649684,
        0.9465786545160301,
        0.8163616906329899,
        0.9904020975096731,
        0.8542704222499649,
        0.9358941316407496,
        0.8479321220870268,
        0.840014634630472,
        0.8645462228983853,
        0.9777297016788934
      ],
      "excerpt": "To help running the model, end to end a docx has been added in case much information about each funcation and thier parameters are required. Here are the steps in summary: \nFrom the original training data, firstly several data augmentation were taken careof as the dataset contains only 150 images. The number of images were increased to around 1330. The huge number of parameters were unable to learn and generalize in case of validaion data. This also helps in decreasing the effect of class imbalance. Some classes have 6 images whereas some have around 20 images. \nAfter the data augmentation, validation dataset is created. 10% of each bird species were taken into validation data for model performance testing. \nThe model were trained on various Imagenet models such as AlexNet, VGG-16/19, ResNet50, Inception V3 and Inception ResNet V2 with pretrained Imagenet weights. Inception ResNet V2 outperforms them all. \nMulti-stage training comes after that. Used Mask R-CNN to localize birds in the images in their original resolution. Single Shot Detector and YOLO were also used but they needs to be resized images into 416x416 or 512x512 due to which many information is lost. Mask R-CNN code and modules are well explained in this github repo. As Mask R-CNN is trained on COCO dataset, and COCO has a class of bird specie, it helped me to crop birds in most of the cases. \nAfter getting the crops, data augmentation on the cropped images were done and dataset was increased to around 1600 images. Performed multi-stage training with both the dataset of cropped images as well as original images. It helps to improve the accuracy by around 10% in case of Inception V3 model and 2% in Inception ResNet V2. \nCreated an architecture end-to-end of Mask R-CNN and Trained Inception models for testing purposes. All the testing images were first passed through Mask R-CNN. After that, it splits into two cases: \nIf the Mask R-CNN is successful to detect bird, which it mostly did, the birdsare cropped from the original and then passed through trained Imagenet models for classification trained on crops and whole images. \nIf the Mask R-CNN fails, then the whole image is classified using pre-trained weights of Imagenet models trained only on original images. \nIt helped to improve the accuracy by 2% from 49 to 51. \nAfter applying Mask R-CNN for both, using confusion matrix Inception V3 performs better in some classes than Inception ResNet V2. Using ensembling, by taking the prediction vector ofboth the models compared them and then finally assign the class to the image whosoever has the highest prediction for certain species. This helped to improve the accuracy by almost 5% from 51 to around 56%. Tables are dicussed below. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8856670139408146,
        0.9688693279861225
      ],
      "excerpt": "Data Augmentation has been done using imgaug.Table for data Augmentation done for different species is shared in data_augmentation folder. \nMask R-CNN on the whole image helped to localize birds in the image. Below are the examples of the birds detection from a high resolution image. As the Mask R-CNN is trained on COCO dataset and it has bird class, it carves out bird ROIs very perfectly. More than 140 images were able to give successfull cropped bird images out of 150 images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.948135302454651,
        0.952421546006653
      ],
      "excerpt": "1) The training dataset mostly contains bird images in which bird were almost 10-20% of the whole image whereas in case of test images the bird contains 70-80% of the image. Sometimes, the model fails to detect the birds due to less number of birds in the dataset. \n2) In some classes the birds cover not even 10% of the whole images or the colour of bird and surrounding are ver similar. Cases where birds are brown in colour. In those cases, model fails to localize birds due to occlusion problem or background similarity problems. Some cases as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8623611316493919,
        0.9746106422474792
      ],
      "excerpt": "I have removed the weights file as it was hosted on my personal server. Plus, there are better imagenet models that have been published which will easily outperform Inception V3 and Inception ResNetV2. \nThe architecture of the model is as below: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8436553427284509,
        0.8669878184560825,
        0.866244773296602
      ],
      "excerpt": "Mask R-CNN + Inception V3  |  48.61 | 45.65|47.09  \nMask R-CNN + Inception ResNet V2|  53.62| 48.72|51.05 \nMask R-CNN + Ensemble   |  56.58 |54.8  |55.67 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9744482652084075
      ],
      "excerpt": "The dataset is uploaded on Kaggle and the link is shared as follow: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9750474650564712
      ],
      "excerpt": "Description of all the codes have been shared in this PDF \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Supervised Classification of bird species :bird: in high resolution images, especially for, Himalayan birds, having diverse species with fairly low amount of labelled data",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://imgaug.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AKASH2907/bird_species_classification/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 24,
      "date": "Sat, 25 Dec 2021 15:52:43 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/AKASH2907/bird_species_classification/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "AKASH2907/bird_species_classification",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.871696128736164
      ],
      "excerpt": "* Generate training data for the model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8296667506470119
      ],
      "excerpt": "After the data augmentation, validation dataset is created. 10% of each bird species were taken into validation data for model performance testing. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.883796613800943
      ],
      "excerpt": "Model Architecture| Data Subset | Train | Validation | Test \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/AKASH2907/bird_species_classification/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2011-2019 Max Bane\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "bird-species-classification",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "bird_species_classification",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "AKASH2907",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/AKASH2907/bird_species_classification/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 58,
      "date": "Sat, 25 Dec 2021 15:52:43 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "cnn",
      "keras",
      "inception-resnet-v2",
      "inceptionv3",
      "mask-rcnn",
      "bird-species-classification",
      "image-classification",
      "ensemble-learning",
      "data-augmentation",
      "multi-stage-training",
      "imagenet-models",
      "rcnn-crops"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Install the required dependencies:\n ```javascript\n pip install -r requirements.txt\n ```\n * [modify_data.py](https://github.com/AKASH2907/bird-species-classification/blob/master/modify_data.py) - This code is used to rename the files. <br /> For example: 10 - Type of Data Augmentation 01- Class of Bird 01 - Image Number - 100101.jpg (Image Name)\n * [data_augmentation.py](https://github.com/AKASH2907/bird-species-classification/blob/master/data_augmentation/data_augmentation.py) - Various types of data augmentation used to counter the challenge of large scale variation in illumination,scale, etc. and class imbalance.\n * [create_validation.py](https://github.com/AKASH2907/bird-species-classification/blob/master/create_validation.py) - Used to create Validation data randomly from the augmented training data.\n* [gen_train_data_test_data.py](https://github.com/AKASH2907/bird-species-classification/blob/master/gen_train_data_test_data.py) - Generates X_train, Y_train, X_validation, Y_validation, X_test, Y_test\n* [inception_v3_finetune.py](https://github.com/AKASH2907/bird-species-classification/blob/master/inception_v3_finetune.py) - Multi-stage Training on Mask R-CNN crops generated and then on data augmented original images.\n* [inception_resnet_v2_finetune.py](https://github.com/AKASH2907/bird-species-classification/blob/master/inception_resnet_v2_finetune.py) - Multi-stage Training on Mask R-CNN crops generated and then on data augmented original images resized to 416x416.\n* [mask_rcnn/rcnn_crops.py](https://github.com/AKASH2907/bird-species-classification/blob/master/mask_rcnn/rcnn_crops.py) - Localizes bird in the images, crops and then save them for multi-stage learning.\n* [mask_rcnn/test_images.py](https://github.com/AKASH2907/bird-species-classification/blob/master/mask_rcnn/test_images.py) - \nEnd-to-end model of classifying bird specie using Mask R-CNN and **ensembling** of Inception V3 and Inception ResNet V2.\n* [evaluate.py](https://github.com/AKASH2907/bird-species-classification/blob/master/evaluate.py) - Calculation of class-averaged precision, recall and F1-scores.\n\n",
      "technique": "Header extraction"
    }
  ]
}
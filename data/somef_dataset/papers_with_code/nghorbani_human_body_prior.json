{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1312.6114"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please cite the following paper if you use this code directly or indirectly in your research/projects:\n```\n@inproceedings{SMPL-X:2019,\n  title = {Expressive Body Capture: 3D Hands, Face, and Body from a Single Image},\n  author = {Pavlakos, Georgios and Choutas, Vasileios and Ghorbani, Nima and Bolkart, Timo and Osman, Ahmed A. A. and Tzionas, Dimitrios and Black, Michael J.},\n  booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},\n  year = {2019}\n}\n```\nAlso note that if you consider training your own VPoser for your research using the AMASS dataset, \nthen please follow its respective citation guideline.\n \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{SMPL-X:2019,\n  title = {Expressive Body Capture: 3D Hands, Face, and Body from a Single Image},\n  author = {Pavlakos, Georgios and Choutas, Vasileios and Ghorbani, Nima and Bolkart, Timo and Osman, Ahmed A. A. and Tzionas, Dimitrios and Black, Michael J.},\n  booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},\n  year = {2019}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nghorbani/human_body_prior",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The code in this repository is developed by [Nima Ghorbani](https://nghorbani.github.io/) \nwhile at [Perceiving Systems](https://ps.is.mpg.de/), Max-Planck Institute for Intelligent Systems, T\u00fcbingen, Germany.\n\nIf you have any questions you can contact us at [smplx@tuebingen.mpg.de](mailto:smplx@tuebingen.mpg.de).\n\nFor commercial licensing, contact [ps-licensing@tue.mpg.de](mailto:ps-licensing@tue.mpg.de)\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-09T08:58:22Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-22T02:42:57Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The articulated 3D pose of the human body is high-dimensional and complex. \nMany applications make use of a prior distribution over valid human poses, but modeling this distribution is difficult.\nHere we present VPoser, a learning based variational human pose prior trained from a large dataset of human poses represented as SMPL bodies.\nThis body prior can be used as an Inverse Kinematics (IK) solver for many tasks such as fitting a body model to images \nas the main contribution of this repository for [SMPLify-X](https://smpl-x.is.tue.mpg.de/). \nVPoser has the following features: \n - defines a prior of SMPL pose parameters\n - is end-to-end differentiable\n - provides a way to penalize impossible poses while admitting valid ones\n - effectively models correlations among the joints of the body\n - introduces an efficient, low-dimensional, representation for human pose\n - can be used to generate valid 3D human poses for data-dependent tasks\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9574206142204393
      ],
      "excerpt": "The keypoints could either be 3D (joint locations, 3D mocap markers on body surface) or 2D (as in SMPLify-X). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9754475219704559,
        0.9394449182630016
      ],
      "excerpt": "- IK for 3D joints  \n- IK for mocap markers  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9191010375677886,
        0.9318827668071368
      ],
      "excerpt": "and fit body model parameters to them while utilizing the efficient learned pose parameterization of  \nVPoser. The supported features are: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.961662113837624
      ],
      "excerpt": "that learns a latent representation of human pose and regularizes the distribution of the latent code  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "VPoser: Variational Human Pose Prior",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nghorbani/human_body_prior/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 89,
      "date": "Thu, 23 Dec 2021 01:49:56 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/nghorbani/human_body_prior/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "nghorbani/human_body_prior",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/nghorbani/human_body_prior/master/tutorials/vposer.ipynb",
      "https://raw.githubusercontent.com/nghorbani/human_body_prior/master/tutorials/vposer_sampling.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "**Requirements**\n- Python 3.7\n- [PyTorch 1.7.1](https://pytorch.org/get-started)\n\n[comment]: <> (- [Torchgeometry 0.1.2]&#40;https://pypi.org/project/torchgeometry/0.1.2/&#41;)\n\n[comment]: <> (- [Body Visualizer]&#40;https://github.com/nghorbani/body_visualizer&#41; for visualizations)\n  \n\nClone this repo and run the following from the root folder:\n```bash\npython install -r requirements.txt\npython setup.py develop\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8589534893990137
      ],
      "excerpt": "Train VPoser \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/nghorbani/human_body_prior/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/nghorbani/human_body_prior/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'License\\n\\nSoftware Copyright License for non-commercial scientific research purposes\\nPlease read carefully the following terms and conditions and any accompanying documentation before you download and/or\\n use the SMPL-X/SMPLify-X model, data and software, (the \"Model & Software\"), including 3D meshes, blend weights,\\n blend shapes, textures, software, scripts, and animations. By downloading and/or using the Model & Software\\n (including downloading, cloning, installing, and any other use of this github repository), you acknowledge that you\\n have read these terms and conditions, understand them, and agree to be bound by them. If you do not agree with these\\n terms and conditions, you must not download and/or use the Model & Software. Any infringement of the terms of this\\n agreement will automatically terminate your rights under this License\\n\\nOwnership / Licensees\\nThe Software and the associated materials has been developed at the\\n\\nMax Planck Institute for Intelligent Systems (hereinafter \"MPI\").\\n\\nAny copyright or patent right is owned by and proprietary material of the\\n\\nMax-Planck-Gesellschaft zur F\\xc3\\xb6rderung der Wissenschaften e.V. (hereinafter \\xe2\\x80\\x9cMPG\\xe2\\x80\\x9d; MPI and MPG hereinafter collectively \\xe2\\x80\\x9cMax-Planck\\xe2\\x80\\x9d)\\n\\nhereinafter the \\xe2\\x80\\x9cLicensor\\xe2\\x80\\x9d.\\n\\nLicense Grant\\nLicensor grants you (Licensee) personally a single-user, non-exclusive, non-transferable, free of charge right:\\n\\nTo install the Model & Software on computers owned, leased or otherwise controlled by you and/or your organization;\\nTo use the Model & Software for the sole purpose of performing non-commercial scientific research, non-commercial\\neducation, or non-commercial artistic projects;\\nAny other use, in particular any use for commercial purposes, is prohibited. This includes, without limitation,\\nincorporation in a commercial product, use in a commercial service, or production of other artifacts for commercial\\npurposes. The Model & Software may not be reproduced, modified and/or made available in any form to any third party\\nwithout Max-Planck\\xe2\\x80\\x99s prior written permission.\\n\\nThe Model & Software may not be used for pornographic purposes or to generate pornographic material whether commercial\\nor not. This license also prohibits the use of the Model & Software to train methods/algorithms/neural networks/etc.\\nfor commercial use of any kind. By downloading the Model & Software, you agree not to reverse engineer it.\\n\\nNo Distribution\\nThe Model & Software and the license herein granted shall not be copied, shared, distributed, re-sold, offered for\\nre-sale, transferred or sub-licensed in whole or in part except that you may make one copy for archive purposes only.\\n\\nDisclaimer of Representations and Warranties\\nYou expressly acknowledge and agree that the Model & Software results from basic research, is provided \\xe2\\x80\\x9cAS IS\\xe2\\x80\\x9d,\\n may contain errors, and that any use of the Model & Software is at your sole risk. LICENSOR MAKES NO REPRESENTATIONS\\n OR WARRANTIES OF ANY KIND CONCERNING THE MODEL & SOFTWARE, NEITHER EXPRESS NOR IMPLIED, AND THE ABSENCE OF ANY LEGAL\\n OR ACTUAL DEFECTS, WHETHER DISCOVERABLE OR NOT. Specifically, and not to limit the foregoing, licensor makes no\\n representations or warranties (i) regarding the merchantability or fitness for a particular purpose of the Model & Software,\\n (ii) that the use of the Model & Software will not infringe any patents, copyrights or other intellectual property rights\\n  of a third party, and (iii) that the use of the Model & Software will not cause any damage of any kind to you or a third party.\\n\\nLimitation of Liability\\nBecause this Model & Software License Agreement qualifies as a donation, according to Section 521 of the German Civil Code\\n(B\\xc3\\xbcrgerliches Gesetzbuch \\xe2\\x80\\x93 BGB) Licensor as a donor is liable for intent and gross negligence only. If the Licensor\\nfraudulently conceals a legal or material defect, they are obliged to compensate the Licensee for the resulting damage.\\nLicensor shall be liable for loss of data only up to the amount of typical recovery costs which would have arisen had\\nproper and regular data backup measures been taken. For the avoidance of doubt Licensor shall be liable in accordance\\nwith the German Product Liability Act in the event of product liability. The foregoing applies also to Licensor\\xe2\\x80\\x99s legal\\nrepresentatives or assistants in performance. Any further liability shall be excluded.\\nPatent claims generated through the usage of the Model & Software cannot be directed towards the copyright holders.\\nThe Model & Software is provided in the state of development the licensor defines. If modified or extended by Licensee,\\nthe Licensor makes no claims about the fitness of the Model & Software and is not responsible for any problems such modifications cause.\\n\\nNo Maintenance Services\\nYou understand and agree that Licensor is under no obligation to provide either maintenance services, update services,\\nnotices of latent defects, or corrections of defects with regard to the Model & Software. Licensor nevertheless reserves\\n the right to update, modify, or discontinue the Model & Software at any time.\\n\\nDefects of the Model & Software must be notified in writing to the Licensor with a comprehensible description of the\\nerror symptoms. The notification of the defect should enable the reproduction of the error. The Licensee is encouraged\\nto communicate any use, results, modification or publication.\\n\\nPublications using the Model & Software\\nYou acknowledge that the Model & Software is a valuable scientific resource and agree to appropriately reference the\\n following papers in any publication making use of the Model & Software.\\n\\nCitation:\\n\\n@inproceedings{SMPL-X:2019,\\n  title = {Expressive Body Capture: 3D Hands, Face, and Body from a Single Image},\\n  author = {Pavlakos, Georgios and Choutas, Vasileios and Ghorbani, Nima and Bolkart, Timo and Osman, Ahmed A. A.\\n  and Tzionas, Dimitrios and Black, Michael J.},\\n  booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},\\n  year = {2019}\\n}\\n\\nCommercial licensing opportunities\\nFor commercial uses of the Software, please send email to ps-license@tue.mpg.de\\n\\nThis Agreement shall be governed by the laws of the Federal Republic of Germany except for the UN Sales Convention.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "VPoser: Variational Human Pose Prior for Body Inverse Kinematics",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "human_body_prior",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "nghorbani",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/nghorbani/human_body_prior/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 369,
      "date": "Thu, 23 Dec 2021 01:49:56 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "vae",
      "prior",
      "human",
      "motion",
      "pose-estimation",
      "pose"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "![alt text](support_data/latent_interpolation_1.gif \"Interpolation of novel poses on the smoother VPoser latent space.\")\n![alt text](support_data/latent_interpolation_2.gif \"Interpolation of novel poses on the smoother VPoser latent space.\")\n\n* [VPoser Body poZ Space for SMPL Body Model Family](tutorials/vposer.ipynb)\n* [Sampling Novel Body Poses with VPoser](tutorials/vposer_sampling.ipynb)\n\n",
      "technique": "Header extraction"
    }
  ]
}
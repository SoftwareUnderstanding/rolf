{
  "citation": [
    {
      "confidence": [
        0.9999935254750115
      ],
      "excerpt": "22st International Conference on Discovery Science (DS 2019) Split, Croatia, October 28-30, 2019 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8043073075947367
      ],
      "excerpt": "    if self.verbose: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8043073075947367
      ],
      "excerpt": "    if self.verbose: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rebelosa/feature-importance-neural-networks",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-08-20T12:37:27Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-17T13:44:04Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9610922063957406,
        0.9981696180061984,
        0.9703613055981191,
        0.9181446877598136,
        0.8022813095361894
      ],
      "excerpt": "This file provides a working example of how to measure the importance of features (inputs) in neural networks.  \nThis method is a new method to measure the relative importance of features in Artificial Neural Networks (ANN) models. Its underlying principle assumes that the more important a feature is, the more the weights, connected to the respective input neuron, will change during the training of the model. To capture this behavior, a running variance of every weight connected to the input layer is measured during training. For that, an adaptation of Welford's online algorithm for computing the online variance is proposed. \nWhen the training is finished, for each input, the variances of the weights are combined with the final weights to obtain the measure of relative importance for each feature. \nThe file variance-based feature importance in artificial neural networks.ipynb includes the code to fully replicate the results obtained in the paper: \nCR de S\u00e1 Variance-based Feature Importance in Neural Networks \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Variance-based Feature Importance in Neural Networks",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rebelosa/feature-importance-neural-networks/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 6,
      "date": "Tue, 28 Dec 2021 11:25:08 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/rebelosa/feature-importance-neural-networks/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "rebelosa/feature-importance-neural-networks",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/rebelosa/feature-importance-neural-networks/master/variance-based%20feature%20importance%20in%20artificial%20neural%20networks.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8942996095545004
      ],
      "excerpt": "        print(\"VIANN version 1.0 (Wellford + Mean) update per epoch\") \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8224121324368083
      ],
      "excerpt": "    delta = np.subtract(currentWeights, self.diff) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8224121324368083
      ],
      "excerpt": "    delta2 = np.subtract(currentWeights, self.diff) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.886500258922403
      ],
      "excerpt": "    scores = np.sum(np.multiply(self.s2, np.abs(self.lastweights)), axis = 1) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9004683488168393
      ],
      "excerpt": "              np.array(self.varScores).argsort()[-10:][::-1]) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/rebelosa/feature-importance-neural-networks/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Variance-based Feature Importance in Neural Networks / Deep Learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "feature-importance-neural-networks",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "rebelosa",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/rebelosa/feature-importance-neural-networks/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 16,
      "date": "Tue, 28 Dec 2021 11:25:08 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "neural-networks",
      "feature-importance",
      "deep-learning"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```python\nVIANN = VarImpVIANN(verbose=1)\n\nmodel = Sequential()\nmodel.add(Dense(50, input_dim=input_dim, activation='relu', kernel_initializer='normal', kernel_regularizer=l2(0.01)))\nmodel.add(Dense(100, activation='relu', kernel_initializer='normal', kernel_regularizer=l2(0.01)))\nmodel.add(Dense(50, activation='relu', kernel_initializer='normal', kernel_regularizer=l2(0.01)))\nmodel.add(Dense(5, activation='softmax', kernel_initializer='normal'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n\nmodel.fit(X, Y, validation_split=0.05, epochs=30, batch_size=64, shuffle=True, \n      verbose=1, callbacks = [VIANN])\n      \nprint(VIANN.varScores)\n[0.75878453 0.2828902  0.85303473 0.6568499  0.07119488 0.20491114\n 0.3517472  0.844915   0.03618119 0.03033427 0.4099664  0.\n 0.3236221  0.21142973 0.00467986 0.02231793 0.0134031  0.03483544\n 0.02274348 0.02686052 1.         0.6406668  0.80592436 0.6484351\n 0.3022079  0.35150513 0.54522735 0.8139651  0.24560207 0.04865947]\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1512.02325"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Single Shot Multibox Detector paper: [paper](https://arxiv.org/abs/1512.02325)\n- Caffe original implementation: [code](https://github.com/weiliu89/caffe/tree/ssd)\n- Pytorch implementation: [code] (https://github.com/ChunML/ssd-pytorch)\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/aniketmaurya/ssd-tf2-tfds",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-19T11:18:23Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-26T06:36:26Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8449085097618282
      ],
      "excerpt": "---pretrained-typepretrained weight type (base: using pretrained VGG backbone, other options: see testing section) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9258695450307245
      ],
      "excerpt": "how to train SSD512 using PASCAL VOC2012 for 120 epochs on GPU 1 with batch size 8 and save weights to ./checkpoints_512: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8217255712129009
      ],
      "excerpt": "---checkpoint-pathpath to a specific checkpoint \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A super clean implementation of SSD (Single Shot MultiBox Detector) made possible by Tensorflow 2.0",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/aniketmaurya/ssd-tf2-tfds/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 09:11:56 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/aniketmaurya/ssd-tf2-tfds/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "aniketmaurya/ssd-tf2-tfds",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/aniketmaurya/ssd-tf2-tfds/master/nbs/anchor-tfds.ipynb",
      "https://raw.githubusercontent.com/aniketmaurya/ssd-tf2-tfds/master/nbs/dataset.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Install necessary dependencies:\n```\npip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8352022631448517
      ],
      "excerpt": "                [--pretrained-type PRETRAINED_TYPE] [--gpu-id GPU_ID] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8397331684428114
      ],
      "excerpt": "---checkpoint-dircheckpoint directory \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8891808154790559
      ],
      "excerpt": "---gpu-id` GPU ID \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8799713121585284
      ],
      "excerpt": "               [--checkpoint-path CHECKPOINT_PATH] [--gpu-id GPU_ID] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8397331684428114
      ],
      "excerpt": "---checkpoint-dircheckpoint directory \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8891808154790559
      ],
      "excerpt": "---gpu-id` GPU ID \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8090672219273377,
        0.800654253488494
      ],
      "excerpt": "tensorflow_datasets will automatically download the VOC dataset \nArguments for the training script: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9355986061254542,
        0.9542055572591756,
        0.806231503790735
      ],
      "excerpt": "python train.py --help \nusage: train.py [-h] [--data-dir DATA_DIR] \n                [--arch ARCH] [--batch-size BATCH_SIZE] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8679433007233487
      ],
      "excerpt": "                [--pretrained-type PRETRAINED_TYPE] [--gpu-id GPU_ID] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8210709119235331
      ],
      "excerpt": "---data-dirdataset directory where tfds will store data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8616801805815764
      ],
      "excerpt": "---num-batchesnumber of batches to train (-1: train all) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8248405999613043,
        0.8248405999613043,
        0.814288978298418,
        0.8115444964919161
      ],
      "excerpt": "---momentummomentum value for SGD \n---weight-decayweight decay value for SGD \n---num-epochsnumber of epochs to train \n---checkpoint-dircheckpoint directory \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8288053970906497,
        0.9047993899108806,
        0.8386335856118362,
        0.9002757927780801
      ],
      "excerpt": "how to train SSD300 using PASCAL VOC2007 for 100 epochs: \npython train_tfds.py --num-epochs 100 \nhow to train SSD512 using PASCAL VOC2012 for 120 epochs on GPU 1 with batch size 8 and save weights to ./checkpoints_512: \npython train_tfds.py --arch ssd512 --num-epochs 120 --batch-size 8 --checkpoint_dir ./checkpoints_512 --gpu-id 1 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9366020278571597,
        0.9547612674518868,
        0.8905749979987088,
        0.8431731151913627
      ],
      "excerpt": "python test.py --help \nusage: test.py [-h] [--data-dir DATA_DIR] \n               [--arch ARCH] [--num-examples NUM_EXAMPLES] \n               [--pretrained-type PRETRAINED_TYPE] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8229356527235756
      ],
      "excerpt": "               [--checkpoint-path CHECKPOINT_PATH] [--gpu-id GPU_ID] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8525178718351011
      ],
      "excerpt": "---data-dirdataset directory (must specify to VOCdevkit folder) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9156176972071206,
        0.8115444964919161
      ],
      "excerpt": "---num-examplesnumber of examples to test (-1: test all) \n---checkpoint-dircheckpoint directory \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/aniketmaurya/ssd-tf2-tfds/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Trung Tran\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "SSD (Single Shot MultiBox Detector) - Tensorflow 2.0",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "ssd-tf2-tfds",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "aniketmaurya",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/aniketmaurya/ssd-tf2-tfds/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Tue, 28 Dec 2021 09:11:56 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "tensorflow",
      "tensorflow2",
      "object-detection",
      "tf2",
      "ssd"
    ],
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "All data used in this competition is provided by Lyft here: https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles/overview/.\n```\n@misc{rsnet2015,\n    title={Deep Residual Learning for Image Recognition},\n    author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},\n    year={2015},\n    eprint={1512.03385},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}\n@article{UNETModel,\n  author    = {Olaf Ronneberger and\n               Philipp Fischer and\n               Thomas Brox},\n  title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},\n  journal   = {CoRR},\n  volume    = {abs/1505.04597},\n  year      = {2015},\n  url       = {http://arxiv.org/abs/1505.04597},\n  archivePrefix = {arXiv},\n  eprint    = {1505.04597},\n  timestamp = {Mon, 13 Aug 2018 16:46:52 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/RonnebergerFB15},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n@misc{semseg2019,\n  author={Trusov, Roman},\n  title={pspnet-pytorch},\n  howpublished={\\url{https://github.com/Lextal/pspnet-pytorch}},\n  year={2019}\n}\n@inproceedings{zhao2017pspnet,\n  title={Pyramid Scene Parsing Network},\n  author={Zhao, Hengshuang and Shi, Jianping and Qi, Xiaojuan and Wang, Xiaogang and Jia, Jiaya},\n  booktitle={CVPR},\n  year={2017}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{zhao2017pspnet,\n  title={Pyramid Scene Parsing Network},\n  author={Zhao, Hengshuang and Shi, Jianping and Qi, Xiaojuan and Wang, Xiaogang and Jia, Jiaya},\n  booktitle={CVPR},\n  year={2017}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{semseg2019,\n  author={Trusov, Roman},\n  title={pspnet-pytorch},\n  howpublished={\\url{https://github.com/Lextal/pspnet-pytorch}},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{UNETModel,\n  author    = {Olaf Ronneberger and\n               Philipp Fischer and\n               Thomas Brox},\n  title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},\n  journal   = {CoRR},\n  volume    = {abs/1505.04597},\n  year      = {2015},\n  url       = {http://arxiv.org/abs/1505.04597},\n  archivePrefix = {arXiv},\n  eprint    = {1505.04597},\n  timestamp = {Mon, 13 Aug 2018 16:46:52 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/RonnebergerFB15},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{rsnet2015,\n    title={Deep Residual Learning for Image Recognition},\n    author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},\n    year={2015},\n    eprint={1512.03385},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9227381084111901
      ],
      "excerpt": "This project contains the source code for [Lyft 3D Object Detection for Autonomous Vehicles competition(Lyft 3D Object Detection for Autonomous Vehicles) on Kaggle. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/shih61/deep-learnging-3d-object-dectation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-26T18:46:52Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-12-02T16:34:02Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9427439584390015
      ],
      "excerpt": "This project contains the source code for [Lyft 3D Object Detection for Autonomous Vehicles competition(Lyft 3D Object Detection for Autonomous Vehicles) on Kaggle. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9198296739144354
      ],
      "excerpt": "1. UnetEnsemble15Epoch.pth - This model is used for U-Net Baseline and in the PSPNet-UNET Ensemble. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8964439355061312,
        0.9460329106047375,
        0.9963005775168172,
        0.9691784314447048,
        0.9458002967108056,
        0.8661015999765216,
        0.9885864237868757,
        0.9915008277942488
      ],
      "excerpt": "Due to GitHub upload size restrictions, we could not upload the PSPNet trained model.  We tried compression, but the file size surpassed the upload limits. \nThis file contains many utility functions for working with the provided data set of LiDAR, camera images, and semantic maps.  Additionally, this file contains the BEV data loader to load pre-trained data to feed into networks. \nThis notebook contains the code and logic for pre-processing the training data.  Since the data provided is in multiple forms: LiDAR, camera images, and semantic maps, we preprocess the data prior to training. We first transform the LiDAR point cloud from the sensor\u2019s reference frame to the car\u2019s reference frame. Next, we voxelize the LiDAR points to project them into a 3-dimensional space. Our final training image is a bird\u2019s eye view (top down) projection of the world around the car. Figure 1 shows an example of this. During training, the data loader concatenates the bird\u2019s eye image representation with the semantic map. (Note: This data processing is used by the Baseline U-Net model; we are still imple- menting preprocessing for the PSPNet model). \nThis notebook is our baseline model for the competition.  It is an implementation of the U-Net Model (Olaf, et. al. 2015). It loads the weights pre-trained by the author, and makes predictions based on validation dataset, which is split by train dataset with about 70/30 ratio. Then, the notebook generates a CSV file called baseline_val_pred.csv which fits the submission format of the competition.   \nAttribution: This notebook is borrowed from https://www.kaggle.com/meaninglesslives/lyft3d-inference-prediction-visualization, and customized to for our environment. \nThis is an efficient Adam optimizer which has a lower memory footprint, and allows us to train on the large dataset. \nThis notebook is an implementation of the Pyramid Scene Parsing Network (Zhao, et. al. 2017).  In addition, it uses the ResNET pre-trained weights to achieve use transfer learning and achieve higher predictions.  This implementatino is based on Trusov's PSPNet model implementation (Trusov). \nThis notebook is an implementation of the Ensemble of PSPNet and UNet model.  The PSPNet model uses ResNET pre-trained weights to use transfer learning. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/shih61/deep-learnging-3d-object-dectation/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 02:16:39 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/shih61/deep-learnging-3d-object-dectation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "shih61/deep-learnging-3d-object-dectation",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/shih61/deep-learnging-3d-object-dectation/master/DataProcessingLyftDatasetToKitty.ipynb",
      "https://raw.githubusercontent.com/shih61/deep-learnging-3d-object-dectation/master/BaselineUNetModel.ipynb",
      "https://raw.githubusercontent.com/shih61/deep-learnging-3d-object-dectation/master/PSPNet_ResNet_UNet_ensemble.ipynb",
      "https://raw.githubusercontent.com/shih61/deep-learnging-3d-object-dectation/master/PSPNet_ResNet.ipynb",
      "https://raw.githubusercontent.com/shih61/deep-learnging-3d-object-dectation/master/EvaluatePredictionAndGroundTruthScores.ipynb",
      "https://raw.githubusercontent.com/shih61/deep-learnging-3d-object-dectation/master/reference-model.ipynb",
      "https://raw.githubusercontent.com/shih61/deep-learnging-3d-object-dectation/master/DataPreprocessing.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/shih61/deep-learnging-3d-object-dectation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Lyft 3D Object Detection for Autonomous Vehicles",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "deep-learnging-3d-object-dectation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "shih61",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/shih61/deep-learnging-3d-object-dectation/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 02:16:39 GMT"
    },
    "technique": "GitHub API"
  }
}
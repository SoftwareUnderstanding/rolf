{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1611.09904",
      "https://arxiv.org/abs/1406.2661",
      "https://arxiv.org/abs/2010.07061 (2020). https://arxiv.org/pdf/2010.07061</i></li>\n      </ul>\n    </li>\n    <li>Persian MIDI Dataset</li>\n    <li>The Lakh MIDI Dataset</li>\n  </ol>\n\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n\n<!-- REFERENCES -->\n## Refereces\n\n[1] *Mogren, Olof. (2016). C-RNN-GAN: Continuous recurrent neural networks with adversarial training. [https://arxiv.org/abs/1611.09904](https://arxiv.org/abs/1611.09904).* \n\n[2] *\u201cGenerating Music with GANs\u2014An Overview and Case Studies\u201d at ISMIR 2019 (November 4th at Delft, The Netherlands). [salu133445.github.io/ismir2019tutorial](https://salu133445.github.io/ismir2019tutorial/).* \n\n[3] *Goodfellow, Ian & Pouget-Abadie, Jean & Mirza, Mehdi & Xu, Bing & Warde-Farley, David & Ozair, Sherjil & Courville, Aaron & Bengio, Y.. (2014). Generative Adversarial Nets.  [ArXiv](https://arxiv.org/abs/1406.2661).* \n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n<!-- CONTACT -->\n## Contact\n\nSeyedmohammadsaleh Mirzatabatabaei - [@seyedsaleh](https://github.com/seyedsaleh) - seyedsaleh.edu@gmail.com\n\nSalman Amimotlagh - [@SMotlaq](https://github.com/SMotlaq) - pilot.motlaq@gmail.com\n\nProject Link: [https://github.com/seyedsaleh/music-generator](https://github.com/seyedsaleh/music-generator)\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n<!-- ROADMAP -->\n## Roadmap\n\n- [x] Multi-instrument by partitioning and joining each part (Music21 Instrument package)\n- [ ] Use offset, duration, velocity with pyPianoroll package\n- [ ] UI mobile and desktop application to create music\n- [ ] using CGANs network to avoid falchs\n\nSee the [open issues](https://github.com/seyedsaleh/music-generator/issues) for a full list of proposed features (and known issues).\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n---\n<div align=\"center\">\n<p>\n <img src=\"https://user-images.githubusercontent.com/47852354/138564509-b5dffb4e-f48b-4db5-b8a4-1385ef2b22c8.png\" width=\"110\">\n <img src=\"https://user-images.githubusercontent.com/47852354/138607395-e18bfc7a-204c-495a-914f-bd5cf8436ca4.jpg\" width=\"70\">\n</p>\n</div>\n\n\n<!-- MARKDOWN LINKS & IMAGES -->\n<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->\n[contributors-shield]: https://img.shields.io/github/contributors/seyedsaleh/music-generator.svg?style=for-the-badge\n[contributors-url]: https://github.com/seyedsaleh/music-generator/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/seyedsaleh/music-generator.svg?style=for-the-badge\n[forks-url]: https://github.com/seyedsaleh/music-generator/network/members\n[stars-shield]: https://img.shields.io/github/stars/seyedsaleh/music-generator.svg?style=for-the-badge\n[stars-url]: https://github.com/seyedsaleh/music-generator/stargazers\n[issues-shield]: https://img.shields.io/github/issues/seyedsaleh/music-generator.svg?style=for-the-badge\n[issues-url]: https://github.com/seyedsaleh/music-generator/issues\n[license-shield]: https://img.shields.io/github/license/seyedsaleh/music-generator.svg?style=for-the-badge\n[license-url]: https://github.com/seyedsaleh/music-generator/blob/master/LICENSE.txt\n",
      "https://arxiv.org/abs/1611.09904](https://arxiv.org/abs/1611.09904).* \n\n[2] *\u201cGenerating Music with GANs\u2014An Overview and Case Studies\u201d at ISMIR 2019 (November 4th at Delft, The Netherlands). [salu133445.github.io/ismir2019tutorial](https://salu133445.github.io/ismir2019tutorial/).* \n\n[3] *Goodfellow, Ian & Pouget-Abadie, Jean & Mirza, Mehdi & Xu, Bing & Warde-Farley, David & Ozair, Sherjil & Courville, Aaron & Bengio, Y.. (2014). Generative Adversarial Nets.  [ArXiv](https://arxiv.org/abs/1406.2661).* \n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n<!-- CONTACT -->\n## Contact\n\nSeyedmohammadsaleh Mirzatabatabaei - [@seyedsaleh](https://github.com/seyedsaleh) - seyedsaleh.edu@gmail.com\n\nSalman Amimotlagh - [@SMotlaq](https://github.com/SMotlaq) - pilot.motlaq@gmail.com\n\nProject Link: [https://github.com/seyedsaleh/music-generator](https://github.com/seyedsaleh/music-generator)\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n<!-- ROADMAP -->\n## Roadmap\n\n- [x] Multi-instrument by partitioning and joining each part (Music21 Instrument package)\n- [ ] Use offset, duration, velocity with pyPianoroll package\n- [ ] UI mobile and desktop application to create music\n- [ ] using CGANs network to avoid falchs\n\nSee the [open issues](https://github.com/seyedsaleh/music-generator/issues) for a full list of proposed features (and known issues).\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n---\n<div align=\"center\">\n<p>\n <img src=\"https://user-images.githubusercontent.com/47852354/138564509-b5dffb4e-f48b-4db5-b8a4-1385ef2b22c8.png\" width=\"110\">\n <img src=\"https://user-images.githubusercontent.com/47852354/138607395-e18bfc7a-204c-495a-914f-bd5cf8436ca4.jpg\" width=\"70\">\n</p>\n</div>\n\n\n<!-- MARKDOWN LINKS & IMAGES -->\n<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->\n[contributors-shield]: https://img.shields.io/github/contributors/seyedsaleh/music-generator.svg?style=for-the-badge\n[contributors-url]: https://github.com/seyedsaleh/music-generator/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/seyedsaleh/music-generator.svg?style=for-the-badge\n[forks-url]: https://github.com/seyedsaleh/music-generator/network/members\n[stars-shield]: https://img.shields.io/github/stars/seyedsaleh/music-generator.svg?style=for-the-badge\n[stars-url]: https://github.com/seyedsaleh/music-generator/stargazers\n[issues-shield]: https://img.shields.io/github/issues/seyedsaleh/music-generator.svg?style=for-the-badge\n[issues-url]: https://github.com/seyedsaleh/music-generator/issues\n[license-shield]: https://img.shields.io/github/license/seyedsaleh/music-generator.svg?style=for-the-badge\n[license-url]: https://github.com/seyedsaleh/music-generator/blob/master/LICENSE.txt\n"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9384552127166319
      ],
      "excerpt": "    <li> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999999999579927
      ],
      "excerpt": "        <li><i>Qiuqiang Kong, Bochen Li, Jitong Chen, and Yuxuan Wang. \"GiantMIDI-Piano: A large-scale MIDI dataset for classical piano music.\" arXiv preprint arXiv:2010.07061 (2020). https://arxiv.org/pdf/2010.07061</i></li> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9384552127166319,
        0.9865374311292784,
        0.968473386661761
      ],
      "excerpt": "    </li> \n    <li>Persian MIDI Dataset</li> \n    <li>The Lakh MIDI Dataset</li> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.981216288168734
      ],
      "excerpt": "[1] Mogren, Olof. (2016). C-RNN-GAN: Continuous recurrent neural networks with adversarial training. arXiv:1611.09904.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "[3] Goodfellow, Ian & Pouget-Abadie, Jean & Mirza, Mehdi & Xu, Bing & Warde-Farley, David & Ozair, Sherjil & Courville, Aaron & Bengio, Y.. (2014). Generative Adversarial Nets.  ArXiv.  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/seyedsaleh/music-generator",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Seyedmohammadsaleh Mirzatabatabaei - [@seyedsaleh](https://github.com/seyedsaleh) - seyedsaleh.edu@gmail.com\n\nSalman Amimotlagh - [@SMotlaq](https://github.com/SMotlaq) - pilot.motlaq@gmail.com\n\nProject Link: [https://github.com/seyedsaleh/music-generator](https://github.com/seyedsaleh/music-generator)\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n\n\n<!-- ROADMAP -->\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-10T19:48:05Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-10T11:40:37Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9858988333154396,
        0.9723397407995885
      ],
      "excerpt": "Generative adversarial networks have been proposed as a way of efficiently training deep generative neural networks. We propose a generative adversarial model that works on continuous sequential data, and apply it by training it on a collection of classical music. We conclude that it generates music that sounds better and better as the model is trained, report statistics on generated music, and let the reader judge the quality by downloading the generated songs. \nRecently, generative neural networks have taken the stage for artistic pursuits, such as image generation and photo retouching. Another area where these deep learning networks are beginning to leave a mark is in music generation. In this project, our goal is to explore the use of LSTM and GAN neural networks to generate music that seems as if it were human-made. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9756824864172741
      ],
      "excerpt": "Listen to our results! :smile: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9014699414132525
      ],
      "excerpt": "Major frameworks/libraries used to this project: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8882298890457321,
        0.9751566965067614,
        0.9990427531608064
      ],
      "excerpt": "an acronym for Musical Instrument Digital Interface, a technical standard that describes a communications protocol, digital interface, and electrical connectors that connect a wide variety of electronic musical instruments, computers. \nMusic21\u00a0is a powerful library in python whose tools are very helpful for creating, analysis and processing of audio files like songs, melodies and etc.. \nIn this project, we have used this library for our purposes of converting the MIDI files into notes, categorizing of notes for preparing the training data, and choosing the playing instruments for the output of our GAN and converting it back to MIDI. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.914601129152371
      ],
      "excerpt": "Parsing MIDI file and preparing the training data and preparing data for C-RNN-GAN network \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8341507915483898
      ],
      "excerpt": "The project has been done with aid of GPU Computing and the use of NVIDIA cuDNN and NVIDIA CUDA Toolkit. It helped us to use Tensorflow with GPU support for computing and learning with more compatibility. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9290965874260868
      ],
      "excerpt": "      GiantMIDI-Piano is a classical piano MIDI dataset contains 10,854 MIDI files of 2,786 composers. The curated subset by constraining composer surnames contains 7,236 MIDI files of 1,787 composers. GiantMIDI-Piano are transcribed from live recordings with a high-resolution piano transcription system. <a href=\"https://github.com/bytedance/GiantMIDI-Piano\">find out more on Github</a> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8129969182247119
      ],
      "excerpt": "[2] \u201cGenerating Music with GANs\u2014An Overview and Case Studies\u201d at ISMIR 2019 (November 4th at Delft, The Netherlands). salu133445.github.io/ismir2019tutorial.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8987766791531161,
        0.961848961357968
      ],
      "excerpt": "[ ] using CGANs network to avoid falchs \nSee the open issues for a full list of proposed features (and known issues). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Multi-Instrument music generation using C-RNN-GAN with MIDI format input \ud83c\udfbc",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/seyedsaleh/music-generator/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Thu, 23 Dec 2021 17:53:00 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/seyedsaleh/music-generator/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "seyedsaleh/music-generator",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/seyedsaleh/music-generator/master/notebooks/Music%20Generation_C_RNN_GAN.ipynb",
      "https://raw.githubusercontent.com/seyedsaleh/music-generator/master/notebooks/Multi%20Instrument%20Music%20Generator.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8837680365796365
      ],
      "excerpt": "Python 3.8 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8138986172493466
      ],
      "excerpt": "The project has been done with aid of GPU Computing and the use of NVIDIA cuDNN and NVIDIA CUDA Toolkit. It helped us to use Tensorflow with GPU support for computing and learning with more compatibility. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8589534893990137,
        0.8485139387667179
      ],
      "excerpt": "- Train \n- Plot loss function \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/seyedsaleh/music-generator/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "HTML",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "about-the-project\">About The Project</a>",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "music-generator",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "seyedsaleh",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/seyedsaleh/music-generator/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Thu, 23 Dec 2021 17:53:00 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "gan",
      "music-generation-deep-learning",
      "lstm-neural-networks",
      "c-rnn-gan",
      "cuda-toolkit",
      "midi-format",
      "music21"
    ],
    "technique": "GitHub API"
  }
}
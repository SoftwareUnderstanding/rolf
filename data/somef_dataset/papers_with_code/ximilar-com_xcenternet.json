{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1904.07850",
      "https://arxiv.org/abs/1703.06211"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.8729393277090676,
        0.8968592401678916,
        0.8729393277090676,
        0.8729393277090676
      ],
      "excerpt": "| ResNet 18      | CenterNet    | DCNSHORTCUT  | 0.7         | Pascal VOC   |   Link   |    Link     |     384     | \n| ResNet 18      | CenterNet    | CONCAT       | 0.64        | Pascal VOC   |   Link   |    Link     |     512     | \n| ResNet 18      | TTF / DIOU   | DCNSHORTCUT  | 0.7         | Pascal VOC   |   Link   |    Link     |     512     | \n| ResNet 18      | TTF / DIOU   | DCNSHORTCUT*  | 0.28        | MSCOCO17     |   Link   |    Link     |     384     | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Ximilar-com/xcenternet",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-23T07:47:42Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-09T10:48:07Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8057774925303828
      ],
      "excerpt": "Train and publish more models and backbones on mscoco \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9675179243026566,
        0.8990730870524615,
        0.8313337768309722,
        0.8275542373032905
      ],
      "excerpt": "We found out that it works very well on our models.  \nUnfortunately there is no official implementation. \nWe are using implementation from smallsunsun1. Currently, you \ncan find it in his fork of TensorFlow Addons for tf2.2 or \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9159115354055597
      ],
      "excerpt": "There is an active merge request to the Addons, we hope it will get there soon. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9487888986366669,
        0.9103960846509879,
        0.8711052929495611
      ],
      "excerpt": "* Model is using deformable convolutions, you need to install TensorFlow Addons with deformable convolutions, see the paragraph above for more info. \nThe mAP results in table are for IoU > 0.5 and score threshold > 0.01. For MSCOCO the mAP is for IoU=0.50:0.95 area=all. We still experience bit overfitting on Pascal VOC and MSCOCO, probably better augmentation, bigger batch size, longer training time can improve the result by few percentage points. In order to train CenterNet you will need to train it in our experience for many epochs. You can see the training progress in provided tensorboards along with learning rate schedule. We use Pascal VOC 2007+2012 TRAIN and VALIDATION dataset for training and we evaluate on Pascal VOC 2007 TEST. For MSCOCO we use 2017 TRAIN vs VALIDATION. Note that all tensorboard logs shows mAP for score threshold > 0.3 and IoU > 0.5. \nWe hope the tensorboards will give you more insights for reproducing and improving future results. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9696087869546454
      ],
      "excerpt": "The format of bounding box in mscoco is [xmin, ymin, width, height] which is converted in our code to the [ymin, xmin, ymax, xmax] (our format) inside of custom_dataset.py data loader. For example you can try to generate mscoco format with images for mnist detection through scripts/helpers/make_mnist.py. Every dataset is internally working with relative [0-1] coordinates and during the training are converted to absolute setReadOnlyAugmentations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9600638126608618
      ],
      "excerpt": "The main image/bbox augmentation work is done in batch_preprocessing.py. You can add (or remove) more augmentations suitable for your data. For example flip upside down is turned off by default. Because we are using tf.data.Dataset you will need to use tf.py_function or implement your augmentations in tf graph. Most of the augmentation is done through tf-image tools.py. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Fast anchor free Object Detection based on CenterNet (Objects As Points) and TTFNet (Training-Time-Friendly Network). Implemented in TensorFlow 2.4+.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ximilar-com/xcenternet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 23,
      "date": "Thu, 30 Dec 2021 04:57:47 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Ximilar-com/xcenternet/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Ximilar-com/xcenternet",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1) Clone this repository.\n2) Install tensorflow 2.4+\n3) Clone and Install [tf-image](https://github.com/Ximilar-com/tf-image)\n4) Install [tf-addons](https://www.tensorflow.org/addons). If you want to use models with deformable convolution (DCN) you will need to install tf.addons from [this branch](https://github.com/smallsunsun1/addons/tree/feature/deformable_ops) for tf2.2 or [updated fork](https://github.com/Cospel/addons/tree/feature/deformable_ops) for tf2.4. \n5) In the repository, execute `pip install . --user`.\n6) Alternatively, you can run the code directly from the cloned repository, however you need to run `python setup.py build_ext --inplace` to compile Cython code first.\n7) Install [classification_models](https://github.com/qubvel/classification_models), tfds and requirements.txt ...\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8822858713739995
      ],
      "excerpt": "here if you want tf2.4 version. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9411798961966211
      ],
      "excerpt": "* Model is using deformable convolutions, you need to install TensorFlow Addons with deformable convolutions, see the paragraph above for more info. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9142103421214066
      ],
      "excerpt": "If you need to evaluate on mscoco dataset then you will need to download the annotation files from coco page. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8291081975162036,
        0.848804620263535
      ],
      "excerpt": "For training on PASCAL VOC dataset run in scripts folder: \nCUDA_VISIBLE_DEVICES=0 nohup python train.py --model_type centernet --model_mode simple --log_dir results_voc \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.815138218250749,
        0.9159252926598656,
        0.9590777890878891
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=0 nohup python train.py --dataset coco --model_type centernet --model_mode simple --log_dir results_coco \nYou will need to use --dataset custom arg  with --dataset_path_tr train.json when running a training. The train.json should be in mscoco format. You can start with downloaded pretrained model: \nCUDA_VISIBLE_DEVICES=0 python train.py --dataset custom --dataset_path_tr train.json --dataset_path_te test.json  --batch_size 20 --pretrained_weights ~/centernet_results/dcn/model.h5 --model_type centernet --model_mode dcnshortcut --image_size 512 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8015868280946945
      ],
      "excerpt": "The main image/bbox augmentation work is done in batch_preprocessing.py. You can add (or remove) more augmentations suitable for your data. For example flip upside down is turned off by default. Because we are using tf.data.Dataset you will need to use tf.py_function or implement your augmentations in tf graph. Most of the augmentation is done through tf-image tools.py. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8066845834519982,
        0.9287651776962736
      ],
      "excerpt": "You can evaluate your model with different thresholds, go to the scripts folder and run eval.py script: \nCUDA_VISIBLE_DEVICES=0 python eval.py --model_type centernet --model_mode concat --load_model ../train/results_voc/checkpoints/model_95 --threshold 0.01 --iou_threshold 0.49 --dataset voc \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9000017272191859
      ],
      "excerpt": "CUDA_VISIBLE_DEVICES=3 python ../scripts/eval.py --load_weights vocsave/checkpoints/model_10 --image_size 512 --threshold 0.3 --model_mode dcnshortcut --model_type centernet --dataset custom --dataset_path test.json \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Ximilar-com/xcenternet/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Cython"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/ximilar-com/xcenternet/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Ximilar s.r.o.\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "## Todos",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "xcenternet",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Ximilar-com",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Ximilar-com/xcenternet/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "liborvaneksw",
        "body": "",
        "dateCreated": "2020-12-18T13:45:05Z",
        "datePublished": "2021-01-04T17:25:15Z",
        "html_url": "https://github.com/Ximilar-com/xcenternet/releases/tag/v1.0.0",
        "name": "First Release (TensorFlow 2.2, 2.3)",
        "tag_name": "v1.0.0",
        "tarball_url": "https://api.github.com/repos/Ximilar-com/xcenternet/tarball/v1.0.0",
        "url": "https://api.github.com/repos/Ximilar-com/xcenternet/releases/35960359",
        "zipball_url": "https://api.github.com/repos/Ximilar-com/xcenternet/zipball/v1.0.0"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 143,
      "date": "Thu, 30 Dec 2021 04:57:47 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "object-detection",
      "detection-model",
      "tensorflow",
      "python",
      "machine-learning",
      "computer-vision",
      "centernet",
      "deep-learning",
      "keras"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Go to the `scripts` folder and run `predict.py`, the result is stored in result.jpg file:\n\n    CUDA_VISIBLE_DEVICES=0 python predict.py --load_model ../scripts/results_voc/checkpoints/model_111 --backbone resnet18 --model_mode concat --image_path voc/21.jpg\n\n",
      "technique": "Header extraction"
    }
  ]
}
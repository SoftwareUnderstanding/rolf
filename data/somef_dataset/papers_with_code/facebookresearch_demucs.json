{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2111.03600\n[waveunet]: https://github.com/f90/Wave-U-Net\n[musdb]: https://sigsep.github.io/datasets/musdb.html\n[openunmix]: https://github.com/sigsep/open-unmix-pytorch\n[mmdenselstm]: https://arxiv.org/abs/1805.02410\n[demucs_v2]: https://github.com/facebookresearch/demucs/tree/v2\n[spleeter]: https://github.com/deezer/spleeter\n[soundcloud]: https://soundcloud.com/voyageuri/sets/source-separation-in-the-waveform-domain\n[d3net]: https://arxiv.org/abs/2010.01733\n[mdx]: https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021\n[kuielab]: https://github.com/kuielab/mdx-net-submission\n[decouple]: https://arxiv.org/abs/2109.05418\n[mdx_submission]: https://github.com/adefossez/mdx21_demucs",
      "https://arxiv.org/abs/1805.02410\n[demucs_v2]: https://github.com/facebookresearch/demucs/tree/v2\n[spleeter]: https://github.com/deezer/spleeter\n[soundcloud]: https://soundcloud.com/voyageuri/sets/source-separation-in-the-waveform-domain\n[d3net]: https://arxiv.org/abs/2010.01733\n[mdx]: https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021\n[kuielab]: https://github.com/kuielab/mdx-net-submission\n[decouple]: https://arxiv.org/abs/2109.05418\n[mdx_submission]: https://github.com/adefossez/mdx21_demucs",
      "https://arxiv.org/abs/2010.01733\n[mdx]: https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021\n[kuielab]: https://github.com/kuielab/mdx-net-submission\n[decouple]: https://arxiv.org/abs/2109.05418\n[mdx_submission]: https://github.com/adefossez/mdx21_demucs",
      "https://arxiv.org/abs/2109.05418\n[mdx_submission]: https://github.com/adefossez/mdx21_demucs"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@inproceedings{defossez2021hybrid,\n  title={Hybrid Spectrogram and Waveform Source Separation},\n  author={D{\\'e}fossez, Alexandre},\n  booktitle={Proceedings of the ISMIR 2021 Workshop on Music Source Separation},\n  year={2021}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{defossez2021hybrid,\n  title={Hybrid Spectrogram and Waveform Source Separation},\n  author={D{\\'e}fossez, Alexandre},\n  booktitle={Proceedings of the ISMIR 2021 Workshop on Music Source Separation},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8588313340652799
      ],
      "excerpt": "Checkout our paper [Hybrid Spectrogram and Waveform Source Separation][hybrid_paper] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.862785435078817
      ],
      "excerpt": "drums and bass extraction, although KUIELAB-MDX-Net performs better for \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8669112007448144
      ],
      "excerpt": "| [Wave-U-Net][waveunet]       | waveform    | no          | 3.2         | -           | -                 | \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/facebookresearch/demucs/main/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/demucs",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to Demucs\nPull Requests\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\nComplete your CLA here: https://code.facebook.com/cla\nDemucs is the implementation of a research paper.\nTherefore, we do not plan on accepting many pull requests for new features.\nWe certainly welcome them for bug fixes.\nIssues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\nLicense\nBy contributing to this repository, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-25T02:43:20Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-27T04:29:05Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9216975174679912,
        0.9103005413402809
      ],
      "excerpt": "This is the 3rd release of Demucs (v3), featuring hybrid source separation. \nFor the waveform only Demucs (v2): [Go this commit][demucs_v2]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8510538596361159
      ],
      "excerpt": "Demucs is based on U-Net convolutional architecture inspired by [Wave-U-Net][waveunet]. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9791942740158983,
        0.9205611916806693,
        0.87118729851211,
        0.8190992863745467,
        0.8717855020653492,
        0.838348535488429,
        0.8330822469635556
      ],
      "excerpt": "for more details. As far as we know, Demucs is currently the only model supporting true \nend-to-end hybrid model training with shared information between the domains, \nas opposed to post-training model blending. \nWhen trained only on MusDB HQ, Hybrid Demucs achieved a SDR of 7.33 on the MDX test set, \nand 8.11 dB with 200 extra training tracks. It is particularly efficient for \ndrums and bass extraction, although KUIELAB-MDX-Net performs better for \nvocals and other accompaniments. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8015307257197332,
        0.9465406330869938
      ],
      "excerpt": "<img src=\"./demucs.png\" alt=\"Schema representing the structure of Demucs, \n    with a dual U-Net structure with a shared core, one branch for the temporal domain, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9776489336054894
      ],
      "excerpt": "See the release notes for more details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.968302450633834,
        0.9089008662522335,
        0.9547220908353603,
        0.8311059136574146
      ],
      "excerpt": "    on all sources. This is the model that won Sony MDX challenge. \n11/05/2021: Adding support for MusDB-HQ and arbitrary wav set, for the MDX challenge. For more information \non joining the challenge with Demucs see the Demucs MDX instructions \n28/04/2021: Demucs v2, with extra augmentation and DiffQ based quantization. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8629007686938392,
        0.8184887893615106
      ],
      "excerpt": "  This version also adds overlap between prediction frames, with linear transition from one to the next, \n  which should prevent sudden changes at frame boundaries. Also, Demucs is now on PyPI, so for separation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8921675267351739,
        0.9489988163698513,
        0.9660652748308249
      ],
      "excerpt": "13/04/2020: Demucs released under MIT: We are happy to release Demucs under the MIT licence. \n    We hope that this will broaden the impact of this research to new applications. \nWe provide hereafter a summary of the different metrics presented in the paper. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8372396012058242,
        0.989810717816229,
        0.9807233190154289,
        0.9878060170227622,
        0.9589040312974123
      ],
      "excerpt": "songs on my [soundcloud playlist][soundcloud]. \nOverall SDR is the mean of the SDR for each of the 4 sources, MOS Quality is a rating from 1 to 5 \nof the naturalness and absence of artifacts given by human listeners (5 = no artifacts), MOS Contamination \nis a rating from 1 to 5 with 5 being zero contamination by other sources. We refer the reader to our [paper][hybrid_paper], \nfor more details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "demucs PATH_TO_AUDIO_FILE_1 [PATH_TO_AUDIO_FILE_2 ...]   #: for Demucs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8930520351427395
      ],
      "excerpt": ": You can select different models with -n mdx_q is the quantized model, smaller but maybe a bit less accurate. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9151649157124346
      ],
      "excerpt": "You can pass --mp3 to save as mp3 instead, and set the bitrate with --mp3-bitrate (default is 320kbps). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8984072171864179,
        0.8231019439150495
      ],
      "excerpt": "The list of pre-trained models is: \n- mdx: trained only on MusDB HQ, winning model on track A at the [MDX][mdx] challenge. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.897075557684642
      ],
      "excerpt": "    of the [MDX][mdx] challenge. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8116533660619388,
        0.9585846664066152,
        0.9361493946995939
      ],
      "excerpt": "    but quality can be slightly worse. mdx_extra_q is the default model used. \n- SIG: where SIG is a single model from the model zoo. \nThe --shifts=SHIFTS performs multiple predictions with random shifts (a.k.a the shift trick) of the input and average them. This makes prediction SHIFTS times \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.956957297446822
      ],
      "excerpt": "Default is 0.25 (i.e. 25%) which is probably fine. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code for the paper Hybrid Spectrogram and Waveform Source Separation",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/demucs/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 445,
      "date": "Mon, 27 Dec 2021 14:33:15 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/facebookresearch/demucs/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "facebookresearch/demucs",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/facebookresearch/demucs/tree/main/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/facebookresearch/demucs/main/Demucs.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9206633769338113
      ],
      "excerpt": "git checkout v2. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8571755594774987
      ],
      "excerpt": "on joining the challenge with Demucs see the Demucs MDX instructions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8061170103914981,
        0.8422625678274904,
        0.9532759512482861
      ],
      "excerpt": "  This version also adds overlap between prediction frames, with linear transition from one to the next, \n  which should prevent sudden changes at frame boundaries. Also, Demucs is now on PyPI, so for separation \n  only, installation is as easy as pip install demucs :) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9565577280459411
      ],
      "excerpt": "Everytime you see python3, replace it with python.exe. You should always run commands from the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.945629065739781,
        0.9933429366787236,
        0.8555168539809244,
        0.9657775515285439,
        0.8503733924089184,
        0.9309480368097586,
        0.8421357339489409,
        0.9707990477290546,
        0.9805538865488989,
        0.9770335174395833,
        0.999746712887969,
        0.9552373142125511,
        0.9932133206256866,
        0.9462503336739874
      ],
      "excerpt": "If you just want to use Demucs to separate tracks, you can install it with \npython3 -m pip install -U demucs \nAdvanced OS support are provided on the following page, you must read the page for your OS before posting an issues: \n- If you are using Windows: Windows support. \n- If you are using MAC OS X: Mac OS X support. \n- If you are using Linux: Linux support. \nIf you have anaconda installed, you can run from the root of this repository: \nconda env update -f environment-cpu.yml  #: if you don't have GPUs \nconda env update -f environment-cuda.yml #: if you have GPUs \nconda activate demucs \npip install -e . \nThis will create a demucs environment with all the dependencies installed. \nYou will also need to install soundstretch/soundtouch: on Mac OSX you can do brew install sound-touch, \nand on Ubuntu sudo apt-get install soundstretch. This is used for the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8556732225728535
      ],
      "excerpt": "In order to try Demucs, you can just run from any folder (as long as you properly installed it) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9640554193009521
      ],
      "excerpt": ": If you used pip install --user you might need to replace demucs with python3 -m demucs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9300572779181543
      ],
      "excerpt": "If you have a GPU, but you run out of memory, please add -d cpu to the command line. See the section hereafter for more details on the memory requirements for GPU acceleration. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9420092368223305
      ],
      "excerpt": "All audio formats supported by torchaudio can be processed (i.e. wav, mp3, flac, ogg/vorbis on Linux/Mac OS X etc.). On Windows, torchaudio has limited support, so we rely on ffmpeg, which should support pretty much anything. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9313924027372682
      ],
      "excerpt": "slower. Don't use it unless you have a GPU. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8833921682668171
      ],
      "excerpt": "<img src=\"./demucs.png\" alt=\"Schema representing the structure of Demucs, \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/facebookresearch/demucs/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) Facebook, Inc. and its affiliates.\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Demucs Music Source Separation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "demucs",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "facebookresearch",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/demucs/blob/main/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You will need at least Python 3.7. See `requirements_minimal.txt` for requirements for separation only,\nand `environment-[cpu|cuda].yml` (or `requirements.txt`) if you want to train a new model.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "If you want to use GPU acceleration, you will need at least 8GB of RAM on your GPU for `demucs`. Sorry, the code for demucs is not super optimized for memory! If you do not have enough memory on your GPU, simply add `-d cpu` to the command line to use the CPU. With Demucs, processing time should be roughly equal to 1.5 times the duration of the track.\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Thanks to @xserrat, there is now a Docker image definition ready for using Demucs. This can ensure all libraries are correctly installed without interfering with the host OS. See his repo [Docker Facebook Demucs](https://github.com/xserrat/docker-facebook-demucs) for more information.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "I made a Colab to easily separate track with Demucs. Note that\ntransfer speeds with Colab are a bit slow for large media files,\nbut it will allow you to use Demucs without installing anything.\n\n[Demucs on Google Colab](https://colab.research.google.com/drive/1dC9nVxk3V_VPjUADsnFu8EiT-xnU1tGH?usp=sharing)\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2662,
      "date": "Mon, 27 Dec 2021 14:33:15 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "(Possibly broken with the update, need to investigate) Integrated to [Huggingface Spaces](https://huggingface.co/spaces) with [Gradio](https://github.com/gradio-app/gradio). See demo: [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/akhaliq/demucs)\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
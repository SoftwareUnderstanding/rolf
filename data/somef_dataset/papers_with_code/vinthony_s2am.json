{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1907.06406",
      "https://arxiv.org/abs/1907.06406",
      "https://arxiv.org/abs/1807.06521"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find our work useful in your research, please consider citing:\n```\n@misc{cun2019improving,\n    title={Improving the Harmony of the Composite Image by Spatial-Separated Attention Module},\n    author={Xiaodong Cun and Chi-Man Pun},\n    year={2019},\n    eprint={1907.06406},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{cun2019improving,\n    title={Improving the Harmony of the Composite Image by Spatial-Separated Attention Module},\n    author={Xiaodong Cun and Chi-Man Pun},\n    year={2019},\n    eprint={1907.06406},\n    archivePrefix={arXiv},\n    primaryClass={cs.CV}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9490753289412834
      ],
      "excerpt": "Arxiv | Demo \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8450045395698996,
        0.9863894589431461
      ],
      "excerpt": "&nbsp;&nbsp;&nbsp;&nbsp;University of Macau<br> \n&nbsp;&nbsp;&nbsp;&nbsp;Trans. on Image Processing, vol. 29, pp. 4759-4771, 2020. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925888097564324
      ],
      "excerpt": "please refer to this link. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "     <td>37.33</td> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "     <td>37.25</rd> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "     <td>30.71</td> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vinthony/s2am",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-15T13:45:48Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-01T09:56:18Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9692284609946287,
        0.9603853038665843,
        0.908925214220865,
        0.9968029537584643
      ],
      "excerpt": "This repo contains the PyTorch implement of the following paper: \n&nbsp;&nbsp;&nbsp;&nbsp;Improving the Harmony of the Composite Image by Spatial-Separated Attention Module<br> \n&nbsp;&nbsp;&nbsp;&nbsp;Xiaodong Cun and Chi-Man Pun<br> \n&nbsp;&nbsp;&nbsp;&nbsp;University of Macau<br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.976161146515402,
        0.9963710432775849
      ],
      "excerpt": "Image composition is one of the most important applications in image processing. However, the inharmonious appearance between the spliced region and background degrade the quality of image. Thus, we address the problem of Image Harmonization: Given a spliced image and the mask of the spliced region, we try to harmonize the ''style'' of the pasted region with the background (non-spliced region). Previous approaches have been focusing on learning directly by the neural network. \nIn this work, we start from an empirical observation: the differences can only be found in the spliced region between the spliced image and the harmonized result while they share the same semantic information and the appearance in the non-spliced region. Thus, in order to learn the feature map in the masked region and the others individually, we propose a novel attention module named Spatial-Separated Attention Module (S\u00b2AM). Furthermore, we design a novel image harmonization framework by inserting the S\u00b2AM in the coarser low level features of the Unet structure by two different ways. Besides image harmonization, we make a big step for harmonizing the composite image without the specific mask under previous observation. The experiments show that the proposed S\u00b2AM performs better than other state-of-the-art attention modules in our task.  Moreover, we demonstrate the advantages of our model against other state-of-the-art image harmonization methods via criteria from multiple points of view. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8570375868161314,
        0.9838739602904544
      ],
      "excerpt": "We report the MAE and PSNR as shown in the original iHarmony5 paper. The pretrained model can be downloaded from here. \nThese results are trained and evaluated using the newer version of our code framework with nothing changes to the algorithm(please refer to our new work here). All the results have been evaluated using a jupyter notebook in eval_s2am_iharmony4.ipynb, which is modified from the evaluation code in DoveNet(CVPR 2020). Notice that the original DoveNet use the total sub-datasets for training, the results report here are trained on each sub-dataset individually. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9847456039946226
      ],
      "excerpt": "We evaluate our method with the baseline attention module: CBAM and original ResNet in CIFAR-10 with the default setting of code in pytorch_resnet_cifar10 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "[TIP 2020] Improving the Harmony of the Composite Image by Spatial-Separated Attention Module",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vinthony/s2am/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Sat, 25 Dec 2021 18:26:24 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/vinthony/s2am/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "vinthony/s2am",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/vinthony/s2am/master/visualize.ipynb",
      "https://raw.githubusercontent.com/vinthony/s2am/master/eval_s2am_iharmony4.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/vinthony/s2am/master/examples/train_harmorization_s2ad.sh",
      "https://raw.githubusercontent.com/vinthony/s2am/master/examples/train.sh",
      "https://raw.githubusercontent.com/vinthony/s2am/master/examples/train_harmorization_wo_mask.sh",
      "https://raw.githubusercontent.com/vinthony/s2am/master/examples/train_harmorization_s2asc.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8633648402345236
      ],
      "excerpt": "chmod +x ./example/train_harmorization_s2ad.sh && ./example/train_harmorization_s2ad.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633648402345236
      ],
      "excerpt": "chmod +x ./example/train_harmorization_s2asc.sh && ./example/train_harmorization_s2asc.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8633648402345236
      ],
      "excerpt": "chmod +x ./example/train_harmorization_wo_mask.sh && ./example/train_harmorization_wo_mask.sh \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8817415589474913
      ],
      "excerpt": "clone this repo. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8627670300380597
      ],
      "excerpt": "run the notebook \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8015396585238513,
        0.814499106087584,
        0.834752385217466
      ],
      "excerpt": "* SCOCO dataset(~5G) contains 40k images for training and 1.7k images for testing.<br> \n* S-Adobe5k(~25G in tiff format) dataset contains 32k images form training and 2k images for testing. <br> \nAll the options of the training can be found in options.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8435117703108503
      ],
      "excerpt": "download some sample validation dataset from google drive \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.820621269507537
      ],
      "excerpt": "run the notebook \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8394175966125845
      ],
      "excerpt": "| method | Test err (Orginal) | Test err (w/ CBAM) | Test err (w/ S\u00b2AM)| \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8702815774991463
      ],
      "excerpt": "| ResNet20 | 8.45% | 7.91% | 7.60% | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/vinthony/s2am/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Spatial-Separated Attention Module (S\u00b2AM)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "s2am",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "vinthony",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/vinthony/s2am/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The code is tested on the python 3.6 and PyTorch v0.4+ under Ubuntu 18.04 OS.</br>\nYou need to install all the requirements from `pip`.</br>\n`Anaconda` is highly recommendation for install the dependences.</br> \n```\ngit clone https://github.com/vinthony/s2am.git\ncd s2am\npip install -r requirements.txt\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 39,
      "date": "Sat, 25 Dec 2021 18:26:24 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "image-harmonization",
      "image-composition",
      "pytorch"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Just visit our [google colab notebook](https://colab.research.google.com/drive/1UTjyi0J1F2mjc9rf9ZbFUOL2_kkZmdlQ?usp=sharing).\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
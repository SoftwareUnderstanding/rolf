{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* Our torch implementation is based on Justin Johnson's [code](https://github.com/jcjohnson/neural-style);\n* We use Anat Levin's Matlab [code](http://www.wisdom.weizmann.ac.il/~levina/matting.tar.gz) to compute the matting Laplacian matrix.\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1703.07511",
      "https://arxiv.org/abs/1606.00915",
      "https://arxiv.org/abs/1703.07511"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this work useful for your research, please cite:\n```\n@article{luan2017deep,\n  title={Deep Photo Style Transfer},\n  author={Luan, Fujun and Paris, Sylvain and Shechtman, Eli and Bala, Kavita},\n  journal={arXiv preprint arXiv:1703.07511},\n  year={2017}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{luan2017deep,\n  title={Deep Photo Style Transfer},\n  author={Luan, Fujun and Paris, Sylvain and Shechtman, Eli and Bala, Kavita},\n  journal={arXiv preprint arXiv:1703.07511},\n  year={2017}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8483679933130212
      ],
      "excerpt": "Berkeley Contour Detection and Image Segmentation Resources \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/divisionai/deep-photo-styletransfer",
    "technique": "GitHub API"
  },
  "contact": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Feel free to contact me if there is any question (Fujun Luan fl356@cornell.edu).\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-20T00:10:37Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-05-20T00:24:43Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9251011885003383,
        0.9337120771290517
      ],
      "excerpt": "Code and data for paper \"Deep Photo Style Transfer\" \nThis software is published for academic and non-commercial use only. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9190966195912955
      ],
      "excerpt": "Here are some automatic and manual tools for creating a segmentation mask for a photo image: \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/divisionai/deep-photo-styletransfer/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 23:29:07 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/divisionai/deep-photo-styletransfer/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "divisionai/deep-photo-styletransfer",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/divisionai/deep-photo-styletransfer/master/models/download_models.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* [Photoshop Quick Selection Tool](https://helpx.adobe.com/photoshop/using/making-quick-selections.html)\n* [GIMP Selection Tool](https://docs.gimp.org/en/gimp-tools-selection.html)\n* [GIMP G'MIC Interactive Foreground Extraction tool](http://gmic.eu/gimp.shtml)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "This code is based on torch. It has been tested on Ubuntu 14.04 LTS.\n\nDependencies:\n* [Torch](https://github.com/torch/torch7) (with [matio-ffi](https://github.com/soumith/matio-ffi.torch) and [loadcaffe](https://github.com/szagoruyko/loadcaffe))\n* [Matlab](https://www.mathworks.com/) or [Octave](https://www.gnu.org/software/octave/)\n\nCUDA backend:\n* [CUDA](https://developer.nvidia.com/cuda-downloads)\n* [cudnn](https://developer.nvidia.com/cudnn)\n\nDownload VGG-19:\n```\nsh models/download_models.sh\n```\n\nCompile ``cuda_utils.cu`` (Adjust ``PREFIX`` and ``NVCC_PREFIX`` in ``makefile`` for your machine):\n```\nmake clean && make\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8424986175223993
      ],
      "excerpt": "| Color variable  | RGB Value | Hex Value |  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/divisionai/deep-photo-styletransfer/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "MATLAB",
      "Lua",
      "Cuda",
      "Python",
      "Makefile",
      "Shell",
      "M"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "deep-photo-styletransfer",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "deep-photo-styletransfer",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "divisionai",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/divisionai/deep-photo-styletransfer/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 23:29:07 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To generate all results (in ``examples/``) using the provided scripts, simply run\n```\nrun('gen_laplacian/gen_laplacian.m')\n```\nin Matlab or Octave and then\n```\npython gen_all.py\n```\nin Python. The final output will be in ``examples/final_results/``.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Given input and style images with semantic segmentation masks, put them in ``examples/`` respectively. They will have the following filename form: ``examples/input/in<id>.png``, ``examples/style/tar<id>.png`` and ``examples/segmentation/in<id>.png``, ``examples/segmentation/tar<id>.png``;\n2. Compute the matting Laplacian matrix using ``gen_laplacian/gen_laplacian.m`` in Matlab. The output matrix will have the following filename form: ``gen_laplacian/Input_Laplacian_3x3_1e-7_CSR<id>.mat``; \n\n**Note: Please make sure that the content image resolution is consistent for Matting Laplacian computation in Matlab and style transfer in Torch, otherwise the result won't be correct.**\n\n3. Run the following script to generate segmented intermediate result:\n```\nth neuralstyle_seg.lua -content_image <input> -style_image <style> -content_seg <inputMask> -style_seg <styleMask> -index <id> -serial <intermediate_folder>\n```\n4. Run the following script to generate final result:\n```\nth deepmatting_seg.lua -content_image <input> -style_image <style> -content_seg <inputMask> -style_seg <styleMask> -index <id> -init_image <intermediate_folder/out<id>_t_1000.png> -serial <final_folder> -f_radius 15 -f_edge 0.01\n```\n\nYou can pass `-backend cudnn` and `-cudnn_autotune` to both Lua scripts (step 3.\nand 4.) to potentially improve speed and memory usage. `libcudnn.so` must be in\nyour `LD_LIBRARY_PATH`. This requires [cudnn.torch](https://github.com/soumith/cudnn.torch).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Here are some results from our algorithm (from left to right are input, style and our output):\n<p align='center'>\n  <img src='examples/input/in3.png' height='194' width='290'/>\n  <img src='examples/style/tar3.png' height='194' width='290'/>\n  <img src='examples/refine_posterization/refine_3.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in4.png' height='194' width='290'/>\n  <img src='examples/style/tar4.png' height='194' width='290'/>\n  <img src='examples/refine_posterization/refine_4.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in13.png' height='194' width='290'/>\n  <img src='examples/style/tar13.png' height='194' width='290'/>\n  <img src='examples/refine_posterization/refine_13.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in9.png' height='194' width='290'/>\n  <img src='examples/style/tar9.png' height='194' width='290'/>\n  <img src='examples/refine_posterization/refine_9.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in20.png' height='194' width='290'/>\n  <img src='examples/style/tar20.png' height='194' width='290'/>\n  <img src='examples/refine_posterization/refine_20.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in1.png' height='194' width='290'/>\n  <img src='examples/style/tar1.png' height='194' width='290'/>\n  <img src='examples/refine_posterization/refine_1.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in39.png' height='194' width='290'/>\n  <img src='examples/style/tar39.png' height='194' width='290'/>\n  <img src='examples/refine_posterization/refine_39.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in57.png' height='194' width='290'/>\n  <img src='examples/style/tar57.png' height='194' width='290'/>\n  <img src='examples/refine_posterization/refine_57.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in47.png' height='194' width='290'/>\n  <img src='examples/style/tar47.png' height='194' width='290'/>\n  <img src='examples/refine_posterization/refine_47.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in58.png' height='194' width='290'/>\n  <img src='examples/style/tar58.png' height='194' width='290'/>\n  <img src='examples/refine_posterization/refine_58.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in51.png' height='194' width='290'/>\n  <img src='examples/style/tar51.png' height='194' width='290'/>\n  <img src='examples/refine_posterization/refine_51.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in7.png' height='194' width='290'/>\n  <img src='examples/style/tar7.png' height='194' width='290'/>\n  <img src='examples/refine_posterization/refine_7.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in23.png' width='290'/>\n  <img src='examples/input/in23.png' width='290'/>\n  <img src='examples/final_results/best23_t_1000.png' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in16.png' height='194' width='290'/>\n  <img src='examples/style/tar16.png' height='194' width='290'/>\n  <img src='examples/refine_posterization/refine_16.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in30.png' height='194' width='290'/>\n  <img src='examples/style/tar30.png' height='194' width='290'/>\n  <img src='examples/refine_posterization/refine_30.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in2.png' height='194' width='290'/>\n  <img src='examples/style/tar2.png' height='194' width='290'/>\n  <img src='examples/final_results/best2_t_1000.png' height='194' width='290'/>\n</p>\n\n<p align='center'>\n  <img src='examples/input/in11.png'  width='290'/>\n  <img src='examples/style/tar11.png' width='290'/>\n  <img src='examples/refine_posterization/refine_11.png'  width='290'/>\n</p>\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1609.03499"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9977994744046882
      ],
      "excerpt": "- Paper: https://arxiv.org/pdf/1906.01083.pdf \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Talk2Levi/DJL",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-08-21T14:35:34Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-10T02:45:52Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9607451869388081,
        0.956107084675512,
        0.9550593098223928,
        0.870654857572221,
        0.90794403006421
      ],
      "excerpt": "Difference: They are the same with time signatures such as 3/4 and 4/4, which have beats of a quarter-note in length. However, time signatures based on eighth-notes have a beat length only half the size, which should normally play twice as fast. \nA unified language that allows different musical pieces of equipment to communicate with one another\u00a0 \nIt is not an audio signal, it is a trigger for communicating to another device, it transmits information such as tonation, the velocity of the performance, volume, etc. \na written form of a musical composition. \nparts for different instruments appear on separate staves on large pages. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9818518822852615
      ],
      "excerpt": "MusicVAE learns a latent space of musical sequences, providing different modes of interactive musical creation, including: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8147826247799591,
        0.9596335221320185,
        0.9009318468160834
      ],
      "excerpt": "- manipulation of existing sequences via attribute vectors or a latent constraint model. \nThis configuration acts as a baseline for melody generation with an LSTM model. It uses basic one-hot encoding to represent extracted melodies as input to the LSTM. For training, all examples are transposed to the MIDI pitch range [48, 84] and outputs will also be in this range. \nAble to generate high-fidelity audio samples that capture structure at timescales that time-domain models have yet to achieve. Powered by Recurrent Convolutional Neural Network. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9464852316655213,
        0.9821670946094702
      ],
      "excerpt": "- Instead of modeling a 1-D time-domain wave form, we can model a 2-D time-frequency representation: Spectrogram. \n  - Spectrogram: a picture of sound. The x-axis is Time, the y-axis is Frequency, and the brightness (lightness or darkness) at any given point represents the energy at that point. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "AI DJ, Drop The Beat.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Talk2Levi/DJL/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 14:11:08 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Talk2Levi/DJL/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Talk2Levi/DJL",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Talk2Levi/DJL/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "DJL",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "DJL",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Talk2Levi",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Talk2Levi/DJL/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Fri, 24 Dec 2021 14:11:08 GMT"
    },
    "technique": "GitHub API"
  }
}
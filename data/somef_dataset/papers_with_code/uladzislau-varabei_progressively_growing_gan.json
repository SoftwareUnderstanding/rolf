{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1710.10196\n<br>\nCode is based on official implementation: https://github.com/tkarras/progressive_growing_of_gans\n\nThis implementation allows finer control of a training process and model complexity: \none can use different parameters which define number of filters of each network (consider function `n_filters("
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.974546715600346
      ],
      "excerpt": "Tensorflow 2 implementation of Progressive Growing of GANs for Improved Quality, Stability, and Variation: https://arxiv.org/abs/1710.10196 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/uladzislau-varabei/progressively_growing_gan",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-06-13T14:07:57Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-02T16:19:47Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8067054977793722
      ],
      "excerpt": "Tensorflow 2 implementation of Progressive Growing of GANs for Improved Quality, Stability, and Variation: https://arxiv.org/abs/1710.10196 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8803052030239988,
        0.9274936545658385
      ],
      "excerpt": "Code is based on official implementation: https://github.com/tkarras/progressive_growing_of_gans \nThis implementation allows finer control of a training process and model complexity:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8613661680588424,
        0.9510979743920988,
        0.9428536443205647
      ],
      "excerpt": "as in this case all GPU resources are released after process is finished.  <br> \nAnother way to incease performance is to use mixed precision training, which not just speeds operations up (especially on Nvidia cards with compute capability 7.0 or higher, e.g. Turing GPUs), but also allows to increase batch size. <br> \nNote: for now restoring/saving optimizer state is not implemented, so if optimizers states should not be reset a model must be trained in a single process. By default models in official implementation reset oprimizer state for new level of details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Tensorflow 2 implementation of Progressive Growing of GANs for Improved Quality, Stability, and Variation",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/uladzislau-varabei/progressively_growing_gan/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 23:47:29 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/uladzislau-varabei/progressively_growing_gan/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "uladzislau-varabei/progressively_growing_gan",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8535243724623167
      ],
      "excerpt": "Optionally configure gpu memory options (consider GPU memory usage section) \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8322765443895876
      ],
      "excerpt": "Define a training config (example in default_config.json, all available options and their default values can be found in utils.py). Note: some values in config are different from original implementation due to memory constraints. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8346340421193428,
        0.9289870797399707,
        0.8297014625013313
      ],
      "excerpt": "Start training with command: <br> \npython train.py --config=path_to_config (e.g. --config=default_config.json) \nTo get maximum performance one should prefer training each model in a separate process (single_process_training in train.py),  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/uladzislau-varabei/progressively_growing_gan/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Progressively growing GAN",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "progressively_growing_gan",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "uladzislau-varabei",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/uladzislau-varabei/progressively_growing_gan/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Code was tested on Linux and Windows. Though when running on Windows you can face additional warning messages from Tensorflow, also, it takes more time to start training (usually up to several additional minutes for each stage), however, it doesn't affect training process\n- Requirements can be installed from `conda_environment.yml`(`conda env create -f conda_environment.yml`)\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 23:47:29 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To control GPU memory usage one can refer to a function `prepare_gpu()` in `utils.py`. \n<br>\nDepending on your operating system use case you might want to change memory managing. \nBy default on Linux memory_growth option is used, while on Windows memory is limited with some reasonable number to allow use of PC (such as opening browsers with small number of tabs).\n<br>\n*Note:* code was used with GPUs with 8 Gb of memory, so if your card has more/less memory it is strongly recommended to consider modifying `prepare_gpu()` function. \n\n",
      "technique": "Header extraction"
    }
  ]
}
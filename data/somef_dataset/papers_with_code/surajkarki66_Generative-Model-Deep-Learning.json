{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1609.04468",
      "https://arxiv.org/abs/1609.05158\n\n### 6"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9854121748519129
      ],
      "excerpt": "Goodfellow et. al (2014) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9944484218006108
      ],
      "excerpt": "PixelShuffle: https://arxiv.org/abs/1609.05158 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/surajkarki66/Generative-Model-Deep-Learning",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-08-07T18:15:34Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-10T14:30:48Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8761164022235732
      ],
      "excerpt": "Construct different mini-batches for real and fake, i.e. each mini-batch needs to contain only all real images or all generated images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8066911099384199
      ],
      "excerpt": "when things are working, D loss has low variance and goes down over time vs having huge variance and spiking \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.834695533457999
      ],
      "excerpt": "adding gaussian noise to every layer of generator (Zhao et. al. EBGAN) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "In this repository i'm gonna walk you through the origin of generative model.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/surajkarki66/Generative-Model-Deep-Learning/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 07:35:46 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/surajkarki66/Generative-Model-Deep-Learning/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "surajkarki66/Generative-Model-Deep-Learning",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Autoencoders/conv_autoencoder.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Autoencoders/variational_autoencoder.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Autoencoders/denoising_autoencoder.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Autoencoders/.ipynb_checkpoints/conv_autoencoder-checkpoint.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Autoencoders/.ipynb_checkpoints/denoising_autoencoder-checkpoint.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Autoencoders/.ipynb_checkpoints/variational_autoencoder-checkpoint.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Generative%20Adversarial%20Network/sketch_to_color_cgan/main.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Generative%20Adversarial%20Network/sketch_to_color_cgan/.ipynb_checkpoints/main-checkpoint.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Generative%20Adversarial%20Network/.ipynb_checkpoints/dcgan-checkpoint.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Generative%20Adversarial%20Network/dcgan/dcgan.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Generative%20Adversarial%20Network/dcgan/.ipynb_checkpoints/dcgan-checkpoint.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Generative%20Adversarial%20Network/anime_dcgan/main.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Generative%20Adversarial%20Network/anime_dcgan/.ipynb_checkpoints/main-checkpoint.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Generative%20Adversarial%20Network/cgan/main.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Generative%20Adversarial%20Network/cgan/.ipynb_checkpoints/main-checkpoint.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Generative%20Adversarial%20Network/pix2pix/main.ipynb",
      "https://raw.githubusercontent.com/surajkarki66/Generative-Model-Deep-Learning/master/Generative%20Adversarial%20Network/pix2pix/.ipynb_checkpoints/main-checkpoint.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/surajkarki66/Generative-Model-Deep-Learning/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Generative-Model-Deep-Learning",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Generative-Model-Deep-Learning",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "surajkarki66",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/surajkarki66/Generative-Model-Deep-Learning/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Tue, 21 Dec 2021 07:35:46 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "deep-learning",
      "gan",
      "tensorflow",
      "pytorch"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Dont sample from a Uniform distribution\n- When doing interpolations, do the interpolation via a great circle, rather than a straight line from point A to point B\n- Tom White's [Sampling Generative Networks](https://arxiv.org/abs/1609.04468) ref code https://github.com/dribnet/plat has more details\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- Label Smoothing, i.e. if you have two target labels: Real=1 and Fake=0, then for each incoming sample, if it is real, then replace the label with a random number between 0.7 and 1.2, and if it is a fake sample, replace it with 0.0 and 0.3 (for example).\n  - Salimans et. al. 2016\n- make the labels the noisy for the discriminator: occasionally flip the labels when training the discriminator\n- fake_labels = `tf.random.uniform(shape=[25, 1], minval=0, maxval=0.3, dtype=tf.float32)`\n- real_labels = `tf.random.uniform(shape=[25, 1], minval=0.7, maxval=1.2, dtype=tf.float32)`\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- Experience Replay\n  - Keep a replay buffer of past generations and occassionally show them\n  - Keep checkpoints from the past of G and D and occassionaly swap them out for a few iterations\n- All stability tricks that work for deep deterministic policy gradients\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- optim.Adam rules!\n  - See Radford et. al. 2015\n- Use SGD for discriminator and ADAM for generator\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- Provide noise in the form of dropout (50%).\n- Apply on several layers of our generator at both training and test time\n- https://arxiv.org/pdf/1611.07004v1.pdf\n",
      "technique": "Header extraction"
    }
  ]
}
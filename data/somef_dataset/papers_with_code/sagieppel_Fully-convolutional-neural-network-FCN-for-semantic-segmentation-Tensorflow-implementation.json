{
  "citation": [
    {
      "confidence": [
        0.9265657891163315
      ],
      "excerpt": "Glass and transparent vessel recognition trained model \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sagieppel/Fully-convolutional-neural-network-FCN-for-semantic-segmentation-Tensorflow-implementation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-08-19T13:28:25Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-29T02:36:36Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9960087433019259,
        0.9517520937782287,
        0.9199848953347076,
        0.9232576428109693,
        0.9663927476042984
      ],
      "excerpt": "This is a simple implementation of a fully convolutional neural network (FCN). The net is based on fully convolutional neural net described in the paper Fully Convolutional Networks for Semantic Segmentation.  The code is based on FCN implementation  by Sarath Shekkizhar with MIT license but replaces the VGG19 encoder with VGG16 encoder. The net is initialized using the pre-trained VGG16 model by Marvin Teichmann. \nAn improved version of this net in pytorch is given here \nThe input for the net is RGB image (Figure 1 right). \nThe net produces pixel-wise annotation as a matrix in the size of the image with the value of each pixel corresponding to its class (Figure 1 left). \nFigure 1) Semantic segmentation of image of liquid in glass vessel with FCN. Red=Glass, Blue=Liquid, White=Background \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8534339900983043
      ],
      "excerpt": "   and set the folder with ground truth labels for the validation set in Valid_Label_Dir \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8033131538446832
      ],
      "excerpt": "3) Set the number of classes in NUM_CLASSES \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sagieppel/Fully-convolutional-neural-network-FCN-for-semantic-segmentation-Tensorflow-implementation/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 44,
      "date": "Mon, 27 Dec 2021 12:52:13 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sagieppel/Fully-convolutional-neural-network-FCN-for-semantic-segmentation-Tensorflow-implementation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "sagieppel/Fully-convolutional-neural-network-FCN-for-semantic-segmentation-Tensorflow-implementation",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The net was tested on a dataset of annotated images of materials in glass vessels. \nThis dataset can be downloaded from [here](https://drive.google.com/file/d/0B6njwynsu2hXRFpmY1pOV1A4SFE/view?usp=sharing)\n\nMIT Scene Parsing Benchmark with over 20k pixel-wise annotated images can also be used for training and can be download from [here](http://sceneparsing.csail.mit.edu/)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1) Download the code from the repository.\n2) Download a pre-trained vgg16 net and put in the /Model_Zoo subfolder in the main code folder. A pre-trained vgg16 net can be download from here[https://drive.google.com/file/d/0B6njwynsu2hXZWcwX0FKTGJKRWs/view?usp=sharing] or from here [ftp://mi.eng.cam.ac.uk/pub/mttt2/models/vgg16.npy]\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9324941652044443,
        0.8406661968548131
      ],
      "excerpt": "In: TRAIN.py \n1) Set folder of the training images in Train_Image_Dir \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8179306821941431
      ],
      "excerpt": "4) Download a pretrained vgg16 model and put in model_path (should be done automatically if you have internet connection) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8069517904501458
      ],
      "excerpt": "6) If you are interested in using validation set during training, set UseValidationSet=True and the validation image folder to Valid_Image_Dir  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8009939330355835
      ],
      "excerpt": "1) Make sure you have trained model in logs_dir (See Train.py for creating trained model) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8116728028222793
      ],
      "excerpt": "4) Set  folder where you want the output annotated images to be saved to Pred_Dir \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8880636280088927,
        0.8009939330355835
      ],
      "excerpt": "In: Evaluate_Net_IOU.py \n1) Make sure you have trained model in logs_dir (See Train.py for creating trained model) \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/sagieppel/Fully-convolutional-neural-network-FCN-for-semantic-segmentation-Tensorflow-implementation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Fully convolutional neural network (FCN) for semantic segmentation with tensorflow.",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Fully-convolutional-neural-network-FCN-for-semantic-segmentation-Tensorflow-implementation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "sagieppel",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/sagieppel/Fully-convolutional-neural-network-FCN-for-semantic-segmentation-Tensorflow-implementation/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "sagieppel",
        "body": "1",
        "dateCreated": "2020-06-22T03:40:06Z",
        "datePublished": "2021-09-16T06:41:10Z",
        "html_url": "https://github.com/sagieppel/Fully-convolutional-neural-network-FCN-for-semantic-segmentation-Tensorflow-implementation/releases/tag/1",
        "name": "1.0",
        "tag_name": "1",
        "tarball_url": "https://api.github.com/repos/sagieppel/Fully-convolutional-neural-network-FCN-for-semantic-segmentation-Tensorflow-implementation/tarball/1",
        "url": "https://api.github.com/repos/sagieppel/Fully-convolutional-neural-network-FCN-for-semantic-segmentation-Tensorflow-implementation/releases/49650854",
        "zipball_url": "https://api.github.com/repos/sagieppel/Fully-convolutional-neural-network-FCN-for-semantic-segmentation-Tensorflow-implementation/zipball/1"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This network was run with Python 3.6  Anaconda package and Tensorflow 1.1. The training was done using Nvidia GTX 1080, on Linux Ubuntu 16.04.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 65,
      "date": "Mon, 27 Dec 2021 12:52:13 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The net was tested on a dataset of annotated images of materials in glass vessels. \nThis dataset can be downloaded from [here](https://drive.google.com/file/d/0B6njwynsu2hXRFpmY1pOV1A4SFE/view?usp=sharing)\n\nMIT Scene Parsing Benchmark with over 20k pixel-wise annotated images can also be used for training and can be download from [here](http://sceneparsing.csail.mit.edu/)\n\n",
      "technique": "Header extraction"
    }
  ]
}
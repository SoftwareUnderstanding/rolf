{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2001.09522"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{zhang2021tmn,\n    Author = {Zhang, Jieyu and Song, Xiangchen and Zeng, Ying and Chen, Jiaze and Shen, Jiaming and Mao, Yuning and Li, Lei},\n    Booktitle = {AAAI},\n    Title = {Taxonomy Completion via Triplet Matching Network},\n    Year = {2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.999657746408747,
        0.9880157813353811
      ],
      "excerpt": "Please cite the following work if you find the code useful. \nContact: Jieyu Zhang (jieyuz2@cs.washington.edu) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JieyuZ2/TMN",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-12-04T03:14:28Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-15T05:41:00Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8239202838038562
      ],
      "excerpt": "Finally, it saves the generated dataset (along with all initial node features) in one pickle file for fast loading next time. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016,
        0.9394449182630016
      ],
      "excerpt": "baselineex: baselines for taxonomy expansion; \ntmnex: TMN for taxonomy expansion; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "tmn: TMN for taxonomy completion; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9501331111708056,
        0.9968029537584643,
        0.9968029537584643,
        0.9968029537584643
      ],
      "excerpt": "We assume the input taxon list is of the following format: \nterm1 \\t embeddings of term1 \nterm2 \\t embeddings of term2 \nterm3 \\t embeddings of term3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9858384820243684
      ],
      "excerpt": "The embedding is space-sperated and of the same dimension of trained model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Code for the paper \"Taxonomy Completion via Triplet Matching Network\" AAAI 2021",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JieyuZ2/TMN/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Tue, 28 Dec 2021 11:40:22 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/JieyuZ2/TMN/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "JieyuZ2/TMN",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/JieyuZ2/TMN/main/build.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "For dataset used in our paper, you can directly download all input files below and skip this section.\n\nFor expanding new input taxonomies, you need to read this section and format your datasets accordingly.\n\n[**MAG-CS**](https://drive.google.com/file/d/11bxzqM8qznI-Qx1aAImd_JDBytw-_rjc/view?usp=sharing)\n\n[**MAG-Psy**](https://drive.google.com/file/d/1joeKI9qvtHl8VX9Dfs9uy2G3EUu0PLDs/view?usp=sharing)\n\n[**WordNet-Noun** ](https://drive.google.com/file/d/1S6ijwV7phg6ZlJbUgSZjPuJTcN98bWwe/view?usp=sharing)\n\n[**WordNet-Verb**](https://drive.google.com/file/d/13LqeaaPq6vS8ah-dgkJO2eWGp107eSfT/view?usp=sharing)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "From following page: [https://www.dgl.ai/pages/start.html](https://www.dgl.ai/pages/start.html)\n\n```\nconda install -c dglteam dgl-cuda10.0\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.892870354853123
      ],
      "excerpt": "You can generate your desired train/validation/test parition files by creating another 3 separated files (named <TAXONOMY_NAME>.terms.train, <TAXONOMY_NAME>.terms.validation, as well as <TAXONOMY_NAME>.terms.test) and puting them in the same directory as the above three required files. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8415347187714453
      ],
      "excerpt": "create a folder \"./data/{DATASET_NAME}\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python generate_dataset_binary.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.902349471256931
      ],
      "excerpt": "Then, if existing_partition is 0, it will generate a random train/validation/test partitions, otherwise, it will load the existing train/validation/test partition files. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8578866479276054
      ],
      "excerpt": "Write all the parameters in an config file, let's say ./config_files/config.universal.json, and then start training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8717399063841372
      ],
      "excerpt": "python train.py --config config_files/config.universal.json \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8676246386227282
      ],
      "excerpt": "python train.py --config config_files/config.universal.json --mm BIM --device 0 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/JieyuZ2/TMN/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Apache License 2.0",
      "url": "https://api.github.com/licenses/apache-2.0"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Triplet Matching Network",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "TMN",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "JieyuZ2",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/JieyuZ2/TMN/blob/main/README.md",
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "For example, BIM method on MAG-PSY:\n\n```\npython train.py --config config_files/MAG-PSY/config.test.baseline.json --mm BIM\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "For example, on MAG-PSY:\n\n```\npython train.py --config config_files/MAG-PSY/config.test.tmn.json --mm TMN\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 12,
      "date": "Tue, 28 Dec 2021 11:40:22 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Although we only use initial embedding as input in our paper, our code supports combinations of complicated encoders such as both GNN and LSTM.\n\nCheck out the `mode` parameter, there are three symbols for `mode`: `r`, `p` and `g`, representing initial embedding, LSTM and GNN respectively. \n\nIf you want to replace initial embedding with a GNN encoder, plz set `mode` to `g`; \n\nIf you want to use a combination of initial embedding and GNN encoder, plz set `mode` to `rg`, and then the initial embedding and embedding output by GNN encoder will be concatenated for calculating matching score; \n\nFor GNN encoder, we defer user to Jiaming's WWW'20 paper [TaxoExpan](https://arxiv.org/abs/2001.09522);\n\nFor LSTM encoder, we collect a path from root to the anchor node, and them use LSTM to encoder it to generate representation of anchor node;\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
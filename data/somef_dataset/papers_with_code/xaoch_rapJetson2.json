{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1812.08008",
      "https://arxiv.org/abs/1812.08008",
      "https://arxiv.org/abs/1812.08008",
      "https://arxiv.org/abs/1611.08050",
      "https://arxiv.org/abs/1704.07809",
      "https://arxiv.org/abs/1602.00134",
      "https://arxiv.org/abs/1812.08008"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please cite these papers in your publications if it helps your research (the face keypoint detector was trained using the procedure described in [Simon et al. 2017] for hands):\n\n    @inproceedings{cao2018openpose,\n      author = {Zhe Cao and Gines Hidalgo and Tomas Simon and Shih-En Wei and Yaser Sheikh},\n      booktitle = {arXiv preprint arXiv:1812.08008},\n      title = {Open{P}ose: realtime multi-person 2{D} pose estimation using {P}art {A}ffinity {F}ields},\n      year = {2018}\n    }\n\n    @inproceedings{cao2017realtime,\n      author = {Zhe Cao and Tomas Simon and Shih-En Wei and Yaser Sheikh},\n      booktitle = {CVPR},\n      title = {Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},\n      year = {2017}\n    }\n\n    @inproceedings{simon2017hand,\n      author = {Tomas Simon and Hanbyul Joo and Iain Matthews and Yaser Sheikh},\n      booktitle = {CVPR},\n      title = {Hand Keypoint Detection in Single Images using Multiview Bootstrapping},\n      year = {2017}\n    }\n\n    @inproceedings{wei2016cpm,\n      author = {Shih-En Wei and Varun Ramakrishna and Takeo Kanade and Yaser Sheikh},\n      booktitle = {CVPR},\n      title = {Convolutional pose machines},\n      year = {2016}\n    }\n\nLinks to the papers:\n\n- [OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields](https://arxiv.org/abs/1812.08008)\n- [Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields](https://arxiv.org/abs/1611.08050)\n- [Hand Keypoint Detection in Single Images using Multiview Bootstrapping](https://arxiv.org/abs/1704.07809)\n- [Convolutional Pose Machines](https://arxiv.org/abs/1602.00134)\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{wei2016cpm,\n  author = {Shih-En Wei and Varun Ramakrishna and Takeo Kanade and Yaser Sheikh},\n  booktitle = {CVPR},\n  title = {Convolutional pose machines},\n  year = {2016}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{simon2017hand,\n  author = {Tomas Simon and Hanbyul Joo and Iain Matthews and Yaser Sheikh},\n  booktitle = {CVPR},\n  title = {Hand Keypoint Detection in Single Images using Multiview Bootstrapping},\n  year = {2017}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{cao2017realtime,\n  author = {Zhe Cao and Tomas Simon and Shih-En Wei and Yaser Sheikh},\n  booktitle = {CVPR},\n  title = {Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},\n  year = {2017}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{cao2018openpose,\n  author = {Zhe Cao and Gines Hidalgo and Tomas Simon and Shih-En Wei and Yaser Sheikh},\n  booktitle = {arXiv preprint arXiv:1812.08008},\n  title = {Open{P}ose: realtime multi-person 2{D} pose estimation using {P}art {A}ffinity {F}ields},\n  year = {2018}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8601411888489422
      ],
      "excerpt": "Single-person tracking for further speed up or visual smoothing. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9773258620485573,
        0.9677640385174676
      ],
      "excerpt": "Training code included in the original CVPR 2017 GitHub repository. \nJan 2019: Unity plugin released! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8086054433170089,
        0.9318188835421087
      ],
      "excerpt": "Dec 2018: Foot dataset and new paper released! \nSep 2018: Experimental single-person tracker for further speed up or visual smoothing! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9601991828361272,
        0.9662067084056507
      ],
      "excerpt": "Jun 2018: OpenCL/AMD graphic card version released! \nJun 2018: Calibration toolbox released! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9737478833998597
      ],
      "excerpt": "    <sup><a href=\"http://tianyizhao.com\" target=\"_blank\">Tianyi Zhao</a> and <a href=\"https://www.gineshidalgo.com\" target=\"_blank\">Gines Hidalgo</a> testing their <a href=\"https://github.com/CMU-Perceptual-Computing-Lab/openpose_unity_plugin\" target=\"_blank\">OpenPose Unity Plugin</a></sup> \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xaoch/rapJetson2",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-28T21:04:03Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-03-28T21:11:34Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8131713502595892,
        0.8803032892520638,
        0.829764411921952
      ],
      "excerpt": "15 or 18 or 25-keypoint body/foot keypoint estimation. Running time invariant to number of detected people. \n2x21-keypoint hand keypoint estimation. Currently, running time depends on number of detected people. \n70-keypoint face keypoint estimation. Currently, running time depends on number of detected people. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9968029537584643,
        0.8651211561510381
      ],
      "excerpt": "Synchronization of Flir cameras handled. \nCompatible with Flir/Point Grey cameras, but provided C++ demos to add your custom input. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9258258971606813
      ],
      "excerpt": "Easy estimation of distortion, intrinsic, and extrinsic camera parameters. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8081919631325624
      ],
      "excerpt": "Jan 2019: Improved Python API released! Including body, face, hands, and all the functionality of the C++ API! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9563482207387877
      ],
      "excerpt": "For further details, check all released features and release notes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9670967175148483
      ],
      "excerpt": "    <sup>Testing the 3D Reconstruction Module of OpenPose</sup> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8529400837257711
      ],
      "excerpt": "Inference time comparison between the 3 available pose estimation libraries: OpenPose, Alpha-Pose (fast Pytorch version), and Mask R-CNN: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9260645045163415
      ],
      "excerpt": "This analysis was performed using the same images for each algorithm and a batch size of 1. Each analysis was repeated 1000 times and then averaged. This was all performed on a system with a Nvidia 1080 Ti and CUDA 8. Megvii (Face++) and MSRA GitHub repositories were excluded because they only provide pose estimation results given a cropped person. However, they suffer the same problem than Alpha-Pose and Mask R-CNN, their runtimes grow linearly with the number of people. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9186600130118575,
        0.962073559065041,
        0.8068207356313903,
        0.8209667310810166
      ],
      "excerpt": "Check the OpenPose Benchmark as well as some hints to speed up and/or reduce the memory requirements for OpenPose on doc/speed_up_openpose.md. \nCheck the foot dataset website and new OpenPose paper for more information. \nOur library is open source for research purposes, and we want to continuously improve it! So please, let us know if... \n... you find videos or images where OpenPose does not seems to work well. Feel free to send them to openposecmu@gmail.com (email only for failure cases!), we will use them to improve the quality of the algorithm! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8461871581041338
      ],
      "excerpt": "... you know how to speed up or improve any part of the library. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "rapJetson2",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xaoch/rapJetson2/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 09:17:33 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/xaoch/rapJetson2/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "xaoch/rapJetson2",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "**Windows portable version**: Simply download and use the latest version from the [Releases](https://github.com/CMU-Perceptual-Computing-Lab/openpose/releases) section.\n\nOtherwise, check [doc/installation.md](doc/installation.md) for instructions on how to build OpenPose from source.\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.888920789185811
      ],
      "excerpt": "OS: Ubuntu (14, 16), Windows (8, 10), Mac OSX, Nvidia TX2. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9525136576736464
      ],
      "excerpt": "CUDA (Nvidia GPU), OpenCL (AMD GPU), and CPU-only (no GPU) versions. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9314414163784198
      ],
      "excerpt": "Output: Basic image + keypoint display/saving (PNG, JPG, AVI, ...), keypoint saving (JSON, XML, YML, ...), and/or keypoints as array class. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8185784219166022
      ],
      "excerpt": "    <img src=\"doc/media/dance_foot.gif\", width=\"360\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8185784219166022
      ],
      "excerpt": "    <img src=\"doc/media/openpose3d.gif\", width=\"360\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8185784219166022,
        0.8185784219166022
      ],
      "excerpt": "    <img src=\"doc/media/pose_face.gif\", width=\"360\"> \n    <img src=\"doc/media/pose_hands.gif\", width=\"360\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8473463230273421,
        0.8473463230273421,
        0.8473463230273421
      ],
      "excerpt": "    <img src=\"doc/media/unity_main.png\", width=\"240\"> \n    <img src=\"doc/media/unity_body_foot.png\", width=\"240\"> \n    <img src=\"doc/media/unity_hand_face.png\", width=\"240\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8473463230273421
      ],
      "excerpt": "    <img src=\"doc/media/openpose_vs_competition.png\", width=\"360\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8606280910157142
      ],
      "excerpt": "Quick Start \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8135831848549969
      ],
      "excerpt": "Output (format, keypoint index ordering, etc.) in doc/output.md. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/xaoch/rapJetson2/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "# Features",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "rapJetson2",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "xaoch",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xaoch/rapJetson2/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 09:17:33 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Most users do not need the OpenPose C++/Python API, but can simply use the OpenPose Demo:\n\n- **OpenPose Demo**: To easily process images/video/webcam and display/save the results. See [doc/demo_overview.md](doc/demo_overview.md). E.g., run OpenPose in a video with:\n```\n#: Ubuntu\n./build/examples/openpose/openpose.bin --video examples/media/video.avi\n:: Windows - Portable Demo\nbin\\OpenPoseDemo.exe --video examples\\media\\video.avi\n```\n\n- **Calibration toolbox**: To easily calibrate your cameras for 3-D OpenPose or any other stereo vision task. See [doc/modules/calibration_module.md](doc/modules/calibration_module.md).\n\n- **OpenPose C++ API**: If you want to read a specific input, and/or add your custom post-processing function, and/or implement your own display/saving, check the C++ API tutorial on [examples/tutorial_api_cpp/](examples/tutorial_api_cpp/) and [doc/library_introduction.md](doc/library_introduction.md). You can create your custom code on [examples/user_code/](examples/user_code/) and quickly compile it with CMake when compiling the whole OpenPose project. Quickly **add your custom code**: See [examples/user_code/README.md](examples/user_code/README.md) for further details.\n\n- **OpenPose Python API**: Analogously to the C++ API, find the tutorial for the Python API on [examples/tutorial_api_python/](examples/tutorial_api_python/).\n\n- **Adding an extra module**: Check [doc/library_add_new_module.md](./doc/library_add_new_module.md).\n\n- **Standalone face or hand detector**:\n    - **Face** keypoint detection **without body** keypoint detection: If you want to speed it up (but also reduce amount of detected faces), check the OpenCV-face-detector approach in [doc/standalone_face_or_hand_keypoint_detector.md](doc/standalone_face_or_hand_keypoint_detector.md).\n    - **Use your own face/hand detector**: You can use the hand and/or face keypoint detectors with your own face or hand detectors, rather than using the body detector. E.g., useful for camera views at which the hands are visible but not the body (OpenPose detector would fail). See [doc/standalone_face_or_hand_keypoint_detector.md](doc/standalone_face_or_hand_keypoint_detector.md).\n\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
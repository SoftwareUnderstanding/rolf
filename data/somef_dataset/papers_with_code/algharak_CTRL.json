{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1909.05858\n\nBlog link: https://blog.einstein.ai/introducing-a-conditional-transformer-language-model-for-controllable-generation/\n\nThe code currently supports two functionalities:\n1. Generating from a trained model, two models are available for download - one with a sequence length of 256 and another with a sequence length of 512 -- they are trained with word-level vocabularies and through a sliding window approach can generate well beyond their trained sequence lengths. \n2. Source attribution - given a prompt, prints the perplexity of the prompt conditional on each domain control code (see Section 5 of the paper",
      "https://arxiv.org/abs/1810.03993",
      "https://arxiv.org/abs/1909.05858"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```\n@article{keskarCTRL2019,\n  title={{CTRL - A Conditional Transformer Language Model for Controllable Generation}},\n  author={Keskar, Nitish Shirish and McCann, Bryan and Varshney, Lav and Xiong, Caiming and Socher, Richard},\n  journal={arXiv preprint arXiv:1909.05858},\n  year={2019}\n}\n```\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{keskarCTRL2019,\n  title={{CTRL - A Conditional Transformer Language Model for Controllable Generation}},\n  author={Keskar, Nitish Shirish and McCann, Bryan and Varshney, Lav and Xiong, Caiming and Socher, Richard},\n  journal={arXiv preprint arXiv:1909.05858},\n  year={2019}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9222383658450612
      ],
      "excerpt": "Sep 25, 2019 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222383658450612
      ],
      "excerpt": "Sep 23, 2019 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9222383658450612
      ],
      "excerpt": "Sep 19, 2019 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999374932667748
      ],
      "excerpt": "How would a science fiction author turn your research into a dystopian story? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8512137605578415
      ],
      "excerpt": " But now he's gone, as if he'd never come. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8738983327489436
      ],
      "excerpt": "Running Title: <GENERATION_BEGINS> I just ran my first 5k in under 30 minutes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9594009889087535
      ],
      "excerpt": "Saving Title: <GENERATION_BEGINS> How to get a free credit report \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9725999786416071
      ],
      "excerpt": "Finance Title: <GENERATION_BEGINS> I have a question about my credit score. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8315930267747198
      ],
      "excerpt": "If so, how long should I wait? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9449187648369126
      ],
      "excerpt": "Il s'agit d'un mod\u00e8le de traitement du langage naturel qui vise \u00e0 g\u00e9n\u00e9rer un texte coh\u00e9rent et contr\u00f4lable. \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/algharak/CTRL/master/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/algharak/CTRL",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-14T23:14:02Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-24T09:21:38Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Large-scale language models show promising text generation capabilities, but\nusers cannot easily control this generation process. We release *CTRL*, a 1.6 billion-parameter conditional\ntransformer language model, trained to condition on control codes that specify\ndomain, subdomain, entities, relationships between entities, dates, and task-specific behavior. Control codes were derived from structure that naturally co-occurs with raw text, preserving the advantages of unsupervised learning while providing more explicit control over text generation.\n\nPaper link: https://arxiv.org/abs/1909.05858\n\nBlog link: https://blog.einstein.ai/introducing-a-conditional-transformer-language-model-for-controllable-generation/\n\nThe code currently supports two functionalities:\n1. Generating from a trained model, two models are available for download - one with a sequence length of 256 and another with a sequence length of 512 -- they are trained with word-level vocabularies and through a sliding window approach can generate well beyond their trained sequence lengths. \n2. Source attribution - given a prompt, prints the perplexity of the prompt conditional on each domain control code (see Section 5 of the paper). \n\nPlease refer to the argument flags for more details regarding the options available for either. \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "Authors: Nitish Shirish Keskar, Bryan McCann, Lav Varshney, Caiming Xiong, and Richard Socher \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9240935579255862,
        0.8451205949569142
      ],
      "excerpt": "We add the code to fine-tune the model on a custom dataset in the training_utils folder. Please refer to the README within the folder for details and example usage.  \nYou can get a 36-layer model from gs://sf-ctrl/seqlen256_36layers_v0.ckpt/; the generation of this model is markedly worse than the 48-layer (base) model but still quite coherent.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.866915164151002
      ],
      "excerpt": "You should now be able to run inference on K80/T4/P100/similar GPUs using the lower_memory branch. We quantized certain weights to fp16 which reduced memory usage. Simply clone the repo and git checkout lower_memory. Here is a collaboratory link that demonstrates this functionality: https://colab.research.google.com/drive/1hVveBQShDru1Mjnhe4C21uQv4A2eH1tV \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9986067859710608,
        0.922095945482642
      ],
      "excerpt": "We consulted extended members of the AI community in the responsible publication of this model. In particular, a preview of a Partnership on AI (PAI) project relating to AI research publication norms was considered prior to the release of this work. While this PAI project is as-yet unpublished, it is informed by companies, organizations, and people differently affected by artificial intelligence and presents key considerations to evaluate before publishing potentially high-impact research. \nThe questions referenced from the early draft of the PAI project included: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9138382479833693
      ],
      "excerpt": "What are the historical patterns of misuse or application in this area? How can the research be made more robust against  such misuse? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9962429803563092
      ],
      "excerpt": "The generations and attributions computed below have been generated using the 256 sequence length model. Comparable results can be obtained from the 512 version of the model as well. We demonstrate only a few of the functionalities, especially the control codes. For a complete list of the control codes, and how to use them, please refer to the paper. Note that &lt;GENERATION_BEGINS&gt; is only included for demonstrative purposes and is not actually generated by the model.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9890149553587586
      ],
      "excerpt": "Links In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9460928471090309,
        0.9463241182897989,
        0.9436088713776939,
        0.8880127648430008,
        0.8487804051686874,
        0.9721551532297017
      ],
      "excerpt": "The scientists were able to track down the unicorn population by analyzing their DNA. They found out that they are descended from an ancient species called the \u201cTapiri,\u201d which is believed to have been extinct for over 10,000 years. \nAccording to scientists, this discovery proves that there may be other undiscovered creatures on our planet. \n\u201cWe believe these animals could still exist and we hope to find them one day,\u201d said Dr. Carlos Jaramillo, director of the National Geographic Society\u2019s Center for Biodiversity Research at the University of Arizona. \nScientists also confirmed that the Unicorn Genome Project has already identified several genes associated with the animal\u2019s unique horn structure. \n\u201cThe genome project will help us understand how the animal evolved its horns so it can better protect itself against predators like jaguars or pumas.\u201d  \nResearchers say that if all goes well, the new genetic information should allow them to create a 3D model of the animal. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8598839358252564
      ],
      "excerpt": "Running it with --temperature 0.2 and --topk 5 yields: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9890149553587586,
        0.9302635146593599
      ],
      "excerpt": "Links In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English. \nThe scientists were able to track down and capture one of these unicorn herds as it roamed through the valley for several days. They then took DNA samples from each animal and compared them with other animals found throughout the region. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8311592271500134,
        0.9952397273107039
      ],
      "excerpt": "What they found is truly astounding. \nAccording to the scientists, there are approximately 50 different species of unicorn, all of which live on two continents \u2014 North America and South America... \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9748342493822121
      ],
      "excerpt": "Wikipedia Salesforce Inc. is &lt;GENERATION_BEGINS&gt; a software company that provides cloud computing and business management software. It was founded in 1999 by Marc Benioff as an online retailer of enterprise software, but it has since expanded into other areas such as e-commerce, customer relationship management, and digital media... \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9920305710891681
      ],
      "excerpt": " I bought this for my son who is a huge fan of the show. He was so excited to get it and when he opened it, we were all very disappointed. The quality of the product is terrible. It looks like something you would buy at a dollar store. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9314158904821562
      ],
      "excerpt": " This item arrived in poor condition. There are several scratches on the front cover as well as some other minor damage... \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8902271671701407
      ],
      "excerpt": " I bought this for my husband and he loves it. He has a small wrist so it is hard to find watches that fit him well. This one fits perfectly. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8615814497959978
      ],
      "excerpt": " It works well as an everyday watch. It's not very fancy or anything, just simple with no extra bells & whistles. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9980472987668473,
        0.9610802787904987
      ],
      "excerpt": " And sleep the slumber of a weary man. \n The morning sun is up, and shines on high; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8066620724351237
      ],
      "excerpt": " And, when at last I looked around, there stood \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8206970710978762
      ],
      "excerpt": " To seek for him, or call him back again. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8133628798192736
      ],
      "excerpt": "Edit: Thank you all so much for your kind words and advice. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9859749411506269
      ],
      "excerpt": " Text: I know that the reason why people lose weight is because they are eating less and burning more calories than their bodies need but how does this work for someone who doesn't have a lot of time or energy to exercise? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8638990271971508
      ],
      "excerpt": "EDIT: Thanks everyone for the responses! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8592163982380099,
        0.8241828857601063
      ],
      "excerpt": "Is there any way that you can just go online and fill out the forms yourself or do they require some sort of ID or something? \nEdit: Thanks everyone for your help! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8042508432589
      ],
      "excerpt": " Text: So I'm currently in the process of applying for an auto loan and I've been told that if you don't pay your bills on time then they will not approve you. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9672142054864924,
        0.8565067524351477
      ],
      "excerpt": "What is the best way to get out of debt without having to file bankruptcy? \nIs it possible to refinance my car loan? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8151309274428578
      ],
      "excerpt": "Questions Q: What is the capital of Australia? &lt;GENERATION_BEGINS&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.928229860568928
      ],
      "excerpt": "Translation English : This is a natural language processing model that aims to generate coherent text in a controllable manner. ; French : &lt;GENERATION_BEGINS&gt;  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.928229860568928
      ],
      "excerpt": "Translation English : This is a natural language processing model that aims to generate coherent text in a controllable manner. ; German : &lt;GENERATION_BEGINS&gt;  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9230627159256757
      ],
      "excerpt": "My landlord is suing me for unpaid rent \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8001977069715351
      ],
      "excerpt": "And then I saw him, the man in the mirror. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9575859305612243,
        0.9235826670001108
      ],
      "excerpt": "Anarchism is an anti-authoritarian political philosophy that rejects hierarchies deemed unjust and advocates their replacement with self-managed, self-governed societies based on voluntary, cooperative institutions. \nPROMPT: Anarchism is an anti-authoritarian political philosophy that rejects hierarchies deemed unjust and advocates their replacement with self-managed, self-governed societies based on voluntary, cooperative institutions. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Salesforce control",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/algharak/CTRL/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "(We hope to update this section frequently). \n\n1. Will you be releasing the training code and data?\n\n~~We plan to release the training code soon.~~\nPlease refer to the update on `Sep 25` for details on training code.\n\nWe will not be releasing the training data, but we will release tips and scripts related to data collection.\n\n2. Is a version of the model available in PyTorch? \n\n~~Not at the moment, but if we come across an equivalent implementation, we will update this section.~~\nPlease refer to the update on `Sep 23` for inference on PyTorch. \n\n3. The code errors out.\n\nMake sure that you have performed the patch as described above. If the error persists, please create a GitHub issue. \n\n4. The code generates non-sense irrespective of the prompt. \n\nMake sure that you have (a) provided the right `--model_dir` and that the folder actually exists and has the checkpoint, (b) provided a valid source code as the first token, and (c) tried generating with a simple prompt such as `Links I` or `Books From`. If the error persists, please create a GitHub issue. \n \n\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Thu, 23 Dec 2021 13:42:47 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/algharak/CTRL/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "algharak/CTRL",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/algharak/CTRL/master/Copy_of_Pre_training_BERT_from_scratch_with_cloud_TPU.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.946147945736064
      ],
      "excerpt": "The repo now supports (experimental) inference on PyTorch; Collaboratory: https://colab.research.google.com/drive/1nDh3ayRPJGK5ciPO2D3TFkYZFqclBWHY. Simply install PyTorch via pip install torch and run python pytorch_generation.py with the same flags as the base generation.py script except one exception: unlike the base version, here, the model_path requires the path to the .data file and not just the ckpt folder (see collaboratory for example). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8787870055595732
      ],
      "excerpt": "You should now be able to run inference on K80/T4/P100/similar GPUs using the lower_memory branch. We quantized certain weights to fp16 which reduced memory usage. Simply clone the repo and git checkout lower_memory. Here is a collaboratory link that demonstrates this functionality: https://colab.research.google.com/drive/1hVveBQShDru1Mjnhe4C21uQv4A2eH1tV \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8891401888405708
      ],
      "excerpt": "Get Involved \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8544662217519248
      ],
      "excerpt": "As a generate note, you don't have to use greedy sampling. You can switch to topk or nucleus through the appropriate argument flags.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8004105661440225
      ],
      "excerpt": " Text: I have been trying for months now and it seems like no one is willing to give me one. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8429377736321286
      ],
      "excerpt": "Two quick notes: (1) Unlike the base version, here, the model_path requires the path to the .data file and not just the ckpt folder (see collaboratory for example), (2) the first generation is slow because of overhead in setting up the model but the subsequent ones should be fast. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8003751159116907
      ],
      "excerpt": "Sample Generations \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "Es handelt sich um ein nat\u00fcrliches Textverarbeitungssystem, das auf eine einheitliche und kontrollierbare Erzeugung von Text abzielt. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/algharak/CTRL/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "BSD 3-Clause \"New\" or \"Revised\" License",
      "url": "https://api.github.com/licenses/bsd-3-clause"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "CTRL - A Conditional Transformer Language Model for Controllable Generation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "CTRL",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "algharak",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/algharak/CTRL/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Thu, 23 Dec 2021 13:42:47 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Here are the steps to get generating:\n\n1. Install the dependencies\n\nThis code relies on [TensorFlow 1.14](https://www.tensorflow.org/install) and [fastBPE](https://github.com/glample/fastBPE). \n\nTensorFlow can be installed via `pip install tensorflow[-gpu]==1.14`. fastBPE installation instructions can be found in the GitHub repository linked above. We highly recommend experimenting within a virtualenv or Docker image. \n\n**For inference on PyTorch, please see the update on `Sep 23` at the top of this README. If you use PyTorch, you can skip Step 2.**\n\n2. Patch the `/usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/keras.py` (or equivalent, if installed elsewhere) by running \n\n```patch -b <path_to_tensorflow_estimator_package>/python/estimator/keras.py estimator.patch```\n\nWe highly recommend experimenting within a virtualenv or Docker image since the workflow involves patching a TensorFlow file to support some custom functionality. This step is not optional; skipping this step will cause errors (irrespective of device).\n\nIf you run into OOM issues because of GPU memory exhaustion, please use the `lower_memory` branch. See the (Sep 19, 2019) update at the top of this README for details. \n\n\n3. Get the model files from `gs://sf-ctrl/seqlen256_v1.ckpt/` or `gs://sf-ctrl/seqlen512_v1.ckpt/`.\n\nA 36-layer model is also available at `gs://sf-ctrl/seqlen256_36layers_v0.ckpt/`. \n\nThe model architecture is identical for both checkpoints. The former is trained with lower training sequence length (256) while the latter is trained with a larger one (512). We plan to update the models (with the appropriate version tags) as we continue to train them longer and on more data. **Our current recommendation is to use the `256_v1` model unless you have a strong reason not to. If you have no preference for domain, `Links` is always a good first choice.**\n\n[With `gsutil` installed](https://cloud.google.com/storage/docs/gsutil_install), you can simply run `gsutil -m cp -r gs://sf-ctrl/seqlen256_v1.ckpt/ .` for copying the model checkpoint over. \n\nWithout `gsutil`, you can follow the route recommended @ https://github.com/salesforce/ctrl/issues/7#issuecomment-531303214\n\n4. Run the generation script `generation.py` or the source attribution script `source_attribution.py`. \n\nThe `generation.py` prompts the user to input text and then prints the continuation. \nThe `source_attribution.py` promps the user to input text and then prints a sorted list of domains and the perplexity of the text conditional on each individual domain. \n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Please create a GitHub issue if you have any questions, suggestions, requests or bug-reports. \nWe welcome PRs!\n",
      "technique": "Header extraction"
    }
  ]
}
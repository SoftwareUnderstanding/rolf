{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2110.11316",
      "https://arxiv.org/abs/2103.00020"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9698483046903941,
        0.8356013927728488
      ],
      "excerpt": "Fei Tang<sup>3</sup>, \nJohannes Lehner<sup>1</sup>, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9979639156924583,
        0.9354546553049569
      ],
      "excerpt": "<sup>1</sup> ELLIS Unit Linz and LIT AI Lab, Institute for Machine Learning, Johannes Kepler University Linz, Austria \n<sup>2</sup> Institute of Advanced Research in Artificial Intelligence (IARAI) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ml-jku/cloob",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-21T14:41:08Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-13T06:50:07Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9915942657630742,
        0.9783055872490868,
        0.8012190976555471
      ],
      "excerpt": "This repository contains the implemenation of CLOOB used to obtain the results reported in the paper. \nThe implementation is based on OpenCLIP, an open source implementation of OpenAI's CLIP. \nFor pre-training we use the two datasets supported by OpenCLIP, namely Conceptual Captions and YFCC. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9535472666929901,
        0.8986563137399658
      ],
      "excerpt": "For more information see YFCC100m Subset on OpenAI's github. \nIn the paper we report results on several downstream tasks.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9069888903323188,
        0.9565290244778073,
        0.9408406541217614,
        0.8315676521403478,
        0.8919328245887231
      ],
      "excerpt": "| Birdsnap      | This dataset contains images of North American bird species, however <br> our dataset is smaller than reported in CLIP as some samples are no longer available.            | Link        | Link  | \n| Country211    | This dataset was published in CLIP and is a small subset of the YFCC100m dataset. <br> It consists of photos that can be assigned to 211 countries via GPS coordinates. <br> For each country 200 photos are sampled for the training set and 100 for testing.            | Link | Link  | \n| Flowers102    | Images of 102 flower categories commonly occuring in the United Kingdom were collected.<br> Several classes are very similar and there is a large variation in scale, pose and lighting.            | Link          | Link  | \n| GTSRB         | This dataset was released for a challenge held at the IJCNN 2011. <br> The dataset contains images of german traffic signs from more than 40 classes.           | Link                | Link  | \n| Stanford Cars | This dataset contains images of 196 car models at the level of make, <br> model and year (e.g. Tesla Model S Sedan 2012).            | Link       | Link  | \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ml-jku/cloob/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Wed, 22 Dec 2021 00:20:49 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ml-jku/cloob/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "ml-jku/cloob",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/ml-jku/cloob/master/src/notebooks/zeroshot.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We provide an 'environment.yml' file to set up a conda environment with all required packages.\nRun the following command to clone the repository and create the environment.\n\n```bash\n#: Clone repository and swtich into the directory\ngit clone https://github.com/ml-jku/cloob\ncd cloob\n\n#: Create the environment and activate it\nconda env create --file environment.yml\nconda activate cloob\n\n#: Additionally, webdataset needs to be installed from git repo for pre-training on YFCC \npip install git+https://github.com/tmbdev/webdataset.git\n\n#: Add the directory to the PYTHONPATH environment variable\nexport PYTHONPATH=\"$PYTHONPATH:$PWD/src\"\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9217647081427385
      ],
      "excerpt": "First, download the Conceptual Captions URLs and then run the script gather_cc.py. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9289720337955271
      ],
      "excerpt": "python3 src/data/gather_cc.py path/to/Train_GCC-training.tsv path/to/Validation_GCC-1.1.0-Validation.tsv \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.803171614092741
      ],
      "excerpt": "| ImageNet      | This dataset spans 1000 object classes and contains 1,281,167 training images, <br> 50,000 validation images and 100,000 test images.            | Link                          | -  | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/ml-jku/cloob/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/ml-jku/cloob/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'CLOOB is licensed for use as follows:\\n\\n\"\"\"\\nCopyright (c) 2021, Institute for Machine Learning, Johannes Kepler University Linz\\n\\nPermission is hereby granted, free of charge, to any person obtaining\\na copy of this software and associated documentation files (the\\n\"Software\"), to deal in the Software without restriction, including\\nwithout limitation the rights to use, copy, modify, merge, publish,\\ndistribute, sublicense, and/or sell copies of the Software, and to\\npermit persons to whom the Software is furnished to do so, subject to\\nthe following conditions:\\n\\nThe above copyright notice and this permission notice shall be\\nincluded in all copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n\"\"\"\\n\\nOpenCLIP is licensed for use as follows:\\n\\n\"\"\"\\nCopyright (c) 2012-2021 Gabriel Ilharco, Mitchell Wortsman,\\nNicholas Carlini, Rohan Taori, Achal Dave, Vaishaal Shankar,\\nJohn Miller, Hongseok Namkoong, Hannaneh Hajishirzi, Ali Farhadi,\\nLudwig Schmidt\\n\\nPermission is hereby granted, free of charge, to any person obtaining\\na copy of this software and associated documentation files (the\\n\"Software\"), to deal in the Software without restriction, including\\nwithout limitation the rights to use, copy, modify, merge, publish,\\ndistribute, sublicense, and/or sell copies of the Software, and to\\npermit persons to whom the Software is furnished to do so, subject to\\nthe following conditions:\\n\\nThe above copyright notice and this permission notice shall be\\nincluded in all copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n\"\"\"'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "CLOOB: Modern Hopfield Networks with InfoLOOB Outperform CLIP",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "cloob",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "ml-jku",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/ml-jku/cloob/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 69,
      "date": "Wed, 22 Dec 2021 00:20:49 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "In the following there is an example command for pretraining on CC with an effective batch size of 512 when used on 4 GPUs.\n\n```bash\npython -u src/training/main.py \\\n--train-data=\"<dataset-dir>/conceptual_captions/Train-GCC-training_output.csv\" \\\n--val-data=\"<dataset-dir>/conceptual_captions/Validation_GCC-1.1.0-Validation_output.csv\" \\\n--path-data=\"<dataset-dir>/conceptual_captions\" \\\n--imagenet-val=\"<dataset-dir>/imagenet/val\" \\\n--warmup 20000 \\\n--batch-size=128 \\\n--lr=1e-3 \\\n--wd=0.1 \\\n--lr-scheduler=\"cosine-restarts\" \\\n--restart-cycles=10 \\\n--epochs=70 \\\n--method=\"cloob\" \\\n--init-inv-tau=30 \\\n--init-scale-hopfield=8 \\\n--workers=8 \\\n--model=\"RN50\" \\\n--dist-url=\"tcp://127.0.0.1:6100\" \\\n--batch-size-eval=512\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
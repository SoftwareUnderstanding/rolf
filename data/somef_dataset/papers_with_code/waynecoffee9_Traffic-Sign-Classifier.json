{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[image1]: ./examples/trainingQTY.jpg \"trainingQTY\"\n[image2]: ./examples/validQTY.jpg \"validQTY\"\n[image3]: ./examples/testQTY.jpg \"testQTY\"\n[image4]: ./examples/before_augmentation.jpg \"Before Augmentation\"\n[image5]: ./examples/augmentation.jpg \"Augmentation\"\n[image6]: ./examples/augmentQTY.jpg \"Total Training Set\"\n[image7]: ./examples/incep_overall.jpg \"Inception v4, 1\"\n[image8]: ./examples/my_incep.jpg \"My Inception v4 Net\"\n[image9]: ./examples/validation_recall.jpg \"Validation Recall\"\n[image10]: ./examples/validation_precision.jpg \"Validation Precision\"\n[image11]: ./examples/class_16_41.jpg \"Misclassification\"\n[image12]: ./examples/new.jpg \"New Images\"\n[image13]: ./examples/image1_prob.jpg \"Image Top 5 Probabilities\"\n[image14]: ./examples/image2_prob.jpg \"Image Top 5 Probabilities\"\n[image15]: ./examples/image3_prob.jpg \"Image Top 5 Probabilities\"\n[image16]: ./examples/image4_prob.jpg \"Image Top 5 Probabilities\"\n[image17]: ./examples/image5_prob.jpg \"Image Top 5 Probabilities\"\n[image18]: ./examples/layer_vis1.jpg \"Feature map 1\"\n[image19]: ./examples/layer_vis2.jpg \"Feature map 2\"\n[image20]: ./examples/layer_vis3.jpg \"Feature map 3\"\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9687893928548532
      ],
      "excerpt": "A typical inception v4 net consists of the following architecture (Reference: https://arxiv.org/pdf/1602.07261.pdf): \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/waynecoffee9/Traffic-Sign-Classifier",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-04-22T17:52:05Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-11-25T18:35:10Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "I used the pandas library to calculate summary statistics of the traffic\nsigns data set:\n\n* Number of training examples = 34799\n* Number of validation examples = 4410\n* Number of testing examples = 12630\n* Image data shape = (32, 32, 3)\n* Number of classes = 43\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9748956060950598
      ],
      "excerpt": "The goals / steps of this project are the following: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8412770035657463
      ],
      "excerpt": "* Explore, summarize and visualize the data set \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8784454581602327,
        0.9363581332277736
      ],
      "excerpt": "* Analyze the softmax probabilities of the new images \n* Summarize the results with a written report \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9473509545465431
      ],
      "excerpt": "Here is an exploratory visualization of the data set. Three bar charts show image counts by class in training, validation, and test sets.  One can see that image counts vary a lot among classes.  This can potentially negatively affect accuracies for classes with fewer images.  Data augmentation will be introduced later in the preprocessing stage. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9112888476326876,
        0.8233903760930993
      ],
      "excerpt": "Each block contains layers of convolutions and pooling in series and parallel.  Please refer to pages 3 and 4 in the reference PDF provided above for the detailed layers. \nMy inception model has fewer filter depths for faster training time.  See below: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9472473171155816,
        0.9852371139972933
      ],
      "excerpt": "To train the model, I used Adam Optimizer because it seems to be faster than traditional gradient descent.  There are also other benefits mentioned online (Reference: https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) \nThe batch size is 128, which is a typical value.  For number of epochs, I set it to 6.  Every time 6 epochs are done, the trained weights are saved.  I regenerate the whole data augmentation and continue until the accuracies have reached peaks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9588671331382078,
        0.8643046864425644,
        0.9539019777469071
      ],
      "excerpt": "For L2 regularization, beta is set to a fixed value of 0.001. \nFor dropout, I keep 80% of the weights during training. \nHere are the bar charts of the top 5 probabilities for 5 new images.  For all 5 images, they are very close to 100% certainty.  This means the model is really well trained. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9000063128789981
      ],
      "excerpt": "Image 2: Right-of-way \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.814196005395468
      ],
      "excerpt": "Image 5: Road work \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Design a deep neural network to classify German traffic signs",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/waynecoffee9/Traffic-Sign-Classifier/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "My final model results were:\n* training set accuracy of 99%+\n* validation set accuracy of 99%+\n* test set accuracy of 98%+\n\nIf a well known architecture was chosen:\n* Inception v4 was chosen for traffic sign classifier.\n* This is a very suitable architecture because it has a very high accuracy for classifier (general inception v4 can be used to classify 1000 classes), and it is quite efficient.\n* It can be concluded this model works very well because all 3 data sets have very high accuracies, which means the model is not under or over fitting (balanced variance and bias).\n\nAdditional visualization of the validation accuracy is analyzed to understand what works or not.\n\nBelow is the validation set recall and precision by class.  Note that class 16 has a low recall (false negative), meaning images from class 16 were predicted as some other clases.  In precision chart, class 41 has a low value (false positive).  It is likely that many class 16 images were misclassified as class 41.\n\n![alt text][image9]\n![alt text][image10]\n\nImages were pulled from classes 16 and 41 and quickly one can see that some class 16 images have red circular borders are quite faded so they could be similar to class 41 images.  Below are classes 16 (left) and 41 (right) sample images.\n\n![alt text][image11]\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 04:00:29 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/waynecoffee9/Traffic-Sign-Classifier/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "waynecoffee9/Traffic-Sign-Classifier",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/waynecoffee9/Traffic-Sign-Classifier/master/CarND-Traffic-Sign-Classifier-Project/Traffic_Sign_Classifier-inception.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/waynecoffee9/Traffic-Sign-Classifier/master/CarND-Traffic-Sign-Classifier-Project/set_git.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Here are the results of the prediction:\n\n| Image\t\t\t        |     Prediction\t        \t\t\t\t\t| \n|:---------------------:|:---------------------------------------------:| \n| Children crossing     | Children crossing  \t\t\t\t\t\t\t| \n| Right-of-way          | Right-of-way\t\t\t\t\t\t\t\t\t|\n| Priority road\t\t\t| Priority road\t\t\t\t\t\t\t\t\t|\n| Turn right ahead \t\t| Turn right ahead\t\t\t\t \t\t\t\t|\n| Road work \t\t\t| Road work         \t\t\t\t\t\t\t|\n\n\nThe model was able to correctly guess 5 of the 5 traffic signs, which gives an accuracy of 100%, which is close to 98% from the test set.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "My final model results were:\n* training set accuracy of 99%+\n* validation set accuracy of 99%+\n* test set accuracy of 98%+\n\nIf a well known architecture was chosen:\n* Inception v4 was chosen for traffic sign classifier.\n* This is a very suitable architecture because it has a very high accuracy for classifier (general inception v4 can be used to classify 1000 classes), and it is quite efficient.\n* It can be concluded this model works very well because all 3 data sets have very high accuracies, which means the model is not under or over fitting (balanced variance and bias).\n\nAdditional visualization of the validation accuracy is analyzed to understand what works or not.\n\nBelow is the validation set recall and precision by class.  Note that class 16 has a low recall (false negative), meaning images from class 16 were predicted as some other clases.  In precision chart, class 41 has a low value (false positive).  It is likely that many class 16 images were misclassified as class 41.\n\n![alt text][image9]\n![alt text][image10]\n\nImages were pulled from classes 16 and 41 and quickly one can see that some class 16 images have red circular borders are quite faded so they could be similar to class 41 images.  Below are classes 16 (left) and 41 (right) sample images.\n\n![alt text][image11]\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "First, I normalized all training images to have float32 from 0 to 1.  I found the accuracy increases faster than -1 to 1 during network training.\nThe matricies below simply show one random image before and after normalization.\n\nBefore normalization:\n\n[[51 36 45 ... 80 79 73]\n\n [47 34 38 ... 64 75 79]\n \n [45 32 38 ... 61 68 71]\n \n ...\n \n [43 38 34 ... 46 42 37]\n \n [44 36 31 ... 36 33 35]\n \n [41 36 38 ... 52 48 50]]\n \nAfter normalization:\n\n[[0.1849315  0.08219178 0.14383562 ... 0.38356164 0.37671232 0.33561644]\n\n [0.15753424 0.06849315 0.09589041 ... 0.2739726  0.34931508 0.37671232]\n \n [0.14383562 0.05479452 0.09589041 ... 0.25342464 0.30136988 0.3219178 ]\n \n ...\n \n [0.13013698 0.09589041 0.06849315 ... 0.15068494 0.12328767 0.0890411 ]\n \n [0.1369863  0.08219178 0.04794521 ... 0.08219178 0.06164384 0.07534247]\n \n [0.11643836 0.08219178 0.09589041 ... 0.19178082 0.16438356 0.1780822 ]]\n\n \n\nAs mentioned before, data augmentation is applied to even out image quantity difference among classes, and to include variations of same images.\n\n* sharpen or smoothing\n* random rotate image\n* random stretch/squeeze image \n* random darken partial image\n* random move image\n\nHere is an example of a traffic sign image before and after augmentation.  The image is stretched horizontally and partially darkened at the bottom.\n\n![alt text][image4] ![alt text][image5]\n\nWhen all training images are added up, the quantity shows:\n\n![alt text][image6]\n\nAs a last step, the training set is shuffled to remove any order.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "I used the pandas library to calculate summary statistics of the traffic\nsigns data set:\n\n* Number of training examples = 34799\n* Number of validation examples = 4410\n* Number of testing examples = 12630\n* Image data shape = (32, 32, 3)\n* Number of classes = 43\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "You're reading it! and here is a link to my [project code](https://github.com/waynecoffee9/Traffic-Sign-Classifier/blob/master/CarND-Traffic-Sign-Classifier-Project/Traffic_Sign_Classifier-inception.ipynb)\nIf you are unable to view it under github, use https://nbviewer.jupyter.org/ and paste the link to view.\n\n",
      "technique": "Header extraction"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8359299706379749,
        0.8359299706379749,
        0.8359299706379749
      ],
      "excerpt": "![alt text][image1] \n![alt text][image2] \n![alt text][image3] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][image7] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][image8] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8077605241713909
      ],
      "excerpt": "Here are the bar charts of the top 5 probabilities for 5 new images.  For all 5 images, they are very close to 100% certainty.  This means the model is really well trained. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][image13] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][image14] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][image15] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][image16] \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/waynecoffee9/Traffic-Sign-Classifier/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2016-2018 Udacity, Inc.\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "**Traffic Sign Recognition**",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Traffic-Sign-Classifier",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "waynecoffee9",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/waynecoffee9/Traffic-Sign-Classifier/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 04:00:29 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You're reading it! and here is a link to my [project code](https://github.com/waynecoffee9/Traffic-Sign-Classifier/blob/master/CarND-Traffic-Sign-Classifier-Project/Traffic_Sign_Classifier-inception.ipynb)\nIf you are unable to view it under github, use https://nbviewer.jupyter.org/ and paste the link to view.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Here are five German traffic signs that I found on the web:\n\n![alt text][image12]\n\nThe first image might be difficult to classify because ...\n\n",
      "technique": "Header extraction"
    }
  ],
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You're reading it! and here is a link to my [project code](https://github.com/waynecoffee9/Traffic-Sign-Classifier/blob/master/CarND-Traffic-Sign-Classifier-Project/Traffic_Sign_Classifier-inception.ipynb)\nIf you are unable to view it under github, use https://nbviewer.jupyter.org/ and paste the link to view.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "First, I normalized all training images to have float32 from 0 to 1.  I found the accuracy increases faster than -1 to 1 during network training.\nThe matricies below simply show one random image before and after normalization.\n\nBefore normalization:\n\n[[51 36 45 ... 80 79 73]\n\n [47 34 38 ... 64 75 79]\n \n [45 32 38 ... 61 68 71]\n \n ...\n \n [43 38 34 ... 46 42 37]\n \n [44 36 31 ... 36 33 35]\n \n [41 36 38 ... 52 48 50]]\n \nAfter normalization:\n\n[[0.1849315  0.08219178 0.14383562 ... 0.38356164 0.37671232 0.33561644]\n\n [0.15753424 0.06849315 0.09589041 ... 0.2739726  0.34931508 0.37671232]\n \n [0.14383562 0.05479452 0.09589041 ... 0.25342464 0.30136988 0.3219178 ]\n \n ...\n \n [0.13013698 0.09589041 0.06849315 ... 0.15068494 0.12328767 0.0890411 ]\n \n [0.1369863  0.08219178 0.04794521 ... 0.08219178 0.06164384 0.07534247]\n \n [0.11643836 0.08219178 0.09589041 ... 0.19178082 0.16438356 0.1780822 ]]\n\n \n\nAs mentioned before, data augmentation is applied to even out image quantity difference among classes, and to include variations of same images.\n\n* sharpen or smoothing\n* random rotate image\n* random stretch/squeeze image \n* random darken partial image\n* random move image\n\nHere is an example of a traffic sign image before and after augmentation.  The image is stretched horizontally and partially darkened at the bottom.\n\n![alt text][image4] ![alt text][image5]\n\nWhen all training images are added up, the quantity shows:\n\n![alt text][image6]\n\nAs a last step, the training set is shuffled to remove any order.\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "My final model results were:\n* training set accuracy of 99%+\n* validation set accuracy of 99%+\n* test set accuracy of 98%+\n\nIf a well known architecture was chosen:\n* Inception v4 was chosen for traffic sign classifier.\n* This is a very suitable architecture because it has a very high accuracy for classifier (general inception v4 can be used to classify 1000 classes), and it is quite efficient.\n* It can be concluded this model works very well because all 3 data sets have very high accuracies, which means the model is not under or over fitting (balanced variance and bias).\n\nAdditional visualization of the validation accuracy is analyzed to understand what works or not.\n\nBelow is the validation set recall and precision by class.  Note that class 16 has a low recall (false negative), meaning images from class 16 were predicted as some other clases.  In precision chart, class 41 has a low value (false positive).  It is likely that many class 16 images were misclassified as class 41.\n\n![alt text][image9]\n![alt text][image10]\n\nImages were pulled from classes 16 and 41 and quickly one can see that some class 16 images have red circular borders are quite faded so they could be similar to class 41 images.  Below are classes 16 (left) and 41 (right) sample images.\n\n![alt text][image11]\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Here are some of the visualized feature maps evaluated on the first new image (children crossing).  It seems some feature maps picked up the shape of the triangle.  Some feature maps picked up the shape of the human figures inside the triangle.  Some feature maps picked up the blue sky on the left.\n\n![alt text][image18]\n![alt text][image19]\n![alt text][image20]\n",
      "technique": "Header extraction"
    }
  ]
}
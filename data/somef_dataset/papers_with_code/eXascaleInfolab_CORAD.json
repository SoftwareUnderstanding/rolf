{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bibtex\n@inproceedings{DBLP:conf/bigdataconf/KhelifatiKC19,\n  author    = {Abdelouahab Khelifati and\n               Mourad Khayati and\n               Philippe Cudr{\\'{e}}{-}Mauroux},\n  title     = {{CORAD:} Correlation-Aware Compression of Massive Time Series using\n               Sparse Dictionary Coding},\n  booktitle = {2019 {IEEE} International Conference on Big Data (Big Data), Los Angeles,\n               CA, USA, December 9-12, 2019},\n  pages     = {2289--2298},\n  publisher = {{IEEE}},\n  year      = {2019},\n  url       = {https://doi.org/10.1109/BigData47090.2019.9005580},\n  doi       = {10.1109/BigData47090.2019.9005580},\n  timestamp = {Fri, 09 Apr 2021 17:11:11 +0200},\n  biburl    = {https://dblp.org/rec/conf/bigdataconf/KhelifatiKC19.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@inproceedings{DBLP:conf/bigdataconf/KhelifatiKC19,\n  author    = {Abdelouahab Khelifati and\n               Mourad Khayati and\n               Philippe Cudr{\\'{e}}{-}Mauroux},\n  title     = {{CORAD:} Correlation-Aware Compression of Massive Time Series using\n               Sparse Dictionary Coding},\n  booktitle = {2019 {IEEE} International Conference on Big Data (Big Data), Los Angeles,\n               CA, USA, December 9-12, 2019},\n  pages     = {2289--2298},\n  publisher = {{IEEE}},\n  year      = {2019},\n  url       = {https://doi.org/10.1109/BigData47090.2019.9005580},\n  doi       = {10.1109/BigData47090.2019.9005580},\n  timestamp = {Fri, 09 Apr 2021 17:11:11 +0200},\n  biburl    = {https://dblp.org/rec/conf/bigdataconf/KhelifatiKC19.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8669112007448144
      ],
      "excerpt": "Prerequisites | Build | Execution | Arguments  | Contributors | Citation \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/eXascaleInfolab/CORAD",
    "technique": "GitHub API"
  },
  "contributor": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Abdelouahab Khelifati (abdel@exascale.info).\n\n___\n\n",
      "technique": "Header extraction"
    }
  ],
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-12-05T13:06:40Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-19T12:03:43Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9939925844217601
      ],
      "excerpt": "CORAD is a new real-time technique to effectively compress time series streams. It relies on a dictionary-based technique that exploits the correlation across time series. In addition, CORAD allows to adjust the degree of accuracy that is acceptable depending on the use-case. Technical details can be found in our  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9114540221093517,
        0.941825735181643
      ],
      "excerpt": "Learn the dictionary learning \nSparse coding of the data  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8624386875419772
      ],
      "excerpt": "All the datasets used in the paper can be found here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9268791328690671
      ],
      "excerpt": " | --trick     | Length of the tricklets  | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "CORAD: Correlation-Aware Compression of Massive Time Series using Sparse Dictionary Coding",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/eXascaleInfolab/CORAD/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sun, 26 Dec 2021 04:38:27 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/eXascaleInfolab/CORAD/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "eXascaleInfolab/CORAD",
    "technique": "GitHub API"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/eXascaleInfolab/CORAD/master/install.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.9401296176580745
      ],
      "excerpt": "CORAD performs the following steps: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.997147271100732,
        0.9872695815759149
      ],
      "excerpt": "To install all the dependencies, run the following installation script: \n    $ sh install.sh \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8311934897413902
      ],
      "excerpt": "Sparse coding of the data  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8878456713567945
      ],
      "excerpt": "    $ python3 corad.py [arguments] \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/eXascaleInfolab/CORAD/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "CORAD: Correlation-Aware Compression of Massive Time Series using Sparse Dictionary Coding",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "CORAD",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "eXascaleInfolab",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/eXascaleInfolab/CORAD/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Install Python 3\n- Clone this repo: `git clone https://github.com/eXascaleInfolab/CORAD.git`\n\n___\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Sun, 26 Dec 2021 04:38:27 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Compress the *PigAirwayPressure* dataset with default parameters (trick=40, err=0.4, atoms=4)\n \n```bash \npython3 corad.py --dataset 'datasets/PigAirwayPressure_TEST.tsv'\n```\n\n2 . Compress the *PigAirwayPressure* dataset with a custom error threshold\n\n```bash \npython3 corad.py --dataset 'datasets/PigAirwayPressure_TEST.tsv' --err 0.1\n ```\n\n3 . Compress the *PigAirwayPressure* dataset with a custom error threshold and number of atoms\n\n```bash \npython3 corad.py --dataset 'datasets/PigAirwayPressure_TEST.tsv' --err 0.1 --atoms 6\n ```\n\n4 . Compress the *PigAirwayPressure* dataset with a custom tricklets length, error threshold and number of atoms \n\n```bash \npython3 corad.py --dataset 'datasets/PigAirwayPressure_TEST.tsv' --trick 20 --err 0.1 --atoms 6\n ```\n___\n\n",
      "technique": "Header extraction"
    }
  ]
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1602.07360. <br/>\nTo solve a classification task using CIFAR 10 dataset, which can be found here:  https://www.cs.toronto.edu/~kriz/cifar.html.\n<br/>\n### CIFAR10:\n-\t60000 32x32 color images in 10 classes, with 6000 images per class. \n-\t50000 training images and 10000 test images.\n-\tCLASSES = 'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'\n <p align=\"center\">\n  <img src=https://github.com/taltole/CIFAR10_SqueezeNet/blob/master/saves/cifar.png? width=\"350\" alt=\"accessibility text\">\n</p>\n \nThe dataset split among five training batches and one test batch, each with 10000 images.\nThe test batch contains exactly 1000 randomly-selected images from each class. \nThe training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. \n\n\u2022\tI placed in the notebook both options to load cifar10 dataset. One as I mentioned above and Keras\u2019 load dataset API with the same inputs, for your convenient.\n\u2022\tThe results are found in Squeezenet_Classifier notebook and main.py app for the inference code.\n\n## Squeeze Net:\nI tried two strategies to improve model performance, since CIFAR images are considerably smaller than ImageNet used for the original work. I created and focus the rest of this task on a smaller model for CIFAR-10 data set inspired by the 'Squeeze Net' architecture proposed by Forrest Iandola et al. (2016"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9711934052878692
      ],
      "excerpt": "In this work, I experiment with SqueezeNet neural network based on the following paper: https://arxiv.org/abs/1602.07360. <br/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9712110496275732
      ],
      "excerpt": "  <img src=https://github.com/taltole/CIFAR10_SqueezeNet/blob/master/saves/deploy.png? width=\"350\" title=\"hover text\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8649590026137133
      ],
      "excerpt": " ![alt text](https://github.com/[username]/[reponame]/blob/[branch]/image.jpg?raw=true) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/taltole/LiteNetwork_Image_Classification",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-02-15T21:37:18Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-07-01T08:36:42Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9282495138989924,
        0.9906977617744136,
        0.9330121046287803,
        0.8924066423715782,
        0.9591943328491963
      ],
      "excerpt": "\u2022   The results are found in Squeezenet_Classifier notebook and main.py app for the inference code. \nI tried two strategies to improve model performance, since CIFAR images are considerably smaller than ImageNet used for the original work. I created and focus the rest of this task on a smaller model for CIFAR-10 data set inspired by the 'Squeeze Net' architecture proposed by Forrest Iandola et al. (2016) and the work of Zac Hancock. I used similar components (fire module, etc.) and add some additional dropout and batch normalization layers to deal with overfitting and slow learning rate, respectively.</br> \nEssentially, the fire module implements a strategy wherein it minimizes the input parameters by utilizing a 'squeeze layer' that only uses 1x1 filters. After the 'squeeze layer' is a series of both 1x1 and 3x3 filters in the 'expand layer' where later the expand layer is then concatenated.  \nThe benefits from using 1x1 filters are as follow:</br> \nThe 1\u00d71 filter can be used to create a linear projection of a stack of feature maps. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9084891892559392
      ],
      "excerpt": "The projection created by a 1\u00d71 can also be used directly or be used to increase the number of feature maps in a model.</br> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9830761423236717,
        0.8497119442288055
      ],
      "excerpt": "Model summary and complete layers configuration found in Notebook. Number of layers were the same as in the Iandola paper only with 1/6 of number of parameters and with comparable performance. \nAfter tweaking layers architectures and adding batch normalization and few dropouts along the net, I reach best accuracy score using Adam optimizer. Train and test - cross entropy and accuracy were consistent along the epochs. This even improved after I added Keras\u2019 data generator for data augmentation which help with overfitting.  \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/taltole/CIFAR10_SqueezeNet/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 22 Dec 2021 11:03:27 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/taltole/LiteNetwork_Image_Classification/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "taltole/LiteNetwork_Image_Classification",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/taltole/CIFAR10_SqueezeNet/master/Sqeezenet_Classifier.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.854872486407625,
        0.8593108438234471
      ],
      "excerpt": "60000 32x32 color images in 10 classes, with 6000 images per class.  \n50000 training images and 10000 test images. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8913559372659194,
        0.8064859759326259,
        0.8254678267791145
      ],
      "excerpt": "The dataset split among five training batches and one test batch, each with 10000 images. \nThe test batch contains exactly 1000 randomly-selected images from each class.  \nThe training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.  \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/taltole/LiteNetwork_Image_Classification/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "HTML",
      "JavaScript",
      "CSS"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "CIFAR10 \u2013 SqueezeNet",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "LiteNetwork_Image_Classification",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "taltole",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/taltole/LiteNetwork_Image_Classification/blob/master/Readme.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 22 Dec 2021 11:03:27 GMT"
    },
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1810.04805",
      "https://arxiv.org/abs/1706.03762",
      "https://arxiv.org/abs/1810.04805",
      "https://arxiv.org/abs/1810.04805"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- For data [Politilact](https://www.politifact.com/) and [Media Charts](https://www.adfontesmedia.com/interactive-media-bias-chart/?v=402f03a963ba)\n- [Keras: The Python Deep Learning library](https://keras.io)\n- [A library of state-of-the-art pretrained models for Natural Language Processing](https://github.com/huggingface/pytorch-transformers)\n- [Pytorch Deep Learning framework](https://github.com/pytorch/pytorch)\n- [Pytorch BERT usage example](https://github.com/sugi-chan/custom_bert_pipeline)\n- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n- [BERT: Pre-training of Deep Bidirectional Transformers for Language\nUnderstanding](https://arxiv.org/abs/1810.04805)\n\n```bibtex\n@article{Wolf2019HuggingFacesTS,\n  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},\n  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R'emi Louf and Morgan Funtowicz and Jamie Brew},\n  journal={ArXiv},\n  year={2019},\n  volume={abs/1910.03771}\n}\n```\n```bibtex\n@article{devlin2018bert,\n  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},\n  journal={arXiv preprint arXiv:1810.04805},\n  year={2018}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{devlin2018bert,\n  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},\n  journal={arXiv preprint arXiv:1810.04805},\n  year={2018}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{Wolf2019HuggingFacesTS,\n  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},\n  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R'emi Louf and Morgan Funtowicz and Jamie Brew},\n  journal={ArXiv},\n  year={2019},\n  volume={abs/1910.03771}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8621912248789162
      ],
      "excerpt": "Triple Branch BERT Siamese Network for fake news classification on LIAR-PLUS dataset \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/abhilashreddys/Fake-News-Article",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-24T13:12:04Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-01-24T22:55:50Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9584551498585236,
        0.8681402992966811
      ],
      "excerpt": "- Some fake articles have relatively frequent use of terms seemingly intended to inspire outrage and the present writing skill in such articles is generally considerably lesser than in standard news. \n- Detecting fake news articles by analyzing patterns in writing of the articles. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9812954389642854
      ],
      "excerpt": "- With an Accuarcy of 80% on the custom dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9658759163497236
      ],
      "excerpt": "Data is collected by scraping the websites of popular news publishing sources. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9075200789573804
      ],
      "excerpt": "Some basic preprocessing is also done on the text collected from scraping websites. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9629270059130306
      ],
      "excerpt": "Used BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding with fine tuning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9643526733456125
      ],
      "excerpt": "BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering andlanguage inference, without substantial taskspecific architecture modifications. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9757996500198058
      ],
      "excerpt": "Trained only for 5 Epochs, trying to use a better model with more data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9159850700596901
      ],
      "excerpt": "Based on Click-Baits \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Detecting fake news articles by analyzing patterns in writing.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/abhilashreddys/Fake-News-Article/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Thu, 30 Dec 2021 02:53:18 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/abhilashreddys/Fake-News-Article/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "abhilashreddys/Fake-News-Article",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/abhilashreddys/Fake-News-Article/master/fake_article.ipynb",
      "https://raw.githubusercontent.com/abhilashreddys/Fake-News-Article/master/transfrom_spam.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Install these libraries/packages.\n\n```shell\n$ pip3 install pandas numpy scikit-learn bs4\n$ pip3 install torch\n$ pip3 install keras\n$ pip3 install pytorch_pretrained_bert\n$ pip3 install transformers\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- All the `code` required to get started.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8745923097412203
      ],
      "excerpt": "Clone this repo to your local machine using https://github.com/abhilashreddys/Fake-News-Article.git \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "$ python3 scrape_politifact.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9336801098518991
      ],
      "excerpt": "$ python3 scrape_media.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/abhilashreddys/Fake-News-Article/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Abhilash Reddy\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Fake-News-Article",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Fake-News-Article",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "abhilashreddys",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/abhilashreddys/Fake-News-Article/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 8,
      "date": "Thu, 30 Dec 2021 02:53:18 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "bert",
      "bert-embeddings",
      "pytorch",
      "python",
      "beautifulsoup",
      "beautifulsoup4",
      "scraping-websites",
      "fake-news",
      "fake-content",
      "transformer",
      "huggingface",
      "fake-articles",
      "media-charts",
      "transformers",
      "analyzing-patterns",
      "fakenews",
      "fake-news-challenge",
      "fakenewsdetection"
    ],
    "technique": "GitHub API"
  }
}
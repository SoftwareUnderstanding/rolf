{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1910.01108\n\nThe Image-Feature Extractor consists of a **ResNet34**-Architecture after *He et al. (2015",
      "https://arxiv.org/abs/1512.03385\n\nThe models were trained on *20%* of the original Fakeddit benchmark dataset and the classification\ntask is to process the Reddit-Posts, respectively the various modalities according to aforementioned\nmodel variant, and correctly classify input posts into the following classes:\n\n- **Authentic news content**\n- **Satire / Parody**\n- **Content with false connection**\n- **Imposter content**\n- **Manipulated content**\n- **Misleading content**,\n\nwheres authentic news content and satire/parody is not to be understood as Fake News per se in order\nto guard freedom of speech. Further, Fake News is to be defined in the most concise definition after\n*Alcott and Gentzkow (2017",
      "https://arxiv.org/abs/1911.03854 (*Nakamura et al. (2020"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "~~~~\n@masterthesis{\n  title={Explanatory detection of fake News with deep learning},\n  author={Enzo Muschik},\n  year={2021}\n}\n~~~~\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@masterthesis{\n  title={Explanatory detection of fake News with deep learning},\n  author={Enzo Muschik},\n  year={2021}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9996600274001227
      ],
      "excerpt": "Title-Image-DistilFND: Processing post title and associated image of Reddit-Post into multi-modale feature representation  for detecting subtypes of Fake News \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8617007912871667
      ],
      "excerpt": "Alcott and Gentzkow (2017) as \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8841736981600854
      ],
      "excerpt": "Multi-modal feature representation yields significantly better results \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8592915573379081
      ],
      "excerpt": "Multi-modal feature processing significantyl improves accuracy performance \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9921718602107769
      ],
      "excerpt": "Singular-visual and multi-modal variants yield poorer performance results \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9999485869650548
      ],
      "excerpt": "https://arxiv.org/abs/1911.03854 (Nakamura et al. (2020) research paper) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/enzomuschik/distilfnd",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-14T08:50:51Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-14T06:02:51Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9412541205395693
      ],
      "excerpt": "Explanatory detection of fake news with deep learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.937458077774607
      ],
      "excerpt": "more or less to high predcticion/classification accuracy scores. In total 4 variants of the model wear developed: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9802393137489666
      ],
      "excerpt": "Image-DistilFND: Processing only image data of Reddit-Posts to detect subtypes of Fake News \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8513856267685004,
        0.9344974814542708,
        0.8975384776543676
      ],
      "excerpt": "The models were trained on 20% of the original Fakeddit benchmark dataset and the classification \ntask is to process the Reddit-Posts, respectively the various modalities according to aforementioned \nmodel variant, and correctly classify input posts into the following classes: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9567588029116127
      ],
      "excerpt": "Content with false connection \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.878161412426856,
        0.9301873832735741
      ],
      "excerpt": "wheres authentic news content and satire/parody is not to be understood as Fake News per se in order \nto guard freedom of speech. Further, Fake News is to be defined in the most concise definition after \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.895605821318169
      ],
      "excerpt": "\"[...] news articles that are intentionally and verifiably false, and could mislead readers.\" (Alcott and Gentzkow (2017)*, S. 213) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.834871419859563,
        0.9841357349353588
      ],
      "excerpt": "model to perform fine-grained categorical Fake News detection. It contains over 700.000 multi-modal sample Reddit-Posts \nincluding image data and over 10 Mio. records of comment data. All model variants were trained on 20% of the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8624620277141457,
        0.8328787890973361
      ],
      "excerpt": "and stratified in order to maintain the proportional distribution per class of the original dataset. Eeventually, 80% \nof the split data was used for training and 10% was used for each validation and testing. All models were trained \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9004890178757857
      ],
      "excerpt": "The models classification accuracy is steadily increased, when various modalitie are integrated in a complementary fashion. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9759068907924788,
        0.9186928086440467,
        0.9568718783193787,
        0.8915123737339726,
        0.9282936236587919
      ],
      "excerpt": "reaches an accuracy of 72,85%, indicating that when it comes to identifying the subtypes of fake news in a multi classification \nproblem, textual content inherits more dominant features. The multi-modal feature extraction by Title-Image-DistilFND the test results significantly and yields an overall performance of optimizes 81,82,% accuracy. Only the DistilFND model, which combines \npost title, associated image and first 5 user comments into a comprehensive feature representation is superior to all aformentioned model variants with an overall accuracy performance of 87,97% on the test data split. Thus, providing reach \ninformation by integration of multi-modal and commentary features yields best results. \nTextual feature are the dominant features to base a classification decision \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8958240688956418
      ],
      "excerpt": "Combination with comment features significantly improves detection performance \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9853735225448376,
        0.9609981048676861,
        0.9059605565894607
      ],
      "excerpt": "Integration of comment features yields even better accuracy results and is superior to singular-modal and multi-modal variants \nIt can be assumed that by providing reach multi-modal and commentary information, DistilFND is able to grasp the underlying context and meaning of satire and parody articles \nSingular modal variants yield poor accuracy results due to lack of ability to understanding the context \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9610795205894346,
        0.9720132023159236,
        0.9742382655909423,
        0.8103084481850888,
        0.9904491355703255,
        0.9372538787637085
      ],
      "excerpt": "Best performance is again reached by integrating user generated comment data providing the most comprehensible feature space and giving the model enough information to understand the underlying context \nThis subtype of Fake News is highly dificult to detect due to only subtle differences to authentic content \nThis is intuitively understandable, as it is this content's main target to perfectly imitate authentic news content in order to manipulated and generate attention \nSingular-modal and multi-modal model various are reaching inferior and not reliable results \nOnly the complete DistilFND model is able to grasp the subtle differences and detect imposter content with moderate to acceptable accuracy performance \nIt is assumed that social media user arn others in the comment section of a post, that a given post is most probably fake and imposter content. Furher, social media user are reacting rapidly, meaning within the first 5 comments per post \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9033604194914727,
        0.9002838832321828
      ],
      "excerpt": "The Image-DistilFND reaches extremely high accuracy scores above 90%. Thus, when it comes to manipulated content, authors and publishers mainly focus on altering the visual content, e.g. attached images and videos \nAdding the comment information to the feature spaces optimizes the overall accuracy performance and yields the best results, yet marginally \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.973985898380537
      ],
      "excerpt": "Only integration of comment information is able to up the overall accuracy performance \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.97640225014506,
        0.898786082122111
      ],
      "excerpt": "On manipulated content specifically visual content features are to be preferred as manipulations within the context of Fake News tend to focus on the visual content, e.g. images and videos. Only combination with comment information is able to marginally increase overally accuracy performance \nAcross all classes, DistilFND yields best accuracy results indicating that the highest capability to detect subtypes of Fake News is by complementarily integrating various multi-modal features such as post title, associated visuals like images and videos \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9113343678169233,
        0.8250030651482033
      ],
      "excerpt": "Additionally, I have developed a DistilFND web application, which loads the highest perofming DistilFND model in the backend \nand gives users the opportunity to interactively predict a total of 12 sample Reddit-Posts (2 per defined class). Modules, application python scripts, batch file for easy launching and the requirements.txt file to install needed modules into your python environment are provided. All source code is made available for further development and research and is provided within the guidlines of the MIT license agreement. Source code for the web application and background information is provided here: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9953369449210296,
        0.918440432242317
      ],
      "excerpt": "The web application is supposed to provde a comprehensible tool for social media users to understand the automatic prediction process of DistilFND, comparing results with own individual thoughts and predictions and make the overall decision process and prediction output transparent and comprehensible for human users. This application is intended for experts and regular social media users alike and has the goal to increas media awareness for Fake News generally and the subtypes of Fake News specifically. \nThe application leverages visualization for transparency and is an initial step towards explaining DistilFND's prediction outputs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Multi-modal categorical fake news detector DistilFND trained on Fakeddit benchmark dataset to classify content within the 7 types of mis- and disinformation after Wardle (2017).",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/enzomuschik/distilfnd/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Wed, 29 Dec 2021 20:14:29 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/enzomuschik/distilfnd/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "enzomuschik/distilfnd",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/enzomuschik/distilfnd/main/distilfnd.ipynb",
      "https://raw.githubusercontent.com/enzomuschik/distilfnd/main/title_image_distilfnd.ipynb",
      "https://raw.githubusercontent.com/enzomuschik/distilfnd/main/fakeddit_data_analysis.ipynb",
      "https://raw.githubusercontent.com/enzomuschik/distilfnd/main/title_distilfnd.ipynb",
      "https://raw.githubusercontent.com/enzomuschik/distilfnd/main/image_distilfnd.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/enzomuschik/distilfnd/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "Batchfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Enzo Muschik\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "DistilFND (Distilled Fake News Detector)",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "distilfnd",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "enzomuschik",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/enzomuschik/distilfnd/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Wed, 29 Dec 2021 20:14:29 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "~~~~\n@masterthesis{\n  title={Explanatory detection of fake News with deep learning},\n  author={Enzo Muschik},\n  year={2021}\n}\n~~~~\n\n",
      "technique": "Header extraction"
    }
  ]
}
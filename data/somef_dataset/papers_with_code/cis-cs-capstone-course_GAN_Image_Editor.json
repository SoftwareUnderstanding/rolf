{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1711.1067\n\n### Style GAN\n\nThe StyleGAN implementation for the GAN Image Editor is built on Impersonator. Although there are two additional capabilities of Impersonator (Human Motion Imitaiton and Novel View Synthesis"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Capstone-Projects-2019-Fall/GAN_Image_Editor",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-10-18T14:58:41Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-06-08T22:50:44Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9943604361151134
      ],
      "excerpt": "GAN Image Editor is a responsive web application that utilizes the ability of GAN (Generative Adversarial Networks) to edit and generate images in real time. A user can upload an image (given that it fits certain parameters) and have the ability to alter specific features of that image. Currently, the web app showcases three types of image alteration that use GAN technology: facial editing, clothing style swapping, and image quality enhancement. These features give the user various methods of customization and allows them to reach their goals without the need of any image editing software or expertise. The website also allows users to register an account and be able to store their images on the web server. This way, users can view their uploaded images alongside multiple edited versions of those same images without needing to store them locally or use any image viewing program. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9508757908357481
      ],
      "excerpt": "Edit up to 13 pretrained features in a face image.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8044243092332747,
        0.9127129976412102
      ],
      "excerpt": "Control the intensiy of each feature you choose to edit.  \nEdit your own custom image using facial GAN. Model can function on any input size of image.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.830314960872555,
        0.9405300721894837,
        0.802908842336701,
        0.86267597546088
      ],
      "excerpt": "Pre-trained model resulting in image of size 384x384 \nCustom model resulting in miage of size 128x128 \nLow resolution to high resolution \nAn image of low resolution will be converted to higher resolution \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8631644219227838
      ],
      "excerpt": "When running StyleGAN multiple times in a row, it may not update but instead show the last generated image.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9683746755989637
      ],
      "excerpt": "url, a string that specifies the url for the database. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8986153143807218,
        0.8314208932999632
      ],
      "excerpt": "user_table and image_table, database tables needed for the server requests. More specifics can be found in other documentation. \nPort numbers need to be changed in the following files to match what the Flask server is listening to: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8263118244658985
      ],
      "excerpt": "File paths also need to be changed to correspond to different deployment environments. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9391427386165165
      ],
      "excerpt": "In order to run the facial GAN, the website should be set up initially to see bugs and error message. See web section to determine changes that need to be made there.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9684915575131307
      ],
      "excerpt": "Dependies for the facial GAN: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.839618576896027
      ],
      "excerpt": "Once dependencies are installed, type the following command in your development environment in order to start to flask server for facial GAN. Default port that the flask server for facial app is run on is 7001. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8741319926540612
      ],
      "excerpt": "The facial GAN allows you to edit the attribute intensity and appearence in a given portrait image.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9214282009179459
      ],
      "excerpt": "The facial GAN currently supports a set of 13 selectable attributes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9983736606788884
      ],
      "excerpt": "The StyleGAN implementation for the GAN Image Editor is built on Impersonator. Although there are two additional capabilities of Impersonator (Human Motion Imitaiton and Novel View Synthesis), the scope of this project is limited to the Appearance Transfer due to time and resource constraints. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/cis-cs-capstone-course/GAN_Image_Editor/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Mon, 27 Dec 2021 11:36:35 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Capstone-Projects-2019-Fall/GAN_Image_Editor/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Capstone-Projects-2019-Fall/GAN_Image_Editor",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/cis-cs-capstone-course/GAN_Image_Editor/master/gan_models/style_gan/impersonator/impersonator.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/cis-cs-capstone-course/GAN_Image_Editor/master/gan_models/quality_gan/test_SRGAN.sh",
      "https://raw.githubusercontent.com/cis-cs-capstone-course/GAN_Image_Editor/master/gan_models/quality_gan/inference_SRGAN.sh",
      "https://raw.githubusercontent.com/cis-cs-capstone-course/GAN_Image_Editor/master/gan_models/quality_gan/train_SRResnet.sh",
      "https://raw.githubusercontent.com/cis-cs-capstone-course/GAN_Image_Editor/master/gan_models/quality_gan/train_SRGAN.sh",
      "https://raw.githubusercontent.com/cis-cs-capstone-course/GAN_Image_Editor/master/gan_models/quality_gan/customInference_SRGAN.sh",
      "https://raw.githubusercontent.com/cis-cs-capstone-course/GAN_Image_Editor/master/gan_models/style_gan/impersonator/scripts/train_iPER_Place2.sh",
      "https://raw.githubusercontent.com/cis-cs-capstone-course/GAN_Image_Editor/master/gan_models/style_gan/impersonator/scripts/train_iPER.sh",
      "https://raw.githubusercontent.com/cis-cs-capstone-course/GAN_Image_Editor/master/gan_models/style_gan/impersonator/scripts/motion_imitation/runner.sh",
      "https://raw.githubusercontent.com/cis-cs-capstone-course/GAN_Image_Editor/master/gan_models/style_gan/impersonator/scripts/motion_imitation/template.sh",
      "https://raw.githubusercontent.com/cis-cs-capstone-course/GAN_Image_Editor/master/gan_models/style_gan/impersonator/scripts/appearance_transfer/runner.sh",
      "https://raw.githubusercontent.com/cis-cs-capstone-course/GAN_Image_Editor/master/gan_models/style_gan/impersonator/scripts/appearance_transfer/template.sh",
      "https://raw.githubusercontent.com/cis-cs-capstone-course/GAN_Image_Editor/master/gan_models/style_gan/impersonator/scripts/novel_view_synthesis/runner.sh",
      "https://raw.githubusercontent.com/cis-cs-capstone-course/GAN_Image_Editor/master/gan_models/style_gan/impersonator/scripts/novel_view_synthesis/template.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Start up the server by running:\n```\n . /opt/anaconda3/etc/profile.d/conda.sh; conda activate tensorflow_gpuenv   \npython myra_app.py\n\nReferences:\nhttps://github.com/brade31919/SRGAN-tensorflow\nhttps://arxiv.org/pdf/1609.04802.pdf\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- Start up the server by running:\n```\n. /opt/anaconda3/etc/profile.d/conda.sh   \nconda activate swapnet\ncd impersonator\npython charles_app.py\n```\n\n- This allows the webpage to call the Style GAN and let it run impersonator whenever called.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8309730602296965
      ],
      "excerpt": "Provide 2 seperate models that can run. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8293727758973368
      ],
      "excerpt": "Download the gan_models folder and store it on the server that you would like to host it on.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8886557968622529
      ],
      "excerpt": "Python 2.7 or 3.6 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8843909667489986
      ],
      "excerpt": "Optional: CUDA Toolkit can be installed to improve training time if using nvidia.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9289432350532367
      ],
      "excerpt": "Once dependencies are installed, type the following command in your development environment in order to start to flask server for facial GAN. Default port that the flask server for facial app is run on is 7001. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8773869995792117
      ],
      "excerpt": "In order to run the facial GAN without the website, you can utilize the following command.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8144110497354211
      ],
      "excerpt": "- The above command only requires the experiment name and test attribute as mandatory, the rest will take default parameters.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.849979579904421
      ],
      "excerpt": "Run the command shown above and replace EXPERIMENT NAME with the name of the folder in ./output. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9358830466959446
      ],
      "excerpt": "Download the VGG19 weights from the http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9246227682586091
      ],
      "excerpt": "python facial_app.py \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9205983922875082
      ],
      "excerpt": "python test_slide1.py --experiement_name [EXPERIMENT NAME] --test_att [TEST ATTRIBUTE] --test_min [TEST MIN] --test_max [TEST MAX] --n_slide [NUM INTENSITY] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8312803884451223,
        0.8526852655376603
      ],
      "excerpt": "Simply download and unzip folder to GAN_Image_Editor/gan_models/facial_editing_gan/output \nRun the command shown above and replace EXPERIMENT NAME with the name of the folder in ./output. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8690931288212675
      ],
      "excerpt": "Download pre-trained model here: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.851070147339342
      ],
      "excerpt": "    <img src='gan_models/style_gan/impersonator/assets/visuals/motion/Sweaters-id_0000088807_4_full.jpg' width=\"135\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8388403574746747
      ],
      "excerpt": "    <img src='gan_models/style_gan/impersonator/assets/visuals/appearance/Sweaters-id_0000337302_4_full.jpg' width=\"135\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8457393585803692
      ],
      "excerpt": "    <img src='gan_models/style_gan/impersonator/assets/visuals/novel/Jackets_Vests-id_0000071603_4_full.jpg' width=\"135\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.851070147339342
      ],
      "excerpt": "    <img src='gan_models/style_gan/impersonator/assets/visuals/motion/009_5_1_000.jpg' width=\"135\"/>     \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8388403574746747
      ],
      "excerpt": "    <img src='gan_models/style_gan/impersonator/assets/visuals/appearance/001_19_1_000.jpg' width=\"135\"/> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8457393585803692
      ],
      "excerpt": "    <img src='gan_models/style_gan/impersonator/assets/visuals/novel/novel_3.jpg' width=\"135\"/> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Capstone-Projects-2019-Fall/GAN_Image_Editor/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "JavaScript",
      "CSS",
      "Java",
      "Shell",
      "HTML",
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2017 Hiroharu Kato\\nCopyright (c) 2018 Nikos Kolotouros\\nA PyTorch implementation of Neural 3D Mesh Renderer (https://github.com/hiroharu-kato/neural_renderer)\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "GAN Image Editor",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "GAN_Image_Editor",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Capstone-Projects-2019-Fall",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Capstone-Projects-2019-Fall/GAN_Image_Editor/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Mon, 27 Dec 2021 11:36:35 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- A conda virtual environment export was set up with a majority of the depenedencies in an all-in-one place. Try this first:\n\n```\n. /opt/anaconda3/etc/profile.d/conda.sh   \n\ncd impersonator\nconda env create\nconda activate swapnet\n```\n\n- Set up `Impersonator` and make sure it is functioning before proceeding. if impersonator runs into any issues on the GPU machine, go to the `gan_models/style_gan/impersonator/readme.md` for further instructions on the set up.\n\n- Also be sure you are running the virtual environment every time you are using impersonator by running:\n\n```\n. /opt/anaconda3/etc/profile.d/conda.sh   \nconda activate swapnet\n```\n\n- The training dataset can be downloaded from [OneDrive](https://onedrive.live.com/?authkey=%21AJL_NAQMkdXGPlA&id=3705E349C336415F%2188052&cid=3705E349C336415F). This should include `PER_256_video_release.zip`, `smpls.zip`, `train.txt`, and `val.txt`.\n\n- The files should be moved and extracted to `impersonator/data/iPER`.\nPlease check `GAN_Image_Editor/gan_models/style_gan/impersonator/readme.md` and `GAN_Image_Editor/gan_models/style_gan/impersonator/doc/train.md` for more details on setting up the pretrained models and the dataset.\n\n\n",
      "technique": "Header extraction"
    }
  ]
}
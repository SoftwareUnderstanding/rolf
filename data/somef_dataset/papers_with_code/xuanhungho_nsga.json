{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Code heavily inspired and modified from [pymoo](https://github.com/msu-coinlab/pymoo), [DARTS](https://github.com/quark0/darts#requirements) and [pytorch-cifar10](https://github.com/kuangliu/pytorch-cifar). \n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1810.03522",
      "https://arxiv.org/abs/1802.01548",
      "https://arxiv.org/abs/1810.03522*\n\n![overview](https://github.com/ianwhale/nsga-net/blob/beta/img/overview_redraw.png  \"Overview of NSGA-Net\")\n\n## Requirements\n``` \nPython >= 3.6.8, PyTorch >= 1.0.1.post2, torchvision >= 0.2.2, pymoo == 0.3.0\n```\n\n## Results on CIFAR-10\n![cifar10_pareto](https://github.com/ianwhale/nsga-net/blob/master/img/cifar10.png  \"cifar10\")\n\n## Pretrained models on CIFAR-10\nThe easiest way to get started is to evaluate our pretrained NSGA-Net models.\n\n#### Macro search space ([NSGA-Net-macro](https://drive.google.com/file/d/173_CXA_YbEjg1_Lnfg6vqweTRDiuDi0J/view?usp=sharing))\n![macro_architecture](https://github.com/ianwhale/nsga-net/blob/beta/img/encoding.png  \"architecture\")\n``` shell\npython validation/test.py --net_type macro --model_path weights.pt\n```\n- Expected result: *3.73%* test error rate with *3.37M* model parameters, *1240M* Multiply-Adds.\n\n#### Micro search space\n![micro_architecture](https://github.com/ianwhale/nsga-net/blob/beta/img/cells.png  \"Normal&Reduction Cells\")\n``` shell\npython validation/test.py --net_type micro --arch NSGANet --init_channels 26 --filter_increment 4 --SE --auxiliary --model_path weights.pt\n```\n- Expected result: *2.43%* test error rate with *1.97M* model parameters, *417M* Multiply-Adds ([*weights.pt*](https://drive.google.com/open?id=1JvMkT1eo6JegtUvT-5qY4LK3xgq-k-OH)). \n\n``` shell\npython validation/test.py --net_type micro --arch NSGANet --init_channels 34 --filter_increment 4 --auxiliary --model_path weights.pt\n```\n- Expected result: *2.22%* test error rate with *2.20M* model parameters, *550M* Multiply-Adds ([*weights.pt*](https://drive.google.com/open?id=1it_aFoez-U7SkxSuRPYWDVFg8kZwE7E7)). \n\n``` shell\npython validation/test.py --net_type micro --arch NSGANet --init_channels 36 --filter_increment 6 --SE --auxiliary --model_path weights.pt\n```\n- Expected result: *2.02%* test error rate with *4.05M* model parameters, *817M* Multiply-Adds ([*weights.pt*](https://drive.google.com/open?id=1kLXzKxQ7dazjmANTvgSoeMPHWwYKiOtm)). \n\n## Pretrained models on CIFAR-100\n``` shell\npython validation/test.py --task cifar100 --net_type micro --arch NSGANet --init_channels 36 --filter_increment 6 --SE --auxiliary --model_path weights.pt\n```\n- Expected result: *14.42%* test error rate with *4.1M* model parameters, *817M* Multiply-Adds ([*weights.pt*](https://drive.google.com/open?id=1CMtSg1l2V5p0HcRxtBsD8syayTtS9QAu)). \n\n## Architecture validation\nTo validate the results by training from scratch, run\n``` \n# architecture found from macro search space\npython validation/train.py --net_type macro --cutout --batch_size 128 --epochs 350 \n# architecture found from micro search space\npython validation/train.py --net_type micro --arch NSGANet --layers 20 --init_channels 34 --filter_increment 4  --cutout --auxiliary --batch_size 96 --droprate 0.2 --SE --epochs 600\n```\nYou may need to adjust the batch_size depending on your GPU memory. \n\nFor customized macro search space architectures, change `genome` and `channels` option in `train.py`. \n\nFor customized micro search space architectures, specify your architecture in `models/micro_genotypes.py` and use `--arch` flag to pass the name. \n\n\n## Architecture search \nTo run architecture search:\n``` shell\n# macro search space\npython search/evolution_search.py --search_space macro --init_channels 32 --n_gens 30\n# micro search space\npython search/evolution_search.py --search_space micro --init_channels 16 --layers 8 --epochs 20 --n_offspring 20 --n_gens 30\n```\nPareto Front               |  Network                  \n:-------------------------:|:-------------------------:\n![](https://github.com/ianwhale/nsga-net/blob/beta/img/pf_macro.gif)  |  ![](https://github.com/ianwhale/nsga-net/blob/beta/img/macro_network.gif)\n\nPareto Front               |  Normal Cell              | Reduction Cell\n:-------------------------:|:-------------------------:|:-------------------------:\n![](https://github.com/ianwhale/nsga-net/blob/beta/img/pf_micro.gif)  |  ![](https://github.com/ianwhale/nsga-net/blob/beta/img/nd_normal_cell.gif)  |  ![](https://github.com/ianwhale/nsga-net/blob/beta/img/nd_reduce_cell.gif)\n\nIf you would like to run asynchronous and parallelize each architecture's back-propagation training, set `--n_offspring` to `1`. The algorithm will run in *steady-state* mode, in which the population is updated as soon as one new architecture candidate is evaludated. It works reasonably well in single-objective case, a similar strategy is used in [here](https://arxiv.org/abs/1802.01548).  \n\n## Visualization\nTo visualize the architectures:\n``` shell\npython visualization/macro_visualize.py NSGANet            # macro search space architectures\npython visualization/micro_visualize.py NSGANet            # micro search space architectures\n```\nFor customized architecture, first define the architecture in `models/*_genotypes.py`, then substitute `NSGANet` with the name of your customized architecture. \n\n## Citations\nIf you find the code useful for your research, please consider citing our works\n``` \n@article{nsganet,\n  title={NSGA-NET: a multi-objective genetic algorithm for neural architecture search"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find the code useful for your research, please consider citing our works\n``` \n@article{nsganet,\n  title={NSGA-NET: a multi-objective genetic algorithm for neural architecture search},\n  author={Lu, Zhichao and Whalen, Ian and Boddeti, Vishnu and Dhebar, Yashesh and Deb, Kalyanmoy and Goodman, Erik and  Banzhaf, Wolfgang},\n  booktitle={GECCO-2019},\n  year={2018}\n}\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{nsganet,\n  title={NSGA-NET: a multi-objective genetic algorithm for neural architecture search},\n  author={Lu, Zhichao and Whalen, Ian and Boddeti, Vishnu and Dhebar, Yashesh and Deb, Kalyanmoy and Goodman, Erik and  Banzhaf, Wolfgang},\n  booktitle={GECCO-2019},\n  year={2018}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8639345340250153,
        0.9343900839872272
      ],
      "excerpt": "NSGA-Net: Neural Architecture Search using Multi-Objective Genetic Algorithm \nZhichao Lu, Ian Whalen, Vishnu Boddeti, Yashesh Dhebar, Kalyanmoy Deb, Erik Goodman and Wolfgang Banzhaf \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xuanhungho/nsga",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-03-28T04:02:09Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-10-19T08:01:33Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8148732879568024
      ],
      "excerpt": "Code accompanying the paper. All codes assume running from root directory. Please update the sys path at the beginning of the codes before running. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "Zhichao Lu, Ian Whalen, Vishnu Boddeti, Yashesh Dhebar, Kalyanmoy Deb, Erik Goodman and Wolfgang Banzhaf \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9918420935325005
      ],
      "excerpt": "The easiest way to get started is to evaluate our pretrained NSGA-Net models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9254751311447194
      ],
      "excerpt": ": macro search space \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9254751311447194
      ],
      "excerpt": ": micro search space \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9402300052000889
      ],
      "excerpt": "To visualize the architectures: \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xuanhungho/nsga/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Fri, 24 Dec 2021 20:42:52 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/xuanhungho/nsga/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "xuanhungho/nsga",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9727723663451282
      ],
      "excerpt": "You may need to adjust the batch_size depending on your GPU memory.  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.925125681324929,
        0.8632985867637891
      ],
      "excerpt": "python validation/test.py --net_type macro --model_path weights.pt \n- Expected result: 3.73% test error rate with 3.37M model parameters, 1240M Multiply-Adds. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925125681324929,
        0.8532121026036568
      ],
      "excerpt": "python validation/test.py --net_type micro --arch NSGANet --init_channels 26 --filter_increment 4 --SE --auxiliary --model_path weights.pt \n- Expected result: 2.43% test error rate with 1.97M model parameters, 417M Multiply-Adds (weights.pt).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9368887027663573,
        0.8532121026036568
      ],
      "excerpt": "python validation/test.py --net_type micro --arch NSGANet --init_channels 34 --filter_increment 4 --auxiliary --model_path weights.pt \n- Expected result: 2.22% test error rate with 2.20M model parameters, 550M Multiply-Adds (weights.pt).  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.925125681324929,
        0.8532121026036568
      ],
      "excerpt": "python validation/test.py --net_type micro --arch NSGANet --init_channels 36 --filter_increment 6 --SE --auxiliary --model_path weights.pt \n- Expected result: 2.02% test error rate with 4.05M model parameters, 817M Multiply-Adds (weights.pt). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.918414318354787,
        0.8064053888084084,
        0.8035223185946352
      ],
      "excerpt": "python validation/test.py --task cifar100 --net_type micro --arch NSGANet --init_channels 36 --filter_increment 6 --SE --auxiliary --model_path weights.pt \n- Expected result: 14.42% test error rate with 4.1M model parameters, 817M Multiply-Adds (weights.pt). \nTo validate the results by training from scratch, run \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9290185568468297
      ],
      "excerpt": "python validation/train.py --net_type macro --cutout --batch_size 128 --epochs 350  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9263532217163565
      ],
      "excerpt": "python validation/train.py --net_type micro --arch NSGANet --layers 20 --init_channels 34 --filter_increment 4  --cutout --auxiliary --batch_size 96 --droprate 0.2 --SE --epochs 600 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8371793493722646
      ],
      "excerpt": "python search/evolution_search.py --search_space macro --init_channels 32 --n_gens 30 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8555071484933153
      ],
      "excerpt": "python search/evolution_search.py --search_space micro --init_channels 16 --layers 8 --epochs 20 --n_offspring 20 --n_gens 30 \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/xuanhungho/nsga/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "NSGA-Net",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "nsga",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "xuanhungho",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/xuanhungho/nsga/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "``` \nPython >= 3.6.8, PyTorch >= 1.0.1.post2, torchvision >= 0.2.2, pymoo == 0.3.0\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Fri, 24 Dec 2021 20:42:52 GMT"
    },
    "technique": "GitHub API"
  }
}
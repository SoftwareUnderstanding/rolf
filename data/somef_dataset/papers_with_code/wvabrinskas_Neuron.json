{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1710.05941v1\n- https://sefiks.com/2018/08/21/swish-as-neural-networks-activation-function/\n- https://www.wandb.com/articles/fundamentals-of-neural-networks\n- https://www.dlology.com/blog/quick-notes-on-how-to-choose-optimizer-in-keras/\n- https://stackoverflow.com/questions/2976452/whats-is-the-difference-between-train-validation-and-test-set-in-neural-netwo\n- https://www.kdnuggets.com/2017/09/neural-network-foundations-explained-activation-function.html#:~:text=Activation%20functions%20reside%20within%20neurons,values%20within%20a%20manageable%20range.\n- https://towardsdatascience.com/regression-models-with-multiple-target-variables-8baa75aacd\n- https://stats.stackexchange.com/questions/265905/derivative-of-softmax-with-respect-to-weights\n- https://www.mldawn.com/the-derivative-of-softmaxz-function-w-r-t-z/\n- https://towardsdatascience.com/optimizers-for-training-neural-network-59450d71caf6\n- https://ruder.io/optimizing-gradient-descent/index.html#adam\n- https://machinelearningmastery.com/multi-label-classification-with-deep-learning/\n- https://medium.com/datathings/neural-networks-and-backpropagation-explained-in-a-simple-way-f540a3611f5e\n- http://page.mi.fu-berlin.de/rojas/neural/chapter/K7.pdf\n- https://gombru.github.io/2018/05/23/cross_entropy_loss/\n- https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy\n- https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/binary-crossentropy\n- https://sefiks.com/2017/12/17/a-gentle-introduction-to-cross-entropy-loss-function/\n- https://datascience.stackexchange.com/questions/27421/when-are-weights-updated-in-cnn\n- https://www.jeremyjordan.me/neural-networks-training/\n- https://medium.com/@pdquant/all-the-backpropagation-derivatives-d5275f727f60\n- https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/\n- https://www.cs.swarthmore.edu/~meeden/cs81/s10/BackPropDeriv.pdf\n- https://www.ics.uci.edu/~pjsadows/notes.pdf\n- https://stackabuse.com/creating-a-neural-network-from-scratch-in-python-multi-class-classification/\n\nCross Entropy + Softmax\n- https://medium.com/data-science-bootcamp/understand-cross-entropy-loss-in-minutes-9fb263caee9a\n- https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d\n- https://deepnotes.io/softmax-crossentropy\n\nVideos: \n- https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/softmax\n\nCost Function vs Loss Function: \n- https://datascience.stackexchange.com/questions/65197/a-cross-entropy-loss-explanation-in-simple-words\n- https://towardsdatascience.com/what-is-loss-function-1e2605aeb904\n\nGradient Clipping: \n- https://towardsdatascience.com/what-is-gradient-clipping-b8e815cdfb48\n\nActivation Functions: \n- https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6\n\nBackpropagation: \n- http://home.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html\n- https://ml-cheatsheet.readthedocs.io/en/latest/backpropagation.html\n- https://stats.stackexchange.com/questions/268561/example-of-backpropagation-for-neural-network-with-softmax-and-sigmoid-activatio\n\nValidation: \n- https://elitedatascience.com/overfitting-in-machine-learning\n- https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/\n\nClassification: \n- https://becominghuman.ai/making-a-simple-neural-network-classification-2449da88c77e\n\nWeight Initialization\n- https://prateekvishnu.medium.com/xavier-and-he-normal-he-et-al-initialization-8e3d7a087528\n\nOptimizers\n- https://medium.com/datadriveninvestor/overview-of-different-optimizers-for-neural-networks-e0ed119440c3\n- https://ruder.io/optimizing-gradient-descent/index.html#adam"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "                  epochs: 10, \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8786044417622563
      ],
      "excerpt": "                    complete: ((_ complete: Bool) -&gt; ())? = nil) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8109194328925066
      ],
      "excerpt": "- exportLoss(_ filename: String? = nil) -&gt; URL? \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "                  batchSize: 10) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9746835383315063
      ],
      "excerpt": "https://deepai.org/machine-learning-glossary-and-terms/softmax-layer  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9873986252484832
      ],
      "excerpt": "- https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/softmax \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8111036989382164
      ],
      "excerpt": "- https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9339068806616879
      ],
      "excerpt": "- https://elitedatascience.com/overfitting-in-machine-learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.999674361061512
      ],
      "excerpt": "- https://prateekvishnu.medium.com/xavier-and-he-normal-he-et-al-initialization-8e3d7a087528 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wvabrinskas/Neuron",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-07-10T00:29:58Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-23T14:21:09Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Neuron is a swift package I developed to help learn how to make neural networks. It is far from perfect and I am still learning. There is A LOT to learn here and I've just scratched the surface. As of right now this package provides a way to get started in machine learning and neural networks.\n\n<img width=\"500\" src=\"images/network.png\">\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "Data Studying \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908925214220865
      ],
      "excerpt": "GAN and WGAN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8727351864101167
      ],
      "excerpt": "It is fairly simple to setup the neural network Brain. This will be the only object you interface with. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8743529676899994,
        0.8776195952281877
      ],
      "excerpt": "The Brain class is the main interactive class for dealing with the neural network. \nThe brain object also supports different log levels so you can see what's going on in the console.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8233352705273693
      ],
      "excerpt": "//show only success and loading logs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8275446596316365
      ],
      "excerpt": "//show all logs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9530945964943728
      ],
      "excerpt": "When defining a bias it is NOT applied to the input layer.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.902246788735066
      ],
      "excerpt": "learningRate - how quickly the node will adjust the weights of its inputs to fit the training model  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9614258320064409
      ],
      "excerpt": "bias - the offset of adjustment to the weight adjustment calculation.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9029548504533327,
        0.9084091569487678
      ],
      "excerpt": "The brain object may not hit the max number of epochs before training is finished if there is validation data passed and it reaches the defined loss threshold. \nThe loss function of the network. This will determine the loss of each epoch as well as the loss of the validation data set.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9078820601265738,
        0.8215528259737348
      ],
      "excerpt": "Currently the network only supports Mean Squared Error, Cross Entropy and Binary Cross Entropy loss functions \nThe loss value the network should reach over an average of 5 epochs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8305846942953019,
        0.8394356323598837
      ],
      "excerpt": "- Currently the network supports Xavier normal distribution and Xavier uniform distribution \nThe brain object can add an optimizer to the network by calling: brain.add(optimizer:) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9455511274441286
      ],
      "excerpt": "Currently only the Adam optimizer is supported. There will be more soon.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9223157735482476
      ],
      "excerpt": "As part of the initializer of the brain object you can specify which type of gradient descent the brain performs.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8549551989730266
      ],
      "excerpt": "The network also supports adding an output activation modifier such as softmax  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9635213063572354
      ],
      "excerpt": "Currently the network on supports Softmax  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8788583121288335
      ],
      "excerpt": "After adding all the specified layers and modifiers do not forget to call compile() on the brain object. This will connect all the layers together using the proper initializer and get the network ready for training. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9436543587950503,
        0.9485751423980711
      ],
      "excerpt": "data: An array of TrainingData objects to be used as the training data set.  \nvalidation: An array of TrainingData objects to be used as the validation data set.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9216531506018659
      ],
      "excerpt": "This is the object that contains the inputs and expected output for that input \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8637349387644837,
        0.8740491289671247,
        0.8441089526004402,
        0.8411675339983
      ],
      "excerpt": "An array of values that should match the number of inputs into the network \nA array of values that the network should target and should match the number of outputs of the network \nBrain can accept a pretrained model in the form of a .smodel file. Basically a renamed JSON format, this is the format the Brain object will export as well.  \n- This will create a fully trained Brain object that is ready to go based on the trained model passed in.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.86476033461413
      ],
      "excerpt": "Pass in new data to feed through the network and get a result.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8624477590947307
      ],
      "excerpt": "- Returns [Float] using the new inputs and the current weights, aka. feed forward. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9162595896804111,
        0.9304299263989105
      ],
      "excerpt": "These features were losely tested but I have come to the conclusion that they work enough to be released. Feel free to open an issue if they do not. \nCreate two Brain objects. One for the discriminator and one for the generator of the network.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.804489343346577
      ],
      "excerpt": "brain.add(.init(nodes: 7)) //some number of inputs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9724685104454465
      ],
      "excerpt": "  - The `Brain` objects are neural networks of their own and will compete to minimize the selected loss function. They are created exactly as any `Brain` object is created as mentioned above. Only thing ignored in this initializer is the `epochs`. This will be handled later.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8990317930061279
      ],
      "excerpt": "epochs - number of rounds of training the GAN \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8289073142376465
      ],
      "excerpt": "generatorTrainPerEpoc - the number of epochs to train the generator per epoch of the GAN training.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8720520352719632,
        0.9184779174971295,
        0.9859017549378426
      ],
      "excerpt": "batchSize - the number of objects to pull from the training data set per epoch. \nlossFunction - the loss function for the GAN to minimize. Currentlt it only supports wasserstein and minimax loss functions. Default: .minimax \nrandomNoise: () -&gt; [Float] - a block that the GAN object will call every epoch to get input data for the generator. The generator takes in random noise from a described latent space. This block is used to define that latent space.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.810066777230834
      ],
      "excerpt": "- https://medium.com/datadriveninvestor/overview-of-different-optimizers-for-neural-networks-e0ed119440c3 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A neural network library for Swift ",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wvabrinskas/Neuron/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Wed, 29 Dec 2021 09:19:46 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/wvabrinskas/Neuron/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "wvabrinskas/Neuron",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8335054843909455
      ],
      "excerpt": "A GAN will attempt to map between one distrubition to another. You can see below the input distribution is a normal even distribution while the output distribution from the GAN is a gaussian distribution.  \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8174352161492149
      ],
      "excerpt": "Calling add(modifier) on the brain object will add the specified output activation to the output layer.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8396893658879493
      ],
      "excerpt": "data: An array of TrainingData objects to be used as the training data set.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8011422545338825
      ],
      "excerpt": "  public var data: [Float] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8133307015286358
      ],
      "excerpt": "- filename: Name of the file to save and export. defaults to loss-{timeIntervalSince1970} \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8852212400028648
      ],
      "excerpt": "<img width=\"600\" src=\"images/graph-sample.png\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8126512229187077,
        0.8206894344289778
      ],
      "excerpt": "criticTrainPerEpoch - the number of epochs to train the critic (discriminator) per epoch of the GAN training.  \ngeneratorTrainPerEpoc - the number of epochs to train the generator per epoch of the GAN training.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8343756915996813
      ],
      "excerpt": "batchSize - the number of objects to pull from the training data set per epoch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9042534665813847,
        0.9042534665813847
      ],
      "excerpt": "<img width=\"600\" src=\"images/input_gan.png\">  \n<img width=\"600\" src=\"images/output_gan.png\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/wvabrinskas/Neuron/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Swift"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 William Vabrinskas\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Neuron",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Neuron",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "wvabrinskas",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/wvabrinskas/Neuron/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "wvabrinskas",
        "body": "Added GAN support ",
        "dateCreated": "2021-12-23T03:17:37Z",
        "datePublished": "2021-12-23T03:18:31Z",
        "html_url": "https://github.com/wvabrinskas/Neuron/releases/tag/1.4.0",
        "name": "v1.4.0",
        "tag_name": "1.4.0",
        "tarball_url": "https://api.github.com/repos/wvabrinskas/Neuron/tarball/1.4.0",
        "url": "https://api.github.com/repos/wvabrinskas/Neuron/releases/55869429",
        "zipball_url": "https://api.github.com/repos/wvabrinskas/Neuron/zipball/1.4.0"
      },
      {
        "authorType": "User",
        "author_name": "wvabrinskas",
        "body": "Added ability to replace weights ",
        "dateCreated": "2021-03-12T20:39:38Z",
        "datePublished": "2021-03-12T20:40:09Z",
        "html_url": "https://github.com/wvabrinskas/Neuron/releases/tag/1.3.4",
        "name": "v1.3.4",
        "tag_name": "1.3.4",
        "tarball_url": "https://api.github.com/repos/wvabrinskas/Neuron/tarball/1.3.4",
        "url": "https://api.github.com/repos/wvabrinskas/Neuron/releases/39737613",
        "zipball_url": "https://api.github.com/repos/wvabrinskas/Neuron/zipball/1.3.4"
      },
      {
        "authorType": "User",
        "author_name": "wvabrinskas",
        "body": "Added a way to import an ExportModel",
        "dateCreated": "2021-03-11T01:34:05Z",
        "datePublished": "2021-03-11T01:35:07Z",
        "html_url": "https://github.com/wvabrinskas/Neuron/releases/tag/1.3.3",
        "name": "v1.3.3",
        "tag_name": "1.3.3",
        "tarball_url": "https://api.github.com/repos/wvabrinskas/Neuron/tarball/1.3.3",
        "url": "https://api.github.com/repos/wvabrinskas/Neuron/releases/39627994",
        "zipball_url": "https://api.github.com/repos/wvabrinskas/Neuron/zipball/1.3.3"
      },
      {
        "authorType": "User",
        "author_name": "wvabrinskas",
        "body": "Added exportModel function",
        "dateCreated": "2021-03-11T01:29:41Z",
        "datePublished": "2021-03-11T01:30:01Z",
        "html_url": "https://github.com/wvabrinskas/Neuron/releases/tag/1.3.2",
        "name": "V1.3.2",
        "tag_name": "1.3.2",
        "tarball_url": "https://api.github.com/repos/wvabrinskas/Neuron/tarball/1.3.2",
        "url": "https://api.github.com/repos/wvabrinskas/Neuron/releases/39627868",
        "zipball_url": "https://api.github.com/repos/wvabrinskas/Neuron/zipball/1.3.2"
      },
      {
        "authorType": "User",
        "author_name": "wvabrinskas",
        "body": "Added adam optimizer and fixes ",
        "dateCreated": "2021-01-29T20:16:15Z",
        "datePublished": "2021-02-07T19:37:42Z",
        "html_url": "https://github.com/wvabrinskas/Neuron/releases/tag/1.3.1",
        "name": "Release 1.3.1",
        "tag_name": "1.3.1",
        "tarball_url": "https://api.github.com/repos/wvabrinskas/Neuron/tarball/1.3.1",
        "url": "https://api.github.com/repos/wvabrinskas/Neuron/releases/37679411",
        "zipball_url": "https://api.github.com/repos/wvabrinskas/Neuron/zipball/1.3.1"
      },
      {
        "authorType": "User",
        "author_name": "wvabrinskas",
        "body": "Fixed adding new inputs \r\nAdded replace Inputs function to neuron",
        "dateCreated": "2020-07-11T17:35:54Z",
        "datePublished": "2020-07-11T17:36:57Z",
        "html_url": "https://github.com/wvabrinskas/Neuron/releases/tag/0.0.5",
        "name": "0.0.5b",
        "tag_name": "0.0.5",
        "tarball_url": "https://api.github.com/repos/wvabrinskas/Neuron/tarball/0.0.5",
        "url": "https://api.github.com/repos/wvabrinskas/Neuron/releases/28469758",
        "zipball_url": "https://api.github.com/repos/wvabrinskas/Neuron/zipball/0.0.5"
      },
      {
        "authorType": "User",
        "author_name": "wvabrinskas",
        "body": "Added ranked output option",
        "dateCreated": "2020-07-10T16:42:38Z",
        "datePublished": "2020-07-10T16:43:23Z",
        "html_url": "https://github.com/wvabrinskas/Neuron/releases/tag/0.0.4",
        "name": "0.0.4b",
        "tag_name": "0.0.4",
        "tarball_url": "https://api.github.com/repos/wvabrinskas/Neuron/tarball/0.0.4",
        "url": "https://api.github.com/repos/wvabrinskas/Neuron/releases/28449665",
        "zipball_url": "https://api.github.com/repos/wvabrinskas/Neuron/zipball/0.0.4"
      },
      {
        "authorType": "User",
        "author_name": "wvabrinskas",
        "body": "Removed the need to import UIKit\r\nAdded macOS and watchOS support",
        "dateCreated": "2020-07-10T15:49:55Z",
        "datePublished": "2020-07-10T15:53:40Z",
        "html_url": "https://github.com/wvabrinskas/Neuron/releases/tag/0.0.3",
        "name": "0.0.3b",
        "tag_name": "0.0.3",
        "tarball_url": "https://api.github.com/repos/wvabrinskas/Neuron/tarball/0.0.3",
        "url": "https://api.github.com/repos/wvabrinskas/Neuron/releases/28447884",
        "zipball_url": "https://api.github.com/repos/wvabrinskas/Neuron/zipball/0.0.3"
      },
      {
        "authorType": "User",
        "author_name": "wvabrinskas",
        "body": "Added README, LICENSE, and image examples",
        "dateCreated": "2020-07-10T13:57:19Z",
        "datePublished": "2020-07-10T13:58:40Z",
        "html_url": "https://github.com/wvabrinskas/Neuron/releases/tag/0.0.2",
        "name": "0.0.2b",
        "tag_name": "0.0.2",
        "tarball_url": "https://api.github.com/repos/wvabrinskas/Neuron/tarball/0.0.2",
        "url": "https://api.github.com/repos/wvabrinskas/Neuron/releases/28443072",
        "zipball_url": "https://api.github.com/repos/wvabrinskas/Neuron/zipball/0.0.2"
      },
      {
        "authorType": "User",
        "author_name": "wvabrinskas",
        "body": "Initial beta release",
        "dateCreated": "2020-07-10T00:43:15Z",
        "datePublished": "2020-07-10T00:45:03Z",
        "html_url": "https://github.com/wvabrinskas/Neuron/releases/tag/0.0.1",
        "name": "0.0.1b",
        "tag_name": "0.0.1",
        "tarball_url": "https://api.github.com/repos/wvabrinskas/Neuron/tarball/0.0.1",
        "url": "https://api.github.com/repos/wvabrinskas/Neuron/releases/28423965",
        "zipball_url": "https://api.github.com/repos/wvabrinskas/Neuron/zipball/0.0.1"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 7,
      "date": "Wed, 29 Dec 2021 09:19:46 GMT"
    },
    "technique": "GitHub API"
  },
  "support": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[<img width=\"100\" src=\"images/twitter.png\"> ](https://twitter.com/wvabrinskas)\n\nFeel free to send me suggestions on how to improve this. I would be delighted to learn more!! You can also feel free to assign issues here as well. Run the unit tests as well to learn how the project works!\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Neuron supports Generative Adversarial Networks and Wasserstein Generative Adversarial Networks. Current Neuron doesn't support image generation with this as it doesn't support convolutional layers yet. \n\n",
      "technique": "Header extraction"
    }
  ],
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- To train the `GAN` you just call `train` on the `GAN` object you created with an array of `TrainingData` objects. Similar to any `Brain` object.\n\n```\nself.ganBrain.train(data: trainingData) { success in }\n```\n\n- To get generated data from the generator of the `GAN` you just call `getGeneratedSample` on your `GAN` object. This returns an array of `Float` from the generator. \n```    \nlet result = self.ganBrain.getGeneratedSample()\n```\n\n- You can also get data from the disrimanator to discriminate against some input data. \n```\nlet result = self.ganBrain.discriminate(input)\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
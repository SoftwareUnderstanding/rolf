{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We would like to thank Reiichiro Nakano for helping us clarifying doubts during the implementation of our Neural Painters and for his supportive and encouraging comments and feedback. Thanks a lot Reiichiro! [@reiinakano](https://twitter.com/reiinakano).\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1904.08410",
      "https://arxiv.org/abs/1603.08155, 2016\n\n[5] *Teaching Agents to Paint Inside Their Own Dreams*. Reiichiro Nakano.\u00a0\nhttps://reiinakano.com/2019/01/27/world-painters.html, 2019\n\n[6] *A Neural Algorithm of Artistic Style*. Leon A. Gatys, Alexander S. Ecker, Matthias Bethge. https://arxiv.org/abs/1508.06576, 2015\n\n[7] *Very Deep Convolutional Networks for Large-Scale Image Recognition*. Karen Simonyan, Andrew Zisserman. https://arxiv.org/abs/1409.1556, 2014\n\n---",
      "https://arxiv.org/abs/1508.06576, 2015\n\n[7] *Very Deep Convolutional Networks for Large-Scale Image Recognition*. Karen Simonyan, Andrew Zisserman. https://arxiv.org/abs/1409.1556, 2014\n\n---",
      "https://arxiv.org/abs/1409.1556, 2014\n\n---",
      "https://arxiv.org/abs/1904.08410](https://arxiv.org/abs/1904.08410), 2019. [Github repo](https://github.com/reiinakano/neural-painters).\n\n[2] *Decrappification, DeOldification, and Super Resolution*. Jason Antic (Deoldify), Jeremy Howard (fast.ai), and Uri Manor (Salk Institute) https://www.fast.ai/2019/05/03/decrappify/\u00a0, 2019.\n\n[3] *Fast.ai MOOC Lesson 7: Resnets from scratch; U-net; Generative (adversarial) networks*. https://course.fast.ai/videos/?lesson=7\u00a0; Notebook: https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson7-superres.ipynb [Accessed on: 2019\u201308]\n\n[4] *Perceptual Losses for Real-Time Style Transfer and Super-Resolution*.\nJustin Johnson, Alexandre Alahi, Li Fei-Fei https://arxiv.org/abs/1603.08155, 2016\n\n[5] *Teaching Agents to Paint Inside Their Own Dreams*. Reiichiro Nakano.\u00a0\nhttps://reiinakano.com/2019/01/27/world-painters.html, 2019\n\n[6] *A Neural Algorithm of Artistic Style*. Leon A. Gatys, Alexander S. Ecker, Matthias Bethge. https://arxiv.org/abs/1508.06576, 2015\n\n[7] *Very Deep Convolutional Networks for Large-Scale Image Recognition*. Karen Simonyan, Andrew Zisserman. https://arxiv.org/abs/1409.1556, 2014\n\n---"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] *Neural Painters: A Learned Differentiable Constraint for Generating Brushstroke Paintings*. Reiichiro Nakano\u00a0\n[arXiv preprint arXiv:1904.08410](https://arxiv.org/abs/1904.08410), 2019. [Github repo](https://github.com/reiinakano/neural-painters).\n\n[2] *Decrappification, DeOldification, and Super Resolution*. Jason Antic (Deoldify), Jeremy Howard (fast.ai), and Uri Manor (Salk Institute) https://www.fast.ai/2019/05/03/decrappify/\u00a0, 2019.\n\n[3] *Fast.ai MOOC Lesson 7: Resnets from scratch; U-net; Generative (adversarial) networks*. https://course.fast.ai/videos/?lesson=7\u00a0; Notebook: https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson7-superres.ipynb [Accessed on: 2019\u201308]\n\n[4] *Perceptual Losses for Real-Time Style Transfer and Super-Resolution*.\nJustin Johnson, Alexandre Alahi, Li Fei-Fei https://arxiv.org/abs/1603.08155, 2016\n\n[5] *Teaching Agents to Paint Inside Their Own Dreams*. Reiichiro Nakano.\u00a0\nhttps://reiinakano.com/2019/01/27/world-painters.html, 2019\n\n[6] *A Neural Algorithm of Artistic Style*. Leon A. Gatys, Alexander S. Ecker, Matthias Bethge. https://arxiv.org/abs/1508.06576, 2015\n\n[7] *Very Deep Convolutional Networks for Large-Scale Image Recognition*. Karen Simonyan, Andrew Zisserman. https://arxiv.org/abs/1409.1556, 2014\n\n---\n",
      "technique": "Header extraction"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/libreai/neural-painters-x",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-08-18T15:07:37Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-25T09:10:10Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9932481065666705,
        0.9428142269709506,
        0.9624858768058885
      ],
      "excerpt": "Blogpost with more details: The Joy of Neural Painting \nThe implementation is broken down in a set of Notebooks to ease exploration and understanding \nThis Neural Painters implementation is the core technique used by the collective diavlex for their Art+AI collection Residual at Cueva Gallery. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9810733569780825,
        0.9858314419250647,
        0.9821446835801573,
        0.9871180485478613,
        0.9513815273578626,
        0.9898635799967932,
        0.9625523061939237,
        0.9982777437784327,
        0.9617365319593475,
        0.9899533823473856,
        0.9677170444035506,
        0.9951059162331773,
        0.9567150168455427
      ],
      "excerpt": "I am sure you know Bob Ross and his program The Joy of Painting where he taught thousands of viewers how to paint beautiful landscapes with a simple and fun way, combining colors and brushstrokes, to achieve great results very quickly. Do you remember him teaching how to paint a pixel at the time? of course not!\u00a0 \nHowever, most of the current generative AI Art methods are still centered to teach machines how to 'paint' at the pixel-level in order to achieve or mimic some painting style, e.g., GANs-based approaches and style transfer. This might be effective, but not very intuitive, specially when explaining this process to artists, who are familiar with colors and brushstrokes. \nAt Libre AI, we have started a Creative AI initiative with the goal to make more accessible the advances of AI to groups of artists who do not necessarily have a tech background. We want to explore how the creative process is enriched by the interaction between creative people and creative machines. \nAs first step, we need to teach a machine how to paint. It should learn to paint as a human would do it: using brushstrokes and combining colors on a canvas. We researched the state-of-the-art and despite the great works, there was not really a single paper that satisfied our requirements, until we found Neural Painters: A Learned Differentiable Constraint for Generating Brushstroke Paintings by Reiichiro Nakano [1]. This finding was quite refreshing. \nNeural Painters [1] are a class of models that can be seen as a fully differentiable simulation of a particular non-differentiable painting program, in other words, the machine \"paints\" by successively generating brushstrokes (i.e., actions that defines a brushstrokes) and applying them on a canvas, as an artist would do. \nThe code available to reproduce the experiments is offered by the author in a series of Google's Colaboratory notebooks available in this Github repo and the dataset used is available in Kaggle. The implementation uses TensorFlow, which is great in terms of performance, but let's face it, it is not great fun to digest TensorFlow's code (specially without Keras\u00a0;) ). \nTeaching machines is the best way to learn Machine Learning\u200a\u2013\u200aE. D.\u00a0A. \nWe played around with the notebooks provided, they were extremely useful to understand the paper and to generate nice sample paintings, but we decided that in order to really learn and master Neural Painters, we needed to experiment and reproduce the results of the paper with our own implementation. To this end, we decided to go with PyTorch and fast.ai as deep learning frameworks instead of TensorFlow as the paper's reference implementation, to do some tinkering and in the process, hopefully, come with a more accessible piece of code. \nGANs are great generative models but they are known to be notoriously difficult to train, specially due to requiring a large amount of data, and therefore, needing large computational power on GPUs. They require a lot of time to train and are sensitive to small hyperparameter variations.\u00a0 \nWe indeed tried first a pure adversarial training following the paper, but although we obtained some decent results with our implementation, in terms of brushstrokes quality, it took a day or two to get there with a single GPU using a Colaboratory notebook and the full dataset.\u00a0 \nTo overcome these known GANs limitations and to speed up the Neural Painter training process, we leveraged the power of Transfer Learning \nTransfer learning is a very useful technique in Machine Learning, e.g., the ImageNet models trained as classifiers, are largely used as powerful image feature extractors, in NLP, word embeddings, learned unsupervised or with minimal supervision (e.g., trying to predict words in the same context), have been very useful as representations of words in more complex language models. In Recommender Systems, representations of items (e.g., book, movie, song) or users can be learned via Collaborative Filtering and then use them not only for personalized ranking, but also for adaptive user interfaces. The fundamental idea, is to learn a model or feature representation on a task, and then transfer that knowledge to another related task, without the need to start from scratch, and only do some fine-tuning to adapt the model or representation parameters on that task. \nMore precisely, since GANs main components are the Generator and Critic the idea is to pre-train them independently, that is in a non-adversarial manner, and do transfer learning by hooking them together after pre-training and proceed with the adversarial training, i.e., GAN mode. This process has shown to produce remarkable results [2] and is the one we follow here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9304634926712321
      ],
      "excerpt": "Pre-train the Critic as a Binary Classifier (i.e., non-adversarially) using the pre-trained Generator (in evaluation mode with frozen model weights) to generate fake brushstrokes. That is, the Critic should learn to discriminate between real images and the generated ones. This step uses a standard binary classification loss, i.e., Binary Cross Entropy, not a GAN loss. (02_neural_painter_x_training_Critic_Non_Adversarial.ipynb) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.888778193809543,
        0.9344517934598888,
        0.9631130391426498
      ],
      "excerpt": "The training set consists of labeled examples where the input corresponds to an action vector and the corresponding brushstroke image to the target.\u00a0 \nThe input action vectors go through the Generator, which consists of a fully-connected layer (to increase the input dimensions) and of a Deep Convolutional Neural Network connected to it. \nThe output of the Generator is an image of a brushstroke. The loss computed between the images is the feature loss introduced in [3] (also known as perceptual loss [4]). The process is depicted in Figure 1. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.856834665801773
      ],
      "excerpt": "After pre-training the Generator using the non-adversarial loss, the brushstrokes look like the ones depicted in Figure 2. A set of brushstrokes images is generated that will help us pre-train the Critic in the next step. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9520008578706997
      ],
      "excerpt": "We train the Critic as binary classifier (Figure 3), that is, the Critic is pre-trained on the task of recognizing true vs generated brushstrokes images (Step (2)).\u00a0We use is the Binary Cross Entropy as binary loss for this step. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9172481558179557
      ],
      "excerpt": "Finally, we continue the Generator and Critic training in a GAN setting as shown in Figure 4. This final step is much faster that training the Generator and Critic from scratch as a GAN.\u00a0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8108011182824799
      ],
      "excerpt": "Figure 4\u00a0. Transfer Learning: Continue the Generator and Critic training in a GAN setting.\u00a0Faster. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.951832066890155
      ],
      "excerpt": "Figure 5 shows the output of the Generator after completing a single epoch of GAN training, i.e., after transferring the knowledge acquired in the pre-training phase. We can observe how the brushstrokes are more refined and, although slightly different to the true brushstrokes, they have interesting textures, which makes them very appealing for brushstrokes paintings. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9829378542453059,
        0.984225150037021,
        0.9857120410663369
      ],
      "excerpt": "Once the Generator training process is completed, we have a machine that is able to translate vectors of actions to brushstrokes, but how do we teach the machine to paint like a Bob Ross' apprentice?\u00a0 \nGiven an input image for inspiration, e.g., a photo of a beautiful landscape, the machine should be able to create a brushstroke painting for that image. To achieve this, we will freeze the Generator model weights and learn a set of action vectors that when input to the Generator will produce brushstrokes, that once combined, will create such painting, which should look similar to the given image, but of course as a painting\u00a0:) \nThe Neural Painters paper [1] introduces a process called Intrinsic Style Transfer, similar in spirit to Neural Style Transfer [6] but which does not require a style image. Intuitively, the features of the content input image and the one produced by the Neural Painter should be similar. The image features are extracted using a VGG16 [7] network as a feature extractor, denoted as CNN in Figure 6, which depicts the whole process.\u00a0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Neural Paiters",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/libreai/neural-painters-x/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 3,
      "date": "Wed, 29 Dec 2021 11:59:15 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/libreai/neural-painters-x/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "libreai/neural-painters-x",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/libreai/neural-painters-x/master/notebooks/04_neural_painter_x_painting.ipynb",
      "https://raw.githubusercontent.com/libreai/neural-painters-x/master/notebooks/02_neural_painter_x_training_Critic_Non_Adversarial.ipynb",
      "https://raw.githubusercontent.com/libreai/neural-painters-x/master/notebooks/01_neural_painter_x_training_Generator_Non_Adversarial.ipynb",
      "https://raw.githubusercontent.com/libreai/neural-painters-x/master/notebooks/03_neural_painter_x_training_GAN_mode.ipynb"
    ],
    "technique": "File Exploration"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/libreai/neural-painters-x/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2019 Libre AI\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "The Joy of Neural Painting",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "neural-painters-x",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "libreai",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/libreai/neural-painters-x/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 70,
      "date": "Wed, 29 Dec 2021 11:59:15 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "neural-painters",
      "brushstroke-painting",
      "style-transfer",
      "gan",
      "transfer-learning",
      "ai-art"
    ],
    "technique": "GitHub API"
  }
}
{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "It was implemented a Siamese Network with [VGG][vgg] features. I got a pretrained VGG with Imagenet[3] and I applied a finetuning for faces.\n\nIn general, I implemented  different networks with different loss techniques:\n- Two siamese neural networks getting features from a VGG convolutional network and the application of a cosine similarity[5]\n- Two siamese networks which a concatenation in order to join features and get a classification with  a cross entropy loss[4]\n- One siamese with a triplet loss function\n\nAbout experiments, they are classified as:\n- Change optimizer SGD or ADAM (With different learning rates and weight decay) (1e-3, 5e-4, 1e-4)\n\t- It was tuned other parameters as weight decay, betas, momentum, etc... In order to find the best configuration that I added in the result table\n- With and without data augmentation. In the data augmentation process with rotations, flips and jitter modifications.\n\t- The idea is check if they have improvements. If it happens, add more modifications to improve the percentage.\n- Changing the loss functions that means change the type of neural network\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "The backend architecute is a VGG16-bn (batch normalized) and its convolutional layers. They are used as a siamese network applying them in two images and get their features. For this project, it is used pretrained networks that speed up our training process with a pretrained neural network with Imagenet\n\nAfter this point, it is applied different techniques to check the performance and compare results:\n- First one, it applies a cosine similarity loss function to search better results with the convolutional layers\n\t- v1 It is the simplest version, it only gets the VGG feature and It is applied the cosine loss function.\n\t- v2 In this version, it is added a linear layer to flat the features that it is trained. Furthermore, It uses the cosine  loss function too.\n- In the second one, it is joined the two branches to get a classification. Furthermore, It is added improvements in order to achieve a better solution.\n\t- The neural network  named decision, it includes a minimal decision network with a few linear layers to do it. It is done  after the concatenation of features (from the two branches)\n\t- In the decision network linear, it is added a linear layer before this concatenation to improve the training and the performance. It tries to get better feature for our use case.\n\n\n\n",
      "technique": "Header extraction"
    }
  ],
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1612.04402\n- *YOLO v3*, trained for faces\n\t- code https://github.com/sthanhng/yoloface\n\t- paper https://pjreddie.com/media/files/papers/YOLOv3.pdf\n\n\nFor datasets, I did two differents:\n\n- *FDDB* Dataset http://vis-www.cs.umass.edu/fddb/\n- *Wider* Dataset http://shuoyang1213.me/WIDERFACE/ \n\n\nThe bubble graph can give us a small overview about the differences of both: (accuracy, time and number of parameters for each network",
      "https://arxiv.org/abs/1612.04402\n\n[VGG_paper] https://arxiv.org/abs/1409.1556\n\n[data_augmentation] https://github.com/aleju/imgaug\n\n[triplet_loss]https://en.wikipedia.org/wiki/Triplet_loss\n\n\n\n[bubbles]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/bubbles.png \"Bubbles\"\n[cfp_dataset]: http://www.cfpw.io/ \"CFP Dataset\"\n[weights]: https://drive.google.com/open?id=1s3Zj0PesMp2juGmS7ERd5GWvxuxk-u2D\n[vgg]: https://arxiv.org/pdf/1409.1556.pdf\n[decision_layers]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_layers.png \"Decision layers\"\n[decision_linear_layers]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_linear_layers.png \"Decision linear layers\"\n[decision_linear_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_linear_sara_adam_normtrans.png \"Decision linear Adam  + Data Augmentation\"\n[decision_linear_sara_sgd]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_linear_sara_sgd.png \"Decision linear SGD\"\n[decision_linear_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_linear_sara_sgd_normtrans.png \"Decision linear  SGD + Data augmentation\"\n[decision_sara_sgd]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_sara_sgd.png \"Decision SGD\"\n[decision_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_sara_adam_normtrans_lr54.png \"Decision Adam  + Data Augmentation\"\n[decision_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_sara_sgd_normtrans_v2.png \"Decision SGD  + Data Augmentation\"\n[siamese1_layers]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_layers.png \"Siamese Cosine 1 layers\"\n[siamese1_sara_sgd]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_sgd.png \"Siamese Cosine 1 SGD\"\n[siamese1_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_adam_normtrans_lr54.png \"Siamese Cosine 1 Adam  + Data Augmentation\"\n[siamese1_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_sgd_normtrans.png  \"Siamese Cosine 1 SGD  + Data Augmentation\"\n[siamese2_layers]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese2_layers.png  \"Siamese 2 layers\"\n[siamese2_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese2_sara_adam_normtrans.png \"Siamese Cosine 2 Adam  + Data Augmentation\"\n[siamese2_sara_sgd]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese2_sara_sgd.png  \"Siamese Cosine 2 SGD\"\n[siamese2_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese2_sara_sgd_normtrans.png  \"Siamese Cosine 2  SGD  + Data Augmentation\"\n[vgg_arch]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/vgg_arch.png \"VGG architecture\"\n[vgg_features]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/vgg_features.png \"VGG features\"\n\n[triplet1_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_triplet_adam_normtrans.png \"Siamese Triplet 1 Adam  + Data Augmentation\"\n[triplet1_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_triplet_sgd_normtrans.png  \"Siamese Triplet 1 SGD  + Data Augmentation\"\n\n\n",
      "https://arxiv.org/abs/1409.1556\n\n[data_augmentation] https://github.com/aleju/imgaug\n\n[triplet_loss]https://en.wikipedia.org/wiki/Triplet_loss\n\n\n\n[bubbles]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/bubbles.png \"Bubbles\"\n[cfp_dataset]: http://www.cfpw.io/ \"CFP Dataset\"\n[weights]: https://drive.google.com/open?id=1s3Zj0PesMp2juGmS7ERd5GWvxuxk-u2D\n[vgg]: https://arxiv.org/pdf/1409.1556.pdf\n[decision_layers]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_layers.png \"Decision layers\"\n[decision_linear_layers]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_linear_layers.png \"Decision linear layers\"\n[decision_linear_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_linear_sara_adam_normtrans.png \"Decision linear Adam  + Data Augmentation\"\n[decision_linear_sara_sgd]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_linear_sara_sgd.png \"Decision linear SGD\"\n[decision_linear_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_linear_sara_sgd_normtrans.png \"Decision linear  SGD + Data augmentation\"\n[decision_sara_sgd]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_sara_sgd.png \"Decision SGD\"\n[decision_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_sara_adam_normtrans_lr54.png \"Decision Adam  + Data Augmentation\"\n[decision_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_sara_sgd_normtrans_v2.png \"Decision SGD  + Data Augmentation\"\n[siamese1_layers]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_layers.png \"Siamese Cosine 1 layers\"\n[siamese1_sara_sgd]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_sgd.png \"Siamese Cosine 1 SGD\"\n[siamese1_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_adam_normtrans_lr54.png \"Siamese Cosine 1 Adam  + Data Augmentation\"\n[siamese1_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_sgd_normtrans.png  \"Siamese Cosine 1 SGD  + Data Augmentation\"\n[siamese2_layers]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese2_layers.png  \"Siamese 2 layers\"\n[siamese2_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese2_sara_adam_normtrans.png \"Siamese Cosine 2 Adam  + Data Augmentation\"\n[siamese2_sara_sgd]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese2_sara_sgd.png  \"Siamese Cosine 2 SGD\"\n[siamese2_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese2_sara_sgd_normtrans.png  \"Siamese Cosine 2  SGD  + Data Augmentation\"\n[vgg_arch]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/vgg_arch.png \"VGG architecture\"\n[vgg_features]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/vgg_features.png \"VGG features\"\n\n[triplet1_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_triplet_adam_normtrans.png \"Siamese Triplet 1 Adam  + Data Augmentation\"\n[triplet1_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_triplet_sgd_normtrans.png  \"Siamese Triplet 1 SGD  + Data Augmentation\"\n\n\n"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[1] Siamese networks https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf\n\n[2] Cosine loss https://pytorch.org/docs/stable/nn.html\n\n[3] Imagenet http://www.image-net.org/\n\n[4] Cross entropy loss https://pytorch.org/docs/stable/nn.html\n\n[5] Cosine similarity https://pytorch.org/docs/stable/nn.html\n\n[Facenet] https://github.com/davidsandberg/facenet\n\n[OpenFace] https://cmusatyalab.github.io/openface/\n\n[YoloV3_paper] https://pjreddie.com/media/files/papers/YOLOv3.pdf\n\n[TinyFaces_paper] https://arxiv.org/abs/1612.04402\n\n[VGG_paper] https://arxiv.org/abs/1409.1556\n\n[data_augmentation] https://github.com/aleju/imgaug\n\n[triplet_loss]https://en.wikipedia.org/wiki/Triplet_loss\n\n\n\n[bubbles]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/bubbles.png \"Bubbles\"\n[cfp_dataset]: http://www.cfpw.io/ \"CFP Dataset\"\n[weights]: https://drive.google.com/open?id=1s3Zj0PesMp2juGmS7ERd5GWvxuxk-u2D\n[vgg]: https://arxiv.org/pdf/1409.1556.pdf\n[decision_layers]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_layers.png \"Decision layers\"\n[decision_linear_layers]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_linear_layers.png \"Decision linear layers\"\n[decision_linear_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_linear_sara_adam_normtrans.png \"Decision linear Adam  + Data Augmentation\"\n[decision_linear_sara_sgd]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_linear_sara_sgd.png \"Decision linear SGD\"\n[decision_linear_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_linear_sara_sgd_normtrans.png \"Decision linear  SGD + Data augmentation\"\n[decision_sara_sgd]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_sara_sgd.png \"Decision SGD\"\n[decision_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_sara_adam_normtrans_lr54.png \"Decision Adam  + Data Augmentation\"\n[decision_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/decision_sara_sgd_normtrans_v2.png \"Decision SGD  + Data Augmentation\"\n[siamese1_layers]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_layers.png \"Siamese Cosine 1 layers\"\n[siamese1_sara_sgd]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_sgd.png \"Siamese Cosine 1 SGD\"\n[siamese1_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_adam_normtrans_lr54.png \"Siamese Cosine 1 Adam  + Data Augmentation\"\n[siamese1_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_sgd_normtrans.png  \"Siamese Cosine 1 SGD  + Data Augmentation\"\n[siamese2_layers]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese2_layers.png  \"Siamese 2 layers\"\n[siamese2_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese2_sara_adam_normtrans.png \"Siamese Cosine 2 Adam  + Data Augmentation\"\n[siamese2_sara_sgd]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese2_sara_sgd.png  \"Siamese Cosine 2 SGD\"\n[siamese2_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese2_sara_sgd_normtrans.png  \"Siamese Cosine 2  SGD  + Data Augmentation\"\n[vgg_arch]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/vgg_arch.png \"VGG architecture\"\n[vgg_features]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/vgg_features.png \"VGG features\"\n\n[triplet1_sara_adam_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_triplet_adam_normtrans.png \"Siamese Triplet 1 Adam  + Data Augmentation\"\n[triplet1_sara_sgd_normtrans]: https://github.com/carlosb1/upc-aidl-19-team4/blob/master/resources/siamese1_sara_triplet_sgd_normtrans.png  \"Siamese Triplet 1 SGD  + Data Augmentation\"\n\n\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9976263808482358
      ],
      "excerpt": "\u251c\u2500\u2500 recognition                               -> Recognition pipeline \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9092486771425272,
        0.9977994744046882
      ],
      "excerpt": "    - code https://github.com/cydonia999/Tiny_Faces_in_Tensorflow \n    - paper https://arxiv.org/abs/1612.04402 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9092486771425272
      ],
      "excerpt": "    - code https://github.com/sthanhng/yoloface \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8955886365383559
      ],
      "excerpt": "| Cosine v1 + triplet + SGD + DA   |   83.28              |    86.32  | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8480724083947546
      ],
      "excerpt": "In general, Siamese cosine v1 works better.  \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/carlosb1/upc-aidl-19-team4",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-07-03T13:39:53Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-16T05:06:01Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "*student: Carlos B\u00e1ez*\n\n\nProject report for the Deep learning postgrade at UPC tech talent (Barcelona). This report explains all the work done, results and extracted conclusions\n\nThe main idea in the project was the implementation of an end-to-end person recognition system. For this, I decided to split the project in two parts:\n\n\n- **Detection**. Study of different implemented algorithms and different datasets to choose the best option for us\n   \n- **Face Recognition**. It is implemented and modified four different solutions with a saimese architecture.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9454859524290288,
        0.9668329559119968
      ],
      "excerpt": "At the beginning, my main motivation was the implementation of a complete pipeline for people recognition, where I analysed the different parts: detection and recognition. In the moment to work with recognition I liked the  Siamese networks[1] and how they improve the performance then  I decided to review it. \nAfter this, I started to be interested in how a retrieval system can work and can be scalable applying cosine functions[2]. With this code, I could figure out how the extraction of features has a powerful role int this type of solution. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8589778470026721
      ],
      "excerpt": "For the detection module. It was studied and analysed two neural networks and two datasets: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9596376475640728
      ],
      "excerpt": "The bubble graph can give us a small overview about the differences of both: (accuracy, time and number of parameters for each network): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9330045603891003
      ],
      "excerpt": "In this image, I can preview the VGG architecture and its convolutional module. It can give us an idea where It is extracted my features for the neural networks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8069728402877135
      ],
      "excerpt": "Previous architectures are depicted in the following schematics. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9294151581912674
      ],
      "excerpt": "In the second type of architectures, they include the concatenation and the decision network to classify. The second done is adding an extra linear layer to train. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8622992591274278,
        0.9313827171139852,
        0.8441009825848749,
        0.9644523448245693,
        0.9715201291791636
      ],
      "excerpt": "In order to evaluate which algorithm can fit better, I did different tests: \n- The chosen dataset is the [cfp dataset][cfp_dataset]. It includes annotations for different or same pair of faces. \n- The result table has the validation accuracy for the dataset, the idea is the calculation of the test accuracy (usin the splitted test dataset) for the best option of all. \n- The table includes results of the tests but It was done some experiments to figure out how to tune parameters as the learning rate. \n- The data augmentation applies jitter, flip and rotations for our images.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9934005241273965
      ],
      "excerpt": "Here, it is the table of results for the validation split: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9898692562494618
      ],
      "excerpt": "The winner in the benchmark is the Cosine v1 + Triplet +  SGD optimizer and Data augmentation. With this choosen neural network, it is tested with the test data set where it is got these results: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8614275699656612
      ],
      "excerpt": "First experiments that I did is applying SGD to obtain first results that I will be able to compare with different configurations. Here, It is possible to check how it learns without problems.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9484172382590775
      ],
      "excerpt": "The data augmentation helps in a better training. It is possible to check how the validation and training data are fitting better. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9749323677118286
      ],
      "excerpt": "Furthermore, the Adam optimizer works well with cosine networks. It is possible to check how it is improved the process to find the best loss. Unfortunately, The accuracy was poor, I tried different values for the learning rate, weight decay (0, 0.001, 5e-4) but It doesn't help, I got the conclusion I need more time to find the best hyperparameters for our case. For this, I stopped this study line. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8290135951251166
      ],
      "excerpt": "My last test was the implementation of the triplet loss where I got the best results. The idea to use negative and positive images in the loss function provide more comparative information to the loss function (para metric was used by default, in this case 1.0) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9378561519077321
      ],
      "excerpt": "It is possible check how the overfitting happens very fast, and I starts to figure out that It is not the best workflow in my use case. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9555842998048816
      ],
      "excerpt": "Here, I figured out that the data augmentation is not improving the values, the overfitting only happens some epochs after.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8193261316887646
      ],
      "excerpt": "Applying Adam, in this case, was exhausting... I tried different hypeparameters values but the accuracy was not better. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "UPC practice Person identification",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/carlosb1/upc-aidl-19-team4/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sat, 25 Dec 2021 17:29:27 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/carlosb1/upc-aidl-19-team4/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "carlosb1/upc-aidl-19-team4",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/carlosb1/upc-aidl-19-team4/master/scripts/print_graphs.ipynb",
      "https://raw.githubusercontent.com/carlosb1/upc-aidl-19-team4/master/scripts/graphs_model.ipynb",
      "https://raw.githubusercontent.com/carlosb1/upc-aidl-19-team4/master/scripts/train.ipynb",
      "https://raw.githubusercontent.com/carlosb1/upc-aidl-19-team4/master/scripts/test_practica_carlos.ipynb"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/carlosb1/upc-aidl-19-team4/master/scripts/remote2local.sh",
      "https://raw.githubusercontent.com/carlosb1/upc-aidl-19-team4/master/scripts/local2remote.sh",
      "https://raw.githubusercontent.com/carlosb1/upc-aidl-19-team4/master/pipeline/scripts/get_models.sh",
      "https://raw.githubusercontent.com/carlosb1/upc-aidl-19-team4/master/pipeline/recognition/parse_cfg_dataset.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8595029190753113
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 parse_cfg_dataset.sh                  -> Script to fix dataset paths \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9441222378192345
      ],
      "excerpt": "    \u251c\u2500\u2500 get_models.sh                         -> Download YOLO weights \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.906142958363181
      ],
      "excerpt": "\u251c\u2500\u2500 local2remote.sh                           -> Script to upload from local to one server \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8178861353814763
      ],
      "excerpt": "\u251c\u2500\u2500 remote2local.sh                           -> Script to download from remote to local  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8454484804509997
      ],
      "excerpt": "    - code https://github.com/cydonia999/Tiny_Faces_in_Tensorflow \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8454484804509997
      ],
      "excerpt": "    - code https://github.com/sthanhng/yoloface \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8586320158497007
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 FDDB_convert_ellipse_to_rect.py   -> Parser from ellipse to rectangle for FDDB dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9240068879197622,
        0.8904315581098956
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 FDDB_show_images.py               -> Example to display FDDB dataset \n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 WIDERFaceDataset.py               -> Wider dataset class example  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8935389680751004,
        0.8078863641545839
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 tiny_face_eval.py                 -> Entrypoint for tiny_faces model (Tensorflow) \n\u2502\u00a0\u00a0 \u2514\u2500\u2500 yolo                                  -> Folder for YOLO model  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8754366523910023
      ],
      "excerpt": "\u2502\u00a0\u00a0         \u251c\u2500\u2500 model.py                      -> YOLO model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8142835995138061
      ],
      "excerpt": "\u251c\u2500\u2500 README.md                                 -> Main README.md \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8796896980567107
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 cfp_dataset.py                        -> CFP Dataset class \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8446803938462032,
        0.8058918679184919,
        0.8260745820906511
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 metrics_retrieval.py                  -> Class to implement ranking \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 models.py                             -> Class with different models \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 params.py                             -> Builder params pattern to customize different tests \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8736285052654941,
        0.9145430750862464
      ],
      "excerpt": "\u2502\u00a0\u00a0 \u251c\u2500\u2500 tests.py                              -> Class to execute different tests \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 train.py                              -> Main class which train loop \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9113953246824341
      ],
      "excerpt": "    \u2514\u2500\u2500 utils.py                              -> Other functions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8306128832620779
      ],
      "excerpt": "\u251c\u2500\u2500 test_practica_carlos.ipynb                -> DEMO. First version of the final demo.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8359299706379749
      ],
      "excerpt": "![alt text][bubbles] \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8770206006234436
      ],
      "excerpt": "|      Name           | SGD    | SGD + Data aug | Adam + Data aug | \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/carlosb1/upc-aidl-19-team4/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Jupyter Notebook",
      "Shell"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018 cydonia\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Introduction",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "upc-aidl-19-team4",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "carlosb1",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/carlosb1/upc-aidl-19-team4/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sat, 25 Dec 2021 17:29:27 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Installation (for python 3.6+)\n```\npip install -r requirements.txt\n\n```\n\nThe code has different entrypoints for different use cases (detection, recognition, creation of graphs, parsing, upload data). The main split of the work  is in two main\nuse cases: *detection* and *recognition* where they are:\n\t\n- Detection - `evaluate_tiny_faces.py` and `evaluate_yolo.py` to execute the benchmark and run the detection algorithms\n- Recognition - `test.py` is the script to train a new neural network. For the triplet, it is the last one implemented, it needed a set of important changes in the architecture, for this reason, it is created a different file `test_triplet.py`\n\nIt is important to comment that I didn't add argument line parser because It was not clear the requirements while I was developing.. For this reason, you must change different\npaths (datasets, weights, etc..) paths for your environment.\n\nThen, to execute the training It must be something like this (for python 3.6+):\n```\n#: In the recognition directory\npython tests.py\n```\nfor triplet training similar:\n```\n#: In the recognition directory\npython test_triplet.py\n```\n\n- If you must change parameters, you change the Builder Params pattern, it is used to customize your parameters[3]\n\n**NOTE**:  It is obvious that the code has technical debt, my main effort was to find the best architecture and parameters.. The code needs to be refactorized.\n\nTo get the validation and test accuracy for recognition. From the recognition folder, you can execute `metrics.py` (for python 3.6+)\n\n```\npython metrics.py path_saved_model_file [threshold]\n``` \n\nIf you add the threshold, it will calculate the accuracy taking care the argument, otherwise it will calculate the best threshold for the dataset and  calculate both accuracies.\n\nThe demo is included in `scripts/test_practica_carlos.py`\n\n**WEIGHTS:**\n- YOLO WEIGHTS: https://drive.google.com/open?id=1ZsWJx2IwMTO7WZrlyC6Bg4G-yUA5Vhd1\n- TINY_FACES WEIGHTS: https://drive.google.com/open?id=18NuCfWNScDpCr9Un3yuhuE6BNpf_2-0e\n\n",
      "technique": "Header extraction"
    }
  ]
}
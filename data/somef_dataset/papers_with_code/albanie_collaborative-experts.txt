This repo provides code:
- TeachText which leverages complementary cues from multiple text encoders to provide an enhanced supervisory signal to the retrieval model using a generalize distillation setup ([paper](http://arxiv.org/abs/2104.08271), [project page](https://www.robots.ox.ac.uk/~vgg/research/teachtext/))
- Learning and evaluating joint video-text embeddings for the task of video retrieval. The approach is described in the paper "Use What You Have: Video retrieval using representations from collaborative experts" ([paper](https://arxiv.org/abs/1907.13487), [project page](https://www.robots.ox.ac.uk/~vgg/research/collaborative-experts/))
- CVPR 2020 Pentathlon challenge

**Requirements:** The code assumes PyTorch 1.4 and Python 3.7 (other versions may work, but have not been tested).  See the section on dependencies towards the end of this file for specific package requirements.

### TeachText

![TeachText diagram](figs/TeachText_method.jpg)

**TeachText results on MSRVTT Benchmark**

| Model | Split | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | Links |
| ----- | ------| ---- | --- | --- | ---- | ---- | --- | --- | --- | ----- |
| CE    | Full  | t2v  | <sub><sup>11.0<sub>(0.0)</sub></sup></sub> | <sub><sup>30.8<sub>(0.1)</sub></sup></sub> | <sub><sup>43.3<sub>(0.3)</sub></sup></sub> | <sub><sup>73.1<sub>(0.2)</sub></sup></sub> | <sub><sup>15.0<sub>(0.0)</sub></sup></sub> | <sub><sup>81.8<sub>(0.2)</sub></sup></sub> | <sub><sup>24.4<sub>(0.1)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msrvtt-train-full-ce/6becbb74/seed-0/2020-06-28_18-31-21/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msrvtt-train-full-ce/6becbb74/seed-0/2020-06-28_18-31-21/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/msrvtt-train-full-ce/6becbb74/seed-0/2020-06-28_18-31-21/summary-seed-0_seed-1_seed-2.json) |
| CE+    | Full  | t2v  | <sub><sup>13.8<sub>(0.1)</sub></sup></sub> | <sub><sup>36.5<sub>(0.2)</sub></sup></sub> | <sub><sup>49.4<sub>(0.4)</sub></sup></sub> | <sub><sup>77.6<sub>(0.2)</sub></sup></sub> | <sub><sup>11.0<sub>(0.0)</sub></sup></sub> | <sub><sup>69.4<sub>(0.8)</sub></sup></sub> | <sub><sup>29.2<sub>(0.2)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msrvtt-train-gpt2-xl-finetuned-adam/244af891/seed-0/2020-10-01_12-22-00/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msrvtt-train-gpt2-xl-finetuned-adam/244af891/seed-0/2020-10-01_12-22-00/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/msrvtt-train-gpt2-xl-finetuned-adam/244af891/seed-0/2020-10-01_12-22-00/summary-seed-0_seed-1_seed-2.json) |
| TeachText - CE    | Full  | t2v  | <sub><sup>11.8<sub>(0.1)</sub></sup></sub> | <sub><sup>32.7<sub>(0.2)</sub></sup></sub> | <sub><sup>45.3<sub>(0.2)</sub></sup></sub> | <sub><sup>74.9<sub>(0.1)</sub></sup></sub> | <sub><sup>13.0<sub>(0.0)</sub></sup></sub> | <sub><sup>74.9<sub>(0.4)</sub></sup></sub> | <sub><sup>25.9<sub>(0.1)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msrvtt-train-ce-intra-mte/4d4508a2/seed-0/2020-11-06_17-27-00/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msrvtt-train-ce-intra-mte/4d4508a2/seed-0/2020-11-06_17-27-00/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/msrvtt-train-ce-intra-mte/4d4508a2/seed-0/2020-11-06_17-27-00/summary-seed-0_seed-1_seed-2.json) |
| TeachText - CE+    | Full  | t2v  | <sub><sup>14.6<sub>(0.0)</sub></sup></sub> | <sub><sup>37.9<sub>(0.1)</sub></sup></sub> | <sub><sup>50.9<sub>(0.2)</sub></sup></sub> | <sub><sup>78.9<sub>(0.0)</sub></sup></sub> | <sub><sup>10.0<sub>(0.0)</sub></sup></sub> | <sub><sup>63.1<sub>(0.2)</sub></sup></sub> | <sub><sup>30.4<sub>(0.0)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msrvtt-train-gpt2-xl-finetuned-mte-adam/6427fd41/seed-0/2020-09-30_20-34-12/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msrvtt-train-gpt2-xl-finetuned-mte-adam/6427fd41/seed-0/2020-09-30_20-34-12/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/msrvtt-train-gpt2-xl-finetuned-mte-adam/6427fd41/seed-0/2020-09-30_20-34-12/summary-seed-0_seed-1_seed-2.json) |

Please note that the numbers are higher than in the original CE due to compression artefacts correction

**Denoising results on MSRVTT**

| Model | Split | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | Links |
| ----- | ------| ---- | --- | --- | ---- | ---- | --- | --- | --- | ----- |
| CE+    | Full  | t2v  | <sub><sup>14.4<sub>(0.1)</sub></sup></sub> | <sub><sup>37.4<sub>(0.2)</sub></sup></sub> | <sub><sup>50.2<sub>(0.1)</sub></sup></sub> | <sub><sup>77.9<sub>(0.1)</sub></sup></sub> | <sub><sup>10.0<sub>(0.0)</sub></sup></sub> | <sub><sup>70.8<sub>(0.1)</sub></sup></sub> | <sub><sup>30.0<sub>(0.1)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msrvtt-train-gpt2-xl-finetuned-denoising-adam/a61447a9/seed-0/2020-11-11_05-31-29/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msrvtt-train-gpt2-xl-finetuned-denoising-adam/a61447a9/seed-0/2020-11-11_05-31-29/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/msrvtt-train-gpt2-xl-finetuned-denoising-adam/a61447a9/seed-0/2020-11-11_05-31-29/summary-seed-0_seed-1_seed-2.json) |
| TeachText - CE+    | Full  | t2v  | <sub><sup>14.9<sub>(0.1)</sub></sup></sub> | <sub><sup>38.3<sub>(0.1)</sub></sup></sub> | <sub><sup>51.5<sub>(0.1)</sub></sup></sub> | <sub><sup>79.2<sub>(0.1)</sub></sup></sub> | <sub><sup>10.0<sub>(0.0)</sub></sup></sub> | <sub><sup>62.5<sub>(0.5)</sub></sup></sub> | <sub><sup>30.9<sub>(0.1)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msrvtt-train-gpt2-xl-finetuned-mte-denoising-adam/2cc98676/seed-0/2020-11-11_06-21-03/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msrvtt-train-gpt2-xl-finetuned-mte-denoising-adam/2cc98676/seed-0/2020-11-11_06-21-03/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/msrvtt-train-gpt2-xl-finetuned-mte-denoising-adam/2cc98676/seed-0/2020-11-11_06-21-03/summary-seed-0_seed-1_seed-2.json) |

**TeachText results on MSVD Benchmark**

| Model | Split | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | Links |
| ----- | ------| ---- | --- | --- | ---- | ---- | --- | --- | --- | ----- |
| CE    | Full  | t2v  | <sub><sup>21.5<sub>(0.6)</sub></sup></sub> | <sub><sup>52.3<sub>(0.9)</sub></sup></sub> | <sub><sup>67.5<sub>(0.8)</sub></sup></sub> | <sub><sup>90.7<sub>(0.0)</sub></sup></sub> | <sub><sup>5.0<sub>(0.0)</sub></sup></sub> | <sub><sup>20.4<sub>(0.0)</sub></sup></sub> | <sub><sup>42.3<sub>(0.6)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msvd-train-full-ce/2ae80bea/seed-0/2020-11-11_13-16-14/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msvd-train-full-ce/2ae80bea/seed-0/2020-11-11_13-16-14/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/msvd-train-full-ce/2ae80bea/seed-0/2020-11-11_13-16-14/summary-seed-0_seed-1_seed-2.json) |
| CE+    | Full  | t2v  | <sub><sup>25.1<sub>(0.9)</sub></sup></sub> | <sub><sup>56.5<sub>(1.4)</sub></sup></sub> | <sub><sup>70.9<sub>(1.6)</sub></sup></sub> | <sub><sup>92.4<sub>(0.5)</sub></sup></sub> | <sub><sup>4.0<sub>(0.0)</sub></sup></sub> | <sub><sup>17.8<sub>(0.6)</sub></sup></sub> | <sub><sup>46.5<sub>(1.0)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msvd-train-gpt2-xl-finetuned-adam/db396303/seed-0/2020-10-01_13-17-33/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msvd-train-gpt2-xl-finetuned-adam/db396303/seed-0/2020-10-01_13-17-33/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/msvd-train-gpt2-xl-finetuned-adam/db396303/seed-0/2020-10-01_13-17-33/summary-seed-0_seed-1_seed-2.json) |
| TeachText - CE    | Full  | t2v  | <sub><sup>22.1<sub>(0.5)</sub></sup></sub> | <sub><sup>52.2<sub>(0.6)</sub></sup></sub> | <sub><sup>67.2<sub>(0.8)</sub></sup></sub> | <sub><sup>91.2<sub>(0.5)</sub></sup></sub> | <sub><sup>5.0<sub>(0.0)</sub></sup></sub> | <sub><sup>19.6<sub>(0.5)</sub></sup></sub> | <sub><sup>42.6<sub>(0.4)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msvd-train-ce-intra-mte/a3026a07/seed-0/2020-11-13_00-19-59/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msvd-train-ce-intra-mte/a3026a07/seed-0/2020-11-13_00-19-59/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/msvd-train-ce-intra-mte/a3026a07/seed-0/2020-11-13_00-19-59/summary-seed-0_seed-1_seed-2.json) |
| TeachText - CE+    | Full  | t2v  | <sub><sup>25.1<sub>(0.6)</sub></sup></sub> | <sub><sup>56.8<sub>(0.6)</sub></sup></sub> | <sub><sup>71.2<sub>(0.6)</sub></sup></sub> | <sub><sup>92.7<sub>(0.3)</sub></sup></sub> | <sub><sup>4.0<sub>(0.0)</sub></sup></sub> | <sub><sup>16.8<sub>(0.3)</sub></sup></sub> | <sub><sup>46.6<sub>(0.5)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msvd-train-gpt2-xl-finetuned-mte-adam/0af2a1ed/seed-0/2020-09-30_21-30-15/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msvd-train-gpt2-xl-finetuned-mte-adam/0af2a1ed/seed-0/2020-09-30_21-30-15/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/msvd-train-gpt2-xl-finetuned-mte-adam/0af2a1ed/seed-0/2020-09-30_21-30-15/summary-seed-0_seed-1_seed-2.json) |

**Denoising results on MSVD**

| Model | Split | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | Links |
| ----- | ------| ---- | --- | --- | ---- | ---- | --- | --- | --- | ----- |
| CE+    | Full  | t2v  | <sub><sup>26.2<sub>(0.5)</sub></sup></sub> | <sub><sup>57.7<sub>(1.0)</sub></sup></sub> | <sub><sup>72.2<sub>(1.2)</sub></sup></sub> | <sub><sup>92.2<sub>(0.4)</sub></sup></sub> | <sub><sup>4.0<sub>(0.0)</sub></sup></sub> | <sub><sup>17.9<sub>(0.5)</sub></sup></sub> | <sub><sup>47.8<sub>(0.6)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msvd-train-gpt2-xl-finetuned-denoising-adam/71686a77/seed-0/2020-11-11_12-19-27/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msvd-train-gpt2-xl-finetuned-denoising-adam/71686a77/seed-0/2020-11-11_12-19-27/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/msvd-train-gpt2-xl-finetuned-denoising-adam/71686a77/seed-0/2020-11-11_12-19-27/summary-seed-0_seed-1_seed-2.json) |
| TeachText - CE+    | Full  | t2v  | <sub><sup>25.4<sub>(0.4)</sub></sup></sub> | <sub><sup>56.9<sub>(0.5)</sub></sup></sub> | <sub><sup>71.3<sub>(0.3)</sub></sup></sub> | <sub><sup>92.8<sub>(0.2)</sub></sup></sub> | <sub><sup>4.0<sub>(0.0)</sub></sup></sub> | <sub><sup>16.7<sub>(0.2)</sub></sup></sub> | <sub><sup>46.9<sub>(0.3)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msvd-train-gpt2-xl-finetuned-mte-denoising-adam/66dc5dff/seed-0/2020-11-11_12-57-29/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/msvd-train-gpt2-xl-finetuned-mte-denoising-adam/66dc5dff/seed-0/2020-11-11_12-57-29/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/msvd-train-gpt2-xl-finetuned-mte-denoising-adam/66dc5dff/seed-0/2020-11-11_12-57-29/summary-seed-0_seed-1_seed-2.json) |

**TeachText results on DiDeMo Benchmark**

| Model | Split | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | Links |
| ----- | ------| ---- | --- | --- | ---- | ---- | --- | --- | --- | ----- |
| CE    | Full  | t2v  | <sub><sup>17.1<sub>(0.9)</sub></sup></sub> | <sub><sup>41.9<sub>(0.2)</sub></sup></sub> | <sub><sup>56.0<sub>(0.5)</sub></sup></sub> | <sub><sup>83.4<sub>(0.9)</sub></sup></sub> | <sub><sup>8.0<sub>(0.0)</sub></sup></sub> | <sub><sup>42.8<sub>(2.8)</sub></sup></sub> | <sub><sup>34.2<sub>(0.4)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/didemo-train-full-ce/4ea49b50/seed-0/2020-06-28_20-04-46/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/didemo-train-full-ce/4ea49b50/seed-0/2020-06-28_20-04-46/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/didemo-train-full-ce/4ea49b50/seed-0/2020-06-28_20-04-46/summary-seed-0_seed-1_seed-2.json) |
| CE+    | Full  | t2v  | <sub><sup>18.2<sub>(0.3)</sub></sup></sub> | <sub><sup>43.9<sub>(1.1)</sub></sup></sub> | <sub><sup>57.1<sub>(0.9)</sub></sup></sub> | <sub><sup>84.0<sub>(1.6)</sub></sup></sub> | <sub><sup>7.9<sub>(0.1)</sub></sup></sub> | <sub><sup>38.5<sub>(3.4)</sub></sup></sub> | <sub><sup>35.8<sub>(0.4)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/didemo-train-gpt2-xl-finetuned-adam/616cf11b/seed-0/2020-10-01_13-31-57/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/didemo-train-gpt2-xl-finetuned-adam/616cf11b/seed-0/2020-10-01_13-31-57/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/didemo-train-gpt2-xl-finetuned-adam/616cf11b/seed-0/2020-10-01_13-31-57/summary-seed-0_seed-1_seed-2.json) |
| TeachText - CE    | Full  | t2v  | <sub><sup>21.0<sub>(0.7)</sub></sup></sub> | <sub><sup>47.5<sub>(1.1)</sub></sup></sub> | <sub><sup>61.9<sub>(0.6)</sub></sup></sub> | <sub><sup>86.4<sub>(1.0)</sub></sup></sub> | <sub><sup>6.0<sub>(0.0)</sub></sup></sub> | <sub><sup>35.1<sub>(1.0)</sub></sup></sub> | <sub><sup>39.5<sub>(0.5)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/didemo-train-ce-intra-mte/1a5a249f/seed-0/2020-11-06_19-12-39/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/didemo-train-ce-intra-mte/1a5a249f/seed-0/2020-11-06_19-12-39/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/didemo-train-ce-intra-mte/1a5a249f/seed-0/2020-11-06_19-12-39/summary-seed-0_seed-1_seed-2.json) |
| TeachText - CE+    | Full  | t2v  | <sub><sup>21.6<sub>(0.8)</sub></sup></sub> | <sub><sup>48.6<sub>(0.5)</sub></sup></sub> | <sub><sup>62.9<sub>(0.7)</sub></sup></sub> | <sub><sup>86.8<sub>(0.3)</sub></sup></sub> | <sub><sup>6.0<sub>(0.0)</sub></sup></sub> | <sub><sup>31.5<sub>(0.8)</sub></sup></sub> | <sub><sup>40.4<sub>(0.4)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/didemo-train-gpt2-xl-finetuned-mte-adam/f004e587/seed-0/2020-09-30_20-19-13/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/didemo-train-gpt2-xl-finetuned-mte-adam/f004e587/seed-0/2020-09-30_20-19-13/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/didemo-train-gpt2-xl-finetuned-mte-adam/f004e587/seed-0/2020-09-30_20-19-13/summary-seed-0_seed-1_seed-2.json) |

**TeachText results on LSMDC Benchmark**

| Model | Split | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | Links |
| ----- | ------| ---- | --- | --- | ---- | ---- | --- | --- | --- | ----- |
| CE    | Full  | t2v  | <sub><sup>12.4<sub>(0.7)</sub></sup></sub> | <sub><sup>28.5<sub>(0.8)</sub></sup></sub> | <sub><sup>37.9<sub>(0.6)</sub></sup></sub> | <sub><sup>64.5<sub>(0.8)</sub></sup></sub> | <sub><sup>21.7<sub>(0.6)</sub></sup></sub> | <sub><sup>88.0<sub>(4.8)</sub></sup></sub> | <sub><sup>23.7<sub>(0.3)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/lsmdc-train-full-ce/7af368b1/seed-0/2020-06-28_20-40-54/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/lsmdc-train-full-ce/7af368b1/seed-0/2020-06-28_20-40-54/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/lsmdc-train-full-ce/7af368b1/seed-0/2020-06-28_20-40-54/summary-seed-0_seed-1_seed-2.json) |
| CE+    | Full  | t2v  | <sub><sup>14.9<sub>(0.7)</sub></sup></sub> | <sub><sup>33.7<sub>(0.2)</sub></sup></sub> | <sub><sup>44.1<sub>(0.7)</sub></sup></sub> | <sub><sup>67.3<sub>(0.8)</sub></sup></sub> | <sub><sup>15.3<sub>(0.6)</sub></sup></sub> | <sub><sup>77.8<sub>(6.7)</sub></sup></sub> | <sub><sup>28.1<sub>(0.3)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/lsmdc-train-gpt2-xl-finetuned-adam/9e2c8afd/seed-0/2020-10-01_13-48-49/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/lsmdc-train-gpt2-xl-finetuned-adam/9e2c8afd/seed-0/2020-10-01_13-48-49/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/lsmdc-train-gpt2-xl-finetuned-adam/9e2c8afd/seed-0/2020-10-01_13-48-49/summary-seed-0_seed-1_seed-2.json) |
| TeachText - CE    | Full  | t2v  | <sub><sup>13.7<sub>(0.9)</sub></sup></sub> | <sub><sup>30.2<sub>(0.4)</sub></sup></sub> | <sub><sup>40.1<sub>(0.4)</sub></sup></sub> | <sub><sup>66.0<sub>(0.6)</sub></sup></sub> | <sub><sup>19.8<sub>(1.3)</sub></sup></sub> | <sub><sup>84.0<sub>(1.8)</sub></sup></sub> | <sub><sup>25.5<sub>(0.5)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/lsmdc-train-ce-intra-mte/1a5555af/seed-0/2020-11-06_19-32-23/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/lsmdc-train-ce-intra-mte/1a5555af/seed-0/2020-11-06_19-32-23/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/lsmdc-train-ce-intra-mte/1a5555af/seed-0/2020-11-06_19-32-23/summary-seed-0_seed-1_seed-2.json) |
| TeachText - CE+    | Full  | t2v  | <sub><sup>17.2<sub>(0.5)</sub></sup></sub> | <sub><sup>36.5<sub>(0.7)</sub></sup></sub> | <sub><sup>46.3<sub>(0.4)</sub></sup></sub> | <sub><sup>68.8<sub>(0.4)</sub></sup></sub> | <sub><sup>13.7<sub>(0.6)</sub></sup></sub> | <sub><sup>72.3<sub>(0.1)</sub></sup></sub> | <sub><sup>30.7<sub>(0.3)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/lsmdc-train-gpt2-xl-finetuned-mte-adam/38e65732/seed-0/2020-09-30_20-52-52/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/lsmdc-train-gpt2-xl-finetuned-mte-adam/38e65732/seed-0/2020-09-30_20-52-52/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/lsmdc-train-gpt2-xl-finetuned-mte-adam/38e65732/seed-0/2020-09-30_20-52-52/summary-seed-0_seed-1_seed-2.json) |

**TeachText results on Activity-Net Benchmark**

| Model | Split | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | Links |
| ----- | ------| ---- | --- | --- | ---- | ---- | --- | --- | --- | ----- |
| CE    | Full  | t2v  | <sub><sup>19.9<sub>(0.4)</sub></sup></sub> | <sub><sup>50.1<sub>(0.8)</sub></sup></sub> | <sub><sup>66.1<sub>(0.6)</sub></sup></sub> | <sub><sup>92.2<sub>(0.7)</sub></sup></sub> | <sub><sup>5.3<sub>(0.6)</sub></sup></sub> | <sub><sup>21.3<sub>(1.1)</sub></sup></sub> | <sub><sup>40.4<sub>(0.3)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/activity-net-train-full-ce/9601c704/seed-0/2020-07-31_00-23-01/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/activity-net-train-full-ce/9601c704/seed-0/2020-07-31_00-23-01/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/activity-net-train-full-ce/9601c704/seed-0/2020-07-31_00-23-01/summary-seed-0_seed-1_seed-2.json) |
| CE+    | Full  | t2v  | <sub><sup>19.4<sub>(0.2)</sub></sup></sub> | <sub><sup>49.3<sub>(0.5)</sub></sup></sub> | <sub><sup>65.4<sub>(0.4)</sub></sup></sub> | <sub><sup>92.1<sub>(0.2)</sub></sup></sub> | <sub><sup>6.0<sub>(0.0)</sub></sup></sub> | <sub><sup>22.5<sub>(0.4)</sub></sup></sub> | <sub><sup>39.7<sub>(0.0)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/activity-net-train-gpt2-xl-finetuned-adam/a791f27d/seed-0/2020-10-01_13-42-29/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/activity-net-train-gpt2-xl-finetuned-adam/a791f27d/seed-0/2020-10-01_13-42-29/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/activity-net-train-gpt2-xl-finetuned-adam/a791f27d/seed-0/2020-10-01_13-42-29/summary-seed-0_seed-1_seed-2.json) |
| TeachText - CE    | Full  | t2v  | <sub><sup>22.7<sub>(0.8)</sub></sup></sub> | <sub><sup>56.2<sub>(0.1)</sub></sup></sub> | <sub><sup>71.6<sub>(0.8)</sub></sup></sub> | <sub><sup>95.3<sub>(0.1)</sub></sup></sub> | <sub><sup>4.0<sub>(0.0)</sub></sup></sub> | <sub><sup>15.8<sub>(0.1)</sub></sup></sub> | <sub><sup>45.0<sub>(0.6)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/activity-net-train-ce-intra-mte/620ad6b4/seed-0/2020-11-06_19-12-39/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/activity-net-train-ce-intra-mte/620ad6b4/seed-0/2020-11-06_19-12-39/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/activity-net-train-ce-intra-mte/620ad6b4/seed-0/2020-11-06_19-12-39/summary-seed-0_seed-1_seed-2.json) |
| TeachText - CE+    | Full  | t2v  | <sub><sup>23.5<sub>(0.2)</sub></sup></sub> | <sub><sup>57.2<sub>(0.6)</sub></sup></sub> | <sub><sup>73.6<sub>(0.2)</sub></sup></sub> | <sub><sup>96.1<sub>(0.1)</sub></sup></sub> | <sub><sup>4.0<sub>(0.0)</sub></sup></sub> | <sub><sup>13.7<sub>(0.1)</sub></sup></sub> | <sub><sup>46.3<sub>(0.2)</sub></sup></sub> | [config_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/activity-net-train-gpt2-xl-finetuned-mte-adam/87d04a50/seed-0/2020-10-01_08-48-36/config.json), [model_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/models/activity-net-train-gpt2-xl-finetuned-mte-adam/87d04a50/seed-0/2020-10-01_08-48-36/trained_model.pth), [log_TT](http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/log/activity-net-train-gpt2-xl-finetuned-mte-adam/87d04a50/seed-0/2020-10-01_08-48-36/summary-seed-0_seed-1_seed-2.json) |

You can download the high quality features used for TeachText from:

```
For MSRVTT:
http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/high-quality/high-quality-MSRVTT-experts.tar.gz
sha1sum: 734650c3b98509996da75cdedc12101836624917

For MSVD:
http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/high-quality/high-quality-MSVD-experts.tar.gz
sha1sum: c8eba8c5291dd6bb501757ed0cc327cd22217965

For DiDeMo:
http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/high-quality/high-quality-DiDeMo-experts.tar.gz
sha1sum: 8e128309f12cf3260fe538f82578b5ad91a46bd0

For ActivityNet:
http:/www.robots.ox.ac.uk/~vgg/research/teachtext/data-hq/high-quality/high-quality-activity-net-experts.tar.gz
sha1sum: 2f3c7c2fe86bd6d0c6230464a940c429291a4012

```
### Collaborative Experts

![CE diagram](figs/CE.png)



**High-level Overview**: The *Collaborative Experts* framework aims to achieve robustness through two mechanisms:
1. The use of information from a wide range of modalities, including those that are typically always available in video (such as RGB) as well as more "specific" clues which may only occasionally be present (such as overlaid text).
2. A module that aims to combine these modalities into a fixed size representation that in a manner that is robust to noise.

**Requirements:** The code assumes PyTorch 1.4 and Python 3.7 (other versions may work, but have not been tested).  See the section on dependencies towards the end of this file for specific package requirements.


**Important: A note on the updated results**: A previous version of the codebase (and paper) reported results on the retrieval benchmarks that included a signficant software bug leading to an overestimate of performance.  We are extremely grateful to Valentin Gabeur who discovered this bug (it has been corrected in the current codebase).


### CVPR 2020: Pentathlon challenge

<p align="center">
<img width="300" alt="logo" src="figs/logo-centre.png">
</p>

We are hosting a video retrieval challenge as part of the Video Pentathlon Workshop. Find out how to participate [here](misc/challenge.md)!


### Pretrained video embeddings

We provide pretrained models for each dataset to reproduce the results reported in the paper [1] (references follow at the end of this README).  Each model is accompanied by training and evaluation logs.  Performance is evalauted for retrieval in both directions (joint-embeddings can be used for either of these two tasks):
* `t2v` denotes that a text query is used to retrieve videos
* `v2t` denotes that a video query is used to retrieve text video descriptions

In the results reported below, the same model is used for both the t2v and v2t evaluations.  Each metric is reported as the mean and standard deviation (in parentheses) across three training runs.


**MSRVTT Benchmark**

| Model | Split | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Links |
| ----- | ------| ---- | --- | --- | ---- | ---- | --- | --- | ----- |
| CE    | Full  | t2v  | <sub><sup>10.0<sub>(0.1)</sub></sup></sub> | <sub><sup>29.0<sub>(0.3)</sub></sup></sub> | <sub><sup>41.2<sub>(0.2)</sub></sup></sub> | <sub><sup>71.4<sub>(0.1)</sub></sup></sub> | <sub><sup>16.0<sub>(0.0)</sub></sup></sub> | <sub><sup>86.8<sub>(0.3)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/summary-seed-0_seed-1_seed-2.json) |
| CE    | 1k-A  | t2v  | <sub><sup>20.9<sub>(1.2)</sub></sup></sub> | <sub><sup>48.8<sub>(0.6)</sub></sup></sub> | <sub><sup>62.4<sub>(0.8)</sub></sup></sub> | <sub><sup>89.1<sub>(0.4)</sub></sup></sub> | <sub><sup>6.0<sub>(0.0)</sub></sup></sub> | <sub><sup>28.2<sub>(0.8)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-jsfusion-ce/2b66fed2/seed-0/2020-01-07_15-30-39/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-jsfusion-ce/2b66fed2/seed-0/2020-01-07_15-30-39/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-jsfusion-ce/2b66fed2/seed-0/2020-01-07_15-30-39/summary-seed-0_seed-1_seed-2.json) |
| CE    | 1k-B  | t2v  | <sub><sup>18.2<sub>(0.7)</sub></sup></sub> | <sub><sup>46.0<sub>(0.4)</sub></sup></sub> | <sub><sup>60.7<sub>(0.2)</sub></sup></sub> | <sub><sup>86.6<sub>(0.5)</sub></sup></sub> | <sub><sup>7.0<sub>(0.0)</sub></sup></sub> | <sub><sup>35.3<sub>(1.1)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-miech-ce/1958a75c/seed-0/2020-01-07_15-35-54/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-miech-ce/1958a75c/seed-0/2020-01-07_15-35-54/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-miech-ce/1958a75c/seed-0/2020-01-07_15-35-54/summary-seed-0_seed-1_seed-2.json) |
| MoEE* | 1k-B  | t2v  | <sub><sup>15.0<sub>(0.7)</sub></sup></sub> | <sub><sup>39.7<sub>(1.0)</sub></sup></sub> | <sub><sup>54.5<sub>(1.1)</sub></sup></sub> | <sub><sup>82.7<sub>(0.6)</sub></sup></sub> | <sub><sup>8.3<sub>(0.6)</sub></sup></sub> | <sub><sup>43.7<sub>(0.7)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-miech-miechfeats-moee/c71acf2c/seed-0/2020-01-07_15-14-30/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-miech-miechfeats-moee/c71acf2c/seed-0/2020-01-07_15-14-30/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-miech-miechfeats-moee/c71acf2c/seed-0/2020-01-07_15-14-30/summary-seed-0_seed-1_seed-2.json) |
| CE    | Full  | v2t  | <sub><sup>15.6<sub>(0.3)</sub></sup></sub> | <sub><sup>40.9<sub>(1.4)</sub></sup></sub> | <sub><sup>55.2<sub>(1.0)</sub></sup></sub> | <sub><sup>84.0<sub>(0.1)</sub></sup></sub> | <sub><sup>8.3<sub>(0.6)</sub></sup></sub> | <sub><sup>38.1<sub>(1.8)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/summary-seed-0_seed-1_seed-2.json) |
| CE    | 1k-A  | v2t  | <sub><sup>20.6<sub>(0.6)</sub></sup></sub> | <sub><sup>50.3<sub>(0.5)</sub></sup></sub> | <sub><sup>64.0<sub>(0.2)</sub></sup></sub> | <sub><sup>89.9<sub>(0.3)</sub></sup></sub> | <sub><sup>5.3<sub>(0.6)</sub></sup></sub> | <sub><sup>25.1<sub>(0.8)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-jsfusion-ce/2b66fed2/seed-0/2020-01-07_15-30-39/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-jsfusion-ce/2b66fed2/seed-0/2020-01-07_15-30-39/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-jsfusion-ce/2b66fed2/seed-0/2020-01-07_15-30-39/summary-seed-0_seed-1_seed-2.json) |
| CE    | 1k-B  | v2t  | <sub><sup>18.0<sub>(0.8)</sub></sup></sub> | <sub><sup>46.0<sub>(0.5)</sub></sup></sub> | <sub><sup>60.3<sub>(0.5)</sub></sup></sub> | <sub><sup>86.4<sub>(0.3)</sub></sup></sub> | <sub><sup>6.5<sub>(0.5)</sub></sup></sub> | <sub><sup>30.6<sub>(1.2)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-miech-ce/1958a75c/seed-0/2020-01-07_15-35-54/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-miech-ce/1958a75c/seed-0/2020-01-07_15-35-54/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-miech-ce/1958a75c/seed-0/2020-01-07_15-35-54/summary-seed-0_seed-1_seed-2.json) |
| MoEE* | 1k-B  | v2t  | <sub><sup>14.5<sub>(0.8)</sub></sup></sub> | <sub><sup>40.4<sub>(0.8)</sub></sup></sub> | <sub><sup>54.9<sub>(1.0)</sub></sup></sub> | <sub><sup>83.8<sub>(0.5)</sub></sup></sub> | <sub><sup>8.8<sub>(0.4)</sub></sup></sub> | <sub><sup>38.7<sub>(0.9)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-miech-miechfeats-moee/c71acf2c/seed-0/2020-01-07_15-14-30/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-miech-miechfeats-moee/c71acf2c/seed-0/2020-01-07_15-14-30/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-miech-miechfeats-moee/c71acf2c/seed-0/2020-01-07_15-14-30/summary-seed-0_seed-1_seed-2.json) |

Models marked with * use the features made available with the MoEE model of [2] (without OCR, speech and scene features), unstarred models on the `1k-B` and `Full` splits make use of OCR, speech and scene features, as well slightly stronger text encodings (GPT, rather than word2vec - see [1] for details). The MoEE model is implemented as a sanity check that our codebase approximately reproduces [2] (the [MoEE paper](https://arxiv.org/abs/1804.02516)).


See the [MSRVTT README](misc/datasets/msrvtt/README.md) for links to the train/val/test lists of each split.

**MSVD Benchmark**

| Model | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Links |
| ------| ------| ---:| ---:| ----:| ----:|----:|----:|------:|
| CE | t2v  | <sub><sup>19.8<sub>(0.3)</sub></sup></sub> | <sub><sup>49.0<sub>(0.3)</sub></sup></sub> | <sub><sup>63.8<sub>(0.1)</sub></sup></sub> | <sub><sup>89.0<sub>(0.2)</sub></sup></sub> | <sub><sup>6.0<sub>(0.0)</sub></sup></sub> | <sub><sup>23.1<sub>(0.3)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msvd-train-full-ce/5bb8dda1/seed-0/2020-01-30_12-29-56/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msvd-train-full-ce/5bb8dda1/seed-0/2020-01-30_12-29-56/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msvd-train-full-ce/5bb8dda1/seed-0/2020-01-30_12-29-56/summary-seed-0_seed-1_seed-2.json) |
| CE | v2t  | <sub><sup>23.9<sub>(1.4)</sub></sup></sub> | <sub><sup>50.2<sub>(0.8)</sub></sup></sub> | <sub><sup>59.6<sub>(1.2)</sub></sup></sub> | <sub><sup>82.3<sub>(0.7)</sub></sup></sub> | <sub><sup>5.6<sub>(0.5)</sub></sup></sub> | <sub><sup>41.2<sub>(3.4)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msvd-train-full-ce/5bb8dda1/seed-0/2020-01-30_12-29-56/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msvd-train-full-ce/5bb8dda1/seed-0/2020-01-30_12-29-56/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msvd-train-full-ce/5bb8dda1/seed-0/2020-01-30_12-29-56/summary-seed-0_seed-1_seed-2.json) |

See the [MSVD README](misc/datasets/msvd/README.md) for descriptions of the train/test splits. Note that the videos in the MSVD dataset do not have soundtracks.

**DiDeMo Benchmark**

| Model | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Links |
| ------| ------| ---:| ---:| ----:| ----:|----:|----:|------:|
| CE | t2v  | <sub><sup>16.1<sub>(1.4)</sub></sup></sub> | <sub><sup>41.1<sub>(0.4)</sub></sup></sub> | <sub><sup>54.4<sub>(0.8)</sub></sup></sub> | <sub><sup>82.7<sub>(0.3)</sub></sup></sub> | <sub><sup>8.3<sub>(0.6)</sub></sup></sub> | <sub><sup>43.7<sub>(3.6)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/didemo-train-full-ce/3d8c2ac9/seed-0/2020-01-30_07-43-45/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/didemo-train-full-ce/3d8c2ac9/seed-0/2020-01-30_07-43-45/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/didemo-train-full-ce/3d8c2ac9/seed-0/2020-01-30_07-43-45/summary-seed-0_seed-1_seed-2.json) |
| CE | v2t  | <sub><sup>15.6<sub>(1.3)</sub></sup></sub> | <sub><sup>40.9<sub>(0.4)</sub></sup></sub> | <sub><sup>55.2<sub>(0.5)</sub></sup></sub> | <sub><sup>82.2<sub>(1.3)</sub></sup></sub> | <sub><sup>8.2<sub>(0.3)</sub></sup></sub> | <sub><sup>42.4<sub>(3.3)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/didemo-train-full-ce/3d8c2ac9/seed-0/2020-01-30_07-43-45/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/didemo-train-full-ce/3d8c2ac9/seed-0/2020-01-30_07-43-45/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/didemo-train-full-ce/3d8c2ac9/seed-0/2020-01-30_07-43-45/summary-seed-0_seed-1_seed-2.json) |

See the [DiDeMo README](misc/datasets/didemo/README.md) for descriptions of the train/val/test splits.

**ActivityNet Benchmark**

| Model | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Links |
| ------| ------| ---:| ---:| ----:| ----:|----:|----:|------:|
| CE | t2v  | <sub><sup>18.2<sub>(0.3)</sub></sup></sub> | <sub><sup>47.7<sub>(0.6)</sub></sup></sub> | <sub><sup>63.9<sub>(0.5)</sub></sup></sub> | <sub><sup>91.4<sub>(0.4)</sub></sup></sub> | <sub><sup>6.0<sub>(0.0)</sub></sup></sub> | <sub><sup>23.1<sub>(0.5)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/activity-net-train-full-ce/cf5b1849/seed-0/2020-01-25_16-33-13/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/activity-net-train-full-ce/cf5b1849/seed-0/2020-01-25_16-33-13/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/activity-net-train-full-ce/cf5b1849/seed-0/2020-01-25_16-33-13/summary-seed-0_seed-1_seed-2.json) |
| CE | v2t  | <sub><sup>17.7<sub>(0.6)</sub></sup></sub> | <sub><sup>46.6<sub>(0.7)</sub></sup></sub> | <sub><sup>62.8<sub>(0.4)</sub></sup></sub> | <sub><sup>90.9<sub>(0.2)</sub></sup></sub> | <sub><sup>6.0<sub>(0.0)</sub></sup></sub> | <sub><sup>24.4<sub>(0.5)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/activity-net-train-full-ce/cf5b1849/seed-0/2020-01-25_16-33-13/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/activity-net-train-full-ce/cf5b1849/seed-0/2020-01-25_16-33-13/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/activity-net-train-full-ce/cf5b1849/seed-0/2020-01-25_16-33-13/summary-seed-0_seed-1_seed-2.json) |

See the [ActivityNet README](misc/datasets/activity-net/README.md) for descriptions of the train/test splits.

**LSMDC Benchmark**

| Model | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Links |
| ------| ------| ---:| ---:| ----:| ----:|----:|----:|------:|
| CE | t2v  | <sub><sup>11.2<sub>(0.4)</sub></sup></sub> | <sub><sup>26.9<sub>(1.1)</sub></sup></sub> | <sub><sup>34.8<sub>(2.0)</sub></sup></sub> | <sub><sup>62.1<sub>(1.5)</sub></sup></sub> | <sub><sup>25.3<sub>(3.1)</sub></sup></sub> | <sub><sup>96.8<sub>(5.0)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/lsmdc-train-full-ce/b314166a/seed-0/2020-01-22_09-13-44/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/lsmdc-train-full-ce/b314166a/seed-0/2020-01-22_09-13-44/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/lsmdc-train-full-ce/b314166a/seed-0/2020-01-22_09-13-44/summary-seed-0_seed-1_seed-2.json) |
| CE | v2t  | <sub><sup>11.7<sub>(0.5)</sub></sup></sub> | <sub><sup>25.8<sub>(1.5)</sub></sup></sub> | <sub><sup>34.4<sub>(1.7)</sub></sup></sub> | <sub><sup>61.4<sub>(0.7)</sub></sup></sub> | <sub><sup>28.0<sub>(2.6)</sub></sup></sub> | <sub><sup>97.6<sub>(2.8)</sub></sup></sub> | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/lsmdc-train-full-ce/b314166a/seed-0/2020-01-22_09-13-44/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/lsmdc-train-full-ce/b314166a/seed-0/2020-01-22_09-13-44/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/lsmdc-train-full-ce/b314166a/seed-0/2020-01-22_09-13-44/summary-seed-0_seed-1_seed-2.json) |

See the [LSMDC README](misc/datasets/lsmdc/README.md) for descriptions of the train/test splits. Please note that to obtain the features and descriptions for this dataset, you must obtain permission from MPII to use the data (this is process is described [here](https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/vision-and-language/mpii-movie-description-dataset/request-access-to-mpii-movie-description-dataset/).  Once you have done so, please request that a member of the LSMDC team contacts us to confirm approval (via albanie at robots dot ox dot ac dot uk) - we can then provide you with a link to the features.




### Ablation studies on MSRVTT

We conduct several ablation studies to investigate the importance of different components in the Collaborative Experts design.  Each ablation is conducted on the MSRVTT dataset. 

**CE Design**: First, we investigate the importance of the parts used by the CE model.

| Model | Task | R@1 | R@5 | R@10 | MdR | Params | Links |
| ---   | :--: | :-: | :-: | :--: | :-: | :----: | :---: |
| Concat | t2v  | <sub><sup>0.0<sub>(0.0)</sub></sup></sub> | <sub><sup>0.0<sub>(0.0)</sub></sup></sub> | <sub><sup>0.0<sub>(0.0)</sub></sup></sub> | <sub><sup>1495.5<sub>(0.0)</sub></sup></sub> | 369.72k | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-concat-ablation/b6fb2189/seed-0/2020-01-07_15-19-41/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-concat-ablation/b6fb2189/seed-0/2020-01-07_15-19-41/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-concat-ablation/b6fb2189/seed-0/2020-01-07_15-19-41/summary-seed-0_seed-1_seed-2.json) |
| CE - MW,P,CG | t2v  | <sub><sup>8.5<sub>(0.1)</sub></sup></sub> | <sub><sup>25.9<sub>(0.3)</sub></sup></sub> | <sub><sup>37.6<sub>(0.2)</sub></sup></sub> | <sub><sup>19.0<sub>(0.0)</sub></sup></sub> | 246.22M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-moee-minus-moee-weights/d8ef2d99/seed-0/2020-01-07_15-20-52/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-moee-minus-moee-weights/d8ef2d99/seed-0/2020-01-07_15-20-52/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-moee-minus-moee-weights/d8ef2d99/seed-0/2020-01-07_15-20-52/summary-seed-0_seed-1_seed-2.json) |
| CE - P,CG | t2v  | <sub><sup>9.6<sub>(0.1)</sub></sup></sub> | <sub><sup>28.0<sub>(0.2)</sub></sup></sub> | <sub><sup>39.7<sub>(0.2)</sub></sup></sub> | <sub><sup>17.7<sub>(0.6)</sub></sup></sub> | 400.41M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-moee/5738fb92/seed-0/2020-01-07_15-27-15/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-moee/5738fb92/seed-0/2020-01-07_15-27-15/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-moee/5738fb92/seed-0/2020-01-07_15-27-15/summary-seed-0_seed-1_seed-2.json) |
| CE - CG  | t2v  | <sub><sup>9.7<sub>(0.1)</sub></sup></sub> | <sub><sup>28.1<sub>(0.2)</sub></sup></sub> | <sub><sup>40.2<sub>(0.1)</sub></sup></sub> | <sub><sup>17.0<sub>(0.0)</sub></sup></sub> | 181.07M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-ablation-dims/351a360e/seed-0/2020-01-07_15-17-10/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-ablation-dims/351a360e/seed-0/2020-01-07_15-17-10/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-ablation-dims/351a360e/seed-0/2020-01-07_15-17-10/summary-seed-0_seed-1_seed-2.json) |
| CE    | t2v  | <sub><sup>10.0<sub>(0.1)</sub></sup></sub> | <sub><sup>29.0<sub>(0.3)</sub></sup></sub> | <sub><sup>41.2<sub>(0.2)</sub></sup></sub> | <sub><sup>16.0<sub>(0.0)</sub></sup></sub> | 183.45M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/summary-seed-0_seed-1_seed-2.json) |
| Concat | v2t  | <sub><sup>0.0<sub>(0.0)</sub></sup></sub> | <sub><sup>0.0<sub>(0.0)</sub></sup></sub> | <sub><sup>0.0<sub>(0.0)</sub></sup></sub> | <sub><sup>29897.5<sub>(0.0)</sub></sup></sub> | 369.72k | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-concat-ablation/b6fb2189/seed-0/2020-01-07_15-19-41/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-concat-ablation/b6fb2189/seed-0/2020-01-07_15-19-41/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-concat-ablation/b6fb2189/seed-0/2020-01-07_15-19-41/summary-seed-0_seed-1_seed-2.json) |
| CE - MW,P,CG | v2t  | <sub><sup>13.7<sub>(0.4)</sub></sup></sub> | <sub><sup>38.8<sub>(1.2)</sub></sup></sub> | <sub><sup>53.1<sub>(1.1)</sub></sup></sub> | <sub><sup>9.2<sub>(0.8)</sub></sup></sub> | 246.22M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-moee-minus-moee-weights/d8ef2d99/seed-0/2020-01-07_15-20-52/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-moee-minus-moee-weights/d8ef2d99/seed-0/2020-01-07_15-20-52/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-moee-minus-moee-weights/d8ef2d99/seed-0/2020-01-07_15-20-52/summary-seed-0_seed-1_seed-2.json) |
| CE - P,CG | v2t  | <sub><sup>14.1<sub>(0.2)</sub></sup></sub> | <sub><sup>39.5<sub>(1.0)</sub></sup></sub> | <sub><sup>53.2<sub>(0.3)</sub></sup></sub> | <sub><sup>9.0<sub>(0.0)</sub></sup></sub> | 400.41M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-moee/5738fb92/seed-0/2020-01-07_15-27-15/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-moee/5738fb92/seed-0/2020-01-07_15-27-15/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-moee/5738fb92/seed-0/2020-01-07_15-27-15/summary-seed-0_seed-1_seed-2.json) |
| CE - CG  | v2t  | <sub><sup>15.1<sub>(0.3)</sub></sup></sub> | <sub><sup>40.3<sub>(0.5)</sub></sup></sub> | <sub><sup>54.3<sub>(0.7)</sub></sup></sub> | <sub><sup>8.8<sub>(0.3)</sub></sup></sub> | 181.07M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-ablation-dims/351a360e/seed-0/2020-01-07_15-17-10/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-ablation-dims/351a360e/seed-0/2020-01-07_15-17-10/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-ablation-dims/351a360e/seed-0/2020-01-07_15-17-10/summary-seed-0_seed-1_seed-2.json) |
| CE    | v2t  | <sub><sup>15.6<sub>(0.3)</sub></sup></sub> | <sub><sup>40.9<sub>(1.4)</sub></sup></sub> | <sub><sup>55.2<sub>(1.0)</sub></sup></sub> | <sub><sup>8.3<sub>(0.6)</sub></sup></sub> | 183.45M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/summary-seed-0_seed-1_seed-2.json) |

Each row adds an additional component to the model.  The names refer to the following model designs:
* **Concat**: A barebones concatenation model.  After aggregating each expert across time (which still requires some parameters for the variable-length VLAD layers), the experts are concatenated and compared directly against the aggregated text embeddings.  Note: this model uses a slightly greater number of VLAD clusters than the others to allow the concatentated embedding to match the dimensionality of the text.
* **CE - MW,P,CG** - The CE model without MoE weights, projecting to a common dimension or Collaborative Gating.
* **CE - P,CG** - The CE model without projecting to a common dimension or Collaborative Gating (note that this is equivalent to the MoEE model proposed in [2]).
* **CE - CG** - The CE model without Collaborative Gating (CG).
* **CE** - The full CE model.

Note that in the table above some metrics have been removed to allow the number of parameters to be displayed---these additional metrics can be found in the linked logs.

**Importance of Different Experts**: The next ablation investigates the value of each of the different experts towards the final embedding.  Since not all experts are available in every video, we pair each expert with scene features, to give an approximation of their usefulness.

| Experts | Task | R@1 | R@5 | R@10 | MdR | Params | Links |
| -----   | :--: | :-: | :-: | :--: | :-: | :----: | :---: |
| Scene    | t2v  | <sub><sup>4.0<sub>(0.1)</sub></sup></sub> | <sub><sup>14.1<sub>(0.1)</sub></sup></sub> | <sub><sup>22.4<sub>(0.3)</sub></sup></sub> | <sub><sup>50.0<sub>(1.0)</sub></sup></sub> | 19.46M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene/812545a9/seed-0/2020-01-07_14-51-54/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene/812545a9/seed-0/2020-01-07_14-51-54/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene/812545a9/seed-0/2020-01-07_14-51-54/summary-seed-0_seed-1_seed-2.json) |
| Scene + Inst. | t2v  | <sub><sup>7.2<sub>(0.1)</sub></sup></sub> | <sub><sup>22.3<sub>(0.3)</sub></sup></sub> | <sub><sup>33.0<sub>(0.2)</sub></sup></sub> | <sub><sup>25.3<sub>(0.6)</sub></sup></sub> | 41.12M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-inst/4bce7bbc/seed-0/2020-01-07_15-06-34/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-inst/4bce7bbc/seed-0/2020-01-07_15-06-34/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-inst/4bce7bbc/seed-0/2020-01-07_15-06-34/summary-seed-0_seed-1_seed-2.json) |
| Scene + r2p1d | t2v  | <sub><sup>6.8<sub>(0.1)</sub></sup></sub> | <sub><sup>21.7<sub>(0.1)</sub></sup></sub> | <sub><sup>32.4<sub>(0.1)</sub></sup></sub> | <sub><sup>25.7<sub>(0.6)</sub></sup></sub> | 39.95M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-r2p1d/2e357adc/seed-0/2020-01-07_15-09-23/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-r2p1d/2e357adc/seed-0/2020-01-07_15-09-23/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-r2p1d/2e357adc/seed-0/2020-01-07_15-09-23/summary-seed-0_seed-1_seed-2.json) |
| Scene + RGB | t2v  | <sub><sup>5.0<sub>(0.2)</sub></sup></sub> | <sub><sup>16.6<sub>(0.7)</sub></sup></sub> | <sub><sup>25.5<sub>(1.0)</sub></sup></sub> | <sub><sup>40.7<sub>(2.1)</sub></sup></sub> | 41.12M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-rgb/8c7aa94e/seed-0/2020-01-07_15-03-11/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-rgb/8c7aa94e/seed-0/2020-01-07_15-03-11/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-rgb/8c7aa94e/seed-0/2020-01-07_15-03-11/summary-seed-0_seed-1_seed-2.json) |
| Scene + Flow | t2v  | <sub><sup>5.3<sub>(0.3)</sub></sup></sub> | <sub><sup>17.6<sub>(0.8)</sub></sup></sub> | <sub><sup>27.1<sub>(0.9)</sub></sup></sub> | <sub><sup>36.0<sub>(1.7)</sub></sup></sub> | 40.34M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-flow/468c68d5/seed-0/2020-01-07_15-05-17/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-flow/468c68d5/seed-0/2020-01-07_15-05-17/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-flow/468c68d5/seed-0/2020-01-07_15-05-17/summary-seed-0_seed-1_seed-2.json) |
| Scene + Audio | t2v  | <sub><sup>5.6<sub>(0.0)</sub></sup></sub> | <sub><sup>18.7<sub>(0.1)</sub></sup></sub> | <sub><sup>28.2<sub>(0.1)</sub></sup></sub> | <sub><sup>33.7<sub>(0.6)</sub></sup></sub> | 40.34M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-audio/4aa51252/seed-0/2020-01-07_15-05-50/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-audio/4aa51252/seed-0/2020-01-07_15-05-50/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-audio/4aa51252/seed-0/2020-01-07_15-05-50/summary-seed-0_seed-1_seed-2.json) |
| Scene + OCR | t2v  | <sub><sup>4.1<sub>(0.1)</sub></sup></sub> | <sub><sup>14.1<sub>(0.1)</sub></sup></sub> | <sub><sup>22.2<sub>(0.2)</sub></sup></sub> | <sub><sup>50.3<sub>(1.2)</sub></sup></sub> | 49.49M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-ocr/f31d8760/seed-0/2020-01-24_08-05-47/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-ocr/f31d8760/seed-0/2020-01-24_08-05-47/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-ocr/f31d8760/seed-0/2020-01-24_08-05-47/summary-seed-0_seed-1_seed-2.json) |
| Scene + Speech | t2v  | <sub><sup>4.6<sub>(0.1)</sub></sup></sub> | <sub><sup>15.5<sub>(0.2)</sub></sup></sub> | <sub><sup>24.4<sub>(0.2)</sub></sup></sub> | <sub><sup>44.7<sub>(1.2)</sub></sup></sub> | 43.94M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech/be8b25b5/seed-0/2020-01-07_14-30-08/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech/be8b25b5/seed-0/2020-01-07_14-30-08/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech/be8b25b5/seed-0/2020-01-07_14-30-08/summary-seed-0_seed-1_seed-2.json) |
| Scene + Face | t2v  | <sub><sup>4.1<sub>(0.1)</sub></sup></sub> | <sub><sup>14.2<sub>(0.3)</sub></sup></sub> | <sub><sup>22.4<sub>(0.4)</sub></sup></sub> | <sub><sup>49.7<sub>(0.6)</sub></sup></sub> | 39.95M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-face/5e28c6f2/seed-0/2020-01-07_14-52-47/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-face/5e28c6f2/seed-0/2020-01-07_14-52-47/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-face/5e28c6f2/seed-0/2020-01-07_14-52-47/summary-seed-0_seed-1_seed-2.json) |
| Scene    | v2t  | <sub><sup>5.6<sub>(0.6)</sub></sup></sub> | <sub><sup>18.2<sub>(0.6)</sub></sup></sub> | <sub><sup>27.7<sub>(0.3)</sub></sup></sub> | <sub><sup>39.0<sub>(0.0)</sub></sup></sub> | 19.46M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene/812545a9/seed-0/2020-01-07_14-51-54/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene/812545a9/seed-0/2020-01-07_14-51-54/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene/812545a9/seed-0/2020-01-07_14-51-54/summary-seed-0_seed-1_seed-2.json) |
| Scene + Inst. | v2t  | <sub><sup>10.1<sub>(0.3)</sub></sup></sub> | <sub><sup>29.7<sub>(0.5)</sub></sup></sub> | <sub><sup>41.9<sub>(0.7)</sub></sup></sub> | <sub><sup>15.2<sub>(0.9)</sub></sup></sub> | 41.12M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-inst/4bce7bbc/seed-0/2020-01-07_15-06-34/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-inst/4bce7bbc/seed-0/2020-01-07_15-06-34/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-inst/4bce7bbc/seed-0/2020-01-07_15-06-34/summary-seed-0_seed-1_seed-2.json) |
| Scene + r2p1d | v2t  | <sub><sup>9.4<sub>(0.3)</sub></sup></sub> | <sub><sup>27.8<sub>(0.6)</sub></sup></sub> | <sub><sup>40.1<sub>(1.1)</sub></sup></sub> | <sub><sup>17.2<sub>(1.1)</sub></sup></sub> | 39.95M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-r2p1d/2e357adc/seed-0/2020-01-07_15-09-23/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-r2p1d/2e357adc/seed-0/2020-01-07_15-09-23/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-r2p1d/2e357adc/seed-0/2020-01-07_15-09-23/summary-seed-0_seed-1_seed-2.json) |
| Scene + RGB | v2t  | <sub><sup>6.9<sub>(0.5)</sub></sup></sub> | <sub><sup>21.2<sub>(0.9)</sub></sup></sub> | <sub><sup>31.1<sub>(1.9)</sub></sup></sub> | <sub><sup>28.7<sub>(3.8)</sub></sup></sub> | 41.12M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-rgb/8c7aa94e/seed-0/2020-01-07_15-03-11/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-rgb/8c7aa94e/seed-0/2020-01-07_15-03-11/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-rgb/8c7aa94e/seed-0/2020-01-07_15-03-11/summary-seed-0_seed-1_seed-2.json) |
| Scene + Flow | v2t  | <sub><sup>7.3<sub>(0.6)</sub></sup></sub> | <sub><sup>22.3<sub>(1.4)</sub></sup></sub> | <sub><sup>33.4<sub>(1.7)</sub></sup></sub> | <sub><sup>25.2<sub>(2.0)</sub></sup></sub> | 40.34M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-flow/468c68d5/seed-0/2020-01-07_15-05-17/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-flow/468c68d5/seed-0/2020-01-07_15-05-17/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-flow/468c68d5/seed-0/2020-01-07_15-05-17/summary-seed-0_seed-1_seed-2.json) |
| Scene + Audio | v2t  | <sub><sup>8.2<sub>(0.4)</sub></sup></sub> | <sub><sup>24.8<sub>(0.4)</sub></sup></sub> | <sub><sup>36.0<sub>(0.1)</sub></sup></sub> | <sub><sup>21.7<sub>(0.6)</sub></sup></sub> | 40.34M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-audio/4aa51252/seed-0/2020-01-07_15-05-50/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-audio/4aa51252/seed-0/2020-01-07_15-05-50/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-audio/4aa51252/seed-0/2020-01-07_15-05-50/summary-seed-0_seed-1_seed-2.json) |
| Scene + OCR | v2t  | <sub><sup>5.4<sub>(0.5)</sub></sup></sub> | <sub><sup>18.6<sub>(1.2)</sub></sup></sub> | <sub><sup>26.6<sub>(1.2)</sub></sup></sub> | <sub><sup>40.0<sub>(1.0)</sub></sup></sub> | 49.49M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-ocr/f31d8760/seed-0/2020-01-24_08-05-47/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-ocr/f31d8760/seed-0/2020-01-24_08-05-47/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-ocr/f31d8760/seed-0/2020-01-24_08-05-47/summary-seed-0_seed-1_seed-2.json) |
| Scene + Speech | v2t  | <sub><sup>6.0<sub>(0.2)</sub></sup></sub> | <sub><sup>20.4<sub>(0.5)</sub></sup></sub> | <sub><sup>30.3<sub>(1.0)</sub></sup></sub> | <sub><sup>33.0<sub>(2.0)</sub></sup></sub> | 43.94M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech/be8b25b5/seed-0/2020-01-07_14-30-08/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech/be8b25b5/seed-0/2020-01-07_14-30-08/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech/be8b25b5/seed-0/2020-01-07_14-30-08/summary-seed-0_seed-1_seed-2.json) |
| Scene + Face | v2t  | <sub><sup>5.6<sub>(1.0)</sub></sup></sub> | <sub><sup>17.9<sub>(0.7)</sub></sup></sub> | <sub><sup>26.7<sub>(0.8)</sub></sup></sub> | <sub><sup>39.1<sub>(2.6)</sub></sup></sub> | 39.95M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-face/5e28c6f2/seed-0/2020-01-07_14-52-47/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-face/5e28c6f2/seed-0/2020-01-07_14-52-47/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-face/5e28c6f2/seed-0/2020-01-07_14-52-47/summary-seed-0_seed-1_seed-2.json) |

We can also study their cumulative effect:

| Experts | Task | R@1 | R@5 | R@10 | MdR | Params | Links |
| -----   | :--: | :-: | :-: | :--: | :-: | :----: | :---: |
| Scene    | t2v  | <sub><sup>4.0<sub>(0.1)</sub></sup></sub> | <sub><sup>14.1<sub>(0.1)</sub></sup></sub> | <sub><sup>22.4<sub>(0.3)</sub></sup></sub> | <sub><sup>50.0<sub>(1.0)</sub></sup></sub> | 19.46M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene/812545a9/seed-0/2020-01-07_14-51-54/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene/812545a9/seed-0/2020-01-07_14-51-54/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene/812545a9/seed-0/2020-01-07_14-51-54/summary-seed-0_seed-1_seed-2.json) |
| Prev. + Speech    | t2v  | <sub><sup>4.6<sub>(0.1)</sub></sup></sub> | <sub><sup>15.5<sub>(0.2)</sub></sup></sub> | <sub><sup>24.4<sub>(0.2)</sub></sup></sub> | <sub><sup>44.7<sub>(1.2)</sub></sup></sub> | 43.94M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech/be8b25b5/seed-0/2020-01-07_14-30-08/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech/be8b25b5/seed-0/2020-01-07_14-30-08/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech/be8b25b5/seed-0/2020-01-07_14-30-08/summary-seed-0_seed-1_seed-2.json) |
| Prev. + Audio    | t2v  | <sub><sup>5.8<sub>(0.1)</sub></sup></sub> | <sub><sup>19.0<sub>(0.3)</sub></sup></sub> | <sub><sup>28.8<sub>(0.2)</sub></sup></sub> | <sub><sup>32.3<sub>(0.6)</sub></sup></sub> | 62.45M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio/9e758bc6/seed-0/2020-01-07_14-30-08/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio/9e758bc6/seed-0/2020-01-07_14-30-08/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech-audio/9e758bc6/seed-0/2020-01-07_14-30-08/summary-seed-0_seed-1_seed-2.json) |
| Prev. + Flow    | t2v  | <sub><sup>6.7<sub>(0.2)</sub></sup></sub> | <sub><sup>21.8<sub>(0.4)</sub></sup></sub> | <sub><sup>32.5<sub>(0.5)</sub></sup></sub> | <sub><sup>25.3<sub>(0.6)</sub></sup></sub> | 80.96M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow/b7e54cca/seed-0/2020-01-07_14-28-36/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow/b7e54cca/seed-0/2020-01-07_14-28-36/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech-audio-flow/b7e54cca/seed-0/2020-01-07_14-28-36/summary-seed-0_seed-1_seed-2.json) |
| Prev. + RGB    | t2v  | <sub><sup>7.5<sub>(0.1)</sub></sup></sub> | <sub><sup>23.4<sub>(0.0)</sub></sup></sub> | <sub><sup>34.1<sub>(0.2)</sub></sup></sub> | <sub><sup>23.7<sub>(0.6)</sub></sup></sub> | 100.26M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb/7ace4a8c/seed-0/2020-01-07_14-32-06/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb/7ace4a8c/seed-0/2020-01-07_14-32-06/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb/7ace4a8c/seed-0/2020-01-07_14-32-06/summary-seed-0_seed-1_seed-2.json) |
| Prev. + Inst    | t2v  | <sub><sup>9.5<sub>(0.2)</sub></sup></sub> | <sub><sup>27.7<sub>(0.1)</sub></sup></sub> | <sub><sup>39.4<sub>(0.1)</sub></sup></sub> | <sub><sup>18.0<sub>(0.0)</sub></sup></sub> | 119.56M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst/f580d35f/seed-0/2020-01-07_14-29-58/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst/f580d35f/seed-0/2020-01-07_14-29-58/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst/f580d35f/seed-0/2020-01-07_14-29-58/summary-seed-0_seed-1_seed-2.json) |
| Prev. + R2P1D    | t2v  | <sub><sup>9.9<sub>(0.1)</sub></sup></sub> | <sub><sup>28.6<sub>(0.3)</sub></sup></sub> | <sub><sup>40.7<sub>(0.1)</sub></sup></sub> | <sub><sup>17.0<sub>(0.0)</sub></sup></sub> | 137.67M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d/95fb9733/seed-0/2020-01-07_14-28-36/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d/95fb9733/seed-0/2020-01-07_14-28-36/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d/95fb9733/seed-0/2020-01-07_14-28-36/summary-seed-0_seed-1_seed-2.json) |
| Prev. + OCR    | t2v  | <sub><sup>10.0<sub>(0.1)</sub></sup></sub> | <sub><sup>28.8<sub>(0.2)</sub></sup></sub> | <sub><sup>40.9<sub>(0.2)</sub></sup></sub> | <sub><sup>16.7<sub>(0.6)</sub></sup></sub> | 165.33M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d-ocr/282b618c/seed-0/2020-01-07_14-28-36/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d-ocr/282b618c/seed-0/2020-01-07_14-28-36/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d-ocr/282b618c/seed-0/2020-01-07_14-28-36/summary-seed-0_seed-1_seed-2.json) |
| Prev. + Face    | t2v  | <sub><sup>10.0<sub>(0.1)</sub></sup></sub> | <sub><sup>29.0<sub>(0.3)</sub></sup></sub> | <sub><sup>41.2<sub>(0.2)</sub></sup></sub> | <sub><sup>16.0<sub>(0.0)</sub></sup></sub> | 183.45M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d-ocr-face/d89c1126/seed-0/2020-01-07_14-28-36/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d-ocr-face/d89c1126/seed-0/2020-01-07_14-28-36/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d-ocr-face/d89c1126/seed-0/2020-01-07_14-28-36/summary-seed-0_seed-1_seed-2.json) |
| Scene    | v2t  | <sub><sup>5.6<sub>(0.6)</sub></sup></sub> | <sub><sup>18.2<sub>(0.6)</sub></sup></sub> | <sub><sup>27.7<sub>(0.3)</sub></sup></sub> | <sub><sup>39.0<sub>(0.0)</sub></sup></sub> | 19.46M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene/812545a9/seed-0/2020-01-07_14-51-54/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene/812545a9/seed-0/2020-01-07_14-51-54/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene/812545a9/seed-0/2020-01-07_14-51-54/summary-seed-0_seed-1_seed-2.json) |
| Prev. + Speech    | v2t  | <sub><sup>6.0<sub>(0.2)</sub></sup></sub> | <sub><sup>20.4<sub>(0.5)</sub></sup></sub> | <sub><sup>30.3<sub>(1.0)</sub></sup></sub> | <sub><sup>33.0<sub>(2.0)</sub></sup></sub> | 43.94M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech/be8b25b5/seed-0/2020-01-07_14-30-08/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech/be8b25b5/seed-0/2020-01-07_14-30-08/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech/be8b25b5/seed-0/2020-01-07_14-30-08/summary-seed-0_seed-1_seed-2.json) |
| Prev. + Audio    | v2t  | <sub><sup>8.6<sub>(0.2)</sub></sup></sub> | <sub><sup>26.1<sub>(0.6)</sub></sup></sub> | <sub><sup>37.8<sub>(0.8)</sub></sup></sub> | <sub><sup>19.8<sub>(0.8)</sub></sup></sub> | 62.45M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio/9e758bc6/seed-0/2020-01-07_14-30-08/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio/9e758bc6/seed-0/2020-01-07_14-30-08/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech-audio/9e758bc6/seed-0/2020-01-07_14-30-08/summary-seed-0_seed-1_seed-2.json) |
| Prev. + Flow    | v2t  | <sub><sup>9.9<sub>(0.4)</sub></sup></sub> | <sub><sup>28.6<sub>(0.7)</sub></sup></sub> | <sub><sup>41.7<sub>(0.8)</sub></sup></sub> | <sub><sup>15.7<sub>(0.6)</sub></sup></sub> | 80.96M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow/b7e54cca/seed-0/2020-01-07_14-28-36/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow/b7e54cca/seed-0/2020-01-07_14-28-36/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech-audio-flow/b7e54cca/seed-0/2020-01-07_14-28-36/summary-seed-0_seed-1_seed-2.json) |
| Prev. + RGB    | v2t  | <sub><sup>11.2<sub>(0.3)</sub></sup></sub> | <sub><sup>32.1<sub>(0.8)</sub></sup></sub> | <sub><sup>45.4<sub>(0.6)</sub></sup></sub> | <sub><sup>13.7<sub>(0.6)</sub></sup></sub> | 100.26M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb/7ace4a8c/seed-0/2020-01-07_14-32-06/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb/7ace4a8c/seed-0/2020-01-07_14-32-06/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb/7ace4a8c/seed-0/2020-01-07_14-32-06/summary-seed-0_seed-1_seed-2.json) |
| Prev. + Inst.    | v2t  | <sub><sup>14.7<sub>(0.6)</sub></sup></sub> | <sub><sup>38.9<sub>(0.8)</sub></sup></sub> | <sub><sup>53.1<sub>(1.0)</sub></sup></sub> | <sub><sup>9.3<sub>(0.6)</sub></sup></sub> | 119.56M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst/f580d35f/seed-0/2020-01-07_14-29-58/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst/f580d35f/seed-0/2020-01-07_14-29-58/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst/f580d35f/seed-0/2020-01-07_14-29-58/summary-seed-0_seed-1_seed-2.json) |
| Prev. + R2P1D    | v2t  | <sub><sup>15.5<sub>(0.6)</sub></sup></sub> | <sub><sup>40.1<sub>(1.2)</sub></sup></sub> | <sub><sup>54.4<sub>(1.3)</sub></sup></sub> | <sub><sup>8.7<sub>(0.6)</sub></sup></sub> | 137.67M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d/95fb9733/seed-0/2020-01-07_14-28-36/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d/95fb9733/seed-0/2020-01-07_14-28-36/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d/95fb9733/seed-0/2020-01-07_14-28-36/summary-seed-0_seed-1_seed-2.json) |
| Prev. + OCR    | v2t  | <sub><sup>15.2<sub>(0.1)</sub></sup></sub> | <sub><sup>41.1<sub>(0.6)</sub></sup></sub> | <sub><sup>54.6<sub>(0.7)</sub></sup></sub> | <sub><sup>8.5<sub>(0.5)</sub></sup></sub> | 165.33M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d-ocr/282b618c/seed-0/2020-01-07_14-28-36/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d-ocr/282b618c/seed-0/2020-01-07_14-28-36/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d-ocr/282b618c/seed-0/2020-01-07_14-28-36/summary-seed-0_seed-1_seed-2.json) |
| Prev. + Face    | v2t  | <sub><sup>15.6<sub>(0.3)</sub></sup></sub> | <sub><sup>40.9<sub>(1.4)</sub></sup></sub> | <sub><sup>55.2<sub>(1.0)</sub></sup></sub> | <sub><sup>8.3<sub>(0.6)</sub></sup></sub> | 183.45M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d-ocr-face/d89c1126/seed-0/2020-01-07_14-28-36/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d-ocr-face/d89c1126/seed-0/2020-01-07_14-28-36/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-scene-speech-audio-flow-rgb-inst-r2p1d-ocr-face/d89c1126/seed-0/2020-01-07_14-28-36/summary-seed-0_seed-1_seed-2.json) |


**Importance of Model Capacity**: The next ablation investigates the value of the shared embedding dimension used by CE.

| Dimension | Task | R@1 | R@5 | R@10 | MdR | Params | Links |
| -----   | :--: | :-: | :-: | :--: | :-: | :----: | :---: |
| 384    | t2v  | <sub><sup>9.4<sub>(0.2)</sub></sup></sub> | <sub><sup>27.8<sub>(0.4)</sub></sup></sub> | <sub><sup>39.8<sub>(0.4)</sub></sup></sub> | <sub><sup>17.7<sub>(0.6)</sub></sup></sub> | 88.62M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-384/777513d3/seed-0/2020-01-24_07-59-43/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-384/777513d3/seed-0/2020-01-24_07-59-43/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-384/777513d3/seed-0/2020-01-24_07-59-43/summary-seed-0_seed-1_seed-2.json) |
| 512    | t2v  | <sub><sup>9.8<sub>(0.3)</sub></sup></sub> | <sub><sup>28.6<sub>(0.4)</sub></sup></sub> | <sub><sup>40.6<sub>(0.4)</sub></sup></sub> | <sub><sup>17.0<sub>(0.0)</sub></sup></sub> | 119.51M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-512/e1b0e018/seed-0/2020-01-24_07-10-30/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-512/e1b0e018/seed-0/2020-01-24_07-10-30/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-512/e1b0e018/seed-0/2020-01-24_07-10-30/summary-seed-0_seed-1_seed-2.json) |
| 640    | t2v  | <sub><sup>10.1<sub>(0.1)</sub></sup></sub> | <sub><sup>28.8<sub>(0.1)</sub></sup></sub> | <sub><sup>40.9<sub>(0.2)</sub></sup></sub> | <sub><sup>16.7<sub>(0.6)</sub></sup></sub> | 151.12M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-640/364b2ecc/seed-0/2020-01-24_07-13-18/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-640/364b2ecc/seed-0/2020-01-24_07-13-18/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-640/364b2ecc/seed-0/2020-01-24_07-13-18/summary-seed-0_seed-1_seed-2.json) |
| 768    | t2v  | <sub><sup>10.0<sub>(0.1)</sub></sup></sub> | <sub><sup>29.0<sub>(0.3)</sub></sup></sub> | <sub><sup>41.2<sub>(0.2)</sub></sup></sub> | <sub><sup>16.0<sub>(0.0)</sub></sup></sub> | 183.45M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/summary-seed-0_seed-1_seed-2.json) |
| 1024    | t2v  | <sub><sup>9.9<sub>(0.1)</sub></sup></sub> | <sub><sup>28.6<sub>(0.3)</sub></sup></sub> | <sub><sup>40.7<sub>(0.4)</sub></sup></sub> | <sub><sup>17.0<sub>(0.0)</sub></sup></sub> | 250.27M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-1024/e25a1038/seed-0/2020-01-24_07-10-29/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-1024/e25a1038/seed-0/2020-01-24_07-10-29/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-1024/e25a1038/seed-0/2020-01-24_07-10-29/summary-seed-0_seed-1_seed-2.json) |
| 384    | v2t  | <sub><sup>14.0<sub>(0.5)</sub></sup></sub> | <sub><sup>38.7<sub>(0.5)</sub></sup></sub> | <sub><sup>52.7<sub>(1.4)</sub></sup></sub> | <sub><sup>9.3<sub>(0.6)</sub></sup></sub> | 88.62M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-384/777513d3/seed-0/2020-01-24_07-59-43/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-384/777513d3/seed-0/2020-01-24_07-59-43/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-384/777513d3/seed-0/2020-01-24_07-59-43/summary-seed-0_seed-1_seed-2.json) |
| 512    | v2t  | <sub><sup>14.8<sub>(0.4)</sub></sup></sub> | <sub><sup>40.4<sub>(0.6)</sub></sup></sub> | <sub><sup>53.9<sub>(0.4)</sub></sup></sub> | <sub><sup>8.8<sub>(0.3)</sub></sup></sub> | 119.51M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-512/e1b0e018/seed-0/2020-01-24_07-10-30/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-512/e1b0e018/seed-0/2020-01-24_07-10-30/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-512/e1b0e018/seed-0/2020-01-24_07-10-30/summary-seed-0_seed-1_seed-2.json) |
| 640    | v2t  | <sub><sup>15.6<sub>(0.6)</sub></sup></sub> | <sub><sup>41.3<sub>(0.7)</sub></sup></sub> | <sub><sup>55.0<sub>(0.5)</sub></sup></sub> | <sub><sup>8.3<sub>(0.6)</sub></sup></sub> | 151.12M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-640/364b2ecc/seed-0/2020-01-24_07-13-18/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-640/364b2ecc/seed-0/2020-01-24_07-13-18/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-640/364b2ecc/seed-0/2020-01-24_07-13-18/summary-seed-0_seed-1_seed-2.json) |
| 768    | v2t  | <sub><sup>15.6<sub>(0.3)</sub></sup></sub> | <sub><sup>40.9<sub>(1.4)</sub></sup></sub> | <sub><sup>55.2<sub>(1.0)</sub></sup></sub> | <sub><sup>8.3<sub>(0.6)</sub></sup></sub> | 183.45M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/summary-seed-0_seed-1_seed-2.json) |
| 1024    | v2t  | <sub><sup>14.7<sub>(0.4)</sub></sup></sub> | <sub><sup>40.7<sub>(0.8)</sub></sup></sub> | <sub><sup>54.4<sub>(0.3)</sub></sup></sub> | <sub><sup>8.5<sub>(0.5)</sub></sup></sub> | 250.27M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-1024/e25a1038/seed-0/2020-01-24_07-10-29/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-1024/e25a1038/seed-0/2020-01-24_07-10-29/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-1024/e25a1038/seed-0/2020-01-24_07-10-29/summary-seed-0_seed-1_seed-2.json) |

**Training with more captions:** Rather than varying the number of experts, we can also investigate how performance changes as we change the number of training captions available per-video.

| Experts | Caps. | Task | R@1 | R@5 | R@10 | MdR | Params | Links |
| -----   | :------: | :--: | :-: | :-: | :--: | :-: | :----: | :---: |
| RGB   | 1 | t2v | <sub><sup>2.6<sub>(0.1)</sub></sup></sub> | <sub><sup>9.3<sub>(0.4)</sub></sup></sub> | <sub><sup>15.0<sub>(0.7)</sub></sup></sub> | <sub><sup>101.3<sub>(15.5)</sub></sup></sub> | 56.7M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-ablation-restrict-captions-only-rgb/f178e88e/seed-0/2020-01-07_15-21-50/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-ablation-restrict-captions-only-rgb/f178e88e/seed-0/2020-01-07_15-21-50/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-ablation-restrict-captions-only-rgb/f178e88e/seed-0/2020-01-07_15-21-50/summary-seed-0_seed-1_seed-2.json) |
| RGB   | 20 | t2v  | <sub><sup>4.9<sub>(0.1)</sub></sup></sub> | <sub><sup>16.5<sub>(0.2)</sub></sup></sub> | <sub><sup>25.3<sub>(0.4)</sub></sup></sub> | <sub><sup>40.7<sub>(1.2)</sub></sup></sub> | 58.05M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-rgb/ee84d270/seed-0/2019-12-20_14-41-56/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-rgb/ee84d270/seed-0/2019-12-20_14-41-56/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-rgb/ee84d270/seed-0/2019-12-20_14-41-56/summary-seed-0_seed-1_seed-2.json) |
| All   | 1 | t2v | <sub><sup>4.8<sub>(0.2)</sub></sup></sub> | <sub><sup>16.2<sub>(0.5)</sub></sup></sub> | <sub><sup>25.0<sub>(0.7)</sub></sup></sub> | <sub><sup>43.3<sub>(4.0)</sub></sup></sub> | 183.45M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-ablation-restrict-captions/517b81c9/seed-0/2020-01-07_15-20-29/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-ablation-restrict-captions/517b81c9/seed-0/2020-01-07_15-20-29/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-ablation-restrict-captions/517b81c9/seed-0/2020-01-07_15-20-29/summary-seed-0_seed-1_seed-2.json) |
| All   | 20 | t2v | <sub><sup>10.0<sub>(0.1)</sub></sup></sub> | <sub><sup>29.0<sub>(0.3)</sub></sup></sub> | <sub><sup>41.2<sub>(0.2)</sub></sup></sub> | <sub><sup>16.0<sub>(0.0)</sub></sup></sub> | 183.45M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/summary-seed-0_seed-1_seed-2.json) |
| RGB   | 1 | v2t | <sub><sup>3.7<sub>(0.3)</sub></sup></sub> | <sub><sup>13.5<sub>(0.6)</sub></sup></sub> | <sub><sup>20.8<sub>(0.4)</sub></sup></sub> | <sub><sup>60.0<sub>(2.0)</sub></sup></sub> | 56.7M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-ablation-restrict-captions-only-rgb/f178e88e/seed-0/2020-01-07_15-21-50/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-ablation-restrict-captions-only-rgb/f178e88e/seed-0/2020-01-07_15-21-50/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-ablation-restrict-captions-only-rgb/f178e88e/seed-0/2020-01-07_15-21-50/summary-seed-0_seed-1_seed-2.json) |
| RGB   | 20 | v2t  | <sub><sup>6.9<sub>(0.6)</sub></sup></sub> | <sub><sup>21.0<sub>(0.3)</sub></sup></sub> | <sub><sup>31.3<sub>(0.3)</sub></sup></sub> | <sub><sup>30.0<sub>(1.7)</sub></sup></sub> | 58.05M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-rgb/ee84d270/seed-0/2019-12-20_14-41-56/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-only-rgb/ee84d270/seed-0/2019-12-20_14-41-56/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-only-rgb/ee84d270/seed-0/2019-12-20_14-41-56/summary-seed-0_seed-1_seed-2.json) |
| All   | 1 | v2t | <sub><sup>8.4<sub>(0.5)</sub></sup></sub> | <sub><sup>25.6<sub>(0.7)</sub></sup></sub> | <sub><sup>37.1<sub>(0.2)</sub></sup></sub> | <sub><sup>20.3<sub>(0.6)</sub></sup></sub> | 183.45M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-ablation-restrict-captions/517b81c9/seed-0/2020-01-07_15-20-29/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce-ablation-restrict-captions/517b81c9/seed-0/2020-01-07_15-20-29/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce-ablation-restrict-captions/517b81c9/seed-0/2020-01-07_15-20-29/summary-seed-0_seed-1_seed-2.json) |
| All   | 20 | v2t | <sub><sup>15.6<sub>(0.3)</sub></sup></sub> | <sub><sup>40.9<sub>(1.4)</sub></sup></sub> | <sub><sup>55.2<sub>(1.0)</sub></sup></sub> | <sub><sup>8.3<sub>(0.6)</sub></sup></sub> | 183.45M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/msrvtt-train-full-ce/074e6b24/seed-0/2020-01-07_15-24-30/summary-seed-0_seed-1_seed-2.json) |

Similar ablation studies for the remaining datasets can be found [here](misc/ablations.md).

### Expert Zoo

For each dataset, the Collaborative Experts model makes use of a collection of pretrained "expert" feature extractors (see [1] for more precise descriptions). Some experts have been obtained from other sources (described where applicable), rather than extracted by us.  To reproduce the experiments listed above, the experts for each dataset have been bundled into compressed tar files.  These can be downloaded and unpacked with a [utility script](misc/sync_experts.py) (recommended -- see example usage below), which will store them in the locations expected by the training code. Each set of experts has a brief README, which also provides a link from which they can be downloaded directly.

| Dataset           | Experts  |  Details and links | Archive size | sha1sum |
|:-------------:|:-----:|:----:|:---:|:---:|
| MSRVTT | audio, face, flow, ocr, rgb, scene, speech | [README](misc/datasets/msrvtt/README.md)| 19.6 GiB | <sup><sub><sup><sub>959bda588793ef05f348d16de26da84200c5a469</sub></sup></sub></sup> |
| LSMDC | audio, face, flow, ocr, rgb, scene | [README](misc/datasets/lsmdc/README.md)| 6.1 GiB | <sup><sub><sup><sub>7ce018e981752db9e793e449c2ba5bc88217373d</sub></sup></sub></sup> |
| MSVD | face, flow, ocr, rgb, scene | [README](misc/datasets/msvd/README.md)| 2.1 GiB | <sup><sub><sup><sub>6071827257c14de455b3a13fe1e885c2a7887c9e</sub></sup></sub></sup> | 
| DiDeMo | audio, face, flow, ocr, rgb, scene, speech | [README](misc/datasets/didemo/README.md)| 2.3 GiB | <sup><sub><sup><sub>6fd4bcc68c1611052de2499fd8ab3f488c7c195b</sub></sup></sub></sup> | 
| ActivityNet | audio, face, flow, ocr, rgb, scene, speech | [README](misc/datasets/activity-net/README.md)| 3.8 GiB | <sup><sub><sup><sub>b16685576c97cdec2783fb89ea30ca7d17abb021</sub></sup></sub></sup> | 

### QuerYD

### MODEL study on QUERYD

**Importance of the model**:

| Model | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | params | Links |
| ----- | ---- | --- | --- | ---- | ---- | --- | --- | ----- | -- | -- |
| HowTo100m S3D | t2v  | <sub><sup>13.5<sub>(0.0)</sub></sup></sub> | <sub><sup>27.5<sub>(0.0)</sub></sup></sub> | <sub><sup>34.5<sub>(0.0)</sub></sup></sub> | <sub><sup>57.0<sub>(0.0)</sub></sup></sub> | <sub><sup>35.0<sub>(0.0)</sub></sup></sub> | <sub><sup>72.5<sub>(0.0)</sub></sup></sub> | <sub><sup>23.4<sub>(0.0)</sub></sup></sub> | 1 | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-mnnet/4f82d8b3/seed-0/2020-10-21_16-32-55/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-mnnet/4f82d8b3/seed-0/2020-10-21_16-32-55/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-mnnet/4f82d8b3/seed-0/2020-10-21_16-32-55/summary-seed-0_seed-1_seed-2.json) |
| CE - P,CG | t2v  | <sub><sup>11.6<sub>(1.3)</sub></sup></sub> | <sub><sup>30.2<sub>(3.0)</sub></sup></sub> | <sub><sup>43.2<sub>(3.1)</sub></sup></sub> | <sub><sup>74.8<sub>(1.7)</sub></sup></sub> | <sub><sup>14.2<sub>(1.6)</sub></sup></sub> | <sub><sup>42.7<sub>(2.6)</sub></sup></sub> | <sub><sup>24.7<sub>(1.9)</sub></sup></sub> | 57.75M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-moee/d75cfe35/seed-0/2020-10-21_16-33-40/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-moee/d75cfe35/seed-0/2020-10-21_16-33-40/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-moee/d75cfe35/seed-0/2020-10-21_16-33-40/summary-seed-0_seed-1_seed-2.json) |
| CE    | t2v  | <sub><sup>13.9<sub>(0.8)</sub></sup></sub> | <sub><sup>37.6<sub>(1.2)</sub></sup></sub> | <sub><sup>48.3<sub>(1.4)</sub></sup></sub> | <sub><sup>78.8<sub>(0.7)</sub></sup></sub> | <sub><sup>11.3<sub>(0.6)</sub></sup></sub> | <sub><sup>35.1<sub>(1.6)</sub></sup></sub> | <sub><sup>29.3<sub>(0.8)</sub></sup></sub> | 30.82M |[config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce/bf393a74/seed-0/2020-10-21_16-29-49/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce/bf393a74/seed-0/2020-10-21_16-29-49/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce/bf393a74/seed-0/2020-10-21_16-29-49/summary-seed-0_seed-1_seed-2.json) |
| HowTo100m S3D | v2t  | <sub><sup>12.4<sub>(0.0)</sub></sup></sub> | <sub><sup>23.8<sub>(0.0)</sub></sup></sub> | <sub><sup>30.8<sub>(0.0)</sub></sup></sub> | <sub><sup>57.0<sub>(0.0)</sub></sup></sub> | <sub><sup>33.0<sub>(0.0)</sub></sup></sub> | <sub><sup>73.4<sub>(0.0)</sub></sup></sub> | <sub><sup>20.9<sub>(0.0)</sub></sup></sub> | 1 | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-mnnet/4f82d8b3/seed-0/2020-10-21_16-32-55/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-mnnet/4f82d8b3/seed-0/2020-10-21_16-32-55/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-mnnet/4f82d8b3/seed-0/2020-10-21_16-32-55/summary-seed-0_seed-1_seed-2.json) |
| CE - P,CG | v2t  | <sub><sup>13.0<sub>(3.1)</sub></sup></sub> | <sub><sup>30.9<sub>(2.0)</sub></sup></sub> | <sub><sup>43.0<sub>(2.8)</sub></sup></sub> | <sub><sup>73.2<sub>(0.1)</sub></sup></sub> | <sub><sup>14.5<sub>(1.8)</sub></sup></sub> | <sub><sup>42.6<sub>(1.5)</sub></sup></sub> | <sub><sup>25.7<sub>(2.3)</sub></sup></sub> | 57.75M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-moee/d75cfe35/seed-0/2020-10-21_16-33-40/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-moee/d75cfe35/seed-0/2020-10-21_16-33-40/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-moee/d75cfe35/seed-0/2020-10-21_16-33-40/summary-seed-0_seed-1_seed-2.json) |
| CE    | v2t  | <sub><sup>13.7<sub>(0.7)</sub></sup></sub> | <sub><sup>35.2<sub>(2.7)</sub></sup></sub> | <sub><sup>46.9<sub>(3.2)</sub></sup></sub> | <sub><sup>78.3<sub>(2.8)</sub></sup></sub> | <sub><sup>12.3<sub>(1.5)</sub></sup></sub> | <sub><sup>35.8<sub>(2.4)</sub></sup></sub> | <sub><sup>28.3<sub>(1.5)</sub></sup></sub> | 30.82M |[config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce/bf393a74/seed-0/2020-10-21_16-29-49/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce/bf393a74/seed-0/2020-10-21_16-29-49/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce/bf393a74/seed-0/2020-10-21_16-29-49/summary-seed-0_seed-1_seed-2.json) |

The influence of different pretrained experts for the performance of the CE model trained on QuerYD is studied. The value and cumulative effect of different experts for scene clas-sification (SCENE), ambient sound classification (AUDIO),image classification (OBJECT), and action recognition (ACTION) are presented. PREV. denotes the experts used in the previous row.


### Ablation studies on QuerYD

We conduct several ablation studies to investigate the importance of different components in the Collaborative Experts design.  Each ablation is conducted on the QuerYD dataset. 


| Experts | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | params | Links |
| ----- | ---- | --- | --- | ---- | ---- | --- | --- | ----- | -- | -- |
| Scene    | t2v  | <sub><sup>8.7<sub>(0.4)</sub></sup></sub> | <sub><sup>26.3<sub>(1.1)</sub></sup></sub> | <sub><sup>37.1<sub>(0.7)</sub></sup></sub> | <sub><sup>68.5<sub>(2.2)</sub></sup></sub> | <sub><sup>22.2<sub>(1.6)</sub></sup></sub> | <sub><sup>52.3<sub>(3.0)</sub></sup></sub> | <sub><sup>20.4<sub>(0.1)</sub></sup></sub> | 7.51M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene/7a747dc4/seed-0/2020-10-21_16-41-01/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene/7a747dc4/seed-0/2020-10-21_16-41-01/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene/7a747dc4/seed-0/2020-10-21_16-41-01/summary-seed-0_seed-1_seed-2.json) |
| Scene + Inst. | t2v  | <sub><sup>11.7<sub>(1.4)</sub></sup></sub> | <sub><sup>31.6<sub>(0.9)</sub></sup></sub> | <sub><sup>43.4<sub>(1.3)</sub></sup></sub> | <sub><sup>74.5<sub>(0.9)</sub></sup></sub> | <sub><sup>14.0<sub>(1.0)</sub></sup></sub> | <sub><sup>41.1<sub>(2.1)</sub></sup></sub> | <sub><sup>25.2<sub>(0.8)</sub></sup></sub> | 17.25M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-inst/bb0be767/seed-0/2020-10-21_16-36-00/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-inst/bb0be767/seed-0/2020-10-21_16-36-00/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene-inst/bb0be767/seed-0/2020-10-21_16-36-00/summary-seed-0_seed-1_seed-2.json) |
| Scene + r2p1d | t2v  | <sub><sup>11.7<sub>(2.1)</sub></sup></sub> | <sub><sup>32.1<sub>(3.0)</sub></sup></sub> | <sub><sup>45.3<sub>(3.3)</sub></sup></sub> | <sub><sup>74.6<sub>(0.4)</sub></sup></sub> | <sub><sup>13.7<sub>(1.9)</sub></sup></sub> | <sub><sup>42.9<sub>(2.2)</sub></sup></sub> | <sub><sup>25.7<sub>(2.4)</sub></sup></sub> | 16.07M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-r2p1d/86e43b8b/seed-0/2020-10-21_16-38-35/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-r2p1d/86e43b8b/seed-0/2020-10-21_16-38-35/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene-r2p1d/86e43b8b/seed-0/2020-10-21_16-38-35/summary-seed-0_seed-1_seed-2.json) |
| Scene + Audio | t2v  | <sub><sup>7.6<sub>(2.7)</sub></sup></sub> | <sub><sup>27.4<sub>(1.4)</sub></sup></sub> | <sub><sup>40.4<sub>(0.9)</sub></sup></sub> | <sub><sup>69.1<sub>(0.9)</sub></sup></sub> | <sub><sup>17.0<sub>(1.7)</sub></sup></sub> | <sub><sup>49.0<sub>(1.9)</sub></sup></sub> | <sub><sup>20.2<sub>(2.3)</sub></sup></sub> | 17.25M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio/c87311b1/seed-0/2020-10-21_16-32-58/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio/c87311b1/seed-0/2020-10-21_16-32-58/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene-audio/c87311b1/seed-0/2020-10-21_16-32-58/summary-seed-0_seed-1_seed-2.json) |
| Scene    | v2t  | <sub><sup>9.1<sub>(0.8)</sub></sup></sub> | <sub><sup>25.4<sub>(0.9)</sub></sup></sub> | <sub><sup>35.3<sub>(1.5)</sub></sup></sub> | <sub><sup>68.2<sub>(2.2)</sub></sup></sub> | <sub><sup>23.2<sub>(0.3)</sub></sup></sub> | <sub><sup>52.6<sub>(2.6)</sub></sup></sub> | <sub><sup>20.1<sub>(0.5)</sub></sup></sub> | 7.51M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene/7a747dc4/seed-0/2020-10-21_16-41-01/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene/7a747dc4/seed-0/2020-10-21_16-41-01/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene/7a747dc4/seed-0/2020-10-21_16-41-01/summary-seed-0_seed-1_seed-2.json) |
| Scene + Inst. | v2t  | <sub><sup>11.9<sub>(0.5)</sub></sup></sub> | <sub><sup>31.0<sub>(3.6)</sub></sup></sub> | <sub><sup>43.5<sub>(2.7)</sub></sup></sub> | <sub><sup>74.8<sub>(1.8)</sub></sup></sub> | <sub><sup>14.5<sub>(0.9)</sub></sup></sub> | <sub><sup>40.8<sub>(2.1)</sub></sup></sub> | <sub><sup>25.2<sub>(1.1)</sub></sup></sub> | 17.25M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-inst/bb0be767/seed-0/2020-10-21_16-36-00/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-inst/bb0be767/seed-0/2020-10-21_16-36-00/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene-inst/bb0be767/seed-0/2020-10-21_16-36-00/summary-seed-0_seed-1_seed-2.json) |
| Scene + r2p1d | v2t  | <sub><sup>12.7<sub>(1.4)</sub></sup></sub> | <sub><sup>30.9<sub>(2.8)</sub></sup></sub> | <sub><sup>44.0<sub>(1.8)</sub></sup></sub> | <sub><sup>74.3<sub>(1.2)</sub></sup></sub> | <sub><sup>14.3<sub>(1.2)</sub></sup></sub> | <sub><sup>42.8<sub>(1.7)</sub></sup></sub> | <sub><sup>25.8<sub>(1.7)</sub></sup></sub> | 16.07M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-r2p1d/86e43b8b/seed-0/2020-10-21_16-38-35/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-r2p1d/86e43b8b/seed-0/2020-10-21_16-38-35/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene-r2p1d/86e43b8b/seed-0/2020-10-21_16-38-35/summary-seed-0_seed-1_seed-2.json) |
| Scene + Audio | v2t  | <sub><sup>10.1<sub>(1.2)</sub></sup></sub> | <sub><sup>25.7<sub>(1.5)</sub></sup></sub> | <sub><sup>37.5<sub>(1.2)</sub></sup></sub> | <sub><sup>69.8<sub>(1.6)</sub></sup></sub> | <sub><sup>20.0<sub>(1.3)</sub></sup></sub> | <sub><sup>48.9<sub>(2.0)</sub></sup></sub> | <sub><sup>21.3<sub>(1.1)</sub></sup></sub> | 17.25M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio/c87311b1/seed-0/2020-10-21_16-32-58/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio/c87311b1/seed-0/2020-10-21_16-32-58/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene-audio/c87311b1/seed-0/2020-10-21_16-32-58/summary-seed-0_seed-1_seed-2.json) |

We can also study their cumulative effect:

| Experts | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | params | Links |
| ----- | ---- | --- | --- | ---- | ---- | --- | --- | ----- | -- | -- |
| Scene    | t2v  | <sub><sup>8.7<sub>(0.4)</sub></sup></sub> | <sub><sup>26.3<sub>(1.1)</sub></sup></sub> | <sub><sup>37.1<sub>(0.7)</sub></sup></sub> | <sub><sup>68.5<sub>(2.2)</sub></sup></sub> | <sub><sup>22.2<sub>(1.6)</sub></sup></sub> | <sub><sup>52.3<sub>(3.0)</sub></sup></sub> | <sub><sup>20.4<sub>(0.1)</sub></sup></sub> | 7.51M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene/7a747dc4/seed-0/2020-10-21_16-41-01/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene/7a747dc4/seed-0/2020-10-21_16-41-01/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene/7a747dc4/seed-0/2020-10-21_16-41-01/summary-seed-0_seed-1_seed-2.json) |
| Prev. + Audio    | t2v  | <sub><sup>7.6<sub>(2.7)</sub></sup></sub> | <sub><sup>27.4<sub>(1.4)</sub></sup></sub> | <sub><sup>40.4<sub>(0.9)</sub></sup></sub> | <sub><sup>69.1<sub>(0.9)</sub></sup></sub> | <sub><sup>17.0<sub>(1.7)</sub></sup></sub> | <sub><sup>49.0<sub>(1.9)</sub></sup></sub> | <sub><sup>20.2<sub>(2.3)</sub></sup></sub> | 17.25M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio/c87311b1/seed-0/2020-10-21_16-32-58/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio/c87311b1/seed-0/2020-10-21_16-32-58/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene-audio/c87311b1/seed-0/2020-10-21_16-32-58/summary-seed-0_seed-1_seed-2.json) |
| Prev. + Inst    | t2v  | <sub><sup>12.7<sub>(1.7)</sub></sup></sub> | <sub><sup>34.8<sub>(1.7)</sub></sup></sub> | <sub><sup>47.0<sub>(1.3)</sub></sup></sub> | <sub><sup>78.0<sub>(1.0)</sub></sup></sub> | <sub><sup>12.3<sub>(0.6)</sub></sup></sub> | <sub><sup>37.6<sub>(2.1)</sub></sup></sub> | <sub><sup>27.5<sub>(1.5)</sub></sup></sub> | 24.63M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio-inst/f302d191/seed-0/2020-10-21_16-29-36/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio-inst/f302d191/seed-0/2020-10-21_16-29-36/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene-audio-inst/f302d191/seed-0/2020-10-21_16-29-36/summary-seed-0_seed-1_seed-2.json) |
| Prev. + R2P1D    | t2v  | <sub><sup>14.3<sub>(0.3)</sub></sup></sub> | <sub><sup>37.5<sub>(1.3)</sub></sup></sub> | <sub><sup>48.6<sub>(0.8)</sub></sup></sub> | <sub><sup>78.8<sub>(0.3)</sub></sup></sub> | <sub><sup>11.3<sub>(0.6)</sub></sup></sub> | <sub><sup>35.2<sub>(1.8)</sub></sup></sub> | <sub><sup>29.7<sub>(0.3)</sub></sup></sub> | 30.82M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio-inst-r2p1d/70feaf3c/seed-0/2020-10-21_16-25-50/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio-inst-r2p1d/70feaf3c/seed-0/2020-10-21_16-25-50/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene-audio-inst-r2p1d/70feaf3c/seed-0/2020-10-21_16-25-50/summary-seed-0_seed-1_seed-2.json) |
| Scene    | v2t  | <sub><sup>9.1<sub>(0.8)</sub></sup></sub> | <sub><sup>25.4<sub>(0.9)</sub></sup></sub> | <sub><sup>35.3<sub>(1.5)</sub></sup></sub> | <sub><sup>68.2<sub>(2.2)</sub></sup></sub> | <sub><sup>23.2<sub>(0.3)</sub></sup></sub> | <sub><sup>52.6<sub>(2.6)</sub></sup></sub> | <sub><sup>20.1<sub>(0.5)</sub></sup></sub> | 7.51M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene/7a747dc4/seed-0/2020-10-21_16-41-01/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene/7a747dc4/seed-0/2020-10-21_16-41-01/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene/7a747dc4/seed-0/2020-10-21_16-41-01/summary-seed-0_seed-1_seed-2.json) |
| Prev. + Audio    | v2t  | <sub><sup>10.1<sub>(1.2)</sub></sup></sub> | <sub><sup>25.7<sub>(1.5)</sub></sup></sub> | <sub><sup>37.5<sub>(1.2)</sub></sup></sub> | <sub><sup>69.8<sub>(1.6)</sub></sup></sub> | <sub><sup>20.0<sub>(1.3)</sub></sup></sub> | <sub><sup>48.9<sub>(2.0)</sub></sup></sub> | <sub><sup>21.3<sub>(1.1)</sub></sup></sub> | 17.25M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio/c87311b1/seed-0/2020-10-21_16-32-58/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio/c87311b1/seed-0/2020-10-21_16-32-58/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene-audio/c87311b1/seed-0/2020-10-21_16-32-58/summary-seed-0_seed-1_seed-2.json) |
| Prev. + Inst.    | v2t  | <sub><sup>12.8<sub>(1.3)</sub></sup></sub> | <sub><sup>33.5<sub>(2.8)</sub></sup></sub> | <sub><sup>46.6<sub>(1.0)</sub></sup></sub> | <sub><sup>76.7<sub>(1.7)</sub></sup></sub> | <sub><sup>11.8<sub>(0.8)</sub></sup></sub> | <sub><sup>37.6<sub>(1.9)</sub></sup></sub> | <sub><sup>27.1<sub>(0.6)</sub></sup></sub> | 24.63M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio-inst/f302d191/seed-0/2020-10-21_16-29-36/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio-inst/f302d191/seed-0/2020-10-21_16-29-36/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene-audio-inst/f302d191/seed-0/2020-10-21_16-29-36/summary-seed-0_seed-1_seed-2.json) |
| Prev. + R2P1D    | v2t  | <sub><sup>14.0<sub>(0.3)</sub></sup></sub> | <sub><sup>35.4<sub>(2.9)</sub></sup></sub> | <sub><sup>47.2<sub>(2.8)</sub></sup></sub> | <sub><sup>78.7<sub>(2.4)</sub></sup></sub> | <sub><sup>12.3<sub>(1.5)</sub></sup></sub> | <sub><sup>35.8<sub>(2.4)</sub></sup></sub> | <sub><sup>28.6<sub>(1.2)</sub></sup></sub> | 30.82M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio-inst-r2p1d/70feaf3c/seed-0/2020-10-21_16-25-50/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/queryd-train-full-ce-only-scene-audio-inst-r2p1d/70feaf3c/seed-0/2020-10-21_16-25-50/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/queryd-train-full-ce-only-scene-audio-inst-r2p1d/70feaf3c/seed-0/2020-10-21_16-25-50/summary-seed-0_seed-1_seed-2.json) |


### QuerYDSegments

### MODEL study on QUERYDSEGMENTS

**Importance of the model**:

| Model | Task | R@1 | R@5 | R@10 | R@50 | MdR | MnR | Geom | params | Links |
| ----- | ---- | --- | --- | ---- | ---- | --- | --- | ----- | -- | -- |
| HowTo100m S3D | t2v  | <sub><sup>6.7<sub>(0.0)</sub></sup></sub> | <sub><sup>14.7<sub>(0.0)</sub></sup></sub> | <sub><sup>20.4<sub>(0.0)</sub></sup></sub> | <sub><sup>36.6<sub>(0.0)</sub></sup></sub> | <sub><sup>133.0<sub>(0.0)</sub></sup></sub> | <sub><sup>342.0<sub>(0.0)</sub></sup></sub> | <sub><sup>12.6<sub>(0.0)</sub></sup></sub> | 1 | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-mnnet/84b0801c/seed-1/2020-10-21_18-28-28/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-mnnet/84b0801c/seed-1/2020-10-21_18-28-28/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/querydsegments-train-full-mnnet/84b0801c/seed-1/2020-10-21_18-28-28/summary-seed-1_seed-2_seed-3.json) |
| CE - P,CG | t2v  | <sub><sup>19.0<sub>(0.8)</sub></sup></sub> | <sub><sup>38.9<sub>(1.0)</sub></sup></sub> | <sub><sup>47.9<sub>(0.7)</sub></sup></sub> | <sub><sup>68.0<sub>(0.4)</sub></sup></sub> | <sub><sup>12.0<sub>(1.0)</sub></sup></sub> | <sub><sup>127.4<sub>(5.9)</sub></sup></sub> | <sub><sup>32.8<sub>(0.6)</sub></sup></sub> | 57.75M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-moee/87a1436a/seed-1/2020-10-21_18-29-07/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-moee/87a1436a/seed-1/2020-10-21_18-29-07/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/querydsegments-train-full-moee/87a1436a/seed-1/2020-10-21_18-29-07/summary-seed-1_seed-2_seed-3.json) |
| CE    | t2v  | <sub><sup>18.2<sub>(0.5)</sub></sup></sub> | <sub><sup>38.1<sub>(0.8)</sub></sup></sub> | <sub><sup>46.8<sub>(0.4)</sub></sup></sub> | <sub><sup>67.3<sub>(0.7)</sub></sup></sub> | <sub><sup>13.3<sub>(0.6)</sub></sup></sub> | <sub><sup>127.5<sub>(3.9)</sub></sup></sub> | <sub><sup>31.9<sub>(0.4)</sub></sup></sub> | 30.82M |[config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-ce/d7737672/seed-1/2020-10-21_18-19-39/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-ce/d7737672/seed-1/2020-10-21_18-19-39/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/querydsegments-train-full-ce/d7737672/seed-1/2020-10-21_18-19-39/summary-seed-1_seed-2_seed-3.json) |
| HowTo100m S3D | v2t  | <sub><sup>8.4<sub>(0.0)</sub></sup></sub> | <sub><sup>15.4<sub>(0.0)</sub></sup></sub> | <sub><sup>19.8<sub>(0.0)</sub></sup></sub> | <sub><sup>34.2<sub>(0.0)</sub></sup></sub> | <sub><sup>154.5<sub>(0.0)</sub></sup></sub> | <sub><sup>363.0<sub>(0.0)</sub></sup></sub> | <sub><sup>13.7<sub>(0.0)</sub></sup></sub> | 1 | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-mnnet/84b0801c/seed-1/2020-10-21_18-28-28/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-mnnet/84b0801c/seed-1/2020-10-21_18-28-28/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/querydsegments-train-full-mnnet/84b0801c/seed-1/2020-10-21_18-28-28/summary-seed-1_seed-2_seed-3.json) |
| CE - P,CG | v2t  | <sub><sup>19.8<sub>(0.2)</sub></sup></sub> | <sub><sup>39.6<sub>(0.6)</sub></sup></sub> | <sub><sup>47.6<sub>(0.1)</sub></sup></sub> | <sub><sup>67.9<sub>(0.5)</sub></sup></sub> | <sub><sup>13.0<sub>(0.0)</sub></sup></sub> | <sub><sup>124.3<sub>(5.5)</sub></sup></sub> | <sub><sup>33.4<sub>(0.2)</sub></sup></sub> | 57.75M | [config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-moee/87a1436a/seed-1/2020-10-21_18-29-07/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-moee/87a1436a/seed-1/2020-10-21_18-29-07/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/querydsegments-train-full-moee/87a1436a/seed-1/2020-10-21_18-29-07/summary-seed-1_seed-2_seed-3.json) |
| CE    | v2t  | <sub><sup>18.1<sub>(0.6)</sub></sup></sub> | <sub><sup>37.3<sub>(0.5)</sub></sup></sub> | <sub><sup>45.9<sub>(0.6)</sub></sup></sub> | <sub><sup>67.2<sub>(0.2)</sub></sup></sub> | <sub><sup>14.0<sub>(1.0)</sub></sup></sub> | <sub><sup>123.9<sub>(3.3)</sub></sup></sub> | <sub><sup>31.4<sub>(0.4)</sub></sup></sub> | 30.82M |[config](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-ce/d7737672/seed-1/2020-10-21_18-19-39/config.json), [model](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/querydsegments-train-full-ce/d7737672/seed-1/2020-10-21_18-19-39/trained_model.pth), [log](http:/www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/log/querydsegments-train-full-ce/d7737672/seed-1/2020-10-21_18-19-39/summary-seed-1_seed-2_seed-3.json) |

### Evaluating a pretrained model

Evaluting a pretrained model for a given dataset requires:
1. The pretrained experts for the target dataset, which should be located in `<root>/data/<dataset-name>/symlinked-feats` (this will be done automatically by the [utility script](misc/sync_experts.py), or can be done manually).
2. A `config.json` file.
3. A `trained_model.pth` file.

Evaluation is then performed with the following command:
```
python3 test.py --config <path-to-config.json> --resume <path-to-trained_model.pth> --device <gpu-id>
```
where `<gpu-id>` is the index of the GPU to evaluate on.  This option can be ommitted to run the evaluation on the CPU.

For example, to reproduce the MSVD results described above, run the following sequence of commands:

```
# fetch the pretrained experts for MSVD 
python3 misc/sync_experts.py --dataset MSVD

# find the name of a pretrained model using the links in the tables above 
export MODEL=data/models/msvd-train-full-ce/5bb8dda1/seed-0/2020-01-30_12-29-56/trained_model.pth

# create a local directory and download the model into it 
mkdir -p $(dirname "${MODEL}")
wget --output-document="${MODEL}" "http://www.robots.ox.ac.uk/~vgg/research/collaborative-experts/${MODEL}"

# Evaluate the model
python3 test.py --config configs/msvd/train-full-ce.json --resume ${MODEL} --device 0 --eval_from_training_config
```


### Training a new model

Training a new video-text embedding requires:
1. The pretrained experts for the dataset used for training, which should be located in `<root>/data/<dataset-name>/symlinked-feats` (this will be done automatically by the [utility script](misc/sync_experts.py), or can be done manually).
2. A `config.json` file.  You can define your own, or use one of the provided configs in the [configs](configs) directory.

Training is then performed with the following command:
```
python3 train.py --config <path-to-config.json> --device <gpu-id>
```
where `<gpu-id>` is the index of the GPU to train on.  This option can be ommitted to run the training on the CPU.

For example, to train a new embedding for the LSMDC dataset, run the following sequence of commands:

```
# fetch the pretrained experts for LSMDC 
python3 misc/sync_experts.py --dataset LSMDC

# Train the model
python3 train.py --config configs/lsmdc/train-full-ce.json --device 0
```

### Visualising the retrieval ranking

Tensorboard lacks video support via HTML5 tags (at the time of writing) so after each evaluation of a retrieval model, a simple HTML file is generated to allow the predicted rankings of different videos to be visualised: an example screenshot is given below (this tool is inspired by the visualiser in the [pix2pix codebase](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)). To view the visualisation, navigate to the `web directory` (this is generated for each experiment, and will be printed in the log during training) and run `python3 -m http.server 9999`, then navigate to `localhost:9999` in your web browser.  You should see something like the following:

![visualisation](figs/vis-ranking.png)

Note that the visualising the results in this manner requires that you also download the source videos for each of the datasets to some directory `<src-video-dir>`. Then set the `visualizer.args.src_video_dir` attribute of the training `config.json` file to point to `<src-video-dir>`.


### Dependencies

Dependencies can be installed via `pip install -r requirements/pip-requirements.txt`.


### References

[1] If you find this code useful or use the extracted features, please consider citing:

```
@inproceedings{croitoru2021teachtext,
  title={Teachtext: Crossmodal generalized distillation for text-video retrieval},
  author={Croitoru, I. and Bogolin, S. and Leordeanu, M. and Jin, H. and Zisserman, A. and Albanie, S. and Liu, Y.},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11583--11593},
  year={2021}
}

@inproceedings{Liu2019a,
  author    = {Liu, Y. and Albanie, S. and Nagrani, A. and Zisserman, A.},
  booktitle = {arXiv preprint arxiv:1907.13487},
  title     = {Use What You Have: Video retrieval using representations from collaborative experts},
  date      = {2019},
}
```

[2] If you make use of the MSRVTT or LSMDC features provided by Miech et al. (details are given in their respective READMEs [here](misc/datasets/msrvtt/README.md) and [here](misc/datasets/lsmdc/README.md)), please cite:

```
@article{miech2018learning,
  title={Learning a text-video embedding from incomplete and heterogeneous data},
  author={Miech, Antoine and Laptev, Ivan and Sivic, Josef},
  journal={arXiv preprint arXiv:1804.02516},
  year={2018}
}
```



### Acknowledgements

This work was inspired by a number of prior works for learning joint embeddings of text and video, but in particular the *Mixture-of-Embedding-Experts* method proposed by Antoine Miech, Ivan Laptev and Josef Sivic ([paper](https://arxiv.org/abs/1804.02516), [code](https://github.com/antoine77340/Mixture-of-Embedding-Experts)). We would also like to thank Zak Stone and Susie Lim for their help with using Cloud TPUs.  The code structure uses the [pytorch-template](https://github.com/victoresque/pytorch-template) by @victoresque.
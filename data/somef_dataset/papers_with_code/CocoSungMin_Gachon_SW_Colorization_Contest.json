{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1505.04597.   \n2. Attention U-Net Learning Where to Look for the Pancreas : https://arxiv.org/abs/1804.03999      \n3. Real-Time User-Guided Image Colorization with Learned Deep Priors : https://arxiv.org/abs/1705.02999.  \n4. Deep Residual Learning for Image Recognition : https://arxiv.org/abs/1512.03385.  \n\n\nBasic model based on \"Hyeju Yoon\" standard u-net : \n```\nhttps://drive.google.com/file/d/1P0Vbt_V5FdcjWVyFcgQiK496nRUOWHzI/view?usp=sharing. \n``` \n\"Sungmin Lee\" replace the [ Conv - BatchNorm - ReLU ] blocks to Residual block and add attention layer in skip connection.   \n \n   \nOur model input has [ l . ab_hint , mask ] as a input.   \nMost of Fully open github project for colorization via deep learning adapted 4 channels as a input.   \nTheir 4 channels consisted with 3 color channel ( e.g. Lab format L and ab channel ",
      "https://arxiv.org/abs/1804.03999      \n3. Real-Time User-Guided Image Colorization with Learned Deep Priors : https://arxiv.org/abs/1705.02999.  \n4. Deep Residual Learning for Image Recognition : https://arxiv.org/abs/1512.03385.  \n\n\nBasic model based on \"Hyeju Yoon\" standard u-net : \n```\nhttps://drive.google.com/file/d/1P0Vbt_V5FdcjWVyFcgQiK496nRUOWHzI/view?usp=sharing. \n``` \n\"Sungmin Lee\" replace the [ Conv - BatchNorm - ReLU ] blocks to Residual block and add attention layer in skip connection.   \n \n   \nOur model input has [ l . ab_hint , mask ] as a input.   \nMost of Fully open github project for colorization via deep learning adapted 4 channels as a input.   \nTheir 4 channels consisted with 3 color channel ( e.g. Lab format L and ab channel ",
      "https://arxiv.org/abs/1705.02999.  \n4. Deep Residual Learning for Image Recognition : https://arxiv.org/abs/1512.03385.  \n\n\nBasic model based on \"Hyeju Yoon\" standard u-net : \n```\nhttps://drive.google.com/file/d/1P0Vbt_V5FdcjWVyFcgQiK496nRUOWHzI/view?usp=sharing. \n``` \n\"Sungmin Lee\" replace the [ Conv - BatchNorm - ReLU ] blocks to Residual block and add attention layer in skip connection.   \n \n   \nOur model input has [ l . ab_hint , mask ] as a input.   \nMost of Fully open github project for colorization via deep learning adapted 4 channels as a input.   \nTheir 4 channels consisted with 3 color channel ( e.g. Lab format L and ab channel ",
      "https://arxiv.org/abs/1512.03385.  \n\n\nBasic model based on \"Hyeju Yoon\" standard u-net : \n```\nhttps://drive.google.com/file/d/1P0Vbt_V5FdcjWVyFcgQiK496nRUOWHzI/view?usp=sharing. \n``` \n\"Sungmin Lee\" replace the [ Conv - BatchNorm - ReLU ] blocks to Residual block and add attention layer in skip connection.   \n \n   \nOur model input has [ l . ab_hint , mask ] as a input.   \nMost of Fully open github project for colorization via deep learning adapted 4 channels as a input.   \nTheir 4 channels consisted with 3 color channel ( e.g. Lab format L and ab channel "
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        0.997497849331919,
        0.9976486432600086
      ],
      "excerpt": "1. U-Net Convolutional Networks for Biomedical Image Segmentation : https://arxiv.org/abs/1505.04597.  \n2. Attention U-Net Learning Where to Look for the Pancreas : https://arxiv.org/abs/1804.03999     \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9998838868777323
      ],
      "excerpt": "4. Deep Residual Learning for Image Recognition : https://arxiv.org/abs/1512.03385.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906244202967742
      ],
      "excerpt": "Sungmin Lee ( Department of Software , undergraduated Research Assistant in VMRLAB Gachon Uni.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8272850713181028
      ],
      "excerpt": "Soeun Lee ( Department of Software , Senior student in Gachon Uni.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9030859728368266
      ],
      "excerpt": "Epoch : 10.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8550101043698384
      ],
      "excerpt": "cuda 10.2 \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CocoSungMin/Gachon_SW_Colorization_Contest",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Sungmin Lee ( Department of Software , undergraduated Research Assistant in VMRLAB Gachon Uni.).   \nTaeho Oh ( Department of Software , Senior student in Gachon Uni.). \nHyeju Yoon ( Department of Software , Senior student in Gachon Uni.).  \nSoeun Lee ( Department of Software , Senior student in Gachon Uni.).",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-05-25T01:48:27Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-17T06:09:17Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8537806706404424
      ],
      "excerpt": "Basic model based on \"Hyeju Yoon\" standard u-net :  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8750732030411582
      ],
      "excerpt": "\"Sungmin Lee\" replace the [ Conv - BatchNorm - ReLU ] blocks to Residual block and add attention layer in skip connection.    \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9564707238437596
      ],
      "excerpt": "Most of Fully open github project for colorization via deep learning adapted 4 channels as a input.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9664040495134981
      ],
      "excerpt": "This work shows better performance than other works in our team. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.898059836643119
      ],
      "excerpt": "Also we augment the training data ( Flip horizontal , Rotate 180 ) to expand training datasets.     \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9732825287222251,
        0.851611209178816,
        0.9966182483994329
      ],
      "excerpt": "But for our model the L1 loss return the highest score than others.  \nAlso for Learning Rate , we used , 1e-2 , 2e-2 , 1e-3 , 1e-4 , 2e-4 , 25e-5 \nLike 1e-2 to 2e-4 shows a lot of blurred pixel with aritifacts but when learning with 25e-5 the epochs goes on the frequency of the artifacts goes down. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.807243478376718,
        0.9252622037155093,
        0.9832941164456948,
        0.9832941164456948,
        0.9832941164456948
      ],
      "excerpt": "After that we got those score in leaderboard at CVIP Colorization Challenges. \nSungmin Lee ( Department of Software , undergraduated Research Assistant in VMRLAB Gachon Uni.) \nTaeho Oh ( Department of Software , Senior student in Gachon Uni.) \nHyeju Yoon ( Department of Software , Senior student in Gachon Uni.) \nSoeun Lee ( Department of Software , Senior student in Gachon Uni.) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Multimedia&Lab lecture Hint based Image Colorization Challenge from Prof. Yong Ju Jung in Gachon Uni",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CocoSungMin/Gachon_SW_Colorization_Contest/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Mon, 27 Dec 2021 05:54:13 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/CocoSungMin/Gachon_SW_Colorization_Contest/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "CocoSungMin/Gachon_SW_Colorization_Contest",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.9322609392449874
      ],
      "excerpt": "pytorch 1.8.1 \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8065209599393635
      ],
      "excerpt": "First time we trained with batch size 4.    \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.834535369022701
      ],
      "excerpt": "Then increasing batchsize , training again from 122th epochs .    \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8538593786678602
      ],
      "excerpt": "Input data size : ( 128 X 128 ).   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8112735652505316
      ],
      "excerpt": "Epoch : 10.   \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8538593786678602
      ],
      "excerpt": "Input data size : ( 128 X 128 ).   \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/CocoSungMin/Gachon_SW_Colorization_Contest/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Colorization with Deep learning competitions in Multimedia&lab lecture, Department of Software Gachon Uni.",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Gachon_SW_Colorization_Contest",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "CocoSungMin",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/CocoSungMin/Gachon_SW_Colorization_Contest/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Mon, 27 Dec 2021 05:54:13 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "colorization",
      "deep-learning"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Before training, please use \"aug.py\" to automatically augmentation training data ( flip , rotate 180 )\n2. For training \n```\npython main.py\n```\n\n3. For testing ( predicting )\n```\npython test.py\n```\n\n4.  Best Weight files\n```\nhttps://drive.google.com/file/d/1dZBjzAy5t9W6Du_GJZPf70RUBkCOpFG3/view?usp=sharing\n```\n-----------------\n",
      "technique": "Header extraction"
    }
  ]
}
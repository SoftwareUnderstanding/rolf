{
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@misc{baselines,\n  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},\n  title = {OpenAI Baselines},\n  year = {2017},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/openai/baselines}},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9999782899735908,
        0.9813161029725735,
        0.9960965048981569,
        0.9146894306581513,
        0.9851092049198196,
        0.989881025149432
      ],
      "excerpt": "  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter}, \n  title = {OpenAI Baselines}, \n  year = {2017}, \n  publisher = {GitHub}, \n  journal = {GitHub repository}, \n  howpublished = {\\url{https://github.com/openai/baselines}}, \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/openai/baselines",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2017-05-24T01:58:13Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-21T05:41:40Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9628697466352178,
        0.9702202631473515
      ],
      "excerpt": "OpenAI Baselines is a set of high-quality implementations of reinforcement learning algorithms. \nThese algorithms will make it easier for the research community to replicate, refine, and identify new ideas, and will create good baselines to build research on top of. Our DQN implementation and its variants are roughly on par with the scores in published papers. We expect they will be used as a base around which new ideas can be added, and as a tool for comparing a new approach against existing ones. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8020289659247102,
        0.819334974602637
      ],
      "excerpt": "Virtualenvs are essentially folders that have copies of python executable and all python packages. \nTo create a virtualenv called venv with python3, one runs  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8371619184066255
      ],
      "excerpt": "The master branch supports Tensorflow from version 1.4 to 1.14. For Tensorflow 2.0 support, please use tf2 branch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8509142799853858
      ],
      "excerpt": "Most of the algorithms in baselines repo are used as follows: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9235115544417739
      ],
      "excerpt": "The algorithms serialization API is not properly unified yet; however, there is a simple method to save / restore trained models.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.917631837350598
      ],
      "excerpt": "This should get to the mean reward per episode about 20. To load and visualize the model, we'll do the following - load the model, train it for 0 steps, and then visualize:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.886094595776142
      ],
      "excerpt": "For examples on how to load and display the training data, see here. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.974067456866589
      ],
      "excerpt": "Results of benchmarks on Mujoco (1M timesteps) and Atari (10M timesteps) are available  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9239265855580691,
        0.8648936863280641
      ],
      "excerpt": "respectively. Note that these results may be not on the latest version of the code, particular commit hash with which results were obtained is specified on the benchmarks page.  \nTo cite this repository in publications: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "OpenAI Baselines: high-quality implementations of reinforcement learning algorithms",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/openai/baselines/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4189,
      "date": "Tue, 21 Dec 2021 07:23:49 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/openai/baselines/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "openai/baselines",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/openai/baselines/master/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/openai/baselines/tree/master/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/openai/baselines/master/docs/viz/viz.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "All unit tests in baselines can be run using pytest runner:\n```\npip install pytest\npytest\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "- Clone the repo and cd into it:\n    ```bash\n    git clone https://github.com/openai/baselines.git\n    cd baselines\n    ```\n- If you don't have TensorFlow installed already, install your favourite flavor of TensorFlow. In most cases, you may use\n    ```bash \n    pip install tensorflow-gpu==1.14 #: if you have a CUDA-compatible gpu and proper drivers\n    ```\n    or \n    ```bash\n    pip install tensorflow==1.14\n    ```\n    to install Tensorflow 1.14, which is the latest version of Tensorflow supported by the master branch. Refer to [TensorFlow installation guide](https://www.tensorflow.org/install/)\n    for more details. \n\n- Install baselines package\n    ```bash\n    pip install -e .\n    ```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9785605051820454,
        0.9835083482395235,
        0.9730041125621232,
        0.9831352864524507,
        0.9980827914613059
      ],
      "excerpt": "sudo apt-get update &amp;&amp; sudo apt-get install cmake libopenmpi-dev python3-dev zlib1g-dev \nInstallation of system packages on Mac requires Homebrew. With Homebrew installed, run the following: \nbrew install cmake openmpi \nFrom the general python package sanity perspective, it is a good idea to use virtual environments (virtualenvs) to make sure packages from different projects do not interfere with each other. You can install virtualenv (which is itself a pip package) via \npip install virtualenv \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8647199432309937,
        0.9136429172208658,
        0.9211091603043597
      ],
      "excerpt": "To create a virtualenv called venv with python3, one runs  \nvirtualenv /path/to/venv --python=python3 \nTo activate a virtualenv:  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9086682060273666
      ],
      "excerpt": "python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v4 --num_timesteps=2e7 --save_path=~/models/pong_20M_ppo2 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9086682060273666
      ],
      "excerpt": "python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v4 --num_timesteps=0 --load_path=~/models/pong_20M_ppo2 --play \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8796914365229054,
        0.8490401722699208
      ],
      "excerpt": "The directory can be changed with the --log_path command-line option. \npython -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v4 --num_timesteps=2e7 --save_path=~/models/pong_20M_ppo2 --log_path=~/logs/Pong/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8529667180402067
      ],
      "excerpt": "Another way the temp directory can be changed is through the use of the $OPENAI_LOGDIR environment variable. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8202383043121549
      ],
      "excerpt": "The directory can be changed with the --log_path command-line option. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8126868504438162
      ],
      "excerpt": "python -m baselines.run --alg=ppo2 --env=PongNoFrameskip-v4 --num_timesteps=2e7 --save_path=~/models/pong_20M_ppo2 --log_path=~/logs/Pong/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8504700317456502
      ],
      "excerpt": "For examples on how to load and display the training data, see here. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/openai/baselines/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "HTML",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'The MIT License\\n\\nCopyright (c) 2017 OpenAI (http://openai.com)\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in\\nall copies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\\nTHE SOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Baselines",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "baselines",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "openai",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/openai/baselines/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Baselines requires python3 (>=3.5) with the development headers. You'll also need system packages CMake, OpenMPI and zlib. Those can be installed as follows\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 12167,
      "date": "Tue, 21 Dec 2021 07:23:49 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "For instance, to train a fully-connected network controlling MuJoCo humanoid using PPO2 for 20M timesteps\n```bash\npython -m baselines.run --alg=ppo2 --env=Humanoid-v2 --network=mlp --num_timesteps=2e7\n```\nNote that for mujoco environments fully-connected network is default, so we can omit `--network=mlp`\nThe hyperparameters for both network and the learning algorithm can be controlled via the command line, for instance:\n```bash\npython -m baselines.run --alg=ppo2 --env=Humanoid-v2 --network=mlp --num_timesteps=2e7 --ent_coef=0.1 --num_hidden=32 --num_layers=3 --value_network=copy\n```\nwill set entropy coefficient to 0.1, and construct fully connected network with 3 layers with 32 hidden units in each, and create a separate network for value function estimation (so that its parameters are not shared with the policy network, but the structure is the same)\n\nSee docstrings in [common/models.py](baselines/common/models.py) for description of network parameters for each type of model, and \ndocstring for [baselines/ppo2/ppo2.py/learn()](baselines/ppo2/ppo2.py#L152) for the description of the ppo2 hyperparameters. \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "DQN with Atari is at this point a classics of benchmarks. To run the baselines implementation of DQN on Atari Pong:\n```\npython -m baselines.run --alg=deepq --env=PongNoFrameskip-v4 --num_timesteps=1e6\n```\n\n",
      "technique": "Header extraction"
    }
  ]
}
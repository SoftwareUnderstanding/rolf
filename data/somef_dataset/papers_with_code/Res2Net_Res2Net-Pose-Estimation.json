{
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you find this work or code is helpful in your research, please cite:\n```\n@article{gao2019res2net,\n  title={Res2Net: A New Multi-scale Backbone Architecture},\n  author={Gao, Shang-Hua and Cheng, Ming-Ming and Zhao, Kai and Zhang, Xin-Yu and Yang, Ming-Hsuan and Torr, Philip},\n  journal={IEEE TPAMI},\n  year={2020},\n  doi={10.1109/TPAMI.2019.2938758}, \n}\n```\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{gao2019res2net,\n  title={Res2Net: A New Multi-scale Backbone Architecture},\n  author={Gao, Shang-Hua and Cheng, Ming-Ming and Zhao, Kai and Zhang, Xin-Yu and Yang, Ming-Hsuan and Torr, Philip},\n  journal={IEEE TPAMI},\n  year={2020},\n  doi={10.1109/TPAMI.2019.2938758}, \n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Res2Net/Res2Net-Pose-Estimation",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2019-08-10T14:40:32Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-06T11:54:59Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This repo uses [*Simple Baselines*](http://openaccess.thecvf.com/content_ECCV_2018/html/Bin_Xiao_Simple_Baselines_for_ECCV_2018_paper.html) as the baseline method for Pose Estimation. \n\n[Res2Net](https://github.com/gasvn/Res2Net) is a powerful backbone architecture that can be easily implemented into state-of-the-art models by replacing the bottleneck with Res2Net module.\nMore detail can be found on [ \"Res2Net: A New Multi-scale Backbone Architecture\"](https://arxiv.org/pdf/1904.01169.pdf)\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Res2Net for Pose Estimation using Simple Baselines as the baseline",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Res2Net/Res2Net-Pose-Estimation/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4,
      "date": "Wed, 29 Dec 2021 00:00:46 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Res2Net/Res2Net-Pose-Estimation/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Res2Net/Res2Net-Pose-Estimation",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "**For MPII data**, please download from [MPII Human Pose Dataset](http://human-pose.mpi-inf.mpg.de/). The original annotation files are in matlab format. We have converted them into json format, you also need to download them from [OneDrive](https://1drv.ms/f/s!AhIXJn_J-blW00SqrairNetmeVu4) or [GoogleDrive](https://drive.google.com/drive/folders/1En_VqmStnsXMdldXA6qpqEyDQulnmS3a?usp=sharing).\nExtract them under {POSE_ROOT}/data, and make them look like this:\n```\n${POSE_ROOT}\n|-- data\n`-- |-- mpii\n    `-- |-- annot\n        |   |-- gt_valid.mat\n        |   |-- test.json\n        |   |-- train.json\n        |   |-- trainval.json\n        |   `-- valid.json\n        `-- images\n            |-- 000001163.jpg\n            |-- 000003072.jpg\n```\n\n**For COCO data**, please download from [COCO download](http://cocodataset.org/#download), 2017 Train/Val is needed for COCO keypoints training and validation. We also provide person detection result of COCO val2017 and test-dev2017 to reproduce our multi-person pose estimation results. Please download from [OneDrive](https://1drv.ms/f/s!AhIXJn_J-blWzzDXoz5BeFl8sWM-) or [GoogleDrive](https://drive.google.com/drive/folders/1fRUDNUDxe9fjqcRZ2bnF_TKMlO0nB_dk?usp=sharing).\nDownload and extract them under {POSE_ROOT}/data, and make them look like this:\n```\n${POSE_ROOT}\n|-- data\n`-- |-- coco\n    `-- |-- annotations\n        |   |-- person_keypoints_train2017.json\n        |   `-- person_keypoints_val2017.json\n        |-- person_detection_results\n        |   |-- COCO_val2017_detections_AP_H_56_person.json\n        |   |-- COCO_test-dev2017_detections_AP_H_609_person.json\n        `-- images\n            |-- train2017\n            |   |-- 000000000009.jpg\n            |   |-- 000000000025.jpg\n            |   |-- 000000000030.jpg\n            |   |-- ... \n            `-- val2017\n                |-- 000000000139.jpg\n                |-- 000000000285.jpg\n                |-- 000000000632.jpg\n                |-- ... \n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "6. Init output(training model output directory) and log(tensorboard log directory) directory:\n\n   ```\n   mkdir output \n   mkdir log\n   ```\n\n   Your directory tree should look like this:\n\n   ```\n   ${POSE_ROOT}\n   \u251c\u2500\u2500 data\n   \u251c\u2500\u2500 experiments\n   \u251c\u2500\u2500 lib\n   \u251c\u2500\u2500 log\n   \u251c\u2500\u2500 models\n   \u251c\u2500\u2500 output\n   \u251c\u2500\u2500 tools \n   \u251c\u2500\u2500 README.md\n   \u2514\u2500\u2500 requirements.txt\n   ```\n\n7. Download pretrained models of Res2Net following the instruction from [Res2Net backbone pretrained models](https://github.com/gasvn/Res2Net). Please change the path to pretrained models **(PRETRAINED: )** in config files:  `experiments/coco/res2net/res2net50_4s_26w_256x192_d256x3_adam_lr1e-3.yaml`\n   ```\n   ${POSE_ROOT}\n    `-- models\n        `-- pytorch\n            |-- imagenet\n            |   |-- res2net50_26w_4s-06e79181.pth\n            |   |-- res2net101_26w_4s-02a759a1.pth\n            |   |-- resnet50-19c8e357.pth\n            |   |-- resnet101-5d3b4d8f.pth\n            |   `-- resnet152-b121ed2d.pth\n            |-- pose_coco\n            |   |-- (pretrained model for res2net_pose will be soon available)\n            |   |-- pose_resnet_101_256x192.pth\n            |   |-- pose_resnet_101_384x288.pth\n            |   |-- pose_resnet_152_256x192.pth\n            |   |-- pose_resnet_152_384x288.pth\n            |   |-- pose_resnet_50_256x192.pth\n            |   `-- pose_resnet_50_384x288.pth\n            `-- pose_mpii\n                |-- pose_resnet_101_256x256.pth\n                |-- pose_resnet_152_256x256.pth\n                `-- pose_resnet_50_256x256.pth\n\n   ```\n   \n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "1. Install pytorch >= v1.0.0 \n2. Clone this repo, and we'll call the directory that you cloned as ${POSE_ROOT}.\n3. Install dependencies:\n   ```\n   pip install -r requirements.txt\n   ```\n4. Make libs:\n   ```\n   cd ${POSE_ROOT}/lib\n   make\n   ```\n5. Install [COCOAPI](https://github.com/cocodataset/cocoapi):\n   ```\n   #: COCOAPI=/path/to/clone/cocoapi\n   git clone https://github.com/cocodataset/cocoapi.git $COCOAPI\n   cd $COCOAPI/PythonAPI\n   #: Install into global site-packages\n   make install\n   #: Alternatively, if you do not have permissions or prefer\n   #: not to install the COCO API into global site-packages\n   python3 setup.py install --user\n   ```\n   Note that instructions like ",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8244951481442103
      ],
      "excerpt": "    --cfg experiments/coco/res2net/res2net50_4s_26w_256x192_d256x3_adam_lr1e-3.yaml \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8244951481442103
      ],
      "excerpt": "    --cfg experiments/coco/res2net/res2net50_4s_26w_256x192_d256x3_adam_lr1e-3.yaml \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9000528184933404
      ],
      "excerpt": "python tools/test.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.910424923022973,
        0.8725487815795144,
        0.898584498893152
      ],
      "excerpt": "    TEST.MODEL_FILE {path to pretrained model.pth} \\ \n    TEST.USE_GT_BBOX False \npython tools/train.py \\ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9000528184933404,
        0.817733597986534,
        0.910424923022973,
        0.898584498893152,
        0.817733597986534
      ],
      "excerpt": "python tools/test.py \\ \n    --cfg experiments/mpii/res2net/res2net50_256x256_d256x3_adam_lr1e-3.yaml \\ \n    TEST.MODEL_FILE {path to pretrained model.pth} \npython tools/train.py \\ \n    --cfg experiments/mpii/res2net/res2net50_256x256_d256x3_adam_lr1e-3.yaml \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Res2Net/Res2Net-Pose-Estimation/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Cuda",
      "Python",
      "C++",
      "Makefile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Res2Net for Pose Estimation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Res2Net-Pose-Estimation",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Res2Net",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Res2Net/Res2Net-Pose-Estimation/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 32,
      "date": "Wed, 29 Dec 2021 00:00:46 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "res2net",
      "mulit-scale",
      "pose-estimation",
      "pose",
      "simple-baselines"
    ],
    "technique": "GitHub API"
  }
}
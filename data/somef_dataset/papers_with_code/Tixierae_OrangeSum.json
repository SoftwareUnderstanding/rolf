{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2010.12321",
      "https://arxiv.org/abs/2010.12321 (2020)."
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "If you use our code or dataset, please cite:\n\n**BibTex**\n````BibTeX\n@article{eddine2020barthez,\n  title={BARThez: a Skilled Pretrained French Sequence-to-Sequence Model},\n  author={Eddine, Moussa Kamal and Tixier, Antoine J-P and Vazirgiannis, Michalis},\n  journal={arXiv preprint arXiv:2010.12321},\n  year={2020}\n}\n````\n**MLA**\n>Eddine, Moussa Kamal, Antoine J-P. Tixier, and Michalis Vazirgiannis. \"BARThez: a Skilled Pretrained French Sequence-to-Sequence Model.\" arXiv preprint arXiv:2010.12321 (2020).\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{eddine2020barthez,\n  title={BARThez: a Skilled Pretrained French Sequence-to-Sequence Model},\n  author={Eddine, Moussa Kamal and Tixier, Antoine J-P and Vazirgiannis, Michalis},\n  journal={arXiv preprint arXiv:2010.12321},\n  year={2020}\n}",
      "technique": "Regular expression"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Tixierae/OrangeSum",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2020-11-23T22:50:33Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-05T20:55:06Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9343205591902347,
        0.9560233238900936,
        0.962892874943215
      ],
      "excerpt": "This repository provides the French summarization dataset introduced in the paper BARThez: a Skilled Pretrained French Sequence-to-Sequence Model (Kamal Eddine, Tixier, and Vazirgiannis, 2020), with the train, development, and test splits used in the paper. \nIt also provides the code that was used to build the dataset, and the test set summaries generated by the BARThez, mBART, mBARThez, and CamemBERT2CamemBERT models, to make cross comparison with future work as easy as possible (in ./summaries/). \nNote: this repository is dedicated to the OrangeSum dataset. The main repository of the paper is https://github.com/moussaKam/BARThez. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9002967764775809
      ],
      "excerpt": "Scraped pages cover almost a decade from Feb 2011 to Sep 2020. They belong to five main categories: France, world, politics, automotive, and society. The society category is itself divided into 8 subcategories: health, environment, people, culture, media, high-tech, unusual (\"insolite\" in French), and miscellaneous. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9066925639435024,
        0.9907172030524871
      ],
      "excerpt": "As a post-processing step, we removed all empty articles, and articles whose titles were shorter than 5 words. \nFor OrangeSum Abstract, we removed the top 10% articles in terms of proportion of novel unigrams in the abstracts, as we observed that such abstracts tended to be introductions rather than real abstracts. This corresponded to a threshold of 57% novel unigrams. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9613970047139079,
        0.9727573940273568
      ],
      "excerpt": "In the table below, Sizes (column 2) are given in thousands of documents, document and summary lengths are in words, and vocab sizes are in thousands of tokens. \nIn the table below, it can be observed that OrangeSum offers approximately the same degree of abstractivity as XSum, and that both of them are more abstractive than traditional summarization datasets. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "The French summarization dataset introduced in \"BARThez: a Skilled Pretrained French Sequence-to-Sequence Model\".",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Tixierae/OrangeSum/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Thu, 23 Dec 2021 00:47:47 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Tixierae/OrangeSum/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Tixierae/OrangeSum",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/Tixierae/OrangeSum/tree/main/data/docs"
    ],
    "technique": "File Exploration"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/Tixierae/OrangeSum/main/Visualization.ipynb"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.838285508027881
      ],
      "excerpt": "Starting from an empty directory structure, run the following scripts, in that order. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.9336801098518991,
        0.9336801098518991,
        0.9336801098518991,
        0.9336801098518991,
        0.9336801098518991
      ],
      "excerpt": "1. get_urls.py \n1. scrape_urls.py \n1. parse_urls.py \n1. compute_overlap.py \n1. filter_split.py \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Tixierae/OrangeSum/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python",
      "R",
      "Rebol"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Creative Commons Attribution Share Alike 4.0 International",
      "url": "https://api.github.com/licenses/cc-by-sa-4.0"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "OrangeSum Dataset",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "OrangeSum",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Tixierae",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Tixierae/OrangeSum/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 14,
      "date": "Thu, 23 Dec 2021 00:47:47 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "nlp",
      "summarization",
      "seq2seq",
      "bart",
      "bert",
      "abstractive-summarization",
      "extreme-summarization",
      "sequence-to-sequence",
      "dataset",
      "newspaper",
      "natural-language-processing",
      "natural-language-generation",
      "nlg-dataset",
      "nlg",
      "natural-language-understanding",
      "nlu"
    ],
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/2108.09084",
      "https://arxiv.org/abs/2107.02192",
      "https://arxiv.org/abs/2005.08100",
      "https://arxiv.org/abs/2001.04451",
      "https://arxiv.org/abs/1706.03762",
      "https://arxiv.org/abs/2006.04558",
      "https://arxiv.org/abs/2108.10447"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [ming024's FastSpeech2](https://github.com/ming024/FastSpeech2)\n- [wuch15's Fastformer](https://github.com/wuch15/Fastformer)\n- [lucidrains' fast-transformer-pytorch](https://github.com/lucidrains/fast-transformer-pytorch)\n- [lucidrains' long-short-transformer](https://github.com/lucidrains/long-short-transformer)\n- [sooftware's conformer](https://github.com/sooftware/conformer)\n- [lucidrains' reformer-pytorch](https://github.com/lucidrains/reformer-pytorch)\n- [NVIDIA's NeMo](https://github.com/NVIDIA/NeMo): Special thanks to [Onur Babacan](https://github.com/babua) and [Rafael Valle](https://github.com/rafaelvalle) for unsupervised duration modeling.\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Please cite this repository by the \"[Cite this repository](https://github.blog/2021-08-19-enhanced-support-citations-github/)\" of **About** section (top right of the main page).\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "cff-version: 1.0.0\nmessage: \"If you use this software, please cite it as below.\"\nauthors:\n- family-names: \"Lee\"\n  given-names: \"Keon\"\n  orcid: \"https://orcid.org/0000-0001-9028-1018\"\ntitle: \"Comprehensive-Transformer-TTS\"\nversion: 0.1.1\ndoi: 10.5281/zenodo.5526991\ndate-released: 2021-09-25\nurl: \"https://github.com/keonlee9420/Comprehensive-Transformer-TTS\"",
      "technique": "File Exploration"
    },
    {
      "confidence": [
        0.9997656974615573,
        0.9887739249159297,
        0.9340311035749151
      ],
      "excerpt": "[x] Long-Short Transformer: Efficient Transformers for Language and Vision (Zhu et al., 2021) \n[x] Conformer: Convolution-augmented Transformer for Speech Recognition (Gulati et al., 2020) \n[x] Reformer: The Efficient Transformer (Kitaev et al., 2020) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.979246951336869
      ],
      "excerpt": "[x] FastSpeech 2: Fast and High-Quality End-to-End Text to Speech (Ren et al., 2020) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/keonlee9420/Comprehensive-Transformer-TTS",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-24T15:24:45Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-25T06:44:30Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9861070577390044
      ],
      "excerpt": "A Non-Autoregressive Transformer based TTS, supporting a family of SOTA transformers with supervised and unsupervised duration modelings. This project grows with the research community, aiming to achieve the ultimate TTS. Any suggestions toward the best Non-AR TTS are welcome :) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8455940375691072,
        0.9069543236505466
      ],
      "excerpt": "[x] FastSpeech 2: Fast and High-Quality End-to-End Text to Speech (Ren et al., 2020) \n[x] One TTS Alignment To Rule Them All (Badlani et al., 2021): We are finally freed from external aligners such as MFA! Validation alignments for LJ014-0329 up to 70K are shown below as an example. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.847196791782075
      ],
      "excerpt": "Toggle the type of building blocks by \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9208650525714004
      ],
      "excerpt": "Toggle the type of duration modelings by \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9193962515160992
      ],
      "excerpt": "DATASET refers to the names of datasets such as LJSpeech and VCTK in the following documents. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9243717878618372
      ],
      "excerpt": "Batch inference is also supported, try \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8605590358331859
      ],
      "excerpt": "The supported datasets are \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9095368652286329
      ],
      "excerpt": "VCTK: The CSTR VCTK Corpus includes speech data uttered by 110 English speakers (multi-speaker TTS) with various accents. Each speaker reads out about 400 sentences, which were selected from a newspaper, the rainbow passage and an elicitation paragraph used for the speech accent archive. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8816330491236615
      ],
      "excerpt": "For a multi-speaker TTS with external speaker embedder, download ResCNN Softmax+Triplet pretrained model of philipperemy's DeepSpeaker for the speaker embedding and locate it in ./deepspeaker/pretrained_models/. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8868845803163208,
        0.9774094653285036
      ],
      "excerpt": "  for some preparations. \nFor the forced alignment, Montreal Forced Aligner (MFA) is used to obtain the alignments between the utterances and the phoneme sequences. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8243373236934204,
        0.9138279450402593,
        0.8824563550672744
      ],
      "excerpt": "Note that there are no pre-extracted phoneme-level variance features in unsupervised duration modeling. \nConvolutional embedding is used as StyleSpeech for phoneme-level variance in unsupervised duration modeling. Otherwise, bucket-based embedding is used as FastSpeech2. \nUnsupervised duration modeling in phoneme-level will take longer time than frame-level since the additional computation of phoneme-level variance is activated at runtime. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A Non-Autoregressive Transformer based TTS, supporting a family of SOTA transformers with supervised and unsupervised duration modelings. This project grows with the research community, aiming to achieve the ultimate TTS.",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/keonlee9420/Comprehensive-Transformer-TTS/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 13,
      "date": "Sun, 26 Dec 2021 16:06:59 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/keonlee9420/Comprehensive-Transformer-TTS/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "keonlee9420/Comprehensive-Transformer-TTS",
    "technique": "GitHub API"
  },
  "hasBuildFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/keonlee9420/Comprehensive-Transformer-TTS/main/Dockerfile"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8526654199962829
      ],
      "excerpt": "  You have to unzip the files in preprocessed_data/DATASET/TextGrid/. Alternately, you can run the aligner by yourself. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8231427514499966
      ],
      "excerpt": "      <img src=\"./img/LJ014-0329.gif\" width=\"60%\"> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.838166860265218
      ],
      "excerpt": "You have to download the pretrained models and put them in output/ckpt/DATASET/. The models are trained with unsupervised duration modeling under transformer building block. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9070504322241887
      ],
      "excerpt": "python3 synthesize.py --text \"YOUR_DESIRED_TEXT\" --restore_step RESTORE_STEP --mode single --dataset DATASET \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9070504322241887,
        0.8399219858822086
      ],
      "excerpt": "python3 synthesize.py --text \"YOUR_DESIRED_TEXT\" --speaker_id SPEAKER_ID --restore_step RESTORE_STEP --mode single --dataset DATASET \nThe dictionary of learned speakers can be found at preprocessed_data/DATASET/speakers.json, and the generated utterances will be put in output/result/. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8778166864889236,
        0.8238653794577389
      ],
      "excerpt": "python3 synthesize.py --source preprocessed_data/DATASET/val.txt --restore_step RESTORE_STEP --mode batch --dataset DATASET \nto synthesize all utterances in preprocessed_data/DATASET/val.txt. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9070504322241887
      ],
      "excerpt": "python3 synthesize.py --text \"YOUR_DESIRED_TEXT\" --restore_step RESTORE_STEP --mode single --dataset DATASET --duration_control 0.8 --energy_control 0.8 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8008331685760428,
        0.8705832100376315
      ],
      "excerpt": "Run  \n  python3 prepare_align.py --dataset DATASET \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8705832100376315,
        0.8287974015137436,
        0.9150949912405066
      ],
      "excerpt": "  python3 preprocess.py --dataset DATASET \nTrain your model with \npython3 train.py --dataset DATASET \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.825361263358686
      ],
      "excerpt": "tensorboard --logdir output/log \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8890818307099057
      ],
      "excerpt": "    <img src=\"./preprocessed_data/VCTK/spker_embed_tsne.png\" width=\"40%\"> \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/keonlee9420/Comprehensive-Transformer-TTS/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python",
      "Dockerfile"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2020 Philippe R\\xc3\\xa9my\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Comprehensive-Transformer-TTS - PyTorch Implementation",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "Comprehensive-Transformer-TTS",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "keonlee9420",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/keonlee9420/Comprehensive-Transformer-TTS/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "keonlee9420",
        "body": "",
        "dateCreated": "2021-09-25T03:49:58Z",
        "datePublished": "2021-09-27T13:49:09Z",
        "html_url": "https://github.com/keonlee9420/Comprehensive-Transformer-TTS/releases/tag/v0.1.1",
        "name": "v0.1.1",
        "tag_name": "v0.1.1",
        "tarball_url": "https://api.github.com/repos/keonlee9420/Comprehensive-Transformer-TTS/tarball/v0.1.1",
        "url": "https://api.github.com/repos/keonlee9420/Comprehensive-Transformer-TTS/releases/50321782",
        "zipball_url": "https://api.github.com/repos/keonlee9420/Comprehensive-Transformer-TTS/zipball/v0.1.1"
      },
      {
        "authorType": "User",
        "author_name": "keonlee9420",
        "body": "",
        "dateCreated": "2021-09-24T17:08:27Z",
        "datePublished": "2021-09-24T17:20:46Z",
        "html_url": "https://github.com/keonlee9420/Comprehensive-Transformer-TTS/releases/tag/v0.1.0",
        "name": "v0.1.0",
        "tag_name": "v0.1.0",
        "tarball_url": "https://api.github.com/repos/keonlee9420/Comprehensive-Transformer-TTS/tarball/v0.1.0",
        "url": "https://api.github.com/repos/keonlee9420/Comprehensive-Transformer-TTS/releases/50222735",
        "zipball_url": "https://api.github.com/repos/keonlee9420/Comprehensive-Transformer-TTS/zipball/v0.1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can install the Python dependencies with\n```\npip3 install -r requirements.txt\n```\nAlso, `Dockerfile` is provided for `Docker` users.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 99,
      "date": "Sun, 26 Dec 2021 16:06:59 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "text-to-speech",
      "supervised",
      "unsupervised",
      "non-autoregressive",
      "non-ar",
      "multi-speaker",
      "ultimate-tts",
      "tts",
      "pytorch",
      "comprehensive",
      "single-speaker",
      "fastspeech",
      "transformer",
      "neural-tts",
      "fastspeech2",
      "hifi-gan",
      "mel-gan",
      "sota",
      "speech-synthesis",
      "deep-learning"
    ],
    "technique": "GitHub API"
  }
}
{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1506.02025",
      "https://arxiv.org/abs/1506.02025*](https://arxiv.org/abs/1506.02025)"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "[*[1] Emmanuel Dauc\u00e9, Pierre Albiges, Laurent U. Perrinet; A dual foveal-peripheral visual processing model implements efficient saccade selection. Journal of Vision 2020;20(8):22.*](https://jov.arvojournals.org/article.aspx?articleid=2770680)\n\n[*[2] Max Jaderberg, Karen Simonyan, Andrew Zisserman, Koray Kavukcuoglu; Spatial Transformer Networks. arXiv:1506.02025*](https://arxiv.org/abs/1506.02025)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9686679014285212
      ],
      "excerpt": "Master's 1 internship, BraiNets team, Institut de Neurosciences de la Timone (INT, Marseille, France). \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dabane-ghassan/int-lab-book",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-04-05T07:41:27Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-05T20:20:43Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9847619837504026,
        0.9619805100176629,
        0.90272803138608
      ],
      "excerpt": "Description of my internship project: \nIn contrast with computer vision, biological vision is characterized by an anisotropic sensor (The Retina) as well as the ability to move the eyesight to   different locations in the visual scene through ocular saccades. To better understand how the human eye analyzes visual scenes, a bio-inspired artificial  vision  model was recently suggested by Dauc\u00e9 et al (2020) <sup>1</sup>.The goal of this master\u2019s internship would be to compare the results obtained by Dauc\u00e9 et   al with some of the more classical attentional computer vision models like the Spatial transformer network <sup>2</sup> where the visual input undergoes a foveal deformation. \nThis module is used in the POLO_ATN network. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9709895857694734,
        0.883094024351828,
        0.8042118345746325
      ],
      "excerpt": "Overall results: Central accuracy of 88% and general accuracy of 43%, compared to 84% and 34% in the generic what pathway, respectively. \nAccuracy map comparaison with the generic what pathway from the paper with the same training parameters: \nSpatial Transformer Network             |  Generic What pathway <sup>1</sup> \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.924732905315678
      ],
      "excerpt": "Training for 110 epochs with an initial learning rate of 0.01 that decays by a factor of 10 every 30 epochs, each 10 epochs increase the standard deviation of the eccentricity, last 20 epochs vary the contrast. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9052272611664306
      ],
      "excerpt": "Performance when the contrast varies between 30-70% and the digit is shifted by 40 pixels (the maximum amount): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8885142735164708,
        0.9216597172253076,
        0.9556781282688702
      ],
      "excerpt": "Training for 110 epochs with an initial learning rate of 0.01 that decays by a half every 10 epochs, each 10 epochs increase the standard deviation of the eccentricity, last 20 epochs vary the contrast. \nAfter transformation with a ATN (STN parametrized for attention), the digit is shifted by 40 pixels to check if the network can catch it: \nPerformance when the contrast is 30 and the digit is shifted by 40 pixels (the maximum amount): \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Foveated Spatial Transformers",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dabane-ghassan/int-lab-book/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 28 Dec 2021 13:04:29 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dabane-ghassan/int-lab-book/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "dabane-ghassan/int-lab-book",
    "technique": "GitHub API"
  },
  "hasExecutableNotebook": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/dabane-ghassan/int-lab-book/main/src/stn_128x128-POLO-tests.ipynb",
      "https://raw.githubusercontent.com/dabane-ghassan/int-lab-book/main/src/stn_128x128.ipynb",
      "https://raw.githubusercontent.com/dabane-ghassan/int-lab-book/main/src/stn_128x128-POLO-tests-DUAL-LOW-COMPRESSION.ipynb",
      "https://raw.githubusercontent.com/dabane-ghassan/int-lab-book/main/src/stn_128x128-POLO-tests-LOW-COMPRESSION.ipynb",
      "https://raw.githubusercontent.com/dabane-ghassan/int-lab-book/main/src/downsampling_attention_stn.ipynb",
      "https://raw.githubusercontent.com/dabane-ghassan/int-lab-book/main/src/stn_128x128-POLO-tests-DUAL-LOW-COMPRESSION-norm.ipynb",
      "https://raw.githubusercontent.com/dabane-ghassan/int-lab-book/main/src/stn_128x128-POLO-tests-DUAL-LOW-COMPRESSION-norm-conv.ipynb",
      "https://raw.githubusercontent.com/dabane-ghassan/int-lab-book/main/src/benchmark.ipynb",
      "https://raw.githubusercontent.com/dabane-ghassan/int-lab-book/main/src/stn_28x28.ipynb"
    ],
    "technique": "File Exploration"
  },
  "invocation": [
    {
      "confidence": [
        0.8022715183581558,
        0.8174540907975313
      ],
      "excerpt": "Training for 160  epochs with SGD, learning rate of 0.01 without decay, Each 10 epochs, increment the shift standard deviation by 1 [0, 15]. \nTraining statistics: \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/dabane-ghassan/int-lab-book/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Jupyter Notebook",
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2021 Ghassan\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Project",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "int-lab-book",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "dabane-ghassan",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/dabane-ghassan/int-lab-book/blob/main/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 2,
      "date": "Tue, 28 Dec 2021 13:04:29 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "spatial-transformer-networks",
      "deep-learning",
      "bio-inspired-vision",
      "computer-vision",
      "machine-learning",
      "foveated-spatial-transformer",
      "stn",
      "convolutional-neural-networks"
    ],
    "technique": "GitHub API"
  }
}
{
  "citation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@InProceedings{beinborn2018multimodal,\n  title = {{Multimodal Grounding for Language Processing}},\n    author = {Beinborn, Lisa and Botschen, Teresa and Gurevych, Iryna},\n    publisher = {Association for Computational Linguistics},\n    booktitle = {Proceedings of COLING 2018, the 27th International Conference on Computational Linguistics: Technical Papers},\n    pages = {to appear},\n    month = {aug},\n    year = {2018},\n    location = {Santa Fe, USA},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.9821149606098638,
        0.9957587253572504
      ],
      "excerpt": "Please use the following citation: \nContact person:  Teresa Botschen (botschen@aiphes.tu-darmstadt.de), Lisa Beinborn (lisa.beinborn@uni-due.de) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9802987603597195,
        0.9940081578632447,
        0.8944178096468923,
        0.9957449685019696
      ],
      "excerpt": "imSitu dataset by Yatskar et al. (2016) (paper: https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Yatskar_Situation_Recognition_Visual_CVPR_2016_paper.pdf, data: http://imsitu.org/) \n--> We trained the embeddings by applying a pre-trained VGG19 neural network for image classification on the visual resources. (pretrained network: Simonyan and Zisserman (2014) (paper: https://arxiv.org/pdf/1409.1556.pdf)) \nvisual imSitu representations: 4096 dim \nGlove embeddings by Pennington et al. (2014) (paper: http://aclweb.org/anthology/D14-1162) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8512418784757423
      ],
      "excerpt": "We mapped from textual to visual embeddings by applying the mapping method by Collell et al. (2017) (paper: http://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14811/14042) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9894424513715641
      ],
      "excerpt": "SimVerb dataset by Gerz et al. (2016) (paper: http://www.aclweb.org/anthology/D16-1235) \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/UKPLab/coling2018-multimodalSurvey",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-05-28T11:43:00Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-09-02T13:52:42Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9939143188285923,
        0.9985371523917298
      ],
      "excerpt": "This repository contains additional information on the analyses in our Coling2018-survey \"Multimodal Grounding for Language Processing\".  \nAbstract: This survey discusses how recent developments in multimodal processing facilitate conceptual grounding of language. We categorize the information flow in multimodal processing with respect to cognitive models of human information processing and analyze different methods for combining multimodal representations. Based on this methodological inventory, we discuss the benefit of multimodal grounding for a variety of language processing tasks and the challenges that arise. We particularly focus on multimodal grounding of verbs which play a crucial role for multimodal compositionality. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9917835011033937,
        0.9286529652543983,
        0.8788748359513266
      ],
      "excerpt": "This repository contains experimental software and is published for the sole purpose of giving additional background details on the respective publication. \nWe present first steps towards an investigation of verb grounding and analyze the quality of verb representations in the most common publicly available approaches for multimodal representations. \nThis project uses different pretrained word embeddings which can be found here: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8528913504903175
      ],
      "excerpt": "We used the following resources to create multimodal representations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9731148825763128
      ],
      "excerpt": "In line with previous work, the quality of the representations is evaluated as the Spearman correlation between the cosine similarity of two verb embeddings and their corresponding similarity rating in the SimVerb dataset. We compare the quality of 3498 verb pairs.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9123563162935723,
        0.9248960258597152,
        0.9054199267748542
      ],
      "excerpt": "This measure indicates to which extent verb meanings involve bodily experience. We obtain embodiment ratings for 1163 pairs.  \nThe class 'high embodiment' contains pairs like 'fall-dive' in which the embodiment of both verbs can be found in the highest quartile (135 pairs),  \n'low embodiment' contains pairs with embodiment ratings in the lowest quartile (81 pairs) like 'know-decide'. \n",
      "technique": "Supervised classification"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/UKPLab/coling18-multimodalSurvey/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Sat, 25 Dec 2021 17:13:09 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/UKPLab/coling2018-multimodalSurvey/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "UKPLab/coling2018-multimodalSurvey",
    "technique": "GitHub API"
  },
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/UKPLab/coling2018-multimodalSurvey/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Apache License 2.0",
      "url": "https://api.github.com/licenses/apache-2.0"
    },
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "coling18-multimodalSurvey",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "coling2018-multimodalSurvey",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "UKPLab",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/UKPLab/coling2018-multimodalSurvey/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 1,
      "date": "Sat, 25 Dec 2021 17:13:09 GMT"
    },
    "technique": "GitHub API"
  }
}
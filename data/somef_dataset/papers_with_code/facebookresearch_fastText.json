{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1607.04606",
      "https://arxiv.org/abs/1607.01759",
      "https://arxiv.org/abs/1612.03651",
      "https://arxiv.org/abs/1612.03651"
    ],
    "technique": "Regular expression"
  },
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Please cite [1](#enriching-word-vectors-with-subword-information) if using this code for learning word representations or [2](#bag-of-tricks-for-efficient-text-classification) if using for text classification.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{joulin2016fasttext,\n  title={FastText.zip: Compressing text classification models},\n  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Douze, Matthijs and J{\\'e}gou, H{\\'e}rve and Mikolov, Tomas},\n  journal={arXiv preprint arXiv:1612.03651},\n  year={2016}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@InProceedings{joulin2017bag,\n  title={Bag of Tricks for Efficient Text Classification},\n  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},\n  booktitle={Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers},\n  month={April},\n  year={2017},\n  publisher={Association for Computational Linguistics},\n  pages={427--431},\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "@article{bojanowski2017enriching,\n  title={Enriching Word Vectors with Subword Information},\n  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},\n  journal={Transactions of the Association for Computational Linguistics},\n  volume={5},\n  year={2017},\n  issn={2307-387X},\n  pages={135--146}\n}",
      "technique": "Regular expression"
    },
    {
      "confidence": [
        0.8929030112788902
      ],
      "excerpt": "Word vectors for 157 languages trained on Wikipedia and Crawl. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9422100272984922
      ],
      "excerpt": "$ wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip \n",
      "technique": "Supervised classification"
    }
  ],
  "codeOfConduct": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://raw.githubusercontent.com/facebookresearch/fastText/main/CODE_OF_CONDUCT.md",
    "technique": "File Exploration"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/fastText",
    "technique": "GitHub API"
  },
  "contributingGuidelines": {
    "confidence": [
      1.0
    ],
    "excerpt": "Contributing to fastText\nWe want to make contributing to this project as easy and transparent as possible.\nIssues\nWe use GitHub issues to track public bugs. Please ensure your description is clear and has sufficient instructions to be able to reproduce the issue.\nReproducing issues\nPlease make sure that the issue you mention is not a result of one of the existing third-party libraries. For example, please do not post an issue if you encountered an error within a third-party Python library. We can only help you with errors which can be directly reproduced either with our C++ code or the corresponding Python bindings. If you do find an error, please post detailed steps to reproduce it. If we can't reproduce your error, we can't help you fix it.\nPull Requests\nPlease post an Issue before submitting a pull request. This might save you some time as it is possible we can't support your contribution, albeit we try our best to accomodate your (planned) work and highly appreciate your time. Generally, it is best to have a pull request emerge from an issue rather than the other way around.\nTo create a pull request:\n\nFork the repo and create your branch from master.\nIf you've added code that should be tested, add tests.\nIf you've changed APIs, update the documentation.\nEnsure the test suite passes.\nMake sure your code lints.\nIf you haven't already, complete the Contributor License Agreement (\"CLA\").\n\nTests\nFirst, you will need to make sure you have the required data. For that, please have a look at the fetch_test_data.sh script under tests. Next run the tests using the runtests.py script passing a path to the directory containing the datasets.\nContributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\nComplete your CLA here: https://code.facebook.com/cla\nLicense\nBy contributing to fastText, you agree that your contributions will be licensed under its MIT license.",
    "technique": "File Exploration"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-07-16T13:38:42Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-20T07:50:19Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9769698115976808
      ],
      "excerpt": "fastText is a library for efficient learning of word representations and sentence classification. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8712700522911636
      ],
      "excerpt": "Obtaining word vectors for out-of-vocabulary words \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8965799723048201
      ],
      "excerpt": "Bag of Tricks for Efficient Text Classification \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.915712009163892,
        0.804878140569991
      ],
      "excerpt": "The preprocessed YFCC100M data used in [2]. \nWe also provide a cheatsheet full of useful one-liners. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8273099514127742,
        0.8445442627931573,
        0.8610864278537756
      ],
      "excerpt": "This will produce object files for all the classes as well as the main binary fasttext. \nIf you do not plan on using the default system-wide compiler, update the two macros defined at the beginning of the Makefile (CC and INCLUDES). \nFor now this is not part of a release, so you will need to clone the master branch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9190149997775718,
        0.8610864278537756
      ],
      "excerpt": "This will create the fasttext binary and also all relevant libraries (shared, static, PIC). \nFor now this is not part of a release, so you will need to clone the master branch. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8776028636598163,
        0.9156813420755983
      ],
      "excerpt": "For further information and introduction see python/README.md \nIn order to learn word vectors, as described in 1, do: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9483541808483614
      ],
      "excerpt": "At the end of optimization the program will save two files: model.bin and model.vec. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9781224015614493,
        0.894958727550187,
        0.8852187335675773
      ],
      "excerpt": "model.bin is a binary file containing the parameters of the model along with the dictionary and all hyper parameters. \nThe binary file can be used later to compute word vectors or to restart the optimization. \nThe previously trained model can be used to compute word vectors for out-of-vocabulary words. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8846431569672244
      ],
      "excerpt": "By default, we assume that labels are words that are prefixed by the string __label__. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9614742823684236,
        0.8272065922480798
      ],
      "excerpt": "The argument k is optional, and is equal to 1 by default. \nIn order to obtain the k most likely labels for a piece of text, use: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8317909397572478
      ],
      "excerpt": "or use predict-prob to also get the probability for each label \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9186981690125441
      ],
      "excerpt": "The argument k is optional, and equal to 1 by default. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8230558135694459
      ],
      "excerpt": "This assumes that the text.txt file contains the paragraphs that you want to get vectors for. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.838895537599196
      ],
      "excerpt": "This will create a .ftz file with a smaller memory footprint. All the standard functionality, like test or predict work the same way on the quantized models: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8965799723048201
      ],
      "excerpt": "[2] A. Joulin, E. Grave, P. Bojanowski, T. Mikolov, Bag of Tricks for Efficient Text Classification \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Library for fast text representation and classification.",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Invoke a command without arguments to list available arguments and their default values:\n\n```\n$ ./fasttext supervised\nEmpty input or output path.\n\nThe following arguments are mandatory:\n  -input              training file path\n  -output             output file path\n\nThe following arguments are optional:\n  -verbose            verbosity level [2]\n\nThe following arguments for the dictionary are optional:\n  -minCount           minimal number of word occurrences [1]\n  -minCountLabel      minimal number of label occurrences [0]\n  -wordNgrams         max length of word ngram [1]\n  -bucket             number of buckets [2000000]\n  -minn               min length of char ngram [0]\n  -maxn               max length of char ngram [0]\n  -t                  sampling threshold [0.0001]\n  -label              labels prefix [__label__]\n\nThe following arguments for training are optional:\n  -lr                 learning rate [0.1]\n  -lrUpdateRate       change the rate of updates for the learning rate [100]\n  -dim                size of word vectors [100]\n  -ws                 size of the context window [5]\n  -epoch              number of epochs [5]\n  -neg                number of negatives sampled [5]\n  -loss               loss function {ns, hs, softmax} [softmax]\n  -thread             number of threads [12]\n  -pretrainedVectors  pretrained word vectors for supervised learning []\n  -saveOutput         whether output params should be saved [0]\n\nThe following arguments for quantization are optional:\n  -cutoff             number of words and ngrams to retain [0]\n  -retrain            finetune embeddings if a cutoff is applied [0]\n  -qnorm              quantizing the norm separately [0]\n  -qout               quantizing the classifier [0]\n  -dsub               size of each sub-vector [2]\n```\n\nDefaults may vary by mode. (Word-representation modes `skipgram` and `cbow` use a default `-minCount` of 5.)\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/fastText/releases",
    "technique": "GitHub API"
  },
  "faq": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can find [answers to frequently asked questions](https://fasttext.cc/docs/en/faqs.html#content) on our [website](https://fasttext.cc/).\n\n",
      "technique": "Header extraction"
    }
  ],
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 4409,
      "date": "Mon, 20 Dec 2021 10:33:04 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/facebookresearch/fastText/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "facebookresearch/fastText",
    "technique": "GitHub API"
  },
  "hasDocumentation": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://github.com/facebookresearch/fastText/tree/main/docs",
      "https://github.com/facebookresearch/fastText/tree/main/website/static/docs"
    ],
    "technique": "File Exploration"
  },
  "hasScriptFile": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/classification-results.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/classification-example.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/word-vector-example.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/get-wikimedia.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/quantization-example.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/scripts/kbcompletion/data.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/scripts/kbcompletion/svo.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/scripts/kbcompletion/fb15k237.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/scripts/kbcompletion/fb15k.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/scripts/kbcompletion/wn18.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/scripts/quantization/quantization-results.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/alignment/example.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/crawl/process_wet_file.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/crawl/filter_dedup.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/crawl/download_crawl.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/tests/fetch_test_data.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/.circleci/gcc_test.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/.circleci/setup_circleimg.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/.circleci/setup_debian.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/.circleci/pull_data.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/.circleci/cmake_test.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/.circleci/run_locally.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/.circleci/python_test.sh",
      "https://raw.githubusercontent.com/facebookresearch/fastText/main/.circleci/pip_test.sh"
    ],
    "technique": "File Exploration"
  },
  "installation": [
    {
      "confidence": [
        0.8058015025548094
      ],
      "excerpt": "Getting the source code \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8606438138370869
      ],
      "excerpt": "$ wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9906248903846466,
        0.8474895321345809
      ],
      "excerpt": "$ cd fastText-0.9.2 \n$ make \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.982061580294172,
        0.9906248903846466,
        0.9920524742609089,
        0.98163424234106
      ],
      "excerpt": "$ git clone https://github.com/facebookresearch/fastText.git \n$ cd fastText \n$ mkdir build &amp;&amp; cd build &amp;&amp; cmake .. \n$ make &amp;&amp; make install \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.982061580294172,
        0.9906248903846466,
        0.999746712887969
      ],
      "excerpt": "$ git clone https://github.com/facebookresearch/fastText.git \n$ cd fastText \n$ pip install . \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8147438040199454
      ],
      "excerpt": "You can also quantize a supervised model to reduce its memory usage with the following command: \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8514016617147449
      ],
      "excerpt": "FastText.zip: Compressing text classification models \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8082022887640018
      ],
      "excerpt": "$ unzip v0.9.2.zip \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.901453818582758,
        0.9103756700490212
      ],
      "excerpt": "$ ./fasttext skipgram -input data.txt -output model \nwhere data.txt is a training file containing UTF-8 encoded text. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9070631331869214
      ],
      "excerpt": "model.vec is a text file containing the word vectors, one per line. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8553814334179051
      ],
      "excerpt": "This will output word vectors to the standard output, one vector per line. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8643354341371444
      ],
      "excerpt": "$ cat queries.txt | ./fasttext print-word-vectors model.bin \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8839158252682724,
        0.9437964632054884
      ],
      "excerpt": "$ ./fasttext supervised -input train.txt -output model \nwhere train.txt is a text file containing a training sentence per line along with the labels. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8271340404619316
      ],
      "excerpt": "This will output two files: model.bin and model.vec. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8951381859294457
      ],
      "excerpt": "$ ./fasttext test model.bin test.txt k \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9118148969249582
      ],
      "excerpt": "$ ./fasttext predict model.bin test.txt k \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9118148969249582,
        0.8919829784350816,
        0.855185380383668
      ],
      "excerpt": "$ ./fasttext predict-prob model.bin test.txt k \nwhere test.txt contains a piece of text to classify per line. \nDoing so will print to the standard output the k most likely labels for each line. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8530417207217321
      ],
      "excerpt": "$ ./fasttext print-sentence-vectors model.bin &lt; text.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8906678155209428
      ],
      "excerpt": "The program will output one vector representation per line in the file. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.857129346874625
      ],
      "excerpt": "$ ./fasttext quantize -output model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8910782061406535
      ],
      "excerpt": "$ ./fasttext test model.ftz test.txt \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.861059532256563
      ],
      "excerpt": "run the script quantization-example.sh for an example. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8514016617147449
      ],
      "excerpt": "[3] A. Joulin, E. Grave, P. Bojanowski, M. Douze, H. J\u00e9gou, T. Mikolov, FastText.zip: Compressing text classification models \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/facebookresearch/fastText/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "HTML",
      "C++",
      "JavaScript",
      "Python",
      "CSS",
      "Shell",
      "Makefile",
      "CMake",
      "Perl"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2016-present, Facebook, Inc.\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "fastText",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "fastText",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "facebookresearch",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/facebookresearch/fastText/blob/main/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "Celebio",
        "body": "We are happy to announce the release of version 0.9.2.\r\n\r\nWebAssembly\r\n--------------\r\nWe are excited to release fastText bindings for WebAssembly. Classification tasks are widely used in web applications and we believe giving access to the complete fastText API from the browser will notably help our community to build nice tools. See our [documentation](https://fasttext.cc/docs/en/webassembly-module.html) to learn more.\r\n\r\nAutotune: automatic hyperparameter optimization\r\n--------------------------------------------\r\nFinding the best hyperparameters is crucial for building efficient models. However, searching the best hyperparameters manually is difficult. This release includes the [autotune feature](https://ai.facebook.com/blog/fasttext-blog-post-open-source-in-brief/) that allows you to find automatically the best hyperparameters for your dataset.\r\nYou can find more information on how to use it [here](https://fasttext.cc/docs/en/autotune.html).\r\n\r\nPython\r\n--------\r\nfastText loves Python. In this release, we have:\r\n- several bug fixes for prediction functions\r\n- nearest neighbors and analogies for Python\r\n- a memory leak fix\r\n- website tutorials with Python examples\r\n\r\nThe autotune feature is fully integrated with our Python API. This allows us to have a more stable autotune optimization loop from Python and to synchronize the best hyper-parameters with the `_FastText` model object.\r\n\r\n\r\nPre-trained models tool\r\n--------------------------\r\nWe release two helper scripts:\r\n- [download_model.py](https://fasttext.cc/docs/en/crawl-vectors.html#download-directly-with-command-line-or-from-python) to automatically download pre-trained vectors from our website\r\n- [reduce_model.py](https://fasttext.cc/docs/en/crawl-vectors.html#adapt-the-dimension) to reduce the word-vectors' size using PCA.\r\n\r\nThey can also be used directly from our Python API.\r\n\r\nMore metrics\r\n---------------\r\nWhen you test a trained model, you can now have more detailed results for the precision/recall metrics of a specific label or all labels.\r\n\r\nPaper source code\r\n------------------\r\nThis release contains the source code of the [unsupervised multilingual alignment paper](https://arxiv.org/abs/1805.11222).\r\n\r\nCommunity feedback and contributions\r\n--------------------------------\r\nWe want to thank our community for giving us feedback on [Facebook](https://www.facebook.com/groups/1174547215919768/) and on [GitHub](https://github.com/facebookresearch/fastText).\r\n\r\n\r\n",
        "dateCreated": "2020-04-28T09:40:33Z",
        "datePublished": "2020-04-28T09:51:33Z",
        "html_url": "https://github.com/facebookresearch/fastText/releases/tag/v0.9.2",
        "name": "v0.9.2",
        "tag_name": "v0.9.2",
        "tarball_url": "https://api.github.com/repos/facebookresearch/fastText/tarball/v0.9.2",
        "url": "https://api.github.com/repos/facebookresearch/fastText/releases/25955458",
        "zipball_url": "https://api.github.com/repos/facebookresearch/fastText/zipball/v0.9.2"
      },
      {
        "authorType": "User",
        "author_name": "Celebio",
        "body": "We are happy to announce the release of version 0.9.1.\r\n\r\nNew release of python module\r\n----------\r\nThe main goal of this release is to merge two existing python modules: the official `fastText` module which was available on our github repository and the unofficial `fasttext` module which was available on pypi.org.\r\n\r\nYou can find an overview of the new API [here](https://fasttext.cc/docs/en/python-module.html), and more insight in our [blog post](https://fasttext.cc/blog/2019/06/25/blog-post.html).\r\n\r\n\r\n\r\nRefactoring\r\n-----\r\nThis version includes a massive rewrite of internal classes. The training and test are now split into three different classes : `Model` that takes care of the computational aspect, `Loss` that handles loss and applies gradients to the output matrix, and `State` that is responsible of holding the model's state inside each thread.\r\n\r\nThat makes the code more straighforward to read but also gives a smaller memory footprint, because the data needed for loss computation is now hold only once unlike before where there was one for each thread.\r\n\r\nMisc\r\n--------\r\n- Compilation issues fix for recent versions of Mac OS X.\r\n- Better unicode handling :\r\n    - [`on_unicode_error` argument](https://github.com/facebookresearch/fastText/commit/e13484bcb261cda51d33c4940ab5e207aba3ee79) that helps to handle unicode issues one can face with some datasets\r\n   - [bug fix](https://github.com/facebookresearch/fastText/commit/71c0ee5a8b91df21585aec8cb18991d696414fd5) related to different behaviour of pybind11's `py::str` class between python2 and python3\r\n- script for [unsupervised alignment](https://github.com/facebookresearch/fastText/commit/29c728ff4f05740be34a580ced3a065f57f8d10b)\r\n- public file hosting changed from `aws` to `fbaipublicfiles`\r\n- we added a Code of Conduct file.\r\n\r\n\r\nThank you !\r\n------------------\r\nAs always, we want to thank you for your help and your precious feedback which helps making this project better.",
        "dateCreated": "2019-07-04T11:48:15Z",
        "datePublished": "2019-07-04T11:53:06Z",
        "html_url": "https://github.com/facebookresearch/fastText/releases/tag/v0.9.1",
        "name": "v0.9.1",
        "tag_name": "v0.9.1",
        "tarball_url": "https://api.github.com/repos/facebookresearch/fastText/tarball/v0.9.1",
        "url": "https://api.github.com/repos/facebookresearch/fastText/releases/18412792",
        "zipball_url": "https://api.github.com/repos/facebookresearch/fastText/zipball/v0.9.1"
      },
      {
        "authorType": "User",
        "author_name": "Celebio",
        "body": "We are happy to announce the change of the license from BSD+patents to MIT and the release of fastText 0.2.0.\r\n\r\nThe main purpose of this release is to set a beta C++ API of the `FastText` class. The class now behaves as a computational library: we moved the display and some usage error handlings outside of it (mainly to `main.cc` and `fasttext_pybind.cc`). It is still compatible with older versions of the class, but some methods are now marked as deprecated and will probably be removed in the next release.\r\n\r\nIn this respect, we also introduce the official support for python. The [python binding of fastText](https://github.com/facebookresearch/fastText/tree/master/python) is a client of the `FastText` class.\r\n\r\nHere is a short summary of the [104 commits](https://github.com/facebookresearch/fastText/compare/v0.1.0...7842495a4d64c7a3bb4339d45d6e64321d002ed8) since 0.1.0 : \r\n\r\nNew : \r\n----\r\n- Introduction of the \u201cOneVsAll\u201d loss function for multi-label classification, which corresponds to the sum of binary cross-entropy computed independently for each label. This new loss can be used with the `-loss ova` or `-loss one-vs-all` command line option ( 8850c51b972ed68642a15c17fbcd4dd58766291d ).\r\n- Computation of the precision and recall metrics for each label ( be1e597cb67c069ba9940ff241d9aad38ccd37da ).\r\n- Removed printing functions from `FastText` class ( 256032b87522cdebc4850c99b204b81b3255cb2a ).\r\n- Better default for number of threads ( 501b9b1e4543fd2de55e4a621a9924ce7d2b5b17 ).\r\n- Python support ( f10ec1faea1605d40fdb79fe472cc2204f3d584c ).\r\n- More tests for circleci/python ( eb9703a4a7ed0f7559d6f341cc8e5d166d5e4d88, 97fcde80ea107ca52d3d778a083564619175039c, 1de0624bfaff02d91fd265f331c07a4a0a7bb857 ).\r\n\r\nBug fixes : \r\n---------\r\n- Normalize buffer vector in analogy queries.\r\n- Typo fixes and clarifications on website.\r\n- Improvements on python install issues : `setup.py` OS X compiler flags, pybind11 include.\r\n- Fix: getSubwords for EOS.\r\n- Fix: ETA time.\r\n- Fix: division by 0 in word analogy evaluation.\r\n- Fix for the infinite loop on ARM cpu.\r\n\r\nOperations :\r\n-------------\r\n- We released more pre-trained vectors (92bc7d230959e2a94125fbe7d3b05257effb1111, 5bf8b4c615b6308d76ad39a5a50fa6c4174113ea ).\r\n\r\nWorth noting : \r\n---------------\r\n\r\n* We added circleci build badges to the `README.md`\r\n* We modified the style to be in compliance with Facebook C++ style.\r\n* We added coverage option for `Makefile` and `setup.py` in order to build for measuring the coverage.\r\n\r\n\r\nThank you fastText community!\r\n--------------------------------\r\nWe want to thank you all for being a part of this community and sharing your passion with us. Some of these improvements would not have been possible without your help. \r\n",
        "dateCreated": "2018-12-18T03:11:13Z",
        "datePublished": "2018-12-19T14:58:16Z",
        "html_url": "https://github.com/facebookresearch/fastText/releases/tag/v0.2.0",
        "name": "0.2.0",
        "tag_name": "v0.2.0",
        "tarball_url": "https://api.github.com/repos/facebookresearch/fastText/tarball/v0.2.0",
        "url": "https://api.github.com/repos/facebookresearch/fastText/releases/14610055",
        "zipball_url": "https://api.github.com/repos/facebookresearch/fastText/zipball/v0.2.0"
      },
      {
        "authorType": "User",
        "author_name": "JoelMarcey",
        "body": "",
        "dateCreated": "2017-12-02T00:43:40Z",
        "datePublished": "2017-12-02T00:44:39Z",
        "html_url": "https://github.com/facebookresearch/fastText/releases/tag/v0.1.0",
        "name": "",
        "tag_name": "v0.1.0",
        "tarball_url": "https://api.github.com/repos/facebookresearch/fastText/tarball/v0.1.0",
        "url": "https://api.github.com/repos/facebookresearch/fastText/releases/8743341",
        "zipball_url": "https://api.github.com/repos/facebookresearch/fastText/zipball/v0.1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "We are continuously building and testing our library, CLI and Python bindings under various docker images using [circleci](https://circleci.com/).\n\nGenerally, **fastText** builds on modern Mac OS and Linux distributions.\nSince it uses some C++11 features, it requires a compiler with good C++11 support.\nThese include :\n\n* (g++-4.7.2 or newer) or (clang-3.3 or newer)\n\nCompilation is carried out using a Makefile, so you will need to have a working **make**.\nIf you want to use **cmake** you need at least version 2.8.9.\n\nOne of the oldest distributions we successfully built and tested the CLI under is [Debian jessie](https://www.debian.org/releases/jessie/).\n\nFor the word-similarity evaluation script you will need:\n\n* Python 2.6 or newer\n* NumPy & SciPy\n\nFor the python bindings (see the subdirectory python) you will need:\n\n* Python version 2.7 or >=3.4\n* NumPy & SciPy\n* [pybind11](https://github.com/pybind/pybind11)\n\nOne of the oldest distributions we successfully built and tested the Python bindings under is [Debian jessie](https://www.debian.org/releases/jessie/).\n\nIf these requirements make it impossible for you to use fastText, please open an issue and we will try to accommodate you.\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 23209,
      "date": "Mon, 20 Dec 2021 10:33:04 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "You can find our [latest stable release](https://github.com/facebookresearch/fastText/releases/latest) in the usual place.\n\nThere is also the master branch that contains all of our most recent work, but comes along with all the usual caveats of an unstable branch. You might want to use this if you are a developer or power-user.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "This library has two main use cases: word representation learning and text classification.\nThese were described in the two papers [1](#enriching-word-vectors-with-subword-information) and [2](#bag-of-tricks-for-efficient-text-classification).\n\n",
      "technique": "Header extraction"
    }
  ]
}
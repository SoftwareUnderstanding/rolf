{
  "arxivLinks": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "https://arxiv.org/abs/1803.00933",
      "https://arxiv.org/abs/1803.00933"
    ],
    "technique": "Regular expression"
  },
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Lyusungwon/apex_dqn_pytorch",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-07-24T10:31:38Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-08-24T07:44:46Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9787638903125595,
        0.937725622513789
      ],
      "excerpt": "Training agents to learn how to play Pikachu Volleyball. Architecture is based on Ape-x DQN from the paper. The game is in exe file which makes the whole problem much more complicated than other Atari games. I built python environment to take screenshot of the game to provide as state and detect the start and end of game. I used mss to take screen shot, cv2 to preprocess image, pynput to press the keyboard, and tensorboardX to record log. I created a number of virtual monitors with Xvfb for each actor. To provide different key input to each monitor, the architecture had to be multi-process. A learner only trains on GPU and many(Assume 10) actors collected data from virtual monitors. They communicate through files in log directory.  \nAs it sounds, it is complicated. My method seems pretty primitive but it was the only way to train pikachu volleyball. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9551522502845237
      ],
      "excerpt": "To see the performance of the agent, reset screen-size in environment.py to set the place for screen shot. Then place the pika.exe to the area and start a actor with trained model.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Ape-x DQN implementation on Pikachu Volleyball",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Lyusungwon/apex_dqn_pytorch/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Sun, 26 Dec 2021 08:19:57 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Lyusungwon/apex_dqn_pytorch/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Lyusungwon/apex_dqn_pytorch",
    "technique": "GitHub API"
  },
  "invocation": [
    {
      "confidence": [
        0.829134213494157
      ],
      "excerpt": "To see the performance of the agent, reset screen-size in environment.py to set the place for screen shot. Then place the pika.exe to the area and start a actor with trained model.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9377981761350243
      ],
      "excerpt": "python actor.py --load-model 180801225440_256_0.0001_4_84_129_32_1_30000_1500_10 --test \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Lyusungwon/apex_dqn_pytorch/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "Python"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Alphachu: Ape-x DQN implementation of Pikachu Volleyball",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "apex_dqn_pytorch",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Lyusungwon",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Lyusungwon/apex_dqn_pytorch/blob/master/README.md",
    "technique": "GitHub API"
  },
  "requirement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- Install PyTorch dependencies from http://pytorch.org\n- Install requirements.txt (```pip install -r requirements.txt```)\n- Install Xvfb(```sudo apt-get install xvfb -y```)\n\n",
      "technique": "Header extraction"
    }
  ],
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Run learner and copy the model timestamp with configuration.\n```\npython learner.py --actor-num 10\nLearner: Model saved in  /home/sungwonlyu/experiment/alphachu/180801225440_256_0.0001_4_84_129_32_1_30000_1500_10/model.pt\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "Run pika.exe and actor in virtual monitor. Also need to do this 10 times with varying epsilons. \n```\nDISPLAY=:99 wine pika.exe\nDISPLAY=:99 python actor.py --load-model 180801225440_256_0.0001_4_84_129_32_1_30000_1500_10 --epsilon 0.9 --wepsilon 0.9\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 43,
      "date": "Sun, 26 Dec 2021 08:19:57 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": " - I tried this in Ubuntu and Mac. \n - Reset log_directory and data_directory in actor.py, and learner.py. \n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "You can find demo on [youtube](https://www.youtube.com/watch?v=vSkLegIUD98). \n\n",
      "technique": "Header extraction"
    }
  ]
}
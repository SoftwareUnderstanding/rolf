{
  "acknowledgement": [
    {
      "confidence": [
        1
      ],
      "excerpt": "This framework is developed since 2018 by many contributors, and we thanks them very much for their contributions to this project! Here is the full list of our amazing contributors.\n\n* [Corentin Marionneau](https://github.com/Slaanaroth) (@Slaanaroth)\n  * Corentin created the first version of `sparql-engine` during its research internship at the [Laboratoire des Sciences du Num\u00e9rique de Nantes](https://www.ls2n.fr/) (LS2N). He is now a Web developer at SII Atlantique.\n* [Merlin Barzilai](https://github.com/Rintarou) (@Rintarou)\n  * Merlin designed the first SPARQL compliance tests for the framework during its research internship at the [LS2N](https://www.ls2n.fr/).\n* [Dustin Whitney](https://github.com/dwhitney) (@dwhitney)\n  * Dustin implemented the support for custom SPARQL functions and provided a lot of feedback during the early stages of development.\n* [Julien Aimonier-Davat](https://github.com/Lastshot97) (@Lastshot97)\n  * Julien implemented the support for SPARQL Property Paths evaluation during its research internship at the [LS2N](https://www.ls2n.fr/). He is now a Ph.D. Student at the University of Nantes.\n* [Arnaud Grall](https://github.com/folkvir) (@folkvir)\n  * Arnaud contributed to many bugfixes and provided a lot of feedback throughout the development of the framework. He is now a Software Engineer at SII Atlantique.\n* [Thomas Minier](https://github.com/Callidon) (@Callidon)\n  * Thomas developed the framework during his PhD thesis in the [Team \"Gestion des Donn\u00e9es Distribu\u00e9es\"](https://sites.google.com/site/gddlina/) (GDD) and supervise its evolution ever since. He is now a Software Engineer at SII Atlantique.\n\n",
      "technique": "Header extraction"
    }
  ],
  "citation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "* [Official W3C RDF specification](https://www.w3.org/TR/rdf11-concepts)\n* [Official W3C SPARQL specification](https://www.w3.org/TR/2013/REC-sparql11-query-20130321/)\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "RDF Graphs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8489039886549369
      ],
      "excerpt": "  object: string; // The Triple's object \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9527448194655507
      ],
      "excerpt": "     * @param  triple - Triple pattern to find \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8614911545511198
      ],
      "excerpt": "    find (triple: TripleObject, options: Object): PipelineStage<TripleObject> { / ... */ } \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8284977317134061
      ],
      "excerpt": "PREFIX ses: &lt;https://callidon.github.io/sparql-engine/search#:&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8284977317134061
      ],
      "excerpt": "PREFIX ses: &lt;https://callidon.github.io/sparql-engine/search#:&gt; \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8665716475375693
      ],
      "excerpt": "    if (rdf.termIsLiteral(rdfTerm) && rdf.literalIsNumeric(rdfTerm)) { \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Callidon/sparql-engine",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-08-12T07:56:10Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-12-11T23:44:57Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.8144288553699692,
        0.9849277700770841,
        0.8334378110984271
      ],
      "excerpt": "* Build a SPARQL query engine on top of any data storage system. \n* Supports the full features of the SPARQL syntax by implementing a single class! \n* Support for all SPARQL property Paths. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9214608555683376
      ],
      "excerpt": "* Supports full text search queries. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8662673857026567,
        0.8425732381417285
      ],
      "excerpt": "* Supports Semantic Caching, to speed up query evaluation of reccurent patterns. \n* Supports the SPARQL UPDATE protocol. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9010917899528366,
        0.8806959910863693
      ],
      "excerpt": "* Customize every step of SPARQL query processing, thanks to a modular architecture. \n* Support for SPARQL Graph Management protocol. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8986349699014355
      ],
      "excerpt": "The sparql-engine framework use the SPARQL.js library for parsing and manipulating SPARQL queries as JSON objects. For TypeScript compiltation, we use a custom package sparqljs-legacy-type for providing the types information.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490037945672047,
        0.8490037945672047
      ],
      "excerpt": "  subject: string; // The Triple's subject \n  predicate: string; // The Triple's predicate \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9718157440385786
      ],
      "excerpt": "The sparql-engine framework uses a pipeline of iterators to execute SPARQL queries. Thus, many methods encountered in this framework needs to return PipelineStage&lt;T&gt;, i.e., objects that generates items of type T in a pull-based fashion. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.899545903128547,
        0.8856519973559626,
        0.9638484961267761
      ],
      "excerpt": "* An array of elements of type T \n* A Javascript Iterator, which yields elements of type T. \n* An EventEmitter which emits elements of type T on a data event. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8450840099681813
      ],
      "excerpt": "const sourceObject = // the object to convert into a PipelineStage \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9676857538919366,
        0.9821873070585683,
        0.9102847955690307
      ],
      "excerpt": "Fore more information on how to create and manipulate the pipeline, please refers to the documentation of Pipeline and PipelineEngine. \nThe first thing to do is to implement a subclass of the Graph abstract class. A Graph represents an RDF Graph and is responsible for inserting, deleting and searching for RDF triples in the database. \nThe main method to implement is Graph.find(triple), which is used by the framework to find RDF triples matching \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9798914198221614,
        0.8102350757059756,
        0.9466877563206493
      ],
      "excerpt": "Similarly, to support the SPARQL UPDATE protocol, you have to provides a graph that implements the Graph.insert(triple) and Graph.delete(triple) methods, which insert and delete RDF triple from the graph, respectively. These methods must returns Promises, which are fulfilled when the insertion/deletion operation is completed. \nFinally, the sparql-engine framework also let your customize how Basic graph patterns (BGPs) are evaluated against \nthe RDF graph. The engine provides a default implementation based on the Graph.find method and the \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8207033558269927
      ],
      "excerpt": "     * Returns an iterator that finds RDF triples matching a triple pattern in the graph. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9086730938172719,
        0.9693233393948762
      ],
      "excerpt": " * Insert a RDF triple into the RDF Graph \n * @param  triple - RDF Triple to insert \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": " * @param  triple - RDF Triple to delete \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8016068558788977
      ],
      "excerpt": "// insert graph_b as a Named Graph \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9600853279518664,
        0.9821500554153099
      ],
      "excerpt": "The sparql-engine provides support for automatic caching of Basic Graph Pattern evaluation using the Semantic Cache algorithm. Basically, the cache will save the results of BGPs already evaluated and, when the engine wants to evaluates a BGP, it will look for the largest subset of the BGP in the cache. If one is available, it will re-use the cached results to speed up query processing. \nBy default, semantic caching is disabled. You can turn it on/off using the PlanBuilder.useCache and PlanBuilder.disableCache methods, respectively. The useCache method accepts an optional parameter, so you can provide your own implementation of the semantic cache. By defaults, it uses an in-memory LRU cache which stores up to 500MB of items for 20 minutes. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9283108930719437
      ],
      "excerpt": "// get an instance of a PlanBuilder \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490037945672047
      ],
      "excerpt": "// disable the cache \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8494754067468074,
        0.9856452671552315,
        0.9967913446580395
      ],
      "excerpt": "allowing users to execute approximate string matching on RDF Terms retrieved by SPARQL queries. \nTo accomplish this integration, it follows an approach similar to BlazeGraph and defines several magic predicates that are given special meaning, and when encountered in a SPARQL query, they are interpreted as configuration parameters for a full text search query. \nThe simplest way to integrate a full text search into a SPARQL query is to use the magic predicate ses:search inside of a SPARQL join group. In the following query, this predicate is used to search for the keywords neil and gaiman in the values binded to the ?o position of the triple pattern. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9697714417999301,
        0.9925130618144816,
        0.9089685237032932,
        0.9507607807373938,
        0.8861987969020054,
        0.9410267514374796,
        0.9143804863514268,
        0.967033679432105
      ],
      "excerpt": "In a way, full text search queries allows users to express more complex SPARQL filters that performs approximate string matching over RDF terms. \nEach result is annotated with a relevance score (how much it matches the keywords, higher is better) and a rank (they represent the descending order of relevance scores). These two values are not binded by default into the query results, but you can use magic predicates to get access to them (see below). Note that the meaning of relevance scores is specific to the implementation of the full text search. \nThe full list of magic predicates that you can use in a full text search query is: \n* ses:search defines keywords to search as a list of keywords separated by spaces. \n* ses:matchAllTerms indicates that only values that contain all of the specified search terms should be considered. \n* ses:minRelevanceand ses:maxRelevance limits the search to matches with a minimum/maximum \nrelevance score, respectively. In the default implementation, scores are floating numbers, ranging from 0.0 to 1.0 with a precision of 4 digits. \n* ses:minRank and ses:maxRank limits the search to matches with a minimum/maximum \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9550267079892488
      ],
      "excerpt": "Below is a more complete example, that use most of these keywords to customize the full text search. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9939893210507816,
        0.859659888871507
      ],
      "excerpt": "To provide a custom implementation for the full text search that is more integrated with your backend, \nyou simply need to override the fullTextSearch method of the Graph class. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9849399183334734,
        0.9360392189797136,
        0.8591578817647706
      ],
      "excerpt": "The sparql-engine framework provides a default implementation of this method, which computes relevance scores as the average ratio of keywords matched by words in the RDF terms. \nNotice that this default implementation is not suited for production usage. \nIt will performs fine for small RDF datasets, but,  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.868704282940482
      ],
      "excerpt": "The sparql-engine framework provides automatic support for evaluating federated SPARQL queries, using the SERVICE keyword. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.96520557481063
      ],
      "excerpt": "This Graph factory is used by the dataset to create new RDF Graph on-demand. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9274343409192684,
        0.8928909969645306
      ],
      "excerpt": "It takes a callback as parameter, which will be invoked to create a new graph from an IRI. \nIt's your responsibility to define the graph creation logic, depending on your application. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8900333195374727
      ],
      "excerpt": "// set the Graph factory of the dataset \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8045201807300967
      ],
      "excerpt": "  // return a new graph for the provided iri \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9171637386431568
      ],
      "excerpt": "Once the Graph factory is set, you have nothing more to do! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9267635429563987,
        0.8286828285819183,
        0.9271379043637625
      ],
      "excerpt": "The sparql-engine framework provides a supports for declaring such custom functions. \nA SPARQL value function is an extension point of the SPARQL query language that allows URI to name a function in the query processor. \nIt is defined by an IRI in a FILTER, BIND or HAVING BY expression. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.87253684402848,
        0.8283602450837848,
        0.8396002201297594
      ],
      "excerpt": "* A new RDF Term (an IRI, a Literal or a Blank Node) in RDF.js format. \n* An array of RDF Terms. \n* An Iterable or a Generator that yields RDF Terms. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9509904334111491
      ],
      "excerpt": "RDF Terms are represented using the RDF.js data model. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9793774250662488,
        0.8497360153488921
      ],
      "excerpt": "of utilities methods to create and manipulate RDF.js terms in the context of custom SPARQL functions. \nThe following shows a declaration of some simple custom functions. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8768991679556293
      ],
      "excerpt": "Then, this JSON object is passed into the constructor of your PlanBuilder. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9000756192194443
      ],
      "excerpt": "For example, here is a query that uses our newly defined custom SPARQL functions. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9587951376829474
      ],
      "excerpt": "#: this bind is not critical, but is here for illustrative purposes \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.850696113808115
      ],
      "excerpt": "GROUP BY ?length \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8406985140351189,
        0.8633877549427185,
        0.9857636939347294,
        0.8786946285056783
      ],
      "excerpt": "The class PipelineEngine (and its subclasses) is the main component used by sparql-engine to evaluate all SPARQL operations. It defines basic operations (map, filter, etc) that can be used \nto manipulate intermediate results and evaluate SPARQL queries. \nBy default, the framework uses an implementation of PipelineEngine based on rxjs, to implements a SPARQL query execution plan as a pipeline of iterators. \nHowever, you are able to switch to others implementations of PipelineEngine, using Pipeline.setInstance. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8062620234136406
      ],
      "excerpt": "// add this before creating a new plan builder \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9366473484346798,
        0.9398236351802857
      ],
      "excerpt": "* RxjsPipeline, based on rxjs, which provides a pure pipeline approach. This approach is selected by default when loading the framework. \n* VectorPipeline, which materializes all intermediate results at each pipeline computation step. This approach is more efficient CPU-wise, but also consumes a lot more memory. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9622902158679255,
        0.9738737526359303
      ],
      "excerpt": "Internally, it defines stages builders to generates operators for executing all types of SPARQL operations. \nFor example, the OrderByStageBuilder is invoked when the PlanBuilder needs to evaluate an ORDER BY modifier. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9164966617723275
      ],
      "excerpt": "You will find below a reference table of all stage builders used by sparql-engine to evaluate SPARQL queries. Please see the API documentation for more details. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "\ud83d\ude82 A framework for building SPARQL query engines in Javascript/Typescript",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "To generate the documentation in the `docs` director:\n```bash\ngit clone https://github.com/Callidon/sparql-engine.git\ncd sparql-engine\nyarn install\nnpm run doc\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Callidon/sparql-engine/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 10,
      "date": "Mon, 20 Dec 2021 16:40:49 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Callidon/sparql-engine/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "Callidon/sparql-engine",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        1
      ],
      "excerpt": "```bash\nnpm install --save sparql-engine\n```\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.9314065180439145
      ],
      "excerpt": "Thus, if you are working with sparql-engine in TypeScript, you will need to install the sparqljs-legacy-type package. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8285978484692095
      ],
      "excerpt": "To create a new PipelineStage&lt;T&gt; from one of these objects, you can use the following code: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8231082134576791
      ],
      "excerpt": "Once you have your subclass of Graph ready, you need to build a collection of RDF Graphs, called a RDF Dataset. A default implementation, HashMapDataset, is made available by the framework, but you can build your own by subclassing Dataset. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8841419308466805
      ],
      "excerpt": "// activate the cache \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8600573192699734
      ],
      "excerpt": "Now, you can execute SPARQL queries with your custom functions! \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8053804429658877
      ],
      "excerpt": "PREFIX foaf: http://xmlns.com/foaf/0.1/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8661176197453521
      ],
      "excerpt": "  ?s foaf:name ?name . \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9084076421563871
      ],
      "excerpt": "Then, you need to configure your plan builder to use them, with the use function. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8304050563464879
      ],
      "excerpt": "// Now, execute SPARQL queries as before with your PlanBuilder \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8378080875653302
      ],
      "excerpt": "| OPTIONAL | OptionalStageBuilder | SPARQL_OPERATION.OPTIONAL | \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8064454270243467
      ],
      "excerpt": "Advanced Usage \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "  ?o ses:matchAllTerms \u201ctrue\u201d . \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8846353529890092
      ],
      "excerpt": "    const result = rdfTerm.value.split(\"\").reverse().join(\"\") === rdfTerm.value \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8731562459058029,
        0.8102780086823556
      ],
      "excerpt": "      const jsValue = rdf.asJS(rdfTerm.value, rdfTerm.datatype.value) \n      const result = jsValue % 2 === 0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8421074476017179
      ],
      "excerpt": "  ?s foaf:name ?name . \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/Callidon/sparql-engine/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "TypeScript",
      "JavaScript"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "MIT License",
      "url": "https://api.github.com/licenses/mit"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'MIT License\\n\\nCopyright (c) 2018-2020 Thomas Minier\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "sparql-engine",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "sparql-engine",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "Callidon",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/Callidon/sparql-engine/blob/master/README.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "Callidon",
        "body": "## What's Changed\r\n* Bump path-parse from 1.0.6 to 1.0.7 by @dependabot in https://github.com/Callidon/sparql-engine/pull/68\r\n\r\n\r\n**Full Changelog**: https://github.com/Callidon/sparql-engine/compare/v0.8.1...v0.8.2",
        "dateCreated": "2021-10-12T11:58:36Z",
        "datePublished": "2021-10-12T11:59:27Z",
        "html_url": "https://github.com/Callidon/sparql-engine/releases/tag/v0.8.2",
        "name": "Fix invalid .npmignore",
        "tag_name": "v0.8.2",
        "tarball_url": "https://api.github.com/repos/Callidon/sparql-engine/tarball/v0.8.2",
        "url": "https://api.github.com/repos/Callidon/sparql-engine/releases/51204550",
        "zipball_url": "https://api.github.com/repos/Callidon/sparql-engine/zipball/v0.8.2"
      },
      {
        "authorType": "User",
        "author_name": "Callidon",
        "body": "This release introduces optimizations & bug fixes for the evaluation of property paths\r\n\r\n## What's Changed\r\n* fix: Resolve `this` correctly in levelgraph adapter example. by @gavinpc-mindgrub in https://github.com/Callidon/sparql-engine/pull/61\r\n* Bump lodash from 4.17.20 to 4.17.21 by @dependabot in https://github.com/Callidon/sparql-engine/pull/64\r\n* Bump hosted-git-info from 2.8.8 to 2.8.9 by @dependabot in https://github.com/Callidon/sparql-engine/pull/65\r\n* fix: Property paths' object is using wrong binding by @sroze in https://github.com/Callidon/sparql-engine/pull/66\r\n* Bump handlebars from 4.7.6 to 4.7.7 by @dependabot in https://github.com/Callidon/sparql-engine/pull/63\r\n* perf: When property path is bound both sides, use both bindings by @sroze in https://github.com/Callidon/sparql-engine/pull/67\r\n\r\n## New Contributors\r\n* @gavinpc-mindgrub made their first contribution in https://github.com/Callidon/sparql-engine/pull/61\r\n* @sroze made their first contribution in https://github.com/Callidon/sparql-engine/pull/66\r\n\r\n**Full Changelog**: https://github.com/Callidon/sparql-engine/compare/v0.8.0...v0.8.1",
        "dateCreated": "2021-07-07T18:11:31Z",
        "datePublished": "2021-07-07T18:16:19Z",
        "html_url": "https://github.com/Callidon/sparql-engine/releases/tag/v0.8.1",
        "name": "Optimization & bug fixes for property paths",
        "tag_name": "v0.8.1",
        "tarball_url": "https://api.github.com/repos/Callidon/sparql-engine/tarball/v0.8.1",
        "url": "https://api.github.com/repos/Callidon/sparql-engine/releases/45858291",
        "zipball_url": "https://api.github.com/repos/Callidon/sparql-engine/zipball/v0.8.1"
      },
      {
        "authorType": "User",
        "author_name": "Callidon",
        "body": "This release introduces the following features:\r\n* Added complete support for [SPARQL Graph management](https://www.w3.org/TR/2013/REC-sparql11-update-20130321/#graphManagement) with [ADD](https://www.w3.org/TR/2013/REC-sparql11-update-20130321/#drop) and [DROP](https://www.w3.org/TR/2013/REC-sparql11-update-20130321/#drop) queries.\r\n* Added formatters for formatting SPARQL results to [W3C XML](https://www.w3.org/TR/2013/REC-rdf-sparql-XMLres-20130321/), [W3C JSON](https://www.w3.org/TR/2013/REC-sparql11-results-json-20130321/), [W3C CSV and W3C TSV](https://www.w3.org/TR/2013/REC-sparql11-results-csv-tsv-20130321/).\r\n\r\n## What's Changed\r\n* Bump codecov from 3.6.5 to 3.7.1 by @dependabot in https://github.com/Callidon/sparql-engine/pull/51\r\n* Bump lodash from 4.17.15 to 4.17.19 by @dependabot in https://github.com/Callidon/sparql-engine/pull/50\r\n* Bump jquery from 3.4.1 to 3.5.0 by @dependabot in https://github.com/Callidon/sparql-engine/pull/49\r\n* Bump node-fetch from 2.6.0 to 2.6.1 by @dependabot in https://github.com/Callidon/sparql-engine/pull/52\r\n* Modernize TypeScript code by @Callidon in https://github.com/Callidon/sparql-engine/pull/53\r\n* Add support for formatting JSON by @Callidon in https://github.com/Callidon/sparql-engine/pull/55\r\n* Add support for formatting query results to CSV and TSV by @Callidon in https://github.com/Callidon/sparql-engine/pull/56\r\n* Add support for CREATE and DROP queries by @Callidon in https://github.com/Callidon/sparql-engine/pull/54\r\n\r\n\r\n**Full Changelog**: https://github.com/Callidon/sparql-engine/compare/v0.7.6...v0.8.0",
        "dateCreated": "2020-11-11T11:21:56Z",
        "datePublished": "2020-11-15T07:44:48Z",
        "html_url": "https://github.com/Callidon/sparql-engine/releases/tag/v0.8.0",
        "name": "SPARQL Graph management and W3C results formatters",
        "tag_name": "v0.8.0",
        "tarball_url": "https://api.github.com/repos/Callidon/sparql-engine/tarball/v0.8.0",
        "url": "https://api.github.com/repos/Callidon/sparql-engine/releases/33969146",
        "zipball_url": "https://api.github.com/repos/Callidon/sparql-engine/zipball/v0.8.0"
      },
      {
        "authorType": "User",
        "author_name": "Callidon",
        "body": "This release introduces support for **Full-text search SPARQL queries**, allowing users to execute [approximate string matching](https://en.wikipedia.org/wiki/Approximate_string_matching) on RDF Terms retrieved by SPARQL queries. To accomplish this integration, it follows an approach similar to [BlazeGraph](https://wiki.blazegraph.com/wiki/index.php/FullTextSearch) and defines several magic predicates that are given special meaning, and when encountered in a SPARQL query, they are interpreted as configuration parameters for a full text search query.\r\n\r\n## What's Changed\r\n* Add full text search feature by @Callidon in https://github.com/Callidon/sparql-engine/pull/38\r\n\r\n\r\n**Full Changelog**: https://github.com/Callidon/sparql-engine/compare/v0.5.9...v0.6.0",
        "dateCreated": "2020-01-22T09:49:46Z",
        "datePublished": "2020-02-17T12:55:11Z",
        "html_url": "https://github.com/Callidon/sparql-engine/releases/tag/v0.6.0",
        "name": "Full Text search queries",
        "tag_name": "v0.6.0",
        "tarball_url": "https://api.github.com/repos/Callidon/sparql-engine/tarball/v0.6.0",
        "url": "https://api.github.com/repos/Callidon/sparql-engine/releases/23731708",
        "zipball_url": "https://api.github.com/repos/Callidon/sparql-engine/zipball/v0.6.0"
      },
      {
        "authorType": "User",
        "author_name": "Callidon",
        "body": "This release introduces the following features:\r\n* Add automatic caching of Basic Graph Pattern evaluation using the [Semantic Cache algorithm](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1161590). Basically, the cache will save the results of BGPs already evaluated and, when the engine wants to evaluate a BGP, it will look for the largest subset of the BGP in the cache. If one is available, it will re-use the cached results to speed up query processing.\r\n* Add native support for [the bound join algorithm](http://achill.informatik.uni-freiburg.de/content/team/schmidt/docs/iswc11_fedx.pdf). It will be automatically used to join with a BGP if the RDF graph supports the evaluation of UNION, using the `Graph.evalUnion` method.\r\n* Reworked the SPARQL expressions systems. I now uses the [RDFJ.js](http://rdf.js.org/data-model-spec/) data model to represent RDF terms. Thus, it allows for the implementation of missing SPARQL expressions, like `replace` or `bnode`.\r\n\r\n## What's Changed\r\n* New Implementation of SPARQL expressions by @Callidon in https://github.com/Callidon/sparql-engine/pull/39\r\n* Enable caching of Basic Graph Patterns by @Callidon in https://github.com/Callidon/sparql-engine/pull/40\r\n\r\n\r\n**Full Changelog**: https://github.com/Callidon/sparql-engine/compare/v0.6.0...v0.7.0",
        "dateCreated": "2020-02-17T12:44:20Z",
        "datePublished": "2020-02-17T12:52:56Z",
        "html_url": "https://github.com/Callidon/sparql-engine/releases/tag/v0.7.0",
        "name": "Semantic Cache, native Bound joins and reworked SPARQL expressions",
        "tag_name": "v0.7.0",
        "tarball_url": "https://api.github.com/repos/Callidon/sparql-engine/tarball/v0.7.0",
        "url": "https://api.github.com/repos/Callidon/sparql-engine/releases/23731650",
        "zipball_url": "https://api.github.com/repos/Callidon/sparql-engine/zipball/v0.7.0"
      },
      {
        "authorType": "User",
        "author_name": "Callidon",
        "body": "Added support for evaluation of [all SPARQL Property Paths](https://www.w3.org/TR/sparql11-query/#propertypaths), with corresponding W3C tests.\r\n\r\nThis support was developed by Arthur Trottier, Charlotte Cogan and Julien Aimonier-Davat, Master students at the Unversity of Nantes.\r\n\r\nThis implementation is compliant with the benchmark from *Adrian Skubella, Daniel Janke and Steffen Staab \"BeSEPPI: Semantic-Based Benchmarking of Property Path Implementations\"*, published in the proceedings of the 16th extended Semantic Web Conference (ESWC 2019).\r\n\r\n## What's Changed\r\n* Fix/18 by @dwhitney in https://github.com/Callidon/sparql-engine/pull/19\r\n* Externalize pipeline architecture by @Callidon in https://github.com/Callidon/sparql-engine/pull/20\r\n* Property paths by @Lastshot97 in https://github.com/Callidon/sparql-engine/pull/23\r\n\r\n## New Contributors\r\n* @Lastshot97 made their first contribution in https://github.com/Callidon/sparql-engine/pull/23\r\n\r\n**Full Changelog**: https://github.com/Callidon/sparql-engine/compare/v0.4.0...v0.5.0",
        "dateCreated": "2019-05-12T21:28:59Z",
        "datePublished": "2019-05-12T21:59:36Z",
        "html_url": "https://github.com/Callidon/sparql-engine/releases/tag/v0.5.0",
        "name": "Support for SPARQL Property Paths",
        "tag_name": "v0.5.0",
        "tarball_url": "https://api.github.com/repos/Callidon/sparql-engine/tarball/v0.5.0",
        "url": "https://api.github.com/repos/Callidon/sparql-engine/releases/17301827",
        "zipball_url": "https://api.github.com/repos/Callidon/sparql-engine/zipball/v0.5.0"
      },
      {
        "authorType": "User",
        "author_name": "Callidon",
        "body": "* Add the support for declaring custom SPARQL functions, thanks to @dwhitney pull request #13 \r\n* Rework of the RDF terms manipulation API, to ease the development of SPARQL functions\r\n\r\n## What's Changed\r\n* protect access to value by @JuniperChicago in https://github.com/Callidon/sparql-engine/pull/11\r\n* Support for more advanced join algorithms by @Callidon in https://github.com/Callidon/sparql-engine/pull/12\r\n* adds support for custom functions by @dwhitney in https://github.com/Callidon/sparql-engine/pull/13\r\n* Ease creation of custom SPARQL functions by @Callidon in https://github.com/Callidon/sparql-engine/pull/14\r\n\r\n## New Contributors\r\n* @JuniperChicago made their first contribution in https://github.com/Callidon/sparql-engine/pull/11\r\n\r\n**Full Changelog**: https://github.com/Callidon/sparql-engine/compare/v0.3.2...v0.4.0",
        "dateCreated": "2019-02-28T14:44:13Z",
        "datePublished": "2019-02-28T14:45:55Z",
        "html_url": "https://github.com/Callidon/sparql-engine/releases/tag/v0.4.0",
        "name": "Custom SPARQL functions",
        "tag_name": "v0.4.0",
        "tarball_url": "https://api.github.com/repos/Callidon/sparql-engine/tarball/v0.4.0",
        "url": "https://api.github.com/repos/Callidon/sparql-engine/releases/15835119",
        "zipball_url": "https://api.github.com/repos/Callidon/sparql-engine/zipball/v0.4.0"
      },
      {
        "authorType": "User",
        "author_name": "Callidon",
        "body": "Second release, with the following features:\r\n* Full SPARQL 1.0 support\r\n* Partial SPARQL 1.1 support:\r\n  * SPARQL SERVICE\r\n  * SPARQL subqueries\r\n  * SPARQL (NOT) EXISTS & MINUS filters\r\n  * SPARQL UPDATE (INSERT, DELETE, CLEAR, MOVE and COPY)\r\n\r\nMissing features:\r\n* SPARQL property paths\r\n* SPARQL Graph Managment protocol (CREATE, DROP, etc)\r\n\r\n**Full Changelog**: https://github.com/Callidon/sparql-engine/compare/v0.2.0...v0.2.1",
        "dateCreated": "2018-09-07T06:57:25Z",
        "datePublished": "2018-09-19T12:54:25Z",
        "html_url": "https://github.com/Callidon/sparql-engine/releases/tag/v0.2.1",
        "name": "SPARQL UPDATE support",
        "tag_name": "v0.2.1",
        "tarball_url": "https://api.github.com/repos/Callidon/sparql-engine/tarball/v0.2.1",
        "url": "https://api.github.com/repos/Callidon/sparql-engine/releases/12979375",
        "zipball_url": "https://api.github.com/repos/Callidon/sparql-engine/zipball/v0.2.1"
      },
      {
        "authorType": "User",
        "author_name": "Callidon",
        "body": "First release, with the following features:\r\n* Full SPARQL 1.0 support\r\n* Partial SPARQL 1.1 support:\r\n  * SPARQL SERVICE\r\n  * SPARQL subqueries\r\n  * SPARQL UPDATE (INSERT, DELETE, CLEAR, MOVE and COPY)\r\n\r\nMissing features:\r\n* SPARQL property paths\r\n* SPARQL Graph Managment protocol (CREATE, DROP, etc)\r\n* SPARQL (NOT) EXISTS & MINUS filters",
        "dateCreated": "2018-09-01T08:09:25Z",
        "datePublished": "2018-09-01T08:13:19Z",
        "html_url": "https://github.com/Callidon/sparql-engine/releases/tag/v0.1.0",
        "name": "SPARQL 1.0 support, partial SPARQL 1.1 support",
        "tag_name": "v0.1.0",
        "tarball_url": "https://api.github.com/repos/Callidon/sparql-engine/tarball/v0.1.0",
        "url": "https://api.github.com/repos/Callidon/sparql-engine/releases/12685727",
        "zipball_url": "https://api.github.com/repos/Callidon/sparql-engine/zipball/v0.1.0"
      }
    ],
    "technique": "GitHub API"
  },
  "run": [
    {
      "confidence": [
        1
      ],
      "excerpt": "Finally, to run a SPARQL query on your RDF dataset, you need to use the `PlanBuilder` class. It is responsible for parsing SPARQL queries and building a pipeline of iterators to evaluate them.\n\n```javascript\n  const { PlanBuilder } = require('sparql-engine')\n\n  // Get the name of all people in the Default Graph\n  const query = `\n    PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n    SELECT ?name\n    WHERE {\n      ?s a foaf:Person .\n      ?s foaf:name ?name .\n    }`\n\n  // Creates a plan builder for the RDF dataset\n  const builder = new PlanBuilder(dataset)\n\n  // Get an iterator to evaluate the query\n  const iterator = builder.build(query)\n\n  // Read results\n  iterator.subscribe(\n    bindings => console.log(bindings),\n    err => console.error(err),\n    () => console.log('Query evaluation complete!')\n  )\n```\n\n",
      "technique": "Header extraction"
    }
  ],
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 57,
      "date": "Mon, 20 Dec 2021 16:40:49 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "rdf",
      "sparql",
      "query-engine",
      "framework"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The `sparql-engine` framework allow you to build a custom SPARQL query engine on top of any data storage system.\n\nIn short, to support SPARQL queries on top of your data storage system, you need to:\n* [Implements a subclass of `Graph`](#rdf-graphs), which provides access to the data storage system.\n* Gather all your Graphs as a `Dataset` (using your own implementation or [the default one](#rdf-datasets)).\n* [Instantiate a `PlanBuilder`](#running-a-sparql-query) and use it to execute SPARQL queries.\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        1
      ],
      "excerpt": "As a starting point, we provide you with two examples of integration:\n* With [N3.js](https://github.com/rdfjs/N3.js), available [here](https://github.com/Callidon/sparql-engine/tree/master/examples/n3.js).\n* With [LevelGraph](https://github.com/levelgraph/levelgraph), available [here](https://github.com/Callidon/sparql-engine/tree/master/examples/levelgraph.js).\n\n",
      "technique": "Header extraction"
    }
  ]
}
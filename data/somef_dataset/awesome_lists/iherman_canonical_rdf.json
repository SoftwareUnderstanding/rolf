{
  "citation": [
    {
      "confidence": [
        0.9992793881918204,
        0.9907893668975284
      ],
      "excerpt": "A. Hogan, \u201cSkolemising Blank Nodes while Preserving Isomorphism,\u201d, WWW2015 conference proceedings, 2015, pp. 430\u2013440. See PDF version. \nA. Hogan, \u201cCanonical Forms for Isomorphic and Equivalent RDF Graphs: Algorithms for Leaning and Labelling Blank Nodes,\u201d ACM Trans. Web, vol. 11, no. 4, pp. 22:1\u201322:62, Jul. 2017. See PDF version. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8325427368520121
      ],
      "excerpt": "The article says: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8325427368520121
      ],
      "excerpt": "The article says: \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/iherman/canonical_rdf",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2018-05-24T14:12:22Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-09-28T07:53:06Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        0.9842640778213556
      ],
      "excerpt": "Aidan Hogan has published two papers on one of the fundamental building blocks for the RDF infrastructure: calculating a canonical RDF graph. A canonical graph allows, for example, to sign an RDF graph, needed for various security, consistency, provenance, etc., considerations in applications like verifiable claims, usage of linked data on block chain, consistency proof for ontologies, publication of data, etc. The two papers are: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9897678784911547,
        0.9991614810901448,
        0.9965654700279444,
        0.992157410391652,
        0.9799608425988451,
        0.9575702468150459,
        0.9121610522475411,
        0.9905440744523771,
        0.8894686569052801,
        0.9827981347534579
      ],
      "excerpt": "(The second paper supersedes the first insofar that it slightly simplifies the relevant algorithm, although it also contains much more than what is relevant for this repository. Note also that the URL above for the second paper refers to the author\u2019s copy on his Web site, which takes care of some minor bugs that surfaced since the publication. That version was used for this implementation.) \nThis repository contains a proof-of-concept implementation in node.js of what is referred to as the \u201ciso-canonical algorithm\u201d described in the papers, using the N3.js library for the representation of quads. It is fully based on Aidan\u2019s algorithm, except for one tiny extension: while Aidan describes the canonicalization of RDF graphs, this implementations deals with RDF datasets (a.k.a. named graphs). The description of the changes are described below. \nThe reason for doing this implementation was to explore whether it is possible to define a stable specification (e.g., W3C Recommendation) on the subject starting with Aidan\u2019s algorithm and, if yes, what is missing in terms of a specification (see the separate section below for more details of those). The implementation does not aim, or pretend, to be of a production quality, it has not been profiled for speed, etc. It shows, however, that the algorithm can be implemented without any further mathematical work based solely on the paper. I.e., Aidan\u2019s algorithm is indeed one of the viable approaches if such a specification is to be produced. \n(Note that Aidan does have an implementation of his own algorithm in Java, which is also on GitHub. This Javascript implementation is completely independent of that one.) \nA matter of terminology: in this paper (and this implementation) a canonical version can(G) of the Graph/Dataset G is isomorphic to G (i.e., can(G)\u2245G), and if H\u2245G then can(H)=can(G). In other words, it is an isomorphic graph where the blank node renaming bijection is deterministic. \nThe changes/additions are as follows (each of those changes are relevant only if there is a separate graph identifier, i.e., if we have a quad instead of a triple. If this is not the case, the algorithm falls back to the original). \nIn algorithm 1, at step 13 and 16, respectively: the hashTuple function gets a fourth argument, before the '+' and '-' characters, respectively, referring to the hash value of the graph identifier; \nIn algorithm 1, after step 17, a similar branch is added for the case of a (s,p,o,b) quad (i.e., if the graph identifier is a blank node); the hashTuple in that branch hashes the full (s,p,o) triple, plus the '.' character. \nThe lexicographic comparison of quads for, e.g., comparing graphs/datasets, take into account the possible graph id, too. \nThe article defines and proves the mathematical algorithm; however, for a precise specification, some further details must be properly specified to ensure interoperable implementations. This is not a shortcoming of the paper; it only means that some of the functions, details, etc., that are only characterized by their behavior, should have a more precise definition. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9541568202723675,
        0.9700290171099126,
        0.9897587908101632,
        0.8853113428345126
      ],
      "excerpt": "Aidan\u2019s algorithm specifies can(G), i.e., the deterministic mapping of the blank nodes in the Graph/Dataset. A full specification for signing RDF Datasets would also include some fairly routine engineering steps: \nDefine the hash of an RDF Dataset G. One approach could be to generate the Canonical N-Quads representation of can(G), lexicographically order it, and calculate the hash of ordered quads. Another possibility would be to hash each individual triples/quads of can(G) separately, and then use the hashBag function (see below), applied to all the hashes, to generate the hash of the Graph/Dataset. \nDefine the signature of G. The usual approach is to encrypt, by some standard means, the hash of G. \nDefine a standard vocabulary for adding the metadata of the signature to the result (public key, hash function used, etc.). An adaptation of the XML Signature specification would probably suffice. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9081754035122636
      ],
      "excerpt": "This implementation uses a Buffer with all zero entries. Essentially, this is a zero number. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9873629772283964
      ],
      "excerpt": "This implementation uses the compare function of Buffer in node.js for the representation of a hash. This corresponds (I believe) to the comparison of the values as large numbers. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9656867303235074
      ],
      "excerpt": "This implementation uses the OpenSSL (i.e., node.js\u2019s crypto package) facility to add new values before generating the digest. I am not sure what this means exactly specification-wise but, probably, a concatenation of the values or Buffer instances before generating the digest. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9826327770214585,
        0.9708995986333693,
        0.8930924328638679
      ],
      "excerpt": "Note that the quality of this function is crucial because, in some cases, hash collision can occur that may create problems. The experimentation of Aidan but also the experience with this implementation shows that such collision do occur (albeit in rare and artificial cases); this was the case when, for example, the XOR values of the Buffer entries were used. \nAn earlier version of this implementation used a modulo 255 sum of the Buffer entries in the node.js representation of the hashes. \nHowever, the current implementation takes a somewhat more complex change of the algorithm, essentially implementing: \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8340779164555256,
        0.9417542667793715
      ],
      "excerpt": "A new object, hash_bag is initialized before line 12; this object stores, for each b, an array consisting (initially) of the single value of hash<sub>i</sub>[b] \nLines 14 and 17 are replaced by adding the value of c to the corresponding array in hash_bag for the key b \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9858099390500555
      ],
      "excerpt": "The algorithm is based on the ability to have a total ordering of graphs/datasets; indeed, the more complex step is based on calculating a minimum of the candidate graphs/datasets. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "Proof-of-concept implementation of Aidan Hogan's RDF canonicalization algorithm in node.js",
      "technique": "GitHub API"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/iherman/canonical_rdf/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 0,
      "date": "Tue, 21 Dec 2021 01:15:51 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/iherman/canonical_rdf/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "iherman/canonical_rdf",
    "technique": "GitHub API"
  },
  "identifier": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://zenodo.org/badge/latestdoi/134724887",
      "technique": "Regular expression"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/iherman/canonical_rdf/issues{/number}",
    "technique": "GitHub API"
  },
  "languages": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "JavaScript"
    ],
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Other",
      "url": "https://raw.githubusercontent.com/iherman/canonical_rdf/master/LICENSE"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'W3C SOFTWARE NOTICE AND LICENSE\\n\\nCopyright (c) 2018 W3C\\xc2\\xae (MIT, ERCIM, Keio, Beihang)\\n\\nLicense\\n\\nBy obtaining and/or copying this work, you (the licensee) agree that you have read, understood, and will comply\\nwith the following terms and conditions.\\n\\nPermission to copy, modify, and distribute this work, with or without modification, for any purpose and without fee\\nor royalty is hereby granted, provided that you include the following on ALL copies of the work or portions thereof,\\nincluding modifications:\\n\\n    - The full text of this NOTICE in a location viewable to users of the redistributed or derivative work.\\n    - Any pre-existing intellectual property disclaimers, notices, or terms and conditions. If none exist,\\n    the W3C Software and Document Short Notice should be included, see\\n    https://www.w3.org/Consortium/Legal/2015/copyright-software-short-notice.html\\n    - Notice of any changes or modifications, through a copyright statement on the new code or document such as\\n    \"This software or document includes material copied from or derived from [title and URI of the W3C document].\\n    Copyright \\xc2\\xa9 [YEAR] W3C\\xc2\\xae (MIT, ERCIM, Keio, Beihang).\"\\n\\nDisclaimers\\n\\nTHIS WORK IS PROVIDED \"AS IS,\" AND COPYRIGHT HOLDERS MAKE NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED,\\nINCLUDING BUT NOT LIMITED TO, WARRANTIES OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF\\nTHE SOFTWARE OR DOCUMENT WILL NOT INFRINGE ANY THIRD PARTY PATENTS, COPYRIGHTS, TRADEMARKS OR OTHER RIGHTS.\\n\\nCOPYRIGHT HOLDERS WILL NOT BE LIABLE FOR ANY DIRECT, INDIRECT, SPECIAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF ANY\\nUSE OF THE SOFTWARE OR DOCUMENT.\\n\\nThe name and trademarks of copyright holders may NOT be used in advertising or publicity pertaining to the work\\nwithout specific, written prior permission. Title to copyright in this work will at all times remain with copyright\\nholders.'",
    "technique": "File Exploration"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Proof-of-concept implementation of Aidan Hogan\u2019s iso-canonical algorithm for RDF graph canonicalization",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "canonical_rdf",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "iherman",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "User",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/iherman/canonical_rdf/blob/master/Readme.md",
    "technique": "GitHub API"
  },
  "releases": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      {
        "authorType": "User",
        "author_name": "iherman",
        "body": "",
        "dateCreated": "2019-05-22T15:22:38Z",
        "datePublished": "2019-05-22T15:26:11Z",
        "html_url": "https://github.com/iherman/canonical_rdf/releases/tag/v1.0",
        "name": "Stable version, with DOI on readme",
        "tag_name": "v1.0",
        "tarball_url": "https://api.github.com/repos/iherman/canonical_rdf/tarball/v1.0",
        "url": "https://api.github.com/repos/iherman/canonical_rdf/releases/17519758",
        "zipball_url": "https://api.github.com/repos/iherman/canonical_rdf/zipball/v1.0"
      },
      {
        "authorType": "User",
        "author_name": "iherman",
        "body": "",
        "dateCreated": "2019-01-17T10:23:30Z",
        "datePublished": "2019-05-22T15:20:16Z",
        "html_url": "https://github.com/iherman/canonical_rdf/releases/tag/citable_zenodo",
        "name": "",
        "tag_name": "citable_zenodo",
        "tarball_url": "https://api.github.com/repos/iherman/canonical_rdf/tarball/citable_zenodo",
        "url": "https://api.github.com/repos/iherman/canonical_rdf/releases/17519583",
        "zipball_url": "https://api.github.com/repos/iherman/canonical_rdf/zipball/citable_zenodo"
      },
      {
        "authorType": "User",
        "author_name": "iherman",
        "body": "",
        "dateCreated": "2019-01-17T10:23:30Z",
        "datePublished": "2019-05-22T15:19:10Z",
        "html_url": "https://github.com/iherman/canonical_rdf/releases/tag/citable",
        "name": "Stable version, citable via zenodo",
        "tag_name": "citable",
        "tarball_url": "https://api.github.com/repos/iherman/canonical_rdf/tarball/citable",
        "url": "https://api.github.com/repos/iherman/canonical_rdf/releases/17519551",
        "zipball_url": "https://api.github.com/repos/iherman/canonical_rdf/zipball/citable"
      },
      {
        "authorType": "User",
        "author_name": "iherman",
        "body": "",
        "dateCreated": "2018-05-28T10:43:34Z",
        "datePublished": "2018-05-30T10:32:07Z",
        "html_url": "https://github.com/iherman/canonical_rdf/releases/tag/original",
        "name": "Original version, following exactly the paper's algorithm",
        "tag_name": "original",
        "tarball_url": "https://api.github.com/repos/iherman/canonical_rdf/tarball/original",
        "url": "https://api.github.com/repos/iherman/canonical_rdf/releases/11237247",
        "zipball_url": "https://api.github.com/repos/iherman/canonical_rdf/zipball/original"
      }
    ],
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 5,
      "date": "Tue, 21 Dec 2021 01:15:51 GMT"
    },
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "The paper does not specify which hash function to use, just that it should be a perfect one. It also contains some measurements and calculation on which functions are worth using. Note that we don't need a cryptographically strong hash function; it is only used to separate blank nodes. Higher level algorithms, i.e., producing the final and public signature of the graph may choose stronger algorithms if needed.\n\n_This implementation uses md5._ The only reason is that the resulting values are relatively short which makes it easier to debug. A final specification should probably use SHA256. (Note that the article refers to SHA128 as being probably enough; however, the OpenSSL library, at least as used in node.js, does not seem to offer this function hence the choice for SAH256 as being probably more widely deployed.) The `crypto` package in node.js (and, consequently, this implementation) stores the values of hashes as a `Buffer` instance of unsigned 8 bit integers; the number of such integers depend on the specific hash function used.\n\n",
      "technique": "Header extraction"
    }
  ]
}
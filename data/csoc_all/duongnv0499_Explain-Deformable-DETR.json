{
    "syntactic": [
        "gpu",
        "cuda",
        "object detection",
        "inference",
        "linux",
        "image features",
        "gpus",
        "convolutional neural networks"
    ],
    "semantic": [
        "gpu",
        "cuda",
        "object detection",
        "inference",
        "linux",
        "image features",
        "gpus",
        "probabilistic inference"
    ],
    "union": [
        "gpu",
        "cuda",
        "object detection",
        "inference",
        "linux",
        "image features",
        "gpus",
        "convolutional neural networks",
        "probabilistic inference"
    ],
    "enhanced": [
        "program processors",
        "parallel programming",
        "graphics processing unit",
        "object recognition",
        "inference engines",
        "operating systems",
        "image retrieval",
        "imaging systems",
        "neural networks",
        "bayesian methods",
        "probability distributions",
        "parallel processing systems",
        "microprocessor chips",
        "parallel algorithms",
        "parallel architectures",
        "computer programming languages",
        "pattern recognition",
        "image segmentation",
        "artificial intelligence",
        "computer science",
        "image enhancement",
        "database systems",
        "information retrieval",
        "image reconstruction",
        "machine learning",
        "probability",
        "distributed systems",
        "computer hardware",
        "computer programming",
        "image analysis",
        "image processing",
        "computer systems",
        "mathematics",
        "distributed computer systems",
        "computer imaging and vision"
    ],
    "explanation": {
        "object detection": [
            "object detection"
        ],
        "image features": [
            "image feature",
            "image"
        ],
        "convolutional neural networks": [
            "cnn"
        ],
        "inference": [
            "size inference",
            "inference speed",
            "inference batch",
            "refer inference",
            "inference"
        ],
        "gpu": [
            "gpu",
            "cuda",
            "nvidia",
            "gpus"
        ],
        "linux": [
            "requirement linux",
            "linux",
            "linux cuda"
        ],
        "cuda": [
            "gpu",
            "gpus",
            "cuda",
            "nvidia"
        ],
        "gpus": [
            "gpu",
            "gpus"
        ],
        "probabilistic inference": [
            "size inference",
            "inference speed",
            "inference",
            "refer inference",
            "inference batch"
        ],
        "program processors": [
            "gpu",
            "cuda",
            "nvidia",
            "gpus"
        ],
        "parallel programming": [
            "gpu",
            "gpus",
            "cuda",
            "nvidia"
        ],
        "graphics processing unit": [
            "gpu",
            "gpus",
            "cuda",
            "nvidia"
        ],
        "object recognition": [
            "image feature",
            "object detection",
            "image"
        ],
        "inference engines": [
            "size inference",
            "inference speed",
            "inference",
            "inference batch",
            "refer inference"
        ],
        "operating systems": [
            "requirement linux",
            "linux",
            "linux cuda"
        ],
        "image retrieval": [
            "image feature",
            "image"
        ],
        "imaging systems": [
            "image feature",
            "image"
        ],
        "neural networks": [
            "cnn"
        ],
        "bayesian methods": [
            "size inference",
            "inference speed",
            "inference",
            "refer inference",
            "inference batch"
        ],
        "probability distributions": [
            "size inference",
            "inference speed",
            "inference",
            "refer inference",
            "inference batch"
        ],
        "parallel processing systems": [
            "gpu",
            "cuda",
            "nvidia",
            "gpus"
        ],
        "microprocessor chips": [
            "gpu",
            "cuda",
            "nvidia",
            "gpus"
        ],
        "parallel algorithms": [
            "gpu",
            "gpus",
            "cuda",
            "nvidia"
        ],
        "parallel architectures": [
            "gpu",
            "gpus",
            "cuda",
            "nvidia"
        ],
        "computer programming languages": [
            "gpu",
            "gpus",
            "cuda",
            "nvidia"
        ],
        "pattern recognition": [
            "image feature",
            "image",
            "object detection"
        ],
        "image segmentation": [
            "image feature",
            "image",
            "object detection"
        ],
        "artificial intelligence": [
            "size inference",
            "inference speed",
            "image feature",
            "object detection",
            "inference batch",
            "inference",
            "image",
            "refer inference",
            "cnn"
        ],
        "computer science": [
            "image feature",
            "inference speed",
            "nvidia",
            "inference",
            "inference batch",
            "requirement linux",
            "cnn",
            "gpu",
            "size inference",
            "linux cuda",
            "cuda",
            "object detection",
            "linux",
            "gpus",
            "image",
            "refer inference"
        ],
        "image enhancement": [
            "image feature",
            "image"
        ],
        "database systems": [
            "image feature",
            "image"
        ],
        "information retrieval": [
            "image feature",
            "image"
        ],
        "image reconstruction": [
            "image feature",
            "image"
        ],
        "machine learning": [
            "image feature",
            "image",
            "object detection",
            "cnn"
        ],
        "probability": [
            "size inference",
            "inference speed",
            "inference",
            "inference batch",
            "refer inference"
        ],
        "distributed systems": [
            "gpu",
            "cuda",
            "nvidia",
            "gpus"
        ],
        "computer hardware": [
            "gpu",
            "cuda",
            "nvidia",
            "gpus"
        ],
        "computer programming": [
            "gpu",
            "gpus",
            "cuda",
            "nvidia"
        ],
        "image analysis": [
            "image feature",
            "image",
            "object detection"
        ],
        "image processing": [
            "image feature",
            "image",
            "object detection"
        ],
        "computer systems": [
            "gpu",
            "image feature",
            "cuda",
            "nvidia",
            "gpus",
            "image"
        ],
        "mathematics": [
            "size inference",
            "inference speed",
            "inference batch",
            "inference",
            "refer inference"
        ],
        "distributed computer systems": [
            "gpu",
            "cuda",
            "nvidia",
            "gpus"
        ],
        "computer imaging and vision": [
            "image feature",
            "image",
            "object detection"
        ]
    }
}
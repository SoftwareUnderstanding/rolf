{
    "syntactic": [
        "convolutional neural networks",
        "gpu",
        "inference"
    ],
    "semantic": [
        "gpu",
        "random access memory",
        "character recognition",
        "inference",
        "probabilistic inference"
    ],
    "union": [
        "gpu",
        "random access memory",
        "convolutional neural networks",
        "character recognition",
        "probabilistic inference",
        "inference"
    ],
    "enhanced": [
        "program processors",
        "random access storage",
        "neural networks",
        "pattern recognition",
        "inference engines",
        "bayesian methods",
        "probability distributions",
        "parallel processing systems",
        "microprocessor chips",
        "machine learning",
        "artificial intelligence",
        "probability",
        "distributed systems",
        "computer hardware",
        "computer science",
        "mathematics",
        "distributed computer systems",
        "computer systems"
    ],
    "explanation": {
        "inference": [
            "inference follow",
            "runtime inference",
            "normalize inference",
            "inference image",
            "inference"
        ],
        "convolutional neural networks": [
            "cnn"
        ],
        "gpu": [
            "gpu"
        ],
        "probabilistic inference": [
            "inference follow",
            "runtime inference",
            "normalize inference",
            "inference image",
            "inference"
        ],
        "character recognition": [
            "image recognition",
            "recognition"
        ],
        "random access memory": [
            "memory",
            "memory map",
            "dat memory"
        ],
        "program processors": [
            "gpu"
        ],
        "random access storage": [
            "memory",
            "memory map",
            "dat memory"
        ],
        "neural networks": [
            "cnn"
        ],
        "pattern recognition": [
            "image recognition",
            "recognition"
        ],
        "inference engines": [
            "inference follow",
            "runtime inference",
            "normalize inference",
            "inference image",
            "inference"
        ],
        "bayesian methods": [
            "inference follow",
            "runtime inference",
            "normalize inference",
            "inference image",
            "inference"
        ],
        "probability distributions": [
            "inference follow",
            "runtime inference",
            "normalize inference",
            "inference image",
            "inference"
        ],
        "parallel processing systems": [
            "gpu",
            "memory map",
            "dat memory",
            "memory"
        ],
        "microprocessor chips": [
            "gpu",
            "memory map",
            "dat memory",
            "memory"
        ],
        "machine learning": [
            "image recognition",
            "recognition",
            "cnn"
        ],
        "artificial intelligence": [
            "inference follow",
            "runtime inference",
            "normalize inference",
            "image recognition",
            "inference image",
            "recognition",
            "inference",
            "cnn"
        ],
        "probability": [
            "inference follow",
            "runtime inference",
            "normalize inference",
            "inference image",
            "inference"
        ],
        "distributed systems": [
            "gpu",
            "memory map",
            "dat memory",
            "memory"
        ],
        "computer hardware": [
            "gpu",
            "memory map",
            "dat memory",
            "memory"
        ],
        "computer science": [
            "inference follow",
            "normalize inference",
            "recognition",
            "memory",
            "inference",
            "memory map",
            "dat memory",
            "cnn",
            "gpu",
            "runtime inference",
            "image recognition",
            "inference image"
        ],
        "mathematics": [
            "inference follow",
            "runtime inference",
            "normalize inference",
            "inference image",
            "inference"
        ],
        "distributed computer systems": [
            "gpu",
            "memory map",
            "dat memory",
            "memory"
        ],
        "computer systems": [
            "gpu",
            "memory map",
            "dat memory",
            "memory"
        ]
    }
}
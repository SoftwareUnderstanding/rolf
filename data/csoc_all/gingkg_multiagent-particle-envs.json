{
    "syntactic": [
        "cooperative communication",
        "communication",
        "actor critic",
        "private key",
        "reward function",
        "multi-agent",
        "action spaces",
        "covert communications"
    ],
    "semantic": [
        "cooperative communication",
        "communication",
        "actor critic",
        "intelligent agents",
        "private key",
        "reward function",
        "multi-agent",
        "software agents",
        "covert communications"
    ],
    "union": [
        "cooperative communication",
        "communication",
        "actor critic",
        "intelligent agents",
        "private key",
        "reward function",
        "multi-agent",
        "action spaces",
        "software agents",
        "covert communications"
    ],
    "enhanced": [
        "wireless sensor networks",
        "fading channels",
        "reinforcement learning",
        "multiagent system",
        "public key cryptography",
        "markov decision processes",
        "steganography",
        "wireless communications",
        "energy utilization",
        "sensor nodes",
        "routing algorithms",
        "communication channels",
        "signal to noise ratio",
        "machine learning",
        "artificial intelligence",
        "authentication",
        "network security",
        "markov processes",
        "security of data",
        "cryptography",
        "computer networks",
        "electricity",
        "sensors",
        "wireless telecommunication systems",
        "signal processing",
        "computer science",
        "correlation analysis",
        "computer security",
        "cryptology",
        "engineering",
        "computer hardware",
        "communication systems",
        "telecommunication systems",
        "mathematics",
        "computer systems"
    ],
    "explanation": {
        "multi-agent": [
            "multiagent core contain",
            "input multiagent scenario",
            "import multiagent",
            "scenario multiagent",
            "behavior screen multiagent",
            "keyboard input multiagent",
            "multiagent policy",
            "multiagent scenario folder",
            "multiagent core",
            "multiagent environment",
            "screen multiagent policy",
            "multiagent render display",
            "scenario multiagent scenario",
            "multiagent scenario",
            "input multiagent",
            "screen multiagent",
            "multiagent",
            "import multiagent environment",
            "multi agent",
            "object multiagent environment",
            "multiagent render",
            "object multiagent"
        ],
        "action spaces": [
            "action space"
        ],
        "actor critic": [
            "actor critic"
        ],
        "reward function": [
            "reward function"
        ],
        "covert communications": [
            "covert communication"
        ],
        "private key": [
            "private key"
        ],
        "cooperative communication": [
            "cooperative communication"
        ],
        "communication": [
            "name name communication",
            "communication",
            "name communication",
            "cooperative communication",
            "covert communication",
            "cooperative communication simple_reference",
            "communication simple_reference"
        ],
        "intelligent agents": [
            "agent landmark agent",
            "agent agent cover",
            "agent obstacle",
            "agent agent",
            "agent actor",
            "hide agent",
            "agent population",
            "agent particle",
            "agent reward",
            "single agent",
            "simple_reference agent",
            "agent split",
            "landmark agent",
            "color agent",
            "collide agent",
            "good agent",
            "agent observation",
            "agent speaker",
            "display agent",
            "agent cover",
            "collective agent",
            "collide agent agent",
            "goal agent agent",
            "navigation agent",
            "goal agent",
            "agent time",
            "agent agent listener",
            "agent landmark",
            "agent",
            "agent listener",
            "agent observe",
            "scenario agent",
            "know agent",
            "agent behavior",
            "agent adversary"
        ],
        "software agents": [
            "agent landmark agent",
            "agent agent cover",
            "agent obstacle",
            "agent agent",
            "agent actor",
            "hide agent",
            "agent population",
            "agent particle",
            "agent reward",
            "single agent",
            "simple_reference agent",
            "agent split",
            "landmark agent",
            "color agent",
            "collide agent",
            "good agent",
            "agent observation",
            "agent speaker",
            "display agent",
            "agent cover",
            "collective agent",
            "collide agent agent",
            "goal agent agent",
            "navigation agent",
            "goal agent",
            "agent time",
            "agent agent listener",
            "agent landmark",
            "agent",
            "agent listener",
            "agent observe",
            "scenario agent",
            "know agent",
            "agent behavior",
            "agent adversary"
        ],
        "wireless sensor networks": [
            "cooperative communication"
        ],
        "fading channels": [
            "cooperative communication"
        ],
        "reinforcement learning": [
            "reward function",
            "actor critic",
            "action space"
        ],
        "multiagent system": [
            "agent landmark agent",
            "agent agent cover",
            "agent obstacle",
            "multiagent core contain",
            "agent agent",
            "input multiagent scenario",
            "import multiagent",
            "behavior screen multiagent",
            "keyboard input multiagent",
            "agent actor",
            "hide agent",
            "agent population",
            "multiagent core",
            "agent particle",
            "screen multiagent policy",
            "multiagent render display",
            "agent reward",
            "single agent",
            "simple_reference agent",
            "input multiagent",
            "agent split",
            "landmark agent",
            "screen multiagent",
            "color agent",
            "collide agent",
            "multiagent",
            "import multiagent environment",
            "multiagent render",
            "object multiagent",
            "good agent",
            "agent observation",
            "agent speaker",
            "scenario multiagent",
            "display agent",
            "multiagent policy",
            "agent cover",
            "collective agent",
            "collide agent agent",
            "goal agent agent",
            "multiagent scenario folder",
            "multiagent environment",
            "navigation agent",
            "scenario multiagent scenario",
            "goal agent",
            "agent time",
            "multiagent scenario",
            "agent agent listener",
            "agent landmark",
            "agent",
            "agent listener",
            "agent observe",
            "scenario agent",
            "multi agent",
            "object multiagent environment",
            "know agent",
            "agent behavior",
            "agent adversary"
        ],
        "public key cryptography": [
            "private key"
        ],
        "markov decision processes": [
            "reward function"
        ],
        "steganography": [
            "covert communication"
        ],
        "wireless communications": [
            "cooperative communication"
        ],
        "energy utilization": [
            "cooperative communication"
        ],
        "sensor nodes": [
            "cooperative communication"
        ],
        "routing algorithms": [
            "cooperative communication"
        ],
        "communication channels": [
            "cooperative communication"
        ],
        "signal to noise ratio": [
            "cooperative communication"
        ],
        "machine learning": [
            "actor critic",
            "reward function",
            "action space"
        ],
        "artificial intelligence": [
            "agent landmark agent",
            "agent agent cover",
            "input multiagent scenario",
            "agent agent",
            "import multiagent",
            "behavior screen multiagent",
            "keyboard input multiagent",
            "agent actor",
            "hide agent",
            "agent particle",
            "agent reward",
            "single agent",
            "simple_reference agent",
            "actor critic",
            "agent split",
            "landmark agent",
            "color agent",
            "multiagent",
            "good agent",
            "agent speaker",
            "multiagent policy",
            "multiagent scenario folder",
            "agent cover",
            "collide agent agent",
            "goal agent agent",
            "scenario multiagent scenario",
            "multiagent scenario",
            "agent agent listener",
            "agent landmark",
            "object multiagent environment",
            "know agent",
            "multiagent core contain",
            "agent obstacle",
            "multiagent core",
            "agent population",
            "screen multiagent policy",
            "multiagent render display",
            "input multiagent",
            "screen multiagent",
            "collide agent",
            "import multiagent environment",
            "multiagent render",
            "object multiagent",
            "agent observation",
            "action space",
            "scenario multiagent",
            "reward function",
            "display agent",
            "collective agent",
            "multiagent environment",
            "navigation agent",
            "goal agent",
            "agent time",
            "agent",
            "agent listener",
            "agent observe",
            "scenario agent",
            "multi agent",
            "agent behavior",
            "agent adversary"
        ],
        "authentication": [
            "private key"
        ],
        "network security": [
            "private key"
        ],
        "markov processes": [
            "reward function"
        ],
        "security of data": [
            "covert communication",
            "private key"
        ],
        "cryptography": [
            "covert communication",
            "private key"
        ],
        "computer networks": [
            "cooperative communication",
            "private key"
        ],
        "electricity": [
            "cooperative communication"
        ],
        "sensors": [
            "cooperative communication"
        ],
        "wireless telecommunication systems": [
            "cooperative communication"
        ],
        "signal processing": [
            "cooperative communication"
        ],
        "computer science": [
            "agent landmark agent",
            "agent agent cover",
            "input multiagent scenario",
            "agent agent",
            "import multiagent",
            "behavior screen multiagent",
            "keyboard input multiagent",
            "agent actor",
            "hide agent",
            "agent particle",
            "agent reward",
            "single agent",
            "simple_reference agent",
            "cooperative communication",
            "actor critic",
            "agent split",
            "landmark agent",
            "color agent",
            "multiagent",
            "good agent",
            "agent speaker",
            "covert communication",
            "private key",
            "multiagent policy",
            "agent cover",
            "multiagent scenario folder",
            "collide agent agent",
            "goal agent agent",
            "scenario multiagent scenario",
            "multiagent scenario",
            "agent agent listener",
            "agent landmark",
            "object multiagent environment",
            "know agent",
            "multiagent core contain",
            "agent obstacle",
            "multiagent core",
            "agent population",
            "screen multiagent policy",
            "multiagent render display",
            "input multiagent",
            "screen multiagent",
            "collide agent",
            "import multiagent environment",
            "multiagent render",
            "object multiagent",
            "agent observation",
            "action space",
            "scenario multiagent",
            "reward function",
            "display agent",
            "collective agent",
            "multiagent environment",
            "navigation agent",
            "goal agent",
            "agent time",
            "agent",
            "agent listener",
            "agent observe",
            "scenario agent",
            "multi agent",
            "agent behavior",
            "agent adversary"
        ],
        "correlation analysis": [
            "reward function"
        ],
        "computer security": [
            "covert communication",
            "private key"
        ],
        "cryptology": [
            "covert communication",
            "private key"
        ],
        "engineering": [
            "cooperative communication"
        ],
        "computer hardware": [
            "cooperative communication"
        ],
        "communication systems": [
            "cooperative communication"
        ],
        "telecommunication systems": [
            "cooperative communication"
        ],
        "mathematics": [
            "reward function"
        ],
        "computer systems": [
            "cooperative communication"
        ]
    }
}
{
    "syntactic": [
        "gpu",
        "cpu",
        "inference",
        "utility functions",
        "gpus",
        "weight information",
        "convolutional neural networks",
        "detection rates"
    ],
    "semantic": [
        "gpu",
        "cpu",
        "inference",
        "utility functions",
        "gpus",
        "weight information",
        "probabilistic inference"
    ],
    "union": [
        "gpu",
        "weight information",
        "inference",
        "utility functions",
        "detection rates",
        "gpus",
        "cpu",
        "convolutional neural networks",
        "probabilistic inference"
    ],
    "enhanced": [
        "program processors",
        "attribute weight",
        "inference engines",
        "game theory",
        "intrusion detection",
        "cuda",
        "neural networks",
        "bayesian methods",
        "probability distributions",
        "parallel processing systems",
        "microprocessor chips",
        "multiple attribute decision making",
        "artificial intelligence",
        "computer crime",
        "parallel programming",
        "graphics processing unit",
        "machine learning",
        "probability",
        "distributed systems",
        "computer hardware",
        "illustrative examples",
        "computer science",
        "security of data",
        "parallel algorithms",
        "parallel architectures",
        "computer programming languages",
        "mathematics",
        "distributed computer systems",
        "linear matrix inequalities",
        "computer security",
        "computer programming",
        "computer systems",
        "matrix algebra"
    ],
    "explanation": {
        "detection rates": [
            "detectron accuracy"
        ],
        "utility functions": [
            "utility function"
        ],
        "weight information": [
            "weight information"
        ],
        "convolutional neural networks": [
            "cnn"
        ],
        "gpu": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "inference": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference",
            "inference batch",
            "inference line",
            "inference perform inference",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference batch inference",
            "perform inference",
            "inference pipeline",
            "gpu inference",
            "inference time"
        ],
        "cpu": [
            "cpu"
        ],
        "gpus": [
            "gpu",
            "gpus"
        ],
        "probabilistic inference": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference batch",
            "inference",
            "inference line",
            "inference perform inference",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference batch inference",
            "perform inference",
            "inference pipeline",
            "gpu inference",
            "inference time"
        ],
        "program processors": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "attribute weight": [
            "weight information"
        ],
        "inference engines": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference batch",
            "inference",
            "inference line",
            "inference perform inference",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference batch inference",
            "perform inference",
            "inference pipeline",
            "gpu inference",
            "inference time"
        ],
        "game theory": [
            "utility function"
        ],
        "intrusion detection": [
            "detectron accuracy"
        ],
        "cuda": [
            "gpu",
            "gpus"
        ],
        "neural networks": [
            "cnn"
        ],
        "bayesian methods": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference batch",
            "inference",
            "inference line",
            "inference perform inference",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference batch inference",
            "perform inference",
            "inference pipeline",
            "gpu inference",
            "inference time"
        ],
        "probability distributions": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference batch",
            "inference",
            "inference line",
            "inference perform inference",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference batch inference",
            "perform inference",
            "inference pipeline",
            "gpu inference",
            "inference time"
        ],
        "parallel processing systems": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "microprocessor chips": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "multiple attribute decision making": [
            "weight information"
        ],
        "artificial intelligence": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference",
            "inference batch",
            "inference line",
            "inference perform inference",
            "cnn",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference batch inference",
            "perform inference",
            "inference pipeline",
            "gpu inference",
            "utility function",
            "inference time"
        ],
        "computer crime": [
            "detectron accuracy"
        ],
        "parallel programming": [
            "gpu",
            "gpus"
        ],
        "graphics processing unit": [
            "gpu",
            "gpus"
        ],
        "machine learning": [
            "cnn"
        ],
        "probability": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference batch",
            "inference",
            "inference line",
            "inference perform inference",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference batch inference",
            "perform inference",
            "inference pipeline",
            "gpu inference",
            "inference time"
        ],
        "distributed systems": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "computer hardware": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "illustrative examples": [
            "weight information"
        ],
        "computer science": [
            "maskrcnn_benchmark inference",
            "inference batch",
            "inference",
            "inference line",
            "gpu cpu",
            "cnn",
            "gpu",
            "inference cpu",
            "support inference",
            "perform inference",
            "gpus",
            "inference pipeline",
            "gpu inference",
            "inference notebook",
            "batch inference",
            "detectron accuracy",
            "inference perform inference",
            "inference cpu inference",
            "cpu inference",
            "inference perform",
            "write inference",
            "inference batch inference",
            "cpu",
            "utility function",
            "inference time"
        ],
        "security of data": [
            "detectron accuracy"
        ],
        "parallel algorithms": [
            "gpu",
            "gpus"
        ],
        "parallel architectures": [
            "gpu",
            "gpus"
        ],
        "computer programming languages": [
            "gpu",
            "gpus"
        ],
        "mathematics": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference batch",
            "inference",
            "inference line",
            "inference perform inference",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference pipeline",
            "inference batch inference",
            "perform inference",
            "weight information",
            "gpu inference",
            "inference time"
        ],
        "distributed computer systems": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "linear matrix inequalities": [
            "weight information"
        ],
        "computer security": [
            "detectron accuracy"
        ],
        "computer programming": [
            "gpu",
            "gpus"
        ],
        "computer systems": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "matrix algebra": [
            "weight information"
        ]
    }
}
{
    "syntactic": [
        "gpu",
        "cpu",
        "object detection",
        "inference",
        "utility functions",
        "visualization",
        "gpus",
        "weight information",
        "convolutional neural networks",
        "detection rates"
    ],
    "semantic": [
        "gpu",
        "cpu",
        "object detection",
        "inference",
        "visualization",
        "utility functions",
        "gpus",
        "weight information",
        "probabilistic inference"
    ],
    "union": [
        "gpu",
        "weight information",
        "object detection",
        "inference",
        "utility functions",
        "visualization",
        "detection rates",
        "gpus",
        "cpu",
        "convolutional neural networks",
        "probabilistic inference"
    ],
    "enhanced": [
        "program processors",
        "attribute weight",
        "object recognition",
        "inference engines",
        "game theory",
        "human computer interaction",
        "intrusion detection",
        "cuda",
        "neural networks",
        "bayesian methods",
        "probability distributions",
        "parallel processing systems",
        "microprocessor chips",
        "multiple attribute decision making",
        "pattern recognition",
        "image segmentation",
        "artificial intelligence",
        "computer science",
        "computer crime",
        "parallel programming",
        "graphics processing unit",
        "machine learning",
        "probability",
        "distributed systems",
        "computer hardware",
        "illustrative examples",
        "image analysis",
        "image processing",
        "security of data",
        "parallel algorithms",
        "parallel architectures",
        "computer programming languages",
        "mathematics",
        "distributed computer systems",
        "linear matrix inequalities",
        "computer imaging and vision",
        "computer security",
        "computer programming",
        "computer systems",
        "matrix algebra"
    ],
    "explanation": {
        "object detection": [
            "object detection"
        ],
        "detection rates": [
            "detectron accuracy"
        ],
        "utility functions": [
            "utility function"
        ],
        "weight information": [
            "weight information"
        ],
        "visualization": [
            "visualization",
            "visualization jupyter",
            "basic visualization"
        ],
        "convolutional neural networks": [
            "cnn"
        ],
        "gpu": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "inference": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference",
            "inference batch",
            "inference line",
            "inference perform inference",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference batch inference",
            "perform inference",
            "inference pipeline",
            "gpu inference",
            "inference time"
        ],
        "cpu": [
            "cpu"
        ],
        "gpus": [
            "gpu",
            "gpus"
        ],
        "probabilistic inference": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference batch",
            "inference",
            "inference line",
            "inference perform inference",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference batch inference",
            "perform inference",
            "inference pipeline",
            "gpu inference",
            "inference time"
        ],
        "program processors": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "attribute weight": [
            "weight information"
        ],
        "object recognition": [
            "object detection"
        ],
        "inference engines": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference batch",
            "inference",
            "inference line",
            "inference perform inference",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference batch inference",
            "perform inference",
            "inference pipeline",
            "gpu inference",
            "inference time"
        ],
        "game theory": [
            "utility function"
        ],
        "human computer interaction": [
            "visualization",
            "visualization jupyter",
            "basic visualization"
        ],
        "intrusion detection": [
            "detectron accuracy"
        ],
        "cuda": [
            "gpu",
            "gpus"
        ],
        "neural networks": [
            "cnn"
        ],
        "bayesian methods": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference batch",
            "inference",
            "inference line",
            "inference perform inference",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference batch inference",
            "perform inference",
            "inference pipeline",
            "gpu inference",
            "inference time"
        ],
        "probability distributions": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference batch",
            "inference",
            "inference line",
            "inference perform inference",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference batch inference",
            "perform inference",
            "inference pipeline",
            "gpu inference",
            "inference time"
        ],
        "parallel processing systems": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "microprocessor chips": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "multiple attribute decision making": [
            "weight information"
        ],
        "pattern recognition": [
            "object detection"
        ],
        "image segmentation": [
            "object detection"
        ],
        "artificial intelligence": [
            "maskrcnn_benchmark inference",
            "inference",
            "inference batch",
            "inference line",
            "cnn",
            "inference cpu",
            "support inference",
            "object detection",
            "perform inference",
            "inference pipeline",
            "gpu inference",
            "inference notebook",
            "batch inference",
            "inference perform inference",
            "inference cpu inference",
            "cpu inference",
            "inference perform",
            "write inference",
            "inference batch inference",
            "utility function",
            "inference time"
        ],
        "computer science": [
            "maskrcnn_benchmark inference",
            "inference batch",
            "inference",
            "inference line",
            "gpu cpu",
            "cnn",
            "gpu",
            "inference cpu",
            "basic visualization",
            "support inference",
            "object detection",
            "perform inference",
            "gpus",
            "inference pipeline",
            "gpu inference",
            "inference notebook",
            "batch inference",
            "visualization",
            "detectron accuracy",
            "inference perform inference",
            "inference cpu inference",
            "cpu inference",
            "inference perform",
            "write inference",
            "inference batch inference",
            "cpu",
            "visualization jupyter",
            "utility function",
            "inference time"
        ],
        "computer crime": [
            "detectron accuracy"
        ],
        "parallel programming": [
            "gpu",
            "gpus"
        ],
        "graphics processing unit": [
            "gpu",
            "gpus"
        ],
        "machine learning": [
            "object detection",
            "cnn"
        ],
        "probability": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference batch",
            "inference",
            "inference line",
            "inference perform inference",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference batch inference",
            "perform inference",
            "inference pipeline",
            "gpu inference",
            "inference time"
        ],
        "distributed systems": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "computer hardware": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "illustrative examples": [
            "weight information"
        ],
        "image analysis": [
            "object detection"
        ],
        "image processing": [
            "object detection"
        ],
        "security of data": [
            "detectron accuracy"
        ],
        "parallel algorithms": [
            "gpu",
            "gpus"
        ],
        "parallel architectures": [
            "gpu",
            "gpus"
        ],
        "computer programming languages": [
            "gpu",
            "gpus"
        ],
        "mathematics": [
            "inference notebook",
            "maskrcnn_benchmark inference",
            "batch inference",
            "inference batch",
            "inference",
            "inference line",
            "inference perform inference",
            "inference cpu",
            "inference cpu inference",
            "inference perform",
            "support inference",
            "cpu inference",
            "write inference",
            "inference pipeline",
            "inference batch inference",
            "perform inference",
            "weight information",
            "gpu inference",
            "inference time"
        ],
        "distributed computer systems": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "linear matrix inequalities": [
            "weight information"
        ],
        "computer imaging and vision": [
            "object detection"
        ],
        "computer security": [
            "detectron accuracy"
        ],
        "computer programming": [
            "gpu",
            "gpus"
        ],
        "computer systems": [
            "gpu",
            "gpus",
            "cpu",
            "gpu cpu"
        ],
        "matrix algebra": [
            "weight information"
        ]
    }
}
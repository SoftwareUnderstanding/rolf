{
    "syntactic": [
        "gpu",
        "image classification",
        "computer vision",
        "engine",
        "quantization",
        "object detection",
        "inference",
        "linux",
        "classification methods",
        "cpu"
    ],
    "semantic": [
        "engine",
        "quantization",
        "image classification",
        "computer vision",
        "object detection",
        "inference",
        "linux",
        "cpu",
        "probabilistic inference"
    ],
    "union": [
        "gpu",
        "image classification",
        "computer vision",
        "engine",
        "quantization",
        "object detection",
        "inference",
        "linux",
        "classification methods",
        "cpu",
        "probabilistic inference"
    ],
    "enhanced": [
        "program processors",
        "imaging systems",
        "computer imaging and vision",
        "engineering",
        "image compression",
        "signal processing",
        "object recognition",
        "inference engines",
        "operating systems",
        "computer systems",
        "bayesian methods",
        "probability distributions",
        "parallel processing systems",
        "microprocessor chips",
        "image reconstruction",
        "computer science",
        "image quality",
        "image coding",
        "pattern recognition",
        "image segmentation",
        "artificial intelligence",
        "probability",
        "distributed systems",
        "computer hardware",
        "image analysis",
        "image processing",
        "machine learning",
        "mathematics",
        "distributed computer systems"
    ],
    "explanation": {
        "image classification": [
            "image classification"
        ],
        "classification methods": [
            "classification task"
        ],
        "computer vision": [
            "computer vision"
        ],
        "object detection": [
            "object detection"
        ],
        "inference": [
            "inference paddle",
            "inference deployment",
            "lite inference",
            "prediction inference",
            "variety inference",
            "inference",
            "inference prediction",
            "paddle_inference_en inference",
            "tensorrt inference",
            "inference doc",
            "cpp inference",
            "accuracy inference",
            "inference service",
            "inference demo",
            "inference time"
        ],
        "cpu": [
            "cpu"
        ],
        "linux": [
            "linux window",
            "linux"
        ],
        "engine": [
            "engine"
        ],
        "quantization": [
            "quantization"
        ],
        "gpu": [
            "cpu",
            "gpu"
        ],
        "probabilistic inference": [
            "inference paddle",
            "inference deployment",
            "inference prediction",
            "paddle_inference_en inference",
            "tensorrt inference",
            "inference doc",
            "lite inference",
            "prediction inference",
            "variety inference",
            "cpp inference",
            "inference",
            "accuracy inference",
            "inference service",
            "inference demo",
            "inference time"
        ],
        "program processors": [
            "cpu",
            "gpu"
        ],
        "imaging systems": [
            "image classification"
        ],
        "computer imaging and vision": [
            "object detection",
            "computer vision",
            "image classification",
            "quantization"
        ],
        "engineering": [
            "engine",
            "quantization"
        ],
        "image compression": [
            "quantization"
        ],
        "signal processing": [
            "quantization"
        ],
        "object recognition": [
            "object detection"
        ],
        "inference engines": [
            "inference paddle",
            "inference deployment",
            "lite inference",
            "prediction inference",
            "variety inference",
            "inference",
            "inference prediction",
            "paddle_inference_en inference",
            "tensorrt inference",
            "inference doc",
            "cpp inference",
            "accuracy inference",
            "inference service",
            "inference demo",
            "inference time"
        ],
        "operating systems": [
            "linux window",
            "linux"
        ],
        "computer systems": [
            "cpu",
            "gpu",
            "classification task"
        ],
        "bayesian methods": [
            "inference paddle",
            "inference deployment",
            "inference prediction",
            "paddle_inference_en inference",
            "tensorrt inference",
            "inference doc",
            "lite inference",
            "prediction inference",
            "variety inference",
            "cpp inference",
            "inference",
            "accuracy inference",
            "inference service",
            "inference demo",
            "inference time"
        ],
        "probability distributions": [
            "inference paddle",
            "inference deployment",
            "inference prediction",
            "paddle_inference_en inference",
            "tensorrt inference",
            "inference doc",
            "lite inference",
            "prediction inference",
            "variety inference",
            "cpp inference",
            "inference",
            "accuracy inference",
            "inference service",
            "inference demo",
            "inference time"
        ],
        "parallel processing systems": [
            "cpu",
            "gpu"
        ],
        "microprocessor chips": [
            "cpu",
            "gpu"
        ],
        "image reconstruction": [
            "image classification"
        ],
        "computer science": [
            "inference paddle",
            "inference deployment",
            "image classification",
            "quantization",
            "lite inference",
            "prediction inference",
            "variety inference",
            "inference",
            "gpu",
            "paddle_inference_en inference",
            "tensorrt inference",
            "object detection",
            "cpp inference",
            "accuracy inference",
            "linux",
            "inference demo",
            "inference prediction",
            "inference doc",
            "computer vision",
            "inference service",
            "cpu",
            "linux window",
            "inference time",
            "classification task"
        ],
        "image quality": [
            "quantization"
        ],
        "image coding": [
            "quantization"
        ],
        "pattern recognition": [
            "object detection"
        ],
        "image segmentation": [
            "object detection"
        ],
        "artificial intelligence": [
            "inference paddle",
            "inference deployment",
            "lite inference",
            "prediction inference",
            "variety inference",
            "inference",
            "inference prediction",
            "paddle_inference_en inference",
            "tensorrt inference",
            "inference doc",
            "object detection",
            "cpp inference",
            "accuracy inference",
            "inference service",
            "inference demo",
            "inference time"
        ],
        "probability": [
            "inference paddle",
            "inference deployment",
            "lite inference",
            "prediction inference",
            "variety inference",
            "inference",
            "inference prediction",
            "paddle_inference_en inference",
            "tensorrt inference",
            "inference doc",
            "cpp inference",
            "accuracy inference",
            "inference service",
            "inference demo",
            "inference time"
        ],
        "distributed systems": [
            "cpu",
            "gpu"
        ],
        "computer hardware": [
            "cpu",
            "gpu"
        ],
        "image analysis": [
            "object detection",
            "image classification",
            "quantization"
        ],
        "image processing": [
            "object detection",
            "image classification",
            "quantization"
        ],
        "machine learning": [
            "object detection"
        ],
        "mathematics": [
            "inference paddle",
            "inference deployment",
            "lite inference",
            "prediction inference",
            "variety inference",
            "inference",
            "inference prediction",
            "paddle_inference_en inference",
            "tensorrt inference",
            "inference doc",
            "cpp inference",
            "accuracy inference",
            "inference service",
            "inference demo",
            "inference time"
        ],
        "distributed computer systems": [
            "cpu",
            "gpu"
        ]
    }
}
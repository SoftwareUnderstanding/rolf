## Stanford cs224n course assignments

----
* assignment 1:  
Exploring word vectors (sparse or dense word representations).

* assignment 2:  
Implement Word2Vec with NumPy.

* assignment 3:  
Implement a neural transition-based dependency parser with PyTorch. (ref: A Fast and Accurate Dependency Parser using Neural Networks ( https://nlp.stanford.edu/pubs/emnlp2014-depparser.pdf))

* assignment 4:  
Implement neural machine translation (NMT) using a attentive encoder-decoder structure with LSTMs. (ref: Neural Machine Translation by Jointly Learning to Align and Translate (https://arxiv.org/abs/1409.0473))

* assignment 5:  
Improve NMT in assignment 4 by adding character-based encoder and decoder modules. (ref: Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models (https://arxiv.org/abs/1604.00788))

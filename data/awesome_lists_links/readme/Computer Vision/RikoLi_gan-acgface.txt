# A GAN Demo: ACG-Style Faces Generating
## Introduction
This is a GAN demo for creating anime character faces from random noise.

## Prerequisite
### Codes
* main.py
* gan.py
* utils.py
* generate.py
* dcgan.py
* nets.py
* show.html
* show.js
* spider.py

#### Main Codes
`main.py` contains training configurations.
`gan.py` defines net structure.
`utils.py` contains some auxiliary functions.
`generate.py` generates anime faces.

#### Not Available Now
`dcgan.py` and `nets.py` are rebuild versions of `main.py` and `gan.py` (not completed). `show.html` and `show.js` are for future presentation on web via Keras.js.

#### Others
`spider.py` collects and downloads training images from the Internet, thanks for the provider Acokil! 


### Datasets
Datasets are not uploaded.

* faces.zip
* hqface.zip

`faces.zip` is an anime face dataset with the image shape of (96, 96, 3). They are collected from [Konachan](http://konachan.net "Konachan~").

`hqface.zip` is also collected from Konachan, but contains images with higher quality.

## Environment
### OS
* Linux CentOS
* Windows 10

The linux mainly serves as training platform. Windows is for coding.

### GPU
* Nvidia Tesla K40M

GPUs are from ZJUSPC. Thanks for the authorization of the usage of K40M from ZJUSPC!

## References
Code references: [GAN-Zoo](https://github.com/hindupuravinash/the-gan-zoo)

Paper references: 
* [Generative Adversarial Nets](https://arxiv.org/abs/1406.2661v1) (arxiv id: 1406.2661v1)
* [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784v1) (arxiv id: 1411.1784v1)
* [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434v2) (arxiv id: 1511.06434v2)

## Results
Here are some generated faces. I used a 300-d random noise as input and trained for 40,000 iterations. In each iteration, I used 64 images to train the model.

![14](example/14.png "No.14") ![72](example/72.png "No.72") ![77](example/77.png "No.77") ![216](example/216.png "No.216") ![221](example/221.png "No.221") ![238](example/238.png "No.238") ![239](example/239.png "No.239") ![249](example/249.png "No.249") ![250](example/250.png "No.250") ![258](example/258.png "No.258") ![260](example/260.png "No.260") ![276](example/276.png "No.276") ![277](example/277.png "No.277")

As you can see, the quality of these faces is not good enough. In fact, for most of the generated images you can only recognize blurry faces so I just picked out some well-performed results. It is hard but worth to improve the model's performance.

## Future
Try to improve performance via these approaches:
* Use high quality training images
* Use larger training images

I adjusted the GAN. Then I used dataset `hqface` with the shape of (112, 112, 3) of each image to train a new model. It performs better on generating images of higher resolution.

Here are some new examples generated by the new GAN.

![hq4](example/hq4.png) ![hq18](example/hq18.png) ![hq23](example/hq23.png) ![hq29](example/hq29.png) ![hq30](example/hq30.png) ![hq31](example/hq31.png) ![hq37](example/hq37.png)

# Almond-Recognition: hyperspectral image classification

## Overview

I modify and train an implementation of ResNeXt with Squeeze and Excitation block to classify hyperspectral images between five classes.

[ResNeXt paper](https://arxiv.org/abs/1611.05431)  
[Squeeze and Excitation block paper](https://arxiv.org/pdf/1709.01507.pdf)  
[Implementation Referenced](https://github.com/taki0112/ResNeXt-Tensorflow)  

I compare classification accuracies used neural networks with different configurations, namely the cardinality of ResNeXt and the number of building blocks for each residual layer, and datasets with different numbers of spectral channels to.

It is shown that even the least powerful neural network trained with dataset having the fewest information performs well, achieving 96.67% accuracy on the testing dataset.

## Folders

ML model: Python code for ML model and image preprocessing

TF logs: log files generated by TensorFlow module

Euler run scrips: shell scripts to execute training and testing in UW-Madison's supercomputer cluster Euler

Euler logs: log files generated while training and testing in UW-Madison's supercomputer cluster Euler

Results: Python script to plot outputs in log files

## Data set information

Image size: 100 x 100 pixel

Image channels: Adjustable using spectral_step

Training and testing sets:

| Image class | Training size | Testing size | Total |
|:-:|:-:|:-:|:-:|
| Almond | 189 | 21 | 210 |
| Amber | 108 | 12 | 120 |
| Shell | 97 | 11 | 108 |
| Stone | 113 | 13 | 126 |
| Wood Chip | 36 | 4 | 40 |

Sadly the image data used for this project is company proprietary and cannot be shared publicly.

## Results ######

Check the subfolder "plots" in the "Results" folder directly.

OR run results.py in the "Results" folder to visualize all outputs. All plots will be saved in the subfolder "plots".

## References

[1] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “ImageNet Classification with Deep Convolutional Neural Networks,” Commun. ACM, vol. 60, no. 6, pp. 84–90, May 2017.  
[2] S. Xie, R. Girshick, P. Dollár, Z. Tu, and K. He, “Aggregated Residual Transformations for Deep Neural Networks,” arXiv:1611.05431 [cs], Nov. 2016.  
[3] J. Hu, L. Shen, and G. Sun, “Squeeze-and-Excitation Networks,” arXiv:1709.01507 [cs], Sep. 2017.  
[4] J. Kim, “Implementation of ResNeXt with S&E block”, code, https://github.com/taki0112/SENet-Tensorflow

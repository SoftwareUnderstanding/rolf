{
    "visibility": {
        "visibility": "public",
        "license": "Other"
    },
    "name": "MoCo: Momentum Contrast for Unsupervised Visual Representation Learning",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "kikacaty",
                "owner_type": "User",
                "name": "adv_guide",
                "url": "https://github.com/kikacaty/adv_guide",
                "stars": 0,
                "pushed_at": "2021-05-19 06:08:19+00:00",
                "created_at": "2021-04-09 16:10:57+00:00",
                "language": "Python",
                "license": "Other",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".github",
                "sha": "4f6c7dd00c2e68c56d150174df9874c573c83f57",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kikacaty/adv_guide/tree/main/.github"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "503b268325ad520df153533fdb9f990db0c1303a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kikacaty/adv_guide/blob/main/.gitignore"
                    }
                },
                "size": 21
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "6b28d560c9cbbb829dec5bf3eb23f8ddae46d697",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kikacaty/adv_guide/blob/main/LICENSE"
                    }
                },
                "size": 19332
            },
            {
                "type": "code",
                "name": "detection",
                "sha": "d6ef71201419fe31fdf683ec98951674ad383ddc",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kikacaty/adv_guide/tree/main/detection"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "main_lincls.py",
                "sha": "159be8b5c9a16a15085eff89a570c86e07de4474",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kikacaty/adv_guide/blob/main/main_lincls.py"
                    }
                },
                "size": 22466
            },
            {
                "type": "code",
                "name": "main_moco.py",
                "sha": "ed23ce2ad28e94e1ae5e569935fe565932a81d19",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kikacaty/adv_guide/blob/main/main_moco.py"
                    }
                },
                "size": 22395
            },
            {
                "type": "code",
                "name": "moco",
                "sha": "ab9714638b64f1162c753430b0ca35b4bae3d889",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kikacaty/adv_guide/tree/main/moco"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "train_cls.sh",
                "sha": "2d16cd41f6bbfff280bf4a9eced9a24fc0953c98",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kikacaty/adv_guide/blob/main/train_cls.sh"
                    }
                },
                "size": 352
            },
            {
                "type": "code",
                "name": "train_moco.sh",
                "sha": "b667fcef2d2bc6ba7a85b40b99460199ad755ca4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kikacaty/adv_guide/blob/main/train_moco.sh"
                    }
                },
                "size": 253
            },
            {
                "type": "code",
                "name": "training.log",
                "sha": "1650e47b08dedce86eb8f9abddd4d7da9f01befb",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kikacaty/adv_guide/blob/main/training.log"
                    }
                },
                "size": 609
            },
            {
                "type": "code",
                "name": "utils",
                "sha": "46bf62b328ab25ed12c725241303890186b7d02f",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kikacaty/adv_guide/tree/main/utils"
                    }
                },
                "num_files": 9
            }
        ]
    },
    "authors": [
        {
            "name": "xiaocw11",
            "github_id": "xiaocw11"
        },
        {
            "name": "Yulong Cao",
            "email": "yulongc@umich.edu",
            "github_id": "kikacaty"
        },
        {
            "name": "Kaiming He",
            "github_id": "KaimingHe"
        },
        {
            "name": "Yuxin Wu",
            "github_id": "ppwwyyxx"
        },
        {
            "name": "Facebook Community Bot",
            "github_id": "facebook-github-bot"
        }
    ],
    "tags": [],
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/kikacaty/adv_guide",
            "stars": 0,
            "issues": true,
            "readme": "## MoCo: Momentum Contrast for Unsupervised Visual Representation Learning\n\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/11435359/71603927-0ca98d00-2b14-11ea-9fd8-10d984a2de45.png\" width=\"300\">\n</p>\n\nThis is a PyTorch implementation of the [MoCo paper](https://arxiv.org/abs/1911.05722):\n```\n@Article{he2019moco,\n  author  = {Kaiming He and Haoqi Fan and Yuxin Wu and Saining Xie and Ross Girshick},\n  title   = {Momentum Contrast for Unsupervised Visual Representation Learning},\n  journal = {arXiv preprint arXiv:1911.05722},\n  year    = {2019},\n}\n```\nIt also includes the implementation of the [MoCo v2 paper](https://arxiv.org/abs/2003.04297):\n```\n@Article{chen2020mocov2,\n  author  = {Xinlei Chen and Haoqi Fan and Ross Girshick and Kaiming He},\n  title   = {Improved Baselines with Momentum Contrastive Learning},\n  journal = {arXiv preprint arXiv:2003.04297},\n  year    = {2020},\n}\n```\n\n\n### Preparation\n\nInstall PyTorch and ImageNet dataset following the [official PyTorch ImageNet training code](https://github.com/pytorch/examples/tree/master/imagenet).\n\nThis repo aims to be minimal modifications on that code. Check the modifications by:\n```\ndiff main_moco.py <(curl https://raw.githubusercontent.com/pytorch/examples/master/imagenet/main.py)\ndiff main_lincls.py <(curl https://raw.githubusercontent.com/pytorch/examples/master/imagenet/main.py)\n```\n\n\n### Unsupervised Training\n\nThis implementation only supports **multi-gpu**, **DistributedDataParallel** training, which is faster and simpler; single-gpu or DataParallel training is not supported.\n\nTo do unsupervised pre-training of a ResNet-50 model on ImageNet in an 8-gpu machine, run:\n```\npython main_moco.py \\\n  -a resnet50 \\\n  --lr 0.03 \\\n  --batch-size 256 \\\n  --dist-url 'tcp://localhost:10001' --multiprocessing-distributed --world-size 1 --rank 0 \\\n  [your imagenet-folder with train and val folders]\n```\nThis script uses all the default hyper-parameters as described in the MoCo v1 paper. To run MoCo v2, set `--mlp --moco-t 0.2 --aug-plus --cos`.\n\n***Note***: for 4-gpu training, we recommend following the [linear lr scaling recipe](https://arxiv.org/abs/1706.02677): `--lr 0.015 --batch-size 128` with 4 gpus. We got similar results using this setting.\n\n\n### Linear Classification\n\nWith a pre-trained model, to train a supervised linear classifier on frozen features/weights in an 8-gpu machine, run:\n```\npython main_lincls.py \\\n  -a resnet50 \\\n  --lr 30.0 \\\n  --batch-size 256 \\\n  --pretrained [your checkpoint path]/checkpoint_0199.pth.tar \\\n  --dist-url 'tcp://localhost:10001' --multiprocessing-distributed --world-size 1 --rank 0 \\\n  [your imagenet-folder with train and val folders]\n```\n\nLinear classification results on ImageNet using this repo with 8 NVIDIA V100 GPUs :\n<table><tbody>\n<!-- START TABLE -->\n<!-- TABLE HEADER -->\n<th valign=\"bottom\"></th>\n<th valign=\"bottom\">pre-train<br/>epochs</th>\n<th valign=\"bottom\">pre-train<br/>time</th>\n<th valign=\"bottom\">MoCo v1<br/>top-1 acc.</th>\n<th valign=\"bottom\">MoCo v2<br/>top-1 acc.</th>\n<!-- TABLE BODY -->\n<tr><td align=\"left\">ResNet-50</td>\n<td align=\"center\">200</td>\n<td align=\"center\">53 hours</td>\n<td align=\"center\">60.8&plusmn;0.2</td>\n<td align=\"center\">67.5&plusmn;0.1</td>\n</tr>\n</tbody></table>\n\nHere we run 5 trials (of pre-training and linear classification) and report mean&plusmn;std: the 5 results of MoCo v1 are {60.6, 60.6, 60.7, 60.9, 61.1}, and of MoCo v2 are {67.7, 67.6, 67.4, 67.6, 67.3}.\n\n\n### Models\n\nOur pre-trained ResNet-50 models can be downloaded as following:\n<table><tbody>\n<!-- START TABLE -->\n<!-- TABLE HEADER -->\n<th valign=\"bottom\"></th>\n<th valign=\"bottom\">epochs</th>\n<th valign=\"bottom\">mlp</th>\n<th valign=\"bottom\">aug+</th>\n<th valign=\"bottom\">cos</th>\n<th valign=\"bottom\">top-1 acc.</th>\n<th valign=\"bottom\">model</th>\n<th valign=\"bottom\">md5</th>\n<!-- TABLE BODY -->\n<tr><td align=\"left\"><a href=\"https://arxiv.org/abs/1911.05722\">MoCo v1</a></td>\n<td align=\"center\">200</td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\">60.6</td>\n<td align=\"center\"><a href=\"https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v1_200ep/moco_v1_200ep_pretrain.pth.tar\">download</a></td>\n<td align=\"center\"><tt>b251726a</tt></td>\n</tr>\n<tr><td align=\"left\"><a href=\"https://arxiv.org/abs/2003.04297\">MoCo v2</a></td>\n<td align=\"center\">200</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">67.7</td>\n<td align=\"center\"><a href=\"https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v2_200ep/moco_v2_200ep_pretrain.pth.tar\">download</a></td>\n<td align=\"center\"><tt>59fd9945</tt></td>\n</tr>\n<tr><td align=\"left\"><a href=\"https://arxiv.org/abs/2003.04297\">MoCo v2</a></td>\n<td align=\"center\">800</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">&#x2713</td>\n<td align=\"center\">71.1</td>\n<td align=\"center\"><a href=\"https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v2_800ep/moco_v2_800ep_pretrain.pth.tar\">download</a></td>\n<td align=\"center\"><tt>a04e12f8</tt></td>\n</tr>\n</tbody></table>\n\n\n### Transferring to Object Detection\n\nSee [./detection](detection).\n\n\n### License\n\nThis project is under the CC-BY-NC 4.0 license. See [LICENSE](LICENSE) for details.\n\n### See Also\n* [moco.tensorflow](https://github.com/ppwwyyxx/moco.tensorflow): A TensorFlow re-implementation.\n* [Colab notebook](https://colab.research.google.com/github/facebookresearch/moco/blob/colab-notebook/colab/moco_cifar10_demo.ipynb): CIFAR demo on Colab GPU.\n",
            "readme_url": "https://github.com/kikacaty/adv_guide",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour",
            "arxiv": "1706.02677",
            "year": 2017,
            "url": "http://arxiv.org/abs/1706.02677v2",
            "abstract": "Deep learning thrives with large neural networks and large datasets. However,\nlarger networks and larger datasets result in longer training times that impede\nresearch and development progress. Distributed synchronous SGD offers a\npotential solution to this problem by dividing SGD minibatches over a pool of\nparallel workers. Yet to make this scheme efficient, the per-worker workload\nmust be large, which implies nontrivial growth in the SGD minibatch size. In\nthis paper, we empirically show that on the ImageNet dataset large minibatches\ncause optimization difficulties, but when these are addressed the trained\nnetworks exhibit good generalization. Specifically, we show no loss of accuracy\nwhen training with large minibatch sizes up to 8192 images. To achieve this\nresult, we adopt a hyper-parameter-free linear scaling rule for adjusting\nlearning rates as a function of minibatch size and develop a new warmup scheme\nthat overcomes optimization challenges early in training. With these simple\ntechniques, our Caffe2-based system trains ResNet-50 with a minibatch size of\n8192 on 256 GPUs in one hour, while matching small minibatch accuracy. Using\ncommodity hardware, our implementation achieves ~90% scaling efficiency when\nmoving from 8 to 256 GPUs. Our findings enable training visual recognition\nmodels on internet-scale data with high efficiency.",
            "authors": [
                "Priya Goyal",
                "Piotr Doll\u00e1r",
                "Ross Girshick",
                "Pieter Noordhuis",
                "Lukasz Wesolowski",
                "Aapo Kyrola",
                "Andrew Tulloch",
                "Yangqing Jia",
                "Kaiming He"
            ]
        },
        {
            "title": "Improved Baselines with Momentum Contrastive Learning",
            "arxiv": "2003.04297",
            "year": 2020,
            "url": "http://arxiv.org/abs/2003.04297v1",
            "abstract": "Contrastive unsupervised learning has recently shown encouraging progress,\ne.g., in Momentum Contrast (MoCo) and SimCLR. In this note, we verify the\neffectiveness of two of SimCLR's design improvements by implementing them in\nthe MoCo framework. With simple modifications to MoCo---namely, using an MLP\nprojection head and more data augmentation---we establish stronger baselines\nthat outperform SimCLR and do not require large training batches. We hope this\nwill make state-of-the-art unsupervised learning research more accessible. Code\nwill be made public.",
            "authors": [
                "Xinlei Chen",
                "Haoqi Fan",
                "Ross Girshick",
                "Kaiming He"
            ]
        },
        {
            "title": "Momentum Contrast for Unsupervised Visual Representation Learning",
            "arxiv": "1911.05722",
            "year": 2019,
            "url": "http://arxiv.org/abs/1911.05722v3",
            "abstract": "We present Momentum Contrast (MoCo) for unsupervised visual representation\nlearning. From a perspective on contrastive learning as dictionary look-up, we\nbuild a dynamic dictionary with a queue and a moving-averaged encoder. This\nenables building a large and consistent dictionary on-the-fly that facilitates\ncontrastive unsupervised learning. MoCo provides competitive results under the\ncommon linear protocol on ImageNet classification. More importantly, the\nrepresentations learned by MoCo transfer well to downstream tasks. MoCo can\noutperform its supervised pre-training counterpart in 7 detection/segmentation\ntasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large\nmargins. This suggests that the gap between unsupervised and supervised\nrepresentation learning has been largely closed in many vision tasks.",
            "authors": [
                "Kaiming He",
                "Haoqi Fan",
                "Yuxin Wu",
                "Saining Xie",
                "Ross Girshick"
            ]
        },
        {
            "title": "moco.tensorflow",
            "url": "https://github.com/ppwwyyxx/moco.tensorflow"
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            },
            {
                "name": "COCO"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999065914541858,
        "task": "Object Detection",
        "task_prob": 0.8278485827627122
    }
}
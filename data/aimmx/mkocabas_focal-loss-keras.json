{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Focal Loss",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "mkocabas",
                "owner_type": "User",
                "name": "focal-loss-keras",
                "url": "https://github.com/mkocabas/focal-loss-keras",
                "stars": 312,
                "pushed_at": "2021-04-23 09:57:03+00:00",
                "created_at": "2017-10-04 14:40:22+00:00",
                "language": "Python",
                "description": "Focal Loss implementation in Keras",
                "license": "MIT License",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "46a130919bfc256fa7ceeb500b717183d3a72588",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/mkocabas/focal-loss-keras/blob/master/LICENSE"
                    }
                },
                "size": 1073
            },
            {
                "type": "code",
                "name": "focal_loss.py",
                "sha": "d178642684fcebbc87d074b998e0e1181bea14c9",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/mkocabas/focal-loss-keras/blob/master/focal_loss.py"
                    }
                },
                "size": 486
            }
        ]
    },
    "authors": [
        {
            "name": "Salih Karagoz",
            "email": "msalihkaragoz@yahoo.com",
            "github_id": "salihkaragoz"
        },
        {
            "name": "Kunjin Chen",
            "email": "yalickj@163.com",
            "github_id": "yalickj"
        },
        {
            "name": "Muhammed Kocabas",
            "github_id": "mkocabas"
        },
        {
            "name": "abc1044",
            "email": "bc@mrbian.cn",
            "github_id": "abc1044"
        }
    ],
    "tags": [],
    "description": "Focal Loss implementation in Keras",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/mkocabas/focal-loss-keras",
            "stars": 312,
            "issues": true,
            "readme": "# Focal Loss\nThis is the keras implementation of focal loss proposed by [Lin](https://vision.cornell.edu/se3/people/tsung-yi-lin/) et. al. in their [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002) paper.\n# Usage\nYou have to compile your model with focal loss.\nSample:\n```\nmodel_prn.compile(optimizer=optimizer, loss=[focal_loss(alpha=.25, gamma=2)])\n```\n\n",
            "readme_url": "https://github.com/mkocabas/focal-loss-keras",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Focal Loss for Dense Object Detection",
            "arxiv": "1708.02002",
            "year": 2017,
            "url": "http://arxiv.org/abs/1708.02002v2",
            "abstract": "The highest accuracy object detectors to date are based on a two-stage\napproach popularized by R-CNN, where a classifier is applied to a sparse set of\ncandidate object locations. In contrast, one-stage detectors that are applied\nover a regular, dense sampling of possible object locations have the potential\nto be faster and simpler, but have trailed the accuracy of two-stage detectors\nthus far. In this paper, we investigate why this is the case. We discover that\nthe extreme foreground-background class imbalance encountered during training\nof dense detectors is the central cause. We propose to address this class\nimbalance by reshaping the standard cross entropy loss such that it\ndown-weights the loss assigned to well-classified examples. Our novel Focal\nLoss focuses training on a sparse set of hard examples and prevents the vast\nnumber of easy negatives from overwhelming the detector during training. To\nevaluate the effectiveness of our loss, we design and train a simple dense\ndetector we call RetinaNet. Our results show that when trained with the focal\nloss, RetinaNet is able to match the speed of previous one-stage detectors\nwhile surpassing the accuracy of all existing state-of-the-art two-stage\ndetectors. Code is at: https://github.com/facebookresearch/Detectron.",
            "authors": [
                "Tsung-Yi Lin",
                "Priya Goyal",
                "Ross Girshick",
                "Kaiming He",
                "Piotr Doll\u00e1r"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9934900680817681,
        "task": "Object Detection",
        "task_prob": 0.9749746758193139
    }
}
{
    "visibility": {
        "visibility": "public",
        "license": "Other"
    },
    "name": "ConvBERT",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "yyht",
                "owner_type": "User",
                "name": "Conv_Bert",
                "url": "https://github.com/yyht/Conv_Bert",
                "stars": 0,
                "pushed_at": "2021-09-18 04:28:46+00:00",
                "created_at": "2020-12-23 03:07:40+00:00",
                "language": "Python",
                "license": "Other",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".DS_Store",
                "sha": "f276cc00d385dd139a6027df1e269b47fcf5322e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/.DS_Store"
                    }
                },
                "size": 8196
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "f058c580c2e8e70cf2c361a4697ba3e7e12d3c8f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/LICENSE"
                    }
                },
                "size": 1714
            },
            {
                "type": "code",
                "name": "build_data.sh",
                "sha": "e90b7643873df0ee4fe0110ae15599e34796063c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/build_data.sh"
                    }
                },
                "size": 330
            },
            {
                "type": "code",
                "name": "build_openwebtext_pretraining_dataset.py",
                "sha": "1449c42010fbd968c7b410ab2d707b41dee02ac5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/build_openwebtext_pretraining_dataset.py"
                    }
                },
                "size": 2825
            },
            {
                "type": "code",
                "name": "build_pretraining_dataset.py",
                "sha": "6a971b8d369c1aea253872b97c4e4cb6b8db33d8",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/build_pretraining_dataset.py"
                    }
                },
                "size": 7730
            },
            {
                "type": "code",
                "name": "configure_finetuning.py",
                "sha": "7cc391202cb523d2afc688a1852684a56ab6390e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/configure_finetuning.py"
                    }
                },
                "size": 7499
            },
            {
                "type": "code",
                "name": "configure_pretraining.py",
                "sha": "57eb6ee6ed04d79fbed4af48bd981ee0a23a6b2b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/configure_pretraining.py"
                    }
                },
                "size": 6040
            },
            {
                "type": "code",
                "name": "download_glue_data.py",
                "sha": "24b0ce79e27a5572672e6abda34f7f73e01211bd",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/download_glue_data.py"
                    }
                },
                "size": 7138
            },
            {
                "type": "code",
                "name": "electra_base_datagrand_params.json",
                "sha": "e8b4fb3d18c0bb3bb02640d339ebae65248d85df",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/electra_base_datagrand_params.json"
                    }
                },
                "size": 463
            },
            {
                "type": "code",
                "name": "electra_base_ori_params.json",
                "sha": "01ec5fab57f6fccdc8c4f548dc0ea578802a50b3",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/electra_base_ori_params.json"
                    }
                },
                "size": 439
            },
            {
                "type": "code",
                "name": "electra_base_params.json",
                "sha": "79458ca24ca9620f144229529dedd5f5cbbb905a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/electra_base_params.json"
                    }
                },
                "size": 496
            },
            {
                "type": "code",
                "name": "finetune.sh",
                "sha": "d503156cbd5914ab015637c0de2bdbaf7931da62",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/finetune.sh"
                    }
                },
                "size": 244
            },
            {
                "type": "code",
                "name": "finetune",
                "sha": "b3eda18725230621da2ae6c472f5f7a804d05503",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/tree/main/finetune"
                    }
                },
                "num_files": 9
            },
            {
                "type": "code",
                "name": "model",
                "sha": "b2c33e82dba82a8a0fceb106dfd495bb6f941e8a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/tree/main/model"
                    }
                },
                "num_files": 7
            },
            {
                "type": "code",
                "name": "pretrain.sh",
                "sha": "e85d25f65712ef03db39ccc5b13b65abd317b7b1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/pretrain.sh"
                    }
                },
                "size": 376
            },
            {
                "type": "code",
                "name": "pretrain",
                "sha": "313eca0eabbfc0905585245182435f992a856b16",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/tree/main/pretrain"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "run_finetuning.py",
                "sha": "cb970616261dc455b5c2477b9f4b09a2f8bbf349",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/run_finetuning.py"
                    }
                },
                "size": 12317
            },
            {
                "type": "code",
                "name": "run_pretraining.py",
                "sha": "d7cd5c4669157be3bfdc2ca94049e88f957b6c94",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/run_pretraining.py"
                    }
                },
                "size": 21928
            },
            {
                "type": "code",
                "name": "run_pretraining.sh",
                "sha": "7f480546c98020656c391b23ede306766650907c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/run_pretraining.sh"
                    }
                },
                "size": 253
            },
            {
                "type": "code",
                "name": "run_pretraining_datagrand.sh",
                "sha": "5d9637500f93de7a7411a728eb388a5cd108f7df",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/run_pretraining_datagrand.sh"
                    }
                },
                "size": 229
            },
            {
                "type": "code",
                "name": "run_pretraining_electra.sh",
                "sha": "9b8db384192550bc2b20f9277ddbf7bec1686683",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/run_pretraining_electra.sh"
                    }
                },
                "size": 218
            },
            {
                "type": "code",
                "name": "util",
                "sha": "d25fce397e670fbdbc0bd5ab65ed81fb6b5a9df2",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/tree/main/util"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "vocab.txt",
                "sha": "a4a9ef2f8100f7f023d2cd2a8c654b1f40040807",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/blob/main/vocab.txt"
                    }
                },
                "size": 266699
            },
            {
                "type": "code",
                "name": "vocab",
                "sha": "e7dc6c0810c2d7d6abb7558c78260c75d19a65b7",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/yyht/Conv_Bert/tree/main/vocab"
                    }
                },
                "num_files": 3
            }
        ]
    },
    "authors": [
        {
            "name": "yyht",
            "github_id": "yyht"
        }
    ],
    "tags": [],
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/yyht/Conv_Bert",
            "stars": 0,
            "issues": true,
            "readme": "# ConvBERT\n\n## Introduction\n\nIn this repo, we introduce a new architecture **ConvBERT** for pre-training based language model. The code is tested on a V100 GPU. For detailed description and experimental results, please refer to our NeurIPS 2020 paper [ConvBERT: Improving BERT with Span-based Dynamic Convolution](https://arxiv.org/abs/2008.02496).\n\n## Requirements\n* Python 3\n* tensorflow 1.15\n* numpy\n* scikit-learn\n\n## Experiments\n\n\n### Pre-training\n\nThese instructions pre-train a medium-small sized ConvBERT model (17M parameters)  using the [OpenWebText](https://skylion007.github.io/OpenWebTextCorpus/) corpus.\n\nTo build the tf-record and pre-train the model, download the [OpenWebText](https://skylion007.github.io/OpenWebTextCorpus/) corpus (12G) and **setup your data directory** in `build_data.sh` and `pretrain.sh`. Then run\n\n```bash\nbash build_data.sh\n```\n\nThe processed data require roughly 30G of disk space. Then, to pre-train the model, run\n\n```bash\nbash pretrain.sh\n```\n\nSee `configure_pretraining.py` for the details of the supported hyperparameters.\n\n### Fine-tining\n\nWe gives the instruction to fine-tune a pre-trained medium-small sized ConvBERT model (17M parameters) on GLUE. You can refer to the Google Colab notebook for a [quick example](https://colab.research.google.com/drive/1WIu2Cc1C8E7ayZBzEmpfd5sXOhe7Ehhz?usp=sharing). See our paper for more details on model performance. Pre-trained model can be found [here](https://drive.google.com/drive/folders/1pSsPcQrGXyt1FB45clALUQf-WTNAbUQa?usp=sharing). (You can also download it from [baidu cloud](https://pan.baidu.com/s/1jPo0e94p2dB8UBz33QuMrQ) with extraction code m9d2.)\n\nTo evaluate the performance on GLUE, you can download the GLUE data by running\n```bash\npython3 download_glue_data.py\n```\nSet up the data by running `mv CoLA cola && mv MNLI mnli && mv MRPC mrpc && mv QNLI qnli && mv QQP qqp && mv RTE rte && mv SST-2 sst && mv STS-B sts && mv diagnostic/diagnostic.tsv mnli && mkdir -p $DATA_DIR/finetuning_data && mv * $DATA_DIR/finetuning_data`. After preparing the GLUE data, **setup your data directory** in `finetune.sh` and  run\n```bash\nbash finetune.sh\n```\nAnd you can test different tasks by changing configs in `finetune.sh`.\n\nIf you find this repo helpful, please consider cite\n```bibtex\n@article{Jiang2020ConvBERT,\n  title={ConvBERT: Improving BERT with Span-based Dynamic Convolution},\n  author={Zi-Hang Jiang and Weihao Yu and Daquan Zhou and Y. Chen and Jiashi Feng and S. Yan},\n  journal={ArXiv},\n  year={2020},\n  volume={abs/2008.02496}\n}\n```\n# References\n\nHere are some great resources we benefit:\n\nCodebase: Our codebase are based on [ELECTRA](https://github.com/google-research/electra).\n\nDynamic convolution: [Implementation](https://github.com/pytorch/fairseq/blob/265791b727b664d4d7da3abd918a3f6fb70d7337/fairseq/modules/lightconv_layer/lightconv_layer.py#L75) from [Pay Less Attention with Lightweight and Dynamic Convolutions](https://openreview.net/pdf?id=SkVhlh09tX)\n\nDataset: [OpenWebText](https://skylion007.github.io/OpenWebTextCorpus/) from [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)\n\n",
            "readme_url": "https://github.com/yyht/Conv_Bert",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "ConvBERT: Improving BERT with Span-based Dynamic Convolution",
            "arxiv": "2008.02496",
            "year": 2020,
            "url": "http://arxiv.org/abs/2008.02496v3",
            "abstract": "Pre-trained language models like BERT and its variants have recently achieved\nimpressive performance in various natural language understanding tasks.\nHowever, BERT heavily relies on the global self-attention block and thus\nsuffers large memory footprint and computation cost. Although all its attention\nheads query on the whole input sequence for generating the attention map from a\nglobal perspective, we observe some heads only need to learn local\ndependencies, which means the existence of computation redundancy. We therefore\npropose a novel span-based dynamic convolution to replace these self-attention\nheads to directly model local dependencies. The novel convolution heads,\ntogether with the rest self-attention heads, form a new mixed attention block\nthat is more efficient at both global and local context learning. We equip BERT\nwith this mixed attention design and build a ConvBERT model. Experiments have\nshown that ConvBERT significantly outperforms BERT and its variants in various\ndownstream tasks, with lower training cost and fewer model parameters.\nRemarkably, ConvBERTbase model achieves 86.4 GLUE score, 0.7 higher than\nELECTRAbase, while using less than 1/4 training cost. Code and pre-trained\nmodels will be released.",
            "authors": [
                "Zihang Jiang",
                "Weihao Yu",
                "Daquan Zhou",
                "Yunpeng Chen",
                "Jiashi Feng",
                "Shuicheng Yan"
            ]
        },
        {
            "volume": "abs/2008.02496",
            "year": "2020",
            "journal": "ArXiv",
            "author": [
                "Jiang, Zi-Hang",
                "Yu, Weihao",
                "Zhou, Daquan",
                "Chen, Y.",
                "Feng, Jiashi",
                "Yan, S."
            ],
            "title": "ConvBERT: Improving BERT with Span-based Dynamic Convolution",
            "ENTRYTYPE": "article",
            "ID": "Jiang2020ConvBERT",
            "authors": [
                "Jiang, Zi-Hang",
                "Yu, Weihao",
                "Zhou, Daquan",
                "Chen, Y.",
                "Feng, Jiashi",
                "Yan, S."
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "GLUE"
            },
            {
                "name": "SST"
            }
        ]
    },
    "domain": {
        "domain_type": "Natural Language Processing",
        "domain_prob": 0.9998682669904725,
        "task": "Machine Translation",
        "task_prob": 0.5795190541276102
    }
}
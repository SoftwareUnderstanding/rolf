{
    "visibility": {
        "visibility": "public",
        "license": "Apache License 2.0"
    },
    "name": "YellowFin is an auto-tuning optimizer based on momentum SGD **which requires no manual specification of learning rate and momentum**. It measures the objective landscape on-the-fly and tunes momentum as well as learning rate using local quadratic approximation.",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "JianGoForIt",
                "owner_type": "User",
                "name": "YellowFin_Pytorch",
                "url": "https://github.com/JianGoForIt/YellowFin_Pytorch",
                "stars": 288,
                "pushed_at": "2019-03-24 22:43:12+00:00",
                "created_at": "2017-06-14 20:50:15+00:00",
                "language": "Python",
                "description": "auto-tuning momentum SGD optimizer",
                "license": "Apache License 2.0",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "c18dd8d83ceed1806b50b0aaa46beb7e335fff13",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/JianGoForIt/YellowFin_Pytorch/blob/master/.gitignore"
                    }
                },
                "size": 13
            },
            {
                "type": "code",
                "name": ".travis.yml",
                "sha": "05720bf3de7809143126c27b30e65cf1b6639396",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/JianGoForIt/YellowFin_Pytorch/blob/master/.travis.yml"
                    }
                },
                "size": 1497
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "8dada3edaf50dbc082c9a125058f25def75e625a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/JianGoForIt/YellowFin_Pytorch/blob/master/LICENSE"
                    }
                },
                "size": 11357
            },
            {
                "type": "code",
                "name": "numerical_test",
                "sha": "fa26d4684af7f71995bc36b6f73fdf9e3d9eadff",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/JianGoForIt/YellowFin_Pytorch/tree/master/numerical_test"
                    }
                },
                "num_files": 13
            },
            {
                "type": "code",
                "name": "pytorch-cifar",
                "sha": "2f37fcab559ef1a520ee3ba2339440f2664fd9d8",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/JianGoForIt/YellowFin_Pytorch/tree/master/pytorch-cifar"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "tuner_utils",
                "sha": "806811ae5c81bbf44f753e967f9b61d27a78b9cf",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/JianGoForIt/YellowFin_Pytorch/tree/master/tuner_utils"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "word_language_model",
                "sha": "b8755e941de72dd1f68d339bda655f3731826a1c",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/JianGoForIt/YellowFin_Pytorch/tree/master/word_language_model"
                    }
                },
                "num_files": 7
            }
        ]
    },
    "authors": [
        {
            "name": "Jian Zhang",
            "github_id": "JianGoForIt"
        },
        {
            "name": "Andrew Drozdov",
            "github_id": "mrdrozdov"
        },
        {
            "name": "elPistolero",
            "github_id": "elPistolero"
        },
        {
            "name": "jpeg729",
            "github_id": "jpeg729"
        },
        {
            "name": "esvhd",
            "github_id": "esvhd"
        }
    ],
    "tags": [],
    "description": "auto-tuning momentum SGD optimizer",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/JianGoForIt/YellowFin_Pytorch",
            "stars": 288,
            "issues": true,
            "readme": "# YellowFin [![Build Status](https://travis-ci.org/JianGoForIt/YellowFin_Pytorch.svg?branch=master)](https://travis-ci.org/JianGoForIt/YellowFin_Pytorch)\n\nYellowFin is an auto-tuning optimizer based on momentum SGD **which requires no manual specification of learning rate and momentum**. It measures the objective landscape on-the-fly and tunes momentum as well as learning rate using local quadratic approximation.\n\nThe implementation here can be **a drop-in replacement for any optimizer in PyTorch**. It supports ```step``` and ```zero_grad``` functions like any PyTorch optimizer after ```from yellowfin import YFOptimizer```. **We also provide interface to manually set the learning rate schedule at every iteration for finer control (see Detailed Guideline Section)**.\n\nFor more technical details, please refer to our paper [YellowFin and the Art of Momentum Tuning](https://arxiv.org/abs/1706.03471).\n\nFor more usage details, please refer to the inline documentation of ```tuner_utils/yellowfin.py```. Example usage can be found here for [ResNext on CIFAR10](https://github.com/JianGoForIt/YellowFin_Pytorch/blob/master/pytorch-cifar/main.py#L91) and [Tied LSTM on PTB](https://github.com/JianGoForIt/YellowFin_Pytorch/blob/master/word_language_model/main.py#L191).\n\n**YellowFin is under active development. Many members of the community have kindly submitted issues and pull requests. We are incorporating fixes and smoothing things out. As a result the repository code is in flux. Please make sure you use the latest version and submit any issues you might have!**\n\n## Updates\n**[2017.07.03] Fixed a gradient clipping bug. Please pull our latest master branch to make gradient clipping great again in YellowFin.**\n\n**[2017.07.28] Switched to logrithmic smoothing to accelerate adaptation to curvature range trends.**\n\n**[2017.08.01] Added optional feature to enforce non-increasing value of lr * gradient norm for stablity in some rare cases.**\n\n**[2017.08.05] Added feature to correct estimation bias from sparse gradient.**\n\n**[2017.08.16] Replace numpy root solver with closed form solution using Vieta's substitution for cubic eqaution. It solves the stability issue of the numpy root solver.**\n\n***[2017.10.29] Major fixe for stability. We added eps to protect fractions in our code, as well as an adaptive clipping feature to properly deal with exploding gradient (manual clipping is still supported as described in the detailed instruction below).***\n\n## Setup instructions for experiments\nPlease clone the master branch and follow the instructions to run YellowFin on [ResNext](https://arxiv.org/abs/1611.05431) for CIFAR10 and [tied LSTM](https://arxiv.org/pdf/1611.01462.pdf) on Penn Treebank for language modeling. The models are adapted from [ResNext repo](https://github.com/kuangliu/pytorch-cifar) and [PyTorch example tied LSTM repo](https://github.com/pytorch/examples/tree/master/word_language_model) respectively. Thanks to the researchers for developing the models. **For more experiments on more convolutional and recurrent neural networks, please refer to our [Tensorflow implementation](https://github.com/JianGoForIt/YellowFin) of YellowFin**.\n\nNote YellowFin is tested with PyTorch v0.2.0 for compatibility. It is tested under Python 2.7.\n\n### Run CIFAR10 ResNext experiments\nThe experiments on 110 layer ResNet with CIFAR10 and 164 layer ResNet with CIFAR100 can be launched using\n```\ncd pytorch-cifar\npython main.py --logdir=path_to_logs --opt_method=YF\n```\n\n### Run Penn Treebank tied LSTM experiments\nThe experiments on multiple-layer LSTM on Penn Treebank can be launched using\n```\ncd word_language_model\npython main.py --emsize 650 --nhid 650 --dropout 0.5 --epochs 40 --tied --opt_method=YF --logdir=path_to_logs --cuda\n```\n\nFor more experiments, please refer to our [YellowFin Tensorflow Repo](https://github.com/JianGoForIt/YellowFin).\n\n## Detailed guidelines\n* **Basic use**: ```optimizer = YFOptimizer(parameter_list)``` uses the uniform setting (i.e. without tuning) for all the PyTorch and Tensorflow experiments in our paper. \n\n* **Interface for manual finer control**: If you want to more finely control the learning rate (say using a manually set constant learning rate), or you want to use the typical lr-dropping technique after a ceritain number of epochs, please use ```set_lr_factor()``` in the YFOptimizer class. E.g. if you want to use a manually set constant learning rate, you can run ```set_lr_factor(desired_lr / self._lr)``` before ```self.step()``` at each iteration. Or e.g., if you want to always multiply a factor 2.0 to the learning rate originally tuned by YellowFin, you may use ```optimizer.set_lr_factor(2.0)``` right after ```optimizer = YFOptimizer(parameter_list)``` and before training with YellowFin. More details can be found [here](https://github.com/JianGoForIt/YellowFin_Pytorch/blob/master/pytorch-cifar/main.py#L109). **(The argument ```lr``` and ```mu``` during ```YFOptimizer``` initialization are dummy, only for backward compatibility)**\n\n* **Gradient clipping**: The default setting uses adaptive gradient clipping to prevent gradient explosion, thresholding norm of gradient to the square root of our estimated maximal curvature. There are three cases regarding gradient clipping. We recommend first turning off gradient clipping, and only turning it on when necessary. \n\n  * If you want to manually set threshold to clip the gradient, please first use ```adapt_clip=False``` to turn off the auto-clipping feature. Then, you can consider either using the ```clip_thresh=thresh_on_the_gradient_norm``` argument when initializing the YFOptimizer to clip acoording to your set threshold inside YFOptimizer, or clipping the gradient outside of YFOptimizer before ```step()``` is called.\n  \n  * If you want to totally turn off gradient clipping in YFOptimizer, please use ```clip_thresh=None, adapt_clip=False``` when initializing the YFOptimizer.\n\n* **Normalization**: When using log probability style losses, please make sure the loss is properly normalized. In some RNN/LSTM cases, the cross_entropy need to be averaged by the number of samples in a minibatch. Sometimes, it also needs to be averaged over the number of classes and the sequence length of each sample in some PyTorch loss functions. E.g. in nn.MultiLabelSoftMarginLoss, ```size_average=True``` needs to be set.\n\n<!---* **Sparsity**: Gradient norm, curvature estimations etc., when calculated with sparse gradient, are biased to larger values than the counterpart from the dense gradient on the full dataset. The bias can be illustrated using the following example: the norm of vectors (1.0, 0.0), (0.0, 1.0) and the norm of their average (0.5, 0.5). The norm of the latter is sqrt(sparsity (i.e. 0.5 here) ) * the norm of the former. The sparsity debias feature is useful when the model is very sparse, e.g. LSTM with word embedding. For non-sparse models, e.g. CNN, turning this feature off could slightly speedup.--->\n\n* **Non-increasing move**: In some rare cases, we have observe increasing value of lr * || grad ||, i.e. the move, may result in unstableness. We implemented an engineering trick to enforce non-increasing value of lr * || grad ||. The default setting turns the feature off, you can turn it on with ```force_non_inc_step_after_iter=the starting iter you want to enforce the non-increasing value ``` **if it is really necessary**. We recommend ```force_non_inc_step_after_iter``` to be at least a few hundreds because some models may need to gradually raise the magnitude of gradient in the beginning (e.g. a model, not properly initialized, may have near zero-gradient and need iterations to get reasonable gradient level).\n\n<!--## Additional experiments to test the repo\nWe use the [ResNext on CIFAR10](https://github.com/JianGoForIt/YellowFin_Pytorch/blob/master/pytorch-cifar/main.py#L91) and [Tied LSTM on PTB](https://github.com/JianGoForIt/YellowFin_Pytorch/blob/master/word_language_model/main.py#L191) to test the PyTorch implementation here. For more on experimental results, please refer to our [paper](https://arxiv.org/abs/1706.03471).-->\n\n<!--![ResNext](plots/resnext_test_acc.png)-->\n\n<!--![Tied LSTM](plots/tied_ptb_test_perp.png)-->\n\n\n## Citation\nIf you use YellowFin in your paper, please cite the paper:\n```\n@article{zhang2017yellowfin,\n  title={YellowFin and the Art of Momentum Tuning},\n  author={Zhang, Jian and Mitliagkas, Ioannis and R{\\'e}, Christopher},\n  journal={arXiv preprint arXiv:1706.03471},\n  year={2017}\n}\n```\n\n## Acknowledgement\nWe thank Olexa Bilaniuk, Andrew Drozdov, Paroma Varma, Bryan He, as well as github user @elPistolero @esvhd for the help in contributing to and testing the codebase.\n\n## Implementation for other platforms\nFor Tensorflow users, we implemented [YellowFin Tensorflow Repo](https://github.com/JianGoForIt/YellowFin).\n\n<!---For MXNet users, Github user [StargazerZhu](https://github.com/StargazerZhu) has already implemented a Theano version here: [YellowFin MXNet Repo](https://github.com/StargazerZhu/YellowFin_MXNet).--->\n\n<!---For Theano users, Github user [botev](https://github.com/botev) has already implemented a Theano version here: [YellowFin Theano Repo](https://gist.github.com/botev/f8b32c00eafee222e47393f7f0747666).--->\n\nWe thank the contributors for YellowFin in different deep learning frameworks.\n",
            "readme_url": "https://github.com/JianGoForIt/YellowFin_Pytorch",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "YellowFin and the Art of Momentum Tuning",
            "arxiv": "1706.03471",
            "year": 2017,
            "url": "http://arxiv.org/abs/1706.03471v2",
            "abstract": "Hyperparameter tuning is one of the most time-consuming workloads in deep\nlearning. State-of-the-art optimizers, such as AdaGrad, RMSProp and Adam,\nreduce this labor by adaptively tuning an individual learning rate for each\nvariable. Recently researchers have shown renewed interest in simpler methods\nlike momentum SGD as they may yield better test metrics. Motivated by this\ntrend, we ask: can simple adaptive methods based on SGD perform as well or\nbetter? We revisit the momentum SGD algorithm and show that hand-tuning a\nsingle learning rate and momentum makes it competitive with Adam. We then\nanalyze its robustness to learning rate misspecification and objective\ncurvature variation. Based on these insights, we design YellowFin, an automatic\ntuner for momentum and learning rate in SGD. YellowFin optionally uses a\nnegative-feedback loop to compensate for the momentum dynamics in asynchronous\nsettings on the fly. We empirically show that YellowFin can converge in fewer\niterations than Adam on ResNets and LSTMs for image recognition, language\nmodeling and constituency parsing, with a speedup of up to 3.28x in synchronous\nand up to 2.69x in asynchronous settings.",
            "authors": [
                "Jian Zhang",
                "Ioannis Mitliagkas"
            ]
        },
        {
            "title": "Aggregated Residual Transformations for Deep Neural Networks",
            "arxiv": "1611.05431",
            "year": 2016,
            "url": "http://arxiv.org/abs/1611.05431v2",
            "abstract": "We present a simple, highly modularized network architecture for image\nclassification. Our network is constructed by repeating a building block that\naggregates a set of transformations with the same topology. Our simple design\nresults in a homogeneous, multi-branch architecture that has only a few\nhyper-parameters to set. This strategy exposes a new dimension, which we call\n\"cardinality\" (the size of the set of transformations), as an essential factor\nin addition to the dimensions of depth and width. On the ImageNet-1K dataset,\nwe empirically show that even under the restricted condition of maintaining\ncomplexity, increasing cardinality is able to improve classification accuracy.\nMoreover, increasing cardinality is more effective than going deeper or wider\nwhen we increase the capacity. Our models, named ResNeXt, are the foundations\nof our entry to the ILSVRC 2016 classification task in which we secured 2nd\nplace. We further investigate ResNeXt on an ImageNet-5K set and the COCO\ndetection set, also showing better results than its ResNet counterpart. The\ncode and models are publicly available online.",
            "authors": [
                "Saining Xie",
                "Ross Girshick",
                "Piotr Doll\u00e1r",
                "Zhuowen Tu",
                "Kaiming He"
            ]
        },
        {
            "title": "Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling",
            "arxiv": "1611.01462",
            "year": 2016,
            "url": "http://arxiv.org/abs/1611.01462v3",
            "abstract": "Recurrent neural networks have been very successful at predicting sequences\nof words in tasks such as language modeling. However, all such models are based\non the conventional classification framework, where the model is trained\nagainst one-hot targets, and each word is represented both as an input and as\nan output in isolation. This causes inefficiencies in learning both in terms of\nutilizing all of the information and in terms of the number of parameters\nneeded to train. We introduce a novel theoretical framework that facilitates\nbetter learning in language modeling, and show that our framework leads to\ntying together the input embedding and the output projection matrices, greatly\nreducing the number of trainable variables. Our framework leads to state of the\nart performance on the Penn Treebank with a variety of network models.",
            "authors": [
                "Hakan Inan",
                "Khashayar Khosravi",
                "Richard Socher"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "Penn Treebank"
            },
            {
                "name": "ILSVRC 2016"
            },
            {
                "name": "ImageNet"
            },
            {
                "name": "COCO"
            }
        ]
    },
    "domain": {
        "domain_type": "Natural Language Processing",
        "domain_prob": 0.9905337071064285,
        "task": "Language Modelling",
        "task_prob": 0.9768869697430463
    }
}
{
    "visibility": {
        "visibility": "public"
    },
    "name": "Pytorch-Adaptive-Instance-Normalization",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "CellEight",
                "owner_type": "User",
                "name": "Pytorch-Adaptive-Instance-Normalization",
                "url": "https://github.com/CellEight/Pytorch-Adaptive-Instance-Normalization",
                "stars": 19,
                "pushed_at": "2020-07-13 19:07:02+00:00",
                "created_at": "2020-07-11 13:16:08+00:00",
                "language": "Python",
                "description": "A Pytorch implementation of the 2017 Huang et. al. paper \"Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization\"",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": "AdaIN.py",
                "sha": "6406b4258a54a8e9ba64412f24dd4138dc25a325",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/CellEight/Pytorch-Adaptive-Instance-Normalization/blob/master/AdaIN.py"
                    }
                },
                "size": 1130
            },
            {
                "type": "code",
                "name": "architecture.jpg",
                "sha": "c00dffbb7cf402a525458ed7afaba0870e5b125e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/CellEight/Pytorch-Adaptive-Instance-Normalization/blob/master/architecture.jpg"
                    }
                },
                "size": 450267
            },
            {
                "type": "code",
                "name": "model.py",
                "sha": "60126aec6fddda9af7dfa3dd807a95b951f6b029",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/CellEight/Pytorch-Adaptive-Instance-Normalization/blob/master/model.py"
                    }
                },
                "size": 2364
            },
            {
                "type": "code",
                "name": "style.py",
                "sha": "dba3f17e9ff03151e6646f7d0ef8ff1d04ac1a12",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/CellEight/Pytorch-Adaptive-Instance-Normalization/blob/master/style.py"
                    }
                },
                "size": 1237
            },
            {
                "type": "code",
                "name": "tmp",
                "sha": "bf4bfe1ddb3049533d76afd7f38da9c82552dfd8",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/CellEight/Pytorch-Adaptive-Instance-Normalization/tree/master/tmp"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "eb4f610910400399541c549b95584ce0cb2a55cd",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/CellEight/Pytorch-Adaptive-Instance-Normalization/blob/master/train.py"
                    }
                },
                "size": 5133
            },
            {
                "type": "code",
                "name": "train",
                "sha": "3a2cb9360ecb4407b2ca5df5f97b7ed7da245c56",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/CellEight/Pytorch-Adaptive-Instance-Normalization/tree/master/train"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "utils.py",
                "sha": "849ea1f541a326ae5b440415a0317e6ce30669a3",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/CellEight/Pytorch-Adaptive-Instance-Normalization/blob/master/utils.py"
                    }
                },
                "size": 1469
            }
        ]
    },
    "authors": [
        {
            "name": "Lewis Patten",
            "email": "lp921@york.ac.uk",
            "github_id": "CellEight"
        }
    ],
    "tags": [
        "deep-learning",
        "style-transfer",
        "neural-networks",
        "computer-vision",
        "machine-learning",
        "deep-learning-papers",
        "pretrained-weights",
        "pytorch",
        "paper",
        "huang",
        "datasets"
    ],
    "description": "A Pytorch implementation of the 2017 Huang et. al. paper \"Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization\"",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/CellEight/Pytorch-Adaptive-Instance-Normalization",
            "stars": 19,
            "issues": true,
            "readme": "# Pytorch-Adaptive-Instance-Normalization\n\nA Pytorch implementation of the 2017 Huang et. al. paper \"Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization\" [https://arxiv.org/abs/1703.06868](https://arxiv.org/abs/1703.06868)\nWritten from scratch with essentially no reference to Xun Huangs implementation in lua/torch (can be found here: [https://github.com/xunhuang1995/AdaIN-style](https://github.com/xunhuang1995/AdaIN-style)) but I'm none the less incredbily greatful to Huang et. al. for writing such an outstandingly beautiful paper and making their method so clear and easy to implement!\n![Architecture](./architecture.jpg)\n\n## Requirements\n\nTo run this model please install the latest version of pytorch, torchvision and CUDA.\n\n## Loading Pretrained Weights\n\nI have made a set of pretrained weights availabe on google drive if you don't want to train the model yourself. You can find them here [https://drive.google.com/file/d/1094pChApSOA7qJZn68kEdNxKIwPWRdHn/view?usp=sharing](https://drive.google.com/file/d/1094pChApSOA7qJZn68kEdNxKIwPWRdHn/view?usp=sharing).\nOnce downloaded just place it into the root directory of the repo and you're good to go. \n\n## Usage\n\nTo use the model for style transfer use the command `python style.pt <path to content image> <path to style image>`. \nThe styled image will be saves as `output.jpg` in the currect directory.\n\n## Traning The Model\n\nTo train the model from scratch first download the datasets you want to use. The paper uses this [https://www.kaggle.com/c/painter-by-numbers/data](https://www.kaggle.com/c/painter-by-numbers/data) Kaggle dataset of Wiki Art images as its soure for style images and the MS-COCO common objecs in context dataset [https://cocodataset.org/](https://cocodataset.org/) for its content images. After you've downloaded the datasets (or a subset of them as they are both pretty large, 10s of GB) place the style images in the `train/style` directory and the content images in the `train/content` directory.\n\nTo actully train the model just run `python -i train.py` which will start training and output previews of it's progress into the `tmp` directory every few interations.\nEvery epoch the model will be saved to a file called `adain_model`.\n\n## To Do\n* Add automatic gpu/cpu selection\n* Add explanatory text to loss printout\n* Implement Bias correction on moving average loss\n* Update default hyperparameters to match that of Huang\n* Train the model for longer and upload better pretrained weights\n* Add command line options for hyperparameters\n* Make `requirements.txt` file\n* Add more advanced runtime style interpolation and masking features from the paper\n* Add some examples to this readme\n",
            "readme_url": "https://github.com/CellEight/Pytorch-Adaptive-Instance-Normalization",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization",
            "arxiv": "1703.06868",
            "year": 2017,
            "url": "http://arxiv.org/abs/1703.06868v2",
            "abstract": "Gatys et al. recently introduced a neural algorithm that renders a content\nimage in the style of another image, achieving so-called style transfer.\nHowever, their framework requires a slow iterative optimization process, which\nlimits its practical application. Fast approximations with feed-forward neural\nnetworks have been proposed to speed up neural style transfer. Unfortunately,\nthe speed improvement comes at a cost: the network is usually tied to a fixed\nset of styles and cannot adapt to arbitrary new styles. In this paper, we\npresent a simple yet effective approach that for the first time enables\narbitrary style transfer in real-time. At the heart of our method is a novel\nadaptive instance normalization (AdaIN) layer that aligns the mean and variance\nof the content features with those of the style features. Our method achieves\nspeed comparable to the fastest existing approach, without the restriction to a\npre-defined set of styles. In addition, our approach allows flexible user\ncontrols such as content-style trade-off, style interpolation, color & spatial\ncontrols, all using a single feed-forward neural network.",
            "authors": [
                "Xun Huang",
                "Serge Belongie"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "https://cocodataset.org/",
                "connection": {
                    "name": "url",
                    "source": {
                        "url": "https://cocodataset.org/"
                    }
                }
            },
            {
                "name": "MS-COCO"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9974982770022327,
        "task": "Object Detection",
        "task_prob": 0.93380388287487
    }
}
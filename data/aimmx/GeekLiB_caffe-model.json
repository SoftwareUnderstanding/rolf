{
    "visibility": {
        "visibility": "public"
    },
    "name": "Caffe-model",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "GeekLiB",
                "owner_type": "User",
                "name": "caffe-model",
                "url": "https://github.com/GeekLiB/caffe-model",
                "stars": 121,
                "pushed_at": "2017-10-21 15:24:56+00:00",
                "created_at": "2017-04-11 09:35:54+00:00",
                "language": "Python",
                "description": "Caffe models (imagenet pretrain) and prototxt generator scripts for inception_v3 \\ inception_v4 \\ inception_resnet \\ fractalnet \\ resnext",
                "frameworks": [
                    "Caffe"
                ]
            },
            {
                "type": "code",
                "name": "alexnet.py",
                "sha": "b70f64b67174fe44eae10cab61d0f5f41e280e1f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/blob/master/alexnet.py"
                    }
                },
                "size": 6674
            },
            {
                "type": "code",
                "name": "cls",
                "sha": "f73335ad10fb5104f5241f5aa1af75e647e618f1",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/tree/master/cls"
                    }
                },
                "num_files": 9
            },
            {
                "type": "code",
                "name": "fractalnet.py",
                "sha": "473bffac10130fa01715ec9b8c03fa52ef83b047",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/blob/master/fractalnet.py"
                    }
                },
                "size": 9757
            },
            {
                "type": "code",
                "name": "inception_resnet.py",
                "sha": "2499c9385107d375e780ce26834b039517aae334",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/blob/master/inception_resnet.py"
                    }
                },
                "size": 26493
            },
            {
                "type": "code",
                "name": "inception_v1.py",
                "sha": "f1453df39630ccbac737fb26c58220cb233970e4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/blob/master/inception_v1.py"
                    }
                },
                "size": 32045
            },
            {
                "type": "code",
                "name": "inception_v3.py",
                "sha": "a9846529619518387c756c4f2187a1eb49bd1bc9",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/blob/master/inception_v3.py"
                    }
                },
                "size": 30145
            },
            {
                "type": "code",
                "name": "inception_v4.py",
                "sha": "1fb7131748906e1e83949e7f4c0e0fa516b6c0ba",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/blob/master/inception_v4.py"
                    }
                },
                "size": 26845
            },
            {
                "type": "code",
                "name": "lenet.py",
                "sha": "56f5591b66e62e0304bd86b4664cfa0b398ee117",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/blob/master/lenet.py"
                    }
                },
                "size": 3797
            },
            {
                "type": "code",
                "name": "make_net.py",
                "sha": "81c5dd89afcb9bd4d36f1eb3321094952f9089ac",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/blob/master/make_net.py"
                    }
                },
                "size": 452
            },
            {
                "type": "code",
                "name": "nin.py",
                "sha": "e4e1d5a9b53e534b29a7cb852549c587799ec2a5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/blob/master/nin.py"
                    }
                },
                "size": 7811
            },
            {
                "type": "code",
                "name": "prototxts",
                "sha": "b13bf830cc62903ec8748e7c25124c6a89a858cd",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/tree/master/prototxts"
                    }
                },
                "num_files": 7
            },
            {
                "type": "code",
                "name": "resnet.py",
                "sha": "2cb12c4d4584cf6f238a2a2f0fe96c07ce3365fd",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/blob/master/resnet.py"
                    }
                },
                "size": 8064
            },
            {
                "type": "code",
                "name": "resnext.py",
                "sha": "ad3145de965a981c5fa8ed40c9d8b2710c83998c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/blob/master/resnext.py"
                    }
                },
                "size": 8469
            },
            {
                "type": "code",
                "name": "seg",
                "sha": "6dec3155e258864233412ddba513b9ad6e10145a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/tree/master/seg"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "vggnet.py",
                "sha": "4be395efd242dfddb071fb767e62b0f60185f97e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/GeekLiB/caffe-model/blob/master/vggnet.py"
                    }
                },
                "size": 13689
            }
        ]
    },
    "authors": [
        {
            "name": "Albert Lee",
            "email": "15333692606@163.com",
            "github_id": "GeekLiB"
        }
    ],
    "tags": [],
    "description": "Caffe models (imagenet pretrain) and prototxt generator scripts for inception_v3 \\ inception_v4 \\ inception_resnet \\ fractalnet \\ resnext",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/GeekLiB/caffe-model",
            "stars": 121,
            "issues": true,
            "readme": "# Caffe-model\nPython script to generate prototxt on Caffe, specially the inception_v3\\inception_v4\\inception_resnet\\fractalnet\n\n# Generator scripts\n\nThe prototxts can be visualized by [ethereon](http://ethereon.github.io/netscope/quickstart.html).\n\nEvery model has a bn (batch normalization) version (maybe only bn version), the paper is [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://arxiv.org/pdf/1502.03167v3)\n\n\n\n# Classificaiton (imagenet)\n\n### Introduction\nThis folder contains the deploy files(include generator scripts) and pre-train models of resnet-v1, resnet-v2, inception-v3, inception-resnet-v2 and densenet(coming soon).\n\nWe didn't train any model from scratch, some of them are converted from other deep learning framworks (inception-v3 from [mxnet](https://github.com/dmlc/mxnet-model-gallery/blob/master/imagenet-1k-inception-v3.md), inception-resnet-v2 from [tensorflow](https://github.com/tensorflow/models/blob/master/slim/nets/inception_resnet_v2.py)), some of them are converted from other modified caffe ([resnet-v2](https://github.com/yjxiong/caffe/tree/mem)). But to achieve the original performance, finetuning is performed on imagenet for several epochs. \n\nThe main contribution belongs to the authors and model trainers.\n\n### Performance on imagenet\n0. Top-1/5 accuracy of pre-train models in this repository.\n\n Network|224/299(single-crop)|224/299(12-crop)|320/395(single-crop)|320/395(12-crop)\n :---:|:---:|:---:|:---:|:---:\n resnet101-v2| 78.05/93.88 | 80.01/94.96 | 79.63/94.84 | 80.71/95.43\n resnet152-v2| 79.15/94.58 | 80.76/95.32 | 80.34/95.26 | 81.16/95.68 \n resnet269-v2| **80.29**/95.00 | **81.75**/95.80 | 81.30/95.67 | **82.13**/96.15 \n inception-v3| 78.33/94.25 | 80.40/95.27 | 79.90/95.18 | 80.75/95.76 \n inception-v4| 79.97/94.91 | 81.40/95.70 | **81.32**/95.68 | 81.88/96.08 \n inception-resnet-v2| 80.14/**95.17** | 81.54/**95.92** | 81.25/**95.98** | 81.85/**96.29**\n resnext50_32x4d| 77.63/93.69 | 79.47/94.65 | 78.90/94.47 | 79.63/94.97 \n resnext101_32x4d| 78.70/94.21 | 80.53/95.11 | 80.09/95.03 | 80.81/95.41\n resnext101_64x4d| 79.40/94.59 | 81.12/95.41 | 80.74/95.37 | 81.52/95.69\n wrn50_2(resnet50_1x128d)| 77.87/93.87 | 79.91/94.94 | 79.32/94.72 | 80.17/95.13\n\n - The pre-train models are tested on original [caffe](https://github.com/BVLC/caffe) by [evaluation_cls.py](https://github.com/soeaver/caffe-model/blob/master/cls/evaluation_cls.py), **but ceil_mode:false\uff08pooling_layer\uff09 is used for the models converted from torch, the detail in https://github.com/BVLC/caffe/pull/3057/files**. If you remove ceil_mode:false, the performance will decline about 1% top1.\n - 224x224(base_size=256) and 320x320(base_size=320) crop size for resnet-v2/resnext/wrn, 299x299(base_size=320) and 395x395(base_size=395) crop size for inception.\n\n0. Top-1/5 accuracy with different crop sizes.\n![teaser](https://github.com/soeaver/caffe-model/blob/master/cls/accuracy.png)\n - Figure: Accuracy curves of inception_v3(left) and resnet101_v2(right) with different crop sizes.\n\n0. **Download url** and forward/backward time cost for each model.\n\n Forward/Backward time cost is evaluated with one image/mini-batch using cuDNN 5.1 on a Pascal Titan X GPU.\n \n We use\n  ```\n    ~/caffe/build/tools/caffe -model deploy.prototxt time -gpu -iterations 1000\n  ```\n to test the forward/backward time cost, the result is really different with time cost of [evaluation_cls.py](https://github.com/soeaver/caffe-model/blob/master/cls/evaluation_cls.py)\n\n Network|F/B(224/299)|F/B(320/395)|Download|Source\n :---:|:---:|:---:|:---:|:---:\n resnet101-v2| 22.31/22.75ms | 26.02/29.50ms | [170.3MB](https://pan.baidu.com/s/1kVQDHFx)|[craftGBD](https://github.com/craftGBD/craftGBD)\n resnet152-v2| 32.11/32.54ms | 37.46/41.84ms | [230.2MB](https://pan.baidu.com/s/1dFIc4vB)|[craftGBD](https://github.com/craftGBD/craftGBD)\n resnet269-v2| 58.20/59.15ms | 69.43/77.26ms | [390.4MB](https://pan.baidu.com/s/1qYbICs0)|[craftGBD](https://github.com/craftGBD/craftGBD)\n inception-v3| 21.79/19.82ms | 22.14/24.88ms | [91.1MB](https://pan.baidu.com/s/1boC0HEf)|[mxnet](https://github.com/dmlc/mxnet-model-gallery/blob/master/imagenet-1k-inception-v3.md)\n inception-v4| 32.96/32.19ms | 36.04/41.91ms | [163.1MB](https://pan.baidu.com/s/1c6D150)|[tensorflow_slim](https://github.com/tensorflow/models/tree/master/slim)\n inception-resnet-v2| 49.06/54.83ms | 54.06/66.38ms | [213.4MB](https://pan.baidu.com/s/1jHPJCX4)|[tensorflow_slim](https://github.com/tensorflow/models/tree/master/slim)\n resnext50_32x4d| 17.29/20.08ms | 19.02/23.81ms | [95.8MB](https://pan.baidu.com/s/1kVqgfJL)|[facebookresearch](https://github.com/facebookresearch/ResNeXt)\n resnext101_32x4d| 30.73/35.75ms | 34.33/41.02ms | [169.1MB](https://pan.baidu.com/s/1hswrNUG)|[facebookresearch](https://github.com/facebookresearch/ResNeXt)\n resnext101_64x4d| 42.07/64.58ms | 51.99/77.71ms | [319.2MB](https://pan.baidu.com/s/1pLhk0Zp)|[facebookresearch](https://github.com/facebookresearch/ResNeXt)\n wrn50_2(resnet50_1x128d)| 16.48/25.28ms | 20.99/35.04ms | [263.1MB](https://pan.baidu.com/s/1nvhoCsh)|[szagoruyko](https://github.com/szagoruyko/wide-residual-networks)\n\n### Check the performance\n0. Download the ILSVRC 2012 classification val set [6.3GB](http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tar), and put the extracted images into the directory:\n    ```\n    ~/Database/ILSVRC2012\n    ```\n\n0. Check the resnet-v2 (101, 152 and 269) performance, the settings of [evaluation_cls.py](https://github.com/soeaver/caffe-model/blob/master/cls/evaluation_cls.py):\n   \n    ```\n    val_file = 'ILSVRC2012_val.txt' # download from this folder, label range 0~999\n    ... ...\n    model_weights = 'resnet-v2/resnet101_v2.caffemodel' # download as below\n    model_deploy = 'resnet-v2/deploy_resnet101_v2.prototxt' # check the parameters of input_shape\n    ... ...\n    mean_value = np.array([102.9801, 115.9465, 122.7717])  # BGR\n    std = np.array([1.0, 1.0, 1.0])  # BGR\n    crop_num = 1    # perform center(single)-crop\n    ```\n\n    Check the inception-v3 performance, the settings of [evaluation_cls.py](https://github.com/soeaver/caffe-model/blob/master/cls/evaluation_cls.py):\n   \n    ```\n    val_file = 'ILSVRC2015_val.txt' # download from this folder, label range 0~999\n    ... ...\n    model_weights = 'inception_v3/inception_v3.caffemodel' # download as below\n    model_deploy = 'inception_v3/deploy_inception_v3.prototxt' # check the parameters of input_shape\n    ... ...\n    mean_value = np.array([128.0, 128.0, 128.0])  # BGR\n    std = np.array([128.0, 128.0, 128.0])  # BGR\n    crop_num = 1    # perform center(single)-crop\n    ```\n    \n    Check the inception-resnet-v2 (inception-v4) performance, the settings of [evaluation_cls.py](https://github.com/soeaver/caffe-model/blob/master/cls/evaluation_cls.py):\n   \n    ```\n    val_file = 'ILSVRC2012_val.txt' # download from this folder, label range 0~999\n    ... ...\n    model_weights = 'inception_resnet_v2/inception_resnet_v2.caffemodel' # download as below\n    model_deploy = 'inception_resnet_v2/deploy_inception_resnet_v2.prototxt' # check the parameters of input_shape\n    ... ...\n    mean_value = np.array([128.0, 128.0, 128.0])  # BGR\n    std = np.array([128.0, 128.0, 128.0])  # BGR\n    crop_num = 1    # perform center(single)-crop\n    ```\n    \n    Check the resnext (50_32x4d, 101_32x4d and 101_64x4d) or wrn50_2 performance, the settings of [evaluation_cls.py](https://github.com/soeaver/caffe-model/blob/master/cls/evaluation_cls.py):\n   \n    ```\n    val_file = 'ILSVRC2012_val.txt' # download from this folder, label range 0~999\n    ... ...\n    model_weights = 'inception_resnet_v2/inception_resnet_v2.caffemodel' # download as below\n    model_deploy = 'inception_resnet_v2/deploy_inception_resnet_v2.prototxt' # check the parameters of input_shape\n    ... ...\n    mean_value = np.array([103.52, 116.28, 123.675])  # BGR\n    std = np.array([57.375, 57.12, 58.395])  # BGR\n    crop_num = 1    # perform center(single)-crop\n    ```\n\n\n0. then\n    ```\n    python evaluation_cls.py\n    ```\n\n\n\n# Acknowlegement\n\nI greatly thank [Yangqing Jia](https://github.com/Yangqing) and [BVLC group](https://www.github.com/BVLC/caffe) for developing Caffe\n\nAnd I would like to thank all the authors of every cnn model\n",
            "readme_url": "https://github.com/GeekLiB/caffe-model",
            "frameworks": [
                "Caffe"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9997326821527547,
        "task": "Image Classification",
        "task_prob": 0.7302403391968505
    }
}
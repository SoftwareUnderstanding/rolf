{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Efficient networks for Computer Vision",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "sacmehta",
                "owner_type": "User",
                "name": "EdgeNets",
                "url": "https://github.com/sacmehta/EdgeNets",
                "stars": 371,
                "pushed_at": "2022-03-24 21:57:00+00:00",
                "created_at": "2019-06-07 19:29:38+00:00",
                "language": "Python",
                "description": "This repository contains the source code of our work on designing efficient CNNs for computer vision",
                "license": "MIT License",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "44ca712e5e96d05609cec01017247c2078e24bbc",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/.gitignore"
                    }
                },
                "size": 33
            },
            {
                "type": "code",
                "name": "Instructions",
                "sha": "6a97939b62ef3f2348a4a0baede4aa85ab3d2cbd",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/Instructions"
                    }
                },
                "size": 560
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "839340a2b902c8586fdd1529f1969ff08f0449cb",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/LICENSE"
                    }
                },
                "size": 1069
            },
            {
                "type": "code",
                "name": "README_Classification.md",
                "sha": "5a85905504ffda013683a5b53714c6dce583b61c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/README_Classification.md"
                    }
                },
                "size": 1976
            },
            {
                "type": "code",
                "name": "README_Detection.md",
                "sha": "2cb83906494af2218e4ece46d3127aeeca7fb095",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/README_Detection.md"
                    }
                },
                "size": 2742
            },
            {
                "type": "code",
                "name": "README_Segmentation.md",
                "sha": "b31511493570a26de77c72ad21117032258eaec9",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/README_Segmentation.md"
                    }
                },
                "size": 5498
            },
            {
                "type": "code",
                "name": "commons",
                "sha": "fdf021dd7f6ead0ac171a83d5531e841b9b15a55",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/tree/master/commons"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "data_loader",
                "sha": "98460662743b5c1f136a11c18a11b25d1766056f",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/tree/master/data_loader"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "detection_demo.py",
                "sha": "1fd8684337c36413cba3817ea3740da71abfccd5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/detection_demo.py"
                    }
                },
                "size": 9611
            },
            {
                "type": "code",
                "name": "images",
                "sha": "fabed00460de45a5f7495c4ea466aa116f3b5aa8",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/tree/master/images"
                    }
                },
                "num_files": 8
            },
            {
                "type": "code",
                "name": "loss_fns",
                "sha": "bb3718ef889c89cfb4bc6d5ceb95490e6284f7c7",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/tree/master/loss_fns"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "model",
                "sha": "bcdfdba94111837f4b8049b448be10b5711aed56",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/tree/master/model"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "nn_layers",
                "sha": "e480aa189533c22deb9582c1f88ede2c193941a1",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/tree/master/nn_layers"
                    }
                },
                "num_files": 9
            },
            {
                "type": "code",
                "name": "onnx_models",
                "sha": "d034bfccdc10cf3ca5a2dd0d6f3866711639e353",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/tree/master/onnx_models"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "ef7e7f2c7a8b1025edaad8937ac33883f786ed39",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/requirements.txt"
                    }
                },
                "size": 33
            },
            {
                "type": "code",
                "name": "sample_images",
                "sha": "8592bb559e1600bf7d3ab48f0014d372d7ef4ea8",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/tree/master/sample_images"
                    }
                },
                "num_files": 13
            },
            {
                "type": "code",
                "name": "segmentation_demo.py",
                "sha": "403ef45856d555e7bed75c94b09414295f07ec8b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/segmentation_demo.py"
                    }
                },
                "size": 6279
            },
            {
                "type": "code",
                "name": "test_classification.py",
                "sha": "c9f891532f89af064758851da960d349f3ce1c51",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/test_classification.py"
                    }
                },
                "size": 3553
            },
            {
                "type": "code",
                "name": "test_detection.py",
                "sha": "f66555efd579df9913bd5968def52b1b894ba79b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/test_detection.py"
                    }
                },
                "size": 6695
            },
            {
                "type": "code",
                "name": "test_segmentation.py",
                "sha": "e996d7c9bf1acf3d8e0e13111d294f6d2f59e97a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/test_segmentation.py"
                    }
                },
                "size": 8109
            },
            {
                "type": "code",
                "name": "train_classification.py",
                "sha": "a41f0a8ec0e88d8acbcbc52bf618063b4ff9da9f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/train_classification.py"
                    }
                },
                "size": 15483
            },
            {
                "type": "code",
                "name": "train_detection.py",
                "sha": "7693bb9c7518d90b932d95e4fb6b3b4470940009",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/train_detection.py"
                    }
                },
                "size": 13088
            },
            {
                "type": "code",
                "name": "train_segmentation.py",
                "sha": "519e39628bbb4205a1bd2471a9de284ebdcdb8e3",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/blob/master/train_segmentation.py"
                    }
                },
                "size": 16619
            },
            {
                "type": "code",
                "name": "transforms",
                "sha": "a9269d5d58148957e5b681d949c8d8a009267825",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/tree/master/transforms"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "utilities",
                "sha": "a349047c378f9a5028bcfb1ac4d56a37670f1e13",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/tree/master/utilities"
                    }
                },
                "num_files": 13
            },
            {
                "type": "code",
                "name": "vision_datasets",
                "sha": "82e3a754b6a0fcb238b03c0e47d05219fbf9cf89",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/sacmehta/EdgeNets/tree/master/vision_datasets"
                    }
                },
                "num_files": 1
            }
        ]
    },
    "authors": [
        {
            "name": "Sachin Mehta",
            "github_id": "sacmehta"
        },
        {
            "name": "Beibin Li",
            "github_id": "BeibinLi"
        },
        {
            "name": "Marcus Vinicius",
            "email": "marcus.costa@ccc.ufcg.edu.br",
            "github_id": "marcusvlc"
        }
    ],
    "tags": [
        "cnn",
        "cnn-classification",
        "object-detection",
        "semantic-segmentation",
        "mscoco",
        "cityscapes",
        "pascal-voc",
        "imagenet-dataset",
        "imagenet-classifier",
        "shufflenetv2",
        "espnetv2",
        "dicenet",
        "pytorch"
    ],
    "description": "This repository contains the source code of our work on designing efficient CNNs for computer vision",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/sacmehta/EdgeNets",
            "stars": 371,
            "issues": true,
            "readme": "# Efficient networks for Computer Vision\n\nThis repo contains source code of our work on designing efficient networks for different computer vision tasks: <span style=\"color:blue\"> (1) Image classification, (2) Object detection, and (3) Semantic segmentation.</span>\n\n<table>\n    <tr>\n        <td colspan=2 align=\"center\"><b>Real-time semantic segmentation using ESPNetv2 on iPhone7. See <a href=\"https://github.com/sacmehta/ESPNetv2-COREML\" target=\"_blank\">here</a> for iOS application source code using COREML.<b></td>\n    </tr>\n    <tr>\n        <td>\n            <img src=\"images/espnetv2_iphone7_video_1.gif\" alt=\"Seg demo on iPhone7\"></img>\n        </td>\n        <td>\n            <img src=\"images/espnetv2_iphone7_video_2.gif\" alt=\"Seg demo on iPhone7\"></img>\n        </td>\n    </tr>\n</table>\n\n<table>\n    <tr>\n        <td colspan=2 align=\"center\"><b>Real-time object detection using ESPNetv2<b></td>\n    </tr>\n    <tr>\n        <td colspan=2 align=\"center\">\n            <img src=\"images/espnetv2_detection_2.gif\" alt=\"Demo 1\"></img>\n        </td>\n    </tr>\n    <tr>\n        <td>\n            <img src=\"images/espnetv2_detection_1.gif\" alt=\"Demo 2\"></img>\n        </td>\n        <td>\n            <img src=\"images/espnetv2_detection_3.gif\" alt=\"Demo 3\"></img>\n        </td>\n    </tr>\n</table>\n\n    \n**Table of contents**\n 1. [Key highlihgts](#key-highlights)\n 2. [Supported networks](#supported-networks)\n 3. [Relevant papers](#relevant-papers)\n 4. [Blogs](#blogs)\n 5. [Performance comparison](#performance-comparison)\n 6. [Training receipe](#training-receipe)\n 7. [Instructions for segmentation and detection demos](#instructions-for-segmentation-and-detection-demos)\n 8. [Citation](#citation)\n 9. [License](#license)\n 10. [Acknowledgements](#acknowledgements)\n 11. [Contributions](#want-to-help-out)\n 12. [Notes](#notes)\n    \n## Key highlights\n * Object classification on the ImageNet and MS-COCO (multi-label)\n * Semantic Segmentation on the PASCAL VOC and the CityScapes\n * Object Detection on the PASCAL VOC and the MS-COCO\n * Supports PyTorch 1.0\n * Integrated with Tensorboard for easy visualization of training logs. \n * Scripts for downloading different datasets.\n * Semantic segmentation application using ESPNetv2 on iPhone can be found [here](https://github.com/sacmehta/ESPNetv2-COREML). \n\n## Supported networks\nThis repo supports following networks:\n * ESPNetv2 (Classification, Segmentation, Detection)\n * DiCENet (Classification, Segmentation, Detection)\n * ShuffleNetv2 (Classification)\n \n\n## Relevant papers\n * [ESPNet (ECCV'18)](https://arxiv.org/abs/1803.06815)\n * [ESPNetv2 (CVPR'19)](https://arxiv.org/abs/1811.11431)\n * [DiCENet (arxiv)](https://arxiv.org/pdf/1906.03516.pdf)\n \n## Blogs\n\n * [Faster Training for Efficient Networks](https://medium.com/p/faster-training-of-efficient-cnns-657953aa080?source=email-dc17ff22fa63--writer.postDistributed&sk=f60110289b6157de4c9e0c00c77f51e9)\n * [Semantic segmentation using ESPNetv2](https://medium.com/@sachinmehta.ngb/espnetv2-for-semantic-segmentation-9e80f155d522?source=friends_link&sk=91bca9326b088a972c170d1f7f5063e8)\n \n## Performance comparison\n\n### ImageNet\nBelow figure compares the performance of DiCENet with other efficient networks on the ImageNet dataset. DiCENet outperforms all existing efficient networks, including MobileNetv2 and ShuffleNetv2. More details [here](model/classification/model_zoo/README.md)\n\n![DiCENet performance on the ImageNet](/images/dicenet_imagenet.png)\n\n### Object detection\n\nBelow table compares the performance of our architecture with other detection networks on the MS-COCO dataset. Our network is fast and accurate. More details [here](model/detection/model_zoo/README.md)\n\n<table>\n    <tr>\n        <td></td>\n        <td colspan=3 align=\"center\"> <b>MSCOCO</b></td>\n    </tr>\n    <tr>\n        <td></td>\n        <td align=\"center\"> <b>Image Size</b> </td>\n        <td align=\"center\"> <b>FLOPs</b> </td>\n        <td align=\"center\"> <b>mIOU</b> </td>\n        <td align=\"center\"> <b>FPS</b> </td>\n    </tr>\n    <tr>\n        <td> SSD-VGG</td>\n        <td align=\"center\"> 512x512 </td>\n        <td align=\"center\"> 100 B</td>\n        <td align=\"center\"> 26.8 </td>\n        <td align=\"center\"> 19 </td>\n    </tr>\n    <tr>\n        <td> YOLOv2</td>\n        <td align=\"center\"> 544x544 </td>\n        <td align=\"center\"> 17.5 B</td>\n        <td align=\"center\"> 21.6 </td>\n        <td align=\"center\"> 40 </td>\n    </tr>\n    <tr>\n        <td> ESPNetv2-SSD (Ours) </td>\n        <td align=\"center\"> 512x512 </td>\n        <td align=\"center\"> 3.2 B</td>\n        <td align=\"center\"> 24.54 </td>\n        <td align=\"center\"> 35 </td>\n    </tr>\n</table>\n\n\n### Semantic Segmentation\n\nBelow figure compares the performance of ESPNet and ESPNetv2 on two different datasets. Note that ESPNets are one of the first efficient networks that delivers competitive performance to existing networks on the PASCAL VOC dataset, even with low resolution images say 256x256. See [here](model/segmentation/model_zoo/README.md) for more details.\n\n<table>\n    <tr>\n        <td></td>\n        <td colspan=3 align=\"center\"> <b>Cityscapes</b></td>\n        <td colspan=3 align=\"center\"> <b>PASCAL VOC 2012</b> </td>\n    </tr>\n    <tr>\n        <td></td>\n        <td align=\"center\"> <b>Image Size</b> </td>\n        <td align=\"center\"> <b>FLOPs</b> </td>\n        <td align=\"center\"> <b>mIOU</b> </td>\n        <td align=\"center\"> <b>Image</b> Size </td>\n        <td align=\"center\"> <b>FLOPs</b></td>\n        <td align=\"center\"> <b>mIOU</b> </td>\n    </tr>\n    <tr>\n        <td> ESPNet</td>\n        <td align=\"center\"> 1024x512 </td>\n        <td align=\"center\"> 4.5 B</td>\n        <td align=\"center\"> 60.3 </td>\n        <td align=\"center\"> 512x512 </td>\n        <td align=\"center\"> 2.2 B</td>\n        <td align=\"center\"> 63 </td>\n    </tr>\n    <tr>\n        <td> ESPNetv2</td>\n        <td align=\"center\"> 1024x512 </td>\n        <td align=\"center\"> 2.7 B</td>\n        <td align=\"center\"> <b>66.2</b> </td>\n        <td align=\"center\"> 384x384 </td>\n        <td align=\"center\"> 0.76 B</td>\n        <td align=\"center\"> <b>68</b> </td>\n    </tr>\n</table>\n\n## Training Receipe\n\n### Image Classification\nDetails about training and testing are provided [here](README_Classification.md).\n\nDetails about performance of different models are provided [here](model/classification/model_zoo/README.md).\n\n### Semantic segmentation\nDetails about training and testing are provided [here](README_Segmentation.md).\n\nDetails about performance of different models are provided [here](model/segmentation/model_zoo/README.md).\n\n\n### Object Detection\n\nDetails about training and testing are provided [here](README_Detection.md).\n\nDetails about performance of different models are provided [here](model/detection/model_zoo/README.md).\n\n## Instructions for segmentation and detection demos\n\nTo run the segmentation demo, just type:\n\n```\npython segmentation_demo.py\n```\n\nTo run the detection demo, run the following command:\n``` \npython detection_demo.py\n\nOR \n\npython detection_demo.py --live\n```\n\nFor other supported arguments, please see the corresponding files.\n\n\n## Citation\nIf you find this repository helpful, please feel free to cite our work:\n```\n@article{mehta2019dicenet,\nAuthor = {Sachin Mehta and Hannaneh Hajishirzi and Mohammad Rastegari},\nTitle = {DiCENet: Dimension-wise Convolutions for Efficient Networks},\nYear = {2020},\njournal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n}\n\n@inproceedings{mehta2018espnetv2,\n  title={ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network},\n  author={Mehta, Sachin and Rastegari, Mohammad and Shapiro, Linda and Hajishirzi, Hannaneh},\n  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},\n  year={2019}\n}\n\n@inproceedings{mehta2018espnet,\n  title={Espnet: Efficient spatial pyramid of dilated convolutions for semantic segmentation},\n  author={Mehta, Sachin and Rastegari, Mohammad and Caspi, Anat and Shapiro, Linda and Hajishirzi, Hannaneh},\n  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},\n  pages={552--568},\n  year={2018}\n}\n```\n\n## License\nBy downloading this software, you acknowledge that you agree to the terms and conditions given [here](License).\n\n\n## Acknowledgements\nMost of our object detection code is adapted from [SSD in pytorch](https://github.com/amdegroot/ssd.pytorch). We thank authors for such an amazing work.\n\n## Want to help out?\nThanks for your interest in our work :).\n\nOpen tasks that are interesting:\n * Tensorflow implementation. I kind of wanna do this but not getting enough time. If you are interested, drop a message and we can talk about it.\n * Optimizing the EESP and the DiceNet block at CUDA-level.\n * Optimize and port pretrained models across multiple mobile platforms, including Android.\n * Other thoughts are also welcome :).\n \n ## Notes\n \n ### Notes about DiCENet paper\n This repository contains DiCENet's source code in PyTorch only and you should be able to reproduce the results of v1/v2 of our arxiv paper. To reproduce the results of our T-PAMI paper, you need to incorporate [MobileNet tricks in Section 5.3](https://arxiv.org/pdf/1906.03516.pdf), which are currently not a part of this repository. \n",
            "readme_url": "https://github.com/sacmehta/EdgeNets",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "DiCENet: Dimension-wise Convolutions for Efficient Networks",
            "arxiv": "1906.03516",
            "year": 2019,
            "url": "http://arxiv.org/abs/1906.03516v3",
            "abstract": "We introduce a novel and generic convolutional unit, DiCE unit, that is built\nusing dimension-wise convolutions and dimension-wise fusion. The dimension-wise\nconvolutions apply light-weight convolutional filtering across each dimension\nof the input tensor while dimension-wise fusion efficiently combines these\ndimension-wise representations; allowing the DiCE unit to efficiently encode\nspatial and channel-wise information contained in the input tensor. The DiCE\nunit is simple and can be seamlessly integrated with any architecture to\nimprove its efficiency and performance. Compared to depth-wise separable\nconvolutions, the DiCE unit shows significant improvements across different\narchitectures. When DiCE units are stacked to build the DiCENet model, we\nobserve significant improvements over state-of-the-art models across various\ncomputer vision tasks including image classification, object detection, and\nsemantic segmentation. On the ImageNet dataset, the DiCENet delivers 2-4%\nhigher accuracy than state-of-the-art manually designed models (e.g.,\nMobileNetv2 and ShuffleNetv2). Also, DiCENet generalizes better to tasks (e.g.,\nobject detection) that are often used in resource-constrained devices in\ncomparison to state-of-the-art separable convolution-based efficient networks,\nincluding neural search-based methods (e.g., MobileNetv3 and MixNet. Our source\ncode in PyTorch is open-source and is available at\nhttps://github.com/sacmehta/EdgeNets/",
            "authors": [
                "Sachin Mehta",
                "Hannaneh Hajishirzi",
                "Mohammad Rastegari"
            ]
        },
        {
            "title": "ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation",
            "arxiv": "1803.06815",
            "year": 2018,
            "url": "http://arxiv.org/abs/1803.06815v3",
            "abstract": "We introduce a fast and efficient convolutional neural network, ESPNet, for\nsemantic segmentation of high resolution images under resource constraints.\nESPNet is based on a new convolutional module, efficient spatial pyramid (ESP),\nwhich is efficient in terms of computation, memory, and power. ESPNet is 22\ntimes faster (on a standard GPU) and 180 times smaller than the\nstate-of-the-art semantic segmentation network PSPNet, while its category-wise\naccuracy is only 8% less. We evaluated ESPNet on a variety of semantic\nsegmentation datasets including Cityscapes, PASCAL VOC, and a breast biopsy\nwhole slide image dataset. Under the same constraints on memory and\ncomputation, ESPNet outperforms all the current efficient CNN networks such as\nMobileNet, ShuffleNet, and ENet on both standard metrics and our newly\nintroduced performance metrics that measure efficiency on edge devices. Our\nnetwork can process high resolution images at a rate of 112 and 9 frames per\nsecond on a standard GPU and edge device, respectively.",
            "authors": [
                "Sachin Mehta",
                "Mohammad Rastegari",
                "Anat Caspi",
                "Linda Shapiro",
                "Hannaneh Hajishirzi"
            ]
        },
        {
            "title": "ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network",
            "arxiv": "1811.11431",
            "year": 2018,
            "url": "http://arxiv.org/abs/1811.11431v3",
            "abstract": "We introduce a light-weight, power efficient, and general purpose\nconvolutional neural network, ESPNetv2, for modeling visual and sequential\ndata. Our network uses group point-wise and depth-wise dilated separable\nconvolutions to learn representations from a large effective receptive field\nwith fewer FLOPs and parameters. The performance of our network is evaluated on\nfour different tasks: (1) object classification, (2) semantic segmentation, (3)\nobject detection, and (4) language modeling. Experiments on these tasks,\nincluding image classification on the ImageNet and language modeling on the\nPenTree bank dataset, demonstrate the superior performance of our method over\nthe state-of-the-art methods. Our network outperforms ESPNet by 4-5% and has\n2-4x fewer FLOPs on the PASCAL VOC and the Cityscapes dataset. Compared to\nYOLOv2 on the MS-COCO object detection, ESPNetv2 delivers 4.4% higher accuracy\nwith 6x fewer FLOPs. Our experiments show that ESPNetv2 is much more power\nefficient than existing state-of-the-art efficient methods including\nShuffleNets and MobileNets. Our code is open-source and available at\nhttps://github.com/sacmehta/ESPNetv2",
            "authors": [
                "Sachin Mehta",
                "Mohammad Rastegari",
                "Linda Shapiro",
                "Hannaneh Hajishirzi"
            ]
        },
        {
            "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "year": "2020",
            "title": "DiCENet: Dimension-wise Convolutions for Efficient Networks",
            "author": [
                "Mehta, Sachin",
                "Hajishirzi, Hannaneh",
                "Rastegari, Mohammad"
            ],
            "ENTRYTYPE": "article",
            "ID": "mehta2019dicenet",
            "authors": [
                "Mehta, Sachin",
                "Hajishirzi, Hannaneh",
                "Rastegari, Mohammad"
            ]
        },
        {
            "year": "2019",
            "booktitle": "Proceedings of the IEEE conference on computer vision and pattern recognition",
            "author": [
                "Mehta, Sachin",
                "Rastegari, Mohammad",
                "Shapiro, Linda",
                "Hajishirzi, Hannaneh"
            ],
            "title": "ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network",
            "ENTRYTYPE": "inproceedings",
            "ID": "mehta2018espnetv2",
            "authors": [
                "Mehta, Sachin",
                "Rastegari, Mohammad",
                "Shapiro, Linda",
                "Hajishirzi, Hannaneh"
            ]
        },
        {
            "year": "2018",
            "pages": "552--568",
            "booktitle": "Proceedings of the European Conference on Computer Vision (ECCV)",
            "author": [
                "Mehta, Sachin",
                "Rastegari, Mohammad",
                "Caspi, Anat",
                "Shapiro, Linda",
                "Hajishirzi, Hannaneh"
            ],
            "title": "Espnet: Efficient spatial pyramid of dilated convolutions for semantic segmentation",
            "ENTRYTYPE": "inproceedings",
            "ID": "mehta2018espnet",
            "authors": [
                "Mehta, Sachin",
                "Rastegari, Mohammad",
                "Caspi, Anat",
                "Shapiro, Linda",
                "Hajishirzi, Hannaneh"
            ]
        },
        {
            "title": "Faster Training for Efficient Networks",
            "url": "https://medium.com/p/faster-training-of-efficient-cnns-657953aa080?source=email-dc17ff22fa63--writer.postDistributed&sk=f60110289b6157de4c9e0c00c77f51e9"
        },
        {
            "title": "Semantic segmentation using ESPNetv2",
            "url": "https://medium.com/@sachinmehta.ngb/espnetv2-for-semantic-segmentation-9e80f155d522?source=friends_link&sk=91bca9326b088a972c170d1f7f5063e8"
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            },
            {
                "name": "MSCOCO"
            },
            {
                "name": "Cityscapes"
            },
            {
                "name": "PASCAL VOC 2012"
            },
            {
                "name": "MS-COCO"
            },
            {
                "name": "COCO"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999681308875337,
        "task": "Semantic Segmentation",
        "task_prob": 0.8063252213791965
    }
}
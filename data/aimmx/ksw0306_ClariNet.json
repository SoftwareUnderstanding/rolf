{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "ClariNet",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "ksw0306",
                "owner_type": "User",
                "name": "ClariNet",
                "url": "https://github.com/ksw0306/ClariNet",
                "stars": 279,
                "pushed_at": "2019-08-05 17:58:06+00:00",
                "created_at": "2018-11-07 04:37:15+00:00",
                "language": "Python",
                "description": "A Pytorch Implementation of ClariNet",
                "license": "MIT License",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "3e203246164a0cdb6041965de3db767411007fab",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ksw0306/ClariNet/blob/master/.gitignore"
                    }
                },
                "size": 54
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "c272c689959f615e1245037b06bb0d8e47f65f7c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ksw0306/ClariNet/blob/master/LICENSE"
                    }
                },
                "size": 1068
            },
            {
                "type": "code",
                "name": "data.py",
                "sha": "9e46b42ae38eab77be003980e28348e2c69af31a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ksw0306/ClariNet/blob/master/data.py"
                    }
                },
                "size": 5934
            },
            {
                "type": "code",
                "name": "loss.py",
                "sha": "b714c4b1c369b6ac66d8dc38e82d538345661fbb",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ksw0306/ClariNet/blob/master/loss.py"
                    }
                },
                "size": 1377
            },
            {
                "type": "code",
                "name": "modules.py",
                "sha": "5060546bcb26cec1179bf78bac80d0e1217fd967",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ksw0306/ClariNet/blob/master/modules.py"
                    }
                },
                "size": 5034
            },
            {
                "type": "code",
                "name": "preprocessing.py",
                "sha": "e3a7c70fa31f4c425c50dfbb74772ef014e4465a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ksw0306/ClariNet/blob/master/preprocessing.py"
                    }
                },
                "size": 3765
            },
            {
                "type": "code",
                "name": "synthesize.py",
                "sha": "be9e33eae89d31efaf2b40372ddc2261b075415c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ksw0306/ClariNet/blob/master/synthesize.py"
                    }
                },
                "size": 4842
            },
            {
                "type": "code",
                "name": "synthesize_student.py",
                "sha": "558bed5e0857434af9aee138a31166742eebb161",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ksw0306/ClariNet/blob/master/synthesize_student.py"
                    }
                },
                "size": 6623
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "8f76c59fda5d46428d0b1b3169fa4b3aa9b22be2",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ksw0306/ClariNet/blob/master/train.py"
                    }
                },
                "size": 10760
            },
            {
                "type": "code",
                "name": "train_student.py",
                "sha": "d634c6e21fe0bb40c86ff1c8551837923b52004f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ksw0306/ClariNet/blob/master/train_student.py"
                    }
                },
                "size": 17316
            },
            {
                "type": "code",
                "name": "wavenet.py",
                "sha": "9d57a6d141b26a2c93912a931110ff2b571bcf70",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ksw0306/ClariNet/blob/master/wavenet.py"
                    }
                },
                "size": 4513
            },
            {
                "type": "code",
                "name": "wavenet_iaf.py",
                "sha": "40665e1c58be6db40c3e5c0613a58755896c8a6f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ksw0306/ClariNet/blob/master/wavenet_iaf.py"
                    }
                },
                "size": 4366
            }
        ]
    },
    "authors": [
        {
            "name": "Sungwon Kim",
            "email": "ksw930306@gmail.com",
            "github_id": "ksw0306"
        },
        {
            "name": "Maria",
            "github_id": "MariaMsu"
        }
    ],
    "tags": [
        "clarinet",
        "wavenet",
        "parallel-wavenet",
        "pytorch"
    ],
    "description": "A Pytorch Implementation of ClariNet",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/ksw0306/ClariNet",
            "stars": 279,
            "issues": true,
            "readme": "# ClariNet\nA Pytorch Implementation of ClariNet (Mel Spectrogram --> Waveform)\n\n\n# Requirements\n\nPyTorch 0.4.1 & python 3.6 & Librosa\n\n# Examples\n\n#### Step 1. Download Dataset\n\n- LJSpeech : [https://keithito.com/LJ-Speech-Dataset/](https://keithito.com/LJ-Speech-Dataset/)\n\n#### Step 2. Preprocessing (Preparing Mel Spectrogram)\n\n`python preprocessing.py --in_dir ljspeech --out_dir DATASETS/ljspeech`\n\n#### Step 3. Train Gaussian Autoregressive WaveNet (Teacher)\n\n`python train.py --model_name wavenet_gaussian --batch_size 8 --num_blocks 2 --num_layers 10`\n\n#### Step 4. Synthesize (Teacher)\n\n`--load_step CHECKPOINT` : the # of the pre-trained *teacher* model's global training step (also depicted in the trained weight file)\n\n`python synthesize.py --model_name wavenet_gaussian --num_blocks 2 --num_layers 10 --load_step 10000 --num_samples 5`\n\n#### Step 5. Train Gaussian Inverse Autoregressive Flow (Student)\n\n`--teacher_name (YOUR TEACHER MODEL'S NAME)`\n\n`--teacher_load_step CHECKPOINT` : the # of the pre-trained *teacher* model's global training step (also depicted in the trained weight file)\n\n`--KL_type qp` : Reversed KL divegence KL(q||p)  or `--KL_type pq` : Forward KL divergence KL(p||q)\n\n`python train_student.py --model_name wavenet_gaussian_student --teacher_name wavenet_gaussian --teacher_load_step 10000 --batch_size 2 --num_blocks_t 2 --num_layers_t 10 --num_layers_s 10 --KL_type qp`\n\n#### Step 6. Synthesize (Student)\n\n`--model_name (YOUR STUDENT MODEL'S NAME)`\n\n`--load_step CHECKPOINT` : the # of the pre-trained *student* model's global training step (also depicted in the trained weight file)\n\n`--teacher_name (YOUR TEACHER MODEL'S NAME)`\n\n`--teacher_load_step CHECKPOINT` :  the # of the pre-trained *teacher* model's global training step (also depicted in the trained weight file)\n\n`python synthesize_student.py --model_name wavenet_gaussian_student --load_step 10000 --teacher_name wavenet_gaussian --teacher_load_step 10000 --num_blocks_t 2 --num_layers_t 10 --num_layers_s 10 --num_samples 5`\n\n# References\n\n- WaveNet vocoder : [https://github.com/r9y9/wavenet_vocoder](https://github.com/r9y9/wavenet_vocoder)\n- ClariNet : [https://arxiv.org/abs/1807.07281](https://arxiv.org/abs/1807.07281)\n",
            "readme_url": "https://github.com/ksw0306/ClariNet",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech",
            "arxiv": "1807.07281",
            "year": 2018,
            "url": "http://arxiv.org/abs/1807.07281v3",
            "abstract": "In this work, we propose a new solution for parallel wave generation by\nWaveNet. In contrast to parallel WaveNet (van den Oord et al., 2018), we\ndistill a Gaussian inverse autoregressive flow from the autoregressive WaveNet\nby minimizing a regularized KL divergence between their highly-peaked output\ndistributions. Our method computes the KL divergence in closed-form, which\nsimplifies the training algorithm and provides very efficient distillation. In\naddition, we introduce the first text-to-wave neural architecture for speech\nsynthesis, which is fully convolutional and enables fast end-to-end training\nfrom scratch. It significantly outperforms the previous pipeline that connects\na text-to-spectrogram model to a separately trained WaveNet (Ping et al.,\n2018). We also successfully distill a parallel waveform synthesizer conditioned\non the hidden representation in this end-to-end model.",
            "authors": [
                "Wei Ping",
                "Kainan Peng",
                "Jitong Chen"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "https://keithito.com/LJ-Speech-Dataset/",
                "connection": {
                    "name": "url",
                    "source": {
                        "url": "https://keithito.com/LJ-Speech-Dataset/"
                    }
                }
            }
        ]
    },
    "domain": {
        "domain_type": "Speech",
        "domain_prob": 0.9323139007211648
    }
}
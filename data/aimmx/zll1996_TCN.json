{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Keras TCN",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "zll1996",
                "owner_type": "User",
                "name": "TCN",
                "url": "https://github.com/zll1996/TCN",
                "stars": 0,
                "pushed_at": "2019-11-15 06:50:06+00:00",
                "created_at": "2019-11-15 06:49:33+00:00",
                "language": "Jupyter Notebook",
                "license": "MIT License",
                "frameworks": [
                    "Keras",
                    "scikit-learn"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "1878da6fda56553078e2207ac908b27c73deb84a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zll1996/TCN/blob/master/.gitignore"
                    }
                },
                "size": 1285
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "22ad4c3de5bda3657d57ab3c5499ee5393290806",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zll1996/TCN/blob/master/LICENSE"
                    }
                },
                "size": 1071
            },
            {
                "type": "code",
                "name": "misc",
                "sha": "71301da622c6ec165df8c4dd552ccff50b622336",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zll1996/TCN/tree/master/misc"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "d06a383841aa9992cfbb5908d9df899bced77ea7",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zll1996/TCN/blob/master/requirements.txt"
                    }
                },
                "size": 57
            },
            {
                "type": "code",
                "name": "setup.py",
                "sha": "11b676b881928243a6b9946fe1c22ae4e3b107cc",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zll1996/TCN/blob/master/setup.py"
                    }
                },
                "size": 392
            },
            {
                "type": "code",
                "name": "tasks",
                "sha": "b0d1fcf5abe934351b41a10fdc87ded6ba20a673",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zll1996/TCN/tree/master/tasks"
                    }
                },
                "num_files": 12
            },
            {
                "type": "code",
                "name": "tcn",
                "sha": "9fd364a860a26470da79ef2a502d4d62827b7f45",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zll1996/TCN/tree/master/tcn"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "tox.ini",
                "sha": "3aad82ed62d8d21972fd58ab3d21f354935b5d17",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zll1996/TCN/blob/master/tox.ini"
                    }
                },
                "size": 312
            }
        ]
    },
    "authors": [
        {
            "name": "Peter Somers",
            "github_id": "psomers3"
        },
        {
            "name": "Quentin Lemaire",
            "github_id": "qlemaire22"
        },
        {
            "name": "769176706",
            "github_id": "769176706"
        },
        {
            "name": "Travis Hoppe",
            "github_id": "thoppe"
        },
        {
            "name": "Xinyi Li",
            "github_id": "li-xin-yi"
        },
        {
            "name": "dependabot-preview[bot]",
            "github_id": "dependabot-preview[bot]"
        },
        {
            "name": "Andrew",
            "email": "muzikinae@gmail.com",
            "github_id": "Kismuz"
        },
        {
            "name": "nbertagnolli",
            "github_id": "nbertagnolli"
        },
        {
            "name": "Rodrigo Laguna",
            "email": "rodrigo.laguna@fing.edu.uy",
            "github_id": "rola93"
        }
    ],
    "tags": [],
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/zll1996/TCN",
            "stars": 0,
            "issues": true,
            "readme": "# Keras TCN\n\n\n[![Downloads](https://pepy.tech/badge/keras-tcn)](https://pepy.tech/project/keras-tcn)\n[![Downloads](https://pepy.tech/badge/keras-tcn/month)](https://pepy.tech/project/keras-tcn)\n```bash\npip install keras-tcn\n```\n\n*Keras Temporal Convolutional Network*\n\n   * [Keras TCN](#keras-tcn)\n      * [Why Temporal Convolutional Network?](#why-temporal-convolutional-network)\n      * [API](#api)\n         * [Arguments](#arguments)\n         * [Input shape](#input-shape)\n         * [Output shape](#output-shape)\n         * [Supported task types](#supported-task-types)\n         * [Receptive field](#receptive-field)\n         * [Non-causal TCN](#non-causal-tcn)\n      * [Installation (Python 3)](#installation-python-3)\n      * [Run](#run)\n      * [Tasks](#tasks)\n         * [Adding Task](#adding-task)\n            * [Explanation](#explanation)\n            * [Implementation results](#implementation-results)\n         * [Copy Memory Task](#copy-memory-task)\n            * [Explanation](#explanation-1)\n            * [Implementation results (first epochs)](#implementation-results-first-epochs)\n         * [Sequential MNIST](#sequential-mnist)\n            * [Explanation](#explanation-2)\n            * [Implementation results](#implementation-results-1)\n      * [References](#references)\n\n## Why Temporal Convolutional Network?\n\n- TCNs exhibit longer memory than recurrent architectures with the same capacity.\n- Constantly performs better than LSTM/GRU architectures on a vast range of tasks (Seq. MNIST, Adding Problem, Copy Memory, Word-level PTB...).\n- Parallelism, flexible receptive field size, stable gradients, low memory requirements for training, variable length inputs...\n\n<p align=\"center\">\n  <img src=\"misc/Dilated_Conv.png\">\n  <b>Visualization of a stack of dilated causal convolutional layers (Wavenet, 2016)</b><br><br>\n</p>\n\n## API\n\nThe usual way is to import the TCN layer and use it inside a Keras model. An example is provided below for a regression task (cf. `tasks/` for other examples):\n\n```python\nfrom keras.layers import Dense\nfrom keras.models import Input, Model\n\nfrom tcn import TCN\n\nbatch_size, timesteps, input_dim = None, 20, 1\n\n\ndef get_x_y(size=1000):\n    import numpy as np\n    pos_indices = np.random.choice(size, size=int(size // 2), replace=False)\n    x_train = np.zeros(shape=(size, timesteps, 1))\n    y_train = np.zeros(shape=(size, 1))\n    x_train[pos_indices, 0] = 1.0\n    y_train[pos_indices, 0] = 1.0\n    return x_train, y_train\n\n\ni = Input(batch_shape=(batch_size, timesteps, input_dim))\n\no = TCN(return_sequences=False)(i)  # The TCN layers are here.\no = Dense(1)(o)\n\nm = Model(inputs=[i], outputs=[o])\nm.compile(optimizer='adam', loss='mse')\n\nx, y = get_x_y()\nm.fit(x, y, epochs=10, validation_split=0.2)\n```\n\nIn the example above, TCNs can also be stacked together, like this:\n\n```python\no = TCN(return_sequences=True)(i)\no = TCN(return_sequences=False)(o)\n```\n\nA ready-to-use TCN model can be used that way (cf. `tasks/` for the full code):\n\n```python\nfrom tcn import compiled_tcn\n\nmodel = compiled_tcn(...)\nmodel.fit(x, y) # Keras model.\n```\n\n### Arguments\n\n`TCN(nb_filters=64, kernel_size=2, nb_stacks=1, dilations=[1, 2, 4, 8, 16, 32], padding='causal', use_skip_connections=True, dropout_rate=0.0, return_sequences=True, activation='linear', kernel_initializer='he_normal', use_batch_norm=False, **kwargs)`\n\n- `nb_filters`: Integer. The number of filters to use in the convolutional layers. Would be similar to `units` for LSTM.\n- `kernel_size`: Integer. The size of the kernel to use in each convolutional layer.\n- `dilations`: List. A dilation list. Example is: [1, 2, 4, 8, 16, 32, 64].\n- `nb_stacks`: Integer. The number of stacks of residual blocks to use.\n- `padding`: String. The padding to use in the convolutions. 'causal' for a causal network (as in the original implementation) and 'same' for a non-causal network.\n- `use_skip_connections`: Boolean. If we want to add skip connections from input to each residual block.\n- `return_sequences`: Boolean. Whether to return the last output in the output sequence, or the full sequence.\n- `dropout_rate`: Float between 0 and 1. Fraction of the input units to drop.\n- `activation`: The activation used in the residual blocks o = activation(x + F(x)).\n- `kernel_initializer`: Initializer for the kernel weights matrix (Conv1D).\n- `use_batch_norm`: Whether to use batch normalization in the residual layers or not.\n- `kwargs`: Any other arguments for configuring parent class Layer. For example \"name=str\", Name of the model. Use unique names when using multiple TCN.\n\n### Input shape\n\n3D tensor with shape `(batch_size, timesteps, input_dim)`.\n\n`timesteps` can be None. This can be useful if each sequence is of a different length: [Multiple Length Sequence Example](tasks/multi_length_sequences.py).\n\n### Output shape\n\n- if `return_sequences=True`: 3D tensor with shape `(batch_size, timesteps, nb_filters)`.\n- if `return_sequences=False`: 2D tensor with shape `(batch_size, nb_filters)`.\n\n### Supported task types\n\n- Regression (Many to one) e.g. adding problem\n- Classification (Many to many) e.g. copy memory task\n- Classification (Many to one) e.g. sequential mnist task\n\nFor a Many to Many regression, a cheap fix for now is to change the [number of units of the final Dense layer](https://github.com/philipperemy/keras-tcn/blob/8151b4a87f906fd856fd1c113c48392d542d0994/tcn/tcn.py#L90).\n\n### Receptive field\n\n- Receptive field = **nb_stacks_of_residuals_blocks * kernel_size * last_dilation**.\n- If a TCN has only one stack of residual blocks with a kernel size of 2 and dilations [1, 2, 4, 8], its receptive field is 2 * 1 * 8 = 16. The image below illustrates it:\n\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/40159126/41830054-10e56fda-7871-11e8-8591-4fa46680c17f.png\">\n  <b>ks = 2, dilations = [1, 2, 4, 8], 1 block</b><br><br>\n</p>\n\n- If the TCN has now 2 stacks of residual blocks, wou would get the situation below, that is, an increase in the receptive field to 32:\n\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/40159126/41830618-a8f82a8a-7874-11e8-9d4f-2ebb70a31465.jpg\">\n  <b>ks = 2, dilations = [1, 2, 4, 8], 2 blocks</b><br><br>\n</p>\n\n\n- If we increased the number of stacks to 3, the size of the receptive field would increase again, such as below:\n\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/40159126/41830628-ae6e73d4-7874-11e8-8ecd-cea37efa33f1.jpg\">\n  <b>ks = 2, dilations = [1, 2, 4, 8], 3 blocks</b><br><br>\n</p>\n\nThanks to [@alextheseal](https://github.com/alextheseal) for providing such visuals.\n\n### Non-causal TCN\n\nMaking the TCN architecture non-causal allows it to take the future into consideration to do its prediction as shown in the figure below.\n\nHowever, it is not anymore suitable for real-time applications.\n\n<p align=\"center\">\n  <img src=\"misc/Non_Causal.png\">\n  <b>Non-Causal TCN - ks = 3, dilations = [1, 2, 4, 8], 1 block</b><br><br>\n</p>\n\nTo use a non-causal TCN, specify `padding='valid'` or `padding='same'` when initializing the TCN layers.\n\nSpecial thanks to: [@qlemaire22](https://github.com/qlemaire22)\n\n## Installation (Python 3)\n\n```bash\ngit clone git@github.com:philipperemy/keras-tcn.git\ncd keras-tcn\nvirtualenv -p python3.6 venv\nsource venv/bin/activate\npip install -r requirements.txt # change to tensorflow if you dont have a gpu.\npip install . --upgrade # install it as a package.\n```\n\nNote: Only compatible with Python 3 at the moment. Should be almost compatible with python 2.\n\n## Run\n\nOnce `keras-tcn` is installed as a package, you can take a glimpse of what's possible to do with TCNs. Some tasks examples are  available in the repository for this purpose:\n\n```bash\ncd adding_problem/\npython main.py # run adding problem task\n\ncd copy_memory/\npython main.py # run copy memory task\n\ncd mnist_pixel/\npython main.py # run sequential mnist pixel task\n```\n\n## Tasks\n\n### Adding Task\n\nThe task consists of feeding a large array of decimal numbers to the network, along with a boolean array of the same length. The objective is to sum the two decimals where the boolean array contain the two 1s.\n\n#### Explanation\n\n<p align=\"center\">\n  <img src=\"misc/Adding_Task.png\">\n  <b>Adding Problem Task</b><br><br>\n</p>\n\n#### Implementation results\n\nThe model takes time to learn this task. It's symbolized by a very long plateau (could take ~8 epochs on some runs).\n\n```\n200000/200000 [==============================] - 293s 1ms/step - loss: 0.1731 - val_loss: 0.1662\n200000/200000 [==============================] - 289s 1ms/step - loss: 0.1675 - val_loss: 0.1665\n200000/200000 [==============================] - 287s 1ms/step - loss: 0.1670 - val_loss: 0.1665\n200000/200000 [==============================] - 288s 1ms/step - loss: 0.1668 - val_loss: 0.1669\n200000/200000 [==============================] - 285s 1ms/step - loss: 0.1085 - val_loss: 0.0019\n200000/200000 [==============================] - 285s 1ms/step - loss: 0.0011 - val_loss: 4.1667e-04\n200000/200000 [==============================] - 282s 1ms/step - loss: 6.0470e-04 - val_loss: 6.7708e-04\n200000/200000 [==============================] - 282s 1ms/step - loss: 4.3099e-04 - val_loss: 7.3898e-04\n200000/200000 [==============================] - 282s 1ms/step - loss: 3.9102e-04 - val_loss: 1.8727e-04\n200000/200000 [==============================] - 280s 1ms/step - loss: 3.1040e-04 - val_loss: 0.0010\n200000/200000 [==============================] - 281s 1ms/step - loss: 3.1166e-04 - val_loss: 2.2333e-04\n200000/200000 [==============================] - 281s 1ms/step - loss: 2.8046e-04 - val_loss: 1.5194e-04\n```\n\n### Copy Memory Task\n\nThe copy memory consists of a very large array:\n- At the beginning, there's the vector x of length N. This is the vector to copy.\n- At the end, N+1 9s are present. The first 9 is seen as a delimiter.\n- In the middle, only 0s are there.\n\nThe idea is to copy the content of the vector x to the end of the large array. The task is made sufficiently complex by increasing the number of 0s in the middle.\n\n#### Explanation\n\n<p align=\"center\">\n  <img src=\"misc/Copy_Memory_Task.png\">\n  <b>Copy Memory Task</b><br><br>\n</p>\n\n#### Implementation results (first epochs)\n\n```\n30000/30000 [==============================] - 30s 1ms/step - loss: 0.1174 - acc: 0.9586 - val_loss: 0.0370 - val_acc: 0.9859\n30000/30000 [==============================] - 26s 874us/step - loss: 0.0367 - acc: 0.9859 - val_loss: 0.0363 - val_acc: 0.9859\n30000/30000 [==============================] - 26s 852us/step - loss: 0.0361 - acc: 0.9859 - val_loss: 0.0358 - val_acc: 0.9859\n30000/30000 [==============================] - 26s 872us/step - loss: 0.0355 - acc: 0.9859 - val_loss: 0.0349 - val_acc: 0.9859\n30000/30000 [==============================] - 25s 850us/step - loss: 0.0339 - acc: 0.9864 - val_loss: 0.0291 - val_acc: 0.9881\n30000/30000 [==============================] - 26s 856us/step - loss: 0.0235 - acc: 0.9896 - val_loss: 0.0159 - val_acc: 0.9944\n30000/30000 [==============================] - 26s 872us/step - loss: 0.0169 - acc: 0.9929 - val_loss: 0.0125 - val_acc: 0.9966\n```\n\n### Sequential MNIST\n\n#### Explanation\n\nThe idea here is to consider MNIST images as 1-D sequences and feed them to the network. This task is particularly hard because sequences are 28*28 = 784 elements. In order to classify correctly, the network has to remember all the sequence. Usual LSTM are unable to perform well on this task.\n\n<p align=\"center\">\n  <img src=\"misc/Sequential_MNIST_Task.png\">\n  <b>Sequential MNIST</b><br><br>\n</p>\n\n#### Implementation results\n\n```\n60000/60000 [==============================] - 118s 2ms/step - loss: 0.2348 - acc: 0.9265 - val_loss: 0.1308 - val_acc: 0.9579\n60000/60000 [==============================] - 116s 2ms/step - loss: 0.0973 - acc: 0.9698 - val_loss: 0.0645 - val_acc: 0.9798\n[...]\n60000/60000 [==============================] - 112s 2ms/step - loss: 0.0075 - acc: 0.9978 - val_loss: 0.0547 - val_acc: 0.9894\n60000/60000 [==============================] - 111s 2ms/step - loss: 0.0093 - acc: 0.9968 - val_loss: 0.0585 - val_acc: 0.9895\n```\n\n## Testing\n\nTesting is based on Tox.\n\n```\npip install tox\ntox\n```\n\n## References\n- https://github.com/locuslab/TCN/ (TCN for Pytorch)\n- https://arxiv.org/pdf/1803.01271.pdf (An Empirical Evaluation of Generic Convolutional and Recurrent Networks\nfor Sequence Modeling)\n- https://arxiv.org/pdf/1609.03499.pdf (Original Wavenet paper)\n\n## Useful links\n- https://github.com/Baichenjia/Tensorflow-TCN (Tensorflow Eager implementation of TCNs)\n\n",
            "readme_url": "https://github.com/zll1996/TCN",
            "frameworks": [
                "Keras",
                "scikit-learn"
            ]
        }
    ],
    "references": [
        {
            "title": "WaveNet: A Generative Model for Raw Audio",
            "arxiv": "1609.03499",
            "year": 2016,
            "url": "http://arxiv.org/abs/1609.03499v2",
            "abstract": "This paper introduces WaveNet, a deep neural network for generating raw audio\nwaveforms. The model is fully probabilistic and autoregressive, with the\npredictive distribution for each audio sample conditioned on all previous ones;\nnonetheless we show that it can be efficiently trained on data with tens of\nthousands of samples per second of audio. When applied to text-to-speech, it\nyields state-of-the-art performance, with human listeners rating it as\nsignificantly more natural sounding than the best parametric and concatenative\nsystems for both English and Mandarin. A single WaveNet can capture the\ncharacteristics of many different speakers with equal fidelity, and can switch\nbetween them by conditioning on the speaker identity. When trained to model\nmusic, we find that it generates novel and often highly realistic musical\nfragments. We also show that it can be employed as a discriminative model,\nreturning promising results for phoneme recognition.",
            "authors": [
                "Aaron van den Oord",
                "Sander Dieleman",
                "Heiga Zen",
                "Karen Simonyan",
                "Oriol Vinyals",
                "Alex Graves",
                "Nal Kalchbrenner",
                "Andrew Senior",
                "Koray Kavukcuoglu"
            ]
        },
        {
            "title": "An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling",
            "arxiv": "1803.01271",
            "year": 2018,
            "url": "http://arxiv.org/abs/1803.01271v2",
            "abstract": "For most deep learning practitioners, sequence modeling is synonymous with\nrecurrent networks. Yet recent results indicate that convolutional\narchitectures can outperform recurrent networks on tasks such as audio\nsynthesis and machine translation. Given a new sequence modeling task or\ndataset, which architecture should one use? We conduct a systematic evaluation\nof generic convolutional and recurrent architectures for sequence modeling. The\nmodels are evaluated across a broad range of standard tasks that are commonly\nused to benchmark recurrent networks. Our results indicate that a simple\nconvolutional architecture outperforms canonical recurrent networks such as\nLSTMs across a diverse range of tasks and datasets, while demonstrating longer\neffective memory. We conclude that the common association between sequence\nmodeling and recurrent networks should be reconsidered, and convolutional\nnetworks should be regarded as a natural starting point for sequence modeling\ntasks. To assist related work, we have made code available at\nhttp://github.com/locuslab/TCN .",
            "authors": [
                "Shaojie Bai",
                "J. Zico Kolter",
                "Vladlen Koltun"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "MNIST"
            },
            {
                "name": "Sequential MNIST"
            }
        ]
    },
    "domain": {
        "domain_type": "Speech",
        "domain_prob": 0.9519799429751397
    }
}
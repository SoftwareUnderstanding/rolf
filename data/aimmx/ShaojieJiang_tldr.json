{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "This is the official repository for the paper TLDR: Token Loss Dynamic Reweighting for Reducing Repetitive Utterance Generation.",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "ShaojieJiang",
                "owner_type": "User",
                "name": "tldr",
                "url": "https://github.com/ShaojieJiang/tldr",
                "stars": 10,
                "pushed_at": "2020-04-08 15:11:05+00:00",
                "created_at": "2020-03-15 08:25:21+00:00",
                "language": "Python",
                "description": "Source code repo for paper \"TLDR: Token Loss Dynamic Reweighting for Reducing Repetitive Utterance Generation\"",
                "license": "MIT License",
                "frameworks": [
                    "NLTK",
                    "scikit-learn",
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".circleci",
                "sha": "f6ea728787444257739f33e3ed8a3681eeda81b3",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/tree/master/.circleci"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": ".coveragerc",
                "sha": "7608429465ac6912759d067dda44245ffa5397c5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/.coveragerc"
                    }
                },
                "size": 148
            },
            {
                "type": "code",
                "name": ".flake8",
                "sha": "012d35fdb4b7008d26534a527efee02517ecd440",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/.flake8"
                    }
                },
                "size": 223
            },
            {
                "type": "code",
                "name": ".github",
                "sha": "99df6305a60e4088e9c1a9f0d033cfb0c787169f",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/tree/master/.github"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "12790110650220e16f5c58a7c05d4c2f1f1b5bab",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/.gitignore"
                    }
                },
                "size": 1532
            },
            {
                "type": "code",
                "name": ".pre-commit-config.yaml",
                "sha": "b9a75affdb41a96fd71f4dc663f3c178f0ad171f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/.pre-commit-config.yaml"
                    }
                },
                "size": 124
            },
            {
                "type": "code",
                "name": "CODE_OF_CONDUCT.md",
                "sha": "ac52b65b55d431a398939a1d95b6faecf7988f7c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/CODE_OF_CONDUCT.md"
                    }
                },
                "size": 245
            },
            {
                "type": "code",
                "name": "CONTRIBUTING.md",
                "sha": "5ecd4e912b9d14706bbb7257859900c400250e97",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/CONTRIBUTING.md"
                    }
                },
                "size": 2179
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "b96dcb0480a0b0be0727976e5202a1e7b23edc3f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/LICENSE"
                    }
                },
                "size": 1086
            },
            {
                "type": "code",
                "name": "MANIFEST.in",
                "sha": "28ed1a8754364ce5e9c956f44a3c655676fdba41",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/MANIFEST.in"
                    }
                },
                "size": 191
            },
            {
                "type": "code",
                "name": "NEWS.md",
                "sha": "30ccdf08dcd60f76b67c9c9c3cbd6f3ea49ce5ba",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/NEWS.md"
                    }
                },
                "size": 8583
            },
            {
                "type": "code",
                "name": "autoformat.sh",
                "sha": "1586a1d143608c85ae9a6970166244dec1350180",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/autoformat.sh"
                    }
                },
                "size": 4592
            },
            {
                "type": "code",
                "name": "codecov.yml",
                "sha": "bb383e0ac268b506309b122e238512083bb1cec1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/codecov.yml"
                    }
                },
                "size": 69
            },
            {
                "type": "code",
                "name": "docs",
                "sha": "c95ce1063f8c0b6eaec76f6eb843464c01a7d1af",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/tree/master/docs"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "example_parlai_internal",
                "sha": "701acca9a2339d09d3a3403431cea10b95ff8734",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/tree/master/example_parlai_internal"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "examples",
                "sha": "d9d80c464b8601e6e209b1875fce23a1a4a767aa",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/tree/master/examples"
                    }
                },
                "num_files": 13
            },
            {
                "type": "code",
                "name": "mypy.ini",
                "sha": "d0e19a85faeca7352b27d8772cff9397f4c70246",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/mypy.ini"
                    }
                },
                "size": 112
            },
            {
                "type": "code",
                "name": "parlai",
                "sha": "2182814f6db7f3c4a2cc7cc36434234c74a1353b",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/tree/master/parlai"
                    }
                },
                "num_files": 10
            },
            {
                "type": "code",
                "name": "projects",
                "sha": "f13f0b32fde350fb571a24dfe070d8fdda0c0f19",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/tree/master/projects"
                    }
                },
                "num_files": 23
            },
            {
                "type": "code",
                "name": "pyproject.toml",
                "sha": "68f3177bf2e695651adfe1cfe69bad15943e7e45",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/pyproject.toml"
                    }
                },
                "size": 190
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "d15fb8481c96f0d9ecf47de029b968578fd9dffe",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/requirements.txt"
                    }
                },
                "size": 497
            },
            {
                "type": "code",
                "name": "setup.py",
                "sha": "a05984961fc5f7547a41b4526216aa1b66ed8a4c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/blob/master/setup.py"
                    }
                },
                "size": 1059
            },
            {
                "type": "code",
                "name": "tests",
                "sha": "48db912295fae56dc01780cf6541e86112c67895",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/tree/master/tests"
                    }
                },
                "num_files": 33
            },
            {
                "type": "code",
                "name": "website",
                "sha": "b66523a5be35964488e8dc277b04ef467f29238b",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ShaojieJiang/tldr/tree/master/website"
                    }
                },
                "num_files": 6
            }
        ]
    },
    "authors": [
        {
            "name": "Shaojie Jiang",
            "github_id": "ShaojieJiang"
        }
    ],
    "tags": [],
    "description": "Source code repo for paper \"TLDR: Token Loss Dynamic Reweighting for Reducing Repetitive Utterance Generation\"",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/ShaojieJiang/tldr",
            "stars": 10,
            "issues": true,
            "readme": "This is the official repository for the paper [TLDR: Token Loss Dynamic Reweighting for Reducing Repetitive Utterance Generation](https://arxiv.org/abs/2003.11963).\nAuthors: [Shaojie Jiang](https://shaojiejiang.github.io/), [Thomas Wolf](https://thomwolf.io/),\n[Christof Monz](https://staff.science.uva.nl/c.monz/) and [Maarten de Rijke](https://staff.fnwi.uva.nl/m.derijke/).\n\nOur work is build upon [Facebook ParlAI](https://github.com/facebookresearch/ParlAI/).\n\nMain features:\n* Training with LDR loss function proposed in our [TLDR paper](https://arxiv.org/abs/2003.11963).\n* Training with Focal Loss introduced in [Focal loss for dense object detection](https://arxiv.org/abs/1708.02002).\n* Seq2seq model with pre attention introduced in our [TLDR paper](https://arxiv.org/abs/2003.11963).\n* A DIversity Metric based on N-grams (DIMEN) for corpus- and sentence-level diversity (a.k.a. sentence-level repetition).\n* Weighted L2-norm (WL2) score for corpus-level repetition.\n\nPlease see below for corresponding training examples.\n\n## Requirements\n```angular2\nPython 3.7\nPyTorch 1.3.1\n```\n\n## Install\n\n```bash\ngit clone https://github.com/ShaojieJiang/tldr.git ~/tldr\ncd ~/tldr; python setup.py develop\n```\n\n## Examples\n\n\nThe following command trains a transformer model with TLDR loss by default,\non the DailyDialog dataset:\n```bash\npython examples/train_model.py -m transformer/generator -t dailydialog\n```\n\nWith arguments `--weight-level sequence` and `--weight-func fl`, you can then\ntrain a model using sequence-level weighting and Focal Loss, respectively.\n\nFor using our proposed Seq2seq with pre attention, please specify\n`-m seq2seq` and add argument `--attention-time pre`.\n\n> :information_source: Our implementation of pre-attention is different than\n> that implemented in the original ParlAI framework.\n\n## Documentation\n\nPlease refer to the official [ParlAI website](https://parl.ai/) for a through documentation if you are unfamiliar with ParlAI.\n\n## Support\n\nIf you have any questions or bug reports with regard to the features \nmentioned above, feel free to create a new issue on our\n[Issues page](https://github.com/ShaojieJiang/tldr/issues),\nor contact [Shaojie Jiang](https://shaojiejiang.github.io/) via the email address provided in our [paper](https://arxiv.org/abs/2003.11963).\n\nFor other questions related to the ParlAI framework, please refer to\nthe [original repository](https://github.com/facebookresearch/ParlAI).\n\n## Citation\n\nIf you use the features provided in this repo, please cite our [paper](https://arxiv.org/abs/2003.11963):\n```\n@article{jiang2020tldr,\n author = {Jiang, Shaojie and Wolf, Thomas and Monz, Christof and de Rijke, Maarten},\n journal = {arXiv preprint arXiv:2003.11963},\n title = {TLDR: Token Loss Dynamic Reweighting for Reducing Repetitive Utterance Generation},\n year = {2020}\n}\n```\nand the [ParlAI paper](https://arxiv.org/abs/1705.06476):\n\n```\n@article{miller2017parlai,\n  title={ParlAI: A Dialog Research Software Platform},\n  author={{Miller}, A.~H. and {Feng}, W. and {Fisch}, A. and {Lu}, J. and {Batra}, D. and {Bordes}, A. and {Parikh}, D. and {Weston}, J.},\n  journal={arXiv preprint arXiv:{1705.06476}},\n  year={2017}\n}\n```\n\n## License\nParlAI is MIT licensed. See the LICENSE file for details.\n",
            "readme_url": "https://github.com/ShaojieJiang/tldr",
            "frameworks": [
                "NLTK",
                "scikit-learn",
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Focal Loss for Dense Object Detection",
            "arxiv": "1708.02002",
            "year": 2017,
            "url": "http://arxiv.org/abs/1708.02002v2",
            "abstract": "The highest accuracy object detectors to date are based on a two-stage\napproach popularized by R-CNN, where a classifier is applied to a sparse set of\ncandidate object locations. In contrast, one-stage detectors that are applied\nover a regular, dense sampling of possible object locations have the potential\nto be faster and simpler, but have trailed the accuracy of two-stage detectors\nthus far. In this paper, we investigate why this is the case. We discover that\nthe extreme foreground-background class imbalance encountered during training\nof dense detectors is the central cause. We propose to address this class\nimbalance by reshaping the standard cross entropy loss such that it\ndown-weights the loss assigned to well-classified examples. Our novel Focal\nLoss focuses training on a sparse set of hard examples and prevents the vast\nnumber of easy negatives from overwhelming the detector during training. To\nevaluate the effectiveness of our loss, we design and train a simple dense\ndetector we call RetinaNet. Our results show that when trained with the focal\nloss, RetinaNet is able to match the speed of previous one-stage detectors\nwhile surpassing the accuracy of all existing state-of-the-art two-stage\ndetectors. Code is at: https://github.com/facebookresearch/Detectron.",
            "authors": [
                "Tsung-Yi Lin",
                "Priya Goyal",
                "Ross Girshick",
                "Kaiming He",
                "Piotr Doll\u00e1r"
            ]
        },
        {
            "title": "ParlAI: A Dialog Research Software Platform",
            "arxiv": "1705.06476",
            "year": 2017,
            "url": "http://arxiv.org/abs/1705.06476v4",
            "abstract": "We introduce ParlAI (pronounced \"par-lay\"), an open-source software platform\nfor dialog research implemented in Python, available at http://parl.ai. Its\ngoal is to provide a unified framework for sharing, training and testing of\ndialog models, integration of Amazon Mechanical Turk for data collection, human\nevaluation, and online/reinforcement learning; and a repository of machine\nlearning models for comparing with others' models, and improving upon existing\narchitectures. Over 20 tasks are supported in the first release, including\npopular datasets such as SQuAD, bAbI tasks, MCTest, WikiQA, QACNN, QADailyMail,\nCBT, bAbI Dialog, Ubuntu, OpenSubtitles and VQA. Several models are integrated,\nincluding neural models such as memory networks, seq2seq and attentive LSTMs.",
            "authors": [
                "Alexander H. Miller",
                "Will Feng",
                "Adam Fisch",
                "Jiasen Lu",
                "Dhruv Batra",
                "Antoine Bordes",
                "Devi Parikh",
                "Jason Weston"
            ]
        },
        {
            "title": "TLDR: Token Loss Dynamic Reweighting for Reducing Repetitive Utterance Generation",
            "arxiv": "2003.11963",
            "year": 2020,
            "url": "http://arxiv.org/abs/2003.11963v2",
            "abstract": "Natural Language Generation (NLG) models are prone to generating repetitive\nutterances. In this work, we study the repetition problem for encoder-decoder\nmodels, using both recurrent neural network (RNN) and transformer\narchitectures. To this end, we consider the chit-chat task, where the problem\nis more prominent than in other tasks that need encoder-decoder architectures.\nWe first study the influence of model architectures. By using pre-attention and\nhighway connections for RNNs, we manage to achieve lower repetition rates.\nHowever, this method does not generalize to other models such as transformers.\nWe hypothesize that the deeper reason is that in the training corpora, there\nare hard tokens that are more difficult for a generative model to learn than\nothers and, once learning has finished, hard tokens are still under-learned, so\nthat repetitive generations are more likely to happen. Based on this\nhypothesis, we propose token loss dynamic reweighting (TLDR) that applies\ndifferentiable weights to individual token losses. By using higher weights for\nhard tokens and lower weights for easy tokens, NLG models are able to learn\nindividual tokens at different paces. Experiments on chit-chat benchmark\ndatasets show that TLDR is more effective in repetition reduction for both RNN\nand transformer architectures than baselines using different weighting\nfunctions.",
            "authors": [
                "Shaojie Jiang",
                "Thomas Wolf",
                "Christof Monz",
                "Maarten de Rijke"
            ]
        },
        {
            "year": "2017",
            "journal": "arXiv preprint arXiv:{1705.06476}",
            "author": [
                "{Miller}, A.~H.",
                "{Feng}, W.",
                "{Fisch}, A.",
                "{Lu}, J.",
                "{Batra}, D.",
                "{Bordes}, A.",
                "{Parikh}, D.",
                "{Weston}, J."
            ],
            "title": "ParlAI: A Dialog Research Software Platform",
            "ENTRYTYPE": "article",
            "ID": "miller2017parlai",
            "authors": [
                "{Miller}, A.~H.",
                "{Feng}, W.",
                "{Fisch}, A.",
                "{Lu}, J.",
                "{Batra}, D.",
                "{Bordes}, A.",
                "{Parikh}, D.",
                "{Weston}, J."
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "DailyDialog"
            },
            {
                "name": "SQuAD"
            },
            {
                "name": "WikiQA"
            },
            {
                "name": "Amazon"
            },
            {
                "name": "bAbi"
            }
        ]
    },
    "domain": {
        "domain_type": "Natural Language Processing",
        "domain_prob": 0.9394567373774149,
        "task": "Machine Translation",
        "task_prob": 0.9501793731353466
    }
}
{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "WaveRNN",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "fatchord",
                "owner_type": "User",
                "name": "WaveRNN",
                "url": "https://github.com/fatchord/WaveRNN",
                "stars": 1698,
                "pushed_at": "2022-03-02 02:56:51+00:00",
                "created_at": "2018-03-16 14:03:52+00:00",
                "language": "Python",
                "description": "WaveRNN Vocoder + TTS",
                "license": "MIT License",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitattributes",
                "sha": "327ba52a0eefacdcd8ce408556858f640b11b328",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/blob/master/.gitattributes"
                    }
                },
                "size": 32
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "c7c9c68dd3f6ba04f44e2c74d25e7b70bbf397e6",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/blob/master/.gitignore"
                    }
                },
                "size": 494
            },
            {
                "type": "code",
                "name": "LICENSE.txt",
                "sha": "dd5a327d8228bb6049b2f4f35f0477cc6afd8fde",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/blob/master/LICENSE.txt"
                    }
                },
                "size": 1095
            },
            {
                "type": "code",
                "name": "assets",
                "sha": "89a9bda543f19f08eafeeeadc50eec51a9f57dd5",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/tree/master/assets"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "gen_tacotron.py",
                "sha": "a96881cebd2e567d1fde2dce51cca3f0b164d41b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/blob/master/gen_tacotron.py"
                    }
                },
                "size": 7192
            },
            {
                "type": "code",
                "name": "gen_wavernn.py",
                "sha": "a58a408e14c8674cdd22d7cd47efbd1e333b4b5a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/blob/master/gen_wavernn.py"
                    }
                },
                "size": 5559
            },
            {
                "type": "code",
                "name": "hparams.py",
                "sha": "fe898c8d6138c7752ef545b07dee2b830e56bd29",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/blob/master/hparams.py"
                    }
                },
                "size": 4234
            },
            {
                "type": "code",
                "name": "models",
                "sha": "da07a03b6440d52fbb2cfe9cfaebe3b5c7ab8c2c",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/tree/master/models"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "notebooks",
                "sha": "e0de55cbc3ee623f8176b668083f76d1ec4e9b2a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/tree/master/notebooks"
                    }
                },
                "num_files": 10
            },
            {
                "type": "code",
                "name": "preprocess.py",
                "sha": "fa9a9a1316656601cd2a3a632d35839bc57eb903",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/blob/master/preprocess.py"
                    }
                },
                "size": 3160
            },
            {
                "type": "code",
                "name": "pretrained",
                "sha": "f45713db3bc2dde382139de794b228ac49db2c60",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/tree/master/pretrained"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "quick_start.py",
                "sha": "07583678f9b61601e05040d27210a3b06ba9c4a2",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/blob/master/quick_start.py"
                    }
                },
                "size": 4707
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "aa7140a6b298e61277aa4c22b50fc4a7a44db27d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/blob/master/requirements.txt"
                    }
                },
                "size": 62
            },
            {
                "type": "code",
                "name": "sentences.txt",
                "sha": "c91b86a864caa4431b5d4f0078e202c755ac8501",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/blob/master/sentences.txt"
                    }
                },
                "size": 442
            },
            {
                "type": "code",
                "name": "train_tacotron.py",
                "sha": "0976751bd7b51a1ba991d95b4db8f16a26252024",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/blob/master/train_tacotron.py"
                    }
                },
                "size": 7541
            },
            {
                "type": "code",
                "name": "train_wavernn.py",
                "sha": "1acb1fdf2a6028884dcbced3c2c85b67af7d710d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/blob/master/train_wavernn.py"
                    }
                },
                "size": 6132
            },
            {
                "type": "code",
                "name": "utils",
                "sha": "81e55a319ca7e69c04b8f8955866428d03c434e1",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/fatchord/WaveRNN/tree/master/utils"
                    }
                },
                "num_files": 9
            }
        ]
    },
    "authors": [
        {
            "name": "Ollie McCarthy",
            "email": "fatchord@tutanota.com",
            "github_id": "fatchord"
        },
        {
            "name": "Ryan Butler",
            "email": "thebutlah@gmail.com",
            "github_id": "TheButlah"
        },
        {
            "name": "Mazzy Star",
            "email": "myfancoo@qq.com",
            "github_id": "mazzzystar"
        },
        {
            "name": "Sih S\u00eeng-h\u00f4ng\u859b\u4e1e\u5b8f",
            "github_id": "sih4sing5hong5"
        }
    ],
    "tags": [
        "wavernn",
        "pytorch",
        "neural-vocoder",
        "speech-synthesis",
        "tts",
        "tacotron",
        "text-to-speech"
    ],
    "description": "WaveRNN Vocoder + TTS",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/fatchord/WaveRNN",
            "stars": 1698,
            "issues": true,
            "readme": "# WaveRNN\n\n##### (Update: Vanilla Tacotron One TTS system just implemented - more coming soon!)\n\n![Tacotron with WaveRNN diagrams](assets/tacotron_wavernn.png)\n\nPytorch implementation of Deepmind's WaveRNN model from [Efficient Neural Audio Synthesis](https://arxiv.org/abs/1802.08435v1)\n\n# Installation\n\nEnsure you have:\n\n* Python >= 3.6\n* [Pytorch 1 with CUDA](https://pytorch.org/)\n\nThen install the rest with pip:\n\n> pip install -r requirements.txt\n\n# How to Use\n\n### Quick Start\n\nIf you want to use TTS functionality immediately you can simply use:\n\n> python quick_start.py\n\nThis will generate everything in the default sentences.txt file and output to a new 'quick_start' folder where you can playback the wav files and take a look at the attention plots\n\nYou can also use that script to generate custom tts sentences and/or use '-u' to generate unbatched (better audio quality):\n\n> python quick_start.py -u --input_text \"What will happen if I run this command?\"\n\n\n### Training your own Models\n![Attenion and Mel Training GIF](assets/training_viz.gif)\n\nDownload the [LJSpeech](https://keithito.com/LJ-Speech-Dataset/) Dataset.\n\nEdit **hparams.py**, point **wav_path** to your dataset and run:\n\n> python preprocess.py\n\nor use preprocess.py --path to point directly to the dataset\n___\n\nHere's my recommendation on what order to run things:\n\n1 - Train Tacotron with:\n\n> python train_tacotron.py\n\n2 - You can leave that finish training or at any point you can use:\n\n> python train_tacotron.py --force_gta\n\nthis will force tactron to create a GTA dataset even if it hasn't finish training.\n\n3 - Train WaveRNN with:\n\n> python train_wavernn.py --gta\n\nNB: You can always just run train_wavernn.py without --gta if you're not interested in TTS.\n\n4 - Generate Sentences with both models using:\n\n> python gen_tacotron.py wavernn\n\nthis will generate default sentences. If you want generate custom sentences you can use\n\n> python gen_tacotron.py --input_text \"this is whatever you want it to be\" wavernn\n\nAnd finally, you can always use --help on any of those scripts to see what options are available :)\n\n\n\n# Samples\n\n[Can be found here.](https://fatchord.github.io/model_outputs/)\n\n# Pretrained Models\n\nCurrently there are two pretrained models available in the /pretrained/ folder':\n\nBoth are trained on LJSpeech\n\n* WaveRNN (Mixture of Logistics output) trained to 800k steps\n* Tacotron trained to 180k steps\n\n____\n\n### References\n\n* [Efficient Neural Audio Synthesis](https://arxiv.org/abs/1802.08435v1)\n* [Tacotron: Towards End-to-End Speech Synthesis](https://arxiv.org/abs/1703.10135)\n* [Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions](https://arxiv.org/abs/1712.05884)\n\n### Acknowlegements\n\n* [https://github.com/keithito/tacotron](https://github.com/keithito/tacotron)\n* [https://github.com/r9y9/wavenet_vocoder](https://github.com/r9y9/wavenet_vocoder)\n* Special thanks to github users [G-Wang](https://github.com/G-Wang), [geneing](https://github.com/geneing) & [erogol](https://github.com/erogol)\n",
            "readme_url": "https://github.com/fatchord/WaveRNN",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Efficient Neural Audio Synthesis",
            "arxiv": "1802.08435",
            "year": 2018,
            "url": "http://arxiv.org/abs/1802.08435v2",
            "abstract": "Sequential models achieve state-of-the-art results in audio, visual and\ntextual domains with respect to both estimating the data distribution and\ngenerating high-quality samples. Efficient sampling for this class of models\nhas however remained an elusive problem. With a focus on text-to-speech\nsynthesis, we describe a set of general techniques for reducing sampling time\nwhile maintaining high output quality. We first describe a single-layer\nrecurrent neural network, the WaveRNN, with a dual softmax layer that matches\nthe quality of the state-of-the-art WaveNet model. The compact form of the\nnetwork makes it possible to generate 24kHz 16-bit audio 4x faster than real\ntime on a GPU. Second, we apply a weight pruning technique to reduce the number\nof weights in the WaveRNN. We find that, for a constant number of parameters,\nlarge sparse networks perform better than small dense networks and this\nrelationship holds for sparsity levels beyond 96%. The small number of weights\nin a Sparse WaveRNN makes it possible to sample high-fidelity audio on a mobile\nCPU in real time. Finally, we propose a new generation scheme based on\nsubscaling that folds a long sequence into a batch of shorter sequences and\nallows one to generate multiple samples at once. The Subscale WaveRNN produces\n16 samples per step without loss of quality and offers an orthogonal method for\nincreasing sampling efficiency.",
            "authors": [
                "Nal Kalchbrenner",
                "Erich Elsen",
                "Karen Simonyan",
                "Seb Noury",
                "Norman Casagrande",
                "Edward Lockhart",
                "Florian Stimberg",
                "Aaron van den Oord",
                "Sander Dieleman",
                "Koray Kavukcuoglu"
            ]
        },
        {
            "title": "Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions",
            "arxiv": "1712.05884",
            "year": 2017,
            "url": "http://arxiv.org/abs/1712.05884v2",
            "abstract": "This paper describes Tacotron 2, a neural network architecture for speech\nsynthesis directly from text. The system is composed of a recurrent\nsequence-to-sequence feature prediction network that maps character embeddings\nto mel-scale spectrograms, followed by a modified WaveNet model acting as a\nvocoder to synthesize timedomain waveforms from those spectrograms. Our model\nachieves a mean opinion score (MOS) of $4.53$ comparable to a MOS of $4.58$ for\nprofessionally recorded speech. To validate our design choices, we present\nablation studies of key components of our system and evaluate the impact of\nusing mel spectrograms as the input to WaveNet instead of linguistic, duration,\nand $F_0$ features. We further demonstrate that using a compact acoustic\nintermediate representation enables significant simplification of the WaveNet\narchitecture.",
            "authors": [
                "Jonathan Shen",
                "Ruoming Pang",
                "Ron J. Weiss",
                "Mike Schuster",
                "Navdeep Jaitly",
                "Zongheng Yang",
                "Zhifeng Chen",
                "Yu Zhang",
                "Yuxuan Wang",
                "RJ Skerry-Ryan",
                "Rif A. Saurous",
                "Yannis Agiomyrgiannakis",
                "Yonghui Wu"
            ]
        },
        {
            "title": "Tacotron: Towards End-to-End Speech Synthesis",
            "arxiv": "1703.10135",
            "year": 2017,
            "url": "http://arxiv.org/abs/1703.10135v2",
            "abstract": "A text-to-speech synthesis system typically consists of multiple stages, such\nas a text analysis frontend, an acoustic model and an audio synthesis module.\nBuilding these components often requires extensive domain expertise and may\ncontain brittle design choices. In this paper, we present Tacotron, an\nend-to-end generative text-to-speech model that synthesizes speech directly\nfrom characters. Given <text, audio> pairs, the model can be trained completely\nfrom scratch with random initialization. We present several key techniques to\nmake the sequence-to-sequence framework perform well for this challenging task.\nTacotron achieves a 3.82 subjective 5-scale mean opinion score on US English,\noutperforming a production parametric system in terms of naturalness. In\naddition, since Tacotron generates speech at the frame level, it's\nsubstantially faster than sample-level autoregressive methods.",
            "authors": [
                "Yuxuan Wang",
                "RJ Skerry-Ryan",
                "Daisy Stanton",
                "Yonghui Wu",
                "Ron J. Weiss",
                "Navdeep Jaitly",
                "Zongheng Yang",
                "Ying Xiao",
                "Zhifeng Chen",
                "Samy Bengio",
                "Quoc Le",
                "Yannis Agiomyrgiannakis",
                "Rob Clark",
                "Rif A. Saurous"
            ]
        },
        {
            "title": "Pytorch 1 with CUDA",
            "url": "https://pytorch.org/"
        },
        {
            "title": "https://github.com/keithito/tacotron",
            "url": "https://github.com/keithito/tacotron"
        },
        {
            "title": "https://github.com/r9y9/wavenet_vocoder",
            "url": "https://github.com/r9y9/wavenet_vocoder"
        }
    ],
    "domain": {
        "domain_type": "Speech",
        "domain_prob": 0.9846690772292237
    }
}
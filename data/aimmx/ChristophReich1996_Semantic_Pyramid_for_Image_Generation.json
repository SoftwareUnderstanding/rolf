{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Semantic Pyramid for Image Generation",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "ChristophReich1996",
                "owner_type": "User",
                "name": "Semantic_Pyramid_for_Image_Generation",
                "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation",
                "stars": 45,
                "pushed_at": "2022-03-28 00:12:35+00:00",
                "created_at": "2020-03-26 20:50:38+00:00",
                "language": "Python",
                "description": "PyTorch reimplementation of the paper: \"Semantic Pyramid for Image Generation\" [CVPR 2020].",
                "license": "MIT License",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "28c20bc6cc95b402bdde2a0ef07db3098baa71c2",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/.gitignore"
                    }
                },
                "size": 1628
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "7f21af9f7aca98edbce030ee58d4c36c724defa9",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/LICENSE"
                    }
                },
                "size": 1071
            },
            {
                "type": "code",
                "name": "caffe2pytorchvgg16.py",
                "sha": "9505341594c39b720991fe9a23156ce5e4c826e5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/caffe2pytorchvgg16.py"
                    }
                },
                "size": 1206
            },
            {
                "type": "code",
                "name": "data.py",
                "sha": "0cb7992eac603a6f413dc5ae4213ebb767baef8e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/data.py"
                    }
                },
                "size": 3627
            },
            {
                "type": "code",
                "name": "download_places365.sh",
                "sha": "c4563c07322f438cbd536336dee3304a6427b436",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/download_places365.sh"
                    }
                },
                "size": 122
            },
            {
                "type": "code",
                "name": "download_pretrained_vgg16.sh",
                "sha": "97f4bcf24bdfe62c71587681540c3de070bb4596",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/download_pretrained_vgg16.sh"
                    }
                },
                "size": 309
            },
            {
                "type": "code",
                "name": "figures",
                "sha": "807e76d360262e728a060351c5453d1e28a1c408",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/tree/master/figures"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "frechet_inception_distance.py",
                "sha": "2bd7df3fc761aafd740d0ecea5f4727f7e57e82b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/frechet_inception_distance.py"
                    }
                },
                "size": 5388
            },
            {
                "type": "code",
                "name": "lossfunction.py",
                "sha": "12d366afd7ad240f637937ab233d84cf26178e25",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/lossfunction.py"
                    }
                },
                "size": 6043
            },
            {
                "type": "code",
                "name": "main.py",
                "sha": "9c40e101713400b9d49290b2d1d5d6d0689dfba2",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/main.py"
                    }
                },
                "size": 4835
            },
            {
                "type": "code",
                "name": "misc.py",
                "sha": "c88d252547df6d3f79fae0aefc72512a6ebb61d4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/misc.py"
                    }
                },
                "size": 7199
            },
            {
                "type": "code",
                "name": "model_wrapper.py",
                "sha": "c40430cfd8ce04bb36137f3b91dc0869ce2db782",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/model_wrapper.py"
                    }
                },
                "size": 15978
            },
            {
                "type": "code",
                "name": "models.py",
                "sha": "52f196040d32312ff230d252eaebd5b7ecda8aa9",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/models.py"
                    }
                },
                "size": 23671
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "cd6c1e230b3d2b8c99d9ba11ba7208dace65c940",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/requirements.txt"
                    }
                },
                "size": 193
            },
            {
                "type": "code",
                "name": "vgg_16_inference.py",
                "sha": "3b7416c4d6345139ebbceabca783dcaae98fd9bd",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/vgg_16_inference.py"
                    }
                },
                "size": 1136
            },
            {
                "type": "code",
                "name": "vgg_16_train.py",
                "sha": "374232a13fee82d3337c35e5872c07abd60ef30e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/vgg_16_train.py"
                    }
                },
                "size": 9715
            }
        ]
    },
    "authors": [
        {
            "name": "Christoph Reich",
            "github_id": "ChristophReich1996"
        },
        {
            "name": "Changmin Choi",
            "email": "cmchoi9901@gmail.com",
            "github_id": "ryul99"
        }
    ],
    "tags": [
        "generative-adversarial-network",
        "gan",
        "adversarial-learning",
        "semantic-pyramid",
        "image-generation",
        "pytorch",
        "deep-learning",
        "deep-neural-networks",
        "machine-learning",
        "convolutional-neural-networks",
        "cnn",
        "semantic-pyramid-image-generation"
    ],
    "description": "PyTorch reimplementation of the paper: \"Semantic Pyramid for Image Generation\" [CVPR 2020].",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation",
            "stars": 45,
            "issues": true,
            "readme": "# Semantic Pyramid for Image Generation\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation/blob/master/LICENSE)\n\n**Unofficel** [PyTorch](https://pytorch.org/) implementation of the paper [Semantic Pyramid for Image Generation](https://arxiv.org/pdf/2003.06221.pdf) by [Assaf Shocher](https://github.com/assafshocher), Yossi Gandelsman et al.\n\n![Results](figures/paper_results_overview.png \"Paper results\")\n[Source](https://arxiv.org/pdf/2003.06221.pdf). Proposed results of the paper.\n\n## Model Architecture\n\n![Architecture](figures/paper_architecture.png \"Paper architecture\")\n[Source](https://arxiv.org/pdf/2003.06221.pdf)\n\nThe full architecture consists of three parts. First, the object recognition model which is implemented as a\npre-trained VGG 16 network. Secondly, the residual generator network which is partly based on the generator architecture \nof the [SAGAN](https://arxiv.org/pdf/1805.08318.pdf).\nAnd thirdly, the residual discriminator network which is also based on the \n[SAGAN](https://arxiv.org/pdf/1805.08318.pdf).\n\n## Dataset\nTo download and extract the [places365](http://places2.csail.mit.edu/download.html) dataset from the official website\nrun the following script\n```\nsh download_places365.sh\n```\n## Trained VGG-16\nThe original VGG-16 provided by the [MIT CV group](https://github.com/CSAILVision/places365) is trained on a resolution\nof 224 x 224. This implementation, however, utilizes the native resolution (256 x 256) of the \n[places365](http://places2.csail.mit.edu/download.html) dataset. This issue is addressed by fine-tuning the pre-trained \nVGG-16 network on the higher resolution.\n\nThe necessary fine-tuned VGG-16 state dict can be downloaded [here](https://studtudarmstadtde-my.sharepoint.com/:u:/g/personal/christoph_reich_stud_tu-darmstadt_de/EaqFAsNXcYZNgcoYxwLQJrIB0YLsWuiT8rD4I3HnWrwhNg?e=YLmMGn).\n\nTo download and convert the original VGG-16 model pre-trained on the lower resolution (224 x 224) places dataset run the \nfollowing command. The downloaded model can be fine-tuned on the higher resolution by using the \n[training script](/vgg_16_train.py), which is based on the \n[original training script](https://github.com/CSAILVision/places365/blob/master/train_placesCNN.py).\n```\nsh download_pretrained_vgg16.sh\n```\nThis script downloads the official pre-trained caffe models from the\n[places365 repository](https://github.com/CSAILVision/places365). Afterwards, the caffe model gets converted with the\nhelp of the [caffemodel2pytorch](https://github.com/vadimkantorov/caffemodel2pytorch) repo created by \n[Vadim Kantorov](https://github.com/vadimkantorov).\n\n## Usage\nTo train or test the GAN simply run the main script `python main.py`. This main script takes multiple arguments.\n\nArgument | Default value | Info\n--- | --- | ---\n`--train` | False | Flag to perform training\n`--test` | False | Flag to perform testing\n`--batch_size` | 20 | Batch size to be utilized\n`--lr` | 1e-04 | Learning rate to use\n`--channel_factor` | 1 | Channel factor adopts the number of channels utilized in the U-Net\n`--device` | 'cuda' | Device to use (cuda recommended)\n`--gpus_to_use` | '0' | Indexes of the GPUs to be use\n`--use_data_parallel` | False | Use multiple GPUs\n`--load_generator_network` | None | Path of the generator network to be loaded (.pt)\n`--load_discriminator_network` | None | Path of the discriminator network to be loaded (.pt)\n`--load_pretrained_vgg16` | 'pre_trained_models/vgg_places_365.pt' | Path of the pre-trained VGG 16 to be loaded (.pt)\n`--path_to_places365` | 'places365_standard' | Path to places365 dataset\n`--epochs` | 50 | Epochs to perform while training\n\nWhile training logs and models gets save automatically to the `saved_data` file. Inference plots also gets saved in the\nsame folder.\n\n## Results\nWith limited compute budget I was not able to reproduce the results form the paper. The plot, shown below, was after approximately 24h of training on a single Nvidia Tesla V100. After 24h the whole performance dropped again. However, due to the limited computing power, I was only able to train 48h.\n\n![Plot](figures/600000.png \"plot\")\n\n## VGG-16 Fine-Tuning Details\n\nThe VGG-16 network is fine-tuned on the higher resolution images for three epochs. In contrast to the original training \nscript the Adam optimizer is utilized. Validation results before and after the fine-tuning on the full resolution is \npresented in the table below.\n\n|                    | Top-1 accuracy | Top-5 accuracy |\n| ------------------ |:--------------:|:--------------:|\n| Before fine-tuning |      7.493     |     23.047     |\n| After fine-tuning  |     51.140     |     82.085     |\n\nAdditional hyperparameters can be seen in the [training script](/vgg_16_train.py).\n",
            "readme_url": "https://github.com/ChristophReich1996/Semantic_Pyramid_for_Image_Generation",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Self-Attention Generative Adversarial Networks",
            "arxiv": "1805.08318",
            "year": 2018,
            "url": "http://arxiv.org/abs/1805.08318v2",
            "abstract": "In this paper, we propose the Self-Attention Generative Adversarial Network\n(SAGAN) which allows attention-driven, long-range dependency modeling for image\ngeneration tasks. Traditional convolutional GANs generate high-resolution\ndetails as a function of only spatially local points in lower-resolution\nfeature maps. In SAGAN, details can be generated using cues from all feature\nlocations. Moreover, the discriminator can check that highly detailed features\nin distant portions of the image are consistent with each other. Furthermore,\nrecent work has shown that generator conditioning affects GAN performance.\nLeveraging this insight, we apply spectral normalization to the GAN generator\nand find that this improves training dynamics. The proposed SAGAN achieves the\nstate-of-the-art results, boosting the best published Inception score from 36.8\nto 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the\nchallenging ImageNet dataset. Visualization of the attention layers shows that\nthe generator leverages neighborhoods that correspond to object shapes rather\nthan local regions of fixed shape.",
            "authors": [
                "Han Zhang",
                "Ian Goodfellow",
                "Dimitris Metaxas",
                "Augustus Odena"
            ]
        },
        {
            "title": "Semantic Pyramid for Image Generation",
            "arxiv": "2003.06221",
            "year": 2020,
            "url": "http://arxiv.org/abs/2003.06221v2",
            "abstract": "We present a novel GAN-based model that utilizes the space of deep features\nlearned by a pre-trained classification model. Inspired by classical image\npyramid representations, we construct our model as a Semantic Generation\nPyramid -- a hierarchical framework which leverages the continuum of semantic\ninformation encapsulated in such deep features; this ranges from low level\ninformation contained in fine features to high level, semantic information\ncontained in deeper features. More specifically, given a set of features\nextracted from a reference image, our model generates diverse image samples,\neach with matching features at each semantic level of the classification model.\nWe demonstrate that our model results in a versatile and flexible framework\nthat can be used in various classic and novel image generation tasks. These\ninclude: generating images with a controllable extent of semantic similarity to\na reference image, and different manipulation tasks such as\nsemantically-controlled inpainting and compositing; all achieved with the same\nmodel, with no further training.",
            "authors": [
                "Assaf Shocher",
                "Yossi Gandelsman",
                "Inbar Mosseri",
                "Michal Yarom",
                "Michal Irani",
                "William T. Freeman",
                "Tali Dekel"
            ]
        },
        {
            "title": "PyTorch",
            "url": "https://pytorch.org/"
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999971118227264,
        "task": "Image Generation",
        "task_prob": 0.849925836435471
    },
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            }
        ]
    }
}
{
    "visibility": {
        "visibility": "public"
    },
    "name": "Object Detection",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "zhongzisha",
                "owner_type": "User",
                "name": "object_detection",
                "url": "https://github.com/zhongzisha/object_detection",
                "stars": 0,
                "pushed_at": "2020-08-08 05:46:36+00:00",
                "created_at": "2020-08-08 05:45:32+00:00",
                "language": "Python",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "017481813ed3aebd89489a3cbb4ac5137fd94095",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/.gitignore"
                    }
                },
                "size": 31
            },
            {
                "type": "code",
                "name": "common.py",
                "sha": "bb40b7c4b238f2a5be6ba7b1e4416764e3464f47",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/common.py"
                    }
                },
                "size": 6787
            },
            {
                "type": "code",
                "name": "config.py",
                "sha": "674f7e55ef658d5da1c6cd3b670704dc107e984c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/config.py"
                    }
                },
                "size": 5113
            },
            {
                "type": "code",
                "name": "data.py",
                "sha": "72ac5d2dc17a5eb3decc1d9353b9f324e22060dd",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/data.py"
                    }
                },
                "size": 45959
            },
            {
                "type": "code",
                "name": "dataset",
                "sha": "6ebd2046afc1ca6d48339a93db967067eeb7ec59",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/tree/master/dataset"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "fasterrcnn_model.py",
                "sha": "20c0f23445233187de92fc08d0989ff16e653688",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/fasterrcnn_model.py"
                    }
                },
                "size": 73940
            },
            {
                "type": "code",
                "name": "fcos_model.py",
                "sha": "b22cce29f05200d1d5f3448e34af1e89916b5097",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/fcos_model.py"
                    }
                },
                "size": 53930
            },
            {
                "type": "code",
                "name": "logger.py",
                "sha": "e5315dd67b765b86005f728037c56660b9755ed9",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/logger.py"
                    }
                },
                "size": 6157
            },
            {
                "type": "code",
                "name": "myaug_lib.py",
                "sha": "7f5d55b34568f1ac4aae0bbf6199608f07062af1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/myaug_lib.py"
                    }
                },
                "size": 1310
            },
            {
                "type": "code",
                "name": "resnet_model.py",
                "sha": "581d388cd3780dabbc2f76072bbc5e08111ea0b8",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/resnet_model.py"
                    }
                },
                "size": 41763
            },
            {
                "type": "code",
                "name": "retinanet_model.py",
                "sha": "0a37ee88b235931f9ffc32e014785c383d794fe1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/retinanet_model.py"
                    }
                },
                "size": 34510
            },
            {
                "type": "code",
                "name": "tensorboard.png",
                "sha": "be03c5583f5cf6b92db468cdd7026beafcdd7f9e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/tensorboard.png"
                    }
                },
                "size": 212858
            },
            {
                "type": "code",
                "name": "train_FCOS.py",
                "sha": "038a28e5d77c716bf3d66431646f74371604bd4b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/train_FCOS.py"
                    }
                },
                "size": 26171
            },
            {
                "type": "code",
                "name": "train_FasterRCNN.py",
                "sha": "4c197c94718267f041447f7f4e36a5fb4b6a557c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/train_FasterRCNN.py"
                    }
                },
                "size": 22237
            },
            {
                "type": "code",
                "name": "train_FasterRCNN_FPN.py",
                "sha": "77e8f59d1cb85ac49f3eadc3c3247386dbbe716d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/train_FasterRCNN_FPN.py"
                    }
                },
                "size": 26081
            },
            {
                "type": "code",
                "name": "train_RetinaNet.py",
                "sha": "a8b1e34c4248ceb0097e9315637d48f02929c080",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/train_RetinaNet.py"
                    }
                },
                "size": 27813
            },
            {
                "type": "code",
                "name": "utils",
                "sha": "f3e57124b3cf306d299c94cc0e434e07d1533cff",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/tree/master/utils"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "viz.py",
                "sha": "3d1142bd4adacf5161a50cff0cb0f2b4f73e6902",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/zhongzisha/object_detection/blob/master/viz.py"
                    }
                },
                "size": 4512
            }
        ]
    },
    "authors": [
        {
            "name": "Zisha Zhong",
            "github_id": "zhongzisha"
        }
    ],
    "tags": [],
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/zhongzisha/object_detection",
            "stars": 0,
            "issues": true,
            "readme": "# Object Detection\r\n\r\nThis repository contains my study (maybe **buggy**) code for the following object detection methods:\r\n\r\n* FasterRCNN (https://arxiv.org/abs/1506.01497)\r\n* FPN (https://arxiv.org/abs/1612.03144)\r\n* RetinaNet (https://arxiv.org/abs/1708.02002)\r\n* FCOS (https://arxiv.org/abs/1904.01355)\r\n\r\n## Environment\r\n\r\n1. tensorflow_gpu-1.14\r\n2. tensorpack-0.10.1 (for fast data loading)\r\n\r\n## Usage\r\n\r\n1. Download the `resnet_resnet-nhwc-2018-02-07/model.ckpt-112603` from Google.\r\n2. Set the related path, GPU configuration, batch_size, ..., in `config.py`\r\n3. To train `FasterRCNN`, set in `config.py`\r\n\r\n    ```\r\n    cfg.MODE_FRCNN = True\r\n    cfg.MODE_FPN = False\r\n    cfg.MODE_MASK = False\r\n    cfg.MODE_FCOS = False\r\n    cfg.MODE_RETINANET = False\r\n    ```\r\n\r\n    run `python train_FasterRCNN.py train`\r\n\r\n4. For evaluation, run `python train_FasterRCNN.py eval`\r\n\r\n## Evaluation Results on COCO2017\r\n\r\n1. FasterRCNN\r\n\r\n    ```\r\n    # coco_val2017 results (20191129) 1x LR-schedule\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.343\r\n    Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.556\r\n    Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.361\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.380\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.296\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.460\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.255\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.666\r\n    ```\r\n\r\n2. FPN\r\n    ```\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\r\n    Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.578\r\n    Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.381\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.466\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.305\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.489\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.339\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.556\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648\r\n    ```\r\n3. RetinaNet\r\n    ```\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\r\n    Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.501\r\n    Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.356\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.427\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.298\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.485\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.522\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.322\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.567\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680\r\n    ```\r\n4. FCOS\r\n    ```\r\n    V100 2GPU, bs=8 (focal loss from tensorflow/tpu/retinanet sigmoid_focal_loss4)\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\r\n    Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.560\r\n    Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.383\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396\r\n    Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.468\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.309\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.502\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.531\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.340\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.574\r\n    Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684\r\n    ```\r\n\r\n## Tensorboard\r\n\r\n![](tensorboard.png)\r\n\r\n\r\n## Finally\r\nSome codes are copied from `tensorflow/tpu` or `tensorpack`.\r\nAny suggestions and comments are welcomed and greatly appreciated! \r\n\r\n",
            "readme_url": "https://github.com/zhongzisha/object_detection",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "FCOS: Fully Convolutional One-Stage Object Detection",
            "arxiv": "1904.01355",
            "year": 2019,
            "url": "http://arxiv.org/abs/1904.01355v5",
            "abstract": "We propose a fully convolutional one-stage object detector (FCOS) to solve\nobject detection in a per-pixel prediction fashion, analogue to semantic\nsegmentation. Almost all state-of-the-art object detectors such as RetinaNet,\nSSD, YOLOv3, and Faster R-CNN rely on pre-defined anchor boxes. In contrast,\nour proposed detector FCOS is anchor box free, as well as proposal free. By\neliminating the predefined set of anchor boxes, FCOS completely avoids the\ncomplicated computation related to anchor boxes such as calculating overlapping\nduring training. More importantly, we also avoid all hyper-parameters related\nto anchor boxes, which are often very sensitive to the final detection\nperformance. With the only post-processing non-maximum suppression (NMS), FCOS\nwith ResNeXt-64x4d-101 achieves 44.7% in AP with single-model and single-scale\ntesting, surpassing previous one-stage detectors with the advantage of being\nmuch simpler. For the first time, we demonstrate a much simpler and flexible\ndetection framework achieving improved detection accuracy. We hope that the\nproposed FCOS framework can serve as a simple and strong alternative for many\nother instance-level tasks. Code is available at:Code is available at:\nhttps://tinyurl.com/FCOSv1",
            "authors": [
                "Zhi Tian",
                "Chunhua Shen",
                "Hao Chen",
                "Tong He"
            ]
        },
        {
            "title": "Feature Pyramid Networks for Object Detection",
            "arxiv": "1612.03144",
            "year": 2016,
            "url": "http://arxiv.org/abs/1612.03144v2",
            "abstract": "Feature pyramids are a basic component in recognition systems for detecting\nobjects at different scales. But recent deep learning object detectors have\navoided pyramid representations, in part because they are compute and memory\nintensive. In this paper, we exploit the inherent multi-scale, pyramidal\nhierarchy of deep convolutional networks to construct feature pyramids with\nmarginal extra cost. A top-down architecture with lateral connections is\ndeveloped for building high-level semantic feature maps at all scales. This\narchitecture, called a Feature Pyramid Network (FPN), shows significant\nimprovement as a generic feature extractor in several applications. Using FPN\nin a basic Faster R-CNN system, our method achieves state-of-the-art\nsingle-model results on the COCO detection benchmark without bells and\nwhistles, surpassing all existing single-model entries including those from the\nCOCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU\nand thus is a practical and accurate solution to multi-scale object detection.\nCode will be made publicly available.",
            "authors": [
                "Tsung-Yi Lin",
                "Piotr Doll\u00e1r",
                "Ross Girshick",
                "Kaiming He",
                "Bharath Hariharan",
                "Serge Belongie"
            ]
        },
        {
            "title": "Focal Loss for Dense Object Detection",
            "arxiv": "1708.02002",
            "year": 2017,
            "url": "http://arxiv.org/abs/1708.02002v2",
            "abstract": "The highest accuracy object detectors to date are based on a two-stage\napproach popularized by R-CNN, where a classifier is applied to a sparse set of\ncandidate object locations. In contrast, one-stage detectors that are applied\nover a regular, dense sampling of possible object locations have the potential\nto be faster and simpler, but have trailed the accuracy of two-stage detectors\nthus far. In this paper, we investigate why this is the case. We discover that\nthe extreme foreground-background class imbalance encountered during training\nof dense detectors is the central cause. We propose to address this class\nimbalance by reshaping the standard cross entropy loss such that it\ndown-weights the loss assigned to well-classified examples. Our novel Focal\nLoss focuses training on a sparse set of hard examples and prevents the vast\nnumber of easy negatives from overwhelming the detector during training. To\nevaluate the effectiveness of our loss, we design and train a simple dense\ndetector we call RetinaNet. Our results show that when trained with the focal\nloss, RetinaNet is able to match the speed of previous one-stage detectors\nwhile surpassing the accuracy of all existing state-of-the-art two-stage\ndetectors. Code is at: https://github.com/facebookresearch/Detectron.",
            "authors": [
                "Tsung-Yi Lin",
                "Priya Goyal",
                "Ross Girshick",
                "Kaiming He",
                "Piotr Doll\u00e1r"
            ]
        },
        {
            "title": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
            "arxiv": "1506.01497",
            "year": 2015,
            "url": "http://arxiv.org/abs/1506.01497v3",
            "abstract": "State-of-the-art object detection networks depend on region proposal\nalgorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN\nhave reduced the running time of these detection networks, exposing region\nproposal computation as a bottleneck. In this work, we introduce a Region\nProposal Network (RPN) that shares full-image convolutional features with the\ndetection network, thus enabling nearly cost-free region proposals. An RPN is a\nfully convolutional network that simultaneously predicts object bounds and\nobjectness scores at each position. The RPN is trained end-to-end to generate\nhigh-quality region proposals, which are used by Fast R-CNN for detection. We\nfurther merge RPN and Fast R-CNN into a single network by sharing their\nconvolutional features---using the recently popular terminology of neural\nnetworks with 'attention' mechanisms, the RPN component tells the unified\nnetwork where to look. For the very deep VGG-16 model, our detection system has\na frame rate of 5fps (including all steps) on a GPU, while achieving\nstate-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS\nCOCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015\ncompetitions, Faster R-CNN and RPN are the foundations of the 1st-place winning\nentries in several tracks. Code has been made publicly available.",
            "authors": [
                "Shaoqing Ren",
                "Kaiming He",
                "Ross Girshick",
                "Jian Sun"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9982275971752123,
        "task": "Object Detection",
        "task_prob": 0.9880555470969223
    },
    "training": {
        "datasets": [
            {
                "name": "PASCAL VOC 2007"
            },
            {
                "name": "COCO"
            }
        ]
    }
}
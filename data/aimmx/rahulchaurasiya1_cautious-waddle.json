{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Cautious Waddle",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "rahulchaurasiya1",
                "owner_type": "User",
                "name": "cautious-waddle",
                "url": "https://github.com/rahulchaurasiya1/cautious-waddle",
                "stars": 2,
                "pushed_at": "2020-06-18 21:02:27+00:00",
                "created_at": "2020-06-18 18:41:54+00:00",
                "language": "Python",
                "description": "traffic management ",
                "license": "MIT License",
                "frameworks": [
                    "scikit-learn"
                ]
            },
            {
                "type": "code",
                "name": "Archive.py",
                "sha": "dbb7683ed195ff4c534c2dbdf4fa9dffc52375cf",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/Archive.py"
                    }
                },
                "size": 1116
            },
            {
                "type": "code",
                "name": "DOCKERFILE",
                "sha": "b38fe89994aacf487eb416dc157e149342c743a4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/DOCKERFILE"
                    }
                },
                "size": 69
            },
            {
                "type": "code",
                "name": "Database.py",
                "sha": "bec4a09d17790bec549a4fc4ba98e248457a2990",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/Database.py"
                    }
                },
                "size": 8806
            },
            {
                "type": "code",
                "name": "DetailLogWindow.py",
                "sha": "09efd36f2f3a737624c426153af4b3b79e749397",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/DetailLogWindow.py"
                    }
                },
                "size": 2697
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "00d3e78259de63f1daad25008ca0f2732a988bfb",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/LICENSE"
                    }
                },
                "size": 1092
            },
            {
                "type": "code",
                "name": "Paper.pdf",
                "sha": "27180d8085c9527dbbbc4acb89e6b917be1ac661",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/Paper.pdf"
                    }
                },
                "size": 490519
            },
            {
                "type": "code",
                "name": "QUERIES.js",
                "sha": "1d465b5faa1ba3a69f2eb9bd86277c288ea3c160",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/QUERIES.js"
                    }
                },
                "size": 2531
            },
            {
                "type": "code",
                "name": "SearchWindow.py",
                "sha": "4dd59b6e2223cbc55d26298c66f5f7ae68d3e5ca",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/SearchWindow.py"
                    }
                },
                "size": 2083
            },
            {
                "type": "code",
                "name": "SystemArch.png",
                "sha": "cab2b82c0b73a364939eb99f9bfd3aba0cf8f17c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/SystemArch.png"
                    }
                },
                "size": 253329
            },
            {
                "type": "code",
                "name": "UI",
                "sha": "eb98636dd78d7986fe73cc5fcf715e2e9e60c0ef",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/tree/master/UI"
                    }
                },
                "num_files": 9
            },
            {
                "type": "code",
                "name": "ViolationItem.py",
                "sha": "fcd083d0e5d299bfe99b69ffd2091eb227eff71a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/ViolationItem.py"
                    }
                },
                "size": 1003
            },
            {
                "type": "code",
                "name": "add_windows",
                "sha": "fcf0612cf41c9a3dd85ed83dbac88643dca39fb9",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/tree/master/add_windows"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "chute",
                "sha": "69b26f0017fda0d571083eca9cb6f434ae667145",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/tree/master/chute"
                    }
                },
                "num_files": 6
            },
            {
                "type": "code",
                "name": "classifier.py",
                "sha": "098422612c881645d45e7cf1b24939f47e1ed8e8",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/classifier.py"
                    }
                },
                "size": 1025
            },
            {
                "type": "code",
                "name": "database",
                "sha": "07c0b569e0d3618fc9f0724eef3ac21457e9d627",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/tree/master/database"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "dataset.zip",
                "sha": "8dc962aef385c36d2de7036cc1eccafba7f1c20c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/dataset.zip"
                    }
                },
                "size": 23638314
            },
            {
                "type": "code",
                "name": "deeplearning",
                "sha": "91cb9d4eebf0e27566f608e620446c0714f3fb96",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/tree/master/deeplearning"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "detect.py",
                "sha": "3f3c15d6eaddabc8dec8c44699a4cdd144468cac",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/detect.py"
                    }
                },
                "size": 4124
            },
            {
                "type": "code",
                "name": "image-processing",
                "sha": "02dbe6816dc07509632c8122426e470c5d3d72cf",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/tree/master/image-processing"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "images",
                "sha": "8ae309c42065b4ca011724b2ffbfdef6ccb37d36",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/tree/master/images"
                    }
                },
                "num_files": 22
            },
            {
                "type": "code",
                "name": "index.js",
                "sha": "d775d6e8541b8f2764878caf589bdffe7b2ddf96",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/index.js"
                    }
                },
                "size": 466
            },
            {
                "type": "code",
                "name": "model_class.json",
                "sha": "2d810f361dec3712a66fe6ef34d5dc20edd7fe93",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/model_class.json"
                    }
                },
                "size": 102
            },
            {
                "type": "code",
                "name": "predictor.py",
                "sha": "e9e6a355246dda6c2478fe87b0d0bad383e98ed3",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/predictor.py"
                    }
                },
                "size": 1969
            },
            {
                "type": "code",
                "name": "processor",
                "sha": "729e581b086c6fef4a1d8ef5b5d52b02e3011aa5",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/tree/master/processor"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "18d74ca2fc47f172b5f968bb7133f9421a61b3d6",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/requirements.txt"
                    }
                },
                "size": 73
            },
            {
                "type": "code",
                "name": "result.png",
                "sha": "ab23291b101803007d50b5d4dd1771b59f9da448",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/result.png"
                    }
                },
                "size": 428812
            },
            {
                "type": "code",
                "name": "save_HOG_LBP.py",
                "sha": "7caffc6ecdccee8f11d683111f10822fda4d8e40",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/save_HOG_LBP.py"
                    }
                },
                "size": 1617
            },
            {
                "type": "code",
                "name": "saverois.py",
                "sha": "28fbcb6535672f1586893576cc2cb178e4c66956",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/saverois.py"
                    }
                },
                "size": 826
            },
            {
                "type": "code",
                "name": "screenshot.png",
                "sha": "e38272930209dd1f64a7c719492821999854158e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/screenshot.png"
                    }
                },
                "size": 680874
            },
            {
                "type": "code",
                "name": "server.py",
                "sha": "20a2e57e4ea74900599389b45f85762fbf1fbd73",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/server.py"
                    }
                },
                "size": 499
            },
            {
                "type": "code",
                "name": "traffic.py",
                "sha": "a60b09c96cf4268511753430ce0cfe28dd3058de",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rahulchaurasiya1/cautious-waddle/blob/master/traffic.py"
                    }
                },
                "size": 1749
            }
        ]
    },
    "authors": [
        {
            "name": "safertraffic",
            "github_id": "rahulchaurasiya1"
        }
    ],
    "tags": [],
    "description": "traffic management ",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/rahulchaurasiya1/cautious-waddle",
            "stars": 2,
            "issues": true,
            "readme": "# Cautious Waddle \n\n# Smart-Traffic-Junction\n\nThis repository contains the working implementation of the paper [link](https://arxiv.org/abs/2005.01770). A simple algorithm for traffic density estimation using image processing and machine learning.\n\n## Dataset\n\nThe dataset was created using <a href=\"http://www.eecs.qmul.ac.uk/~sgg/QMUL_Junction_Datasets/Junction2/Junction2.html\">QMUL junction 2</a> video. We manually sorted the rois of the <a href=\"dataset.zip\">dataset</a>.\n\n## Files\n1) save_rois.py : saves ROIs (small blocks of image) from the QMUL junction 2 video <br>\n2) save_HOG_LBP.py : saves the HOG(Histogram of Oriented Gradients) and LBP(Local Binary Pattern) features into pickle file\n3) classifier.py : trains the SVM classifier and saves the model into pickle\n4) predictor.py : reads the video and predicts the output on the image\n\n## System Architecture\n![System Architecture of smart traffic junction](https://github.com/DevashishPrasad/Smart-Traffic-Junction/blob/master/SystemArch.png)\n\n\n# Traffic Rules Violation Detection with Computer Vision\n\n> Initial Release (Everything is not completed)\n\n:star: Please star this project. It helps a lot.\n\n![Overal use case](images/main.gif)\n\n\n![Dark theme Screen shot](images/main_black.png)\n\n## TL;DR\n\n<img src=\"images/overall-usage.png\" alt=\"Overal Usage\" align=\"right\" width=\"250\" />\nThis is a software for practice of developing a system from completely scratch. Understanding this will help a lot in system development and basic structure of a system along with computer vision, GUI with python library PyQt and basic opencv.\n\nGo [here](#quick-starting-the-project) if you don't have time.\n\n## Table of content\n\n- [TL;DR](#TL;DR)\n- [Motivation](#motivation)\n- [Introduction](#introduction)\n- [Objective](#objective)\n- [Quick Starting the project](#quick-starting-the-project)\n- [System Overview](#system-overview)\n- [Methodology](#methodology)\n  - [Image Processing](#image-processing)\n  - [Vehicle Classification](#vehicle-classification)\n  - [Violation Detection](#violation-detection)\n  - [Database Structure](#database-structure)\n- [Implementation](#implementation)\n  - [Image Processing and Computer Vision](#image-processing-and-computer-vision)\n  - [Graphical User Interface](#graphical-user-interface-gui)\n  - [Rules Violation Video Representation](#rules-violation-video-representation-in-ui)\n- [Contributing](#contributing)\n- [Links and References](#links-and-references)\n- [Author](#author)\n- [Licensing](#licensing)\n\n## Motivation\n\nThis project is made for the third year second semester System Development(CSE-3200) course.\n\n## Introduction\n\nThe increasing number of cars in cities can cause high volume of traffic, and implies that traffic violations become more critical nowadays in Bangladesh and also around the world. This causes severe destruction of property and more accidents that may endanger the lives of the people. To solve the alarming problem and prevent such unfathomable consequences, traffic violation detection systems are needed. For which the system enforces proper traffic regulations at all times, and apprehend those who does not comply. A traffic violation detection system must be realized in real-time as the authorities track the roads all the time. Hence, traffic enforcers will not only be at ease in implementing safe roads accurately, but also efficiently; as the traffic detection system detects violations faster than humans. This system can detect most common three types of traffic violation in real-time which are signal violation, parking violation and wrong direction violation. A user friendly graphical interface is associated with the system to make it simple for the user to operate the system, monitor traffic and take action against the violations of traffic rules.\n\n## Objective\n\nThe goal of the project is to automate the traffic rules violation detection system and make it ease for the traffic police department to monitor the traffic and take action against the violated vehicle owner in a fast and efficient way. Detecting and tracking the vehicle and their activities accurately is the main priority of the system.\n\n## Quick starting the project\n\n1. `git clone https://github.com/rahatzamancse/EyeTask.git`\n2. Install required python dependencies from `requirements.txt` into your python virtual environment. (`pip install -r requirements.txt`)\n3. `python main.py`\n\n## System Overview\n\n![System Overview](images/system.png)\n\nThe System consists of two main components -\n\n* Vehicle detection model and\n* A graphical user interface (GUI)\n\nFirst the CCTV camera footage from the road side is sent to the system. Vehicles are detected from the footage. Tracking the activity of vehicles system determines if their is any any violation or not. Different types of violations have different algorithms to determine the violation. A system flowchart 1 shows how the system works.\nThe Graphical User Interface (GUI) makes the system interactive for user to use. User can monitor the traffic footage and get the alert of violation with the captured vehicle image. User can take further action using the GUI.\n\n## Methodology\n\n### Image Processing\n\n1. ** Grayscaling and blurring **\n   As the part of preprocessing the input frame got from the CCTV footage, the image is grayscaled and blurred with Gaussian Blur method.\n\n2. ** Background Subtraction **\n   Background subtraction method is used to subtract the current frame from the reference frame to get the desired object\u2019s area. equation (1) shows the method.\n   `dst(I) = saturate(|scr1(I) \u2212 scr2(I)|)`\n\n3. ** Binary Threshold **\n   Binarization method is used to remove all the holes and noises from the frame and get the desired object area accurately. equation (2) shows how the binary threshold works.\n   `dst(x, y) = maxVal if scr(x, y) > thresh else 0`\n\n4. ** Dilation and find the contour **\n   After getting the thresholded image, it is dilated to fill the holes and the contour is found from the image. drawing rectangle box over the contours desired moving objects are taken.\n\n### Vehicle Classification\n\nFrom the preprocessed image moving objects are extracted. A vehicle classification model is used to classify those moving objects into three class - Car, Motobike and Non-vehicle. The classifier model is built with mobilenet v1 neural network architecture.\n\n![Mobilenet Architecture](images/mobilenetv1.png)\n\nFig: MobileNet Body Architecture.\n\n![Parameter Trainning](images/trainning.png)\n\nFig-2: Trainning hyperparameters.\n\nTransfer learning approach is used to training the model with our dataset.The dataset consists of 500  images per class. The training parameters are mentioned in table (2).\n\n### Violation detection\n\nAfter detecting the vehicles three violation cases arises-\n\n* Signal violation: if a vehicle crosses a predefined line on the road while there is red signal, it is detected as a signal violation.\n* Parking violation: if a vehicle stands still in no parking zone for a predefined time, it is detected as a parking violation.\n* Direction violation: when a vehicle comes from a wrong direction,it is detected by tracking the vehicle. The direction of the vehicle is determined using its current position and previous few positions.\n\n### Database Structure\n\nWe have used SQLite database with python to manage the whole data of our application. Here, in the relational database we have used BCNF of 5 tables. The tables are:\n\n1. Cars\n2. Rules\n3. Cameras\n4. Violations\n5. Groups\n\n![Database Scheme](images/schema.png)\n\n** Here are the descriptions of each tables: **\n\n##### Cars:\n\nThis table will hold the recorded cars by the camera. A car entity is a car with a unique identifier(id), color(color), license-number of the car(license), where the car is first sighted (first_sighted), an image of the license number (license_image), an image of the car(car_image), number of rules broken so far(num_rules_broken) and the owner of the car (owner).\n\n##### Rules:\n\nThis table holds all the rules, their description(name) and fine for breaking that rule (fine).\n\n##### Camera:\n\nCamera table holds a unique identifier for the camera(id), location description(location), the longitude(coordinate_x) and the latitude(coordinate_y) of the location of the camera, where the camera will feed its data video(feed) and in which group the camera is in(group).\n\n##### Camera_group:\n\nThis table simply holds the unique group names of the camera groups(name). Violations: This table takes all the ids of other tables as foreign key and creates a semantic record like this: A car with this id has broken that rule at this time, which is captured by this camera.\n\n## Implementation\n\n### Image Processing and Computer Vision\n\nOpenCV computer vision library is used in  Python for image processing purpose. For implementing the vehicle classifier with ,  Tensorflow machine learning framework is used.\n\n### Graphical User Interface (GUI)\n\nThe user interface has all the options needed for the administration and other debugging purpose so that, we do not need to edit code for any management. For example, if we need to add some sample cars or camera in the database, we can do it with the menu item (see fig-3).\n\n![Figure 2](images/fig2.png)\n\nFigure 2: Overall user interface view\n\nPrimarily, for the start of the project usage, the administrator needs to add a camera with the menu item. In the way, the administrator can add the location of the camera, the feed file for the camera. Here the feed file is installed by the camera module over the internet. We have used Linux file sharing pattern for getting the video from the camera, where the camera will feed the given file to the server, and the server will take the feed file to process and detect violation. Also the X and Y coordinate(fig-3) of the camera location can be saved by the admin. This is done for future use, when we will try to use a map for locating the cameras with ease. Also the admin need to specify some rules with a JSON file for the camera. For example, the camera is used for cross road on red line violation, or is used for wrong place parking detection etc.\n\n![Figure 3](images/fig3.png)\n\nFigure 3: Interface for adding camera entity\n\nActually, this is all mainly needed for starting up the system. After adding the camera, the software will automatically start detecting violations of traffic rules. After this, opening the camera by selecting it with the drop down menu, will fill the detection rules violations(fig-4).\n\n![Figure 4](images/fig4.png)\n\nFigure 4: List view of violation records\n\nThe user has many other objects to insert into the database. The admin can add the following entities in the graphical user interface:\n\n1. Camera (fig-3)\n2. Car (fig-5)\n3. Rule (fig-5)\n4. Violation (fig-5)\n\n![Figure 5](images/fig5.png)\n\nFigure 5: Adding items interface\n\nThe GUI is made mainly for this purpose that, there will always be a supervisor for a group of cameras. He can see the list of rule violations and can see details of the cars that violated the rules (fig-8). If he clicks on the detail button, a new window will appear where the user will be able to file the report or send/print ticket for the car owner.\n\n![Figure 8](images/detail.png)\n\nFigure 8: details of rule violation\n\nAlso the admin/user can delete the records if he gets a false positive. But there will never a record deleted. The database has a marker of which file have been archived. If we want to retrieve a record from the deleted once, then the admin needs to go to the archive window. There he can restore any record he wants.\nThe user can also search for a vehicle, with its license number, its color, or date of a rule violation. The license number has text prediction so the user will be sure while typing a license number that it exists.\n\n![Figure 9](images/search.png)\n\nFigure  9: Searching a car or rule violation\n\n### Rules violation video representation in UI\n\nThere are currently 3 rules we are concerned with.\n\n1. Signal Violation\n2. Parking Violation\n3. Direction Violation.\n\nFor Signal Violation, We have used a straight line in the picture. When the traffic light is red and a car is crossing the straight line, a picture of that car is registered in the database along with some environmental values. The user can see in the live preview which car are being detected real time and tested if they are crossing the line.\n\n![Figure 11](images/signal.png)\n\nFigure  11: Signal violation camera representation\n\nFor Parking violation, we have prefigured a rectangle, which is the restricted area for car parking. If there is a vehicle in the rectangle for more than a predefined time, then a image with other environmental values is being registered to the database.\n\n![Figure 12](images/parking.png)\n\nFigure  12: Parking violation camera representation\n\nFor direction violation detection, some lines are drawn to divide into regions. Then when a car moves from one region to another, its direction is measured. If the direction is wrong, then it is registered as previous.\n\n![Figure 13](images/direction.png)\n\nFigure  13: Direction violation camera representation\n\nLibraries used for graphical user interface:\n\n1. PyQt5\n2. QDarkStyle\n3. PyQtTimer\n\n# Traffic-Net\nTraffic-Net is a dataset containing images of dense traffic, sparse traffic, accidents and burning vehicles.\n<br><br>\n<img src=\"images/traffic_net.jpg\" />\n<hr>\n<b>Traffic-Net</b> is a dataset of traffic images, collected in order to ensure that machine learning systems can be trained\n to detect traffic conditions and provide real-time monitoring, analytics and alerts. This is part of <a href=\"https://deepquestai.com\" >DeepQuest AI</a>'s to train machine learning systems to \n  perceive, understand and act accordingly in solving problems in any environment they are deployed. <br><br>\n\n  This is the first release of the Traffic-Net dataset. It contains 4,400 images that span cover 4 classes. The classes\n  included in this release are: <br><br>\n\n  - <b> Accident </b> <br>\n  - <b> Dense Traffic </b> <br>\n  - <b> Fire </b> <br>\n  - <b> Sparse Traffic </b> <br>\n\n  There are <b>1,100 images</b> for each category, with <b>900 images for trainings </b> and <b>200 images for testing</b> . We are working on adding more\n   categories in the future and will continue to improve the dataset.\n  <br><br> <br> <br>\n\n  <b>>>> DOWNLOAD, TRAINING AND PREDICTION: </b> <br><br>\n The <b>Traffic-Net</b> dataset is provided for download in the <b>release</b> section of this repository.\n You can download the dataset via the link below.<br><br> <a href=\"https://github.com/OlafenwaMoses/Traffic-Net/releases/tag/1.0\" >https://github.com/OlafenwaMoses/Traffic-Net/releases/tag/1.0</a>  <br><br>\n\n We have also provided a python codebase to download the images, train <b>ResNet50</b> on the images\n  and perform prediction using a pretrained model (also using <b>ResNet50</b>) provided in the release section of this repository.\n  The python codebase is contained in the <b><a href=\"traffic_net.py\" >traffic_net.py</a></b> file and the model class labels for prediction is also provided the \n  <b><a href=\"model_class.json\" >model_class.json</a></b>. The pretrained <b>ResNet50</b> model is available for download via the link below. <br><br> \n  <b><a href=\"https://github.com/OlafenwaMoses/Traffic-Net/releases/download/1.0/trafficnet_resnet_model_ex-055_acc-0.913750.h5\" >https://github.com/OlafenwaMoses/Traffic-Net/releases/download/1.0/trafficnet_resnet_model_ex-055_acc-0.913750.h5</a></b><br>\n  <br>\n   This pre-trained model was trained for **60 epochs** only, but it achieved over **91%** accuracy on 800 test images. You can see the prediction results on new images that were not part of the dataset in the **Prediction Results** section below. More experiments will enhance the accuracy of the model.\n<br>\nRunning the experiment or prediction requires that you have **Tensorflow**, and **Keras**, **OpenCV** and **ImageAI** installed. You can install this dependencies via the commands below.\n\n<br><span><b>- Tensorflow 1.4.0 (and later versions)  </b>      <a href=\"https://www.tensorflow.org/install/install_windows\" style=\"text-decoration: none;\" > Install</a></span> or install via pip <pre> pip3 install --upgrade tensorflow </pre> \n       \n  <span><b>- OpenCV  </b>        <a href=\"https://pypi.python.org/pypi/opencv-python\" style=\"text-decoration: none;\" >Install</a></span> or install via pip <pre> pip3 install opencv-python </pre> \n       \n   <span><b>- Keras 2.x  </b>     <a href=\"https://keras.io/#installation\" style=\"text-decoration: none;\" >Install</a></span> or install via pip <pre> pip3 install keras </pre> \n  \n   <span><b>- ImageAI 2.0.3  </b>  \n   <span>      <pre>pip3 install imageai </pre></span> <br><br> <br>\n\n\n\n<b>>>> Video & Prediction Results</b> <br><br>\nClick below to watch the video demonstration of the trained model at work. <br>\n<a href=\"https://www.youtube.com/watch?v=PupK_qd3bP0\" ><img src=\"images/video_image.jpg\" /></a>\n<br><br><br><br>\n  <img src=\"images/1.jpg\" />\n<pre>\nSparse_Traffic  :  99.98759031295776\nAccident  :  0.006892996316310018\nDense_Traffic  :  0.0031178133212961257\nFire  :  0.0023975149815669283\n</pre>\n\n<hr>\n<br>\n<img src=\"images/2.jpg\" />\n<pre>\nDense_Traffic  :  100.0\nAccident  :  9.411973422857045e-07\nFire  :  2.656607822615342e-07\nSparse_Traffic  :  4.631924704900925e-09\n</pre>\n\n<hr>\n<br>\n\n<img src=\"images/3.jpg\" />\n<pre>\nAccident  :  99.94832277297974\nSparse_Traffic  :  0.04670554480981082\nFire  :  0.004610423275153153\nDense_Traffic  :  0.00035401615150476573\n</pre>\n\n<hr>\n<br>\n\n<img src=\"images/4.jpg\" />\n<pre>\nFire  :  100.0\nAccident  :  1.9869084979303675e-22\nDense_Traffic  :  3.262699368229192e-23\nSparse_Traffic  :  6.003136426033551e-28\n</pre>\n\n\n<br>\n\n<h3><b><u>References</u></b></h3>\n\n \n 1. Kaiming H. et al, Deep Residual Learning for Image Recognition <br>\n <a href=\"https://arxiv.org/abs/1512.03385\" >https://arxiv.org/abs/1512.03385</a> <br><br>\n \n Paradrop Traffic Camera\n=======================\n\nThis demo chute uses an OpenCV cascade classifier to detect and count\nvehicles in images from a camera mounted on a street pole.\n\n![Screenshot](screenshot.png)\n\nRequirements\n------------\n\nThe default configuration of this chute requires the Paradrop node to\nhave the **paradrop-imserve** module installed. This is because it pulls\nimages from a virtual camera (a web server that provides a different\nframe with each request). If you are using this chute for a tutorial,\nit is likely we installed paradrop-imserve for you. Otherwise, you will\nneed to install **paradrop-imserve** or change the **IMAGE\\_SOURCE\\_URL**\nenvironment variable to point to a real camera.\n\nTo install **paradrop-imserve**, connect to the node using SSH and run\nthe following command.\n\n    snap install paradrop-imserve\n    \n# Dynamic Traffic Monitoring System\n\nThe system uses image processing to control traffic. Traffic density of lanes is calculated using image processing which is done using images of lanes that are captured using a camera and compared to reference images of lanes with no traffic. According to the traffic densities on all roads, our model will allocate intelligently the time period of green light for each road. We have chosen image processing for calculation of traffic density as cameras are readily available infrastructure on road intersections.\n\n## Requirements\n\n- Raspberry Pi Model 3\n- Web Camera\n- GSM Module\n- Thingspeak Account\n\n### Dependencies\n\n- Python 3.4+\n- OpenCV 3.2.0 compiled with Python3 support\n- RaspberryPi GPIO Libraries for Python\n- node.js (>= 6.0)\n- MySQL\n- Raspbian Jessie (or equivalent)\n\n### Setting up the data visualization\n\n1. Log into your ThingSpeak account.\n2. Create a channel.\n3. Get the API write key for the channel.\n4. Paste the value in `sample.py`\n5. Add the `analysis.m` file to the channel.\n6. Once the script is running on the Pi (directions below) the data can be seen on the ThingSpeak dashboard.\n\n### Running the script\n\nTo run the script,\n\n1. `ssh` onto a Raspberry Pi and paste the contents of the `raspi-scripts` folder onto the Raspberry Pi.\n2. Run `python3 sample.py`\n",
            "readme_url": "https://github.com/rahulchaurasiya1/cautious-waddle",
            "frameworks": [
                "scikit-learn"
            ]
        }
    ],
    "references": [
        {
            "title": "Deep Residual Learning for Image Recognition",
            "arxiv": "1512.03385",
            "year": 2015,
            "url": "http://arxiv.org/abs/1512.03385v1",
            "abstract": "Deeper neural networks are more difficult to train. We present a residual\nlearning framework to ease the training of networks that are substantially\ndeeper than those used previously. We explicitly reformulate the layers as\nlearning residual functions with reference to the layer inputs, instead of\nlearning unreferenced functions. We provide comprehensive empirical evidence\nshowing that these residual networks are easier to optimize, and can gain\naccuracy from considerably increased depth. On the ImageNet dataset we evaluate\nresidual nets with a depth of up to 152 layers---8x deeper than VGG nets but\nstill having lower complexity. An ensemble of these residual nets achieves\n3.57% error on the ImageNet test set. This result won the 1st place on the\nILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100\nand 1000 layers.\n  The depth of representations is of central importance for many visual\nrecognition tasks. Solely due to our extremely deep representations, we obtain\na 28% relative improvement on the COCO object detection dataset. Deep residual\nnets are foundations of our submissions to ILSVRC & COCO 2015 competitions,\nwhere we also won the 1st places on the tasks of ImageNet detection, ImageNet\nlocalization, COCO detection, and COCO segmentation.",
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ]
        },
        {
            "title": "HOG, LBP and SVM based Traffic Density Estimation at Intersection",
            "arxiv": "2005.01770",
            "year": 2020,
            "url": "http://arxiv.org/abs/2005.01770v1",
            "abstract": "Increased amount of vehicular traffic on roads is a significant issue. High\namount of vehicular traffic creates traffic congestion, unwanted delays,\npollution, money loss, health issues, accidents, emergency vehicle passage and\ntraffic violations that ends up in the decline in productivity. In peak hours,\nthe issues become even worse. Traditional traffic management and control\nsystems fail to tackle this problem. Currently, the traffic lights at\nintersections aren't adaptive and have fixed time delays. There's a necessity\nof an optimized and sensible control system which would enhance the efficiency\nof traffic flow. Smart traffic systems perform estimation of traffic density\nand create the traffic lights modification consistent with the quantity of\ntraffic. We tend to propose an efficient way to estimate the traffic density on\nintersection using image processing and machine learning techniques in real\ntime. The proposed methodology takes pictures of traffic at junction to\nestimate the traffic density. We use Histogram of Oriented Gradients (HOG),\nLocal Binary Patterns (LBP) and Support Vector Machine (SVM) based approach for\ntraffic density estimation. The strategy is computationally inexpensive and can\nrun efficiently on raspberry pi board. Code is released at\nhttps://github.com/DevashishPrasad/Smart-Traffic-Junction.",
            "authors": [
                "Devashish Prasad",
                "Kshitij Kapadni",
                "Ayan Gadpal",
                "Manish Visave",
                "Kavita Sultanpure"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9788367088507518,
        "task": "Object Detection",
        "task_prob": 0.8547266281247734
    },
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            },
            {
                "name": "ImageNet Detection"
            },
            {
                "name": "ILSVRC 2015"
            },
            {
                "name": "CIFAR-10"
            },
            {
                "name": "COCO"
            }
        ]
    }
}
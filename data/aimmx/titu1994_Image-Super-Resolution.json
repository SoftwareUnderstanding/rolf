{
    "visibility": {
        "visibility": "public"
    },
    "name": "Image Super Resolution using in Keras 2+",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "titu1994",
                "owner_type": "User",
                "name": "Image-Super-Resolution",
                "url": "https://github.com/titu1994/Image-Super-Resolution",
                "stars": 774,
                "pushed_at": "2021-08-21 12:08:40+00:00",
                "created_at": "2016-06-24 14:35:12+00:00",
                "language": "Python",
                "description": "Implementation of Super Resolution CNN in Keras.",
                "frameworks": [
                    "Keras",
                    "TensorFlow",
                    "Theano"
                ]
            },
            {
                "type": "code",
                "name": "Framework-Update.md",
                "sha": "7b9621857f0f291996adb610c99e553ebf9b14fd",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/titu1994/Image-Super-Resolution/blob/master/Framework-Update.md"
                    }
                },
                "size": 5017
            },
            {
                "type": "code",
                "name": "advanced.py",
                "sha": "fce919674da7704fa86a610fcfe7230b0be7f245",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/titu1994/Image-Super-Resolution/blob/master/advanced.py"
                    }
                },
                "size": 11094
            },
            {
                "type": "code",
                "name": "architectures",
                "sha": "bea50b9d8bd28ef345df1f0360da7ef1546f48cd",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/titu1994/Image-Super-Resolution/tree/master/architectures"
                    }
                },
                "num_files": 10
            },
            {
                "type": "code",
                "name": "distill_network.py",
                "sha": "ac80a5526df00424cdad671c7351a93ef3b4df9f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/titu1994/Image-Super-Resolution/blob/master/distill_network.py"
                    }
                },
                "size": 3882
            },
            {
                "type": "code",
                "name": "img-utils",
                "sha": "dbca9c0fe29fb21de3c2e2a62e04fabd6b47bb58",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/titu1994/Image-Super-Resolution/blob/master/img-utils"
                    }
                },
                "size": 14822
            },
            {
                "type": "code",
                "name": "input_images",
                "sha": "5fd63983e48ee45cae2cc3a88ad838ae4827fcc4",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/titu1994/Image-Super-Resolution/tree/master/input_images"
                    }
                },
                "num_files": 91
            },
            {
                "type": "code",
                "name": "main.py",
                "sha": "a85bdb5ba0cee63c623e9e971229e915a4c2ce26",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/titu1994/Image-Super-Resolution/blob/master/main.py"
                    }
                },
                "size": 2488
            },
            {
                "type": "code",
                "name": "models.py",
                "sha": "29795b9bbfaebfd583bea42bae944912ff77e74b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/titu1994/Image-Super-Resolution/blob/master/models.py"
                    }
                },
                "size": 51426
            },
            {
                "type": "code",
                "name": "results",
                "sha": "3bf654fc0a283573da826e3fb243c4cbf5863f3a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/titu1994/Image-Super-Resolution/tree/master/results"
                    }
                },
                "num_files": 24
            },
            {
                "type": "code",
                "name": "tests.py",
                "sha": "a29d4d166335a653d1f6d5c84443ae905c7ab907",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/titu1994/Image-Super-Resolution/blob/master/tests.py"
                    }
                },
                "size": 5286
            },
            {
                "type": "code",
                "name": "val_images",
                "sha": "51bc5b5f72d66d5021fac035efaaeddcadb1fa09",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/titu1994/Image-Super-Resolution/tree/master/val_images"
                    }
                },
                "num_files": 7
            },
            {
                "type": "code",
                "name": "weights",
                "sha": "8a8309aaf0b4db06cd16abad4f6d71bb77f37e95",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/titu1994/Image-Super-Resolution/tree/master/weights"
                    }
                },
                "num_files": 7
            },
            {
                "type": "code",
                "name": "windows_helper",
                "sha": "739a181cc1fc75bafe5eef44541116d3f7506893",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/titu1994/Image-Super-Resolution/tree/master/windows_helper"
                    }
                },
                "num_files": 8
            }
        ]
    },
    "authors": [
        {
            "name": "Somshubra Majumdar",
            "email": "titu1994@gmail.com",
            "github_id": "titu1994"
        },
        {
            "name": "CaptainStabs",
            "github_id": "CaptainStabs"
        }
    ],
    "tags": [],
    "description": "Implementation of Super Resolution CNN in Keras.",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/titu1994/Image-Super-Resolution",
            "stars": 774,
            "issues": true,
            "readme": "# Image Super Resolution using in Keras 2+\n\nImplementation of Image Super Resolution CNN in Keras from the paper \n<i><a href=\"https://arxiv.org/pdf/1501.00092v3.pdf\">Image Super-Resolution Using Deep Convolutional Networks</a></i>.\n\nAlso contains models that outperforms the above mentioned model, termed Expanded Super Resolution, Denoiseing Auto Encoder SRCNN which outperforms both of the above models and Deep Denoise SR, which with certain limitations, outperforms all of the above.\n\n## Setup\nSupports Keras with Theano and Tensorflow backend. Due to recent report that Theano will no longer be updated, Tensorflow is the default backend for this project now.\n\nRequires Pillow, imageio, sklearn, scipy, keras 2.3.1, tensorflow 1.15.0\n## Usage\n\n**Note**: The project is going to be reworked. Therefore please refer to [Framework-Updates.md](https://github.com/titu1994/Image-Super-Resolution/blob/master/Framework-Update.md) to see the changes which will affect performance.\n\nThe model weights are already provided in the weights folder, therefore simply running :<br>\n`python main.py \"imgpath\"`, where imgpath is a full path to the image.\n\nThe default model is DDSRCNN (dsr), which outperforms the other three models. To switch models,<br>\n`python main.py \"imgpath\" --model=\"type\"`, where type = `sr`, `esr`, `dsr`, `ddsr`\n\nIf the scaling factor needs to be altered then :<br>\n`python main.py \"imgpath\" --scale=s`, where s can be any number. Default `s = 2`\n\nIf the intermediate step (bilinear scaled image) is needed, then:<br>\n`python main.py \"imgpath\" --scale=s --save_intermediate=\"True\"`\n\n## Window Helper\nThe windows_helper script contains a C# program for Windows to easily use the Super Resolution script using any of the available models.\n\n## Parameters\n```\n--model : Can be one of \"sr\" (Image Super Resolution), \"esr\" (Expanded SR), \"dsr\" (Denoiseing Auto Encoder SR), \"ddsr\" (Deep Denoise SR), \"rnsr\" (ResNet SR) or \"distilled_rnsr\" (Distilled ResNet SR)\n--scale : Scaling factor can be any integer number. Default is 2x scaling.\n--save_intermediate= : Save the intermediate results before applying the Super Resolution algorithm.\n--mode : \"fast\" or \"patch\". Patch mode can be useful for memory constrained GPU upscaling, whereas fast mode submits whole image for upscaling in one pass.\n--suffix : Suffix of the scaled image filename\n--patch_size : Used only when patch mode is used. Sets the size of each patch\n```\n\n## Model Architecture\n### Super Resolution CNN (SRCNN)\n<img src=\"https://raw.githubusercontent.com/titu1994/ImageSuperResolution/master/architectures/SRCNN.png\" height=100% width=25%>\n\nThe model above is the simplest model of the ones described in the paper above, consisting of the 9-1-5 model.\nLarger architectures can be easily made, but come at the cost of execution time, especially on CPU.\n\nHowever there are some differences from the original paper:\n<br><b>[1]</b> Used the Adam optimizer instead of RMSProp.\n<br><b>[2]</b> This model contains some 21,000 parameters, more than the 8,400 of the original paper.\n\nIt is to be noted that the original models underperform compared to the results posted in the paper. This may be due to the only 91 images being the training set compared to the entire ILSVR 2013 image set. It still performs well, however images are slightly noisy.\n\n### Expanded Super Resolution CNN (ESRCNN)\n<img src=\"https://raw.githubusercontent.com/titu1994/ImageSuperResolution/master/architectures/ESRCNN.png\" height=100% width=75%>\n\nThe above is called \"Expanded SRCNN\", which performs slightly worse than the default SRCNN model on Set5 (PSNR 31.78 dB vs 32.4 dB).\n\nThe \"Expansion\" occurs in the intermediate hidden layer, in which instead of just 1x1 kernels, we also use 3x3 and 5x5 kernels in order to maximize information learned from the layer. The outputs of this layer are then averaged, in order to construct more robust upscaled images.\n\n### Denoiseing (Auto Encoder) Super Resolution CNN (DSRCNN)\n<img src=\"https://raw.githubusercontent.com/titu1994/ImageSuperResolution/master/architectures/Denoise.png\" height=100% width=40%>\n\nThe above is the \"Denoiseing Auto Encoder SRCNN\", which performs even better than SRCNN on Set5 (PSNR 32.57 dB vs 32.4 dB).\n\nThis model uses bridge connections between the convolutional layers of the same level in order to speed up convergence and improve output results. The bridge connections are averaged to be more robust. \n\nSince the training images are passed through a gausian filter (sigma = 0.5), then downscaled to 1/3rd the size, then upscaled to the original 33x33 size images, the images can be considered \"noisy\". Thus, this auto encoder quickly improves on the earlier results, and reduces the noisy output image problem faced by the simpler SRCNN model.\n\n### Deep Denoiseing Super Resolution (DDSRCNN)\n<img src=\"https://raw.githubusercontent.com/titu1994/ImageSuperResolution/master/architectures/Deep Denoise.png\" height=100% width=40%>\n\nThe above is the \"Deep Denoiseing SRCNN\", which is a modified form of the architecture described in the paper <a href=\"http://arxiv.org/abs/1606.08921\">\"Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections\"</a> applied to image super-resolution. It can perform far better than even the Denoiseing SRCNN, but is currently not working properly.\n\nSimilar to the paper <a href=\"http://arxiv.org/abs/1606.08921\">Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections</a>, this can be considered a highly simplified and shallow model compared to the 30 layer architecture used in the above paper. \n\n<img src=\"https://raw.githubusercontent.com/titu1994/ImageSuperResolution/master/architectures/DDSRCNN%20validation%20plot.png\" width=100% height=100%>\n\n### ResNet Super Resolution (ResNet SR)\n<img src=\"https://github.com/titu1994/Image-Super-Resolution/blob/master/architectures/ResNet.png?raw=true\" height=2% width=40%>\nThe above is the \"ResNet SR\" model, derived from the \"SRResNet\" model of the paper [Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network](https://arxiv.org/abs/1609.04802)\n\nCurrently uses only 6 residual blocks and 2x upscaling rather than the 15 residual blocks and the 4x upscaling from the paper.\n\n### Efficient SubPixel Convolutional Neural Network (ESPCNN)\nThe above model is the Efficient Subpixel Convolution Neural Network which uses the Subpixel Convolution layers to upscale rather than UpSampling or Deconvolution.\nCurrently has not been trained properly.\n\n### GAN Image Super Resolution (GANSR)\n<img src=\"https://github.com/titu1994/Image-Super-Resolution/blob/master/architectures/GAN%20Image%20SR.png?raw=true\" height=100% width=40%>\nThe above model is the GAN trained Image Super Resolution network based on the ResNet SR and the SRGAN from the paper above.\n\n**Note** : Does not work properly right now.\n\n### Distilled ResNet Super Resolution (Distilled ResNetSR)\n<img src=\"https://github.com/titu1994/Image-Super-Resolution/blob/master/architectures/distilled_resnet_sr.png?raw=true\" height=100% width=40%>\nThe above model is a smaller ResNet SR that was trained using model distilation techniques from the \"teacher\" model - the original larger ResNet SR (with 6 residual blocks).\n\nThe model was trained via the `distill_network.py` script which can be used to perform distilation training from any teacher network onto a smaller 'student' network.\n\n### Non-Local ResNet Super Resolution (Non-Local ResNetSR)\n<img src=\"https://github.com/titu1994/Image-Super-Resolution/blob/master/architectures/non_local_resnet_sr.png?raw=true\" height=40% width=40%>\nThe above model is a trial to see if Non-Local blocks can obtain better super resolution.\n\nVarious issues :\n\n1) They break the fully convolutional behaviour of the network. Due to the flatten and reshape parts of this module, you need to have a set size for the image when building it.\n\nTherefore you cannot construct one model and then pass random size input images to evaluate.\n\n2) The non local blocks require vast amount of memory as their intermediate products. I think this is the reason they suggested to use this at the end of the network where the spatial dimension is just 14x14 or 7x7.\n\nI had consistent ooms when trying it on multiple positions of a super resolution network, and could only successfully place it at the last ResNet block without oom (on just 4 GB 980M).\n\nFinally, I was able to train a model anyway and it got pretty high psnr scores. I wasn't able to evaluate that, and was able to distill the model into ordinary ResNet. It got exactly same psnr score as the original non local model.\nEvaluating that, all the images were a little smoothed out. This is worse than a distilled ResNet which obtains a lower psnr score but sharper images.\n\n## Training\nIf you wish to train the network on your own data set, follow these steps (Performance may vary) :\n<br><b>[1]</b> Save all of your input images of any size in the <b>\"input_images\"</b> folder\n<br><b>[2]</b> Run img_utils.py function, `transform_images(input_path, scale_factor)`. By default, input_path is \"input_images\" path.\nNote: Unless you are training ESPCNN, set the variable `true_upsampling` to False and then run the img_utils.py script to generate the dataset. Only for ESPCNN training do you need to set `true_upsampling` to True.\n<br><b>[3]</b> Open <b>tests.py</b> and un-comment the lines at model.fit(...), where model can be sr, esr or dsr, ddsr. \n<br><b>Note: It may be useful to save the original weights in some other location.</b>\n<br><b>[4]</b> Execute tests.py to begin training. GPU is recommended, although if small number of images are provided then GPU may not be required.\n\n## Caveats\nVery large images may not work with the GPU. Therefore, \n<br>[1] If using Theano, set device=\"cpu\" and cnmem=0.0 in theanorc.txt\n<br>[2] If using Tensorflow, set it to cpu mode\n\nOn the CPU, extremely high resolution images of the size upto 6000 x 6000 pixels can be handled if 16 GB RAM is provided. \n\n## Examples\nThere are 14 extra images provided in results, 2 of which (Monarch Butterfly and Zebra) have been scaled using both bilinear, SRCNN, ESRCNN and DSRCNN.\n\n### Monarch Butterfly\nBilinear\n<img src=\"https://raw.githubusercontent.com/titu1994/ImageSuperResolution/master/results/monarch_intermediate.jpg\" width=25% height=25%> SRCNN\n<img src=\"https://raw.githubusercontent.com/titu1994/ImageSuperResolution/master/results/monarch_sr(2x).jpg\" width=25% height=25%> <br>ESRCNN\n<img src=\"https://raw.githubusercontent.com/titu1994/ImageSuperResolution/master/results/monarch_esr(2x).jpg\" width=25% height=25%> \nDDSRCNN\n<img src=\"https://raw.githubusercontent.com/titu1994/ImageSuperResolution/master/results/monarch_ddsr(2x).png\" height=25% width=25%>\n\n### Zebra\nBilinear\n<img src=\"https://raw.githubusercontent.com/titu1994/ImageSuperResolution/master/results/zebra_intermediate.jpg\" width=25% height=25%> SRCNN\n<img src=\"https://raw.githubusercontent.com/titu1994/ImageSuperResolution/master/results/zebra_sr(2x).jpg\" width=25% height=25%>\n<br>ESRCNN\n<img src=\"https://raw.githubusercontent.com/titu1994/ImageSuperResolution/master/results/zebra_esr(2x).jpg\" width=25% height=25%>\nDDSRCNN\n<img src=\"https://raw.githubusercontent.com/titu1994/ImageSuperResolution/master/results/zebra_ddsr(2x).png\" width=25% height=25%>\n",
            "readme_url": "https://github.com/titu1994/Image-Super-Resolution",
            "frameworks": [
                "Keras",
                "TensorFlow",
                "Theano"
            ]
        }
    ],
    "references": [
        {
            "title": "Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections",
            "arxiv": "1606.08921",
            "year": 2016,
            "url": "http://arxiv.org/abs/1606.08921v3",
            "abstract": "Image restoration, including image denoising, super resolution, inpainting,\nand so on, is a well-studied problem in computer vision and image processing,\nas well as a test bed for low-level image modeling algorithms. In this work, we\npropose a very deep fully convolutional auto-encoder network for image\nrestoration, which is a encoding-decoding framework with symmetric\nconvolutional-deconvolutional layers. In other words, the network is composed\nof multiple layers of convolution and de-convolution operators, learning\nend-to-end mappings from corrupted images to the original ones. The\nconvolutional layers capture the abstraction of image contents while\neliminating corruptions. Deconvolutional layers have the capability to upsample\nthe feature maps and recover the image details. To deal with the problem that\ndeeper networks tend to be more difficult to train, we propose to symmetrically\nlink convolutional and deconvolutional layers with skip-layer connections, with\nwhich the training converges much faster and attains better results.",
            "authors": [
                "Xiao-Jiao Mao",
                "Chunhua Shen",
                "Yu-Bin Yang"
            ]
        },
        {
            "title": "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network",
            "arxiv": "1609.04802",
            "year": 2016,
            "url": "http://arxiv.org/abs/1609.04802v5",
            "abstract": "Despite the breakthroughs in accuracy and speed of single image\nsuper-resolution using faster and deeper convolutional neural networks, one\ncentral problem remains largely unsolved: how do we recover the finer texture\ndetails when we super-resolve at large upscaling factors? The behavior of\noptimization-based super-resolution methods is principally driven by the choice\nof the objective function. Recent work has largely focused on minimizing the\nmean squared reconstruction error. The resulting estimates have high peak\nsignal-to-noise ratios, but they are often lacking high-frequency details and\nare perceptually unsatisfying in the sense that they fail to match the fidelity\nexpected at the higher resolution. In this paper, we present SRGAN, a\ngenerative adversarial network (GAN) for image super-resolution (SR). To our\nknowledge, it is the first framework capable of inferring photo-realistic\nnatural images for 4x upscaling factors. To achieve this, we propose a\nperceptual loss function which consists of an adversarial loss and a content\nloss. The adversarial loss pushes our solution to the natural image manifold\nusing a discriminator network that is trained to differentiate between the\nsuper-resolved images and original photo-realistic images. In addition, we use\na content loss motivated by perceptual similarity instead of similarity in\npixel space. Our deep residual network is able to recover photo-realistic\ntextures from heavily downsampled images on public benchmarks. An extensive\nmean-opinion-score (MOS) test shows hugely significant gains in perceptual\nquality using SRGAN. The MOS scores obtained with SRGAN are closer to those of\nthe original high-resolution images than to those obtained with any\nstate-of-the-art method.",
            "authors": [
                "Christian Ledig",
                "Lucas Theis",
                "Ferenc Huszar",
                "Jose Caballero",
                "Andrew Cunningham",
                "Alejandro Acosta",
                "Andrew Aitken",
                "Alykhan Tejani",
                "Johannes Totz",
                "Zehan Wang",
                "Wenzhe Shi"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999984937620051,
        "task": "Image Denoising",
        "task_prob": 0.9608206822936102
    }
}
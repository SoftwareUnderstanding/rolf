{
    "visibility": {
        "visibility": "public",
        "license": "Apache License 2.0"
    },
    "name": "Android People Segmentation Application with Mobile Deeplab-v3-plus powered by [MACE](https://github.com/XiaoMi/mace).",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "nolanliou",
                "owner_type": "User",
                "name": "PeopleSegmentationDemo",
                "url": "https://github.com/nolanliou/PeopleSegmentationDemo",
                "stars": 51,
                "pushed_at": "2019-05-23 01:13:27+00:00",
                "created_at": "2019-05-22 09:29:37+00:00",
                "language": "Java",
                "description": "Android People Segmentation Application using Deeplab-V3+ model with MobilenetV2 powered by MACE.",
                "license": "Apache License 2.0",
                "frameworks": []
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "cea3ef5791f0bf5bea5b730094adab6d407f0703",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nolanliou/PeopleSegmentationDemo/blob/master/.gitignore"
                    }
                },
                "size": 125
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "d645695673349e3947e8e5ae42332d0ac3164cd7",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nolanliou/PeopleSegmentationDemo/blob/master/LICENSE"
                    }
                },
                "size": 11358
            },
            {
                "type": "code",
                "name": "app",
                "sha": "eeb7238f59adace5eec4142aaaaed9c452a103af",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nolanliou/PeopleSegmentationDemo/tree/master/app"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "build.gradle",
                "sha": "e6b32bc7884bb98a5024981d37fec787514b56c8",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nolanliou/PeopleSegmentationDemo/blob/master/build.gradle"
                    }
                },
                "size": 546
            },
            {
                "type": "code",
                "name": "docs",
                "sha": "3d82939ce011cd2e9e81b417e83af3a80b42c8a9",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nolanliou/PeopleSegmentationDemo/tree/master/docs"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "gradle.properties",
                "sha": "aac7c9b4614ccfde6c721f24994cf30885a791d0",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nolanliou/PeopleSegmentationDemo/blob/master/gradle.properties"
                    }
                },
                "size": 730
            },
            {
                "type": "code",
                "name": "gradle",
                "sha": "b0c41e48cfcbff77d557ee44c9b435b69e824c2e",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nolanliou/PeopleSegmentationDemo/tree/master/gradle"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "gradlew",
                "sha": "9d82f78915133e1c35a6ea51252590fb38efac2f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nolanliou/PeopleSegmentationDemo/blob/master/gradlew"
                    }
                },
                "size": 4971
            },
            {
                "type": "code",
                "name": "gradlew.bat",
                "sha": "aec99730b4e8fcd90b57a0e8e01544fea7c31a89",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nolanliou/PeopleSegmentationDemo/blob/master/gradlew.bat"
                    }
                },
                "size": 2404
            },
            {
                "type": "code",
                "name": "macelibrary",
                "sha": "25e010503095c49af551db50405a889037975a4b",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nolanliou/PeopleSegmentationDemo/tree/master/macelibrary"
                    }
                },
                "num_files": 6
            },
            {
                "type": "code",
                "name": "settings.gradle",
                "sha": "d22c6f43baa8efb0486c51886d7b5400eef35de1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nolanliou/PeopleSegmentationDemo/blob/master/settings.gradle"
                    }
                },
                "size": 31
            }
        ]
    },
    "authors": [
        {
            "name": "Liu Qi",
            "email": "nolan.liou@gmail.com",
            "github_id": "nolanliou"
        }
    ],
    "tags": [],
    "description": "Android People Segmentation Application using Deeplab-V3+ model with MobilenetV2 powered by MACE.",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/nolanliou/PeopleSegmentationDemo",
            "stars": 51,
            "issues": true,
            "readme": "# Android People Segmentation Application with [Mobile Deeplab-v3-plus](https://github.com/nolanliou/mobile-deeplab-v3-plus) powered by [MACE](https://github.com/XiaoMi/mace).\n\n\u8fd9\u4e2a\u9879\u76ee\u65e8\u5728\u5c55\u793a\u4e00\u79cd\u80fd\u591f\u5728\u5c3d\u53ef\u80fd\u591a\u7684Android\u8bbe\u5907\u4e0a\u57fa\u4e8e[MACE](https://github.com/XiaoMi/mace)\u8fd0\u884c\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u89e3\u51b3\u65b9\u6848\u3002\n\n\u6b64\u5916\uff0c\u672c\u9879\u76ee\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u7684MACE JNI\u7684\u63a5\u53e3\u4f9b\u5927\u5bb6\u53c2\u8003\uff0c\u8be5\u5957\u63a5\u53e3\u53ef\u4ee5\u6269\u5c55\u652f\u6301\u591a\u79cd\u6a21\u578b\u3002\u53c2\u8003[blog](https://zhuanlan.zhihu.com/p/66662510)\u53ef\u4ee5\u4e86\u89e3\u5b8c\u6574\u7684\u8fc7\u7a0b\u3002\n\nThis Application aim to show a solution to run NN models with [MACE](https://github.com/XiaoMi/mace) on\n as many android devices as possible.\n\nThe project could extent to multiple kind models(classification, object detection...)\n and every kind model supports multiple different quality models for offering different effects for different devices.\n \n# \u793a\u4f8b\nPrebuilt [APK](http://cnbj1.fds.api.xiaomi.com/mace/demo/people_segmentation_demo.apk).\n> **Build with NDK-17b**\n\n![Demo](docs/demo.gif)\n\n\n# \u7b80\u4ecb\n## \u901a\u7528\u6027\u95ee\u9898\n\u76ee\u524d\u6765\u770b\uff0c\u73b0\u5728\u6ca1\u6709\u529e\u6cd5\u505a\u5230\u5728\u6240\u6709\u8bbe\u5907\u4e0a\u90fd\u8fd0\u884c\u540c\u4e00\u4e2a\u6a21\u578b\uff0c\u56e0\u4e3a\u5404\u8bbe\u5907\u7684\u7b97\u529b\u4e0d\u5c3d\u76f8\u540c\u3002\n\u76ee\u524d\u7684\u89e3\u51b3\u65b9\u6848\u4e00\u822c\u662f\u6839\u636e\u8bbe\u5907\u7684\u7b97\u529b\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\uff0c\u4f9d\u636e\u8bbe\u5907\u7b97\u529b\u9009\u62e9\u4e0d\u540c\u6548\u679c\u7684\u6a21\u578b\uff0c\u4ee5\u6700\u5927\u5316\u6536\u76ca\uff0c\n\u6bd4\u5982\u6700\u65b0\u7684\u9ad8\u901a\u9a81\u9f99855\u673a\u578b\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528DSP\u7684\u6a21\u578b\uff0c\u4e00\u822c\u673a\u578b\u53ef\u4ee5\u4f7f\u7528GPU\uff0c\u6216\u8005CPU\u91cf\u5316\u6a21\u578b\u3002\n\u8fd9\u4e2a\u9879\u76ee\u5c31\u662f\u4e3a\u4e86\u7ed9\u5927\u5bb6\u5c55\u793a\u4e00\u4e0b\u57fa\u4e8e[MACE](https://github.com/XiaoMi/mace)\u7684\u901a\u7528\u6027\u89e3\u51b3\u65b9\u6848\u3002\n \n## \u89e3\u51b3\u65b9\u6848\n\u8be5\u89e3\u51b3\u65b9\u6848\u7684\u6838\u5fc3\u662f\u5982\u4f55\u9884\u4f30\u6a21\u578b\u7684\u8fd0\u884c\u65f6\u95f4(\u5176\u5b9e\u8fd9\u4e2a\u5f88\u96be)\u3002\nMACE\u63d0\u4f9b\u4e86\u67e5\u8be2\u8fd0\u7b97\u8bbe\u5907\uff08CPU\uff0cGPU\u7b49\uff09\u7b97\u529b\u7684[\u63a5\u53e3](https://github.com/XiaoMi/mace/blob/master/mace/public/mace.h#L137)\uff0c\n\u8be5\u63a5\u53e3\u662f\u57fa\u4e8eMobilenet-V2\u7684\u7f51\u7edc\u6765\u6d4b\u8bd5\u8fd0\u7b97\u8bbe\u5907\u7684\u7b97\u529b\uff0c\u4ee5\u6b64\u6765\u9884\u4f30\u6a21\u578b\u7684\n\u8fd0\u884c\u65f6\u95f4\uff08`\u8fd9\u4e2a\u65f6\u95f4\u4e0d\u662f\u5b8c\u5168\u51c6\u786e\u7684\uff0c\u53ea\u80fd\u4f5c\u4e3a\u4e00\u4e2a\u53c2\u8003\u503c`\uff09\u3002\n\u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\u53ef\u4ee5\u53c2\u8003[ModelSelector](app/src/main/java/com/nolan/macesegmentationdemo/segmentation/ModelSelector.java).\n\n## \u6a21\u578b\u9009\u62e9\u7b56\u7565\n\u4ece\u4e24\u4e2a\u7ef4\u5ea6\u51fa\u53d1\uff1a\u8bbe\u5907\uff0c\u6a21\u578b\u5927\u5c0f\u3002\n1. \u8bbe\u5907: DSP->CPU(quantized)->GPU(float)->CPU(float)\n2. \u6a21\u578b\u5927\u5c0f\uff1a\u9ad8->\u4f4e\n\n# \u9879\u76eeBuild\u6d41\u7a0b\n1. build\n```bash\n./gradlew build\n```\n2. install\n```bash\nadb install app/build/outputs/apk/release/app-release.apk\n```\n\n# \u6a21\u578b\u6784\u5efa\u6d41\u7a0b\n1. \u6a21\u578b\u8bad\u7ec3\n    * \u57fa\u4e8e[Mobile Deeplab-v3-plus](https://github.com/nolanliou/mobile-deeplab-v3-plus)\u9879\u76ee\uff0c\u8bad\u7ec3\u5f97\u5230\u6a21\u578b\u6587\u4ef6\u3002\n2. \u5b9a\u4e49MACE\u6240\u9700\u7684\u6a21\u578b\u914d\u7f6e\u6587\u4ef6\n    ```yaml\n    # model.yml\n    library_name: deeplab-v3-plus-mobilenet-v2\n    target_abis: [arm64-v8a]\n    target_socs: [all]\n    model_graph_format: file\n    model_data_format: file\n    models:\n      deeplab_v3_plus_mobilenet_v2:\n        platform: tensorflow\n        model_file_path: /path/to/model.pb\n        model_sha256_checksum: f672f424ac7b4827e13a097060860d0e4a77e5dd2933492be4329635fe1dfab2\n        subgraphs:\n          - input_tensors:\n              - Input\n            output_tensors:\n              - ResizeBilinear_1\n            input_shapes:\n              - 1,513,513,3\n            output_shapes:\n              - 1,513,513,2\n        runtime: cpu+gpu\n        limit_opencl_kernel_time: 0\n        nnlib_graph_mode: 0\n        obfuscate: 1\n        winograd: 0\n    ```\n3. \u6a21\u578b\u8f6c\u56fe\n    ```bash\n    git clone https://github.com/XiaoMi/mace\n    cd mace\n    git checkout v0.11.0-rc1\n    python tools/converter.py convert --config=/path/to/model.yml\n    python tools/converter.py run --config=/path/to/model.yml --validate --disable_tuning\n    ```\n    \u6709\u4e24\u4e2a\u53d8\u91cf\u9700\u8981\u63d0\u524d\u83b7\u53d6, \u53ef\u4ee5\u901a\u8fc7`MACE`\u7684\u5de5\u5177\u83b7\u53d6\u3002\n    * [BASE_CPU_EXEC_TIME](app/src/main/java/com/nolan/macesegmentationdemo/segmentation/ModelSelector.java): \u6d4b\u8bd5\u8bbe\u5907\u7684CPU capability\u3002\n    * [ModelInfo.baseCPUExexTime](app/src/main/java/com/nolan/macesegmentationdemo/common/ModelInfo.java): \u6a21\u578b\u5728\u6d4b\u8bd5\u8bbe\u5907\u4e0a\u7684CPU\u8fd0\u884c\u65f6\u95f4\u3002\n4. \u6a21\u578b\u91cf\u5316\n    * \u4f7f\u7528MACE\u7684Post Quantization\u5de5\u5177\u5bf9\u6a21\u578b\u8fdb\u884c\u91cf\u5316\uff0c[\u6587\u6863](https://mace.readthedocs.io/en/latest/user_guide/quantization_usage.html).\n    * \u4e0a\u8ff0\u6a21\u578b\u91cf\u5316\u540e\uff0c\u7cbe\u5ea6\u635f\u5931\u57281\u4e2a\u70b9\u4ee5\u5185\u3002\n5. \u62f7\u8d1d\u6a21\u578b\u6587\u4ef6\n    ```sh\n    # float model\n    cp builds/deeplab-v3-plus-mobilenet-v2/model/deeplab_v3_plus_mobilenet_v2.pb app/src/main/assets/deeplab_v3_plus_mobilenet_v2.pb\n    cp builds/deeplab-v3-plus-mobilenet-v2/model/deeplab_v3_plus_mobilenet_v2.data app/src/main/assets/deeplab_v3_plus_mobilenet_v2.data\n    # quantization model\n    cp builds/deeplab-v3-plus-mobilenet-v2/model/deeplab_v3_plus_mobilenet_v2.pb app/src/main/assets/deeplab_v3_plus_mobilenet_v2_quant.pb\n    cp builds/deeplab-v3-plus-mobilenet-v2/model/deeplab_v3_plus_mobilenet_v2.data app/src/main/assets/deeplab_v3_plus_mobilenet_v2_qunat.data\n    ```\n\n\n# TODO\n- [x] Add quantization model\n- [ ] Support multiple models with different input size\n- [ ] Add DSP model\n- [ ] Support multiple kind models\n\n## License\n[Apache License 2.0](LICENSE).\n\n# References\n1. **Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation**<br>\n\n    Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, Hartwig Adam. arXiv: 1802.02611.<br>\n\n    [[link]](https://arxiv.org/abs/1802.02611). arXiv: 1802.02611, 2018.\n   \n2. **MobileNetV2: Inverted Residuals and Linear Bottlenecks**<br />\n\n    Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen<br />\n   \n    [[link]](https://arxiv.org/abs/1801.04381). In CVPR, 2018.\n\n# Acknowledgement\n[JejuNet](https://github.com/tantara/JejuNet)\n\n",
            "readme_url": "https://github.com/nolanliou/PeopleSegmentationDemo",
            "frameworks": []
        }
    ],
    "references": [
        {
            "title": "MobileNetV2: Inverted Residuals and Linear Bottlenecks",
            "arxiv": "1801.04381",
            "year": 2018,
            "url": "http://arxiv.org/abs/1801.04381v4",
            "abstract": "In this paper we describe a new mobile architecture, MobileNetV2, that\nimproves the state of the art performance of mobile models on multiple tasks\nand benchmarks as well as across a spectrum of different model sizes. We also\ndescribe efficient ways of applying these mobile models to object detection in\na novel framework we call SSDLite. Additionally, we demonstrate how to build\nmobile semantic segmentation models through a reduced form of DeepLabv3 which\nwe call Mobile DeepLabv3.\n  The MobileNetV2 architecture is based on an inverted residual structure where\nthe input and output of the residual block are thin bottleneck layers opposite\nto traditional residual models which use expanded representations in the input\nan MobileNetV2 uses lightweight depthwise convolutions to filter features in\nthe intermediate expansion layer. Additionally, we find that it is important to\nremove non-linearities in the narrow layers in order to maintain\nrepresentational power. We demonstrate that this improves performance and\nprovide an intuition that led to this design. Finally, our approach allows\ndecoupling of the input/output domains from the expressiveness of the\ntransformation, which provides a convenient framework for further analysis. We\nmeasure our performance on Imagenet classification, COCO object detection, VOC\nimage segmentation. We evaluate the trade-offs between accuracy, and number of\noperations measured by multiply-adds (MAdd), as well as the number of\nparameters",
            "authors": [
                "Mark Sandler",
                "Andrew Howard",
                "Menglong Zhu",
                "Andrey Zhmoginov",
                "Liang-Chieh Chen"
            ]
        },
        {
            "title": "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation",
            "arxiv": "1802.02611",
            "year": 2018,
            "url": "http://arxiv.org/abs/1802.02611v3",
            "abstract": "Spatial pyramid pooling module or encode-decoder structure are used in deep\nneural networks for semantic segmentation task. The former networks are able to\nencode multi-scale contextual information by probing the incoming features with\nfilters or pooling operations at multiple rates and multiple effective\nfields-of-view, while the latter networks can capture sharper object boundaries\nby gradually recovering the spatial information. In this work, we propose to\ncombine the advantages from both methods. Specifically, our proposed model,\nDeepLabv3+, extends DeepLabv3 by adding a simple yet effective decoder module\nto refine the segmentation results especially along object boundaries. We\nfurther explore the Xception model and apply the depthwise separable\nconvolution to both Atrous Spatial Pyramid Pooling and decoder modules,\nresulting in a faster and stronger encoder-decoder network. We demonstrate the\neffectiveness of the proposed model on PASCAL VOC 2012 and Cityscapes datasets,\nachieving the test set performance of 89.0\\% and 82.1\\% without any\npost-processing. Our paper is accompanied with a publicly available reference\nimplementation of the proposed models in Tensorflow at\n\\url{https://github.com/tensorflow/models/tree/master/research/deeplab}.",
            "authors": [
                "Liang-Chieh Chen",
                "Yukun Zhu",
                "George Papandreou",
                "Florian Schroff",
                "Hartwig Adam"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999321117508009,
        "task": "Semantic Segmentation",
        "task_prob": 0.8396496291110616
    },
    "training": {
        "datasets": [
            {
                "name": "Cityscapes"
            },
            {
                "name": "COCO"
            },
            {
                "name": "PASCAL VOC 2012"
            },
            {
                "name": "ImageNet"
            }
        ]
    }
}
{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "CBAM-TensorFlow-Slim",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "kobiso",
                "owner_type": "User",
                "name": "CBAM-tensorflow-slim",
                "url": "https://github.com/kobiso/CBAM-tensorflow-slim",
                "stars": 102,
                "pushed_at": "2018-09-14 12:05:16+00:00",
                "created_at": "2018-08-06 12:45:21+00:00",
                "language": "Python",
                "description": "CBAM implementation on TensorFlow Slim",
                "license": "MIT License",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "f449d87ffd94f46e66e137be3dcfb95222547b6a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kobiso/CBAM-tensorflow-slim/blob/master/LICENSE"
                    }
                },
                "size": 1068
            },
            {
                "type": "code",
                "name": "__init__.py",
                "sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kobiso/CBAM-tensorflow-slim/blob/master/__init__.py"
                    }
                },
                "size": 0
            },
            {
                "type": "code",
                "name": "datasets",
                "sha": "7b03e159425be8189aba4d43d1880ae91111bf0c",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kobiso/CBAM-tensorflow-slim/tree/master/datasets"
                    }
                },
                "num_files": 9
            },
            {
                "type": "code",
                "name": "deployment",
                "sha": "9fbb06a2665916f804c19733dd6e2034546814c9",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kobiso/CBAM-tensorflow-slim/tree/master/deployment"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "eval_image_classifier.py",
                "sha": "e3b4021a9d1bd3967ca5ed49be156485aafd5607",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kobiso/CBAM-tensorflow-slim/blob/master/eval_image_classifier.py"
                    }
                },
                "size": 7069
            },
            {
                "type": "code",
                "name": "eval_image_classifier_loop.py",
                "sha": "213eaf33f9e51e70b9cfb24203b5518112fcfa93",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kobiso/CBAM-tensorflow-slim/blob/master/eval_image_classifier_loop.py"
                    }
                },
                "size": 7580
            },
            {
                "type": "code",
                "name": "figures",
                "sha": "1bb2bf7abfa450239c6251dc4c3ab788d25a176e",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kobiso/CBAM-tensorflow-slim/tree/master/figures"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "nets",
                "sha": "f2502821ab1372f7b3afd35826cadb36002dda4b",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kobiso/CBAM-tensorflow-slim/tree/master/nets"
                    }
                },
                "num_files": 43
            },
            {
                "type": "code",
                "name": "preprocessing",
                "sha": "d0a5fc838f2082e83a7e692e3c4cc612cffadc51",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kobiso/CBAM-tensorflow-slim/tree/master/preprocessing"
                    }
                },
                "num_files": 6
            },
            {
                "type": "code",
                "name": "scripts",
                "sha": "b767f0c8f34cddf7f7596289526258d927320ae9",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kobiso/CBAM-tensorflow-slim/tree/master/scripts"
                    }
                },
                "num_files": 6
            },
            {
                "type": "code",
                "name": "train_image_classifier.py",
                "sha": "895046beb6628739bc01f48a5e7439ada9d8c61e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kobiso/CBAM-tensorflow-slim/blob/master/train_image_classifier.py"
                    }
                },
                "size": 20835
            }
        ]
    },
    "authors": [
        {
            "name": "ByungSoo Ko",
            "email": "kobiso62@gmail.com",
            "github_id": "kobiso"
        }
    ],
    "tags": [
        "cbam",
        "senet",
        "tensorflow",
        "slim",
        "resnet",
        "inception-resnet-v2",
        "inception-v4"
    ],
    "description": "CBAM implementation on TensorFlow Slim",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/kobiso/CBAM-tensorflow-slim",
            "stars": 102,
            "issues": true,
            "readme": "# CBAM-TensorFlow-Slim\nThis is a Tensorflow implementation of [\"CBAM: Convolutional Block Attention Module\"](https://arxiv.org/pdf/1807.06521) aiming to be compatible on the [TensorFlow-Slim image classification model library](https://github.com/tensorflow/models/tree/master/research/slim).\nThis repository includes the implementation of [\"SENet-tensorflow-slim\"](https://github.com/kobiso/SENet-tensorflow-slim).\n\nIf you want to use simpler implementation, check the repository **\"[CBAM-TensorFlow](https://github.com/kobiso/CBAM-tensorflow)\"** which includes simple tensorflow implementation of [*ResNext*](https://arxiv.org/abs/1611.05431), [*Inception-V4*, and *Inception-ResNet-V2*](https://arxiv.org/abs/1602.07261) on Cifar10 dataset.\n\n## CBAM: Convolutional Block Attention Module\n**CBAM** proposes an architectural unit called *\"Convolutional Block Attention Module\" (CBAM)* block to improve representation power by using attention mechanism: focusing on important features and supressing unnecessary ones.\nThis research can be considered as a descendant and an improvement of [\"Squeeze-and-Excitation Networks\"](https://arxiv.org/pdf/1709.01507).\n\n### Diagram of a CBAM_block\n<div align=\"center\">\n  <img src=\"https://github.com/kobiso/CBAM-tensorflow-slim/blob/master/figures/overview.png\">\n</div>\n\n### Diagram of each attention sub-module\n<div align=\"center\">\n  <img src=\"https://github.com/kobiso/CBAM-tensorflow-slim/blob/master/figures/submodule.png\">\n</div>\n\n### Classification results on ImageNet-1K\n\n<div align=\"center\">\n  <img src=\"https://github.com/kobiso/CBAM-tensorflow-slim/blob/master/figures/exp4.png\">\n</div>\n\n<div align=\"center\">\n  <img src=\"https://github.com/kobiso/CBAM-tensorflow-slim/blob/master/figures/exp5.png\"  width=\"750\">\n</div>\n\n## Prerequisites\n- Python 3.x\n- TensorFlow 1.x\n- TF-slim\n  - Check the ['installation' part of TF-Slim image models README](https://github.com/tensorflow/models/tree/master/research/slim#installation).\n\n## Prepare Data set\nYou should prepare your own dataset or open dataset (Cifar10, flowers, MNIST, ImageNet).\nFor preparing dataset, you can follow the ['preparing the datasets' part in TF-Slim image models README](https://github.com/tensorflow/models/tree/master/research/slim#preparing-the-datasets).\n\n## CBAM_block and SE_block Supportive Models\nThis project is based on TensorFlow-Slim image classification model library.\nEvery image classification model in TensorFlow-Slim can be run the same.\nAnd, you can run **CBAM_block** or **SE_block** added models in the below list by adding one argument `--attention_module=cbam_block` or `--attention_module=se_block` when you train or evaluate a model.\n\n- Inception V4 + CBAM / + SE\n- Inception-ResNet-v2 + CBAM / + SE\n- ResNet V1 50 + CBAM / + SE\n- ResNet V1 101 + CBAM / + SE\n- ResNet V1 152 + CBAM / + SE\n- ResNet V1 200 + CBAM / + SE\n- ResNet V2 50 + CBAM / + SE\n- ResNet V2 101 + CBAM / + SE\n- ResNet V2 152 + CBAM / + SE\n- ResNet V2 200 + CBAM / + SE\n\n### Change *Reduction ratio*\nTo change *reduction ratio*, you have to manually set the ratio on `def cbam_block(input_feature, name, ratio=16)` method for cbam_block or `def se_block(residual, name, ratio=8)` method for se_block in `CBAM-tensorflow-slim/nets/attention_module.py`.\n\n## Train a Model\nYou can find example of training script in `CBAM-tensorflow-slim/scripts/`.\n\n### Train a model with CBAM_block\nBelow script gives you an example of training a model with CBAM_block.\n```\nDATASET_DIR=/DIRECTORY/TO/DATASET\nTRAIN_DIR=/DIRECTORY/TO/TRAIN\nCUDA_VISIBLE_DEVICES=0 python train_image_classifier.py \\\n    --train_dir=${TRAIN_DIR} \\\n    --dataset_name=imagenet \\\n    --dataset_split_name=train \\\n    --dataset_dir=${DATASET_DIR} \\\n    --model_name=resnet_v1_50 \\\n    --batch_size=100 \\\n    --attention_module=cbam_block\n```\n\n### Train a model with SE_block\nBelow script gives you an example of training a model with SE_block.\n```\nDATASET_DIR=/DIRECTORY/TO/DATASET\nTRAIN_DIR=/DIRECTORY/TO/TRAIN\nCUDA_VISIBLE_DEVICES=0 python train_image_classifier.py \\\n    --train_dir=${TRAIN_DIR} \\\n    --dataset_name=imagenet \\\n    --dataset_split_name=train \\\n    --dataset_dir=${DATASET_DIR} \\\n    --model_name=resnet_v1_50 \\\n    --batch_size=100 \\\n    --attention_module=se_block\n```\n\n\n### Train a model without attention module\nBelow script gives you an example of training a model without attention module.\n```\nDATASET_DIR=/DIRECTORY/TO/DATASET\nTRAIN_DIR=/DIRECTORY/TO/TRAIN\nCUDA_VISIBLE_DEVICES=0 python train_image_classifier.py \\\n    --train_dir=${TRAIN_DIR} \\\n    --dataset_name=imagenet \\\n    --dataset_split_name=train \\\n    --dataset_dir=${DATASET_DIR} \\\n    --model_name=resnet_v1_50 \\\n    --batch_size=100\n```\n\n## Evaluate a Model\nYou can find example of evaluation script in `CBAM-tensorflow-slim/scripts/`.\nTo keep track of validation accuracy while training, you can use `eval_image_classifier_loop.py` which evaluate the performance at multiple checkpoints during training.\nIf you want to just evaluate a model once, you can use `eval_image_classifier.py`.\n\n### Evaluate a model with CBAM_block\nBelow script gives you an example of evaluating a model with CBAM_block during training.\n\n\n```\nDATASET_DIR=/DIRECTORY/TO/DATASET\nCHECKPOINT_FILE=/DIRECTORY/TO/CHECKPOINT\nEVAL_DIR=/DIRECTORY/TO/EVAL\nCUDA_VISIBLE_DEVICES=0 python eval_image_classifier_loop.py \\\n    --alsologtostderr \\\n    --checkpoint_path=${CHECKPOINT_FILE} \\\n    --dataset_dir=${DATASET_DIR} \\\n    --eval_dir=${EVAL_DIR} \\\n    --dataset_name=imagenet \\\n    --dataset_split_name=validation \\\n    --model_name=resnet_v1_50 \\\n    --batch_size=100 \\\n    --attention_module=cbam_block\n```\n\n### Evaluate a model with SE-block\nBelow script gives you an example of evaluating a model with SE_block during training.\n\n```\nDATASET_DIR=/DIRECTORY/TO/DATASET\nCHECKPOINT_FILE=/DIRECTORY/TO/CHECKPOINT\nEVAL_DIR=/DIRECTORY/TO/EVAL\nCUDA_VISIBLE_DEVICES=0 python eval_image_classifier_loop.py \\\n    --alsologtostderr \\\n    --checkpoint_path=${CHECKPOINT_FILE} \\\n    --dataset_dir=${DATASET_DIR} \\\n    --eval_dir=${EVAL_DIR} \\\n    --dataset_name=imagenet \\\n    --dataset_split_name=validation \\\n    --model_name=resnet_v1_50 \\\n    --batch_size=100 \\\n    --attention_module=se_block\n```\n\n### Evaluate a model without attention module\nBelow script gives you an example of evaluating a model without attention module during training.\n\n```\nDATASET_DIR=/DIRECTORY/TO/DATASET\nCHECKPOINT_FILE=/DIRECTORY/TO/CHECKPOINT\nEVAL_DIR=/DIRECTORY/TO/EVAL\nCUDA_VISIBLE_DEVICES=0 python eval_image_classifier_loop.py \\\n    --alsologtostderr \\\n    --checkpoint_path=${CHECKPOINT_FILE} \\\n    --dataset_dir=${DATASET_DIR} \\\n    --eval_dir=${EVAL_DIR} \\\n    --dataset_name=imagenet \\\n    --dataset_split_name=validation \\\n    --model_name=resnet_v1_50 \\\n    --batch_size=100 \n```\n\n## Related Works\n- Blog: [CBAM: Convolutional Block Attention Module](https://kobiso.github.io//research/research-CBAM/)\n- Repository: [CBAM-TensorFlow](https://github.com/kobiso/CBAM-tensorflow)\n- Repository: [CBAM-Keras](https://github.com/kobiso/CBAM-keras)\n- Repository: [SENet-TensorFlow-Slim](https://github.com/kobiso/SENet-tensorflow-slim)\n\n## Reference\n- Paper: [CBAM: Convolutional Block Attention Module](https://arxiv.org/pdf/1807.06521)\n- Paper: [Squeeze-and-Excitation Networks](https://arxiv.org/pdf/1709.01507)\n- Repository: [TensorFlow-Slim image classification model library](https://github.com/tensorflow/models/tree/master/research/slim)\n  \n## Author\nByung Soo Ko / kobiso62@gmail.com\n",
            "readme_url": "https://github.com/kobiso/CBAM-tensorflow-slim",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning",
            "arxiv": "1602.07261",
            "year": 2016,
            "url": "http://arxiv.org/abs/1602.07261v2",
            "abstract": "Very deep convolutional networks have been central to the largest advances in\nimage recognition performance in recent years. One example is the Inception\narchitecture that has been shown to achieve very good performance at relatively\nlow computational cost. Recently, the introduction of residual connections in\nconjunction with a more traditional architecture has yielded state-of-the-art\nperformance in the 2015 ILSVRC challenge; its performance was similar to the\nlatest generation Inception-v3 network. This raises the question of whether\nthere are any benefit in combining the Inception architecture with residual\nconnections. Here we give clear empirical evidence that training with residual\nconnections accelerates the training of Inception networks significantly. There\nis also some evidence of residual Inception networks outperforming similarly\nexpensive Inception networks without residual connections by a thin margin. We\nalso present several new streamlined architectures for both residual and\nnon-residual Inception networks. These variations improve the single-frame\nrecognition performance on the ILSVRC 2012 classification task significantly.\nWe further demonstrate how proper activation scaling stabilizes the training of\nvery wide residual Inception networks. With an ensemble of three residual and\none Inception-v4, we achieve 3.08 percent top-5 error on the test set of the\nImageNet classification (CLS) challenge",
            "authors": [
                "Christian Szegedy",
                "Sergey Ioffe",
                "Vincent Vanhoucke",
                "Alex Alemi"
            ]
        },
        {
            "title": "Aggregated Residual Transformations for Deep Neural Networks",
            "arxiv": "1611.05431",
            "year": 2016,
            "url": "http://arxiv.org/abs/1611.05431v2",
            "abstract": "We present a simple, highly modularized network architecture for image\nclassification. Our network is constructed by repeating a building block that\naggregates a set of transformations with the same topology. Our simple design\nresults in a homogeneous, multi-branch architecture that has only a few\nhyper-parameters to set. This strategy exposes a new dimension, which we call\n\"cardinality\" (the size of the set of transformations), as an essential factor\nin addition to the dimensions of depth and width. On the ImageNet-1K dataset,\nwe empirically show that even under the restricted condition of maintaining\ncomplexity, increasing cardinality is able to improve classification accuracy.\nMoreover, increasing cardinality is more effective than going deeper or wider\nwhen we increase the capacity. Our models, named ResNeXt, are the foundations\nof our entry to the ILSVRC 2016 classification task in which we secured 2nd\nplace. We further investigate ResNeXt on an ImageNet-5K set and the COCO\ndetection set, also showing better results than its ResNet counterpart. The\ncode and models are publicly available online.",
            "authors": [
                "Saining Xie",
                "Ross Girshick",
                "Piotr Doll\u00e1r",
                "Zhuowen Tu",
                "Kaiming He"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "'preparing the datasets' part in TF-Slim image models README",
                "connection": {
                    "name": "url",
                    "source": {
                        "url": "https://github.com/tensorflow/models/tree/master/research/slim#preparing-the-datasets"
                    }
                }
            },
            {
                "name": "MNIST"
            },
            {
                "name": "ImageNet"
            },
            {
                "name": "ILSVRC 2016"
            },
            {
                "name": "COCO"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999987070555084,
        "task": "Image Classification",
        "task_prob": 0.986992595775517
    }
}
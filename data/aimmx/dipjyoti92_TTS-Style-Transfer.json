{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Enhancing Speech Intelligibility in Text-To-Speech Synthesis using Speaking Style Conversion",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "dipjyoti92",
                "owner_type": "User",
                "name": "TTS-Style-Transfer",
                "url": "https://github.com/dipjyoti92/TTS-Style-Transfer",
                "stars": 12,
                "pushed_at": "2020-12-03 00:09:34+00:00",
                "created_at": "2020-07-29 08:12:12+00:00",
                "language": "Python",
                "description": "Official PyTorch implementation of TTS Style Transfer",
                "license": "MIT License",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitattributes",
                "sha": "327ba52a0eefacdcd8ce408556858f640b11b328",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/blob/master/.gitattributes"
                    }
                },
                "size": 32
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "c7c9c68dd3f6ba04f44e2c74d25e7b70bbf397e6",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/blob/master/.gitignore"
                    }
                },
                "size": 494
            },
            {
                "type": "code",
                "name": "LICENSE.txt",
                "sha": "dd5a327d8228bb6049b2f4f35f0477cc6afd8fde",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/blob/master/LICENSE.txt"
                    }
                },
                "size": 1095
            },
            {
                "type": "code",
                "name": "_config.yml",
                "sha": "c4192631f25b34d77a7f159aa0da0e3ae99c4ef4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/blob/master/_config.yml"
                    }
                },
                "size": 26
            },
            {
                "type": "code",
                "name": "assets",
                "sha": "acf3cde6c194755b5f93f02051a41122d0f243d4",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/tree/master/assets"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "checkpoints",
                "sha": "8506027b35193bb9f2a7cde191c0380cdddedae3",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/tree/master/checkpoints"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "gen_tacotron.py",
                "sha": "f74a376f2443dd976197a1e22d4057b40d23e90a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/blob/master/gen_tacotron.py"
                    }
                },
                "size": 4681
            },
            {
                "type": "code",
                "name": "gen_wavernn.py",
                "sha": "ec7f56ca127d775ff499befbf870c1203be4199a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/blob/master/gen_wavernn.py"
                    }
                },
                "size": 4325
            },
            {
                "type": "code",
                "name": "hparams.py",
                "sha": "a74b1fa4960c77435dc644666e0182cc9125564f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/blob/master/hparams.py"
                    }
                },
                "size": 3967
            },
            {
                "type": "code",
                "name": "models",
                "sha": "aca922365f0769fa052f600fb6a9f5743ccd12dd",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/tree/master/models"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "notebooks",
                "sha": "e0de55cbc3ee623f8176b668083f76d1ec4e9b2a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/tree/master/notebooks"
                    }
                },
                "num_files": 10
            },
            {
                "type": "code",
                "name": "preprocess.py",
                "sha": "77c1a9d4db14df076ad53c91f3a668c83bf7dde4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/blob/master/preprocess.py"
                    }
                },
                "size": 2497
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "aa7140a6b298e61277aa4c22b50fc4a7a44db27d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/blob/master/requirements.txt"
                    }
                },
                "size": 62
            },
            {
                "type": "code",
                "name": "sentences.txt",
                "sha": "c91b86a864caa4431b5d4f0078e202c755ac8501",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/blob/master/sentences.txt"
                    }
                },
                "size": 442
            },
            {
                "type": "code",
                "name": "train_tacotron.py",
                "sha": "f6c41ec6a35ffa8964c70c59528cbca6f7dc1a98",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/blob/master/train_tacotron.py"
                    }
                },
                "size": 5039
            },
            {
                "type": "code",
                "name": "train_wavernn.py",
                "sha": "0a36f35a5582d91b3801cdea6649804777914b1d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/blob/master/train_wavernn.py"
                    }
                },
                "size": 4411
            },
            {
                "type": "code",
                "name": "utils",
                "sha": "d14e548b029696a651ac452b31b96a32a34b9cda",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/dipjyoti92/TTS-Style-Transfer/tree/master/utils"
                    }
                },
                "num_files": 9
            }
        ]
    },
    "authors": [
        {
            "name": "Dipjyoti Paul",
            "github_id": "dipjyoti92"
        }
    ],
    "tags": [],
    "description": "Official PyTorch implementation of TTS Style Transfer",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/dipjyoti92/TTS-Style-Transfer",
            "stars": 12,
            "issues": true,
            "readme": "# Enhancing Speech Intelligibility in Text-To-Speech Synthesis using Speaking Style Conversion\n\nDipjyoti Paul<sup>a</sup>,  Muhammed PV Shifas<sup>a</sup>, Yannis Pantazis<sup>b</sup> and Yannis Stylianou<sup>a</sup>\n\n<sup>a</sup>Computer Science Department, University of Crete\n\n<sup>b</sup>Inst. of Applied and Computational Mathematics, Foundation for Research and Technology - Hellas\n\n\n### Abstract: \nThe increased adoption of digital assistants makes text-to-speech (TTS) synthesis systems an indispensable feature of modern mobile devices. It is hence desirable to build a system capable of generating highly intelligible speech in the presence of noise. Past studies have investigated style conversion in TTS synthesis, yet degraded synthesized quality often leads to worse intelligibility. To overcome such limitations, we proposed a novel transfer learning approach using Tacotron and WaveRNN based TTS synthesis. The proposed speech system exploits two modification strategies: (a) Lombard speaking style data and (b) Spectral Shaping and Dynamic Range Compression (SSDRC) which has been shown to provide high intelligibility gains by redistributing the signal energy on the time-frequency domain. We refer to this extension as Lombard-SSDRC TTS system. Intelligibility enhancement as quantified by the Intelligibility in Bits (SIIB-Gauss) measure shows that the proposed Lombard-SSDRC TTS system shows significant relative improvement between 110% and 130% in speech-shaped noise (SSN), and 47% to 140% in competing-speaker noise (CSN) against the state-of-the-art TTS approach. Additional subjective evaluation shows that Lombard-SSDRC TTS successfully increases the speech intelligibility with relative improvement of 455% for SSN and 104% for CSN in median keyword correction rate compared to the baseline TTS method.\n\n# Audio Samples:\n[Samples](https://www.csd.uoc.gr/~dipjyotipaul/Style-transfer-tts-IS20)\n\n# Tacotron + WaveRNN Diagram:\n\n![Tacotron with WaveRNN diagrams](assets/Tacotron_wavernn.jpg)\n\n# WaveRNN Diagram:\n\n![WaveRNN diagrams](assets/WaveRNN.jpg)\n\nPytorch implementation of Tarotron and WaveRNN model.\n\n# Installation\n\nEnsure you have:\n\n* Python >= 3.6\n* [Pytorch 1 with CUDA](https://pytorch.org/)\n\nThen install the rest with pip:\n\n> pip install -r requirements.txt\n\n\n# Training\n![Attenion and Mel Training GIF](assets/training_viz.gif)\n\n### Preprocessing\nDownload your Dataset.\n* LJSpeech corpus\n*  Nick Hurricane Challenge speech data (Normal and Lombard styles)\n*  SSDRC-ed Nick data\n\nEdit **hparams.py**, point **wav_path** to your dataset and run:\n\n> python preprocess.py\n\nor use preprocess.py --path to point directly to the dataset\n___\n### Train Tacotron & WaveRNN\nHere's my recommendation on what order to run things:\n\n1 - Train Tacotron with:\n\n> python train_tacotron.py\n\n2 - You can leave that finish training or at any point you can use:\n\n> python train_tacotron.py --force_gta\n\nthis will force tactron to create a GTA dataset even if it hasn't finish training.\n\n3 - Train WaveRNN with:\n\n> python train_wavernn.py --gta\n\nNB: You can always just run train_wavernn.py without --gta if you're not interested in TTS.\n\n4 - Generate Sentences with both models using:\n\n> python gen_tacotron.py\n\nthis will generate default sentences. If you want generate custom sentences you can use\n\n> python gen_tacotron.py --input_text \"this is whatever you want it to be\"\n\nAnd finally, you can always use --help on any of those scripts to see what options are available :)\n\n____\n\n### References\n\n* [Efficient Neural Audio Synthesis](https://arxiv.org/abs/1802.08435v1)\n* [Tacotron: Towards End-to-End Speech Synthesis](https://arxiv.org/abs/1703.10135)\n* [Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions](https://arxiv.org/abs/1712.05884)\n* [Lombard Speech Synthesis using Transfer Learning in a TacotronText-to-Speech System](https://www.isca-speech.org/archive/Interspeech_2019/pdfs/1333.pdf) \n\n### Acknowlegements\n\n* [https://github.com/fatchord/WaveRNN](https://github.com/fatchord/WaveRNN)\n* [https://github.com/keithito/tacotron](https://github.com/keithito/tacotron)\n\n",
            "readme_url": "https://github.com/dipjyoti92/TTS-Style-Transfer",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Efficient Neural Audio Synthesis",
            "arxiv": "1802.08435",
            "year": 2018,
            "url": "http://arxiv.org/abs/1802.08435v2",
            "abstract": "Sequential models achieve state-of-the-art results in audio, visual and\ntextual domains with respect to both estimating the data distribution and\ngenerating high-quality samples. Efficient sampling for this class of models\nhas however remained an elusive problem. With a focus on text-to-speech\nsynthesis, we describe a set of general techniques for reducing sampling time\nwhile maintaining high output quality. We first describe a single-layer\nrecurrent neural network, the WaveRNN, with a dual softmax layer that matches\nthe quality of the state-of-the-art WaveNet model. The compact form of the\nnetwork makes it possible to generate 24kHz 16-bit audio 4x faster than real\ntime on a GPU. Second, we apply a weight pruning technique to reduce the number\nof weights in the WaveRNN. We find that, for a constant number of parameters,\nlarge sparse networks perform better than small dense networks and this\nrelationship holds for sparsity levels beyond 96%. The small number of weights\nin a Sparse WaveRNN makes it possible to sample high-fidelity audio on a mobile\nCPU in real time. Finally, we propose a new generation scheme based on\nsubscaling that folds a long sequence into a batch of shorter sequences and\nallows one to generate multiple samples at once. The Subscale WaveRNN produces\n16 samples per step without loss of quality and offers an orthogonal method for\nincreasing sampling efficiency.",
            "authors": [
                "Nal Kalchbrenner",
                "Erich Elsen",
                "Karen Simonyan",
                "Seb Noury",
                "Norman Casagrande",
                "Edward Lockhart",
                "Florian Stimberg",
                "Aaron van den Oord",
                "Sander Dieleman",
                "Koray Kavukcuoglu"
            ]
        },
        {
            "title": "Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions",
            "arxiv": "1712.05884",
            "year": 2017,
            "url": "http://arxiv.org/abs/1712.05884v2",
            "abstract": "This paper describes Tacotron 2, a neural network architecture for speech\nsynthesis directly from text. The system is composed of a recurrent\nsequence-to-sequence feature prediction network that maps character embeddings\nto mel-scale spectrograms, followed by a modified WaveNet model acting as a\nvocoder to synthesize timedomain waveforms from those spectrograms. Our model\nachieves a mean opinion score (MOS) of $4.53$ comparable to a MOS of $4.58$ for\nprofessionally recorded speech. To validate our design choices, we present\nablation studies of key components of our system and evaluate the impact of\nusing mel spectrograms as the input to WaveNet instead of linguistic, duration,\nand $F_0$ features. We further demonstrate that using a compact acoustic\nintermediate representation enables significant simplification of the WaveNet\narchitecture.",
            "authors": [
                "Jonathan Shen",
                "Ruoming Pang",
                "Ron J. Weiss",
                "Mike Schuster",
                "Navdeep Jaitly",
                "Zongheng Yang",
                "Zhifeng Chen",
                "Yu Zhang",
                "Yuxuan Wang",
                "RJ Skerry-Ryan",
                "Rif A. Saurous",
                "Yannis Agiomyrgiannakis",
                "Yonghui Wu"
            ]
        },
        {
            "title": "Tacotron: Towards End-to-End Speech Synthesis",
            "arxiv": "1703.10135",
            "year": 2017,
            "url": "http://arxiv.org/abs/1703.10135v2",
            "abstract": "A text-to-speech synthesis system typically consists of multiple stages, such\nas a text analysis frontend, an acoustic model and an audio synthesis module.\nBuilding these components often requires extensive domain expertise and may\ncontain brittle design choices. In this paper, we present Tacotron, an\nend-to-end generative text-to-speech model that synthesizes speech directly\nfrom characters. Given <text, audio> pairs, the model can be trained completely\nfrom scratch with random initialization. We present several key techniques to\nmake the sequence-to-sequence framework perform well for this challenging task.\nTacotron achieves a 3.82 subjective 5-scale mean opinion score on US English,\noutperforming a production parametric system in terms of naturalness. In\naddition, since Tacotron generates speech at the frame level, it's\nsubstantially faster than sample-level autoregressive methods.",
            "authors": [
                "Yuxuan Wang",
                "RJ Skerry-Ryan",
                "Daisy Stanton",
                "Yonghui Wu",
                "Ron J. Weiss",
                "Navdeep Jaitly",
                "Zongheng Yang",
                "Ying Xiao",
                "Zhifeng Chen",
                "Samy Bengio",
                "Quoc Le",
                "Yannis Agiomyrgiannakis",
                "Rob Clark",
                "Rif A. Saurous"
            ]
        },
        {
            "title": "Pytorch 1 with CUDA",
            "url": "https://pytorch.org/"
        },
        {
            "title": "Lombard Speech Synthesis using Transfer Learning in a TacotronText-to-Speech System",
            "url": "https://www.isca-speech.org/archive/Interspeech_2019/pdfs/1333.pdf"
        },
        {
            "title": "https://github.com/fatchord/WaveRNN",
            "url": "https://github.com/fatchord/WaveRNN"
        },
        {
            "title": "https://github.com/keithito/tacotron",
            "url": "https://github.com/keithito/tacotron"
        }
    ],
    "domain": {
        "domain_type": "Speech",
        "domain_prob": 0.9869458618514275
    }
}
{
    "visibility": {
        "visibility": "public",
        "license": "Other"
    },
    "name": "Yolo-v3 and Yolo-v2 for Windows and Linux",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "kyunghwan",
                "owner_type": "User",
                "name": "darknet_v3",
                "url": "https://github.com/kyunghwan/darknet_v3",
                "stars": 0,
                "pushed_at": "2019-07-18 01:10:37+00:00",
                "created_at": "2018-07-06 07:28:07+00:00",
                "language": "Shell",
                "license": "Other",
                "frameworks": []
            },
            {
                "type": "code",
                "name": ".circleci",
                "sha": "d21e3844195fd45760fa92e04f74733a7cac9388",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/tree/master/.circleci"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "1bd67d08836ebe59bf7ad5a02a3f48d9c621e456",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/.gitignore"
                    }
                },
                "size": 271
            },
            {
                "type": "code",
                "name": "3rdparty",
                "sha": "babc39d0d66a4fd7e40737b79f9b53a2d4c476a4",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/tree/master/3rdparty"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "a50f7d700ba02bfacd50f59b315311cf4d0bbda2",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/LICENSE"
                    }
                },
                "size": 515
            },
            {
                "type": "code",
                "name": "Makefile",
                "sha": "610b29e4c7a19f33a4b4f21758b0b6ae4d1fc165",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/Makefile"
                    }
                },
                "size": 4281
            },
            {
                "type": "code",
                "name": "anchors.txt",
                "sha": "21b673faef471edbffdf55504869a578db2dd06b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/anchors.txt"
                    }
                },
                "size": 169
            },
            {
                "type": "code",
                "name": "bad.list",
                "sha": "3edab87b6e0ed70ccac8f3fea68479c9c459a20c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/bad.list"
                    }
                },
                "size": 61
            },
            {
                "type": "code",
                "name": "bad_label.list",
                "sha": "a0ddd40ca8f95da50cd46a0984c4fbd1986e3a19",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/bad_label.list"
                    }
                },
                "size": 602923
            },
            {
                "type": "code",
                "name": "build",
                "sha": "2371c04d33c68e3e88e79bcef8f13e8f2252489d",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/tree/master/build"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "cfg",
                "sha": "d5a762ece8b42829a881d635e52eb8f16342603c",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/tree/master/cfg"
                    }
                },
                "num_files": 56
            },
            {
                "type": "code",
                "name": "chart.jpg",
                "sha": "b82f63559ab8438afdb935a0de523883608bf464",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/chart.jpg"
                    }
                },
                "size": 408535
            },
            {
                "type": "code",
                "name": "chart_1.jpg",
                "sha": "2bc68ab2cfc5261fe0f20d3a4ae09677221fd76a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/chart_1.jpg"
                    }
                },
                "size": 406872
            },
            {
                "type": "code",
                "name": "chart_v3.jpg",
                "sha": "6069462476062a30768060a8c5d71b7fdb5ec60e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/chart_v3.jpg"
                    }
                },
                "size": 410384
            },
            {
                "type": "code",
                "name": "darknet",
                "sha": "038df23d4f00e25be43847ad03312c120a14f020",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/darknet"
                    }
                },
                "size": 2089568
            },
            {
                "type": "code",
                "name": "darknet.py",
                "sha": "4bca5f5a3b9253717faf9a1d6612ef7083701ad0",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/darknet.py"
                    }
                },
                "size": 15851
            },
            {
                "type": "code",
                "name": "data",
                "sha": "df3f28cb7a8a1c176c8759ddbe2acaa56d4adb34",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/tree/master/data"
                    }
                },
                "num_files": 14
            },
            {
                "type": "code",
                "name": "image_yolov2.sh",
                "sha": "b1d518640a8e48145aa008d8d888caf093d70b69",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/image_yolov2.sh"
                    }
                },
                "size": 108
            },
            {
                "type": "code",
                "name": "image_yolov3.sh",
                "sha": "49cc5eb66db36d7036bbb70388edefc26a3468b8",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/image_yolov3.sh"
                    }
                },
                "size": 110
            },
            {
                "type": "code",
                "name": "mjpeg_stream.sh",
                "sha": "ff21ddf49b2b4c6b96c31d9725c62d626c76203d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/mjpeg_stream.sh"
                    }
                },
                "size": 245
            },
            {
                "type": "code",
                "name": "net_cam_v3.sh",
                "sha": "5320eddf34d089edcdf7c776ee2e0f06449ec7db",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/net_cam_v3.sh"
                    }
                },
                "size": 160
            },
            {
                "type": "code",
                "name": "predictions.jpg",
                "sha": "fac241a20312a38d63c7d12de05270b3f62141b7",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/predictions.jpg"
                    }
                },
                "size": 3418509
            },
            {
                "type": "code",
                "name": "result.txt",
                "sha": "387311909504b27aeedd1b79d7847efba760e941",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/result.txt"
                    }
                },
                "size": 56944
            },
            {
                "type": "code",
                "name": "scripts",
                "sha": "68db61fe49dd909066a8bcbbc7de756f10624e01",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/tree/master/scripts"
                    }
                },
                "num_files": 14
            },
            {
                "type": "code",
                "name": "src",
                "sha": "bd3a8e4ffa6c8af42e46b70159af73a8ab35dc1a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/tree/master/src"
                    }
                },
                "num_files": 128
            },
            {
                "type": "code",
                "name": "test0529.sh",
                "sha": "8e947212aedc4cc160b8e1be9f0e84f47de2d5ee",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/test0529.sh"
                    }
                },
                "size": 113300
            },
            {
                "type": "code",
                "name": "test0711.sh",
                "sha": "6163895d8e864b2bf2bcc9e3b2c37dcdd9f5bbc2",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/test0711.sh"
                    }
                },
                "size": 121700
            },
            {
                "type": "code",
                "name": "test0814.sh",
                "sha": "018100b99e6078240dd73e5a5e065a18ef4b9dd7",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/test0814.sh"
                    }
                },
                "size": 121700
            },
            {
                "type": "code",
                "name": "test1022.sh",
                "sha": "43a8257eb2807d81553031f3dc4f3615bbbaac4a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/test1022.sh"
                    }
                },
                "size": 73445
            },
            {
                "type": "code",
                "name": "test1121.sh",
                "sha": "44f31a39554935ca18ba875bf7ba9a2a76695c92",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/test1121.sh"
                    }
                },
                "size": 122969
            },
            {
                "type": "code",
                "name": "test_1121_3.sh",
                "sha": "5416ed4af31d25261752ddde099950a2809dd430",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/test_1121_3.sh"
                    }
                },
                "size": 259471
            },
            {
                "type": "code",
                "name": "test_1121_4.sh",
                "sha": "f865675605640f540ee7179ffca123c927326014",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/test_1121_4.sh"
                    }
                },
                "size": 247471
            },
            {
                "type": "code",
                "name": "test_1121_5.sh",
                "sha": "8688d17b49718a8a9f6c1d6238dc01f9c833e16f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/test_1121_5.sh"
                    }
                },
                "size": 247471
            },
            {
                "type": "code",
                "name": "uselib",
                "sha": "69934726a18f6d5b2a2d8d3f242fa776cc9c5184",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/uselib"
                    }
                },
                "size": 125000
            },
            {
                "type": "code",
                "name": "video_v2.sh",
                "sha": "919c5791c340e215f78aeea9ac33012c1b6bb666",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/video_v2.sh"
                    }
                },
                "size": 108
            },
            {
                "type": "code",
                "name": "video_yolov3.sh",
                "sha": "2d0346acb88d6b4c8ac1e34845c0974ed07333d0",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kyunghwan/darknet_v3/blob/master/video_yolov3.sh"
                    }
                },
                "size": 108
            }
        ]
    },
    "authors": [
        {
            "name": "Alexey",
            "github_id": "AlexeyAB"
        },
        {
            "name": "Joseph Redmon",
            "github_id": "pjreddie"
        },
        {
            "name": "Tino Hager",
            "email": "tino.hager@nager.at",
            "github_id": "tinohager"
        },
        {
            "name": "khgit",
            "email": "ckh327@gmail.com",
            "github_id": "kyunghwan"
        },
        {
            "name": "Philip Kahn",
            "email": "tigerhawkvok@gmail.com",
            "github_id": "tigerhawkvok"
        },
        {
            "name": "IlyaOvodov",
            "github_id": "IlyaOvodov"
        },
        {
            "name": "Vinjn Zhang",
            "github_id": "vinjn"
        },
        {
            "name": "Jud White",
            "email": "contact@judsonwhite.com",
            "github_id": "judwhite"
        },
        {
            "name": "Aven",
            "github_id": "AvenSun"
        },
        {
            "name": "Galileo Daras",
            "github_id": "oldgalileo"
        },
        {
            "name": "adesun",
            "github_id": "adesun"
        },
        {
            "name": "Bartek G\u0105siorzewski",
            "github_id": "bgasiorzewski"
        },
        {
            "name": "Marcin Kmiec",
            "github_id": "bonzoq"
        },
        {
            "name": "Nadeen Udantha",
            "email": "me@nadeen.lk",
            "github_id": "NadeenUdantha"
        },
        {
            "name": "Timon",
            "github_id": "timonsku"
        },
        {
            "name": "Puneet Kohli",
            "github_id": "PuneetKohli"
        },
        {
            "name": "Rakesh Jasti",
            "github_id": "rakeshjasti"
        },
        {
            "name": "Ruslan_Lenin",
            "github_id": "Rus-L"
        },
        {
            "name": "Yu Hao",
            "email": "jinyu121@gmail.com",
            "github_id": "jinyu121"
        },
        {
            "name": "salbatron",
            "github_id": "salbatron"
        },
        {
            "name": "Sivagnanam Namasivayamurthy",
            "email": "sivagnanammurthy@gmail.com",
            "github_id": "sivagnanamn"
        },
        {
            "name": "stereo",
            "email": "thamngapwei@gmail.com",
            "github_id": "stereomatchingkiss"
        }
    ],
    "tags": [],
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/kyunghwan/darknet_v3",
            "stars": 0,
            "issues": true,
            "readme": "# Yolo-v3 and Yolo-v2 for Windows and Linux\n### (neural network for object detection)\n\n[![CircleCI](https://circleci.com/gh/AlexeyAB/darknet.svg?style=svg)](https://circleci.com/gh/AlexeyAB/darknet)\n\n1. [How to use](#how-to-use)\n2. [How to compile on Linux](#how-to-compile-on-linux)\n3. [How to compile on Windows](#how-to-compile-on-windows)\n4. [How to train (Pascal VOC Data)](#how-to-train-pascal-voc-data)\n5. [How to train (to detect your custom objects)](#how-to-train-to-detect-your-custom-objects)\n6. [When should I stop training](#when-should-i-stop-training)\n7. [How to calculate mAP on PascalVOC 2007](#how-to-calculate-map-on-pascalvoc-2007)\n8. [How to improve object detection](#how-to-improve-object-detection)\n9. [How to mark bounded boxes of objects and create annotation files](#how-to-mark-bounded-boxes-of-objects-and-create-annotation-files)\n10. [Using Yolo9000](#using-yolo9000)\n11. [How to use Yolo as DLL](#how-to-use-yolo-as-dll)\n\n\n\n|  ![Darknet Logo](http://pjreddie.com/media/files/darknet-black-small.png) | &nbsp; ![map_fps](https://hsto.org/webt/pw/zd/0j/pwzd0jb9g7znt_dbsyw9qzbnvti.jpeg) mAP (AP50) https://pjreddie.com/media/files/papers/YOLOv3.pdf |\n|---|---|\n\n* Yolo v3 source chart for the RetinaNet on MS COCO got from Table 1 (e): https://arxiv.org/pdf/1708.02002.pdf\n* Yolo v2 on Pascal VOC 2007: https://hsto.org/files/a24/21e/068/a2421e0689fb43f08584de9d44c2215f.jpg\n* Yolo v2 on Pascal VOC 2012 (comp4): https://hsto.org/files/3a6/fdf/b53/3a6fdfb533f34cee9b52bdd9bb0b19d9.jpg\n\n\n# \"You Only Look Once: Unified, Real-Time Object Detection (versions 2 & 3)\"\nA Yolo cross-platform Windows and Linux version (for object detection). Contributtors: https://github.com/pjreddie/darknet/graphs/contributors\n\nThis repository is forked from Linux-version: https://github.com/pjreddie/darknet\n\nMore details: http://pjreddie.com/darknet/yolo/\n\nThis repository supports:\n\n* both Windows and Linux\n* both OpenCV 2.x.x and OpenCV <= 3.4.0 (3.4.1 and higher isn't supported)\n* both cuDNN v5-v7\n* CUDA >= 7.5\n* also create SO-library on Linux and DLL-library on Windows\n\n##### Requires: \n* **Linux GCC>=4.9 or Windows MS Visual Studio 2015 (v140)**: https://go.microsoft.com/fwlink/?LinkId=532606&clcid=0x409  (or offline [ISO image](https://go.microsoft.com/fwlink/?LinkId=615448&clcid=0x409))\n* **CUDA 9.1**: https://developer.nvidia.com/cuda-downloads\n* **OpenCV 3.4.0**: https://sourceforge.net/projects/opencvlibrary/files/opencv-win/3.4.0/opencv-3.4.0-vc14_vc15.exe/download\n* **or OpenCV 2.4.13**: https://sourceforge.net/projects/opencvlibrary/files/opencv-win/2.4.13/opencv-2.4.13.2-vc14.exe/download\n  - OpenCV allows to show image or video detection in the window and store result to file that specified in command line `-out_filename res.avi`\n* **GPU with CC >= 3.0**: https://en.wikipedia.org/wiki/CUDA#GPUs_supported\n\n##### Pre-trained models for different cfg-files can be downloaded from (smaller -> faster & lower quality):\n* `yolov3.cfg` (236 MB COCO **Yolo v3**) - requires 4 GB GPU-RAM: https://pjreddie.com/media/files/yolov3.weights\n* `yolov3-tiny.cfg` (34 MB COCO **Yolo v3 tiny**) - requires 1 GB GPU-RAM:  https://pjreddie.com/media/files/yolov3-tiny.weights\n* `yolov2.cfg` (194 MB COCO Yolo v2) - requires 4 GB GPU-RAM: https://pjreddie.com/media/files/yolov2.weights\n* `yolo-voc.cfg` (194 MB VOC Yolo v2) - requires 4 GB GPU-RAM: http://pjreddie.com/media/files/yolo-voc.weights\n* `yolov2-tiny.cfg` (43 MB COCO Yolo v2) - requires 1 GB GPU-RAM: https://pjreddie.com/media/files/yolov2-tiny.weights\n* `yolov2-tiny-voc.cfg` (60 MB VOC Yolo v2) - requires 1 GB GPU-RAM: http://pjreddie.com/media/files/yolov2-tiny-voc.weights\n* `yolo9000.cfg` (186 MB Yolo9000-model) - requires 4 GB GPU-RAM: http://pjreddie.com/media/files/yolo9000.weights\n\nPut it near compiled: darknet.exe\n\nYou can get cfg-files by path: `darknet/cfg/`\n\n##### Examples of results:\n\n[![Everything Is AWESOME](http://img.youtube.com/vi/VOC3huqHrss/0.jpg)](https://www.youtube.com/watch?v=VOC3huqHrss \"Everything Is AWESOME\")\n\nOthers: https://www.youtube.com/channel/UC7ev3hNVkx4DzZ3LO19oebg\n\n### How to use:\n\n##### Example of usage in cmd-files from `build\\darknet\\x64\\`:\n\n* `darknet_yolo_v3.cmd` - initialization with 236 MB **Yolo v3** COCO-model yolov3.weights & yolov3.cfg and show detection on the image: dog.jpg\n\n* `darknet_voc.cmd` - initialization with 194 MB VOC-model yolo-voc.weights & yolo-voc.cfg and waiting for entering the name of the image file\n* `darknet_demo_voc.cmd` - initialization with 194 MB VOC-model yolo-voc.weights & yolo-voc.cfg and play your video file which you must rename to: test.mp4\n* `darknet_demo_store.cmd` - initialization with 194 MB VOC-model yolo-voc.weights & yolo-voc.cfg and play your video file which you must rename to: test.mp4, and store result to: res.avi\n* `darknet_net_cam_voc.cmd` - initialization with 194 MB VOC-model, play video from network video-camera mjpeg-stream (also from you phone)\n* `darknet_web_cam_voc.cmd` - initialization with 194 MB VOC-model, play video from Web-Camera number #0\n* `darknet_coco_9000.cmd` - initialization with 186 MB Yolo9000 COCO-model, and show detection on the image: dog.jpg\n* `darknet_coco_9000_demo.cmd` - initialization with 186 MB Yolo9000 COCO-model, and show detection on the video (if it is present): street4k.mp4, and store result to: res.avi\n\n##### How to use on the command line:\n\nOn Linux use `./darknet` instead of `darknet.exe`, like this:`./darknet detector test ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights`\n\n* **Yolo v3** COCO - image: `darknet.exe detector test data/coco.data cfg/yolov3.cfg yolov3.weights -i 0 -thresh 0.25`\n* Alternative method Yolo v3 COCO - image: `darknet.exe detect cfg/yolov3.cfg yolov3.weights -i 0 -thresh 0.25`\n* Output coordinates of objects: `darknet.exe detector test data/coco.data yolov3.cfg yolov3.weights -thresh 0.25 dog.jpg -ext_output`\n* 194 MB VOC-model - image: `darknet.exe detector test data/voc.data yolo-voc.cfg yolo-voc.weights -i 0`\n* 194 MB VOC-model - video: `darknet.exe detector demo data/voc.data yolo-voc.cfg yolo-voc.weights test.mp4 -i 0`\n* 194 MB VOC-model - **save result to the file res.avi**: `darknet.exe detector demo data/voc.data yolo-voc.cfg yolo-voc.weights test.mp4 -i 0 -out_filename res.avi`\n* Alternative method 194 MB VOC-model - video: `darknet.exe yolo demo yolo-voc.cfg yolo-voc.weights test.mp4 -i 0`\n* 43 MB VOC-model for video: `darknet.exe detector demo data/coco.data cfg/yolov2-tiny.cfg yolov2-tiny.weights test.mp4 -i 0`\n* **Yolo v3** 236 MB COCO for net-videocam - Smart WebCam: `darknet.exe detector demo data/coco.data cfg/yolov3.cfg yolov3.weights http://192.168.0.80:8080/video?dummy=param.mjpg -i 0`\n* 194 MB VOC-model for net-videocam - Smart WebCam: `darknet.exe detector demo data/voc.data yolo-voc.cfg yolo-voc.weights http://192.168.0.80:8080/video?dummy=param.mjpg -i 0`\n* 194 MB VOC-model - WebCamera #0: `darknet.exe detector demo data/voc.data yolo-voc.cfg yolo-voc.weights -c 0`\n* 186 MB Yolo9000 - image: `darknet.exe detector test cfg/combine9k.data yolo9000.cfg yolo9000.weights`\n* Remeber to put data/9k.tree and data/coco9k.map under the same folder of your app if you use the cpp api to build an app\n* To process a list of images `data/train.txt` and save results of detection to `result.txt` use:                             \n    `darknet.exe detector test data/voc.data yolo-voc.cfg yolo-voc.weights -dont_show -ext_output < data/train.txt > result.txt`\n\n##### For using network video-camera mjpeg-stream with any Android smartphone:\n\n1. Download for Android phone mjpeg-stream soft: IP Webcam / Smart WebCam\n\n\n    * Smart WebCam - preferably: https://play.google.com/store/apps/details?id=com.acontech.android.SmartWebCam2\n    * IP Webcam: https://play.google.com/store/apps/details?id=com.pas.webcam\n\n2. Connect your Android phone to computer by WiFi (through a WiFi-router) or USB\n3. Start Smart WebCam on your phone\n4. Replace the address below, on shown in the phone application (Smart WebCam) and launch:\n\n\n* 194 MB COCO-model: `darknet.exe detector demo data/coco.data yolo.cfg yolo.weights http://192.168.0.80:8080/video?dummy=param.mjpg -i 0`\n* 194 MB VOC-model: `darknet.exe detector demo data/voc.data yolo-voc.cfg yolo-voc.weights http://192.168.0.80:8080/video?dummy=param.mjpg -i 0`\n\n### How to compile on Linux:\n\nJust do `make` in the darknet directory.\nBefore make, you can set such options in the `Makefile`: [link](https://github.com/AlexeyAB/darknet/blob/9c1b9a2cf6363546c152251be578a21f3c3caec6/Makefile#L1)\n* `GPU=1` to build with CUDA to accelerate by using GPU (CUDA should be in `/usr/local/cuda`)\n* `CUDNN=1` to build with cuDNN v5-v7 to accelerate training by using GPU (cuDNN should be in `/usr/local/cudnn`)\n* `CUDNN_HALF=1` to build for Tensor Cores (on Titan V / Tesla V100 / DGX-2 and later) speedup Detection 3x, Training 2x\n* `OPENCV=1` to build with OpenCV 3.x/2.4.x - allows to detect on video files and video streams from network cameras or web-cams\n* `DEBUG=1` to bould debug version of Yolo\n* `OPENMP=1` to build with OpenMP support to accelerate Yolo by using multi-core CPU\n* `LIBSO=1` to build a library `darknet.so` and binary runable file `uselib` that uses this library. Or you can try to run so `LD_LIBRARY_PATH=./:$LD_LIBRARY_PATH ./uselib test.mp4` How to use this SO-library from your own code - you can look at C++ example: https://github.com/AlexeyAB/darknet/blob/master/src/yolo_console_dll.cpp\n    or use in such a way: `LD_LIBRARY_PATH=./:$LD_LIBRARY_PATH ./uselib data/coco.names cfg/yolov3.cfg yolov3.weights test.mp4`\n\n### How to compile on Windows:\n\n1. If you have **MSVS 2015, CUDA 9.1, cuDNN 7.0 and OpenCV 3.x** (with paths: `C:\\opencv_3.0\\opencv\\build\\include` & `C:\\opencv_3.0\\opencv\\build\\x64\\vc14\\lib`), then start MSVS, open `build\\darknet\\darknet.sln`, set **x64** and **Release** https://hsto.org/webt/uh/fk/-e/uhfk-eb0q-hwd9hsxhrikbokd6u.jpeg and do the: Build -> Build darknet. **NOTE:** If installing OpenCV, use OpenCV 3.4.0 or earlier. This is a bug in OpenCV 3.4.1 in the C API (see [#500](https://github.com/AlexeyAB/darknet/issues/500)).\n\n    1.1. Find files `opencv_world320.dll` and `opencv_ffmpeg320_64.dll` (or `opencv_world340.dll` and `opencv_ffmpeg340_64.dll`) in `C:\\opencv_3.0\\opencv\\build\\x64\\vc14\\bin` and put it near with `darknet.exe`\n    \n    1.2 Check that there are `bin` and `include` folders in the `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.1` if aren't, then copy them to this folder from the path where is CUDA installed\n    \n    1.3. To install CUDNN (speedup neural network), do the following:\n      \n    * download and install **cuDNN 7.0 for CUDA 9.1**: https://developer.nvidia.com/cudnn\n      \n    * add Windows system variable `cudnn` with path to CUDNN: https://hsto.org/files/a49/3dc/fc4/a493dcfc4bd34a1295fd15e0e2e01f26.jpg\n    \n    1.4. If you want to build **without CUDNN** then: open `\\darknet.sln` -> (right click on project) -> properties  -> C/C++ -> Preprocessor -> Preprocessor Definitions, and remove this: `CUDNN;`\n\n2. If you have other version of **CUDA (not 9.1)** then open `build\\darknet\\darknet.vcxproj` by using Notepad, find 2 places with \"CUDA 9.1\" and change it to your CUDA-version, then do step 1\n\n3. If you **don't have GPU**, but have **MSVS 2015 and OpenCV 3.0** (with paths: `C:\\opencv_3.0\\opencv\\build\\include` & `C:\\opencv_3.0\\opencv\\build\\x64\\vc14\\lib`), then start MSVS, open `build\\darknet\\darknet_no_gpu.sln`, set **x64** and **Release**, and do the: Build -> Build darknet_no_gpu\n\n4. If you have **OpenCV 2.4.13** instead of 3.0 then you should change pathes after `\\darknet.sln` is opened\n\n    4.1 (right click on project) -> properties  -> C/C++ -> General -> Additional Include Directories:  `C:\\opencv_2.4.13\\opencv\\build\\include`\n  \n    4.2 (right click on project) -> properties  -> Linker -> General -> Additional Library Directories: `C:\\opencv_2.4.13\\opencv\\build\\x64\\vc14\\lib`\n    \n5. If you have GPU with Tensor Cores (nVidia Titan V / Tesla V100 / DGX-2 and later) speedup Detection 3x, Training 2x:\n    `\\darknet.sln` -> (right click on project) -> properties -> C/C++ -> Preprocessor -> Preprocessor Definitions, and add here: `CUDNN_HALF;`\n    \n    **Note:** CUDA must be installed only after that MSVS2015 had been installed.\n\n### How to compile (custom):\n\nAlso, you can to create your own `darknet.sln` & `darknet.vcxproj`, this example for CUDA 9.1 and OpenCV 3.0\n\nThen add to your created project:\n- (right click on project) -> properties  -> C/C++ -> General -> Additional Include Directories, put here: \n\n`C:\\opencv_3.0\\opencv\\build\\include;..\\..\\3rdparty\\include;%(AdditionalIncludeDirectories);$(CudaToolkitIncludeDir);$(cudnn)\\include`\n- (right click on project) -> Build dependecies -> Build Customizations -> set check on CUDA 9.1 or what version you have - for example as here: http://devblogs.nvidia.com/parallelforall/wp-content/uploads/2015/01/VS2013-R-5.jpg\n- add to project all `.c` & `.cu` files and file `http_stream.cpp` from `\\src`\n- (right click on project) -> properties  -> Linker -> General -> Additional Library Directories, put here: \n\n`C:\\opencv_3.0\\opencv\\build\\x64\\vc14\\lib;$(CUDA_PATH)lib\\$(PlatformName);$(cudnn)\\lib\\x64;%(AdditionalLibraryDirectories)`\n-  (right click on project) -> properties  -> Linker -> Input -> Additional dependecies, put here: \n\n`..\\..\\3rdparty\\lib\\x64\\pthreadVC2.lib;cublas.lib;curand.lib;cudart.lib;cudnn.lib;%(AdditionalDependencies)`\n- (right click on project) -> properties -> C/C++ -> Preprocessor -> Preprocessor Definitions\n\n`OPENCV;_TIMESPEC_DEFINED;_CRT_SECURE_NO_WARNINGS;_CRT_RAND_S;WIN32;NDEBUG;_CONSOLE;_LIB;%(PreprocessorDefinitions)`\n\n- compile to .exe (X64 & Release) and put .dll-s near with .exe: https://hsto.org/webt/uh/fk/-e/uhfk-eb0q-hwd9hsxhrikbokd6u.jpeg\n\n    * `pthreadVC2.dll, pthreadGC2.dll` from \\3rdparty\\dll\\x64\n\n    * `cusolver64_91.dll, curand64_91.dll, cudart64_91.dll, cublas64_91.dll` - 91 for CUDA 9.1 or your version, from C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.1\\bin\n\n    * For OpenCV 3.2: `opencv_world320.dll` and `opencv_ffmpeg320_64.dll` from `C:\\opencv_3.0\\opencv\\build\\x64\\vc14\\bin` \n    * For OpenCV 2.4.13: `opencv_core2413.dll`, `opencv_highgui2413.dll` and `opencv_ffmpeg2413_64.dll` from  `C:\\opencv_2.4.13\\opencv\\build\\x64\\vc14\\bin`\n\n## How to train (Pascal VOC Data):\n\n1. Download pre-trained weights for the convolutional layers (154 MB): http://pjreddie.com/media/files/darknet53.conv.74 and put to the directory `build\\darknet\\x64`\n\n2. Download The Pascal VOC Data and unpack it to directory `build\\darknet\\x64\\data\\voc` will be created dir `build\\darknet\\x64\\data\\voc\\VOCdevkit\\`:\n    * http://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar\n    * http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n    * http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\n    \n    2.1 Download file `voc_label.py` to dir `build\\darknet\\x64\\data\\voc`: http://pjreddie.com/media/files/voc_label.py\n\n3. Download and install Python for Windows: https://www.python.org/ftp/python/3.5.2/python-3.5.2-amd64.exe\n\n4. Run command: `python build\\darknet\\x64\\data\\voc\\voc_label.py` (to generate files: 2007_test.txt, 2007_train.txt, 2007_val.txt, 2012_train.txt, 2012_val.txt)\n\n5. Run command: `type 2007_train.txt 2007_val.txt 2012_*.txt > train.txt`\n\n6. Set `batch=64` and `subdivisions=8` in the file `yolov3-voc.cfg`: [link](https://github.com/AlexeyAB/darknet/blob/ee38c6e1513fb089b35be4ffa692afd9b3f65747/cfg/yolov3-voc.cfg#L3-L4)\n\n7. Start training by using `train_voc.cmd` or by using the command line: \n\n    `darknet.exe detector train data/voc.data cfg/yolov3-voc.cfg darknet53.conv.74` \n\n(**Note:** To disable Loss-Window use flag `-dont_show`. If you are using CPU, try `darknet_no_gpu.exe` instead of `darknet.exe`.)\n\nIf required change pathes in the file `build\\darknet\\x64\\data\\voc.data`\n\nMore information about training by the link: http://pjreddie.com/darknet/yolo/#train-voc\n\n **Note:** If during training you see `nan` values for `avg` (loss) field - then training goes wrong, but if `nan` is in some other lines - then training goes well.\n\n## How to train with multi-GPU:\n\n1. Train it first on 1 GPU for like 1000 iterations: `darknet.exe detector train data/voc.data cfg/yolov3-voc.cfg darknet53.conv.74`\n\n2. Then stop and by using partially-trained model `/backup/yolov3-voc_1000.weights` run training with multigpu (up to 4 GPUs): `darknet.exe detector train data/voc.data cfg/yolov3-voc.cfg /backup/yolov3-voc_1000.weights -gpus 0,1,2,3`\n\nhttps://groups.google.com/d/msg/darknet/NbJqonJBTSY/Te5PfIpuCAAJ\n\n## How to train (to detect your custom objects):\n(to train old Yolo v2 `yolov2-voc.cfg`, `yolov2-tiny-voc.cfg`, `yolo-voc.cfg`, `yolo-voc.2.0.cfg`, ... [click by the link](https://github.com/AlexeyAB/darknet/tree/47c7af1cea5bbdedf1184963355e6418cb8b1b4f#how-to-train-pascal-voc-data))\n\nTraining Yolo v3:\n\n1. Create file `yolo-obj.cfg` with the same content as in `yolov3.cfg` (or copy `yolov3.cfg` to `yolo-obj.cfg)` and:\n\n  * change line batch to [`batch=64`](https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L3)\n  * change line subdivisions to [`subdivisions=8`](https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L4)\n  * change line `classes=80` to your number of objects in each of 3 `[yolo]`-layers:\n      * https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L610\n      * https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L696\n      * https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L783\n  * change [`filters=255`] to filters=(classes + 5)x3 in the 3 `[convolutional]` before each `[yolo]` layer\n      * https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L603\n      * https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L689\n      * https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L776\n\n  So if `classes=1` then should be `filters=18`. If `classes=2` then write `filters=21`.\n  \n  **(Do not write in the cfg-file: filters=(classes + 5)x3)**\n  \n  (Generally `filters` depends on the `classes`, `coords` and number of `mask`s, i.e. filters=`(classes + coords + 1)*<number of mask>`, where `mask` is indices of anchors. If `mask` is absence, then filters=`(classes + coords + 1)*num`)\n\n  So for example, for 2 objects, your file `yolo-obj.cfg` should differ from `yolov3.cfg` in such lines in each of **3** [yolo]-layers:\n\n  ```\n  [convolutional]\n  filters=21\n\n  [region]\n  classes=2\n  ```\n\n2. Create file `obj.names` in the directory `build\\darknet\\x64\\data\\`, with objects names - each in new line\n\n3. Create file `obj.data` in the directory `build\\darknet\\x64\\data\\`, containing (where **classes = number of objects**):\n\n  ```\n  classes= 2\n  train  = data/train.txt\n  valid  = data/test.txt\n  names = data/obj.names\n  backup = backup/\n  ```\n\n4. Put image-files (.jpg) of your objects in the directory `build\\darknet\\x64\\data\\obj\\`\n\n5. You should label each object on images from your dataset. Use this visual GUI-software for marking bounded boxes of objects and generating annotation files for Yolo v2 & v3: https://github.com/AlexeyAB/Yolo_mark\n\nIt will create `.txt`-file for each `.jpg`-image-file - in the same directory and with the same name, but with `.txt`-extension, and put to file: object number and object coordinates on this image, for each object in new line: `<object-class> <x> <y> <width> <height>`\n\n  Where: \n  * `<object-class>` - integer number of object from `0` to `(classes-1)`\n  * `<x> <y> <width> <height>` - float values relative to width and height of image, it can be equal from (0.0 to 1.0]\n  * for example: `<x> = <absolute_x> / <image_width>` or `<height> = <absolute_height> / <image_height>`\n  * atention: `<x> <y>` - are center of rectangle (are not top-left corner)\n\n  For example for `img1.jpg` you will be created `img1.txt` containing:\n\n  ```\n  1 0.716797 0.395833 0.216406 0.147222\n  0 0.687109 0.379167 0.255469 0.158333\n  1 0.420312 0.395833 0.140625 0.166667\n  ```\n\n6. Create file `train.txt` in directory `build\\darknet\\x64\\data\\`, with filenames of your images, each filename in new line, with path relative to `darknet.exe`, for example containing:\n\n  ```\n  data/obj/img1.jpg\n  data/obj/img2.jpg\n  data/obj/img3.jpg\n  ```\n\n7. Download pre-trained weights for the convolutional layers (154 MB): https://pjreddie.com/media/files/darknet53.conv.74 and put to the directory `build\\darknet\\x64`\n\n8. Start training by using the command line: `darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74`\n\n    (file `yolo-obj_xxx.weights` will be saved to the `build\\darknet\\x64\\backup\\` for each 100 iterations)\n    (To disable Loss-Window use `darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74 -dont_show`, if you train on computer without monitor like a cloud Amazaon EC2)\n\n9. After training is complete - get result `yolo-obj_final.weights` from path `build\\darknet\\x64\\backup\\`\n\n * After each 100 iterations you can stop and later start training from this point. For example, after 2000 iterations you can stop training, and later just copy `yolo-obj_2000.weights` from `build\\darknet\\x64\\backup\\` to `build\\darknet\\x64\\` and start training using: `darknet.exe detector train data/obj.data yolo-obj.cfg yolo-obj_2000.weights`\n\n    (in the original repository https://github.com/pjreddie/darknet the weights-file is saved only once every 10 000 iterations `if(iterations > 1000)`)\n\n * Also you can get result earlier than all 45000 iterations.\n \n **Note:** If during training you see `nan` values for `avg` (loss) field - then training goes wrong, but if `nan` is in some other lines - then training goes well.\n \n **Note:** If you changed width= or height= in your cfg-file, then new width and height must be divisible by 32.\n \n **Note:** After training use such command for detection: `darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj_8000.weights`\n \n### How to train tiny-yolo (to detect your custom objects):\n\nDo all the same steps as for the full yolo model as described above. With the exception of:\n* Download default weights file for yolov3-tiny: https://pjreddie.com/media/files/yolov3-tiny.weights\n* Get pre-trained weights `yolov3-tiny.conv.15` using command: `darknet.exe partial cfg/yolov3-tiny.cfg yolov3-tiny.weights yolov3-tiny.conv.15 15`\n* Make your custom model `yolov3-tiny-obj.cfg` based on `cfg/yolov3-tiny_obj.cfg` instead of `yolov3.cfg`\n* Start training: `darknet.exe detector train data/obj.data yolov3-tiny-obj.cfg yolov3-tiny.conv.15`\n\nFor training Yolo based on other models ([DenseNet201-Yolo](https://github.com/AlexeyAB/darknet/blob/master/build/darknet/x64/densenet201_yolo.cfg) or [ResNet50-Yolo](https://github.com/AlexeyAB/darknet/blob/master/build/darknet/x64/resnet50_yolo.cfg)), you can download and get pre-trained weights as showed in this file: https://github.com/AlexeyAB/darknet/blob/master/build/darknet/x64/partial.cmd\nIf you made you custom model that isn't based on other models, then you can train it without pre-trained weights, then will be used random initial weights.\n \n## When should I stop training:\n\nUsually sufficient 2000 iterations for each class(object). But for a more precise definition when you should stop training, use the following manual:\n\n1. During training, you will see varying indicators of error, and you should stop when no longer decreases **0.XXXXXXX avg**:\n\n  > Region Avg IOU: 0.798363, Class: 0.893232, Obj: 0.700808, No Obj: 0.004567, Avg Recall: 1.000000,  count: 8\n  > Region Avg IOU: 0.800677, Class: 0.892181, Obj: 0.701590, No Obj: 0.004574, Avg Recall: 1.000000,  count: 8\n  >\n  > **9002**: 0.211667, **0.060730 avg**, 0.001000 rate, 3.868000 seconds, 576128 images\n  > Loaded: 0.000000 seconds\n\n  * **9002** - iteration number (number of batch)\n  * **0.060730 avg** - average loss (error) - **the lower, the better**\n\n  When you see that average loss **0.xxxxxx avg** no longer decreases at many iterations then you should stop training.\n\n2. Once training is stopped, you should take some of last `.weights`-files from `darknet\\build\\darknet\\x64\\backup` and choose the best of them:\n\nFor example, you stopped training after 9000 iterations, but the best result can give one of previous weights (7000, 8000, 9000). It can happen due to overfitting. **Overfitting** - is case when you can detect objects on images from training-dataset, but can't detect objects on any others images. You should get weights from **Early Stopping Point**:\n\n![Overfitting](https://hsto.org/files/5dc/7ae/7fa/5dc7ae7fad9d4e3eb3a484c58bfc1ff5.png) \n\nTo get weights from Early Stopping Point:\n\n  2.1. At first, in your file `obj.data` you must specify the path to the validation dataset `valid = valid.txt` (format of `valid.txt` as in `train.txt`), and if you haven't validation images, just copy `data\\train.txt` to `data\\valid.txt`.\n\n  2.2 If training is stopped after 9000 iterations, to validate some of previous weights use this commands:\n\n(If you use another GitHub repository, then use `darknet.exe detector recall`... instead of `darknet.exe detector map`...)\n\n* `darknet.exe detector map data/obj.data yolo-obj.cfg backup\\yolo-obj_7000.weights`\n* `darknet.exe detector map data/obj.data yolo-obj.cfg backup\\yolo-obj_8000.weights`\n* `darknet.exe detector map data/obj.data yolo-obj.cfg backup\\yolo-obj_9000.weights`\n\nAnd comapre last output lines for each weights (7000, 8000, 9000):\n\nChoose weights-file **with the highest IoU** (intersect of union) and mAP (mean average precision)\n\nFor example, **bigger IOU** gives weights `yolo-obj_8000.weights` - then **use this weights for detection**.\n\nExample of custom object detection: `darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj_8000.weights`\n\n* **IoU** (intersect of union) - average instersect of union of objects and detections for a certain threshold = 0.24\n\n* **mAP** (mean average precision) - mean value of `average precisions` for each class, where `average precision` is average value of 11 points on PR-curve for each possible threshold (each probability of detection) for the same class (Precision-Recall in terms of PascalVOC, where Precision=TP/(TP+FP) and Recall=TP/(TP+FN) ), page-11: http://homepages.inf.ed.ac.uk/ckiw/postscript/ijcv_voc09.pdf\n\n**mAP** is default metric of precision in the PascalVOC competition, **this is the same as AP50** metric in the MS COCO competition.\nIn terms of Wiki, indicators Precision and Recall have a slightly different meaning than in the PascalVOC competition, but **IoU always has the same meaning**.\n\n![precision_recall_iou](https://hsto.org/files/ca8/866/d76/ca8866d76fb840228940dbf442a7f06a.jpg)\n\n### How to calculate mAP on PascalVOC 2007:\n\n1. To calculate mAP (mean average precision) on PascalVOC-2007-test:\n* Download PascalVOC dataset, install Python 3.x and get file `2007_test.txt` as described here: https://github.com/AlexeyAB/darknet#how-to-train-pascal-voc-data\n* Then download file https://raw.githubusercontent.com/AlexeyAB/darknet/master/scripts/voc_label_difficult.py to the dir `build\\darknet\\x64\\data\\` then run `voc_label_difficult.py` to get the file `difficult_2007_test.txt`\n* Remove symbol `#` from this line to un-comment it: https://github.com/AlexeyAB/darknet/blob/master/build/darknet/x64/data/voc.data#L4\n* Then there are 2 ways to get mAP:\n    1. Using Darknet + Python: run the file `build/darknet/x64/calc_mAP_voc_py.cmd` - you will get mAP for `yolo-voc.cfg` model, mAP = 75.9%\n    2. Using this fork of Darknet: run the file `build/darknet/x64/calc_mAP.cmd` - you will get mAP for `yolo-voc.cfg` model, mAP = 75.8%\n    \n (The article specifies the value of mAP = 76.8% for YOLOv2 416\u00d7416, page-4 table-3: https://arxiv.org/pdf/1612.08242v1.pdf. We get values lower - perhaps due to the fact that the model was trained on a slightly different source code than the code on which the detection is was done)\n\n* if you want to get mAP for `tiny-yolo-voc.cfg` model, then un-comment line for tiny-yolo-voc.cfg and comment line for yolo-voc.cfg in the .cmd-file\n* if you have Python 2.x instead of Python 3.x, and if you use Darknet+Python-way to get mAP, then in your cmd-file use `reval_voc.py` and `voc_eval.py` instead of `reval_voc_py3.py` and `voc_eval_py3.py` from this directory: https://github.com/AlexeyAB/darknet/tree/master/scripts\n\n### Custom object detection:\n\nExample of custom object detection: `darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj_8000.weights`\n\n| ![Yolo_v2_training](https://hsto.org/files/d12/1e7/515/d121e7515f6a4eb694913f10de5f2b61.jpg) | ![Yolo_v2_training](https://hsto.org/files/727/c7e/5e9/727c7e5e99bf4d4aa34027bb6a5e4bab.jpg) |\n|---|---|\n\n## How to improve object detection:\n\n1. Before training:\n  * set flag `random=1` in your `.cfg`-file - it will increase precision by training Yolo for different resolutions: [link](https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L788)\n\n  * increase network resolution in your `.cfg`-file (`height=608`, `width=608` or any value multiple of 32) - it will increase precision\n\n  * recalculate anchors for your dataset for `width` and `height` from cfg-file:\n  `darknet.exe detector calc_anchors data/obj.data -num_of_clusters 9 -width 416 -height 416`\n   then set the same 9 `anchors` in each of 3 `[yolo]`-layers in your cfg-file\n\n  * check that each object are mandatory labeled in your dataset - no one object in your data set should not be without label. In the most training issues - there are wrong labels in your dataset (got labels by using some conversion script, marked with a third-party tool, ...). Always check your dataset by using: https://github.com/AlexeyAB/Yolo_mark\n\n  * desirable that your training dataset include images with objects at diffrent: scales, rotations, lightings, from different sides, on different backgrounds - you should preferably have 2000 different images for each class or more, and you should train `2000*classes` iterations or more\n\n  * desirable that your training dataset include images with non-labeled objects that you do not want to detect - negative samples without bounded box (empty `.txt` files) - use as many images of negative samples as there are images with objects\n\n  * for training with a large number of objects in each image, add the parameter `max=200` or higher value in the last layer [region] in your cfg-file\n  \n  * for training for small objects - set `layers = -1, 11` instead of https://github.com/AlexeyAB/darknet/blob/6390a5a2ab61a0bdf6f1a9a6b4a739c16b36e0d7/cfg/yolov3.cfg#L720\n      and set `stride=4` instead of https://github.com/AlexeyAB/darknet/blob/6390a5a2ab61a0bdf6f1a9a6b4a739c16b36e0d7/cfg/yolov3.cfg#L717\n  \n  * General rule - your training dataset should include such a set of relative sizes of objects that you want to detect: \n\n    * `train_network_width * train_obj_width / train_image_width ~= detection_network_width * detection_obj_width / detection_image_width`\n    * `train_network_height * train_obj_height / train_image_height ~= detection_network_height * detection_obj_height / detection_image_height`\n  \n  * to speedup training (with decreasing detection accuracy) do Fine-Tuning instead of Transfer-Learning, set param `stopbackward=1` here: https://github.com/AlexeyAB/darknet/blob/6d44529cf93211c319813c90e0c1adb34426abe5/cfg/yolov3.cfg#L548\n\n2. After training - for detection:\n\n  * Increase network-resolution by set in your `.cfg`-file (`height=608` and `width=608`) or (`height=832` and `width=832`) or (any value multiple of 32) - this increases the precision and makes it possible to detect small objects: [link](https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L8-L9)\n  \n    * you do not need to train the network again, just use `.weights`-file already trained for 416x416 resolution\n    * if error `Out of memory` occurs then in `.cfg`-file you should increase `subdivisions=16`, 32 or 64: [link](https://github.com/AlexeyAB/darknet/blob/0039fd26786ab5f71d5af725fc18b3f521e7acfd/cfg/yolov3.cfg#L4)\n\n## How to mark bounded boxes of objects and create annotation files:\n\nHere you can find repository with GUI-software for marking bounded boxes of objects and generating annotation files for Yolo v2 & v3: https://github.com/AlexeyAB/Yolo_mark\n\nWith example of: `train.txt`, `obj.names`, `obj.data`, `yolo-obj.cfg`, `air`1-6`.txt`, `bird`1-4`.txt` for 2 classes of objects (air, bird) and `train_obj.cmd` with example how to train this image-set with Yolo v2 & v3\n\n## Using Yolo9000\n\n Simultaneous detection and classification of 9000 objects:\n\n* `yolo9000.weights` - (186 MB Yolo9000 Model) requires 4 GB GPU-RAM: http://pjreddie.com/media/files/yolo9000.weights\n\n* `yolo9000.cfg` - cfg-file of the Yolo9000, also there are paths to the `9k.tree` and `coco9k.map`  https://github.com/AlexeyAB/darknet/blob/617cf313ccb1fe005db3f7d88dec04a04bd97cc2/cfg/yolo9000.cfg#L217-L218\n\n    * `9k.tree` - **WordTree** of 9418 categories  - `<label> <parent_it>`, if `parent_id == -1` then this label hasn't parent: https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/9k.tree\n\n    * `coco9k.map` - map 80 categories from MSCOCO to WordTree `9k.tree`: https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/coco9k.map\n\n* `combine9k.data` - data file, there are paths to: `9k.labels`, `9k.names`, `inet9k.map`, (change path to your `combine9k.train.list`): https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/combine9k.data\n\n    * `9k.labels` - 9418 labels of objects: https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/9k.labels\n\n    * `9k.names` -\n9418 names of objects: https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/9k.names\n\n    * `inet9k.map` - map 200 categories from ImageNet to WordTree `9k.tree`: https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/inet9k.map\n\n\n## How to use Yolo as DLL\n\n1. To compile Yolo as C++ DLL-file `yolo_cpp_dll.dll` - open in MSVS2015 file `build\\darknet\\yolo_cpp_dll.sln`, set **x64** and **Release**, and do the: Build -> Build yolo_cpp_dll\n    * You should have installed **CUDA 9.1**\n    * To use cuDNN do: (right click on project) -> properties -> C/C++ -> Preprocessor -> Preprocessor Definitions, and add at the beginning of line: `CUDNN;`\n\n2. To use Yolo as DLL-file in your C++ console application - open in MSVS2015 file `build\\darknet\\yolo_console_dll.sln`, set **x64** and **Release**, and do the: Build -> Build yolo_console_dll\n\n    * you can run your console application from Windows Explorer `build\\darknet\\x64\\yolo_console_dll.exe`\n    * or you can run from MSVS2015 (before this - you should copy 2 files `yolo-voc.cfg` and `yolo-voc.weights` to the directory `build\\darknet\\` )\n    * after launching your console application and entering the image file name - you will see info for each object: \n    `<obj_id> <left_x> <top_y> <width> <height> <probability>`\n    * to use simple OpenCV-GUI you should uncomment line `//#define OPENCV` in `yolo_console_dll.cpp`-file: [link](https://github.com/AlexeyAB/darknet/blob/a6cbaeecde40f91ddc3ea09aa26a03ab5bbf8ba8/src/yolo_console_dll.cpp#L5)\n    * you can see source code of simple example for detection on the video file: [link](https://github.com/AlexeyAB/darknet/blob/ab1c5f9e57b4175f29a6ef39e7e68987d3e98704/src/yolo_console_dll.cpp#L75)\n   \n`yolo_cpp_dll.dll`-API: [link](https://github.com/AlexeyAB/darknet/blob/master/src/yolo_v2_class.hpp#L42)\n```\nclass Detector {\npublic:\n\tDetector(std::string cfg_filename, std::string weight_filename, int gpu_id = 0);\n\t~Detector();\n\n\tstd::vector<bbox_t> detect(std::string image_filename, float thresh = 0.2, bool use_mean = false);\n\tstd::vector<bbox_t> detect(image_t img, float thresh = 0.2, bool use_mean = false);\n\tstatic image_t load_image(std::string image_filename);\n\tstatic void free_image(image_t m);\n\n#ifdef OPENCV\n\tstd::vector<bbox_t> detect(cv::Mat mat, float thresh = 0.2, bool use_mean = false);\n#endif\n};\n```\n",
            "readme_url": "https://github.com/kyunghwan/darknet_v3",
            "frameworks": []
        }
    ],
    "references": [
        {
            "title": "Focal Loss for Dense Object Detection",
            "arxiv": "1708.02002",
            "year": 2017,
            "url": "http://arxiv.org/abs/1708.02002v2",
            "abstract": "The highest accuracy object detectors to date are based on a two-stage\napproach popularized by R-CNN, where a classifier is applied to a sparse set of\ncandidate object locations. In contrast, one-stage detectors that are applied\nover a regular, dense sampling of possible object locations have the potential\nto be faster and simpler, but have trailed the accuracy of two-stage detectors\nthus far. In this paper, we investigate why this is the case. We discover that\nthe extreme foreground-background class imbalance encountered during training\nof dense detectors is the central cause. We propose to address this class\nimbalance by reshaping the standard cross entropy loss such that it\ndown-weights the loss assigned to well-classified examples. Our novel Focal\nLoss focuses training on a sparse set of hard examples and prevents the vast\nnumber of easy negatives from overwhelming the detector during training. To\nevaluate the effectiveness of our loss, we design and train a simple dense\ndetector we call RetinaNet. Our results show that when trained with the focal\nloss, RetinaNet is able to match the speed of previous one-stage detectors\nwhile surpassing the accuracy of all existing state-of-the-art two-stage\ndetectors. Code is at: https://github.com/facebookresearch/Detectron.",
            "authors": [
                "Tsung-Yi Lin",
                "Priya Goyal",
                "Ross Girshick",
                "Kaiming He",
                "Piotr Doll\u00e1r"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            },
            {
                "name": "MSCOCO"
            },
            {
                "name": "PASCAL VOC 2012"
            },
            {
                "name": "PASCAL VOC 2007"
            },
            {
                "name": "COCO"
            },
            {
                "name": "Wikipedia"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999998624662063,
        "task": "Object Detection",
        "task_prob": 0.9923365523110061
    }
}
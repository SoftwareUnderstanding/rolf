{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Single Shot MultiBox Detector implemented by Keras",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "nirajdpandey",
                "owner_type": "User",
                "name": "Object-detection-and-localization-using-SSD",
                "url": "https://github.com/nirajdpandey/Object-detection-and-localization-using-SSD",
                "stars": 0,
                "pushed_at": "2020-02-26 11:48:49+00:00",
                "created_at": "2019-11-21 20:45:03+00:00",
                "language": "Jupyter Notebook",
                "description": "Object-detection-and-localization-using-SSD neural network architecture ",
                "license": "MIT License",
                "frameworks": [
                    "Keras"
                ]
            },
            {
                "type": "code",
                "name": "Assets",
                "sha": "01aecb200aecbe735d5754b349cbb8b8d51b1b41",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nirajdpandey/Object-detection-and-localization-using-SSD/tree/master/Assets"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "Data-set",
                "sha": "bcd7951590213977e5f72e321fc625799e059d50",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nirajdpandey/Object-detection-and-localization-using-SSD/tree/master/Data-set"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "e24876245f2f1d5c5cb4c9f51d59efa4bd9b32f1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nirajdpandey/Object-detection-and-localization-using-SSD/blob/master/LICENSE"
                    }
                },
                "size": 1073
            },
            {
                "type": "code",
                "name": "SSD_model",
                "sha": "8873b614e8c15acd7b69a170525c993115155f02",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nirajdpandey/Object-detection-and-localization-using-SSD/tree/master/SSD_model"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "data-generator",
                "sha": "2cb80dd7df36dedc31568abd7babb3297b1b856d",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/nirajdpandey/Object-detection-and-localization-using-SSD/tree/master/data-generator"
                    }
                },
                "num_files": 2
            }
        ]
    },
    "authors": [
        {
            "name": "Niraj D Pandey ",
            "github_id": "nirajdpandey"
        }
    ],
    "tags": [],
    "description": "Object-detection-and-localization-using-SSD neural network architecture ",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/nirajdpandey/Object-detection-and-localization-using-SSD",
            "stars": 0,
            "issues": true,
            "readme": "# Single Shot MultiBox Detector implemented by Keras\n\n\n## Introduction\n\nSSD(Single Shot MultiBox Detector) is a state-of-art object detection algorithm, brought by Wei Liu and other wonderful guys, see [SSD: Single Shot MultiBox Detector @ arxiv](https://arxiv.org/abs/1512.02325), recommended to read for better understanding.\n\nAlso, SSD currently performs good at PASCAL VOC Challenge, see [http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=3](http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=3)\n\n## SSD Architecture \nBelow find the architectural defference between Yolo and SSD. \n![title](https://github.com/nirajdevpandey/Object-detection-and-localization-using-SSD-/blob/master/Assets/Yolo_vs_SSD.png)\n\n \n\n## Guides\n\nThe code structures looks like below:\n\n```\n1. Aseets - Prior boxes  (prior_boxes_ssd300.pkl is the model pre-defined static prior boxes)\n2. Data-set - VOC-2007\n3. SSD Model - The training and the test scripts \n\n  - ssd_v2.py # main model architecture using Keras\n\t- ssd_layers.py # Normalize and PriorBox defenition\n\t- ssd_training.py # MultiboxLoss Definition\n\t- ssd_utils.py # Utilities including encode,decode,assign_boxes\n  \n4.  data-generator  # customrized generator, which return proper training data structure\n\t\t\t\t            # including image and assigned boxes(similar to input boxex)\n  - get_data_from_XML.py # parse Annotations of PASCAL VOC, helper of generator\n  \n  ```\n## Walk-through\n\nThe multibox loss is consist of `L1 smooth loss` and `softmax` loss. Let's see how they llok like \n\n`Arguments`\n    y_true: Ground truth bounding boxes,\n\ttensor of shape (?, num_boxes, 4).\n    y_pred: Predicted bounding boxes,\n\ttensor of shape (?, num_boxes, 4).\n\t\n`Returns`\n    l1_loss: L1-smooth loss, tensor of shape (?, num_boxes).\n    \n`References` - https://arxiv.org/abs/1504.08083\n\n```python\ndef _l1_smooth_loss(self, y_true, y_pred):\n\tabs_loss = tf.abs(y_true - y_pred)\n\tsq_loss = 0.5 * (y_true - y_pred)**2\n\tl1_loss = tf.where(tf.less(abs_loss, 1.0), sq_loss, abs_loss - 0.5)\n\treturn tf.reduce_sum(l1_loss, -1)\n```\nNow let's walk through the `softmax` loss\n\n `Arguments`\n    y_true: Ground truth targets,\n\ttensor of shape (?, num_boxes, num_classes).\n    y_pred: Predicted logits,\n\ttensor of shape (?, num_boxes, num_classes).\n\t\n`Returns`\n    softmax_loss: Softmax loss, tensor of shape (?, num_boxes).\n    \n\n```python\ndef _softmax_loss(self, y_true, y_pred):\n\ty_pred = tf.maximum(tf.minimum(y_pred, 1 - 1e-15), 1e-15)\n\tsoftmax_loss = -tf.reduce_sum(y_true * tf.log(y_pred),\n\t\t\t\t      axis=-1)\n\treturn softmax_loss\n```\n### Resources\n\ndataset can be downloaded from [http://host.robots.ox.ac.uk/pascal/VOC/, use The VOC2007 Challenge in this example\n\nWeights can be downloaded at [https://drive.google.com/file/d/0B5o_TPhUdyJWWEl5WG1lcUxCZzQ/view?usp=sharing](https://drive.google.com/file/d/0B5o_TPhUdyJWWEl5WG1lcUxCZzQ/view?usp=sharing)\n\n\n### Hint\n\nThe folder called Data-set has just 5-10 samples of the VOC-2007. to train your own model please download the entire data set by clicking on the link above. Thanks \n\n### References\n\nMy work is just playing with this fantastic algorithm, and see the detection result of my own. Many many thanks goes to the author of the SSD paper\n",
            "readme_url": "https://github.com/nirajdpandey/Object-detection-and-localization-using-SSD",
            "frameworks": [
                "Keras"
            ]
        }
    ],
    "references": [
        {
            "title": "SSD: Single Shot MultiBox Detector",
            "arxiv": "1512.02325",
            "year": 2015,
            "url": "http://arxiv.org/abs/1512.02325v5",
            "abstract": "We present a method for detecting objects in images using a single deep\nneural network. Our approach, named SSD, discretizes the output space of\nbounding boxes into a set of default boxes over different aspect ratios and\nscales per feature map location. At prediction time, the network generates\nscores for the presence of each object category in each default box and\nproduces adjustments to the box to better match the object shape. Additionally,\nthe network combines predictions from multiple feature maps with different\nresolutions to naturally handle objects of various sizes. Our SSD model is\nsimple relative to methods that require object proposals because it completely\neliminates proposal generation and subsequent pixel or feature resampling stage\nand encapsulates all computation in a single network. This makes SSD easy to\ntrain and straightforward to integrate into systems that require a detection\ncomponent. Experimental results on the PASCAL VOC, MS COCO, and ILSVRC datasets\nconfirm that SSD has comparable accuracy to methods that utilize an additional\nobject proposal step and is much faster, while providing a unified framework\nfor both training and inference. Compared to other single stage methods, SSD\nhas much better accuracy, even with a smaller input image size. For $300\\times\n300$ input, SSD achieves 72.1% mAP on VOC2007 test at 58 FPS on a Nvidia Titan\nX and for $500\\times 500$ input, SSD achieves 75.1% mAP, outperforming a\ncomparable state of the art Faster R-CNN model. Code is available at\nhttps://github.com/weiliu89/caffe/tree/ssd .",
            "authors": [
                "Wei Liu",
                "Dragomir Anguelov",
                "Dumitru Erhan",
                "Christian Szegedy",
                "Scott Reed",
                "Cheng-Yang Fu",
                "Alexander C. Berg"
            ]
        },
        {
            "title": "Fast R-CNN",
            "arxiv": "1504.08083",
            "year": 2015,
            "url": "http://arxiv.org/abs/1504.08083v2",
            "abstract": "This paper proposes a Fast Region-based Convolutional Network method (Fast\nR-CNN) for object detection. Fast R-CNN builds on previous work to efficiently\nclassify object proposals using deep convolutional networks. Compared to\nprevious work, Fast R-CNN employs several innovations to improve training and\ntesting speed while also increasing detection accuracy. Fast R-CNN trains the\nvery deep VGG16 network 9x faster than R-CNN, is 213x faster at test-time, and\nachieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains\nVGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is\nimplemented in Python and C++ (using Caffe) and is available under the\nopen-source MIT License at https://github.com/rbgirshick/fast-rcnn.",
            "authors": [
                "Ross Girshick"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999134648745766,
        "task": "Object Detection",
        "task_prob": 0.9893990512514658
    },
    "training": {
        "datasets": [
            {
                "name": "COCO"
            },
            {
                "name": "PASCAL VOC 2012"
            }
        ]
    }
}
{
    "visibility": {
        "visibility": "public"
    },
    "name": "ResNet-CIFAR10",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "VinayBN8997",
                "owner_type": "User",
                "name": "ResNet-CIFAR10",
                "url": "https://github.com/VinayBN8997/ResNet-CIFAR10",
                "stars": 0,
                "pushed_at": "2019-07-25 02:18:43+00:00",
                "created_at": "2019-07-25 01:54:10+00:00",
                "language": "Jupyter Notebook",
                "description": "A notebook reference to model ResNet on CIFAR 10. Gradcam is applied on it.",
                "frameworks": [
                    "Keras"
                ]
            },
            {
                "type": "code",
                "name": "ResNet_on_CIFAR10.ipynb",
                "sha": "3d057078e4b1928a86ebbb4da88a6eee93200713",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/VinayBN8997/ResNet-CIFAR10/blob/master/ResNet_on_CIFAR10.ipynb"
                    }
                },
                "size": 1545534
            }
        ]
    },
    "authors": [
        {
            "name": "Vinay Bn",
            "email": "vinaybn8997@gmail.com",
            "github_id": "VinayBN8997"
        }
    ],
    "tags": [],
    "description": "A notebook reference to model ResNet on CIFAR 10. Gradcam is applied on it.",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/VinayBN8997/ResNet-CIFAR10",
            "stars": 0,
            "issues": true,
            "readme": "# ResNet-CIFAR10\nA notebook referenct to model ResNet on CIFAR 10\n\n### In this post,  we are tarining a ResNet network on CIFAR10. The ResNet model used is pretrained on the ImageNet dataset.\n\nTo import the pretarined model, we are using another GitHub repository from Pavel Yakubovskiy.\nLink: https://github.com/qubvel\n\nThe model is trained on Google Colab which provides 12 hours of free GPU instance per session.\n\nTo clone the model into python library:\n```python\n!pip install git+https://github.com/qubvel/classification_models.git\n```\nRequirements:\n1. Keras\n2. Classification_models : Github: https://github.com/qubvel/classification_models.git\n3. Numpy\n4. Matplotlib\n5. OpenCV\n\n\n\n## About training dataset:\n\nThe CIFAR-10 dataset (Canadian Institute For Advanced Research) is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class. CIFAR-10 is a labeled subset of the 80 million tiny images dataset.\n\nSource: https://en.wikipedia.org/wiki/CIFAR-10\n\n\n## Network architecture: ResNet\n\narXiv: https://arxiv.org/abs/1512.03385\n\nIt is observed that as the networks goes deeper and deeper, during the convergence, the degradation of weights is an inevitable problem. The weights get too small which leads to saturated accuracy.\nTo avoid this problem, skip connections are introduced into the architecture so that instead of just stacking up of layers, the prior reidual mapping is also concatenated with the current mapping so that the architecture is explicitly let to fit a residual mapping.\nBelow is a Residual block used in the ResNet architecture. Here the identity mapping of input X is also added to the output of the convolution block. On doing this in all the convolution blocks, the degradation problem is tackled.\n\n![image](https://user-images.githubusercontent.com/33830482/61840489-f89b9880-aeae-11e9-809d-8eaa7befdf9a.png)\n\nTo get the model configured from ImageNet to CIFAR10 configuration, we need to add anothe layer at the end.\n\n```python\nbase_model = ResNet18(input_shape=(32,32,3), weights='imagenet', include_top=False)\nx = keras.layers.GlobalAveragePooling2D()(base_model.output)\noutput = keras.layers.Dense(n_classes, activation='softmax')(x)\nmodel = keras.models.Model(inputs=[base_model.input], outputs=[output])\n```\n\n## Next, we are working on Gradcam which helps in understanding what the model is looking at\n\nReference: http://www.hackevolve.com/where-cnn-is-looking-grad-cam/\n\nGradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say logits for \u2018dog\u2019 or even a caption), flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept.\nProcess:\n\n1. Compute the gradient of the class output value with respect to the feature map\n2. Pool the gradients over all the axes leaving out the channel dimension\n3. Weigh the output feature map with the computed gradient values\n4. Average the weighed feature map along the channel dimension resulting in a heat map of size same as the input image\n5. Finally normalize the heat map to make the values in between 0 and 1\n\n### 3 funtions are written which returns the activation map from thier respective layers as below:\n\n1. stage1_unit1_relu2 : Initial stage of the network\n2. stage1_unit2_relu2 : Layer approximately in the middle of the architecture\n3. stage4_unit1_relu1: Deeper stage of the network\n\n\n\n\n\n\n",
            "readme_url": "https://github.com/VinayBN8997/ResNet-CIFAR10",
            "frameworks": [
                "Keras"
            ]
        }
    ],
    "references": [
        {
            "title": "Deep Residual Learning for Image Recognition",
            "arxiv": "1512.03385",
            "year": 2015,
            "url": "http://arxiv.org/abs/1512.03385v1",
            "abstract": "Deeper neural networks are more difficult to train. We present a residual\nlearning framework to ease the training of networks that are substantially\ndeeper than those used previously. We explicitly reformulate the layers as\nlearning residual functions with reference to the layer inputs, instead of\nlearning unreferenced functions. We provide comprehensive empirical evidence\nshowing that these residual networks are easier to optimize, and can gain\naccuracy from considerably increased depth. On the ImageNet dataset we evaluate\nresidual nets with a depth of up to 152 layers---8x deeper than VGG nets but\nstill having lower complexity. An ensemble of these residual nets achieves\n3.57% error on the ImageNet test set. This result won the 1st place on the\nILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100\nand 1000 layers.\n  The depth of representations is of central importance for many visual\nrecognition tasks. Solely due to our extremely deep representations, we obtain\na 28% relative improvement on the COCO object detection dataset. Deep residual\nnets are foundations of our submissions to ILSVRC & COCO 2015 competitions,\nwhere we also won the 1st places on the tasks of ImageNet detection, ImageNet\nlocalization, COCO detection, and COCO segmentation.",
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            },
            {
                "name": "CIFAR-10"
            },
            {
                "name": "Wikipedia"
            },
            {
                "name": "ImageNet Detection"
            },
            {
                "name": "ILSVRC 2015"
            },
            {
                "name": "COCO"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.999999822417954,
        "task": "Object Detection",
        "task_prob": 0.6922998521004009
    }
}
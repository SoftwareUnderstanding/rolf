{
    "visibility": {
        "visibility": "public",
        "license": "Apache License 2.0"
    },
    "name": "RetinaNet",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "srihari-humbarwadi",
                "owner_type": "User",
                "name": "retinanet-tensorflow2.x",
                "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x",
                "stars": 31,
                "pushed_at": "2021-10-14 14:48:48+00:00",
                "created_at": "2020-08-08 15:12:21+00:00",
                "language": "Jupyter Notebook",
                "description": "TensorFlow2.x implementation of RetinaNet",
                "license": "Apache License 2.0",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".deepsource.toml",
                "sha": "25bc3d76d21fef2f2bb83f345e15c289322caf6d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/blob/master/.deepsource.toml"
                    }
                },
                "size": 106
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "29efe80c971bb5d63c6722a372b6889a56bac8b4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/blob/master/.gitignore"
                    }
                },
                "size": 2216
            },
            {
                "type": "code",
                "name": ".pre-commit-config.yaml",
                "sha": "d97b7551428ad18611fdc910206e87b6397d570e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/blob/master/.pre-commit-config.yaml"
                    }
                },
                "size": 407
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "c774558e633d68a95c5660be5ee24264883bf91f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/blob/master/LICENSE"
                    }
                },
                "size": 11348
            },
            {
                "type": "code",
                "name": "RESULTS.md",
                "sha": "7e74ba5f715d678b01f0d03ae689e7a03a570dd5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/blob/master/RESULTS.md"
                    }
                },
                "size": 3637
            },
            {
                "type": "code",
                "name": "agx_xavier",
                "sha": "55b5cd4f0a5f93643403b1dc23bcc7eb2d95c764",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/tree/master/agx_xavier"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "assets",
                "sha": "e0a526bd1a083a70733efb15873f7e9fd78de1fb",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/tree/master/assets"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "configs",
                "sha": "dbd467152fd8a3873109ab5304e2f026f1a69013",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/tree/master/configs"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "google_cloud",
                "sha": "88df4695b04047873134696fa8b628bd47be1625",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/tree/master/google_cloud"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "launch.sh",
                "sha": "a3299590d922174ca6cbbefb94f34b6b1de84384",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/blob/master/launch.sh"
                    }
                },
                "size": 157
            },
            {
                "type": "code",
                "name": "notebooks",
                "sha": "34e81a8be51c238fa3351cbe73b88fddd43fb801",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/tree/master/notebooks"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "prepare_coco_dataset.sh",
                "sha": "2eaa44b5b41c28b3c91ad528752980629ec06263",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/blob/master/prepare_coco_dataset.sh"
                    }
                },
                "size": 411
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "9b82c9fed29045e1aa3e45415432a360c280fcaa",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/blob/master/requirements.txt"
                    }
                },
                "size": 153
            },
            {
                "type": "code",
                "name": "retinanet",
                "sha": "3ed58b9616e5db65f5c54a72c2402daf8f7a704b",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/tree/master/retinanet"
                    }
                },
                "num_files": 19
            },
            {
                "type": "code",
                "name": "sotabench.py",
                "sha": "d5659a6ad200f869434db9b4902b4f478eaba3c1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/blob/master/sotabench.py"
                    }
                },
                "size": 3130
            },
            {
                "type": "code",
                "name": "sotabench_setup.sh",
                "sha": "291446a991a3bfa16008d9ebfb0eef4acd4772ab",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x/blob/master/sotabench_setup.sh"
                    }
                },
                "size": 89
            }
        ]
    },
    "authors": [
        {
            "name": "Srihari Humbarwadi",
            "email": "sriharihumbarwadi97@gmail.com",
            "github_id": "srihari-humbarwadi"
        },
        {
            "name": "deepsource-autofix[bot]",
            "github_id": "deepsource-autofix[bot]"
        },
        {
            "name": "DeepSource Bot",
            "github_id": "deepsourcebot"
        }
    ],
    "tags": [
        "tensorflow",
        "retinanet",
        "object-detection"
    ],
    "description": "TensorFlow2.x implementation of RetinaNet",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x",
            "stars": 31,
            "issues": true,
            "readme": "# RetinaNet\n### This work is supported by Cloud TPUs from Google's TPU Research Cloud (TRC)\n\n#### Supports\n - [x] Distributed training on multiple GPUs\n - [x] Stable training with Automatic Mixed Precision (~2.5x faster compared to fp32)\n - [x] Training on TPU and TPU pods\n - [x] Export `saved_model`\n - [x] COCO mAP evaluation callback\n - [x] Fine tuning on custom datasets\n - [x] Continuous evaluation on separate instance\n - [x] All NMS variants:  `combined`, `per class soft/hard`, `global soft/hard`\n - [x] Batched inference\n - [x] Moving Average Optimizer\n - [x] FPN feature fusion modes `sum`, `fast_attention`, `fast_channel_attention`\n - [x] Efficientnet family of backbones\n - [x] MobileDet family of backbones\n - [ ] Anchor optimization for custom datasets\n - [x] Logging to Discord server\n - [x] Export TF-TensorRT model\n - [x] Export as ONNX model\n - [x] Build and export `TensorRT` engine\n - [x] Post training INT8 quantization with `TensorRT`\n - [ ] 8bit Quantization Aware Training with `Q/DQ` layers [WIP]\n - [ ] TF-lite NMS op\n - [ ] Export TF-lite model\n\n## Results\n| config | schedule | coco2017 mAP IoU=0.50:0.95 | GPU |TF FP32 | TF-TensorRT FP32 | TF-TensorRT FP16| TF-TensorRT INT8 |\n|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|\n| [resnet50-640x640](configs/v3-32/mscoco-retinanet-resnet50-640x640-30x-256.json) | 30x | 0.403 | Tesla V100 SXM2 16GB | 25.0 ms (40.5 FPS) | 19.0 ms (52.6 FPS) | 11.0 ms (90.1 FPS) | 10.7 ms (93.4 FPS) |\n| [resnet50-640x640](configs/v3-32/mscoco-retinanet-resnet50-640x640-30x-256.json) | 30x | 0.403 | Tesla T4 16GB | 59.0 ms (16.9 FPS) | 46.0 ms (21.7 FPS) | 19.5 ms (51.2 FPS) | ... |\n\n**Note**: *Tesla V100 has no native support for INT8 acceleration with tensor cores, this causes TensorRT to switch the format of certain layers from INT8 to FP16 if it achieves faster execution in FP16. This explains the significantly low speed-up for INT8 when compared to FP32*.\n\n## Getting Started\n### Training\n - Use `prepare_coco_dataset.sh` to download the COCO2017 dataset and create the tfrecords.\n - If you plan to train on **Google Cloud TPU**, upload the `coco_tfrecords` folder to your **Google Cloud Storage** bucket.\n - `python3 -m retinanet --config_path configs/v3-32/mscoco-retinanet-resnet50-640x640-3x-256.json --log_dir logs --alsologtostderr --is_multi_host` to train, you should now be able to see logs similar to this. (use `--is_multi_host` only when training on **TPU Pods**)\n\n```\nI0119 06:09:24.804542 140235606591296 main.py:82] Running on 32 replicas\nI0119 06:09:24.885937 140235606591296 trainer.py:69] Setting up model for train\nI0119 06:09:52.733288 140235606591296 resnet.py:352] Initialized weights from gs://tfrc_datasets/resnet50/imagenet-ckpt\nI0119 06:10:10.742130 140235606591296 builder.py:20] Trainable weights: 285\nI0119 06:10:10.742389 140235606591296 builder.py:25] Freezing initial weights\nI0119 06:10:10.749390 140235606591296 builder.py:32] Trainable weights after freezing: 252\nI0119 06:10:10.879731 140235606591296 builder.py:43] Initial l2_regularization loss 0.4231932759284973\nI0119 06:10:11.012778 140235606591296 builder.py:78] Total trainable parameters: 33,865,815\nI0119 06:10:11.013074 140235606591296 trainer.py:96] Setting up train dataset\nI0119 06:10:11.064891 140235606591296 input_pipeline.py:34] Found 257 train tfrecords matching gs://tfrc_datasets/coco_tfrecords/train*\nW0119 06:10:11.074972 140235606591296 input_pipeline.py:50] [Worker ID 0] Using 65/257 train tfrecords\nI0119 06:10:11.075413 140235606591296 input_pipeline.py:57] [Worker ID 0] Using per_replica batch_size of 8 for train\nI0119 06:10:12.979864 140235606591296 input_pipeline.py:34] Found 257 train tfrecords matching gs://tfrc_datasets/coco_tfrecords/train*\nW0119 06:10:12.989384 140235606591296 input_pipeline.py:50] [Worker ID 1] Using 64/257 train tfrecords\nI0119 06:10:12.989683 140235606591296 input_pipeline.py:57] [Worker ID 1] Using per_replica batch_size of 8 for train\nI0119 06:10:13.460913 140235606591296 input_pipeline.py:34] Found 257 train tfrecords matching gs://tfrc_datasets/coco_tfrecords/train*\nW0119 06:10:13.471797 140235606591296 input_pipeline.py:50] [Worker ID 2] Using 64/257 train tfrecords\nI0119 06:10:13.472265 140235606591296 input_pipeline.py:57] [Worker ID 2] Using per_replica batch_size of 8 for train\nI0119 06:10:13.941818 140235606591296 input_pipeline.py:34] Found 257 train tfrecords matching gs://tfrc_datasets/coco_tfrecords/train*\nW0119 06:10:13.952078 140235606591296 input_pipeline.py:50] [Worker ID 3] Using 64/257 train tfrecords\nI0119 06:10:13.952428 140235606591296 input_pipeline.py:57] [Worker ID 3] Using per_replica batch_size of 8 for train\nI0119 06:10:14.383789 140235606591296 trainer.py:128] Looking for existing checkpoints in gs://tfrc_datasets/model_files/retinanet-640-6x-256-tpu-pod\nW0119 06:10:14.452945 140235606591296 trainer.py:146] No existing checkpoints found in gs://tfrc_datasets/model_files/retinanet-640-6x-256-tpu-pod,                 running model in train mode with random weights initialization!\nI0119 06:10:14.489678 140235606591296 trainer.py:289] Starting training from step 0 for 33750 steps with 200 steps per execution\nI0119 06:10:14.489963 140235606591296 trainer.py:291] Saving checkpoints every 10000 steps in gs://tfrc_datasets/model_files/retinanet-640-6x-256-tpu-pod\nI0119 06:10:14.490106 140235606591296 trainer.py:108] Setting up summary writer\nI0119 06:10:14.491234 140235606591296 trainer.py:113] Writing summaries to gs://tfrc_datasets/tensorboard/retinanet-640-6x-256-tpu-pod\nI0119 06:10:17.358940 140235606591296 tpu.py:1259] Automatic outside compilation is enabled. Ops without XLA kernels will be automatically placed on CPU.\nI0119 06:10:55.354405 140235606591296 tpu.py:1259] Automatic outside compilation is enabled. Ops without XLA kernels will be automatically placed on CPU.\nI0119 06:11:38.859327 140235606591296 tpu.py:1259] Automatic outside compilation is enabled. Ops without XLA kernels will be automatically placed on CPU.\nI0119 06:12:10.568544 140235606591296 tpu.py:1259] Automatic outside compilation is enabled. Ops without XLA kernels will be automatically placed on CPU.\nI0119 06:16:43.704283 140235606591296 trainer.py:344] [global_step 200/33750] [ETA: 17:19:16] [137.74 imgs/s] {'box-loss': 0.007, 'class-loss': 0.694, 'weighted-loss': 1.029, 'l2-regularization': 0.419, 'total-loss': 1.448, 'gradient-norm': 4.354, 'execution-time': 371.72, 'learning-rate': 0.069}\nI0119 06:17:23.686627 140235606591296 trainer.py:344] [global_step 400/33750] [ETA: 01:50:14] [1290.65 imgs/s] {'box-loss': 0.006, 'class-loss': 0.547, 'weighted-loss': 0.84, 'l2-regularization': 0.407, 'total-loss': 1.246, 'gradient-norm': 4.103, 'execution-time': 39.67, 'learning-rate': 0.132}\nI0119 06:18:04.471802 140235606591296 trainer.py:344] [global_step 600/33750] [ETA: 01:52:19] [1259.22 imgs/s] {'box-loss': 0.006, 'class-loss': 0.509, 'weighted-loss': 0.791, 'l2-regularization': 0.388, 'total-loss': 1.18, 'gradient-norm': 3.857, 'execution-time': 40.66, 'learning-rate': 0.195}\n\n```\n___\n### Running Inference\n```python\n# Populate image paths\nimage_dir = '../val2017'\nimage_paths = sorted(glob(image_dir + '/*'))\n\nprint('Found {} images in {}'.format(len(image_paths), image_dir))\n\n# Load label mapping\nwith open('coco_label_map.json', 'r') as f:\n    label_map = json.load(f)\n\n# Load `saved_model`\nmodel = tf.saved_model.load(\n    '../model_files/saved_models/mscoco-retinanet-resnet50-640x640-3x-256/')\n\n\nprepare_image_fn = model.signatures['prepare_image']  # get concrete function for preprocessing images\nserving_fn = model.signatures['serving_default']  # get concrete function for running the model\n\nidx = 4348\nimage = read_image(image_paths[idx])\nserving_input = prepare_image_fn(image=image)\ntik = time()\ndetections = serving_fn(serving_input['image'])\ntoc = time()\n\nvalid_detections = detections['valid_detections'][0].numpy()\nboxes = detections['boxes'][0][:valid_detections].numpy()\nclasses = [\n    label_map[str(idx)]\n    for idx in detections['classes'][0][:valid_detections].numpy()\n]\nscores = detections['scores'][0][:valid_detections].numpy()\n\n#  Visualize detections\nvisualize_detections(image,\n                     boxes,\n                     classes,\n                     scores,\n                     title='Image: {}'.format(idx),\n                     score_threshold=0.30,\n                     save=False,\n                     filename='image_{}.png'.format(idx))\n\nprint('Inference time: {:.2f} ms'.format((toc - tik) * 1000))\n```\n___\n### Visualizations\n\n<table>\n  <tr>\n    <td valign=\"top\"><img src=\"assets/image_3116.png\"></td>\n    <td valign=\"top\"><img src=\"assets/image_1618.png\"></td>\n    <td valign=\"top\"><img src=\"assets/image_4964.png\"></td>\n    <td valign=\"top\"><img src=\"assets/image_4348.png\"></td>\n  </tr>\n </table>\n\n___\n### Tensorboard\n![loss curves](assets/tensorboard.png)\n\n```\n@misc{1708.02002,\nAuthor = {Tsung-Yi Lin and Priya Goyal and Ross Girshick and Kaiming He and Piotr Doll\u00e1r},\nTitle = {Focal Loss for Dense Object Detection},\nYear = {2017},\nEprint = {arXiv:1708.02002},\n}\n```\n___\n\n#### References\n - https://github.com/tensorflow/models\n - https://github.com/facebookresearch/detectron2\n",
            "readme_url": "https://github.com/srihari-humbarwadi/retinanet-tensorflow2.x",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "eprint": "arXiv:1708.02002",
            "year": "2017",
            "title": "Focal Loss for Dense Object Detection",
            "author": [
                "Lin, Tsung-Yi",
                "Goyal, Priya",
                "Girshick, Ross",
                "He, Kaiming",
                "Doll\u00e1r, Piotr"
            ],
            "ENTRYTYPE": "misc",
            "ID": "1708.02002",
            "authors": [
                "Lin, Tsung-Yi",
                "Goyal, Priya",
                "Girshick, Ross",
                "He, Kaiming",
                "Doll\u00e1r, Piotr"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            },
            {
                "name": "MSCOCO"
            },
            {
                "name": "COCO"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9952036965739002,
        "task": "Object Detection",
        "task_prob": 0.6539595930201269
    }
}
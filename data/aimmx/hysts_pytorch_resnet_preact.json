{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "PyTorch Implementation of ResNet-preact",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "hysts",
                "owner_type": "User",
                "name": "pytorch_resnet_preact",
                "url": "https://github.com/hysts/pytorch_resnet_preact",
                "stars": 9,
                "pushed_at": "2019-08-05 06:05:54+00:00",
                "created_at": "2017-12-23 05:20:58+00:00",
                "language": "Python",
                "description": "A PyTorch implementation of ResNet-preact",
                "license": "MIT License",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "7bbc71c09205c78d790739d246bbe4f9f1881c17",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hysts/pytorch_resnet_preact/blob/master/.gitignore"
                    }
                },
                "size": 1157
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "0a02eee952faa7c4efc5bb3422cd1642293d3859",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hysts/pytorch_resnet_preact/blob/master/LICENSE"
                    }
                },
                "size": 1062
            },
            {
                "type": "code",
                "name": "config.py",
                "sha": "33bdfe2e651dcb8dc72c4432b8877a99f5197cfd",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hysts/pytorch_resnet_preact/blob/master/config.py"
                    }
                },
                "size": 1134
            },
            {
                "type": "code",
                "name": "dataloader.py",
                "sha": "7e3434e57f29ef95c982d4ab3a1aa55264d2a2f6",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hysts/pytorch_resnet_preact/blob/master/dataloader.py"
                    }
                },
                "size": 1446
            },
            {
                "type": "code",
                "name": "figures",
                "sha": "efb6ff54d189f2a3faaefa3d0dcaae2b9fa06fd0",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hysts/pytorch_resnet_preact/tree/master/figures"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "resnet_preact.py",
                "sha": "d3630ef364e8c6d2aed120d8fd932b60518ff22e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hysts/pytorch_resnet_preact/blob/master/resnet_preact.py"
                    }
                },
                "size": 8373
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "efeb85f034c01049b637ee12761fc4f6d644f0c5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hysts/pytorch_resnet_preact/blob/master/train.py"
                    }
                },
                "size": 8495
            }
        ]
    },
    "authors": [
        {
            "name": "hysts",
            "github_id": "hysts"
        }
    ],
    "tags": [
        "pytorch",
        "computer-vision",
        "cifar10"
    ],
    "description": "A PyTorch implementation of ResNet-preact",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/hysts/pytorch_resnet_preact",
            "stars": 9,
            "issues": true,
            "readme": "# PyTorch Implementation of ResNet-preact\n\n## Requirements\n\n* Python >= 3.6\n* PyTorch >= 1.0.1\n* torchvision\n* [tensorboardX](https://github.com/lanpa/tensorboardX)\n* [YACS](https://github.com/rbgirshick/yacs)\n\n\n## Usage\n\n```\n$ python train.py model.block_type basic model.depth 110 run.outdir results\n```\n\n### Use PyramidNet-like Residual Unit\n\n```\n$ python train.py model.block_type basic model.depth 110 model.remove_first_relu True model.add_last_bn True run.outdir results\n```\n\n## Results on CIFAR-10\n\n| Model                        | Test Error (median of 3 runs) | Test Error (in paper)   | Training Time |\n|:-----------------------------|:-----------------------------:|:-----------------------:|--------------:|\n| ResNet-preact-110            | 6.47                          | 6.37 (median of 5 runs) |   3h05m       |\n| ResNet-preact-164 bottleneck | 5.90                          | 5.46 (median of 5 runs) |   4h01m       |\n\n![](figures/ResNet-preact-110_basic.png)\n\n![](figures/ResNet-preact-164_bottleneck.png)\n\n## References\n\n* He, Kaiming, et al. \"Deep residual learning for image recognition.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. [arXiv:1512.03385]( https://arxiv.org/abs/1512.03385 )\n* He, Kaiming, et al. \"Identity mappings in deep residual networks.\" European Conference on Computer Vision. Springer International Publishing, 2016. [arXiv:1603.05027]( https://arxiv.org/abs/1603.05027 ), [Torch implementation]( https://github.com/KaimingHe/resnet-1k-layers )\n\n\n",
            "readme_url": "https://github.com/hysts/pytorch_resnet_preact",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Deep Residual Learning for Image Recognition",
            "arxiv": "1512.03385",
            "year": 2015,
            "url": "http://arxiv.org/abs/1512.03385v1",
            "abstract": "Deeper neural networks are more difficult to train. We present a residual\nlearning framework to ease the training of networks that are substantially\ndeeper than those used previously. We explicitly reformulate the layers as\nlearning residual functions with reference to the layer inputs, instead of\nlearning unreferenced functions. We provide comprehensive empirical evidence\nshowing that these residual networks are easier to optimize, and can gain\naccuracy from considerably increased depth. On the ImageNet dataset we evaluate\nresidual nets with a depth of up to 152 layers---8x deeper than VGG nets but\nstill having lower complexity. An ensemble of these residual nets achieves\n3.57% error on the ImageNet test set. This result won the 1st place on the\nILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100\nand 1000 layers.\n  The depth of representations is of central importance for many visual\nrecognition tasks. Solely due to our extremely deep representations, we obtain\na 28% relative improvement on the COCO object detection dataset. Deep residual\nnets are foundations of our submissions to ILSVRC & COCO 2015 competitions,\nwhere we also won the 1st places on the tasks of ImageNet detection, ImageNet\nlocalization, COCO detection, and COCO segmentation.",
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ]
        },
        {
            "title": "Identity Mappings in Deep Residual Networks",
            "arxiv": "1603.05027",
            "year": 2016,
            "url": "http://arxiv.org/abs/1603.05027v3",
            "abstract": "Deep residual networks have emerged as a family of extremely deep\narchitectures showing compelling accuracy and nice convergence behaviors. In\nthis paper, we analyze the propagation formulations behind the residual\nbuilding blocks, which suggest that the forward and backward signals can be\ndirectly propagated from one block to any other block, when using identity\nmappings as the skip connections and after-addition activation. A series of\nablation experiments support the importance of these identity mappings. This\nmotivates us to propose a new residual unit, which makes training easier and\nimproves generalization. We report improved results using a 1001-layer ResNet\non CIFAR-10 (4.62% error) and CIFAR-100, and a 200-layer ResNet on ImageNet.\nCode is available at: https://github.com/KaimingHe/resnet-1k-layers",
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ]
        },
        {
            "title": "tensorboardX",
            "url": "https://github.com/lanpa/tensorboardX"
        },
        {
            "title": "YACS",
            "url": "https://github.com/rbgirshick/yacs"
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "CIFAR-10"
            },
            {
                "name": "ImageNet"
            },
            {
                "name": "ImageNet Detection"
            },
            {
                "name": "ILSVRC 2015"
            },
            {
                "name": "CIFAR-100"
            },
            {
                "name": "COCO"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999999507712438,
        "task": "Object Detection",
        "task_prob": 0.9684451463447634
    }
}
{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Implicit Neural Representations with Periodic Activation Functions",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "TalFurman",
                "owner_type": "User",
                "name": "Implict_neural_representation_of_images",
                "url": "https://github.com/TalFurman/Implict_neural_representation_of_images",
                "stars": 0,
                "pushed_at": "2021-08-15 10:36:46+00:00",
                "created_at": "2021-08-06 17:57:27+00:00",
                "language": "Jupyter Notebook",
                "description": "Extend single image encoding paradigms to jointly encode multiple images ",
                "license": "MIT License",
                "frameworks": [
                    "scikit-learn",
                    "TensorFlow",
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "b6e47617de110dea7ca47e087ff1347cc2646eda",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/blob/master/.gitignore"
                    }
                },
                "size": 1799
            },
            {
                "type": "code",
                "name": "Implicit_neural_representation.ipynb",
                "sha": "142329ba5c71b3cab95d03227f150e5e1ec65c5b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/blob/master/Implicit_neural_representation.ipynb"
                    }
                },
                "size": 1591438
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "966a4bf049697eb0557aece20c4109a0a3e207f1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/blob/master/LICENSE"
                    }
                },
                "size": 1073
            },
            {
                "type": "code",
                "name": "data",
                "sha": "cf42d890c88190e1f6237a6f2dbc709e0624a1e2",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/tree/master/data"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "dataio.py",
                "sha": "7643a86d9fa196b7206a6078d04c3eb6d8344850",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/blob/master/dataio.py"
                    }
                },
                "size": 35038
            },
            {
                "type": "code",
                "name": "diff_operators.py",
                "sha": "98022a688ec25f414f40ab8179e194fa09dd206e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/blob/master/diff_operators.py"
                    }
                },
                "size": 1896
            },
            {
                "type": "code",
                "name": "environment.yml",
                "sha": "3dd65b9ffea19aeae6dfef1ffa62d63c1bc9a1d5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/blob/master/environment.yml"
                    }
                },
                "size": 6198
            },
            {
                "type": "code",
                "name": "experiment_scripts",
                "sha": "140000b9fa4c91857256c05f41dd1c18989cfaea",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/tree/master/experiment_scripts"
                    }
                },
                "num_files": 18
            },
            {
                "type": "code",
                "name": "explore_siren.ipynb",
                "sha": "dec3b8cbc112411a601442f255a9204ae3782448",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/blob/master/explore_siren.ipynb"
                    }
                },
                "size": 33891
            },
            {
                "type": "code",
                "name": "loss_functions.py",
                "sha": "1b58e582e48b473545cdd4f7ac0a1fa44a67e629",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/blob/master/loss_functions.py"
                    }
                },
                "size": 10398
            },
            {
                "type": "code",
                "name": "make_figures.py",
                "sha": "0434617ad917236683f27ccee2a00e6cc4448cae",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/blob/master/make_figures.py"
                    }
                },
                "size": 11589
            },
            {
                "type": "code",
                "name": "meta_modules.py",
                "sha": "be9625b56309d6465f058c5da0fe2a35a355c95a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/blob/master/meta_modules.py"
                    }
                },
                "size": 6526
            },
            {
                "type": "code",
                "name": "modules.py",
                "sha": "f26f980684c8961cb4b9a0e3c36d96cc24f13e97",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/blob/master/modules.py"
                    }
                },
                "size": 24357
            },
            {
                "type": "code",
                "name": "sdf_meshing.py",
                "sha": "b5516b76a06a3e5f9c54c56a8e661498d2f1a12d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/blob/master/sdf_meshing.py"
                    }
                },
                "size": 4218
            },
            {
                "type": "code",
                "name": "torchmeta",
                "sha": "665fff72a6a3998c995e253e37811dc4c47ffa32",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/tree/master/torchmeta"
                    }
                },
                "num_files": 8
            },
            {
                "type": "code",
                "name": "training.py",
                "sha": "6e0d98c8d8b6ee9f0bbcb85dfee0e0c2158d78ef",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/blob/master/training.py"
                    }
                },
                "size": 5696
            },
            {
                "type": "code",
                "name": "utils.py",
                "sha": "c13c6ac77e5d6241f607b3d78f010dccbe7b45c6",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TalFurman/Implict_neural_representation_of_images/blob/master/utils.py"
                    }
                },
                "size": 28748
            }
        ]
    },
    "authors": [
        {
            "name": "Vincent Sitzmann",
            "github_id": "vsitzmann"
        },
        {
            "name": "Julien N.P. Martel",
            "github_id": "jnpmartel"
        },
        {
            "name": "TalFurman",
            "github_id": "TalFurman"
        },
        {
            "name": "Alex",
            "email": "awb@stanford.edu",
            "github_id": "alexanderbergman7"
        }
    ],
    "tags": [],
    "description": "Extend single image encoding paradigms to jointly encode multiple images ",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/TalFurman/Implict_neural_representation_of_images",
            "stars": 0,
            "issues": true,
            "readme": "# Implicit Neural Representations with Periodic Activation Functions\n### [Project Page](https://vsitzmann.github.io/siren) | [Paper](https://arxiv.org/abs/2006.09661) | [Data](https://drive.google.com/drive/folders/1_iq__37-hw7FJOEUK1tX7mdp8SKB368K?usp=sharing)\n[![Explore Siren in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vsitzmann/siren/blob/master/explore_siren.ipynb)<br>\n\n[Vincent Sitzmann](https://vsitzmann.github.io/)\\*,\n[Julien N. P. Martel](http://www.jmartel.net)\\*,\n[Alexander W. Bergman](http://alexanderbergman7.github.io),\n[David B. Lindell](http://www.davidlindell.com/),\n[Gordon Wetzstein](https://stanford.edu/~gordonwz/)<br>\nStanford University, \\*denotes equal contribution\n\nThis is the official implementation of the paper \"Implicit Neural Representations with Periodic Activation Functions\".\n\n[![siren_video](https://img.youtube.com/vi/Q2fLWGBeaiI/0.jpg)](https://www.youtube.com/watch?v=Q2fLWGBeaiI)\n\n\n## Google Colab\nIf you want to experiment with Siren, we have written a [Colab](https://colab.research.google.com/github/vsitzmann/siren/blob/master/explore_siren.ipynb).\nIt's quite comprehensive and comes with a no-frills, drop-in implementation of SIREN. It doesn't require \ninstalling anything, and goes through the following experiments / SIREN properties:\n* Fitting an image\n* Fitting an audio signal\n* Solving Poisson's equation\n* Initialization scheme & distribution of activations\n* Distribution of activations is shift-invariant\n* Periodicity & behavior outside of the training range. \n\n## Tensorflow Playground\nYou can also play arond with a tiny SIREN interactively, directly in the browser, via the Tensorflow Playground [here](https://dcato98.github.io/playground/#activation=sine). Thanks to [David Cato](https://github.com/dcato98) for implementing this! \n\n## Get started\nIf you want to reproduce all the results (including the baselines) shown in the paper, the videos, point clouds, and \naudio files can be found [here](https://drive.google.com/drive/folders/1_iq__37-hw7FJOEUK1tX7mdp8SKB368K?usp=sharing).\n\nYou can then set up a conda environment with all dependencies like so:\n```\nconda env create -f environment.yml\nconda activate siren\n```\n\n## High-Level structure\nThe code is organized as follows:\n* dataio.py loads training and testing data.\n* training.py contains a generic training routine.\n* modules.py contains layers and full neural network modules.\n* meta_modules.py contains hypernetwork code.\n* utils.py contains utility functions, most promintently related to the writing of Tensorboard summaries.\n* diff_operators.py contains implementations of differential operators.\n* loss_functions.py contains loss functions for the different experiments.\n* make_figures.py contains helper functions to create the convergence videos shown in the video.\n* ./experiment_scripts/ contains scripts to reproduce experiments in the paper.\n\n## Reproducing experiments\nThe directory `experiment_scripts` contains one script per experiment in the paper.\n\nTo monitor progress, the training code writes tensorboard summaries into a \"summaries\"\" subdirectory in the logging_root.\n\n### Image experiments\nThe image experiment can be reproduced with\n```\npython experiment_scripts/train_img.py --model_type=sine\n```\nThe figures in the paper were made by extracting images from the tensorboard summaries. Example code how to do this can\nbe found in the make_figures.py script.\n\n### Audio experiments\nThis github repository comes with both the \"counting\" and \"bach\" audio clips under ./data.\n\nThey can be trained with\n```\npython experiment_scipts/train_audio.py --model_type=sine --wav_path=<path_to_audio_file>\n```\n\n### Video experiments\nThe \"bikes\" video sequence comes with scikit-video and need not be downloaded. The cat video can be downloaded with the\nlink above.\n\nTo fit a model to a video, run\n```\npython experiment_scipts/train_video.py --model_type=sine --experiment_name bikes_video\n```\n\n### Poisson experiments\nFor the poisson experiments, there are three separate scripts: One for reconstructing an image from its gradients \n(train_poisson_grad_img.py), from its laplacian (train_poisson_lapl_image.py), and to combine two images \n(train_poisson_gradcomp_img.py).\n\nSome of the experiments were run using the BSD500 datast, which you can download [here](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/).\n\n### SDF Experiments\nTo fit a Signed Distance Function (SDF) with SIREN, you first need a pointcloud in .xyz format that includes surface normals.\nIf you only have a mesh / ply file, this can be accomplished with the open-source tool Meshlab.\n\nTo reproduce our results, we provide both models of the Thai Statue from the 3D Stanford model repository and the living room used in our paper\nfor download here.\n\nTo start training a SIREN, run:\n```\npython experiments_scripts/train_single_sdf.py --model_type=sine --point_cloud_path=<path_to_the_model_in_xyz_format> --batch_size=250000 --experiment_name=experiment_1\n```\nThis will regularly save checkpoints in the directory specified by the rootpath in the script, in a subdirectory \"experiment_1\". \nThe batch_size is typically adjusted to fit in the entire memory of your GPU. \nOur experiments show that with a 256, 3 hidden layer SIREN one can set the batch size between 230-250'000 for a NVidia GPU with 12GB memory.\n\nTo inspect a SDF fitted to a 3D point cloud, we now need to create a mesh from the zero-level set of the SDF. \nThis is performed with another script that uses a marching cubes algorithm (adapted from the DeepSDF github repo) \nand creates the mesh saved in a .ply file format. It can be called with:\n```\npython experiments_scripts/test_single_sdf.py --checkpoint_path=<path_to_the_checkpoint_of_the_trained_model> --experiment_name=experiment_1_rec \n```\nThis will save the .ply file as \"reconstruction.ply\" in \"experiment_1_rec\" (be patient, the marching cube meshing step takes some time ;) )\nIn the event the machine you use for the reconstruction does not have enough RAM, running test_sdf script will likely freeze. If this is the case, \nplease use the option --resolution=512 in the command line above (set to 1600 by default) that will reconstruct the mesh at a lower spatial resolution.\n\nThe .ply file can be visualized using a software such as [Meshlab](https://www.meshlab.net/#download) (a cross-platform visualizer and editor for 3D models).\n\n### Helmholtz and wave equation experiments\nThe helmholtz and wave equation experiments can be reproduced with the train_wave_equation.py and train_helmholtz.py scripts.\n\n## Torchmeta\nWe're using the excellent [torchmeta](https://github.com/tristandeleu/pytorch-meta) to implement hypernetworks. We \nrealized that there is a technical report, which we forgot to cite - it'll make it into the camera-ready version!\n\n## Citation\nIf you find our work useful in your research, please cite:\n```\n@inproceedings{sitzmann2019siren,\n    author = {Sitzmann, Vincent\n              and Martel, Julien N.P.\n              and Bergman, Alexander W.\n              and Lindell, David B.\n              and Wetzstein, Gordon},\n    title = {Implicit Neural Representations\n              with Periodic Activation Functions},\n    booktitle = {arXiv},\n    year={2020}\n}\n```\n\n## Contact\nIf you have any questions, please feel free to email the authors.\n",
            "readme_url": "https://github.com/TalFurman/Implict_neural_representation_of_images",
            "frameworks": [
                "scikit-learn",
                "TensorFlow",
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Implicit Neural Representations with Periodic Activation Functions",
            "arxiv": "2006.09661",
            "year": 2020,
            "url": "http://arxiv.org/abs/2006.09661v1",
            "abstract": "Implicitly defined, continuous, differentiable signal representations\nparameterized by neural networks have emerged as a powerful paradigm, offering\nmany possible benefits over conventional representations. However, current\nnetwork architectures for such implicit neural representations are incapable of\nmodeling signals with fine detail, and fail to represent a signal's spatial and\ntemporal derivatives, despite the fact that these are essential to many\nphysical signals defined implicitly as the solution to partial differential\nequations. We propose to leverage periodic activation functions for implicit\nneural representations and demonstrate that these networks, dubbed sinusoidal\nrepresentation networks or Sirens, are ideally suited for representing complex\nnatural signals and their derivatives. We analyze Siren activation statistics\nto propose a principled initialization scheme and demonstrate the\nrepresentation of images, wavefields, video, sound, and their derivatives.\nFurther, we show how Sirens can be leveraged to solve challenging boundary\nvalue problems, such as particular Eikonal equations (yielding signed distance\nfunctions), the Poisson equation, and the Helmholtz and wave equations. Lastly,\nwe combine Sirens with hypernetworks to learn priors over the space of Siren\nfunctions.",
            "authors": [
                "Vincent Sitzmann",
                "Julien N. P. Martel",
                "Alexander W. Bergman",
                "David B. Lindell",
                "Gordon Wetzstein"
            ]
        },
        {
            "year": "2020",
            "booktitle": "arXiv",
            "title": "Implicit Neural Representations\nwith Periodic Activation Functions",
            "author": [
                "Sitzmann, Vincent",
                "Martel, Julien N.P.",
                "Bergman, Alexander W.",
                "Lindell, David B.",
                "Wetzstein, Gordon"
            ],
            "ENTRYTYPE": "inproceedings",
            "ID": "sitzmann2019siren",
            "authors": [
                "Sitzmann, Vincent",
                "Martel, Julien N.P.",
                "Bergman, Alexander W.",
                "Lindell, David B.",
                "Wetzstein, Gordon"
            ]
        }
    ],
    "domain": {
        "domain_type": "Unknown"
    }
}
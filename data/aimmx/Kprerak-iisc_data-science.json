{
    "visibility": {
        "visibility": "public"
    },
    "name": "data-science",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "Kprerak-iisc",
                "owner_type": "User",
                "name": "data-science",
                "url": "https://github.com/Kprerak-iisc/data-science",
                "stars": 0,
                "pushed_at": "2020-08-27 05:41:09+00:00",
                "created_at": "2020-08-15 13:19:41+00:00",
                "language": "Jupyter Notebook",
                "description": "Data science Projects ",
                "frameworks": [
                    "Keras",
                    "NLTK",
                    "scikit-learn",
                    "TensorFlow",
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": "ML",
                "sha": "5f10b0d2b51667486979622b96defbf136dd13a1",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Kprerak-iisc/data-science/tree/master/ML"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "NLP",
                "sha": "2f12eb4214fa6f4649ede71a9c15d5b9c39074b8",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Kprerak-iisc/data-science/tree/master/NLP"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "Time-Series",
                "sha": "af70de72b43e47000fe909a832a177dd8c7a77ad",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Kprerak-iisc/data-science/tree/master/Time-Series"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "Vision",
                "sha": "9cc148b1e53d53ddc9a776624fa7259cd7473320",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Kprerak-iisc/data-science/tree/master/Vision"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "horse2zebra_cyclegan.ipynb",
                "sha": "e7ec2c2391104c40bfdc565a1c5eedf81b0be9a7",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Kprerak-iisc/data-science/blob/master/horse2zebra_cyclegan.ipynb"
                    }
                },
                "size": 1135294
            }
        ]
    },
    "authors": [
        {
            "name": "KUMAR PRERAK",
            "github_id": "Kprerak-iisc"
        }
    ],
    "tags": [],
    "description": "Data science Projects ",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/Kprerak-iisc/data-science",
            "stars": 0,
            "issues": true,
            "readme": "# data-science\nData science Projects \n\nNLP: Contains projects related to Natural Lnaguage Processing\n\nBiDAF_QA_SQuAD.ipynb : Dataset: https://github.com/rajpurkar/SQuAD-explorer/tree/master/dataset\nImplemented Bi-directional attention flow(BiDAF) network from scratch as proposed in Minjoon Seo et. Al on Stanford Question Answering Dataset v1.1 to build a closed-domain, extractive Q&A model which can extract a span of text from the context as the answer.\n\nNmt_seq2seq: Neural machine translation from English to German and again back to English from German.\ndataset: http://www.manythings.org/anki/deu-eng.zip \n\u2022 Implemented Encoder- decoder based Sequence-to-Sequence (seq2seq) model on only 20k data out of over 150,000 data due to less computational power. \n\u2022 For the encoder, I used an embedding layer and an LSTM layer\n\u2022 For the decoder, I used another LSTM layer followed by a dense layer\n\nTopic_modeling_consumers:  Discovering Hidden Semantic Structures of Texts from Large Corpus of Documents\nDataset: https://drive.google.com/file/d/141NT1NvZGaBPPzdXStsATJzLZYa77uTw/view?usp=sharing\n\u2022 Developed a probabilistic model to cluster the abstract topics present in Consumer complaints in Financial domain from CFPB website.\n\u2022 Used Reg-ex based text regularization, Stop words removal, Stemming for pre-processing and Tfidf Vectorizer to build featurevector.\n\u2022 Implemented Topic Modeling using Latent Dirichlet Allocation (LDA) to classify each consumer complaints into one of the six topics.\n\nTopic Modeling using Latent Dirichlet Allocation (LDA) on https://www.kaggle.com/benhamner/nips-papers dataset.\n\n\nML: Projects related to Machine Learning\n\ncred_bal.ipynb: Dataset: https://rdrr.io/cran/ISLR/man/Credit.html\n\u2022\tObjective: Analyze the dataset consisting of information from credit card holders to comprehend which factors influence the Credit Card Balance of a cardholder, and to predict the average Balance of a given individual. \n\u2022\tCarried out EDA of the dataset, followed by feature selection and regression analysis to build a model which explains 96% variance. \n\nfraud.ipynb: Dataset: https://www.kaggle.com/mlg-ulb/creditcardfraud\n\u2022\tDeveloped various predictive models to compare their efficiency in detecting fraudulent transactions based on their F1 score.\n\u2022\tApplied SMOTE for oversampling the minority class and used Logistic regression, K-nearest neighbour, support vector classifier and decision tree classifier.\n\u2022\tUsed Principal component analysis(PCA) and t-SNE for clustering fraudulent transactions and non-fraudulent transactions separately.\n\u2022\tBest result: XGBoost classifier was able to detect more than 80% fraud transactions without classifying a lot of non-frauds as fraudulent.\n\n\nVision: Projects related to Computer Vision\n\nAmazon.ipynb :  Dataset : https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data\n\u2022 To label satellite images provided by Planet and SCCON with atmospheric conditions and various classes of land cover/use. \n\u2022 Developed a convolutional neural network for multi-label photo classification to achieve F1 score of 0.837 using only 10% of data.\n\u2022 Used Transfer learning to improve the model performance using VGG-16 model to achieve F1 score of 0.886 with only 10% of data.\n\nMnsit_CNN.ipynb : Dataset: http://yann.lecun.com/exdb/mnist/\nThe MNIST problem is a dataset developed by Yann LeCun, Corinna Cortes and Christopher Burges for evaluating machine learning models on the handwritten digit classification problem. The dataset was constructed from a number of scanned document dataset available from the National Institute of Standards and Technology (NIST). This is where the name for the dataset comes from, as the Modified NIST or MNIST dataset. Each image is a 28 by 28 pixel square (784 pixels total). A standard split of the dataset is used to evaluate and compare models, where 60,000 images are used to train a model and a separate set of 10,000 images are used to test it.\nIt is a digit recognition task. As such there are 10 digits (0 to 9) or 10 classes to predict. Results are reported using prediction error. Convolutional Neural Networks has been used in the model to obtain prediction error of less than 1%.\n\ncifar_10_imageclassification.ipynb: Dataset: https://www.cs.toronto.edu/~kriz/cifar.html\nCIFAR-10 (Canadian Institute For Advanced Research) is the \u201chello world\u201d type dataset of computer vision. Used deep leaning Convolutional neural network to build the model using Keras API for Image Classification with 88.6% accuracy on test set.\n\nGAN(Generative Adversarial networks) Project\n\nMonet2photo_cyclegan.ipynb : Dataset: https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/monet2photo.zip\nStudied the construct and the underlying architecture of simple GAN and CycleGAN. Implemented CycleGAN model for Painting style neural transfer using \u2018monet2photo\u2019 dataset which generated images of photos from images of Monet paintings, and vice-versa in absence of one-to-one correspondence between input and output images. \n\nhorse2zebra_cyclegan.ipynb:  Dataset: https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip\nApplied CycleGAN model on the Horse Zebra   dataset used by Zhu et al. (Research Paper: https://arxiv.org/abs/1703.10593) in keras\n \n\n\nTime Series: Project related to Time Series Analysis And Forecasting\n\ntrade.r : dataset: http://mgmt.iisc.ac.in/CM/MG222/Data_Files/gdp.data\n\u2022\tBuilt an appropriate SARIMA model to model the trend and seasonality present in the time series data of Quarterly GDP of India from 1996-97:Q1 to 2013-14:Q2. Validated if the residuals of the model satisfied all the assumptions using graphical and statistical methods\n\u2022\tForecasted the GDP next 4 Quarters using the fitted model with Mean Absolute Percentage Error(MAPE) equal to 2.18%\n\n\n\n\n",
            "readme_url": "https://github.com/Kprerak-iisc/data-science",
            "frameworks": [
                "Keras",
                "NLTK",
                "scikit-learn",
                "TensorFlow",
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks",
            "arxiv": "1703.10593",
            "year": 2017,
            "url": "http://arxiv.org/abs/1703.10593v7",
            "abstract": "Image-to-image translation is a class of vision and graphics problems where\nthe goal is to learn the mapping between an input image and an output image\nusing a training set of aligned image pairs. However, for many tasks, paired\ntraining data will not be available. We present an approach for learning to\ntranslate an image from a source domain $X$ to a target domain $Y$ in the\nabsence of paired examples. Our goal is to learn a mapping $G: X \\rightarrow Y$\nsuch that the distribution of images from $G(X)$ is indistinguishable from the\ndistribution $Y$ using an adversarial loss. Because this mapping is highly\nunder-constrained, we couple it with an inverse mapping $F: Y \\rightarrow X$\nand introduce a cycle consistency loss to push $F(G(X)) \\approx X$ (and vice\nversa). Qualitative results are presented on several tasks where paired\ntraining data does not exist, including collection style transfer, object\ntransfiguration, season transfer, photo enhancement, etc. Quantitative\ncomparisons against several prior methods demonstrate the superiority of our\napproach.",
            "authors": [
                "Jun-Yan Zhu",
                "Taesung Park",
                "Phillip Isola",
                "Alexei A. Efros"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "Amazon"
            },
            {
                "name": "SQuAD"
            },
            {
                "name": "MNIST"
            },
            {
                "name": "CIFAR-10"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.976515511493694,
        "task": "Image-to-Image Translation",
        "task_prob": 0.9330539636155262
    }
}
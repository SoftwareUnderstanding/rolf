{
    "visibility": {
        "visibility": "public"
    },
    "name": "DL_cv-mdt_NVIDIA_Cert_Course_StudyPI",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "lkeonwoo94",
                "owner_type": "User",
                "name": "DL_cv-mdt_NVIDIA_Cert_Course_StudyPI",
                "url": "https://github.com/lkeonwoo94/DL_cv-mdt_NVIDIA_Cert_Course_StudyPI",
                "stars": 0,
                "pushed_at": "2020-03-02 09:46:14+00:00",
                "created_at": "2020-02-02 16:05:02+00:00",
                "language": "Jupyter Notebook",
                "description": "NVIDIA \uad6d\uc81c \uc778\uc99d\uacfc\uc815 - \ucef4\ud4e8\ud130 \ube44\uc804 \ub525\ub7ec\ub2dd & \ub2e4\uc911 \ub370\uc774\ud130 \uc720\ud615 \ub525\ub7ec\ub2dd \uae30\ucd08",
                "frameworks": [
                    "Caffe",
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": "CV",
                "sha": "55ef0efdabebe76a1aa52737f2ce4748d4c4d1cc",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/lkeonwoo94/DL_cv-mdt_NVIDIA_Cert_Course_StudyPI/tree/master/CV"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "MDT",
                "sha": "05c15d22a645fa60241604e2c8a028a351dc28a9",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/lkeonwoo94/DL_cv-mdt_NVIDIA_Cert_Course_StudyPI/tree/master/MDT"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "ML.png",
                "sha": "05865159dc0f96ad3091c15f3713893e8b62ae2b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/lkeonwoo94/DL_cv-mdt_NVIDIA_Cert_Course_StudyPI/blob/master/ML.png"
                    }
                },
                "size": 341015
            },
            {
                "type": "code",
                "name": "SGD.png",
                "sha": "2119ae3fd191349030e9a48fec54d82590fb0000",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/lkeonwoo94/DL_cv-mdt_NVIDIA_Cert_Course_StudyPI/blob/master/SGD.png"
                    }
                },
                "size": 732372
            },
            {
                "type": "code",
                "name": "opt.png",
                "sha": "cc03b8f8eec09c3a1aac7cd996edf4779eb03e38",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/lkeonwoo94/DL_cv-mdt_NVIDIA_Cert_Course_StudyPI/blob/master/opt.png"
                    }
                },
                "size": 628302
            },
            {
                "type": "code",
                "name": "optmizer\ubc1c\ub2ec.png",
                "sha": "2bfdf434555a3ad6d7169f6bb5e0fd176f1d6271",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/lkeonwoo94/DL_cv-mdt_NVIDIA_Cert_Course_StudyPI/blob/master/optmizer\ubc1c\ub2ec.png"
                    }
                },
                "size": 1099929
            }
        ]
    },
    "authors": [
        {
            "name": "Lee Keon Woo",
            "email": "lkeonw0o@naver.com",
            "github_id": "lkeonwoo94"
        }
    ],
    "tags": [],
    "description": "NVIDIA \uad6d\uc81c \uc778\uc99d\uacfc\uc815 - \ucef4\ud4e8\ud130 \ube44\uc804 \ub525\ub7ec\ub2dd & \ub2e4\uc911 \ub370\uc774\ud130 \uc720\ud615 \ub525\ub7ec\ub2dd \uae30\ucd08",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/lkeonwoo94/DL_cv-mdt_NVIDIA_Cert_Course_StudyPI",
            "stars": 0,
            "issues": true,
            "readme": "# DL_cv-mdt_NVIDIA_Cert_Course_StudyPI\nNVIDIA \uad6d\uc81c \uc778\uc99d\uacfc\uc815 - \ucef4\ud4e8\ud130 \ube44\uc804 \ub525\ub7ec\ub2dd &amp; \ub2e4\uc911 \ub370\uc774\ud130 \uc720\ud615 \ub525\ub7ec\ub2dd \uae30\ucd08\n\n\n* caffe -> Torch\uc5d0 \ud761\uc218\n* keras -> TensorFlow\uc5d0 \ud761\uc218\n\n![](https://github.com/lkeonwoo94/DL_cv-mdt_NVIDIA_Cert_Course_StudyPI/blob/master/ML.png)\n\n\n\ucc38\uace0\uc790\ub8cc : [\uac00\uc7a5 \ube60\ub974\uac8c \ub525\ub7ec\ub2dd \uc774\ud574\ud558\uae30](https://www.slideshare.net/yongho/ss-79607172/49)\n[Optimizer\uc815\ub9ac-\uc218\uc2dd](http://shuuki4.github.io/deep%20learning/2016/05/20/Gradient-Descent-Algorithm-Overview.html)\n\n\n> \ucc38\uace0\uc790\ub8cc\uc5d0\uc11c \ub0b4\uac00 \ubab0\ub790\ub358 \ubd80\ubd84\n\n![SGD](https://github.com/lkeonwoo94/DL_cv-mdt_NVIDIA_Cert_Course_StudyPI/blob/master/SGD.png)   \n![opt](https://github.com/lkeonwoo94/DL_cv-mdt_NVIDIA_Cert_Course_StudyPI/blob/master/opt.png)\n![optmizer\ubc1c\ub2ec](https://github.com/lkeonwoo94/DL_cv-mdt_NVIDIA_Cert_Course_StudyPI/blob/master/optmizer%EB%B0%9C%EB%8B%AC.png)\n\n---\n\n\uc548\ub155\ud558\uc138\uc694,\nCV, MDT\uac15\uc758\ub97c \ud1b5\ud2c0\uc5b4 \ub3c4\uc6c0\uc774 \ub420\ub9cc\ud55c \uc9c8\ubb38\uacfc \ub2f5\ubcc0\uc744 \uc815\ub9ac\ud574\ubd24\uc2b5\ub2c8\ub2e4.\n\uc2ec\uc2ec\ud558\uc2e4 \ub54c \ud55c\ubc88\uc529 \ubcf5\uc2b5\uc0bc\uc544 \uc77d\uc5b4\ubd10\uc8fc\uc2dc\uba74 \ub3c4\uc6c0\uc774 \ub418\ub9ac\ub77c \uc0dd\uac01\ud569\ub2c8\ub2e4^^\n\uc9c8\ubb38 \uc8fc\uc2e0\ubd84\ub4e4 \uac10\uc0ac\ub4dc\ub9ac\uace0, \ucc38\uac00\uc790 \uc5ec\ub7ec\ubd84\ub4e4 \ubaa8\ub450 \uace0\uc0dd \ub9ce\uc73c\uc168\uc2b5\ub2c8\ub2e4.\n---------------------------------------------------------------------------------------------------\n1. \ucee8\ubcfc\ub8e8\uc158 \uac2f\uc218\ub098 \ud544\ud130 \uac2f\uc218\ub294 \uc790\uae30\uac00 \uc9c1\uc811 \uc815\ud558\ub294 \uac74\uac00\uc694? , ' \ucee8\ubcfc\ub8e8\uc158 - \ud480\ub9c1 - \ucee8\ubcfc\ub8e8\uc158 - \ud480\ub9c1 ' \uc774 \uc544\ub2cc '\ucee8\ubcfc\ub8e8\uc158 - \ucee8\ubcfc\ub8e8\uc158 - \ucee8\ubcfc\ub8e8\uc158 - \ud480\ub9c1 - \ud480\ub9c1 - ...' \uc21c\uc73c\ub85c \uc0ac\uc6a9\uc790\uac00 \uc9c1\uc811 \ubc14\uafb8\uc5b4\ub3c4 \uc0c1\uad00 \uc5c6\ub098\uc694 ?! \ub610\ud55c \uc65c \uc774 \ub54c Fully Connected Layer\ub97c \uc0ac\uc6a9\ud588\ub294\uc9c0 \ub4f1\ub4f1 \uce35\uc744 \uc313\ub294 \uc21c\uc11c\uc5d0 \ub300\ud574 \uad81\uae08\ud574\uc694.\n\n\n\n\n-> \uac2f\uc218\ub4e4\uc744 \uc9c1\uc811 \uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n-> \uadf8 \uc21c\uc11c\ub294 \ud480\ub9c1\uc744 \ucee8\ubc8c\ub8e8\uc120 \uc911\uc559\uc5d0 \ubc30\uce58\ud558\ub294\uac8c \uc77c\ubc18\uc801\uc785\ub2c8\ub2e4. \uc608\ub97c\ub4e4\uc5b4, \ucee8\ubc8c\ub8e8\uc158\uc744 \uc5f0\uc18d\uc73c\ub85c \uc4f0\uace0 \uc2f6\uc740 \uacbd\uc6b0\uc5d0\ub294 \ucee8-\ucee8-\ucee8-\ud480-\ucee8-\ucee8-\ucee8-\ud480\uacfc \uac19\uc774 \uc0ac\uc6a9\ud558\uae30\ub3c4 \ud558\uace0, \uc5bc\ub9c8\ub4e0\uc9c0 \uc9c1\uc811 \ubc14\uafb8\uc5b4 \uc0ac\uc6a9\ud558\uae30\ub3c4 \ud569\ub2c8\ub2e4. \uc544\ub798\ub9c1\ud06c\uc758 VGG\uc640 \uac19\uc740 \uc720\uba85\ud55c \ub124\ud2b8\uc6cc\ud06c\ub3c4 \ucee8\ucee8-\ud480-\ucee8\ucee8-\ud480- \uc774\ub807\uac8c \uad6c\uc131\ud569\ub2c8\ub2e4.\nhttps://www.google.com/search?q=vggnet&sxsrf=ACYBGNTG3d5ZhZa_LxW-eOAVA5SldW9pCw:1581309366464&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjVv8W4lMbnAhWLMN4KHSouBzcQ_AUoAXoECAwQAw&biw=1805&bih=928#imgrc=AON1iVApOf8dvM\n\n\n\n\n-> \ud480\ub9c1\uc740 \ucee8\ubc8c\ub8e8\uc158\uc744 \ud1b5\ud574 depth\uc758 \uc22b\uc790\uac00 \uae4a\uc5b4\uc9c0\uae30 \uc9c1\uc804\uc5d0 \ubcf4\ud1b5 \uc774\ub8e8\uc5b4 \uc9d1\ub2c8\ub2e4. depth\ub9cc \uae4a\uc5b4\uc9c0\uae30\ub9cc\ud558\ub2e4\uac00\ub294 memory\uac00 \ub108\ubb34 \ub9ce\uc774 \ud544\uc694\ub85c\ub418\uae30 \ub54c\ubb38\uc5d0 \uae4a\uc5b4\uc9c0\uae30 \uc9c1\uc804\uc5d0 \uba54\ubaa8\ub9ac\ub97c \uc904\uc77c \ubaa9\uc801\uacfc \uc801\ub2f9\ud788 \ucee8\ubc8c\ub8e8\uc158\uc774 \uc774\ub8e8\uc5b4\uc9c4 \uc2dc\uc810\uc5d0\uc11c dominant\ud55c feature\ub4e4\uc744 \ubf51\uc544\ub0b4\ub294 \ubaa9\uc801\uc73c\ub85c \uc4f0\uc785\ub2c8\ub2e4.\n\n\n\n\n-> Fully connected layer\ub294 flatten\uc744 \uc2dc\ud0b4\uc73c\ub85c\uc368 \uacf5\uac04\uc801\ubcf4\ub97c \uc5c6\uc560\ubc84\ub9bd\ub2c8\ub2e4. \uadf8\ub807\uae30 \ub54c\ubb38\uc5d0 \ucd08\ubc18\uc5d0\ub294 \uc785\ub825\uc73c\ub85c\ubd80\ud130 \uacf5\uac04\uc815\ubcf4\ub97c \ud65c\uc6a9\ud558\ub294 feature\ub4e4\uc744 convolution\uc73c\ub85c \ucda9\ubd84\ud788 \ubf51\uc544\ub0b8 \ub4a4, \uadf8 feature\ub4e4\uc744 flatten\uc744 \uc2dc\ucf1c \uac1c\uc778\uc9c0 \uace0\uc591\uc778\uc9c0 mapping\uc2dc\ucf1c\ubcf4\uae30 \uc704\ud55c fully connected layer\ub97c \ubc30\uce58\uc2dc\ud0a4\ub294 \uac83 \uc785\ub2c8\ub2e4.\n\n\n\n\n2. \uc774\ubbf8\uc9c0\ub97c input\uc73c\ub85c \ubc1b\uace0 \ucee8\ubcfc\ub8e8\uc158\uacfc \ud480\ub9c1\uc744 \uac70\uccd0\uc11c depth\uac00 \ub298\uc5b4\ub098\uace0 width, height\uac00 \uc904\uc5b4\ub4e4\uba74\uc11c \uc77c\ub82c\ub85c \ud3b4\uc9c0\uac8c \ub418\ub294 \uacfc\uc815\uc744 \uac70\uce58\uac8c \ub418\ub294\ub370 \uaf2d \uc774 \uacfc\uc815\uc744 \ucee4\uccd0\uc57c\ub9cc \ud558\ub294\uc9c0\uc694? Input\uc73c\ub85c \ubc1b\uace0 \ucee8\ubcfc\ub8e8\uc158 \ud544\ud130 \uc0ac\uc774\uc988\ub098, \ud480\ub9c1 \uc0ac\uc774\uc988\ub97c \ub9ce\uc774 \ud0a4\uc6cc\uc11c input size\ub97c \ud655\ud655 \uc904\uc774\uba74\uc740 \uc548\ub418\ub294\uc9c0?\n\n\n\n\n-> \uc720\uc6a9\ud558\uac8c \uc4f0\uc77c \uc218 \uc788\ub294 \uace0\ucc28\uc6d0 \uc815\ubcf4\ub97c \ucd94\ucd9c\ud558\uae30 \uc704\ud574 CNN\uad6c\uc131\uc758 \uc55e\ub2e8\uc5d0\ub294 \uc800\ucc28\uc6d0, \uc810\uc810 \uc911\uc5d0\uc11c \uace0\ucc28\uc6d0\uc73c\ub85c \ucd94\ucd9c\uc744 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\uc640\uac19\uc774 \uc720\uc6a9\ud55c \uace0\ucc28\uc6d0\uc744 \ubf51\uae30 \uc704\ud574\uc11c\ub294 \ud55c\ubc88\uc5d0 \uc601\uc0c1\uc0ac\uc774\uc988\ub97c \uc904\uc5ec\ubc84\ub9ac\uba74 \uc798 \ubf51\ud788\uc9c0 \ubabb\ud558\ub294 \ubb38\uc81c\uac00 \ubc1c\uc0dd\ud569\ub2c8\ub2e4. \uc544\ub798 \ub9c1\ud06c\ub97c \ud1b5\ud574 \ubcf4\uc2dc\uba74 \uc544\uc2dc\uaca0\uc9c0\ub9cc, \uacb0\uad6d \uc0ac\ub78c\uc5bc\uad74\uc774\ub77c\ub294 feature\ub97c \ubf51\uae30 \uc704\ud574 \ub2e8\uacc4\ubcc4\ub85c feature\ub4e4\uc744 \ubf51\ub294\uacfc\uc815\uc774 \uc788\ub294\uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.\nhttps://www.google.com/search?q=deep+learning+face+&tbm=isch&ved=2ahUKEwjxjazAlMbnAhWRG6YKHcgjB_sQ2-cCegQIABAA&oq=deep+learning+face+&gs_l=img.3..0j0i30l3j0i24l2j0i8i30l4.274192.276551..276821...2.0..1.189.1684.18j1......0....1..gws-wiz-img.....10..35i39j0i131j35i362i39.akvy1Pfq4qU&ei=xt1AXvGSMpG3mAXIx5zYDw&bih=928&biw=1805#imgrc=4Q9C-i666c9lgM\n\n\n\n\n3. \uc720\uba85\ud55c \ub124\ud2b8\uc6cc\ud06c \ubaa8\ub378\ub4e4 (AlexNet ...) \ub0b4\ubd80\ub97c \ubcf4\uba74 \uc5ec\ub7ec\uac1c\ub85c \uc313\uc5ec\uc9c4 \uce35\uc744 \ud655\uc778\ud560 \uc218 \uc788\ub294\ub370, \uce35\uc774 \uc774\ub807\uac8c \uc313\uc5ec\uc9c4 \uc774\uc720\uac19\uc740\uac8c \uc874\uc7ac\ud560\uae4c\uc694? ( \uadf8\ub0e5 \ub2e8\uc9c0 \ub9ce\uc740 \ub178\uac00\ub2e4\ub97c \ud588\ub294\ub370 \uc774\ub807\uac8c \uc313\ub294\uac8c \uc81c\uc77c \uc131\ub2a5\uc774 \uc88b\uc558\ub2e4\ub354\ub77c. \ub77c\ub358\uc9c0 ?)\n\n\n\n\n-> \uce35\uc744 \uae4a\uac8c \uc313\uc740 \uc774\uc720\ub294 \uc800\ucc28\uc6d0 \uc815\ubcf4\uc5d0\uc11c \uace0\ucc28\uc6d0 \uc815\ubcf4\ub97c \ucd94\ucd9c\ud558\uae30 \uc704\ud568\uc774\uace0, \uc774\ub97c \uc704\ud574 \uce35\uc744 \ub9ce\uc774 \uc313\uace0, \uc810\uc810 \uae4a\uc5b4\uc9c8\uc218\ub85d feature\ub97c \ub354 \ubf51\uac8c \ud569\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \uc608\uc804\uc5d0\ub294 \uae4a\uac8c\ub9cc \uc313\ub294\ub2e4\uace0 \uc88b\uc744\uae4c?\ub77c\uace0\ud574\uc11c \uae4a\uac8c\ub9cc \uc313\uc558\ub354\ub2c8 \uc131\uacfc\uac00 \uc88b\uc9c0 \ubabb\ud588\uc73c\ub098, ResNet\uc774\ub77c\ub294 \uc54c\uace0\ub9ac\uc998\uc774 \uae4a\uac8c \uc313\uc744\uc218\ub85d residual\uc744 \ub808\uc774\uc5b4\uac04\uc5d0 \uc798 \uc804\ub2ec\ub9cc \ud574\uc8fc\uba74 performance\uac00 \ub192\uc544\uc9c4\ub2e4\ub77c\ub294 \ub17c\ubb38\uc744 \uc4f0\uae30\ub3c4 \ud588\uc2b5\ub2c8\ub2e4.\n\uc544\ub798\ub9c1\ud06c \ucc38\uace0\ud574\uc8fc\uc138\uc694!\n\ub17c\ubb38\uc6d0\ubcf8: https://arxiv.org/abs/1512.03385\n\ud55c\uae00\uc124\uba85: https://blog.naver.com/sohyunst/221666285678\n\n\n\n\n4. \ub098\uc911\uc5d0 \uc601\uc0c1 \uc774\ubbf8\uc9c0\ub97c \uac00\uc9c0\uace0 deep learing\uacfc AI\uc5d0 \ud65c\uc6a9\ud558\ub824\uba74 \uad6c\uccb4\uc801\uc73c\ub85c \uc5b4\ub5bb\uac8c \ud574\uc57c \ud558\ub294\uc9c0, deep learning\uc744 \ud65c\uc6a9\ud558\ub294\ub370 \uc5b4\ub290 \uc815\ub3c4\ub97c \uc54c\uc544\uc57c \ud560\uae4c\uc694??\n\n\n\n\n-> \uc6b0\uc120 data, algorithm, GPU\uac00 \ud544\uc694\ud558\ub2e4\ub294\uac74 \uc54c\uace0 \uacc4\uc2dc\uc8e0?! data\ub294 labeling\ub41c (\uc815\ub2f5\uc774 \uc788\ub294) \ub370\uc774\ud130\ub97c \ub9d0\ud569\ub2c8\ub2e4!\n\uc6b0\uc120 \uc774 \uc138\uac1c\uac00 \ud544\uc218\uc694\uc18c\ub77c \ubcf4\uc2dc\uba74 \ub418\uace0, github\uc5d0 classification, detection, segmentation, \ub4f1\ub4f1\uc774 running\ub418\uac8c\ud558\ub294 \uc18c\uc2a4\ucf54\ub4dc\uac00 \uc788\uc2b5\ub2c8\ub2e4. \uc18c\uc2a4\ucf54\ub4dc\ub4e4\uc744 \ud6d1\uc5b4\ubd24\uc744 \ub54c \uc6b0\ub9ac\uc758 \ub370\uc774\ud130\uc5d0 \ub9de\uac8c \ub3cc\uc544\uac00\uac8c\ub9cc \uc18c\uc2a4\ucf54\ub4dc\ub4e4\uc774 \uc694\uad6c\ud558\ub294 \ub370\uc774\ud130\ud3ec\ub9f7\ub9cc \ud3ec\ub9f7\ud305\ud574\uc904 \uc218 \uc788\uc744\uc815\ub3c4\uc758 python \ubb38\ubc95\uc744 \uc0ac\uc6a9\ud560 \uc904 \uc544\uc2dc\uba74 \ub429\ub2c8\ub2e4.\n\n\n\n\n\uc608\ub97c \ub4e4\uc5b4, csv type\uc758 \ud30c\uc77c\ud615\ud0dc\ub85c detection algorithm\uc744 running\uc2dc\ud0a4\uac8c \ud558\ub294 \uc18c\uc2a4\ucf54\ub4dc\ub97c \uc0ac\uc6a9\ud558\uc2dc\uaca0\ub2e4 \ud558\uba74 \uc120\uc0dd\ub2d8\uc758 data\ub4e4\uc744 csv type\uc5d0 \ub9de\ucdb0 python \ucf54\ub4dc\ub4e4\ub85c \ub9cc\ub4e4\uae30\ub9cc \ud558\uba74 \uadf8 detection code\uac00 \ub3cc\uc544\uac11\ub2c8\ub2e4.\n\ucc98\uc74c\ubd80\ud130 \uacf5\ubd80\ud558\uace0 \uc811\uadfc\ud558\uae30\ubcf4\ub2e4, \uc608\uc81c\ud615\ud0dc\uc758 \uc18c\uc2a4\ucf54\ub4dc\ub4e4\uc744 \uad6c\uae00\ub9c1\ud574\uc11c \ud544\uc694\ud55c \uc2a4\ud0ac\ub4e4\uc744 \uc5bb\uc5b4\uac00\uc2dc\uba74 \ub420 \ub4ef \ud569\ub2c8\ub2e4.\n\n\n\n\n5. \uc544\uc0b0 \ubcd1\uc6d0\uc5d0\uc11c\ub294 \uc758\ub8cc \uc601\uc0c1\uc5d0 \ub300\ud55c deep learning \uc5f0\uad6c\ub97c \uc5b4\ub5bb\uac8c \ud558\uace0 \uc788\ub294\uc9c0\uc694?\n\n\n\n\n-> \uc800\ud76c\ub294 \ucca0\uc800\ud788 \uc758\ub8cc\uc9c4\uc758 unmet needs\uc5d0 \uc758\ud574 \uc5f0\uad6c\ub97c \uc2dc\uc791\ud569\ub2c8\ub2e4. \uc758\ub8cc\uc9c4\uc758 \uadf8 needs\ub97c \uacf5\ud559\uc790\ub4e4\uacfc discussion\ub4e4\uc744 \ud1b5\ud574 \uc11c\ub85c \uc774\ud574\ud558\uace0\ub098\uc11c IRB\ub97c \ud1b5\ud574 \ub370\uc774\ud130\uc0ac\uc6a9\uc5d0 \ub300\ud55c \uc2ec\uc758\ub97c \ubc1b\uac8c \ub418\uace0, \ud1b5\uacfc\ud558\uac8c \ub418\uba74 \uc5f0\uad6c\ubaa9\uc801\uc73c\ub85c \ud2b9\uc815\uc2dc\uae30, \ubaa9\uc801\uc5d0 \uc758\ud574 \uc758\ub8cc \ub370\uc774\ud130\ub97c \ud65c\uc6a9\ud560 \uc218 \uc788\uac8c \ub429\ub2c8\ub2e4.\n\uc758\ub8cc\uc9c4\ub4e4\ub3c4 \uaca9\uc8fc \uc5f4\ub9ac\ub294 \ud68c\uc758\uc5d0 \ud56d\uc0c1 \ucc38\uc5ec\ud558\uc5ec \uc801\uadf9\uc801\uc73c\ub85c \uc778\uacf5\uc9c0\ub2a5 \uc131\ub2a5\ub4e4\uc5d0 \ub300\ud55c discussion\uc744 \ud558\uba74\uc11c \uc11c\ub85c\uc758 feedback\uc744 \ud65c\ubc1c\ud788 \uc8fc\uace0\ubc1b\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\uacb0\uad6d\uc5d0\ub294 \uc758\ub8cc\uc9c4\ub4e4\ub3c4 workflow\uc5d0 \uac1c\uc120\uc2dc\ud0a4\uace0\uc790 unmet needs\ub97c \ud1b5\ud574 \uc5f0\uad6c\ub97c \ud558\uba74\uc11c \ub17c\ubb38\uc2e4\uc801\uc744 \ub05d\uc73c\ub85c \uc5f0\uad6c\ub97c \ub9c8\ubb34\ub9ac\ud558\ub294 \uc870\uae08\uc758 \uad34\ub9ac\uac10(?) \uc744 \uac16\uac8c\ud558\ub294 \uba87\uba87 \uc8fc\uc81c\ub4e4\ub3c4 \uc788\uae34 \ud558\uc9c0\ub9cc, \uc758\ub300\uc0dd\ub4e4\uc758 \uad50\uc721\ubaa9\uc801\uc774\ub098 \uc0ac\uc5c5\ud654, \ud639\uc740 \uae30\uc220\uc774\uc804\ub4f1\uc73c\ub85c \uacb0\uacfc\ub4e4\uc744 \ub0b4\uace0 \uc788\ub2e4\uace0 \ubcf4\uc2dc\uba74 \ub429\ub2c8\ub2e4.\n\n\n\n\n6. Dropout\uc744 \ub123\uc73c\uba74 \ud574\ub2f9 \ud788\ub4e0 \ub808\uc774\uc5b4 \uc911 \uc77c\ubd80 \ub178\ub4dc\uac00 \uc774\uc6a9\ub418\uc9c0 \uc54a\uc73c\ub2c8 \uc5f0\uc0b0\uc18d\ub3c4\uac00 \uc62c\ub77c\uac08\uaebc\ub77c \uc0dd\uac01\ud588\ub294\ub370, \uc624\ud788\ub824 \ub298\uc5b4\ub098\ub294 \uac83 \uac19\uc740\ub370 \uc65c \uadf8\ub7f4\uae4c\uc694?\n\n\n\n\n-> \uac1c\ub150\uc0c1 \ub178\ub4dc\ub97c off\uc2dc\ud0a4\uae30\ub9cc \ud558\uae30 \ub54c\ubb38\uc5d0 \uc26c\uc6cc\ubcf4\uc774\uace0 \ud559\uc2b5\ud558\uae30 \uc704\ud55c weight\uac00 \uc99d\uac00\ud558\ub294 \uac83\uc740 \uc544\ub2d9\ub2c8\ub2e4\ub9cc,\nrandomness\uc5d0 \uc758\ud574 off\ub418\ub294 \ub178\ub4dc\ub4e4\ub3c4 \ub9e4\ubc88 \ubc14\ub00c\ub294 \ub4f1\uc758 \uc18c\uc2a4\ucf54\ub4dc\uc0c1 \uad6c\ud604\ub2e8\uc758 \ucd94\uac00\uc801\uc778 computation cost\ub4e4\uc774 \ud544\uc694\ud560 \uac83\uc73c\ub85c \ubcf4\uc785\ub2c8\ub2e4.\n\uadf8\ub798\uc11c dropout\uc774 \uc2e4\uc81c \ub3d9\uc791\ud558\uae30 \uc704\ud55c \uc18c\uc2a4\ucf54\ub4dc\ub97c \ucc3e\uc544\ubd24\ub294\ub370 \uc18c\uc2a4\ub4dc\uac00 100\uc904\uc815\ub3c4 \ub418\ub354\uad70\uc694!\nhttps://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/ops/nn_ops.py#L4232-L4317\n\n\n\n\n7. CNN\uc5d0\uc11c \uac01 \ud53d\uc140\uac12\ub4e4\uc758 fully connected network \ub85c \uad6c\uc131\ud558\uc9c0 \uc54a\uace0 \uc55e\ub2e8\uc5d0 convolution \uacfc\uc815\uc744 \uac70\uce58\ub294 \uadfc\ubcf8\uc801\uc778 \uc774\uc720\uac00 \ubb34\uc5c7\uc778\uac00\uc694? convolution \uacfc\uc815\uc744 \ud1b5\ud574 \uc5bb\ub294 \uc774\uc810\uc774 \ubb34\uc5c7\uc778\uac00\uc694?\n\n\n\n\n-> Convolutional neural network\ub97c \ud1b5\ud574 \uacf5\uac04\uc815\ubcf4\ub85c\ubd80\ud130 \ub2e4\uc591\ud55c feature\ub97c \ucd94\ucd9c\ud560 \uc218 \uc788\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4. \uacf5\uac04\uc815\ubcf4\ub97c \uc5c6\uc560\uba74\uc11c \ucc98\ub9ac\ud558\ub294 fully connected layer\uc774 \ub9e8 \uc55e\uc5d0 \ubc30\uce58\ub41c \ucc44\ub85c feature\ub97c \ucd94\ucd9c\ud558\uac8c \ub418\ubc84\ub9ac\uba74 \uc601\uc0c1\uc5d0\uc11c \uacf5\uac04\uc0c1\uc5d0\uc11c \ub098\ud0c0\ub0a0 \uc218 \uc788\ub294 \ud615\ud0dc (\ub208, \ucf54, \uc785, \ub4f1\ub4f1)\ub97c \ub098\ud0c0\ub0b4\ub294 \uc815\ubcf4\ub4e4\uc744 \ucd94\ucd9c\ud560 \uc218 \uc5c6\ub294 \uac83\uc774\uc8e0.\n\n```\narXiv.orgarXiv.org\nDeep Residual Learning for Image Recognition\nDeeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We...\ntensorflow/python/ops/nn_ops.py:4232-4317\n```\n```python\n@tf_export(\"nn.dropout\", v1=[])\ndef dropout_v2(x, rate, noise_shape=None, seed=None, name=None):\n  \"\"\"Computes dropout.\n\n  With probability `rate`, drops elements of `x`. Input that are kept are\n  scaled up by `1 / (1 - rate)`, otherwise outputs `0`.  The scaling is so that\n  the expected sum is unchanged.\n\n  **Note:** The behavior of dropout has changed between TensorFlow 1.x and 2.x.\n  When converting 1.x code, please use named arguments to ensure behavior stays\n  consistent.\n\n  By default, each element is kept or dropped independently.  If `noise_shape`\n  is specified, it must be\n  [broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n  to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`\n  will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`\n  and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be\n  kept independently and each row and column will be kept or not kept together.\n\n  Args:\n    x: A floating point tensor.\n    rate: A scalar `Tensor` with the same type as x. The probability\n      that each element is dropped. For example, setting rate=0.1 would drop\n      10% of input elements.\n    noise_shape: A 1-D `Tensor` of type `int32`, representing the\n      shape for randomly generated keep/drop flags.\n    seed: A Python integer. Used to create random seeds. See\n      `tf.compat.v1.set_random_seed` for behavior.\n    name: A name for this operation (optional).\n\n  Returns:\n    A Tensor of the same shape of `x`.\n\n  Raises:\n    ValueError: If `rate` is not in `(0, 1]` or if `x` is not a floating point\n      tensor.\n  \"\"\"\n  with ops.name_scope(name, \"dropout\", [x]) as name:\n    x = ops.convert_to_tensor(x, name=\"x\")\n    if not x.dtype.is_floating:\n      raise ValueError(\"x has to be a floating point tensor since it's going to\"\n                       \" be scaled. Got a %s tensor instead.\" % x.dtype)\n    if isinstance(rate, numbers.Real):\n      if not (rate >= 0 and rate < 1):\n        raise ValueError(\"rate must be a scalar tensor or a float in the \"\n                         \"range [0, 1), got %g\" % rate)\n      if rate > 0.5:\n        logging.log_first_n(\n            logging.WARN, \"Large dropout rate: %g (>0.5). In TensorFlow \"\n            \"2.x, dropout() uses dropout rate instead of keep_prob. \"\n            \"Please ensure that this is intended.\", 5, rate)\n\n    # Early return if nothing needs to be dropped.\n    if isinstance(rate, numbers.Real) and rate == 0:\n      return x\n    if context.executing_eagerly():\n      if isinstance(rate, ops.EagerTensor):\n        if rate.numpy() == 0:\n          return x\n    else:\n      rate = ops.convert_to_tensor(\n          rate, dtype=x.dtype, name=\"rate\")\n      rate.get_shape().assert_has_rank(0)\n\n      # Do nothing if we know rate == 0\n      if tensor_util.constant_value(rate) == 0:\n        return x\n\n    noise_shape = _get_noise_shape(x, noise_shape)\n    # Sample a uniform distribution on [0.0, 1.0) and select values larger than\n    # rate.\n    #\n    # NOTE: Random uniform actually can only generate 2^23 floats on [1.0, 2.0)\n    # and subtract 1.0.\n    random_tensor = random_ops.random_uniform(\n        noise_shape, seed=seed, dtype=x.dtype)\n    keep_prob = 1 - rate\n    scale = 1 / keep_prob\n    # NOTE: if (1.0 + rate) - 1 is equal to rate, then we want to consider that\n    # float to be selected, hence we use a >= comparison.\n    keep_mask = random_tensor >= rate\n    ret = x * scale * math_ops.cast(keep_mask, x.dtype)\n    if not context.executing_eagerly():\n      ret.set_shape(x.get_shape())\n    return ret\n```\n<https://github.com/tensorflow/tensorflow|tensorflow/tensorflow>tensorflow/tensorflow | Added by GitHub\n",
            "readme_url": "https://github.com/lkeonwoo94/DL_cv-mdt_NVIDIA_Cert_Course_StudyPI",
            "frameworks": [
                "Caffe",
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Deep Residual Learning for Image Recognition",
            "arxiv": "1512.03385",
            "year": 2015,
            "url": "http://arxiv.org/abs/1512.03385v1",
            "abstract": "Deeper neural networks are more difficult to train. We present a residual\nlearning framework to ease the training of networks that are substantially\ndeeper than those used previously. We explicitly reformulate the layers as\nlearning residual functions with reference to the layer inputs, instead of\nlearning unreferenced functions. We provide comprehensive empirical evidence\nshowing that these residual networks are easier to optimize, and can gain\naccuracy from considerably increased depth. On the ImageNet dataset we evaluate\nresidual nets with a depth of up to 152 layers---8x deeper than VGG nets but\nstill having lower complexity. An ensemble of these residual nets achieves\n3.57% error on the ImageNet test set. This result won the 1st place on the\nILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100\nand 1000 layers.\n  The depth of representations is of central importance for many visual\nrecognition tasks. Solely due to our extremely deep representations, we obtain\na 28% relative improvement on the COCO object detection dataset. Deep residual\nnets are foundations of our submissions to ILSVRC & COCO 2015 competitions,\nwhere we also won the 1st places on the tasks of ImageNet detection, ImageNet\nlocalization, COCO detection, and COCO segmentation.",
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9863111724826035,
        "task": "Image Classification",
        "task_prob": 0.6267302397878395
    },
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            },
            {
                "name": "CIFAR-10"
            },
            {
                "name": "ILSVRC 2015"
            },
            {
                "name": "COCO"
            },
            {
                "name": "ImageNet Detection"
            }
        ]
    }
}
{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Tacotron",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "keithito",
                "owner_type": "User",
                "name": "tacotron",
                "url": "https://github.com/keithito/tacotron",
                "stars": 2621,
                "pushed_at": "2022-01-24 16:20:14+00:00",
                "created_at": "2017-07-08 17:03:31+00:00",
                "language": "Python",
                "description": "A TensorFlow implementation of Google's Tacotron speech synthesis with pre-trained model (unofficial)",
                "license": "MIT License",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "7e377245c354b32b905a885081a3f9713099691e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/blob/master/.gitignore"
                    }
                },
                "size": 45
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "4ad4ed1d5e34d95c8380768ec16405d789cc6de4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/blob/master/LICENSE"
                    }
                },
                "size": 1053
            },
            {
                "type": "code",
                "name": "TRAINING_DATA.md",
                "sha": "f1ac3cb6de42c84475f4274e513b2a5764efe8fb",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/blob/master/TRAINING_DATA.md"
                    }
                },
                "size": 2786
            },
            {
                "type": "code",
                "name": "datasets",
                "sha": "8aba6389a86057a8ff95a201a794afa5ef310bdb",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/tree/master/datasets"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "demo_server.py",
                "sha": "decea2366341a72b8a714b5c1803d9aea14d4c62",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/blob/master/demo_server.py"
                    }
                },
                "size": 3045
            },
            {
                "type": "code",
                "name": "eval.py",
                "sha": "8f87aba9917435b620ba360dde86dbc8cd1a37ba",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/blob/master/eval.py"
                    }
                },
                "size": 1860
            },
            {
                "type": "code",
                "name": "hparams.py",
                "sha": "05ae82a351e3bc27375040d5d8fc95fda9ea8bf3",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/blob/master/hparams.py"
                    }
                },
                "size": 1185
            },
            {
                "type": "code",
                "name": "models",
                "sha": "1c9ead12656108f13fec22ad8921f6e5c36ac7d2",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/tree/master/models"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "preprocess.py",
                "sha": "fddb0b8da2b35f1a38f0165ba1952a366f47ae0d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/blob/master/preprocess.py"
                    }
                },
                "size": 1795
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "7588bb2335254780975a283f7432c27dd7742b50",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/blob/master/requirements.txt"
                    }
                },
                "size": 300
            },
            {
                "type": "code",
                "name": "synthesizer.py",
                "sha": "ded61c8a6ceba1c1479f1fd8b83dc0c9a8f0fd1b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/blob/master/synthesizer.py"
                    }
                },
                "size": 1435
            },
            {
                "type": "code",
                "name": "tests",
                "sha": "b6b66335b8b3f77cbe9c22e962368f20a0c2fc2b",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/tree/master/tests"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "text",
                "sha": "7c2d30efe83eed090b61d60fa3dde5557d529c35",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/tree/master/text"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "033860e45658c9ca01dd7294c1bd564fd0818919",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/blob/master/train.py"
                    }
                },
                "size": 6242
            },
            {
                "type": "code",
                "name": "util",
                "sha": "ae45d1fd23cec713bdac4e9920a25a35ef883cb8",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/keithito/tacotron/tree/master/util"
                    }
                },
                "num_files": 4
            }
        ]
    },
    "authors": [
        {
            "name": "Keith Ito",
            "github_id": "keithito"
        },
        {
            "name": "Yunchao He",
            "github_id": "candlewill"
        },
        {
            "name": "Yuchao Zhang",
            "github_id": "npuichigo"
        },
        {
            "name": "Dar\u00edo Here\u00f1\u00fa",
            "github_id": "kant"
        },
        {
            "name": "Ioannis (Yannis) Kalfas",
            "email": "kalfasyan@gmail.com",
            "github_id": "kalfasyan"
        },
        {
            "name": "Matthew Goldey",
            "email": "matthew.goldey@gmail.com",
            "github_id": "mgoldey"
        },
        {
            "name": "Pawe\u0142 Kope\u0107",
            "email": "pawelkopec10@gmail.com",
            "github_id": "pawelkopec"
        },
        {
            "name": "Ryuichi Yamamoto",
            "email": "zryuichi@gmail.com",
            "github_id": "r9y9"
        },
        {
            "name": "Scott Stevenson",
            "email": "scott@stevenson.io",
            "github_id": "srstevenson"
        },
        {
            "name": "jyegerlehner",
            "github_id": "jyegerlehner"
        }
    ],
    "tags": [
        "tacotron",
        "tensorflow",
        "speech-synthesis",
        "python",
        "machine-learning",
        "tts"
    ],
    "description": "A TensorFlow implementation of Google's Tacotron speech synthesis with pre-trained model (unofficial)",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/keithito/tacotron",
            "stars": 2621,
            "issues": true,
            "readme": "# Tacotron\n\nAn implementation of Tacotron speech synthesis in TensorFlow.\n\n\n### Audio Samples\n\n  * **[Audio Samples](https://keithito.github.io/audio-samples/)** from models trained using this repo.\n    * The first set was trained for 441K steps on the [LJ Speech Dataset](https://keithito.com/LJ-Speech-Dataset/)\n      * Speech started to become intelligible around 20K steps.\n    * The second set was trained by [@MXGray](https://github.com/MXGray) for 140K steps on the [Nancy Corpus](http://www.cstr.ed.ac.uk/projects/blizzard/2011/lessac_blizzard2011/).\n\n\n### Recent Updates\n\n1. @npuichigo [fixed](https://github.com/keithito/tacotron/pull/205) a bug where dropout was not being applied in the prenet.\n\n2. @begeekmyfriend created a [fork](https://github.com/begeekmyfriend/tacotron) that adds location-sensitive attention and the stop token from the [Tacotron 2](https://arxiv.org/abs/1712.05884) paper. This can greatly reduce the amount of data required to train a model.\n\n\n## Background\n\nIn April 2017, Google published a paper, [Tacotron: Towards End-to-End Speech Synthesis](https://arxiv.org/pdf/1703.10135.pdf),\nwhere they present a neural text-to-speech model that learns to synthesize speech directly from\n(text, audio) pairs. However, they didn't release their source code or training data. This is an\nindependent attempt to provide an open-source implementation of the model described in their paper.\n\nThe quality isn't as good as Google's demo yet, but hopefully it will get there someday :-).\nPull requests are welcome!\n\n\n\n## Quick Start\n\n### Installing dependencies\n\n1. Install Python 3.\n\n2. Install the latest version of [TensorFlow](https://www.tensorflow.org/install/) for your platform. For better\n   performance, install with GPU support if it's available. This code works with TensorFlow 1.3 and later.\n\n3. Install requirements:\n   ```\n   pip install -r requirements.txt\n   ```\n\n\n### Using a pre-trained model\n\n1. **Download and unpack a model**:\n   ```\n   curl https://data.keithito.com/data/speech/tacotron-20180906.tar.gz | tar xzC /tmp\n   ```\n\n2. **Run the demo server**:\n   ```\n   python3 demo_server.py --checkpoint /tmp/tacotron-20180906/model.ckpt\n   ```\n\n3. **Point your browser at localhost:9000**\n   * Type what you want to synthesize\n\n\n\n### Training\n\n*Note: you need at least 40GB of free disk space to train a model.*\n\n1. **Download a speech dataset.**\n\n   The following are supported out of the box:\n    * [LJ Speech](https://keithito.com/LJ-Speech-Dataset/) (Public Domain)\n    * [Blizzard 2012](http://www.cstr.ed.ac.uk/projects/blizzard/2012/phase_one) (Creative Commons Attribution Share-Alike)\n\n   You can use other datasets if you convert them to the right format. See [TRAINING_DATA.md](TRAINING_DATA.md) for more info.\n\n\n2. **Unpack the dataset into `~/tacotron`**\n\n   After unpacking, your tree should look like this for LJ Speech:\n   ```\n   tacotron\n     |- LJSpeech-1.1\n         |- metadata.csv\n         |- wavs\n   ```\n\n   or like this for Blizzard 2012:\n   ```\n   tacotron\n     |- Blizzard2012\n         |- ATrampAbroad\n         |   |- sentence_index.txt\n         |   |- lab\n         |   |- wav\n         |- TheManThatCorruptedHadleyburg\n             |- sentence_index.txt\n             |- lab\n             |- wav\n   ```\n\n3. **Preprocess the data**\n   ```\n   python3 preprocess.py --dataset ljspeech\n   ```\n     * Use `--dataset blizzard` for Blizzard data\n\n4. **Train a model**\n   ```\n   python3 train.py\n   ```\n\n   Tunable hyperparameters are found in [hparams.py](hparams.py). You can adjust these at the command\n   line using the `--hparams` flag, for example `--hparams=\"batch_size=16,outputs_per_step=2\"`.\n   Hyperparameters should generally be set to the same values at both training and eval time.\n   The default hyperparameters are recommended for LJ Speech and other English-language data.\n   See [TRAINING_DATA.md](TRAINING_DATA.md) for other languages.\n\n\n5. **Monitor with Tensorboard** (optional)\n   ```\n   tensorboard --logdir ~/tacotron/logs-tacotron\n   ```\n\n   The trainer dumps audio and alignments every 1000 steps. You can find these in\n   `~/tacotron/logs-tacotron`.\n\n6. **Synthesize from a checkpoint**\n   ```\n   python3 demo_server.py --checkpoint ~/tacotron/logs-tacotron/model.ckpt-185000\n   ```\n   Replace \"185000\" with the checkpoint number that you want to use, then open a browser\n   to `localhost:9000` and type what you want to speak. Alternately, you can\n   run [eval.py](eval.py) at the command line:\n   ```\n   python3 eval.py --checkpoint ~/tacotron/logs-tacotron/model.ckpt-185000\n   ```\n   If you set the `--hparams` flag when training, set the same value here.\n\n\n## Notes and Common Issues\n\n  * [TCMalloc](http://goog-perftools.sourceforge.net/doc/tcmalloc.html) seems to improve\n    training speed and avoids occasional slowdowns seen with the default allocator. You\n    can enable it by installing it and setting `LD_PRELOAD=/usr/lib/libtcmalloc.so`. With TCMalloc,\n    you can get around 1.1 sec/step on a GTX 1080Ti.\n\n  * You can train with [CMUDict](http://www.speech.cs.cmu.edu/cgi-bin/cmudict) by downloading the\n    dictionary to ~/tacotron/training and then passing the flag `--hparams=\"use_cmudict=True\"` to\n    train.py. This will allow you to pass ARPAbet phonemes enclosed in curly braces at eval\n    time to force a particular pronunciation, e.g. `Turn left on {HH AW1 S S T AH0 N} Street.`\n\n  * If you pass a Slack incoming webhook URL as the `--slack_url` flag to train.py, it will send\n    you progress updates every 1000 steps.\n\n  * Occasionally, you may see a spike in loss and the model will forget how to attend (the\n    alignments will no longer make sense). Although it will recover eventually, it may\n    save time to restart at a checkpoint prior to the spike by passing the\n    `--restore_step=150000` flag to train.py (replacing 150000 with a step number prior to the\n    spike). **Update**: a recent [fix](https://github.com/keithito/tacotron/pull/7) to gradient\n    clipping by @candlewill may have fixed this.\n    \n  * During eval and training, audio length is limited to `max_iters * outputs_per_step * frame_shift_ms`\n    milliseconds. With the defaults (max_iters=200, outputs_per_step=5, frame_shift_ms=12.5), this is\n    12.5 seconds.\n    \n    If your training examples are longer, you will see an error like this:\n    `Incompatible shapes: [32,1340,80] vs. [32,1000,80]`\n    \n    To fix this, you can set a larger value of `max_iters` by passing `--hparams=\"max_iters=300\"` to\n    train.py (replace \"300\" with a value based on how long your audio is and the formula above).\n    \n  * Here is the expected loss curve when training on LJ Speech with the default hyperparameters:\n    ![Loss curve](https://user-images.githubusercontent.com/1945356/36077599-c0513e4a-0f21-11e8-8525-07347847720c.png)\n\n\n## Other Implementations\n  * By Alex Barron: https://github.com/barronalex/Tacotron\n  * By Kyubyong Park: https://github.com/Kyubyong/tacotron\n",
            "readme_url": "https://github.com/keithito/tacotron",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions",
            "arxiv": "1712.05884",
            "year": 2017,
            "url": "http://arxiv.org/abs/1712.05884v2",
            "abstract": "This paper describes Tacotron 2, a neural network architecture for speech\nsynthesis directly from text. The system is composed of a recurrent\nsequence-to-sequence feature prediction network that maps character embeddings\nto mel-scale spectrograms, followed by a modified WaveNet model acting as a\nvocoder to synthesize timedomain waveforms from those spectrograms. Our model\nachieves a mean opinion score (MOS) of $4.53$ comparable to a MOS of $4.58$ for\nprofessionally recorded speech. To validate our design choices, we present\nablation studies of key components of our system and evaluate the impact of\nusing mel spectrograms as the input to WaveNet instead of linguistic, duration,\nand $F_0$ features. We further demonstrate that using a compact acoustic\nintermediate representation enables significant simplification of the WaveNet\narchitecture.",
            "authors": [
                "Jonathan Shen",
                "Ruoming Pang",
                "Ron J. Weiss",
                "Mike Schuster",
                "Navdeep Jaitly",
                "Zongheng Yang",
                "Zhifeng Chen",
                "Yu Zhang",
                "Yuxuan Wang",
                "RJ Skerry-Ryan",
                "Rif A. Saurous",
                "Yannis Agiomyrgiannakis",
                "Yonghui Wu"
            ]
        },
        {
            "title": "Tacotron: Towards End-to-End Speech Synthesis",
            "arxiv": "1703.10135",
            "year": 2017,
            "url": "http://arxiv.org/abs/1703.10135v2",
            "abstract": "A text-to-speech synthesis system typically consists of multiple stages, such\nas a text analysis frontend, an acoustic model and an audio synthesis module.\nBuilding these components often requires extensive domain expertise and may\ncontain brittle design choices. In this paper, we present Tacotron, an\nend-to-end generative text-to-speech model that synthesizes speech directly\nfrom characters. Given <text, audio> pairs, the model can be trained completely\nfrom scratch with random initialization. We present several key techniques to\nmake the sequence-to-sequence framework perform well for this challenging task.\nTacotron achieves a 3.82 subjective 5-scale mean opinion score on US English,\noutperforming a production parametric system in terms of naturalness. In\naddition, since Tacotron generates speech at the frame level, it's\nsubstantially faster than sample-level autoregressive methods.",
            "authors": [
                "Yuxuan Wang",
                "RJ Skerry-Ryan",
                "Daisy Stanton",
                "Yonghui Wu",
                "Ron J. Weiss",
                "Navdeep Jaitly",
                "Zongheng Yang",
                "Ying Xiao",
                "Zhifeng Chen",
                "Samy Bengio",
                "Quoc Le",
                "Yannis Agiomyrgiannakis",
                "Rob Clark",
                "Rif A. Saurous"
            ]
        },
        {
            "title": "LJ Speech",
            "url": "https://keithito.com/LJ-Speech-Dataset/"
        },
        {
            "title": "Blizzard 2012",
            "url": "http://www.cstr.ed.ac.uk/projects/blizzard/2012/phase_one"
        },
        {
            "title": "TCMalloc",
            "url": "http://goog-perftools.sourceforge.net/doc/tcmalloc.html"
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "LJ Speech Dataset",
                "connection": {
                    "name": "url",
                    "source": {
                        "url": "https://keithito.com/LJ-Speech-Dataset/"
                    }
                }
            },
            {
                "name": "Nancy Corpus",
                "connection": {
                    "name": "url",
                    "source": {
                        "url": "http://www.cstr.ed.ac.uk/projects/blizzard/2011/lessac_blizzard2011/"
                    }
                }
            }
        ]
    },
    "domain": {
        "domain_type": "Speech",
        "domain_prob": 0.9915455761684968
    }
}
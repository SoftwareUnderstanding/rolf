{
    "visibility": {
        "visibility": "public",
        "license": "GNU General Public License v3.0"
    },
    "name": "Based on A clean and readable Pytorch implementation of CycleGAN (https://arxiv.org/abs/1703.10593)",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "uzielroy",
                "owner_type": "User",
                "name": "CUT",
                "url": "https://github.com/uzielroy/CUT",
                "stars": 0,
                "pushed_at": "2021-07-23 12:26:33+00:00",
                "created_at": "2021-06-30 10:33:50+00:00",
                "language": "Python",
                "license": "GNU General Public License v3.0",
                "frameworks": [
                    "scikit-learn",
                    "TensorFlow",
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "99b09f67a556402f7d3ed398c8020339f92b0894",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/uzielroy/CUT/blob/master/.gitignore"
                    }
                },
                "size": 793
            },
            {
                "type": "code",
                "name": ".gitmodules",
                "sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/uzielroy/CUT/blob/master/.gitmodules"
                    }
                },
                "size": 0
            },
            {
                "type": "code",
                "name": "DiffAugment_pytorch.py",
                "sha": "8b2064f2562f4348404251c183315ac7b0fd9f74",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/uzielroy/CUT/blob/master/DiffAugment_pytorch.py"
                    }
                },
                "size": 3038
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "94a9ed024d3859793618152ea559a168bbcbb5e2",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/uzielroy/CUT/blob/master/LICENSE"
                    }
                },
                "size": 35147
            },
            {
                "type": "code",
                "name": "datasets.py",
                "sha": "cb171e57249776cc739fbb7b46cbf0cb2ec8b71f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/uzielroy/CUT/blob/master/datasets.py"
                    }
                },
                "size": 6856
            },
            {
                "type": "code",
                "name": "kaggle",
                "sha": "fdb48660ec596aeee245fb28b0353e3f9c533da9",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/uzielroy/CUT/tree/master/kaggle"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "models.py",
                "sha": "b94e48933aab6da2d616e724e8ee56baa521ba0f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/uzielroy/CUT/blob/master/models.py"
                    }
                },
                "size": 3232
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "6762fe337b087ac8ddf7cc6416aedd6da55c99ee",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/uzielroy/CUT/blob/master/requirements.txt"
                    }
                },
                "size": 148
            },
            {
                "type": "code",
                "name": "test.py",
                "sha": "2395a8b4bd1c43ce720f87dd3ef52e52c166bace",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/uzielroy/CUT/blob/master/test.py"
                    }
                },
                "size": 3315
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "029a7f0c9e62662807b512488a4b7529b65b2726",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/uzielroy/CUT/blob/master/train.py"
                    }
                },
                "size": 7762
            },
            {
                "type": "code",
                "name": "utils.py",
                "sha": "02d34dd2caa38f3683a211e1d4e17d46f535eb9d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/uzielroy/CUT/blob/master/utils.py"
                    }
                },
                "size": 6807
            }
        ]
    },
    "authors": [
        {
            "name": "taesungp",
            "github_id": "taesungp"
        },
        {
            "name": "Jun-Yan Zhu",
            "github_id": "junyanz"
        },
        {
            "name": "uzielroy",
            "github_id": "uzielroy"
        }
    ],
    "tags": [],
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/uzielroy/CUT",
            "stars": 0,
            "issues": true,
            "readme": "### Based on A clean and readable Pytorch implementation of CycleGAN (https://arxiv.org/abs/1703.10593)\n\nYou can run a training session on 30 Monet images using the following Jupiter notebook:\n\nhttps://drive.google.com/file/d/1T4c3eX4un60XGudMnvktL4pSs691JO2A/view?usp=sharing\nIts recommended that you mount your google drive for easier access to the checkpoint at the end of the training.\nKaggle dataset will be downloaded and saved.\nThe selected 30 Monet images (done by choosing the farthest 30 points, after dimensionality reduction) will be saved.\n\n### Evaluation notebook:\nhttps://drive.google.com/file/d/1QxWmf7VrWMstAG9p80qslF2nmzCc-5yx/view?usp=sharing\n\n\nTrained for around 20 hours.\nYou can view a sample of 30 style transfer pairs and the training graphs (from Tensorboard).\n",
            "readme_url": "https://github.com/uzielroy/CUT",
            "frameworks": [
                "scikit-learn",
                "TensorFlow",
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks",
            "arxiv": "1703.10593",
            "year": 2017,
            "url": "http://arxiv.org/abs/1703.10593v7",
            "abstract": "Image-to-image translation is a class of vision and graphics problems where\nthe goal is to learn the mapping between an input image and an output image\nusing a training set of aligned image pairs. However, for many tasks, paired\ntraining data will not be available. We present an approach for learning to\ntranslate an image from a source domain $X$ to a target domain $Y$ in the\nabsence of paired examples. Our goal is to learn a mapping $G: X \\rightarrow Y$\nsuch that the distribution of images from $G(X)$ is indistinguishable from the\ndistribution $Y$ using an adversarial loss. Because this mapping is highly\nunder-constrained, we couple it with an inverse mapping $F: Y \\rightarrow X$\nand introduce a cycle consistency loss to push $F(G(X)) \\approx X$ (and vice\nversa). Qualitative results are presented on several tasks where paired\ntraining data does not exist, including collection style transfer, object\ntransfiguration, season transfer, photo enhancement, etc. Quantitative\ncomparisons against several prior methods demonstrate the superiority of our\napproach.",
            "authors": [
                "Jun-Yan Zhu",
                "Taesung Park",
                "Phillip Isola",
                "Alexei A. Efros"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9968757332340478,
        "task": "Image-to-Image Translation",
        "task_prob": 0.9563655389356344
    }
}
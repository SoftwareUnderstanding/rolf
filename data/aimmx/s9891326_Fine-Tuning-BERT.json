{
    "visibility": {
        "visibility": "public"
    },
    "name": "OpView\u60c5\u7dd2\u8a13\u7df4\u5de5\u5177",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "s9891326",
                "owner_type": "User",
                "name": "Fine-Tuning-BERT",
                "url": "https://github.com/s9891326/Fine-Tuning-BERT",
                "stars": 1,
                "pushed_at": "2021-05-03 11:45:45+00:00",
                "created_at": "2021-01-17 08:20:14+00:00",
                "language": "Python",
                "frameworks": [
                    "scikit-learn",
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".dockerignore",
                "sha": "794c3a7fed9a411850a734c63219673768500845",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/s9891326/Fine-Tuning-BERT/blob/main/.dockerignore"
                    }
                },
                "size": 91
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "b14aca79a2b38c90fafd47f7b1fdfc9273cf0348",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/s9891326/Fine-Tuning-BERT/blob/main/.gitignore"
                    }
                },
                "size": 1479
            },
            {
                "type": "code",
                "name": "Makefile",
                "sha": "b7b95001be43146187d47408685e9f6dbdb4bf21",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/s9891326/Fine-Tuning-BERT/blob/main/Makefile"
                    }
                },
                "size": 2745
            },
            {
                "type": "code",
                "name": "bin",
                "sha": "4e89d06284e87b6714a6a2cc047a5f67c2ee43d3",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/s9891326/Fine-Tuning-BERT/tree/main/bin"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "core",
                "sha": "13ab58723f524dd13522ff9b398f340a631accd3",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/s9891326/Fine-Tuning-BERT/tree/main/core"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "datasets",
                "sha": "37156e87763e2c928647d801f23e2b45f63b0539",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/s9891326/Fine-Tuning-BERT/tree/main/datasets"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "definitions.py",
                "sha": "20d8e3e5d0ab11cd7a4618af81261ff8b8b48197",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/s9891326/Fine-Tuning-BERT/blob/main/definitions.py"
                    }
                },
                "size": 236
            },
            {
                "type": "code",
                "name": "model_structure.png",
                "sha": "b64b61dba2b4f1d53e808934e115d4861a9dc2bf",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/s9891326/Fine-Tuning-BERT/blob/main/model_structure.png"
                    }
                },
                "size": 292788
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "b8d22bfaaf6572cdb0b4c7e9a38f2a60efb076a7",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/s9891326/Fine-Tuning-BERT/blob/main/requirements.txt"
                    }
                },
                "size": 212
            },
            {
                "type": "code",
                "name": "serving",
                "sha": "c3e8b4ecfe9b0444449f91f9af1d06822513daff",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/s9891326/Fine-Tuning-BERT/tree/main/serving"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "utils",
                "sha": "dea8ca81b913922ce261de05ced4a366bb16226c",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/s9891326/Fine-Tuning-BERT/tree/main/utils"
                    }
                },
                "num_files": 3
            }
        ]
    },
    "trained_model": {
        "binaries": [
            {
                "type": "binary",
                "name": "Dockerfile",
                "sha": "2b36de4fd6a36bd2f8b369f56eaa8668645c5c2a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/s9891326/Fine-Tuning-BERT/blob/main/Dockerfile"
                    }
                },
                "size": 213
            }
        ]
    },
    "authors": [
        {
            "name": "s9891326",
            "github_id": "s9891326"
        }
    ],
    "tags": [],
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/s9891326/Fine-Tuning-BERT",
            "stars": 1,
            "issues": true,
            "readme": "# OpView\u60c5\u7dd2\u8a13\u7df4\u5de5\u5177\n\u672c\u5c08\u6848\u70ba\u91dd\u5c0dOpView\u8cc7\u6599\u5167\u5bb9\uff0c\u9032\u884c\u60c5\u7dd2\u5206\u6790(Fine-Tuning BERT)\uff0c\u4e26\u63d0\u4f9bMakefile\u8f14\u52a9\u8a13\u7df4\u3002\n\n## outline\n- [\u76ee\u7684](#\u76ee\u7684)\n- [\u9700\u6c42](#\u9700\u6c42)\n- [Requirements](#requirements)\n- [\u60c5\u7dd2\u5c0d\u7167\u8868](#\u60c5\u7dd2\u5c0d\u7167\u8868)\n- [\u8f38\u5165\u8cc7\u6599\u7bc4\u4f8b](#\u8f38\u5165\u8cc7\u6599\u7bc4\u4f8b)\n- [\u8f38\u51fa\u8cc7\u6599\u683c\u5f0f](#\u8f38\u51fa\u8cc7\u6599\u683c\u5f0f)\n- [Quick start](#quick-start)\n- [\u6a21\u578b\u8aaa\u660e](#\u6a21\u578b\u8aaa\u660e)\n- [\u529f\u80fd\u8aaa\u660e](#\u529f\u80fd\u8aaa\u660e)\n    - [\u60c5\u7dd2\u6a21\u578b](#\u60c5\u7dd2\u6a21\u578b)\n        - [\u8a13\u7df4\u6a21\u578b](#\u8a13\u7df4\u6a21\u578b)\n        - [\u9a57\u8b49\u6a21\u578b](#\u9a57\u8b49\u6a21\u578b)\n        - [\u5c55\u793a\u6a21\u578b](#\u5c55\u793a\u6a21\u578b)\n    - [\u6df7\u5408\u8a13\u7df4\u96c6](#\u6df7\u5408\u8a13\u7df4\u96c6)\n- [\u8a13\u7df4\u5de5\u5177\u4f7f\u7528\u6b65\u9a5f](#\u8a13\u7df4\u5de5\u5177\u4f7f\u7528\u6b65\u9a5f)\n- [\u90e8\u5c6c\u8aaa\u660e](#\u90e8\u5c6c\u8aaa\u660e)\n- [\u5be6\u9a57\u7d00\u9304](#\u5be6\u9a57\u7d00\u9304)\n    - [\u6bd4\u8f03learning_rate\u5c0d\u5404\u6a21\u578b\u7684\u5f71\u97ff](#\u6bd4\u8f03learning_rate\u5c0d\u5404\u6a21\u578b\u7684\u5f71\u97ff)\n    - [\u6bd4\u8f03\u5404\u6a21\u578b\u7684\u67b6\u69cb](#\u6bd4\u8f03\u5404\u6a21\u578b\u7684\u67b6\u69cb)\n    - [\u6bd4\u8f03\u5b57\u8a5e\u9577\u5ea6\u8207batch\u9577\u5ea6\u7684\u95dc\u4fc2](\u6bd4\u8f03\u5b57\u8a5e\u9577\u5ea6\u8207batch\u9577\u5ea6\u7684\u95dc\u4fc2)\n    - [Siege_test](#siege_test)\n    - [\u6a21\u578b\u5bb9\u91cf\u6bd4\u8f03](#\u6a21\u578b\u5bb9\u91cf\u6bd4\u8f03)\n- [\u53c3\u8003\u8cc7\u6599](#\u53c3\u8003\u8cc7\u6599)\n- [FAQ](#faq)\n- [Future_work](#future_work)\n\n## \u76ee\u7684\n- \u6e1b\u5c11\u8a13\u7df4\u6a21\u578b\u7684\u96e3\u5ea6\uff0c\u4ee5\u53ca\u66f4\u65b0\u539f\u6709\u7684\u6846\u67b6(TensorFlow 1 -> 2)\n- \u4f7f\u7528\u8f03\u5c11\u7684\u8cc7\u6599\u8a13\u7df4\u6a21\u578b\uff0c\u85c9\u6b64\u4f86\u964d\u4f4e\u8a13\u7df4\u6a21\u578b\u7684\u96e3\u5ea6\u4ee5\u53ca\u8a13\u7df4\u6642\u9593\n- \u8a2d\u8a08\u6301\u7e8c\u66f4\u65b0\u6a21\u578b\u7684\u6a5f\u5236\n\n## \u9700\u6c42\n1. \u8a13\u7df4\u5de5\u5177\u9700\u6c42\n    - \u8f38\u5165\u8cc7\u6599\u96c6(\u8a13\u7df4\u96c6\u3001\u6e2c\u8a66\u96c6)\uff0c\u8f38\u51fa\u8a13\u7df4\u597d\u7684BERT\u6a21\u578b(savedModel\u683c\u5f0f)\n2. \u6a21\u578b\u9700\u6c42\n    - \u8f38\u5165\u6587\u7ae0\u5b57\u4e32\uff0c\u8f38\u51fa\u6a5f\u7387\u5206\u6578\u548c\u9810\u6e2c\u5206\u985e\n\n## Requirements\n- ubuntu == 18.04\n- python >= 3.6.9\n- [nvidia-docker](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installing-on-ubuntu-and-debian)\n    <details>\n    <summary>\u5b89\u88dd\u6b65\u9a5f</summary>\n    \n    ```\n    sudo apt-get install -y nvidia-docker2\n    sudo systemctl restart docker\n    sudo docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi\n    ```\n    </details>\n- Nvidia \u986f\u5361\u9a45\u52d5(nvidia-smi)\n    <details>\n    <summary>\u5b89\u88dd\u6b65\u9a5f</summary>\n\n    ```\n    \u5b89\u88dd\u6b65\u9a5f\n    1. sudo apt install ubuntu-drivers-common\n    2. ubuntu-drivers devices - \u67e5\u770b\u986f\u5361\u578b\u865f\u548c\u63a8\u85a6\u5b89\u88dd\u9a45\u52d5\u7248\u672c\u865f\uff0c\u4e26\u9078\u64c7\u60f3\u5b89\u88dd\u7684\u7248\u672c\n    2. sudo apt install nvidia-driver-455 - \u5b89\u88dd\u9a45\u52d5\n    3. \u91cd\u65b0\u555f\u52d5 (sudo reboot)\n    4. nvidia-smi - \u6aa2\u67e5GPU\u72c0\u614b\n    ```\n    </details>\n\n## \u60c5\u7dd2\u5c0d\u7167\u8868\n```json\n{\n  \"0\": \"\u6b63\u9762\",\n  \"1\": \"\u8ca0\u9762\",\n  \"2\": \"\u4e2d\u7acb\"\n}\n```\n\n## \u8f38\u5165\u8cc7\u6599\u7bc4\u4f8b\n- \u6a94\u6848\u76ee\u9304 : datasets/old_sentiment/\n- \u8a13\u7df4\u8cc7\u6599`train.tsv`\u8207\u9a57\u8b49\u8cc7\u6599`test.tsv`\u7686\u70ba`tsv\u683c\u5f0f`\uff0c\u4e26\u4e14\u4ee5`\\t`\u4f5c\u70ba\u5206\u9694\u3002\n\ntext|label|\n----|-----|\n\u5653:\u7687\u6c11\u662f\u65e5\u672c\u4eba\u7684\u610f\u601d\u5594\uff0c\u7f75\u7aa9\u5011\u7687\u6c11\u662f\u5728\u7a31\u8b9a\u5427|1\n\u63a8:\u984f\u8272\u597d\u7f8e\uff01|0\n\u63a8:\u4e00\u9280\u90a3\u9ebc\u597d\u501f\u600e\u9ebc\u90fd\u4e0d\u501f\u6211|2\n\n## \u8f38\u51fa\u8cc7\u6599\u683c\u5f0f\n- \u5373\u5404\u500b\u6587\u7ae0\u5b57\u4e32\u7684\u6a5f\u7387\u5206\u6578\uff0c\u6293\u6700\u5927\u503c\u4f86\u4ee3\u8868\u60c5\u7dd2\n- e.g : [0.00403965 0.98463815 0.01132222]\uff0c\u6700\u5927\u503c\u70ba**0.98463815**\uff0cindex=**1**\uff0c\u5c0d\u61c9\u5230\u5c0d\u7167\u8868\uff0c\u5373\u4ee3\u8868**\u8ca0\u9762**\u60c5\u7dd2\n```\n[[0.00403965 0.98463815 0.01132222],\n [0.9897307  0.00142236 0.00884701],\n [0.00303223 0.9747216  0.02224614],\n ...\n [0.09621345 0.46099612 0.4427904 ]\n [0.0937982  0.21287207 0.6933297 ]\n [0.23805933 0.00547114 0.75646955]]\n```\n\n## Quick start\n- \u78ba\u8a8d\u8cc7\u6599\u96c6(dataset/old_sentiment/)\u662f\u5426\u5b58\u5728\uff0c\u4e14\u5305\u542btrain.tsv\u3001test.tsv\n\n#### \u5efa\u7acbimages\n- \u5229\u7528docker file\u5efa\u7acbimages\uff0c\u4e26\u639b\u8f09\u7576\u524d\u76ee\u9304\u5230images\u5167\n```bash\nmake build_images\n```\n\n#### \u8a13\u7df4\u6a21\u578b\n- \u900f\u904e\u5efa\u7acb\u597d\u7684docker image\u9032\u884crun\u7684\u64cd\u4f5c\u3002\u53ef\u4ee5\u6307\u6d3e\u8981\u4f7f\u7528\u7684GPU\u6578\u91cf\n```bash\nmake run_fine_tuning_sentiment\n```\n\n#### \u9a57\u8b49\u6a21\u578b\n- \u900f\u904e\u5efa\u7acb\u597d\u7684docker image\u9032\u884crun\u7684\u64cd\u4f5c\u3002\u53ef\u4ee5\u6307\u6d3e\u8981\u4f7f\u7528\u7684GPU\u6578\u91cf\n```bash\nmake run_test_sentiment\n```\n\n#### inference\u6a21\u578b\n- \u900f\u904e\u5efa\u7acb\u597d\u7684docker image\u9032\u884crun\u7684\u64cd\u4f5c\u3002\u53ef\u4ee5\u6307\u6d3e\u8981\u4f7f\u7528\u7684GPU\u6578\u91cf\n```bash\nmake run_inference_sentiment\n```\n\n#### \u5feb\u901f\u90e8\u5c6c\n- \u8a13\u7df4\u597d\u60f3\u8981\u7684\u6a21\u578b\u5f8c\u9032\u884c\u90e8\u5c6c\uff0c\u8b93\u6a21\u578b\u80fd\u5feb\u901f\u8b93\u4eba\u4f7f\u7528\u3002\n```bash\nmake deploy_model\n```\n\n## \u6a21\u578b\u8aaa\u660e\n- \u53c3\u6578model_type\u6709\u4e09\u7a2e\u985e\u578b\n    - [custom\u3001origin](https://huggingface.co/transformers/model_doc/bert.html#tfbertforsequenceclassification)\n        - \u5f9etransformers\u4e0a\u6293pre-trained model\n        - custom\u6703\u5728\u6700\u5f8c\u4e00\u5c64\u589e\u52a0\u4e00\u5c64Dense\u9032\u884csoftmax\u4e26\u9032\u884c\u8a13\u7df4\n    - [tf-hub](https://tfhub.dev/tensorflow/bert_zh_L-12_H-768_A-12/3)\n        - \u5f9etensorFlow-hub\u4e0a\u6293pre-trained model\n        - \u6703\u5728\u6700\u5f8c\u4e00\u5c64\u589e\u52a0\u4e00\u5c64Dense\u9032\u884csoftmax\u4e26\u9032\u884c\u8a13\u7df4\n- \u5132\u5b58\u683c\u5f0f\u6bd4\u8f03\n    - `savedModel`\n        - \u9700\u89811.4G\u5de6\u53f3\u7684GPU Memory\n        - \u7528\u65bctest\u3001demo\u3001\u8f09\u5165\u820a\u6a21\u578b\u8a13\u7df4\u65b0\u6a21\u578b\n    - `h5 -> savedModel`\n        - \u4e00\u958b\u59cb\u5b58\u6210h5\u518d\u91cd\u65b0load_weights\u518d\u5b58\u6210savedModel\n        - \u53ea\u9700\u8981\u7528400M\u5de6\u53f3\u7684GPU Memory\n        - \u7528\u65bcdeploy\n    - `tflite`\n        - [Ref.](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/model_servers/main.cc)\n        - \u63d0\u4f9b\u7d66\u7a7f\u6234\u5f0f\u88dd\u7f6e\u7684\u6a21\u578b\uff0c\u4f46TensorFlow\u5b98\u65b9\u8aaa\u70ba\u5be6\u9a57\u6027\u8cea\uff0c\u5c0e\u81f4\u7121\u6cd5\u9806\u5229\u90e8\u5c6c\u5230tf-serving\u4e0a\n    - `h5 -> savedModel -> tensorRT`\n        - [Ref.](https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html)\n        - default parameter: `precision_mode`: `fp16`\u3001`minimum_segment_size(n)`: `3`\u3001`maximum_cached_engines(c)`: `1`\n        - \u6700\u5c11\u9700\u8981\u7d04880M\u5de6\u53f3\u7684GPU Memory\u7528\u65bc\u555f\u52d5\uff0ctensorRT\u9084\u6703\u81ea\u5df1\u5403\u6389\u4e00\u4e9bMemory(\u53ef\u4ee5\u8a2d\u5b9a)\n        - \u7b2c\u4e00\u6b21\u9700\u8981\u521d\u59cb\u5316\u6a21\u578b\uff0c\u9700\u8981\u7d041\u5206\u9418\u5de6\u53f3\u7684\u6642\u9593\n\n## \u529f\u80fd\u8aaa\u660e\n### \u60c5\u7dd2\u6a21\u578b\n- \u4f7f\u7528Command Line Interface(CLI)\u4e32\u63a5\u8f38\u5165\u53c3\u6578 \n```\npython core/run_sentiment.py --help\n```\n\n<details>\n<summary>args</summary>\n\n```\nUsage: run_sentiment.py [OPTIONS]\n\nOptions:\n  --data_dir TEXT            The input data dir. Should contain the .tsv files\n                             (or other data files) for the task.  [required]\n\n  --task_name TEXT           The name of the task to train.  [required]\n  --output_dir TEXT          The output directory(savedModel) where the model\n                             checkpoints will be written.  [required]\n\n  --deploy_dir TEXT          If direct save the savedModel,will too large.\n                             Because there default save the optimizer.So we\n                             save to .h5 format, and convert to savedModel,\n                             that will not save optimizer in savedModel.And\n                             used this variable to deploy to tensorFlow\n                             serving\n\n  --learning_rate FLOAT      The initial learning rate for Adam.  [default:\n                             2e-05]\n\n  --num_epochs INTEGER       Total number of training epochs to perform.\n                             [default: 3]\n\n  --dropout_rate FLOAT       Discard some neuron in the network to prevent\n                             cooperation between feature. E.g., 0.1 = 10% of\n                             neuron.  [default: 0.1]\n\n  --batch_size INTEGER       Total batch size for training.  [default: 32]\n  --max_seq_length INTEGER   The maximum total input sequence length after\n                             WordPiece tokenization. Sequences longer than\n                             this will be truncated, and sequences shorter\n                             than this will be padded.  [default: 128]\n\n  --do_train BOOLEAN         Whether to run training.  [default: False]\n  --do_test BOOLEAN          Whether to run test on the dev set.  [default:\n                             False]\n\n  --do_inference BOOLEAN     Whether to run the model in inference mode on the\n                             test set.  [default: False]\n\n  --save_format LIST         Default is [\"savedmodel\", \"tensorRT\"]. Input have\n                             \"savedmodel\" will save savedmodel with h5 convert\n                             to savedmodel, when input have \"tensorRT\" and\n                             \"savedmodel\", will save converted savedmodel to\n                             tensorRT, if just \"tensorRT\" will save origin\n                             savedmodel to tensorRT, input have \"tflite\" will\n                             save tflite format, but that is not correct work.\n                             [default: savedmodel, tensorRT]\n\n  --model_type BOOLEAN       Which model type do you want to use.\n                             Default is \"custom\", can use \"custom\"\u3001\"tf-hub\"\u3001\"origin\n                             [default: custom]\n\n  --model_name TEXT          Please input \"bert-base-chinese\"\u3001\"ckiplab/bert-\n                             base-chinese\"\u3001\"ckiplab/albert-base-chinese\"\u3001\n                             \"ckiplab/albert-tiny-chinese\",to set pretrained\n                             model name.  [default: bert-base-chinese]\n\n  --load_model_dir TEXT      If you want load old model(savedModel) to train\n                             the new model, please set where to load the old\n                             model dir.\n\n  --use_dev_dataset TEXT     Whether to evaluation the other dataset when\n                             do_test times. The dataset name is\n                             latest_test.tsv  [default: False]\n\n  --mix_number INTEGER       How many training dataset to mix? If not set, the\n                             old datasetwill be mixed according to the number\n                             of tags in the new dataset  [default: 0]\n\n  --help                     Show this message and exit.\n```\n</details>\n\n#### \u8a13\u7df4\u6a21\u578b\n- \u8b80\u53d6**data_dir**\u53c3\u6578\u4e0b\u7684\u6a94\u6848(train.tsv\u3001test.tsv)\uff0c\u9032\u884cFine-Tuning BERT\u591a\u985e\u5225\u4efb\u52d9\uff0c\u6700\u5f8c\u5132\u5b58[\u6a21\u578b\u5831\u544a](#\u6a21\u578b\u5831\u544a)\n- shell args \u5fc5\u5e36\u53c3\u6578\n```\n--task_name=$(TASK_NAME) \\\n--do_train=True \\\n--save_format=$(SAVE_FORMAT) \\\n--model_type=$(MODEL_TYPE) \\\n--batch_size=16 \\\n--data_dir=$(DATA_DIR) \\\n--model_name=$(MODEL_NAME) \\\n--output_dir=$(OUTPUT_DIR) \\\n--deploy_dir=$(DEPLOY_DIR)\n```\n- \u76ee\u524d\u6e2c\u8a66\u904e\u7684\u6a21\u578bcheckpoint(ckiplab: \u4e2d\u7814\u9662)\uff0c\n    - `bert-base-chinese`\n    - `ckiplab/bert-base-chinese`\n    - `ckiplab/albert-base-chinese`\n    - `ckiplab/albert-tiny-chinese`\n- \u5ba2\u88fd\u5316\u6a21\u578bInput\u3001Output\u85c9\u6b64\u4f86\u7b26\u5408\u820a\u898f\u683c\n<details>\n<summary>Code example</summary>\n\n```python\nimport tensorflow as tf\nfrom transformers import TFAutoModel\nfrom absl import flags\n\nFLAGS = flags.FLAGS\n\ndef create_model(self):\n    \"\"\"Build BERT model. Custom Input Layer(input_ids\u3001input_mask\u3001segment_ids) and Output Layer(Dropout\u3001Dense)\"\"\"\n    input_word_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32,\n                                           name=\"input_ids\")\n    input_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int32,\n                                       name=\"input_mask\")\n    segment_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32,\n                                        name=\"segment_ids\")\n    # because ckiplab/models is use Pytorch develop so need to add 'from_pt' args\n    model = TFAutoModel.from_pretrained(\n        pretrained_model_name_or_path=self.model_name,\n        from_pt=True if \"ckiplab/\" in self.model_name else False,\n        num_labels=len(self.label_list)\n    )\n    model._saved_model_inputs_spec = None\n    sequence_output = model([input_word_ids, input_mask, segment_ids])\n    out = tf.keras.layers.Dropout(FLAGS.warmup_proportion)(sequence_output.pooler_output)\n    out = tf.keras.layers.Dense(\n        units=len(self.label_list),\n        activation=\"softmax\",\n        name=\"probabilities\"\n    )(out)\n\n    model = tf.keras.models.Model(\n        inputs=[input_word_ids, input_mask, segment_ids],\n        outputs=out,\n        name=self.task_name)\n\n    model.summary()\n\n    return model\n```\n</details>\n\n- \u5982\u679c\u662f\u8981\u7528load_model\u7684\u8a13\u7df4\u65b9\u5f0f\uff0c\u5247\u9700\u6e96\u5099\u597d\u65b0\u7684\u8a13\u7df4\u96c6\uff0c\u9810\u8a2d\u547d\u540d\u70ba`new_train.tsv`\uff0c\u5b58\u653e\u5728`dataset/old_sentiment`\u4e0b\uff0c\u4e26\u8a2d\u5b9a\u8b80\u53d6\u820a\u6a21\u578b\u7684\u8def\u5f91\n```shell script\n--task_name=$(TASK_NAME) \\\n--do_train=True \\\n--save_format=$(SAVE_FORMAT) \\\n--data_dir=$(DATA_DIR) \\\n--load_model_dir=$(LOAD_MODEL_DIR) \\\n--mix_number=$(MIX_NUMBER) \\\n--model_name=$(MODEL_NAME) \\\n--output_dir=$(OUTPUT_DIR) \\\n--deploy_dir=$(DEPLOY_DIR)\n```\n\n##### \u6a21\u578b\u5831\u544a\n- \u8a13\u7df4\u5b8c\u6a21\u578b\u5f8c\uff0c\u5132\u5b58\u7684\u6a21\u578b\u6b77\u53f2\u7d00\u9304\uff0c\u4ee5\u53ca\u9a57\u8b49\u8cc7\u6599\u7684confusion matrix\uff0c\u7528\u4f86\u89c0\u770b\u6a21\u578b\u597d\u58de\n<details>\n<summary>summary \u7bc4\u4f8b</summary>\n\n```\n        - epoch:         [0, 1]\n        - params:        {'verbose': 1, 'epochs': 2, 'steps': 417}\n        - loss:          [0.40817883610725403, 0.21885691583156586]\n        - accuracy:      [0.8476840853691101, 0.9230538010597229]\n        - val_loss:      [0.2668299973011017, 0.2991047501564026]\n        - val_accuracy:  [0.9088318943977356, 0.9017093777656555]\n        - report:      \n              precision    recall  f1-score   support\n\n           0     0.9366    0.9131    0.9247      1036\n           1     0.8828    0.9300    0.9058      1328\n           2     0.8687    0.8345    0.8513      1142\n\n    accuracy                         0.8939      3506\n   macro avg     0.8960    0.8925    0.8939      3506\nweighted avg     0.8941    0.8939    0.8936      3506\n\n        - total_time:    621.076s\n```\n</details> \n\n#### \u9a57\u8b49\u6a21\u578b\n- \u900f\u904e**output_dir**\u53c3\u6578\u4f86\u6307\u5b9a\u6a21\u578b\u4f4d\u7f6e\uff0c\u4e26\u9032\u884c**keras.load_model**\u7684\u52d5\u4f5c\uff0c\u518d\u8b80\u53d6**data_dir**\u88e1\u7684test.tsv\u9032\u884c\u9a57\u8b49\uff0c\u6700\u5f8c\u64b0\u5beb[\u9a57\u8b49\u5831\u544a](#\u9a57\u8b49\u5831\u544a)\u5132\u5b58\u5728**output_dir**\u5167\n- shell args \u5fc5\u5e36\u53c3\u6578\n```\n--task_name=$(TASK_NAME) \\\n--do_test=True \\\n--use_dev_dataset=$(USE_DEV_DATASET) \\\n--model_type=$(MODEL_TYPE) \\\n--data_dir=$(DATA_DIR) \\\n--output_dir=$(OUTPUT_DIR)\n```\n\n- python example\n```python\nimport tensorflow as tf\n\noutput_dir = \"checkpoints/sentiment/2/\"\nmodel = tf.keras.models.load_model(output_dir)\nmodel.summary()\n```\n##### \u9a57\u8b49\u5831\u544a\n- test_report.txt:\u5132\u5b58\u9a57\u8b49\u8cc7\u6599\u7684confusion matrix\n```\n        - report:      \n              precision    recall  f1-score   support\n\n           0     1.0000    1.0000    1.0000        10\n           1     0.9167    0.9167    0.9167        12\n           2     0.9000    0.9000    0.9000        10\n\n    accuracy                         0.9375        32\n   macro avg     0.9389    0.9389    0.9389        32\nweighted avg     0.9375    0.9375    0.9375        32\n\n        - total_time:    217.657s\n```\n\n- test_result.tsv:\u5132\u5b58\u9a57\u8b49\u8cc7\u6599\u7684\u5be6\u969blabel\u548c\u9810\u6e2clabel\u6bd4\u8f03\u5716\n```\ntext,true,pred\n\u5653:\u7687\u6c11\u662f\u65e5\u672c\u4eba\u7684\u610f\u601d\u5594\uff0c\u7f75\u7aa9\u5011\u7687\u6c11\u662f\u5728\u7a31\u8b9a\u5427,1,1\n\u63a8:\u984f\u8272\u597d\u7f8e\uff01,0,0\n...\n\u904e\u654f\u6240\u4ee5\u66ab\u4e0d\u8003\u616e\u9019\u9593~~,1,1\n\u63a8:\u4e00\u9280\u90a3\u9ebc\u597d\u501f\u600e\u9ebc\u90fd\u4e0d\u501f\u6211,2,2\n```\n\n#### \u5c55\u793a\u6a21\u578b\n- \u900f\u904e**output_dir**\u53c3\u6578\u4f86\u6307\u5b9a\u6a21\u578b\u4f4d\u7f6e\uff0c\u4e26\u9032\u884c**keras.load_model**\u7684\u52d5\u4f5c\uff0c\u518d\u7b49\u5f85\u4f7f\u7528\u8005\u8f38\u5165\u6587\u7ae0\u5b57\u4e32\uff0c\u6700\u5f8c\u8f38\u51fa\u5404\u7a2e\u5206\u985e\u7684\u5206\u6578\uff0c\u4ee5\u53ca\u9810\u6e2c\u7d50\u679c\n- \u53ef\u85c9\u7531console\u9032\u884c\u6a21\u578b\u9810\u6e2c\u5c55\u793a\n- shell args \u5fc5\u5e36\u53c3\u6578\n```\n--task_name=$(TASK_NAME) \\\n--do_inference=True \\\n--model_type=$(MODEL_TYPE) \\\n--output_dir=$(OUTPUT_DIR)\n```\n- \u4f7f\u7528\u7bc4\u4f8b\n```\n--> [input content]: \u9019\u5bb6\u5e97\u8d85\u68d2\u7684\npositive:0.9112719297409058, negative:0.027610205113887787, neutral:0.061117853969335556\npredict result : positive\n\n--> [input content]: \u9019\u5bb6\u5e97\u8d85\u721b\u7684\npositive:0.27210354804992676, negative:0.6493704915046692, neutral:0.07852598279714584\npredict result : negative\n\n--> [input content]: \u9019\u5bb6\u5e97\u666e\u901a\npositive:0.3982468247413635, negative:0.13436941802501678, neutral:0.4673837423324585\npredict result : neutral\n```\n\n### \u6df7\u5408\u8a13\u7df4\u96c6\n- \u7576\u8a13\u7df4\u65b0\u6a21\u578b\u6642\u6709\u8a2d\u5b9a\u5230`load_model_dir`\u53c3\u6578\u7684\u8a71\uff0c\u6703\u81ea\u52d5\u53bb\u5275\u5efa\u65b0\u8a13\u7df4\u96c6\n- \u7576\u4f7f\u7528\u5c11\u91cf\u8cc7\u6599\u9032\u884c\u6a21\u578b\u8a13\u7df4\u6642\uff0c\u9700\u8981\u52a0\u5165\u4e9b\u8a31\u7684\u820a\u8cc7\u6599\uff0c\u4f86\u63d0\u5347\u6574\u9ad4\u7684\u6e96\u78ba\u7387\uff0c\u9019\u908a\u63d0\u4f9b\u5169\u7a2e\u6df7\u5408\u7684\u65b9\u5f0f\n    - \u4f9d\u7167\u65b0\u8cc7\u6599\u96c6\u5167\u5404\u6a19\u7c64\u7684\u6578\u91cf\u6c7a\u5b9a\u6df7\u5408\u5c31\u8cc7\u6599\u7684\u6578\u76ee\n        - *\u4f46\u5982\u679c\u65b0\u8cc7\u6599\u96c6\u5167\u5404\u6a19\u7c64\u7b46\u6578\u5927\u65bc3\u4f4d\u6578(1000\u4ee5\u4e0a)\uff0c\u5247\u6703\u9078\u64c7\u4f7f\u7528\u4e09\u500b\u6a19\u7c64\u7684\u6700\u5c0f\u516c\u500d\u6578\u9032\u884c\u8cc7\u6599\u7684\u586b\u88dc*\n        - eg: \u5047\u8a2d\u65b0\u8cc7\u6599\u96c6\u5404\u6a19\u7c64\u7b46\u6578[0, 1, 489]\uff0c\u6df7\u5408\u7b46\u6578[1000, 1000, 500] => [1000, 1001, 989]\n    - \u6307\u5b9a\u6df7\u5408\u6578\u91cf\n        - eg: \u5047\u8a2d\u65b0\u8cc7\u6599\u96c6\u5404\u6a19\u7c64\u7b46\u6578[0, 1, 489]\uff0c\u6307\u5b9a\u6df7\u5408\u7b46\u6578100 => [100, 101, 589]\n- click --help\n```markdown\nUsage: create_load_dataset.py [OPTIONS]\n\n  Create new dataset, that have some old dataset\n\n  Args:     \n    maximum_digits:     old_dataset_name(str): old datasets file name.     \n    new_dataset_name(str): new datasets file name.\n    output_dataset_name(str): mix old and new datasets file name.\n    mix_number(int): How many training sets to mix.\n    minimum_content_length(int): Limit the minimum number of content when mix dataset.\n\nOptions:\n  --old_dataset_name TEXT         \u820a\u8cc7\u6599\u96c6\u540d\u7a31  [default: train.tsv]\n  --new_dataset_name TEXT         \u65b0\u8cc7\u6599\u96c6\u540d\u7a31  [default: new_train.tsv]\n  --output_dataset_name TEXT      \u6df7\u5408\u8cc7\u6599\u96c6\u540d\u7a31  [default: train.tsv]\n  --mix_number INTEGER            \u6df7\u5408\u591a\u5c11\u6578\u91cf\u7684\u8a13\u7df4\u96c6\uff0c\u5982\u679c\u6c92\u8a2d\u5b9a\uff0c\u5247\u662f\u4f9d\u7167\u65b0\u8cc7\u6599\u96c6\u5167\u7684\u5404\u6a19\u7c64\u7684\u6578\u91cf\u9032\u884c\u820a\u8cc7\u6599\u7684\u6df7\u5408\n                                  [default: 0]\n\n  --minimum_content_length INTEGER\n                                  \u6df7\u5408\u8cc7\u6599\u6642\uff0c\u820a\u8cc7\u6599\u6293\u53d6\u6642\u7684\u6700\u5c11\u5b57\u6578\u9650\u5236  [default: 20]\n  --maximum_digits INTEGER        \u6700\u5927\u80fd\u63a5\u53d7\u8cc7\u6599\u7b46\u6578\u7684\u4f4d\u5143\u500b\u6578\uff0c\u5982\u679c\u8d85\u904e\u6293\u6700\u5c0f\u516c\u500d\u6578\uff0c\u6c92\u8d85\u904e\u5247\u4ee510^maximum_di\n                                  gits\u88dc\u8cc7\u6599\uff0ceg\uff1a1000\u7b46 => 4\u4f4d\u5143\uff0c  [default: 3]\n\n  --help                          Show this message and exit.\n```\n\n## \u8a13\u7df4\u5de5\u5177\u4f7f\u7528\u6b65\u9a5f\n- \u9810\u8a2d\u4f7f\u7528`tf-hub`\u7684model\uff0c\u662f\u5be6\u9a57\u904e\u5f8c\u6b63\u78ba\u7387\u3001\u6548\u80fd\u6700\u597d\u7684\n1. \u8a2d\u5b9a\u597dMakefile\u6a94\u6848\u5167\u8b8a\u6578\uff0c[Ref.](#\u60c5\u7dd2\u6a21\u578b)\n    - e.g: `DATA_DIR`\u3001`OUTPUT_DIR`\u3001`DEPLOY_DIR`\u3001`LOAD_MODEL_DIR`...\n2. \u5efa\u7acbdocker images\n    - `make build_images`\n3. \u9032\u884c\u6a21\u578b\u8a13\u7df4\n    - \u8a13\u7df4\u65b0\u6a21\u578b\n        - `make run_fine_tuning_sentiment`\n    - \u8f09\u5165\u820a\u6a21\u578b\u8a13\u7df4\u65b0\u6a21\u578b\n        - `make run_load_model_to_train`\n4. \u82e5\u8a13\u7df4\u7d50\u679c\u4e0d\u6eff\u610f\n    1. \u5148\u9032\u884c\u6a21\u578b\u9a57\u8b49\uff0c\u4f86\u89c0\u770b\u6a21\u578b\u9810\u6e2c\u8207\u5be6\u969b\u6bd4\u5c0d\u7d50\u679c\n        - `make run_test_sentiment`\n    2. \u624b\u52d5\u8abf\u6574\u6709\u554f\u984c\u7684\u8a13\u7df4\u96c6or\u6e2c\u8a66\u96c6\uff0c\u518d\u91cd\u65b0\u8a13\u7df4\n    3. \u82e5\u5c0d\u7d50\u679c\u9084\u662f\u4e0d\u6eff\u610f\uff0c\u5247\u53ef\u4ee5\u8003\u616e\u8abf\u6574\u8d85\u53c3\u6578\n        - `learning_rate`\u3001`num_epochs`\u3001`batch_size`\u3001`dropout_rate`...\n5. \u90e8\u5c6c\u6a21\u578b\n    - \u5148\u78ba\u5b9a`serving/model/model.config`\u6a94\u5167\u7684\u8a2d\u5b9a\uff0c\u53ef\u53c3\u8003\u4e0b\u9762\u7684[\u90e8\u5c6c\u8aaa\u660e](#\u90e8\u5c6c\u8aaa\u660e)\n    - \u8a2d\u5b9aMakefile\u7684`SERVING_DIR`\n    - `make deploy_model`\uff0c\u9700\u6ce8\u610f`SERVING_DIR`\u5167\u7684\u6a21\u578b\u7248\u672c\u865f\u662f\u5426\u6709\u885d\u7a81\n\n## \u90e8\u5c6c\u8aaa\u660e\n- \u7576\u8a13\u7df4\u597d\u4e00\u500b\u6a21\u578b\u5f8c\u4e26\u5132\u5b58\u6210SavedModel\u683c\u5f0f\u5f8c\uff0c\u6211\u5011\u900f\u904eTF serving\u9032\u884c\u6a21\u578b\u7684\u90e8\u5c6c\uff0c\u4e26\u7528grpc\u9032\u884c\u547c\u53eb\n    - TF serving \u7c21\u55ae\u4ecb\u7d39\n        - TF serving`\u652f\u63f4\u540c\u6a21\u7d44\u4e0b\u591a\u500b\u7248\u672c\u7684\u6a21\u578b\u540c\u6642\u904b\u884c`(\u60c5\u7dd2\u6a21\u578b\u4e0b\u67091\u30012\u7248)\n        - TF serving`\u652f\u63f4\u7121\u75db\u4e0a\u7248\u3001\u9000\u7248`\uff0c\u53ea\u9700\u66f4\u6539model.config\u5373\u53ef\n    - models.config \u8a2d\u5b9a\n        - models.config\u4e2d\u4f7f\u7528`version_labels`(\u6709key: string => \u81ea\u5b9a\u7fa9\u7684\u540d\u7a31\u3001value: int => \u5c0d\u61c9\u7684\u7248\u672c)\u4f86\u7d81\u5b9a\u4e0d\u540c\u7248\u672c\u5c0d\u61c9\u5230\u7684\u540d\u7a31\uff0c\u4ee5\u5229\u65bcgrpc\u547c\u53eb\u6642\u53ef\u547c\u53eb\u4e0d\u540c\u7248\u672c\n        - \u9700\u78ba\u8a8dmodels.config\u4e2d\u4f7f\u7528`versions`\u5c0d\u61c9\u7684`base_path`\u8def\u5f91\u4e0b\u7684\u8cc7\u6599\u593e\u540d\u7a31(\u5373\u662f\u7248\u672c\u865f\u78bc)\u662f\u5426\u4e00\u81f4\n        \n        <details>\n        <summary>models.config\u8a2d\u5b9a\u7bc4\u4f8b</summary>\n        \n        ```\n        model_config_list {\n            config {\n                name: 'sentiment',\n                base_path: '/models/sentiment/',\n                model_platform: \"tensorflow\",\n                model_version_policy: {\n                    specific: {\n                        versions: 1,\n                        versions: 2\n                    }\n                },\n                version_labels: {\n                    key: \"stable\",\n                    value: 1\n                },\n                version_labels: {\n                    key: \"canary\",\n                    value: 2\n                }\n            }\n        }\n        ```\n        </details>\n        \n- \u90e8\u5c6c\u4f4d\u7f6e: `/serving/models/`\n- \u90e8\u5c6c\u8a2d\u5b9a\u6a94: `/serving/models/models.config`\n- \u5feb\u901f\u90e8\u5c6c: \u5982\u4e0a\u9762Quick start\u5167\u7684\u5feb\u901f\u90e8\u5c6c\n- \u4e0a\u7248\u3001\u9000\u7248(\u7248\u672c\u5207\u63db)\u6d41\u7a0b:\n    - \u76ee\u524d\u8a2d\u5b9a\u5169\u7a2e\u7248\u672c\n        1. \u7a69\u5b9a\u7248(stable)\n        2. \u6e2c\u8a66\u7248(canary)\n    - \u4e0a\u7248\u6d41\u7a0b:\n        - \u5047\u8a2d\u539f\u672c\u7248\u672c\u70bastable -> 1\u3001canary -> 2\uff0c\u78ba\u8a8d\u6e2c\u8a66\u7248(canary\u7248\u672c)\u7a69\u5b9a\u5f8c\u53ef\u4ee5\u4e0a\u7dda\u6642\uff0c\u5373\u53ef\u4fee\u6539stable -> 2\uff0ccanary\u53ef\u4e0d\u8b8a\u3002\n    - \u9000\u7248\u6d41\u7a0b:\n        - \u5047\u8a2d\u539f\u672c\u7248\u672c\u70bastable -> 2\uff0c\u4eca\u5929\u4e0a\u7684\u7248\u672c\u6709\u554f\u984c\u9700\u8981\u9000\u7248\uff0c\u5247\u4fee\u6539\u70bastable -> 2 => 1\uff0c\u5373\u53ef\u9054\u6210\uff0c\u4e0d\u9700\u518d\u984d\u5916\u518d\u9032\u884c\u8a2d\u5b9a\u3002\n- \u53c3\u8003\u7db2\u7ad9: \n    - [TensorFlow serving](https://www.tensorflow.org/tfx/serving/serving_config#serving_multiple_versions_of_a_model)\n    - [TensorFlow 2.x \u6a21\u578b Serving \u670d\u52d9](https://www.mdeditor.tw/pl/pXfR/zh-tw)\n\n## \u5be6\u9a57\u7d00\u9304\n- [\u66f4\u591a\u7684\u5be6\u9a57\u8a18\u9304](https://gitting.eland.com.tw/rd2/models/sentiment-training-tool/-/wikis/home)\n\n### \u6bd4\u8f03learning_rate\u5c0d\u5404\u6a21\u578b\u7684\u5f71\u97ff\n- max_seq_length=128\n- batch_size=32\n- num_train_epochs=2\n- predict_data=test.tsv(3506\u7b46)\n- train_data=train.tsv(14023\u7b46)\n\n- `bert-base-chinese` best test_acc: 0.9062\n- `ckiplab/bert-base-chinese` est test_acc: 0.9016\n\n| | lr |train_loss|train_acc|val_loss|val_acc|test_loss|test_acc|train_times|predict_times|\n|---|---|---|---|---|---|---|---|---|---|\n|bert-base-chinese(no train)|2e-5|1.4478|0.3872|1.4788|0.3782|1.4278|0.3889|207.03s|23.506s|\n|bert-base-chinese(no val dataset)|2e-5|0.2531|0.9084| | |0.3169|0.9022|654.327s|23.53s|\n|`bert-base-chinese`|2e-5|0.2491|0.9133|0.2656|0.9217|0.2989|`0.9062`|635.389s|22.797s|\n|bert-base-chinese|5e-5|0.2360|0.9183|0.3150|0.8875|0.3095|0.8925|635.733s|22.816s|\n|ckiplab/bert-base-chinese|2e-5|0.2517|0.9125|0.2811|0.9031|0.3176|0.8959|636.942s|22.86s|\n|ckiplab/bert-base-chinese|5e-5|0.2664|0.9072|0.3025|0.9074|0.3568|0.8756|634.246s|22.808s|\n|ckiplab/albert-base-chinese|2e-5|0.4138|0.8462|0.4197|0.8632|0.4093|0.8577|523.806s|19.81s|\n|ckiplab/albert-base-chinese|5e-5|0.4277|0.8524|0.4144|0.8618|0.4012|0.8574|520.125s|19.839s|\n|ckiplab/albert-tiny-chinese|2e-5|0.4922|0.8111|0.4460|0.8376|0.4463|0.8360|104.799s|3.375s|\n|ckiplab/albert-tiny-chinese|5e-5|0.4301|0.8343|0.4130|0.8476|0.4326|0.8363|104.413s|3.363s|\n\n### \u6bd4\u8f03\u5404\u6a21\u578b\u7684\u67b6\u69cb\n- TF1 model structure\u3001TF2 tf-models-official model structure\u3001TF2 transformers model structure\n![model_structure](model_structure.png)\n\n### \u6bd4\u8f03\u5b57\u8a5e\u9577\u5ea6\u8207batch\u9577\u5ea6\u7684\u95dc\u4fc2\n- \u6bd4\u8f03bert-base-chinese\u6a21\u578bSeq-Length\u548cMax-Batch-Size\u7684\u95dc\u4fc2\n- \u89c0\u5bdf\u591a\u5c11\u7684Seq-Length\u4e0b\uff0cMax-Batch-Size\u7b49\u65bc\u591a\u5c11\u4e0d\u6703OOM(Out-of-memory)\n- max_seq_length : \u5225\u4ebatrained\u597d\u7684\u6a21\u578b\u662f\u5229\u7528`512`\u9577\u5ea6\u9032\u884c\u8a13\u7df4\uff0c\u4f46\u6211\u5011\u53ef\u4ee5\u5229\u7528\u8f03\u5c0f\u7684\u9577\u5ea6\u9032\u884cfine-tuning\u4f86\u7bc0\u7701memory\n- train_batch_size : train_batch_size\u8ddfmemory\u662f\u6b63\u6bd4\u95dc\u4fc2\n- optimizer : BERT\u9810\u8a2d\u662fAdam\uff0c\u4f46\u5979\u9700\u8981\u984d\u5916\u7684memory\u53bb\u5b58\u53d6`m`\u548c`v`\u5411\u91cf\uff0c\u6211\u5011\u53ef\u4ee5\u9078\u64c7\u5176\u4ed6\u7684optimizer\u4f86\u6e1b\u5c11memory\u7684\u4f7f\u7528\uff0c\u4f46\u9019\u6a23\u6703\u5f15\u97ff\u7d50\u679c\uff0c\u6240\u4ee5\u9019\u500b\u5be6\u9a57\u4e0d\u6539\u8b8aoptimizer\n- System : `bert-base-chinese`\uff0c\u56e0\u70ba\u9019\u662f\u6211\u5011\u4e0a\u9762\u5be6\u9a57\u904eAccuracy\u6700\u9ad8\u7684\u6a21\u578b\n\n| Seq Length | Max Batch Size |\n|------------|----------------|\n| 64 | 64 |\n| 128 | 32 |\n| 256 | 16 |\n| 320 | 14 |\n| 384 | 12 |\n| 512 | 6 |\n\n### Siege_test\n- \u5171\u540c\u7684\u8acb\u6c42\u6578\u76ee\uff0c\u4f86\u89c0\u6e2c\u8207\u539f\u6a21\u578b\u4e4b\u9593\u8655\u7406\u901f\u5ea6\u4e0a\u7684\u5dee\u7570\n- \u986f\u5361: GeForce RTX 2070 super\n- \u8acb\u6c42\u6b21\u6578: 5000\n- h5 -> savedModel: \u5148\u5132\u5b58\u6210h5\u4f86\u6392\u9664\u6389\u90e8\u5206\u90e8\u5c6c\u4e0d\u9700\u8981\u7684\u8cc7\u8a0a(opt\u3001loss...)\uff0c\u518d\u8f49\u5b58\u6210savedModel\n- savedModel -> tensorRT: \u5f9esavedModel\u8f49\u63db\u6210tensorRT\uff0ctensorRT\u5132\u5b58\u6642\u5176\u5be6\u9084\u662fsavedModel\uff0c\u4f46\u4fee\u6539\u4e86\u5167\u90e8graph\u67b6\u69cb\n\n|   | Elap Time | Data Trans | Resp Time | Trans Rate | Throughput | Concurrent | OKAY | Failed |\n|---|-----------|------------|-----------|------------|------------|------------|------|--------|\n| \u539f\u6a21\u578b | `268.65` | 1 | 0.11 | 18.61 | 0.00 | 2.00 | 5000 | 0 |\n| savedModel(no_train) | 291.28 | 1 | 0.12 | 17.17 | 0.00 | 2.00 | 5000 | 0 |\n| savedModel | 377.44 | 1 | 0.15 | 13.25 | 0.00 | 2.00 | 5000 | 0 |\n| savedModel -> tensorRT | 358.67 | 1 | 0.14 | 13.94 | 0.00 | 2.00 | 5000 | 0 |\n| h5 -> savedModel | 375.54 | 1 | 0.15 | 13.31 | 0.00 | 2.00 | 5000 | 0 |\n| h5 -> savedModel -> tensorRT | 361.04 | 1 |0.14 | 13.85 | 0.00 | 2.00 | 5000 | 0 |\n| tensorRT_fp16_n15_c100_tensorRT| 371.09 | 1 | 0.15 | 13.47 | 0.00 | 2.00 | 5000 | 0 |\n| ckiplab_bert-savedmodel | 381.34 | 1 | 0.15 | 13.11 | 0.00 | 2.00 | 5000 | 0 | \n| `tensorflow-hub-h5 -> savedmodel` | `291.66` | 1 | 0.12 | 17.14 | 0.00 | 2.00 | 5000 | 0 |\n| `tensorflow-hub-h5 -> savedmodel -> tensorRT` | `291.63` | 1 | 0.12 | 17.15 | 0.00 | 2.00 | 5000 | 0 |\n\n### \u6a21\u578b\u5bb9\u91cf\u6bd4\u8f03\n- \u76f8\u540c\u7684\u8a13\u7df4\u96c6\uff0c\u4f86\u6bd4\u8f03\u54ea\u7a2e\u5132\u5b58\u985e\u578b\u6240\u9700\u7684`.pd`\u3001`variables`\u8f03\u5c0f\n\n|   | saved_model.pb | variables.data-00000-of-00001 | model.tflite |\n|---|----------------|-------------------------------|--------------|\n| \u539f\u6a21\u578b | 1020K | 390M | - |\n| savedModel | 10M | 1.1G | - |\n| h5 -> savedModel | 9.5M | 390M | - |\n| tflite -> tf serving | - | - | 99M |\n| savedmodel -> tensorRT -> tensorRT | 790M | 1.1G | - |\n| h5 -> savedmodel -> tensorRT | 401M | 390M | - |\n| `Tensorflow-hub h5 -> savedmodel` | 14M | 393M | - |\n| `Tensorflow-hub h5 -> savedmodel -> tensorRT` | 795M | 393M | - |\n\n## \u53c3\u8003\u8cc7\u6599\n- https://www.tensorflow.org/official_models/fine_tuning_bert\n- https://huggingface.co/transformers/master/model_doc/bert.html#tfbertforsequenceclassification\n- https://github.com/ckiplab/ckip-transformers\n- https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html\n- https://arxiv.org/pdf/1706.03762.pdf\n\n## FAQ\n\n**\u6a21\u578b\u5132\u5b58**\n\n- How to save the whole model as SavedModel format for inference?\n    - [answer](https://github.com/huggingface/transformers/issues/6864#issuecomment-690086932)\n\n**\u6a21\u578b\u90e8\u5c6c**\n\n- \u53ef\u4ee5\u7528`nvtop`\u9032\u884c\u89c0\u6e2c\uff0c\u770b\u986f\u5361\u7684Memory\u6709\u6c92\u6709\u5403\u5230\n    - Memory\u4e0d\u5920\uff0c\u5c0e\u81f4\u6a21\u578b\u8b80\u4e0d\u9032\u4f86\uff0c\u8abf\u6574bin/run_serving.sh\u5167\u7684docker\u8a2d\u5b9a`CONTAINER_RAM`\u3001`CONTAINER_CPU`\u53ef\u4ee5\u63d0\u9ad8\u70ba`8g`\n\n## Future_work\n- \u52a0\u5165\u6a19\u984c\u9032\u884c\u8a13\u7df4\uff0c\u85c9\u6b64\u589e\u52a0\u8f38\u5165\u7279\u5fb5\uff0c\u4f86\u63d0\u9ad8\u77ed\u6587\u7684\u9810\u6e2c\u80fd\u529b\n    - [\u8a0e\u8ad6] Youtube\u8981\u79fb\u9664\u6240\u6709\u8cea\u7591\u9078\u8209\u7d50\u679c\u7684\u5f71\u7247\uff1b`\u63a8: \u4eba\u6c11\u5e63\u771f\u9999`\n    - [\u8a0e\u8ad6] Youtube\u8981\u79fb\u9664\u6240\u6709\u8cea\u7591\u9078\u8209\u7d50\u679c\u7684\u5f71\u7247\uff1b\u63a8: \u9019\u4e5f\u592a\u5641\n    - [\u8a0e\u8ad6] Youtube\u8981\u79fb\u9664\u6240\u6709\u8cea\u7591\u9078\u8209\u7d50\u679c\u7684\u5f71\u7247\uff1b\u63a8: \u9019\u9ebc\u53b2\u5bb3\n",
            "readme_url": "https://github.com/s9891326/Fine-Tuning-BERT",
            "frameworks": [
                "scikit-learn",
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Attention Is All You Need",
            "arxiv": "1706.03762",
            "year": 2017,
            "url": "http://arxiv.org/abs/1706.03762v5",
            "abstract": "The dominant sequence transduction models are based on complex recurrent or\nconvolutional neural networks in an encoder-decoder configuration. The best\nperforming models also connect the encoder and decoder through an attention\nmechanism. We propose a new simple network architecture, the Transformer, based\nsolely on attention mechanisms, dispensing with recurrence and convolutions\nentirely. Experiments on two machine translation tasks show these models to be\nsuperior in quality while being more parallelizable and requiring significantly\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\nEnglish-to-German translation task, improving over the existing best results,\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\ntranslation task, our model establishes a new single-model state-of-the-art\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\nof the training costs of the best models from the literature. We show that the\nTransformer generalizes well to other tasks by applying it successfully to\nEnglish constituency parsing both with large and limited training data.",
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N. Gomez",
                "Lukasz Kaiser",
                "Illia Polosukhin"
            ]
        }
    ],
    "domain": {
        "domain_type": "Natural Language Processing",
        "domain_prob": 0.9993879334583531,
        "task": "Machine Translation",
        "task_prob": 0.5027194895045715
    }
}
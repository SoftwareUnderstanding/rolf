{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "pytorch-a3c",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "ikostrikov",
                "owner_type": "User",
                "name": "pytorch-a3c",
                "url": "https://github.com/ikostrikov/pytorch-a3c",
                "stars": 982,
                "pushed_at": "2019-09-25 18:08:56+00:00",
                "created_at": "2017-02-13 03:57:55+00:00",
                "language": "Python",
                "description": "PyTorch implementation of Asynchronous Advantage Actor Critic (A3C) from \"Asynchronous Methods for Deep Reinforcement Learning\".",
                "license": "MIT License",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "8d35cb3277ff6eb0d637147c09e95934604a431c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ikostrikov/pytorch-a3c/blob/master/.gitignore"
                    }
                },
                "size": 18
            },
            {
                "type": "code",
                "name": "LICENSE.md",
                "sha": "0c7ee94257b32209876fce8ca2116e6f84d1c348",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ikostrikov/pytorch-a3c/blob/master/LICENSE.md"
                    }
                },
                "size": 1071
            },
            {
                "type": "code",
                "name": "envs.py",
                "sha": "0724432ad192905acf7952e17af842f070843ce4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ikostrikov/pytorch-a3c/blob/master/envs.py"
                    }
                },
                "size": 1804
            },
            {
                "type": "code",
                "name": "images",
                "sha": "4fff051e2890d1bb717e273a0f8ed10e604ddb97",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ikostrikov/pytorch-a3c/tree/master/images"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "main.py",
                "sha": "bbb81143673b49a9cdf45c28424031f07aefc5cf",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ikostrikov/pytorch-a3c/blob/master/main.py"
                    }
                },
                "size": 2889
            },
            {
                "type": "code",
                "name": "model.py",
                "sha": "2cdff4d10f7550f42872e0c7097ea791592a5a90",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ikostrikov/pytorch-a3c/blob/master/model.py"
                    }
                },
                "size": 2346
            },
            {
                "type": "code",
                "name": "my_optim.py",
                "sha": "298bc2d0cd289f6fc0d8ca5aef35a3615365bb77",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ikostrikov/pytorch-a3c/blob/master/my_optim.py"
                    }
                },
                "size": 2413
            },
            {
                "type": "code",
                "name": "test.py",
                "sha": "00566c3eb5d9a5ea95af9f53502ba0315bc7f240",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ikostrikov/pytorch-a3c/blob/master/test.py"
                    }
                },
                "size": 2014
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "da31b5e995ec62318293f906c6c8b25f4b1e61ec",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ikostrikov/pytorch-a3c/blob/master/train.py"
                    }
                },
                "size": 3294
            }
        ]
    },
    "authors": [
        {
            "name": "Ilya Kostrikov",
            "email": "ikostrikov@gmail.com",
            "github_id": "ikostrikov"
        },
        {
            "name": "Adam Paszke",
            "email": "adam.paszke@gmail.com",
            "github_id": "apaszke"
        },
        {
            "name": "Ethan Caballero",
            "email": "ethanvictorcaballero@gmail.com",
            "github_id": "ethancaballero"
        },
        {
            "name": "Andrew Gambardella",
            "github_id": "atgambardella"
        },
        {
            "name": "Lucas Beyer",
            "email": "lucasb.eyer.be@gmail.com",
            "github_id": "lucasb-eyer"
        },
        {
            "name": "Ben Duffy",
            "email": "benfduffy@gmail.com",
            "github_id": "beduffy"
        },
        {
            "name": "nadavbh12",
            "github_id": "nadavbh12"
        }
    ],
    "tags": [
        "python",
        "reinforcement-learning",
        "pytorch",
        "deep-learning",
        "actor-critic",
        "a3c",
        "pytorch-a3c",
        "asynchronous-methods",
        "deep-reinforcement-learning",
        "asynch",
        "asynchronous-advantage-actor-critic"
    ],
    "description": "PyTorch implementation of Asynchronous Advantage Actor Critic (A3C) from \"Asynchronous Methods for Deep Reinforcement Learning\".",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/ikostrikov/pytorch-a3c",
            "stars": 982,
            "issues": true,
            "readme": "# pytorch-a3c\n\nThis is a PyTorch implementation of Asynchronous Advantage Actor Critic (A3C) from [\"Asynchronous Methods for Deep Reinforcement Learning\"](https://arxiv.org/pdf/1602.01783v1.pdf).\n\nThis implementation is inspired by [Universe Starter Agent](https://github.com/openai/universe-starter-agent).\nIn contrast to the starter agent, it uses an optimizer with shared statistics as in the original paper.\n\nPlease use this bibtex if you want to cite this repository in your publications:\n\n    @misc{pytorchaaac,\n      author = {Kostrikov, Ilya},\n      title = {PyTorch Implementations of Asynchronous Advantage Actor Critic},\n      year = {2018},\n      publisher = {GitHub},\n      journal = {GitHub repository},\n      howpublished = {\\url{https://github.com/ikostrikov/pytorch-a3c}},\n    }\n\n## A2C\n\nI **highly recommend** to check a sychronous version and other algorithms: [pytorch-a2c-ppo-acktr](https://github.com/ikostrikov/pytorch-a2c-ppo-acktr).\n\nIn my experience, A2C works better than A3C and ACKTR is better than both of them. Moreover, PPO is a great algorithm for continuous control. Thus, I recommend to try A2C/PPO/ACKTR first and use A3C only if you need it specifically for some reasons.\n\nAlso read [OpenAI blog](https://blog.openai.com/baselines-acktr-a2c/) for more information.\n\n## Contributions\n\nContributions are very welcome. If you know how to make this code better, don't hesitate to send a pull request.\n\n## Usage\n```bash\n# Works only wih Python 3.\npython3 main.py --env-name \"PongDeterministic-v4\" --num-processes 16\n```\n\nThis code runs evaluation in a separate thread in addition to 16 processes.\n\n## Results\n\nWith 16 processes it converges for PongDeterministic-v4 in 15 minutes.\n![PongDeterministic-v4](images/PongReward.png)\n\nFor BreakoutDeterministic-v4 it takes more than several hours.\n",
            "readme_url": "https://github.com/ikostrikov/pytorch-a3c",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "domain": {
        "domain_type": "Playing Games",
        "domain_prob": 0.9877385488859711
    }
}
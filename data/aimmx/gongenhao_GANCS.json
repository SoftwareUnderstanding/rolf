{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "GANCS",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "gongenhao",
                "owner_type": "User",
                "name": "GANCS",
                "url": "https://github.com/gongenhao/GANCS",
                "stars": 88,
                "pushed_at": "2017-12-18 02:38:38+00:00",
                "created_at": "2017-04-28 03:20:19+00:00",
                "language": "Jupyter Notebook",
                "description": "Compressed Sensing MRI based on Deep Generative Adversarial Network ",
                "license": "MIT License",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".DS_Store",
                "sha": "2fe774ea2f7dcc7fe2412aa66820a3cda68b9674",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/gongenhao/GANCS/blob/master/.DS_Store"
                    }
                },
                "size": 8196
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "125866914f2cf53d871c0ca9030432c4d6ad7321",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/gongenhao/GANCS/blob/master/.gitignore"
                    }
                },
                "size": 13
            },
            {
                "type": "code",
                "name": "LICENSE.md",
                "sha": "de78b6b2d2960be5444df017be1c82fd3a984efb",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/gongenhao/GANCS/blob/master/LICENSE.md"
                    }
                },
                "size": 1069
            },
            {
                "type": "code",
                "name": "Ratings",
                "sha": "34928e30d9c4ffabee28ee163084b785cdeeb31b",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/gongenhao/GANCS/tree/master/Ratings"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "Training_Data_Generation",
                "sha": "ddd8a4c0bbc62725a94e13c3d5cf14d452e07e94",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/gongenhao/GANCS/tree/master/Training_Data_Generation"
                    }
                },
                "num_files": 7
            },
            {
                "type": "code",
                "name": "sample_command.sh",
                "sha": "90221455aa89451f72a392c8a7cbecd1da278f13",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/gongenhao/GANCS/blob/master/sample_command.sh"
                    }
                },
                "size": 540
            },
            {
                "type": "code",
                "name": "srez_demo.py",
                "sha": "76fc6985739694012547b6aa33ce8d5f041fe296",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/gongenhao/GANCS/blob/master/srez_demo.py"
                    }
                },
                "size": 755
            },
            {
                "type": "code",
                "name": "srez_input.py",
                "sha": "7c4e9cb2a89eff145af77b3bda1086e3a49b4e0e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/gongenhao/GANCS/blob/master/srez_input.py"
                    }
                },
                "size": 5297
            },
            {
                "type": "code",
                "name": "srez_main.py",
                "sha": "7b51b32b2101afb15a2676d0d5b753b54964d83d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/gongenhao/GANCS/blob/master/srez_main.py"
                    }
                },
                "size": 22049
            },
            {
                "type": "code",
                "name": "srez_model.py",
                "sha": "e5f94392938d141342988e987c6f05ef041f5bc1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/gongenhao/GANCS/blob/master/srez_model.py"
                    }
                },
                "size": 46758
            },
            {
                "type": "code",
                "name": "srez_train.py",
                "sha": "2fde1d12175d05f80553e13181ef066f40f9aa04",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/gongenhao/GANCS/blob/master/srez_train.py"
                    }
                },
                "size": 11050
            }
        ]
    },
    "authors": [
        {
            "name": "Enhao Gong",
            "email": "enhaog@stanford.edu",
            "github_id": "gongenhao"
        },
        {
            "name": "Morteza Mardani",
            "email": "morteza@stanford.edu",
            "github_id": "MortezaMardani"
        },
        {
            "name": "Xiaolin Lin",
            "email": "xlin615@gmail.com",
            "github_id": "shallinlin"
        }
    ],
    "tags": [],
    "description": "Compressed Sensing MRI based on Deep Generative Adversarial Network ",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/gongenhao/GANCS",
            "stars": 88,
            "issues": true,
            "readme": "# GANCS\nCompressed Sensing MRI based on Generative Adversarial Network \n\n# Introduction\n\n## First Authors:\nMorteza Mardani, Enhao Gong\n\n## Arxiv Paper\nDeep Generative Adversarial Networks for Compressed Sensing Automates MRI\nArxiv Paper: https://arxiv.org/abs/1706.00051\n\n## References:\nThe basic code base is derived from super resolution github repo. https://github.com/david-gpu/srez\n\nhttps://github.com/david-gpu/srez\nhttps://arxiv.org/abs/1609.04802\nhttps://github.com/carpedm20/DCGAN-tensorflow\nhttp://wiseodd.github.io/techblog/2017/03/02/least-squares-gan/\nhttp://wiseodd.github.io/techblog/2017/02/04/wasserstein-gan/\n\n\n# Method\n\n## Deep Generative Adversarial Networks for CS MRI\nMagnetic resonance imaging (MRI) suffers from aliasing artifacts when it is highly undersampled for fast imaging. Conventional CS MRI reconstruction uses regularized iterative reconstruction based on pre-defined sparsity transform, which usually include time-consuming iterative optimization and may result in undesired artifacts such as oversmoothing. Here we propose a novel CS framework that permeates benefits from deep learning and generative adversarial networks (GAN) to modeling a manifold of MR images from historical patients. Extensive evaluations on a large MRI datasets of pediatric pateints show it results in superior perforamnce, retrieves image with improved quality and finer details relative to conventional CS and pixel-wise deep learning schemes. \n\n## Undersampling\n### 1D undersampling\n1D undersampling is generated using the variable density distribution. \n`R_factor` defines the desired reduction factor, which controls how many samples to randomly pick. \n`R_alpha` defines the decay of VD distribution with formula `p=x^alpha`.\n`R_seed` defines the random seed used, for negative values there is no fixed undersampling pattern.\n\n### 1D/2D undersampling\n`sampling_pattern` can be a path to .mat file for specific 1D/2D undersampling mask\n\n\n## Generator Model\nSeveral models are explored including ResNet-ish models from super-resolution paper and encoder-decoder models.\n\n## Descriminator Model\nCurrently we are using 4*(Conv-BN-RELU-POOL)+2*(CONV-BN-RELU)+CONV+MEAN+softmax (for logloss)\n\n### descriminator related loss\nWe have been exploring different loss functions for GAN, including:\n\n* log-loss\n* LS loss (better than log-loss, use as default, easy to tune and optimize)\n* Cycle-GAN/WGAN loss (todo)\n\n### Loss formulation\nLoss is a mixed combination with: 1) Data consistency loss, 2) pixel-wise MSE/L1/L2 loss and 3) LS-GAN loss\n\n`FLAGS.gene_log_factor = 0 # log loss vs least-square loss`\n\n`FLAGS.gene_dc_factor = 0.9 # data-consistency (kspace) loss vs generator loss`\n\n`FLAGS.gene_mse_factor = 0.001 # simple MSE loss originally for forward-passing model vs GAN loss`\nGAN loss = generator loss + discriminator loss\n\n`gene_fool_loss = FLAGS.gene_log_factor * gene_log_loss + (1-FLAGS.gene_log_factor) * gene_LS_loss`\n\n`gene_non_mse_loss = FLAGS.gene_dc_factor * gene_dc_loss + (1-FLAGS.gene_dc_factor) * gene_fool_loss`\n\n`gene_loss = FLAGS.gene_mse_factor * gene_mse_loss + (1- FLAGS.gene_mse_factor) * gene_non_mse_loss`\n\n## Dataset\nDataset is parsed to pngs saved in specific folders\n* Phantom dataset\n* Knee dataset\n* DCE dataset\n\n## Results\nMultiple results are exported while traning\n* loss changes\n* test results (zero-fill VS Recon VS Ref) saved to png for each epoch\n* some of the train results are exported to png, WARNING, there was a memory bug before when we try to export all train results\n* layers (some layers are skipped) of generator and detectors are exported into json after each epoch.\n\n\n# Code structures\n\n## Files\n* `srez_main.py` handles commendline arguments\n* `srez_input.py` loads from input files, conducting undersampling or loading/extracting the undersampled patterns, \n* `srez_model.py` defines Generator and Discriminator models\n* `srez_train.py` trains model in batch and export checkpoints and results for progress summaries \n\n## Usage example:\n\n### Training example \n(currently working on t2)\n`python srez_main.py --dataset_input /home/enhaog/GANCS/srez/dataset_MRI/phantom --batch_size 8 --run train --summary_period 123 --sample_size 256 --train_time 10  --train_dir train_save_all --R_factor 4 --R_alpha 3 --R_seed 0`              \n\n(currently working on t2 for DCE)\n`python srez_main.py --run train --dataset_input /home/enhaog/GANCS/srez/dataset_MRI/abdominal_DCE --sample_size 200 --sample_size_y 100 --sampling_pattern /home/enhaog/GANCS/srez/dataset_MRI/sampling_pattern_DCE/mask_2dvardesnity_radiaview_4fold.mat --batch_size 4  --summary_period 125 --sample_test 32 --sample_train 10000 --train_time 200  --train_dir train_DCE_test `\n\n",
            "readme_url": "https://github.com/gongenhao/GANCS",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network",
            "arxiv": "1609.04802",
            "year": 2016,
            "url": "http://arxiv.org/abs/1609.04802v5",
            "abstract": "Despite the breakthroughs in accuracy and speed of single image\nsuper-resolution using faster and deeper convolutional neural networks, one\ncentral problem remains largely unsolved: how do we recover the finer texture\ndetails when we super-resolve at large upscaling factors? The behavior of\noptimization-based super-resolution methods is principally driven by the choice\nof the objective function. Recent work has largely focused on minimizing the\nmean squared reconstruction error. The resulting estimates have high peak\nsignal-to-noise ratios, but they are often lacking high-frequency details and\nare perceptually unsatisfying in the sense that they fail to match the fidelity\nexpected at the higher resolution. In this paper, we present SRGAN, a\ngenerative adversarial network (GAN) for image super-resolution (SR). To our\nknowledge, it is the first framework capable of inferring photo-realistic\nnatural images for 4x upscaling factors. To achieve this, we propose a\nperceptual loss function which consists of an adversarial loss and a content\nloss. The adversarial loss pushes our solution to the natural image manifold\nusing a discriminator network that is trained to differentiate between the\nsuper-resolved images and original photo-realistic images. In addition, we use\na content loss motivated by perceptual similarity instead of similarity in\npixel space. Our deep residual network is able to recover photo-realistic\ntextures from heavily downsampled images on public benchmarks. An extensive\nmean-opinion-score (MOS) test shows hugely significant gains in perceptual\nquality using SRGAN. The MOS scores obtained with SRGAN are closer to those of\nthe original high-resolution images than to those obtained with any\nstate-of-the-art method.",
            "authors": [
                "Christian Ledig",
                "Lucas Theis",
                "Ferenc Huszar",
                "Jose Caballero",
                "Andrew Cunningham",
                "Alejandro Acosta",
                "Andrew Aitken",
                "Alykhan Tejani",
                "Johannes Totz",
                "Zehan Wang",
                "Wenzhe Shi"
            ]
        },
        {
            "title": "Deep Generative Adversarial Networks for Compressed Sensing Automates MRI",
            "arxiv": "1706.00051",
            "year": 2017,
            "url": "http://arxiv.org/abs/1706.00051v1",
            "abstract": "Magnetic resonance image (MRI) reconstruction is a severely ill-posed linear\ninverse task demanding time and resource intensive computations that can\nsubstantially trade off {\\it accuracy} for {\\it speed} in real-time imaging. In\naddition, state-of-the-art compressed sensing (CS) analytics are not cognizant\nof the image {\\it diagnostic quality}. To cope with these challenges we put\nforth a novel CS framework that permeates benefits from generative adversarial\nnetworks (GAN) to train a (low-dimensional) manifold of diagnostic-quality MR\nimages from historical patients. Leveraging a mixture of least-squares (LS)\nGANs and pixel-wise $\\ell_1$ cost, a deep residual network with skip\nconnections is trained as the generator that learns to remove the {\\it\naliasing} artifacts by projecting onto the manifold. LSGAN learns the texture\ndetails, while $\\ell_1$ controls the high-frequency noise. A multilayer\nconvolutional neural network is then jointly trained based on diagnostic\nquality images to discriminate the projection quality. The test phase performs\nfeed-forward propagation over the generator network that demands a very low\ncomputational overhead. Extensive evaluations are performed on a large\ncontrast-enhanced MR dataset of pediatric patients. In particular, images rated\nbased on expert radiologists corroborate that GANCS retrieves high contrast\nimages with detailed texture relative to conventional CS, and pixel-wise\nschemes. In addition, it offers reconstruction under a few milliseconds, two\norders of magnitude faster than state-of-the-art CS-MRI schemes.",
            "authors": [
                "Morteza Mardani",
                "Enhao Gong",
                "Joseph Y. Cheng",
                "Shreyas Vasanawala",
                "Greg Zaharchuk",
                "Marcus Alley",
                "Neil Thakur",
                "Song Han",
                "William Dally",
                "John M. Pauly",
                "Lei Xing"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "MR"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.999994642516602,
        "task": "Image Generation",
        "task_prob": 0.9261046902113291
    }
}
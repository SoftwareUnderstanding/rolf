{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Image-colorization-using-CycleGAN",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "ArkaJU",
                "owner_type": "User",
                "name": "Image-Colorization-CycleGAN",
                "url": "https://github.com/ArkaJU/Image-Colorization-CycleGAN",
                "stars": 16,
                "pushed_at": "2021-05-30 09:51:42+00:00",
                "created_at": "2018-10-19 18:57:05+00:00",
                "language": "Python",
                "description": "Colorization of grayscale images using CycleGAN in TensorFlow.",
                "license": "MIT License",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "d242bb9433cd496d544eb378b658c5b76c8fefd4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ArkaJU/Image-Colorization-CycleGAN/blob/master/LICENSE"
                    }
                },
                "size": 1066
            },
            {
                "type": "code",
                "name": "images",
                "sha": "2df1246246736579440c189a97667dfd61e0d5e7",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ArkaJU/Image-Colorization-CycleGAN/tree/master/images"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "main.ipynb",
                "sha": "a38770aace6c0421611e869f070c7e115c4c3694",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ArkaJU/Image-Colorization-CycleGAN/blob/master/main.ipynb"
                    }
                },
                "size": 989
            },
            {
                "type": "code",
                "name": "model.py",
                "sha": "8fc5646f87d31954f9a50506b149082083ca9dd4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ArkaJU/Image-Colorization-CycleGAN/blob/master/model.py"
                    }
                },
                "size": 10147
            },
            {
                "type": "code",
                "name": "module.py",
                "sha": "4f591d348fce01a4f62d44e87b4ddc60eb4fcb98",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ArkaJU/Image-Colorization-CycleGAN/blob/master/module.py"
                    }
                },
                "size": 6654
            },
            {
                "type": "code",
                "name": "ops.py",
                "sha": "d27f48b98a0fb05f4226dd350c09f8799bccea27",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ArkaJU/Image-Colorization-CycleGAN/blob/master/ops.py"
                    }
                },
                "size": 2254
            },
            {
                "type": "code",
                "name": "utils.py",
                "sha": "81e83cf72bde9a158ffa4b7a727be9984e2ce380",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ArkaJU/Image-Colorization-CycleGAN/blob/master/utils.py"
                    }
                },
                "size": 3783
            }
        ]
    },
    "authors": [
        {
            "name": "Arka Saha",
            "github_id": "ArkaJU"
        }
    ],
    "tags": [
        "generative-adversarial-network",
        "cyclegan",
        "image-colorization",
        "deep-learning",
        "computer-vision"
    ],
    "description": "Colorization of grayscale images using CycleGAN in TensorFlow.",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/ArkaJU/Image-Colorization-CycleGAN",
            "stars": 16,
            "issues": true,
            "readme": "# Image-colorization-using-CycleGAN\n\n# Introduction\n\nAutomatic image colorization has been a popular image-to-image translation problem of significant interest for several practical application areas including restoration of aged or degraded images. This project attempts to utilize CycleGANs to colorize grayscale images back to their colorful RGB form.\n\n# Overview\n\nImage-to-image  translation  is  a  class  of  vision  and graphics problems where the goal is to learn the mapping\nbetween an input image and an output image using a training set of aligned image pairs. But for many tasks, paired training data may not be available like this problem of image colorization. This is where the power of CycleGAN becomes apparent. Superiority of CycleGAN has been demonstrated on several tasks where paired training data hardly exist, e.g., in object transfiguration and painting style and season transfer\n\n# Model\n\nGenerative Adversarial Networks(GANs) are composed of two models:\n1. Generator: Aims to generate new data similar to the expected one. The Generator could be related to a human art forger, which creates fake works of art.\n2. Discriminator: It's goal is to recognize if an input data is \u2018real\u2019\u200a\u2014\u200abelongs to the original dataset\u200a\u2014\u200aor if it is \u2018fake\u2019\u200a\u2014\u200agenerated by a forger. In this scenario, a Discriminator is analogous to  an art expert, who tries to detect artworks as truthful or fraud.\n\nThe CycleGAN consists of 2 generators and discriminators. One generator maps from domain A to B and the other one, from B to A.\nThey compete with their corresponding adversarial discriminators.\n\n\nTo regularize the model, the authors introduce the constraint of cycle-consistency - if we transform from source distribution to target and then back again to source distribution, we should get samples from our source distribution.\n\n![](images/CycleLoss.png)\n\n# Data\n\nThe experiment was done on 2 datasets: \n1. Grayscale of flowers(domain A) and their RGB version(domain B): 2K images in each folder.\n2. Frames extracted from old B&W movies(domain A) and new movies (domain B): 24K images in each folder.\n\nThe second problem is a very interesting one as the frames are taken from very old movies(1950s and before) and there is no scope for paired data, making this a useful application for CycleGAN.\n\n# Training\n\nThe models were trained on a GPU. It took about 15 hours for the first model to train. The 2nd model took a bit longer to achieve decent results, after training about 20 hours. Sample results were frequently monitored through TensorBoard.\n\n# Results\n\nThe first model yielded fine results. Some of the best ones are shown below:\n![](images/results/1.PNG)\n![](images/results/2.PNG)\n\n\nFor the second model the results were also good, some of which are shown below:\n![](images/results/3.PNG)\n![](images/results/4.PNG)\n\n\n# References\n- Original Paper: [Arxiv](https://arxiv.org/abs/1703.10593)\n- Base project [Github](https://github.com/xhujoy/CycleGAN-tensorflow)\n- Dataset: https://drive.google.com/file/d/1-3DKl_h5NkJWyXib-AVf4ioPY236lsgM/view?usp=sharing\n",
            "readme_url": "https://github.com/ArkaJU/Image-Colorization-CycleGAN",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks",
            "arxiv": "1703.10593",
            "year": 2017,
            "url": "http://arxiv.org/abs/1703.10593v7",
            "abstract": "Image-to-image translation is a class of vision and graphics problems where\nthe goal is to learn the mapping between an input image and an output image\nusing a training set of aligned image pairs. However, for many tasks, paired\ntraining data will not be available. We present an approach for learning to\ntranslate an image from a source domain $X$ to a target domain $Y$ in the\nabsence of paired examples. Our goal is to learn a mapping $G: X \\rightarrow Y$\nsuch that the distribution of images from $G(X)$ is indistinguishable from the\ndistribution $Y$ using an adversarial loss. Because this mapping is highly\nunder-constrained, we couple it with an inverse mapping $F: Y \\rightarrow X$\nand introduce a cycle consistency loss to push $F(G(X)) \\approx X$ (and vice\nversa). Qualitative results are presented on several tasks where paired\ntraining data does not exist, including collection style transfer, object\ntransfiguration, season transfer, photo enhancement, etc. Quantitative\ncomparisons against several prior methods demonstrate the superiority of our\napproach.",
            "authors": [
                "Jun-Yan Zhu",
                "Taesung Park",
                "Phillip Isola",
                "Alexei A. Efros"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999691232977771,
        "task": "Image-to-Image Translation",
        "task_prob": 0.9889318148450864
    }
}
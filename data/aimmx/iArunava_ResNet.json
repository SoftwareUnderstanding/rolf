{
    "visibility": {
        "visibility": "public",
        "license": "BSD 3-Clause \"New\" or \"Revised\" License"
    },
    "name": "ResNet",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "iArunava",
                "owner_type": "User",
                "name": "ResNet",
                "url": "https://github.com/iArunava/ResNet",
                "stars": 7,
                "pushed_at": "2019-03-20 11:41:10+00:00",
                "created_at": "2019-02-10 04:32:44+00:00",
                "language": "Python",
                "description": "In this repository I will reproduce the resnet paper",
                "license": "BSD 3-Clause \"New\" or \"Revised\" License",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "894a44cc066a027465cd26d634948d56d13af9af",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iArunava/ResNet/blob/master/.gitignore"
                    }
                },
                "size": 1203
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "96b13140171dc93ee4cc57297ba682f62b8af93f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iArunava/ResNet/blob/master/LICENSE"
                    }
                },
                "size": 1507
            },
            {
                "type": "code",
                "name": "models",
                "sha": "7a03f7902dc8c44cc6e532ec84d97a96e95d79d8",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iArunava/ResNet/tree/master/models"
                    }
                },
                "num_files": 4
            }
        ]
    },
    "authors": [
        {
            "name": "Arunava",
            "github_id": "iArunava"
        }
    ],
    "tags": [],
    "description": "In this repository I will reproduce the resnet paper",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/iArunava/ResNet",
            "stars": 7,
            "issues": true,
            "readme": "# ResNet\n\nIn this repository, I have duplicated the ResNet paper. Each of the modules of the ResNet is seperated in a file so users can utilize each\nblock of the resnet seperately and use the ResNet Blocks in their architectures. The link to the paper can be found here: https://arxiv.org/pdf/1512.03385.pdf\n\nThe Repository contains the code to create all 5 ResNet architectures:\n- ResNet18\n- ResNet34\n- ResNet50\n- ResNet101\n- ResNet152\n\n```\n>>> # To get the ResNet18 use\n>>> ResNet(nc, ResNetBlock2L, [2, 2, 2, 2])\n>>>\n>>> # To get the ResNet34 use\n>>> ResNet(nc, ResNetBlock2L, [3, 4, 6, 3])\n>>>\n>>> # To get the ResNet50 use\n>>> ResNet(nc, ResNetBlock3L, [3, 4, 6, 3])\n>>>\n>>> # To get the ResNet101 use\n>>> ResNet(nc, ResNetBlock3L, [3, 4, 23 3])\n>>>\n>>> To get the ResNet152 use\n>>> ResNet(nc, ResNetBlock3L, [3, 8, 36, 3])\n```\n\n## Pretrained Models\n\n1. ResNet18 - CIFAR10 - 83.9% - [Download](https://drive.google.com/file/d/1JLZ5h15yF7e6QBzXrZrzEE6i98SrQylA/view?usp=sharing)\n\n## References\n\n1. Deep Residual Learning for Image Recognition He et al. [Paper](https://arxiv.org/pdf/1512.03385.pdf)\n2. Identity Mappings in Deep Residual Networks He et al. [Paper](https://arxiv.org/pdf/1603.05027.pdf)\n\n## License\n\nThe code in this repository is free to use and modify for both commercial and non-commercial use.\nIf possible, just refer back to this repository.\n",
            "readme_url": "https://github.com/iArunava/ResNet",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Deep Residual Learning for Image Recognition",
            "arxiv": "1512.03385",
            "year": 2015,
            "url": "http://arxiv.org/abs/1512.03385v1",
            "abstract": "Deeper neural networks are more difficult to train. We present a residual\nlearning framework to ease the training of networks that are substantially\ndeeper than those used previously. We explicitly reformulate the layers as\nlearning residual functions with reference to the layer inputs, instead of\nlearning unreferenced functions. We provide comprehensive empirical evidence\nshowing that these residual networks are easier to optimize, and can gain\naccuracy from considerably increased depth. On the ImageNet dataset we evaluate\nresidual nets with a depth of up to 152 layers---8x deeper than VGG nets but\nstill having lower complexity. An ensemble of these residual nets achieves\n3.57% error on the ImageNet test set. This result won the 1st place on the\nILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100\nand 1000 layers.\n  The depth of representations is of central importance for many visual\nrecognition tasks. Solely due to our extremely deep representations, we obtain\na 28% relative improvement on the COCO object detection dataset. Deep residual\nnets are foundations of our submissions to ILSVRC & COCO 2015 competitions,\nwhere we also won the 1st places on the tasks of ImageNet detection, ImageNet\nlocalization, COCO detection, and COCO segmentation.",
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ]
        },
        {
            "title": "Identity Mappings in Deep Residual Networks",
            "arxiv": "1603.05027",
            "year": 2016,
            "url": "http://arxiv.org/abs/1603.05027v3",
            "abstract": "Deep residual networks have emerged as a family of extremely deep\narchitectures showing compelling accuracy and nice convergence behaviors. In\nthis paper, we analyze the propagation formulations behind the residual\nbuilding blocks, which suggest that the forward and backward signals can be\ndirectly propagated from one block to any other block, when using identity\nmappings as the skip connections and after-addition activation. A series of\nablation experiments support the importance of these identity mappings. This\nmotivates us to propose a new residual unit, which makes training easier and\nimproves generalization. We report improved results using a 1001-layer ResNet\non CIFAR-10 (4.62% error) and CIFAR-100, and a 200-layer ResNet on ImageNet.\nCode is available at: https://github.com/KaimingHe/resnet-1k-layers",
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999999686260704,
        "task": "Object Detection",
        "task_prob": 0.9925170745758959
    },
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            },
            {
                "name": "ImageNet Detection"
            },
            {
                "name": "ILSVRC 2015"
            },
            {
                "name": "CIFAR-100"
            },
            {
                "name": "CIFAR-10"
            },
            {
                "name": "COCO"
            }
        ]
    }
}
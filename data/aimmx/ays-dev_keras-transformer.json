{
    "visibility": {
        "visibility": "public"
    },
    "name": "Requirements",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "ays-dev",
                "owner_type": "User",
                "name": "keras-transformer",
                "url": "https://github.com/ays-dev/keras-transformer",
                "stars": 4,
                "pushed_at": "2022-02-13 10:57:07+00:00",
                "created_at": "2021-02-18 15:53:49+00:00",
                "language": "Python",
                "description": "Transformer",
                "frameworks": [
                    "NLTK",
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "43ac309c246315c876419b412a208257d08defe3",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ays-dev/keras-transformer/blob/master/.gitignore"
                    }
                },
                "size": 119
            },
            {
                "type": "code",
                "name": "dataset.py",
                "sha": "6283960a1ff0ef64693d36aa3a810c1f003acf9b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ays-dev/keras-transformer/blob/master/dataset.py"
                    }
                },
                "size": 2316
            },
            {
                "type": "code",
                "name": "dic-en.txt",
                "sha": "e58aabacec634b587c122191c33179d3e40c4f12",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ays-dev/keras-transformer/blob/master/dic-en.txt"
                    }
                },
                "size": 244215
            },
            {
                "type": "code",
                "name": "dic-fr.txt",
                "sha": "69de8a41fa52701562bae829f9cee3f13f5b98cd",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ays-dev/keras-transformer/blob/master/dic-fr.txt"
                    }
                },
                "size": 476403
            },
            {
                "type": "code",
                "name": "fr-en-train.txt",
                "sha": "c7c5fea99cea9e622431f96e3fc70513c0dc258b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ays-dev/keras-transformer/blob/master/fr-en-train.txt"
                    }
                },
                "size": 28006156
            },
            {
                "type": "code",
                "name": "logs",
                "sha": "f1517a3649a4757410d0861fe48f4fa5a242f24a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ays-dev/keras-transformer/tree/master/logs"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "model.py",
                "sha": "8332e12abd6f2829bbfb70e8e49334d98271c0d2",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ays-dev/keras-transformer/blob/master/model.py"
                    }
                },
                "size": 1559
            },
            {
                "type": "code",
                "name": "models",
                "sha": "0f7e37e9739e109acd2af5882b8c834130ca1020",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ays-dev/keras-transformer/tree/master/models"
                    }
                },
                "num_files": 8
            },
            {
                "type": "code",
                "name": "params.py",
                "sha": "c35d7bdf7104a7fb9b5d2569b4a485f7be2460f4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ays-dev/keras-transformer/blob/master/params.py"
                    }
                },
                "size": 2787
            },
            {
                "type": "code",
                "name": "predict.py",
                "sha": "51787de6b556243bae2bc58dfb16586661da19d1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ays-dev/keras-transformer/blob/master/predict.py"
                    }
                },
                "size": 1258
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "b4b055cce080585e6167b108a0926f4fbdfd484f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ays-dev/keras-transformer/blob/master/requirements.txt"
                    }
                },
                "size": 42
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "f1c7dd3822558c7c1099ad84be2ab165c5bff17a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ays-dev/keras-transformer/blob/master/train.py"
                    }
                },
                "size": 1811
            },
            {
                "type": "code",
                "name": "utils",
                "sha": "c1334435fabcbc7b1cd269eb16c3fdf7db3cfea6",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/ays-dev/keras-transformer/tree/master/utils"
                    }
                },
                "num_files": 6
            }
        ]
    },
    "authors": [
        {
            "name": "dev",
            "github_id": "ays-dev"
        }
    ],
    "tags": [],
    "description": "Transformer",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/ays-dev/keras-transformer",
            "stars": 4,
            "issues": true,
            "readme": "### Requirements\n\n```\n$ cat requirements.txt && pip install -r requirements.txt\n```\n\n```\ntensorflow==2.3.0\nnumpy==1.18.5\nnltk==3.5\n```\n\n```\n$ tensorboard --version\n> 2.4.1\n\n$ pip --version\n> pip 21.0.1 from /Users/ays-dev/opt/anaconda3/envs/tf/lib/python3.7/site-packages/pip (python 3.7)\n\n$ python --version\n> Python 3.7.9\n```\n\n\n### Train\n``python train.py``\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\nfrom dataset import get_dataset, prepare_dataset\nfrom model import get_model\n\n\ndataset = get_dataset(\"fr-en\")\n\nprint(\"Dataset loaded. Length:\", len(dataset), \"lines\")\n\ntrain_dataset = dataset[0:100000]\n\nprint(\"Train data loaded. Length:\", len(train_dataset), \"lines\")\n\n(encoder_input,\ndecoder_input,\ndecoder_output,\nencoder_vocab,\ndecoder_vocab,\nencoder_inverted_vocab,\ndecoder_inverted_vocab) = prepare_dataset(\n  train_dataset,\n  shuffle = False,\n  lowercase = True,\n  max_window_size = 20\n)\n\ntransformer_model = get_model(\n  EMBEDDING_SIZE = 64,\n  ENCODER_VOCAB_SIZE = len(encoder_vocab),\n  DECODER_VOCAB_SIZE = len(decoder_vocab),\n  ENCODER_LAYERS = 2,\n  DECODER_LAYERS = 2,\n  NUMBER_HEADS = 4,\n  DENSE_LAYER_SIZE = 128\n)\n\ntransformer_model.compile(\n  optimizer = \"adam\",\n  loss = [\n    \"sparse_categorical_crossentropy\"\n  ],\n  metrics = [\n    \"accuracy\"\n  ]\n)\n\ntransformer_model.summary()\n\nx = [np.array(encoder_input), np.array(decoder_input)]\ny = np.array(decoder_output)\n\nname = \"transformer\"\ncheckpoint_filepath = \"./logs/transformer_ep-{epoch:02d}_loss-{loss:.2f}_acc-{accuracy:.2f}.ckpt\"\n\ntensorboard_callback = tf.keras.callbacks.TensorBoard(\n  log_dir = \"logs/{}\".format(name)\n)\n\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n  filepath = checkpoint_filepath,\n  monitor = \"val_accuracy\",\n  mode = \"max\",\n  save_weights_only = True,\n  save_best_only = True,\n  verbose = True\n)\n\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(\n  monitor = \"val_accuracy\",\n  mode = \"max\",\n  patience = 2,\n  min_delta = 0.001,\n  verbose = True\n)\n\ntransformer_model.fit(\n  x,\n  y,\n  epochs = 15,\n  batch_size = 32,\n  validation_split = 0.1,\n  callbacks=[\n    model_checkpoint_callback,\n    tensorboard_callback,\n    early_stopping_callback\n  ]\n)\n```\n\n\n##### Output\n\n```\nDataset loaded. Length: 185583 lines\nTrain data loaded. Length: 100000 lines\nModel: \"Transformer-Model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to\n==================================================================================================\nEncoder-Input (InputLayer)      [(None, None)]       0\n__________________________________________________________________________________________________\nDecoder-Input (InputLayer)      [(None, None)]       0\n__________________________________________________________________________________________________\nEncoder-Word-Embedding (WordEmb (None, None, 64)     1110016     Encoder-Input[0][0]\n__________________________________________________________________________________________________\nDecoder-Word-Embedding (WordEmb (None, None, 64)     579456      Decoder-Input[0][0]\n__________________________________________________________________________________________________\nEncoder-Positional-Embedding (P (None, None, 64)     0           Encoder-Word-Embedding[0][0]\n__________________________________________________________________________________________________\nDecoder-Positional-Embedding (P (None, None, 64)     0           Decoder-Word-Embedding[0][0]\n__________________________________________________________________________________________________\nEncoder (Encoder)               (None, None, 64)     66944       Encoder-Positional-Embedding[0][0\n__________________________________________________________________________________________________\nDecoder (Decoder)               (None, None, 64)     100480      Decoder-Positional-Embedding[0][0\n                                                                 Encoder[0][0]\n__________________________________________________________________________________________________\nDecoder-Output (Dense)          (None, None, 9054)   588510      Decoder[0][0]\n==================================================================================================\nTotal params: 2,445,406\nTrainable params: 2,445,406\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/15\n2813/2813 [==============================] - ETA: 0s - loss: 1.0506 - accuracy: 0.8396\nEpoch 00001: val_accuracy improved from -inf to 0.84285, saving model to ./logs/transformer_ep-01_loss-1.05_acc-0.84.ckpt\n2813/2813 [==============================] - 1010s 359ms/step - loss: 1.0506 - accuracy: 0.8396 - val_loss: 0.9235 - val_accuracy: 0.8429\nEpoch 2/15\n2813/2813 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.9142\nEpoch 00002: val_accuracy improved from 0.84285 to 0.87188, saving model to ./logs/transformer_ep-02_loss-0.46_acc-0.91.ckpt\n2813/2813 [==============================] - 962s 342ms/step - loss: 0.4577 - accuracy: 0.9142 - val_loss: 0.7430 - val_accuracy: 0.8719\nEpoch 3/15\n2813/2813 [==============================] - ETA: 0s - loss: 0.3159 - accuracy: 0.9340\nEpoch 00003: val_accuracy improved from 0.87188 to 0.88687, saving model to ./logs/transformer_ep-03_loss-0.32_acc-0.93.ckpt\n2813/2813 [==============================] - 959s 341ms/step - loss: 0.3159 - accuracy: 0.9340 - val_loss: 0.6626 - val_accuracy: 0.8869\n...\nEpoch 8/15\n2813/2813 [==============================] - ETA: 0s - loss: 0.1545 - accuracy: 0.9600\nEpoch 00008: val_accuracy improved from 0.89448 to 0.89624, saving model to ./logs/transformer_ep-08_loss-0.15_acc-0.96.ckpt\n2813/2813 [==============================] - 910s 324ms/step - loss: 0.1545 - accuracy: 0.9600 - val_loss: 0.6334 - val_accuracy: 0.8962\nEpoch 9/15\n2813/2813 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.9621\nEpoch 00009: val_accuracy improved from 0.89624 to 0.89654, saving model to ./logs/transformer_ep-09_loss-0.14_acc-0.96.ckpt\n2813/2813 [==============================] - 903s 321ms/step - loss: 0.1441 - accuracy: 0.9621 - val_loss: 0.6387 - val_accuracy: 0.8965\nEpoch 10/15\n2813/2813 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9640\nEpoch 00010: val_accuracy did not improve from 0.89654\n2813/2813 [==============================] - 913s 324ms/step - loss: 0.1346 - accuracy: 0.9640 - val_loss: 0.6730 - val_accuracy: 0.8933\nEpoch 00010: early stopping\n```\n\n\n### Predict\n``python predict.py``\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\nfrom dataset import get_dataset, prepare_dataset\nfrom model import get_model\nfrom utils.make_translate import make_translate\n\n\ndataset = get_dataset(\"fr-en\")\n\nprint(\"Dataset loaded. Length:\", len(dataset), \"lines\")\n\ntrain_dataset = dataset[0:100000]\n\nprint(\"Train data loaded. Length:\", len(train_dataset), \"lines\")\n\n(encoder_input,\ndecoder_input,\ndecoder_output,\nencoder_vocab,\ndecoder_vocab,\nencoder_inverted_vocab,\ndecoder_inverted_vocab) = prepare_dataset(\n  train_dataset,\n  shuffle = False,\n  lowercase = True,\n  max_window_size = 20\n)\n\ntransformer_model = get_model(\n  EMBEDDING_SIZE = 64,\n  ENCODER_VOCAB_SIZE = len(encoder_vocab),\n  DECODER_VOCAB_SIZE = len(decoder_vocab),\n  ENCODER_LAYERS = 2,\n  DECODER_LAYERS = 2,\n  NUMBER_HEADS = 4,\n  DENSE_LAYER_SIZE = 128\n)\n\ntransformer_model.summary()\n\ntransformer_model.load_weights('./logs/transformer_ep-10_loss-0.14_acc-0.96.ckpt')\n\ntranslate = make_translate(transformer_model, encoder_vocab, decoder_vocab, decoder_inverted_vocab)\n\ntranslate(\"c'est une belle journ\u00e9e .\")\ntranslate(\"j'aime manger du g\u00e2teau .\")\ntranslate(\"c'est une bonne chose .\")\ntranslate(\"il faut faire \u00e0 manger pour nourrir les gens .\")\ntranslate(\"tom a achet\u00e9 un nouveau v\u00e9lo .\")\n```\n\n\n##### Output\n\n```\nOriginal: c'est une belle journ\u00e9e .\nTraduction: it' s a beautiful day .\nOriginal: j'aime manger du g\u00e2teau .\nTraduction: i like to eat some cake .\nOriginal: c'est une bonne chose .\nTraduction: that' s a good thing .\nOriginal: il faut faire \u00e0 manger pour nourrir les gens .\nTraduction: we have to feed the people .\nOriginal: tom a achet\u00e9 un nouveau v\u00e9lo .\nTraduction: tom bought a new bicycle .\n```\n\n\n### Fine-tuning\n``python params.py``\n\n```python\nimport tensorflow as tf\nimport numpy as np\n\nfrom tensorboard.plugins.hparams import api as hp\n\nfrom dataset import get_dataset, prepare_dataset\nfrom model import get_model\n\n\ndataset = get_dataset(\"fr-en\")\n\ntrain_dataset = dataset[0:150]\n\n(encoder_input,\ndecoder_input,\ndecoder_output,\nencoder_vocab,\ndecoder_vocab,\nencoder_inverted_vocab,\ndecoder_inverted_vocab) = prepare_dataset(\n  train_dataset,\n  shuffle = True,\n  lowercase = True,\n  max_window_size = 20\n)\n\nx_train = [np.array(encoder_input[0:100]), np.array(decoder_input[0:100])]\ny_train = np.array(decoder_output[0:100])\n\nx_test = [np.array(encoder_input[100:150]), np.array(decoder_input[100:150])]\ny_test = np.array(decoder_output[100:150])\n\nBATCH_SIZE = hp.HParam(\"batch_num\", hp.Discrete([32, 16]))\nDENSE_NUM = hp.HParam(\"dense_num\", hp.Discrete([512, 256]))\nHEAD_NUM = hp.HParam(\"head_num\", hp.Discrete([8, 4]))\nEMBED_NUM = hp.HParam(\"embed_num\", hp.Discrete([512, 256]))\nLAYER_NUM = hp.HParam(\"layer_num\", hp.Discrete([6, 4]))\n\nwith tf.summary.create_file_writer(\"logs/hparam_tuning\").as_default():\n  hp.hparams_config(\n    hparams=[LAYER_NUM, HEAD_NUM, EMBED_NUM, DENSE_NUM, BATCH_SIZE],\n    metrics=[\n      hp.Metric(\"val_accuracy\")\n    ],\n  )\n\ndef train_test_model(hparams):\n  transformer_model = get_model(\n    EMBEDDING_SIZE = hparams[EMBED_NUM],\n    ENCODER_VOCAB_SIZE = len(encoder_vocab),\n    DECODER_VOCAB_SIZE = len(decoder_vocab),\n    ENCODER_LAYERS = hparams[LAYER_NUM],\n    DECODER_LAYERS = hparams[LAYER_NUM],\n    NUMBER_HEADS = hparams[HEAD_NUM],\n    DENSE_LAYER_SIZE = hparams[DENSE_NUM]\n  )\n\n  transformer_model.compile(\n    optimizer = \"adam\",\n    loss = [\"sparse_categorical_crossentropy\"],\n    metrics = [\"accuracy\"]\n  )\n\n  transformer_model.fit(x_train, y_train, epochs = 1, batch_size = hparams[BATCH_SIZE])\n\n  _, accuracy = transformer_model.evaluate(x_test, y_test)\n\n  return accuracy\n\ndef run(run_dir, hparams):\n  with tf.summary.create_file_writer(run_dir).as_default():\n    hp.hparams(hparams)\n    accuracy = train_test_model(hparams)\n    tf.summary.scalar(\"val_accuracy\", accuracy, step = 1)\n\nsession_num = 0\n\nfor batch_num in BATCH_SIZE.domain.values:\n  for dense_num in DENSE_NUM.domain.values:\n    for num_heads in HEAD_NUM.domain.values:\n      for num_embed in EMBED_NUM.domain.values:\n        for num_units in LAYER_NUM.domain.values:\n          hparams = {\n              BATCH_SIZE: batch_num,\n              DENSE_NUM: dense_num,\n              HEAD_NUM: num_heads,\n              EMBED_NUM: num_embed,\n              LAYER_NUM: num_units\n          }\n          run_name = \"run-%d\" % session_num\n\n          print(\"--- Starting trial: %s\" % run_name)\n          print({ h.name: hparams[h] for h in hparams })\n\n          run(\"logs/hparam_tuning/\" + run_name, hparams)\n\n          session_num += 1\n```\n\n\n##### Output\n\n```\n--- Starting trial: run-0\n{'batch_num': 16, 'dense_num': 256, 'head_num': 4, 'embed_num': 256, 'layer_num': 4}\n7/7 [==============================] - 1s 136ms/step - loss: 2.3796 - accuracy: 0.5590\n2/2 [==============================] - 0s 35ms/step - loss: 1.3560 - accuracy: 0.8240\n--- Starting trial: run-1\n{'batch_num': 16, 'dense_num': 256, 'head_num': 4, 'embed_num': 256, 'layer_num': 6}\n7/7 [==============================] - 1s 203ms/step - loss: 2.9393 - accuracy: 0.5625\n2/2 [==============================] - 0s 53ms/step - loss: 1.1636 - accuracy: 0.8240\n...\n--- Starting trial: run-29\n{'batch_num': 32, 'dense_num': 512, 'head_num': 8, 'embed_num': 256, 'layer_num': 6}\n4/4 [==============================] - 1s 323ms/step - loss: 6.8676 - accuracy: 0.2650\n2/2 [==============================] - 0s 74ms/step - loss: 13.1447 - accuracy: 0.0500\n--- Starting trial: run-30\n{'batch_num': 32, 'dense_num': 512, 'head_num': 8, 'embed_num': 512, 'layer_num': 4}\n4/4 [==============================] - 2s 513ms/step - loss: 7.4851 - accuracy: 0.2650\n2/2 [==============================] - 0s 111ms/step - loss: 13.9821 - accuracy: 0.0310\n--- Starting trial: run-31\n{'batch_num': 32, 'dense_num': 512, 'head_num': 8, 'embed_num': 512, 'layer_num': 6}\n4/4 [==============================] - 3s 761ms/step - loss: 7.1519 - accuracy: 0.2660\n2/2 [==============================] - 0s 162ms/step - loss: 14.0015 - accuracy: 0.0500\n```\n\n### Visualize\n\n```\n$ ./tensorboard --logdir=./logs\n```\n\n\n### Configs\n\n```\nBase (training on CPU) :\n  EMBEDDING_SIZE = 64\n  ENCODER_VOCAB_SIZE = 10000\n  DECODER_VOCAB_SIZE = 10000\n  ENCODER_LAYERS = 2\n  DECODER_LAYERS = 2\n  NUMBER_HEADS = 4\n  DENSE_LAYER_SIZE = 128\n  MAX_WINDOW_SIZE = 20\n  DATASET_SIZE = 100000\n  BATCH_SIZE = 32\n -> 2.4 millions params (model size : ~28 Mo)\n\nBig (training on GPU) :\n  EMBEDDING_SIZE = 512\n  ENCODER_VOCAB_SIZE = 30000\n  DECODER_VOCAB_SIZE = 30000\n  ENCODER_LAYERS = 6\n  DECODER_LAYERS = 6\n  NUMBER_HEADS = 8\n  DENSE_LAYER_SIZE = 1024\n  MAX_WINDOW_SIZE = 65\n  DATASET_SIZE = 200000\n  BATCH_SIZE = 32\n -> 60 millions params (model size : ~600 Mo)\n```\n\n### Credits\n\n<pre>\n<b>Coder un Transformer avec Tensorflow et Keras (LIVE)</b>\n<a href=\"https://www.youtube.com/watch?v=mWA-PmxMBDk\">https://www.youtube.com/watch?v=mWA-PmxMBDk</a>\n<i>Thibault Neveu</i>\n<a href=\"https://colab.research.google.com/drive/1akAsUAddF2-x57BJBA_gF-v4htyiR12y?usp=sharing\">https://colab.research.google.com/drive/1akAsUAddF2-x57BJBA_gF-v4htyiR12y?usp=sharing</a>\n</pre>\n\n<pre>\n<b>[TUTORIAL + C\u00d3DIGO] Machine Translation usando redes TRANSFORMER (Python + Keras)</b>\n<a href=\"https://www.youtube.com/watch?v=p2sTJYoIwj0\">https://www.youtube.com/watch?v=p2sTJYoIwj0</a>\n<i>codificandobits</i>\n<a href=\"https://github.com/codificandobits/Traductor_con_redes_Transformer/blob/master/machine-translation-transformers.ipynb\">https://github.com/codificandobits/Traductor_con_redes_Transformer/blob/master/machine-translation-transformers.ipynb</a>\n</pre>\n\n<pre>\n<a href=\"https://github.com/CyberZHG/keras-transformer\">https://github.com/CyberZHG/keras-transformer</a>\n<i>CyberZHG</i>\n</pre>\n\n<pre>\n<b>Dataset</b>\n<a href=\"https://www.manythings.org/anki/\">https://www.manythings.org/anki/</a>\n</pre>\n\n### Ressources\n\n<https://arxiv.org/abs/1706.03762> Attention Is All You Need (official paper)\n\n<https://github.com/Kyubyong/transformer/blob/fb023bb097e08d53baf25b46a9da490beba51a21/tf1.2_legacy/train.py>\n\n<https://github.com/Kyubyong/transformer/blob/master/model.py>\n\n<https://github.com/pemywei/attention-is-all-you-need-tensorflow/blob/master/Transformer/model/nmt.py>\n\n<https://github.com/tensorflow/models/blob/master/official/nlp/transformer/transformer.py>\n\n<https://towardsdatascience.com/attention-is-all-you-need-discovering-the-transformer-paper-73e5ff5e0634>\n\n<http://jalammar.github.io/illustrated-transformer/>\n\n<https://nlp.seas.harvard.edu/2018/04/03/attention.html>\n\n<http://statmt.org/wmt14/translation-task.html>\n\n<https://github.com/lucidrains/feedback-transformer-pytorch/blob/main/feedback_transformer_pytorch/feedback_transformer_pytorch.py>\n\n<https://huggingface.co/blog/encoder-decoder>\n\n<http://vandergoten.ai/2018-09-18-attention-is-all-you-need/> (softmax implementation)\n\n<https://www.prhlt.upv.es/aigaion2/attachments/Transformer.pdf-54651af972703d4b1443fc03a8a9e9a6.pdf>\n\n<https://github.com/lilianweng/transformer-tensorflow/blob/master/transformer.py>\n\n<https://towardsdatascience.com/transformer-neural-network-step-by-step-breakdown-of-the-beast-b3e096dc857f>\n\n<https://charon.me/posts/pytorch/pytorch_seq2seq_6/#training-the-seq2seq-model>\n\n<https://trungtran.io/2019/04/29/create-the-transformer-with-tensorflow-2-0/>\n",
            "readme_url": "https://github.com/ays-dev/keras-transformer",
            "frameworks": [
                "NLTK",
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Attention Is All You Need",
            "arxiv": "1706.03762",
            "year": 2017,
            "url": "http://arxiv.org/abs/1706.03762v5",
            "abstract": "The dominant sequence transduction models are based on complex recurrent or\nconvolutional neural networks in an encoder-decoder configuration. The best\nperforming models also connect the encoder and decoder through an attention\nmechanism. We propose a new simple network architecture, the Transformer, based\nsolely on attention mechanisms, dispensing with recurrence and convolutions\nentirely. Experiments on two machine translation tasks show these models to be\nsuperior in quality while being more parallelizable and requiring significantly\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\nEnglish-to-German translation task, improving over the existing best results,\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\ntranslation task, our model establishes a new single-model state-of-the-art\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\nof the training costs of the best models from the literature. We show that the\nTransformer generalizes well to other tasks by applying it successfully to\nEnglish constituency parsing both with large and limited training data.",
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N. Gomez",
                "Lukasz Kaiser",
                "Illia Polosukhin"
            ]
        }
    ],
    "domain": {
        "domain_type": "Natural Language Processing",
        "domain_prob": 0.8802527813070634,
        "task": "Machine Translation",
        "task_prob": 0.9694105131230055
    }
}
{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Tacotron",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "0fengzi0",
                "owner_type": "User",
                "name": "tacotron",
                "url": "https://github.com/0fengzi0/tacotron",
                "stars": 0,
                "pushed_at": "2019-03-24 13:26:32+00:00",
                "created_at": "2019-03-23 02:27:31+00:00",
                "language": "Python",
                "description": "A TensorFlow implementation of Google's Tacotron speech synthesis with pre-trained model",
                "license": "MIT License",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "7e377245c354b32b905a885081a3f9713099691e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/blob/mandarin/.gitignore"
                    }
                },
                "size": 45
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "4ad4ed1d5e34d95c8380768ec16405d789cc6de4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/blob/mandarin/LICENSE"
                    }
                },
                "size": 1053
            },
            {
                "type": "code",
                "name": "TRAINING_DATA.md",
                "sha": "f1ac3cb6de42c84475f4274e513b2a5764efe8fb",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/blob/mandarin/TRAINING_DATA.md"
                    }
                },
                "size": 2786
            },
            {
                "type": "code",
                "name": "datasets",
                "sha": "8a7d45c5315ef657ab6191f7554429b8fee38a9e",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/tree/mandarin/datasets"
                    }
                },
                "num_files": 6
            },
            {
                "type": "code",
                "name": "demo_server.py",
                "sha": "decea2366341a72b8a714b5c1803d9aea14d4c62",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/blob/mandarin/demo_server.py"
                    }
                },
                "size": 3045
            },
            {
                "type": "code",
                "name": "eval.py",
                "sha": "ec510fc52e1917ce66f284434ce26d78eb0cb145",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/blob/mandarin/eval.py"
                    }
                },
                "size": 2842
            },
            {
                "type": "code",
                "name": "hparams.py",
                "sha": "7ccccb66c5c580a6d30be3413e57c74de50335b9",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/blob/mandarin/hparams.py"
                    }
                },
                "size": 1296
            },
            {
                "type": "code",
                "name": "models",
                "sha": "b90a57f6fa9b8f588d1b2e7e7e8d184217aa21f2",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/tree/mandarin/models"
                    }
                },
                "num_files": 7
            },
            {
                "type": "code",
                "name": "preprocess.py",
                "sha": "8aac117015f99d8878ae7c62e2013b460e1650b4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/blob/mandarin/preprocess.py"
                    }
                },
                "size": 2145
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "7588bb2335254780975a283f7432c27dd7742b50",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/blob/mandarin/requirements.txt"
                    }
                },
                "size": 300
            },
            {
                "type": "code",
                "name": "synthesizer.py",
                "sha": "e0bddf025bb3cfcbed7dbfa9317d6178bfb92e6b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/blob/mandarin/synthesizer.py"
                    }
                },
                "size": 1394
            },
            {
                "type": "code",
                "name": "tests",
                "sha": "b6b66335b8b3f77cbe9c22e962368f20a0c2fc2b",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/tree/mandarin/tests"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "text",
                "sha": "279e7c9874c40c8aaae50946c4c3337a69afba9d",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/tree/mandarin/text"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "add16a846ed1067f6c96fb46c528d1a6c0af036d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/blob/mandarin/train.py"
                    }
                },
                "size": 6649
            },
            {
                "type": "code",
                "name": "util",
                "sha": "ca5b99dd9050f5de3ad5e7d961cb04fb60183b4e",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/0fengzi0/tacotron/tree/mandarin/util"
                    }
                },
                "num_files": 4
            }
        ]
    },
    "authors": [
        {
            "name": "Keith Ito",
            "github_id": "keithito"
        },
        {
            "name": "Leo Ma",
            "email": "begeekmyfriend@gmail.com",
            "github_id": "begeekmyfriend"
        },
        {
            "name": "i\u5c0f\u98ce",
            "github_id": "0fengzi0"
        },
        {
            "name": "Yunchao He",
            "github_id": "candlewill"
        },
        {
            "name": "Matthew Goldey",
            "email": "matthew.goldey@gmail.com",
            "github_id": "mgoldey"
        },
        {
            "name": "Pawe\u0142 Kope\u0107",
            "email": "pawelkopec10@gmail.com",
            "github_id": "pawelkopec"
        },
        {
            "name": "Ryuichi Yamamoto",
            "email": "zryuichi@gmail.com",
            "github_id": "r9y9"
        },
        {
            "name": "Scott Stevenson",
            "email": "scott@stevenson.io",
            "github_id": "srstevenson"
        },
        {
            "name": "jyegerlehner",
            "github_id": "jyegerlehner"
        }
    ],
    "tags": [],
    "description": "A TensorFlow implementation of Google's Tacotron speech synthesis with pre-trained model",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/0fengzi0/tacotron",
            "stars": 0,
            "issues": false,
            "readme": "# Tacotron\n\nAn implementation of Tacotron speech synthesis in TensorFlow.\n\n\n### Audio Samples\n\n  * **[Audio Samples](https://keithito.github.io/audio-samples/)** from models trained using this repo.\n    * The first set was trained for 877K steps on the [LJ Speech Dataset](https://keithito.com/LJ-Speech-Dataset/)\n      * Speech started to become intelligble around 20K steps.\n      * Although loss continued to decrease, there wasn't much noticable improvement after ~250K steps.\n    * The second set was trained by [@MXGray](https://github.com/MXGray) for 140K steps on the [Nancy Corpus](http://www.cstr.ed.ac.uk/projects/blizzard/2011/lessac_blizzard2011/).\n\n\n\n## Background\n\nIn April 2017, Google published a paper, [Tacotron: Towards End-to-End Speech Synthesis](https://arxiv.org/pdf/1703.10135.pdf),\nwhere they present a neural text-to-speech model that learns to synthesize speech directly from\n(text, audio) pairs. However, they didn't release their source code or training data. This is an\nindependent attempt to provide an open-source implementation of the model described in their paper.\n\nThe quality isn't as good as Google's demo yet, but hopefully it will get there someday :-).\nPull requests are welcome!\n\n\n\n## Quick Start\n\n### Installing dependencies\n\n1. Install Python 3.\n\n2. Install the latest version of [TensorFlow](https://www.tensorflow.org/install/) for your platform. For better\n   performance, install with GPU support if it's available. This code works with TensorFlow 1.3 and later.\n\n3. Install requirements:\n   ```\n   pip install -r requirements.txt\n   ```\n\n\n### Using a pre-trained model\n\n1. **Download and unpack a model**:\n   ```\n   curl http://data.keithito.com/data/speech/tacotron-20170720.tar.bz2 | tar xjC /tmp\n   ```\n\n2. **Run the demo server**:\n   ```\n   python demo_server.py --checkpoint /tmp/tacotron-20170720/model.ckpt\n   ```\n\n3. **Point your browser at localhost:9000**\n   * Type what you want to synthesize\n\n\n\n### Training\n\n*Note: you need at least 40GB of free disk space to train a model.*\n\n1. **Download a speech dataset.**\n\n   The following are supported out of the box:\n    * [LJ Speech](https://keithito.com/LJ-Speech-Dataset/) (Public Domain)\n    * [Blizzard 2012](http://www.cstr.ed.ac.uk/projects/blizzard/2012/phase_one) (Creative Commons Attribution Share-Alike)\n\n   You can use other datasets if you convert them to the right format. See [TRAINING_DATA.md](TRAINING_DATA.md) for more info.\n\n\n2. **Unpack the dataset into `~/tacotron`**\n\n   After unpacking, your tree should look like this for LJ Speech:\n   ```\n   tacotron\n     |- LJSpeech-1.1\n         |- metadata.csv\n         |- wavs\n   ```\n\n   or like this for Blizzard 2012:\n   ```\n   tacotron\n     |- Blizzard2012\n         |- ATrampAbroad\n         |   |- sentence_index.txt\n         |   |- lab\n         |   |- wav\n         |- TheManThatCorruptedHadleyburg\n             |- sentence_index.txt\n             |- lab\n             |- wav\n   ```\n\n3. **Preprocess the data**\n   ```\n   python preprocess.py --dataset ljspeech\n   ```\n     * Use `--dataset blizzard` for Blizzard data\n\n4. **Train a model**\n   ```\n   python train.py\n   ```\n\n   Tunable hyperparameters are found in [hparams.py](hparams.py). You can adjust these at the command\n   line using the `--hparams` flag, for example `--hparams=\"batch_size=16,outputs_per_step=2\"`.\n   Hyperparameters should generally be set to the same values at both training and eval time.\n   The default hyperparameters are recommended for LJ Speech and other English-language data.\n   See [TRAINING_DATA.md](TRAINING_DATA.md) for other languages.\n\n\n5. **Monitor with Tensorboard** (optional)\n   ```\n   tensorboard --logdir ~/tacotron/logs-tacotron\n   ```\n\n   The trainer dumps audio and alignments every 1000 steps. You can find these in\n   `~/tacotron/logs-tacotron`.\n\n6. **Synthesize from a checkpoint**\n   ```\n   python demo_server.py --checkpoint ./logs-tacotron/model.ckpt-185000\n   ```\n   Replace \"185000\" with the checkpoint number that you want to use, then open a browser\n   to `localhost:9000` and type what you want to speak. Alternately, you can\n   run [eval.py](eval.py) at the command line:\n   ```\n   python eval.py --checkpoint ./logs-tacotron/model.ckpt-185000\n   ```\n   If you set the `--hparams` flag when training, set the same value here.\n\n\n## Notes and Common Issues\n\n  * [TCMalloc](http://goog-perftools.sourceforge.net/doc/tcmalloc.html) seems to improve\n    training speed and avoids occasional slowdowns seen with the default allocator. You\n    can enable it by installing it and setting `LD_PRELOAD=/usr/lib/libtcmalloc.so`. With TCMalloc,\n    you can get around 1.1 sec/step on a GTX 1080Ti.\n\n  * You can train with [CMUDict](http://www.speech.cs.cmu.edu/cgi-bin/cmudict) by downloading the\n    dictionary to ~/tacotron/training and then passing the flag `--hparams=\"use_cmudict=True\"` to\n    train.py. This will allow you to pass ARPAbet phonemes enclosed in curly braces at eval\n    time to force a particular pronunciation, e.g. `Turn left on {HH AW1 S S T AH0 N} Street.`\n\n  * If you pass a Slack incoming webhook URL as the `--slack_url` flag to train.py, it will send\n    you progress updates every 1000 steps.\n\n  * Occasionally, you may see a spike in loss and the model will forget how to attend (the\n    alignments will no longer make sense). Although it will recover eventually, it may\n    save time to restart at a checkpoint prior to the spike by passing the\n    `--restore_step=150000` flag to train.py (replacing 150000 with a step number prior to the\n    spike). **Update**: a recent [fix](https://github.com/keithito/tacotron/pull/7) to gradient\n    clipping by @candlewill may have fixed this.\n    \n  * During eval and training, audio length is limited to `max_iters * outputs_per_step * frame_shift_ms`\n    milliseconds. With the defaults (max_iters=200, outputs_per_step=5, frame_shift_ms=12.5), this is\n    12.5 seconds.\n    \n    If your training examples are longer, you will see an error like this:\n    `Incompatible shapes: [32,1340,80] vs. [32,1000,80]`\n    \n    To fix this, you can set a larger value of `max_iters` by passing `--hparams=\"max_iters=300\"` to\n    train.py (replace \"300\" with a value based on how long your audio is and the formula above).\n    \n  * Here is the expected loss curve when training on LJ Speech with the default hyperparameters:\n    ![Loss curve](https://user-images.githubusercontent.com/1945356/36077599-c0513e4a-0f21-11e8-8525-07347847720c.png)\n\n\n## Other Implementations\n  * By Alex Barron: https://github.com/barronalex/Tacotron\n  * By Kyubyong Park: https://github.com/Kyubyong/tacotron\n",
            "readme_url": "https://github.com/0fengzi0/tacotron",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Tacotron: Towards End-to-End Speech Synthesis",
            "arxiv": "1703.10135",
            "year": 2017,
            "url": "http://arxiv.org/abs/1703.10135v2",
            "abstract": "A text-to-speech synthesis system typically consists of multiple stages, such\nas a text analysis frontend, an acoustic model and an audio synthesis module.\nBuilding these components often requires extensive domain expertise and may\ncontain brittle design choices. In this paper, we present Tacotron, an\nend-to-end generative text-to-speech model that synthesizes speech directly\nfrom characters. Given <text, audio> pairs, the model can be trained completely\nfrom scratch with random initialization. We present several key techniques to\nmake the sequence-to-sequence framework perform well for this challenging task.\nTacotron achieves a 3.82 subjective 5-scale mean opinion score on US English,\noutperforming a production parametric system in terms of naturalness. In\naddition, since Tacotron generates speech at the frame level, it's\nsubstantially faster than sample-level autoregressive methods.",
            "authors": [
                "Yuxuan Wang",
                "RJ Skerry-Ryan",
                "Daisy Stanton",
                "Yonghui Wu",
                "Ron J. Weiss",
                "Navdeep Jaitly",
                "Zongheng Yang",
                "Ying Xiao",
                "Zhifeng Chen",
                "Samy Bengio",
                "Quoc Le",
                "Yannis Agiomyrgiannakis",
                "Rob Clark",
                "Rif A. Saurous"
            ]
        },
        {
            "title": "LJ Speech",
            "url": "https://keithito.com/LJ-Speech-Dataset/"
        },
        {
            "title": "Blizzard 2012",
            "url": "http://www.cstr.ed.ac.uk/projects/blizzard/2012/phase_one"
        },
        {
            "title": "TCMalloc",
            "url": "http://goog-perftools.sourceforge.net/doc/tcmalloc.html"
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "LJ Speech Dataset",
                "connection": {
                    "name": "url",
                    "source": {
                        "url": "https://keithito.com/LJ-Speech-Dataset/"
                    }
                }
            },
            {
                "name": "Nancy Corpus",
                "connection": {
                    "name": "url",
                    "source": {
                        "url": "http://www.cstr.ed.ac.uk/projects/blizzard/2011/lessac_blizzard2011/"
                    }
                }
            }
        ]
    },
    "domain": {
        "domain_type": "Speech",
        "domain_prob": 0.9895131342901934
    }
}
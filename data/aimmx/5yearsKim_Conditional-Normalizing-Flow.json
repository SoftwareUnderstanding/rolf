{
    "visibility": {
        "visibility": "public"
    },
    "name": "Conditionial-Normalizing-Flow",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "5yearsKim",
                "owner_type": "User",
                "name": "Conditional-Normalizing-Flow",
                "url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow",
                "stars": 29,
                "pushed_at": "2020-01-09 06:04:12+00:00",
                "created_at": "2020-01-09 04:40:13+00:00",
                "language": "Python",
                "description": "Conditional Generative model (Normalizing Flow) and experimenting style transfer using this model",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "a46c2eefdbcb5bbb55d7bb06d1d03b6ca5be79c8",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow/blob/master/.gitignore"
                    }
                },
                "size": 38
            },
            {
                "type": "code",
                "name": "data",
                "sha": "aecdd84894930de3ef7c1fe185c80a4c82a9dbdc",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow/tree/master/data"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "environment.yml",
                "sha": "1436153db6ac93d0751b784a168d44cf9d498010",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow/blob/master/environment.yml"
                    }
                },
                "size": 158
            },
            {
                "type": "code",
                "name": "figs",
                "sha": "916296b744be71d53897ebb0f5a12bfc2cd71288",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow/tree/master/figs"
                    }
                },
                "num_files": 7
            },
            {
                "type": "code",
                "name": "inference.py",
                "sha": "eb8bf78355f9393e2cfd73fcda7c57a779a5c687",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow/blob/master/inference.py"
                    }
                },
                "size": 3396
            },
            {
                "type": "code",
                "name": "inference_data",
                "sha": "e986e502182c51456aa0b8b620be57f02f82c260",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow/tree/master/inference_data"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "models",
                "sha": "5a981ab2b250af9b8443230a74e78ec6eddff040",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow/tree/master/models"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "ref_pics",
                "sha": "6a91e6675b6519ddfdf87b481f84f4ff013a57d5",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow/tree/master/ref_pics"
                    }
                },
                "num_files": 22
            },
            {
                "type": "code",
                "name": "test_files.txt",
                "sha": "6dc6f75dfe30e982ecf67000c716ec1619c27824",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow/blob/master/test_files.txt"
                    }
                },
                "size": 110
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "a602641788823106633dcc14591412b5ed3ec1d6",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow/blob/master/train.py"
                    }
                },
                "size": 7366
            },
            {
                "type": "code",
                "name": "train_files.txt",
                "sha": "8e6a95dc3d1544167e52a1b3dea2e07c626038e7",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow/blob/master/train_files.txt"
                    }
                },
                "size": 5401
            },
            {
                "type": "code",
                "name": "util",
                "sha": "21fb296dfcca0881fa03a452b6567cce98578d96",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow/tree/master/util"
                    }
                },
                "num_files": 4
            }
        ]
    },
    "authors": [
        {
            "name": "5yearsKim",
            "github_id": "5yearsKim"
        }
    ],
    "tags": [],
    "description": "Conditional Generative model (Normalizing Flow) and experimenting style transfer using this model",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow",
            "stars": 29,
            "issues": true,
            "readme": "# Conditionial-Normalizing-Flow\nImplementing conditional generative model using normalizing flow. \nrelative paper:\n1. Glow: Generative Flow with Invertible 1x1 Convolutions\nhttps://arxiv.org/abs/1807.03039\n2. Guided Image Generation with Conditional Invertible Neural Networks\nhttps://arxiv.org/abs/1907.02392\n\n\n# Description\nCode adapted from https://github.com/chrischute/glow\nAdding conditioning layer to affine coupling layer. Tried conditioning for many domain.\nApplied style transfer using the property of conditional flow model. (reconstruct image giving different condition in forward and reverse procedure of Glow)\n\n\n# implementation\nutilize celeba dataset\nhttp://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\n\n1. download celeba dataset and move to /data folder\n2. make list of train set and test set\n ```command\n  mv data/celeba\n  ls *.jpg | tail -n+10 > train_files.txt\n  ls *.jpg | head -n10 > test_files.txt\n  mv train_files.txt test_files.txt ../..\n ```\n\n3. run code after configuration\n```command\npython3 train.py\n```\n4. applying style tranfer with sample data\n```command\n python3 inference.py\n```\n\n# what you can do?\n### super resolution\nBy training with decimated as a condition, cFlow can successfully generate high resolution images\n![Alt text](/figs/SR.jpg)\ndecimated(input image)/ reconstructed image/ original image\n### super resolution with controlled feature\nsuper resolution is ill-posed problem. when resolution is really low, there are many ways to reconstruct the image. we can also control feature of the image by giving additional feature to the model(\"Smiling\" in example below)\n![Alt text](/figs/SR_feature.png)\nConditional flow not only reconstructed super blur image to realistic image, but also controlled feature gradiently\n### Colorization\nimplementing colorization by giving gray image as a condition\n![Alt text](/figs/Colorization.png)\ngray image(input)/ reconstructed image/ original image\n### Sketch-to-image\ngenerating image from simple sketch can also be implemented. Conditioin is simply given using canny-edge detection algorithm.(highly sure of better performance if applied with better edge detection model such as HED)\n![Alt text](/figs/sketch-to-image.png)\n### Style transfer with conditional Flow\nfiltering image to Normalizing flow with condition image A, and reconstruct image with condition image B, we can somewhat mix two different image together.\n![Alt text](/figs/ST_example.png)\nhere is simple explanation of principle of this style mixing. My FYP paper is of that conditioning to generative model is subtraction of specific information(relatied to condition) from input image\n![Alt text](/figs/ST_principle.png)\n### image-to-image translation: Modifying feature from given image\nby giving feature(such as \"smiling\", \"Pale face\" and so on) as a condition and applying same method as Style transfer, I could also modify feature of the image. \n![Alt text](/figs/modifying_feature.png)\n",
            "readme_url": "https://github.com/5yearsKim/Conditional-Normalizing-Flow",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Guided Image Generation with Conditional Invertible Neural Networks",
            "arxiv": "1907.02392",
            "year": 2019,
            "url": "http://arxiv.org/abs/1907.02392v3",
            "abstract": "In this work, we address the task of natural image generation guided by a\nconditioning input. We introduce a new architecture called conditional\ninvertible neural network (cINN). The cINN combines the purely generative INN\nmodel with an unconstrained feed-forward network, which efficiently\npreprocesses the conditioning input into useful features. All parameters of the\ncINN are jointly optimized with a stable, maximum likelihood-based training\nprocedure. By construction, the cINN does not experience mode collapse and\ngenerates diverse samples, in contrast to e.g. cGANs. At the same time our\nmodel produces sharp images since no reconstruction loss is required, in\ncontrast to e.g. VAEs. We demonstrate these properties for the tasks of MNIST\ndigit generation and image colorization. Furthermore, we take advantage of our\nbi-directional cINN architecture to explore and manipulate emergent properties\nof the latent space, such as changing the image style in an intuitive way.",
            "authors": [
                "Lynton Ardizzone",
                "Carsten L\u00fcth",
                "Jakob Kruse",
                "Carsten Rother",
                "Ullrich K\u00f6the"
            ]
        },
        {
            "title": "Glow: Generative Flow with Invertible 1x1 Convolutions",
            "arxiv": "1807.03039",
            "year": 2018,
            "url": "http://arxiv.org/abs/1807.03039v2",
            "abstract": "Flow-based generative models (Dinh et al., 2014) are conceptually attractive\ndue to tractability of the exact log-likelihood, tractability of exact\nlatent-variable inference, and parallelizability of both training and\nsynthesis. In this paper we propose Glow, a simple type of generative flow\nusing an invertible 1x1 convolution. Using our method we demonstrate a\nsignificant improvement in log-likelihood on standard benchmarks. Perhaps most\nstrikingly, we demonstrate that a generative model optimized towards the plain\nlog-likelihood objective is capable of efficient realistic-looking synthesis\nand manipulation of large images. The code for our model is available at\nhttps://github.com/openai/glow",
            "authors": [
                "Diederik P. Kingma",
                "Prafulla Dhariwal"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "CUHK"
            },
            {
                "name": "CelebA"
            },
            {
                "name": "MNIST"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999992855632761,
        "task": "Image Generation",
        "task_prob": 0.8377073036692202
    }
}
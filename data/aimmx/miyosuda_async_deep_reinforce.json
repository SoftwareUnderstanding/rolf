{
    "visibility": {
        "visibility": "public",
        "license": "Apache License 2.0"
    },
    "name": "async_deep_reinforce",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "miyosuda",
                "owner_type": "User",
                "name": "async_deep_reinforce",
                "url": "https://github.com/miyosuda/async_deep_reinforce",
                "stars": 579,
                "pushed_at": "2018-08-09 09:29:30+00:00",
                "created_at": "2016-04-10 16:10:40+00:00",
                "language": "Python",
                "description": "Asynchronous Methods for Deep Reinforcement Learning",
                "license": "Apache License 2.0",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "a04936c971315edb3ade62de1f83cc99dbd7736a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/miyosuda/async_deep_reinforce/blob/master/.gitignore"
                    }
                },
                "size": 33
            },
            {
                "type": "code",
                "name": "LICENSE.txt",
                "sha": "93e3e3b28516b4d3a7dad666963aaaf4571ad8e5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/miyosuda/async_deep_reinforce/blob/master/LICENSE.txt"
                    }
                },
                "size": 11388
            },
            {
                "type": "code",
                "name": "a3c.py",
                "sha": "81b4c0bca1fb46577fe6c348d424c981c922bf7a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/miyosuda/async_deep_reinforce/blob/master/a3c.py"
                    }
                },
                "size": 4451
            },
            {
                "type": "code",
                "name": "a3c_display.py",
                "sha": "f296762803ebd7c832ffbf0ce2b654c8ac1674c5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/miyosuda/async_deep_reinforce/blob/master/a3c_display.py"
                    }
                },
                "size": 1856
            },
            {
                "type": "code",
                "name": "a3c_training_thread.py",
                "sha": "d5df33d4c68954a067a6d0a795d15acd49824579",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/miyosuda/async_deep_reinforce/blob/master/a3c_training_thread.py"
                    }
                },
                "size": 6109
            },
            {
                "type": "code",
                "name": "a3c_visualize.py",
                "sha": "cd46dcf29f056ef3ad924fa4bdfc9c172dababcb",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/miyosuda/async_deep_reinforce/blob/master/a3c_visualize.py"
                    }
                },
                "size": 2046
            },
            {
                "type": "code",
                "name": "constants.py",
                "sha": "17fd7dba62063daffe9577820f8b37a3d2298a71",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/miyosuda/async_deep_reinforce/blob/master/constants.py"
                    }
                },
                "size": 833
            },
            {
                "type": "code",
                "name": "docs",
                "sha": "98438d00cc186be7df0e84595d80627aeb2665b4",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/miyosuda/async_deep_reinforce/tree/master/docs"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "game_ac_network.py",
                "sha": "8d6bad9a263f2fee297158633c07170efe828913",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/miyosuda/async_deep_reinforce/blob/master/game_ac_network.py"
                    }
                },
                "size": 11111
            },
            {
                "type": "code",
                "name": "game_state.py",
                "sha": "a2ccb0e970e14dd604b0ae043df08d7bfced5c0a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/miyosuda/async_deep_reinforce/blob/master/game_state.py"
                    }
                },
                "size": 2391
            },
            {
                "type": "code",
                "name": "game_state_test.py",
                "sha": "44750ebf3c58b121e612693d612a8775e0749357",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/miyosuda/async_deep_reinforce/blob/master/game_state_test.py"
                    }
                },
                "size": 1542
            },
            {
                "type": "code",
                "name": "pong.bin",
                "sha": "14a5bdfc72548613c059938bdf712efdbb5d3806",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/miyosuda/async_deep_reinforce/blob/master/pong.bin"
                    }
                },
                "size": 2048
            },
            {
                "type": "code",
                "name": "rmsprop_applier.py",
                "sha": "71039b08fb2ae1ebad826597ae094ed9a23a763d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/miyosuda/async_deep_reinforce/blob/master/rmsprop_applier.py"
                    }
                },
                "size": 3727
            },
            {
                "type": "code",
                "name": "rmsprop_applier_test.py",
                "sha": "a5e1c06cd4c7d61ac224a063dd8c8731b550caee",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/miyosuda/async_deep_reinforce/blob/master/rmsprop_applier_test.py"
                    }
                },
                "size": 1518
            }
        ]
    },
    "authors": [
        {
            "name": "Kosuke Miyoshi",
            "email": "miyosuda@gmail.com",
            "github_id": "miyosuda"
        },
        {
            "name": "Itsukara",
            "email": "iitt21-t@yahoo.co.jp",
            "github_id": "Itsukara"
        },
        {
            "name": "Wonseok Jeon",
            "email": "jeonwonseok0125@gmail.com",
            "github_id": "wsjeon"
        }
    ],
    "tags": [
        "tensorflow",
        "reinforcement-learning",
        "a3c",
        "deep-learning"
    ],
    "description": "Asynchronous Methods for Deep Reinforcement Learning",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/miyosuda/async_deep_reinforce",
            "stars": 579,
            "issues": true,
            "readme": "# async_deep_reinforce\n\nAsynchronous deep reinforcement learning\n\n## About\n\nAn attempt to repdroduce Google Deep Mind's paper \"Asynchronous Methods for Deep Reinforcement Learning.\"\n\nhttp://arxiv.org/abs/1602.01783\n\nAsynchronous Advantage Actor-Critic (A3C) method for playing \"Atari Pong\" is implemented with TensorFlow.\nBoth A3C-FF and A3C-LSTM are implemented.\n\nLearning result movment after 26 hours (A3C-FF) is like this.\n\n[![Learning result after 26 hour](http://narr.jp/private/miyoshi/deep_learning/a3c_preview_image.jpg)](https://youtu.be/ZU71YdAedZs)\n\nAny advice or suggestion is strongly welcomed in issues thread.\n\nhttps://github.com/miyosuda/async_deep_reinforce/issues/1\n\n## How to build\n\nFirst we need to build multi thread ready version of Arcade Learning Enviroment.\nI made some modification to it to run it on multi thread enviroment.\n\n    $ git clone https://github.com/miyosuda/Arcade-Learning-Environment.git\n    $ cd Arcade-Learning-Environment\n    $ cmake -DUSE_SDL=ON -DUSE_RLGLUE=OFF -DBUILD_EXAMPLES=OFF .\n    $ make -j 4\n\t\n    $ pip install .\n\nI recommend to install it on VirtualEnv environment.\n\n## How to run\n\nTo train,\n\n    $python a3c.py\n\nTo display the result with game play,\n\n    $python a3c_disp.py\n\n## Using GPU\nTo enable gpu, change \"USE_GPU\" flag in \"constants.py\".\n\nWhen running with 8 parallel game environemts, speeds of GPU (GTX980Ti) and CPU(Core i7 6700) were like this. (Recorded with LOCAL_T_MAX=20 setting.)\n\n|type | A3C-FF             |A3C-LSTM          |\n|-----|--------------------|------------------|\n| GPU | 1722 steps per sec |864 steps per sec |\n| CPU | 1077 steps per sec |540 steps per sec |\n\n\n## Result\nScore plots of local threads of pong were like these. (with GTX980Ti)\n\n### A3C-LSTM LOCAL_T_MAX = 5\n\n![A3C-LSTM T=5](./docs/graph_t5.png)\n\n### A3C-LSTM LOCAL_T_MAX = 20\n\n![A3C-LSTM T=20](./docs/graph_t20.png)\n\nScores are not averaged using global network unlike the original paper.\n\n## Requirements\n- TensorFlow r1.0\n- numpy\n- cv2\n- matplotlib\n\n## References\n\nThis project uses setting written in muupan's wiki [muuupan/async-rl] (https://github.com/muupan/async-rl/wiki)\n\n\n## Acknowledgements\n\n- [@aravindsrinivas](https://github.com/aravindsrinivas) for providing information for some of the hyper parameters.\n\n",
            "readme_url": "https://github.com/miyosuda/async_deep_reinforce",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Asynchronous Methods for Deep Reinforcement Learning",
            "arxiv": "1602.01783",
            "year": 2016,
            "url": "http://arxiv.org/abs/1602.01783v2",
            "abstract": "We propose a conceptually simple and lightweight framework for deep\nreinforcement learning that uses asynchronous gradient descent for optimization\nof deep neural network controllers. We present asynchronous variants of four\nstandard reinforcement learning algorithms and show that parallel\nactor-learners have a stabilizing effect on training allowing all four methods\nto successfully train neural network controllers. The best performing method,\nan asynchronous variant of actor-critic, surpasses the current state-of-the-art\non the Atari domain while training for half the time on a single multi-core CPU\ninstead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds\non a wide variety of continuous motor control problems as well as on a new task\nof navigating random 3D mazes using a visual input.",
            "authors": [
                "Volodymyr Mnih",
                "Adri\u00e0 Puigdom\u00e8nech Badia",
                "Mehdi Mirza",
                "Alex Graves",
                "Timothy P. Lillicrap",
                "Tim Harley",
                "David Silver",
                "Koray Kavukcuoglu"
            ]
        }
    ],
    "domain": {
        "domain_type": "Playing Games",
        "domain_prob": 0.9911493340294097
    }
}
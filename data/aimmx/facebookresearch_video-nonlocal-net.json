{
    "visibility": {
        "visibility": "public",
        "license": "Other"
    },
    "name": "Non-local Neural Networks for Video Classification",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "facebookresearch",
                "owner_type": "Organization",
                "name": "video-nonlocal-net",
                "url": "https://github.com/facebookresearch/video-nonlocal-net",
                "stars": 1857,
                "pushed_at": "2021-09-15 17:26:10+00:00",
                "created_at": "2018-01-26 20:31:43+00:00",
                "language": "Python",
                "description": "Non-local Neural Networks for Video Classification",
                "license": "Other",
                "frameworks": [
                    "Caffe2"
                ]
            },
            {
                "type": "code",
                "name": "CODE_OF_CONDUCT.md",
                "sha": "98ab2019a7214e57dfbfd9ee7bb5a765313817de",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/facebookresearch/video-nonlocal-net/blob/main/CODE_OF_CONDUCT.md"
                    }
                },
                "size": 285
            },
            {
                "type": "code",
                "name": "CONTRIBUTING.md",
                "sha": "67d09f41295c14da1913a74d319f12a739dc1a76",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/facebookresearch/video-nonlocal-net/blob/main/CONTRIBUTING.md"
                    }
                },
                "size": 1473
            },
            {
                "type": "code",
                "name": "DATASET.md",
                "sha": "15b66a5fde81eba9bc74f434c121c83195d14a35",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/facebookresearch/video-nonlocal-net/blob/main/DATASET.md"
                    }
                },
                "size": 5156
            },
            {
                "type": "code",
                "name": "INSTALL.md",
                "sha": "90155863334f3e3a7a407e3efbaaef8d790df61c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/facebookresearch/video-nonlocal-net/blob/main/INSTALL.md"
                    }
                },
                "size": 4376
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "6b28d560c9cbbb829dec5bf3eb23f8ddae46d697",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/facebookresearch/video-nonlocal-net/blob/main/LICENSE"
                    }
                },
                "size": 19332
            },
            {
                "type": "code",
                "name": "caffe2_customized_ops",
                "sha": "8cc4230428fddd8f5761943384acdd9887ec790a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/facebookresearch/video-nonlocal-net/tree/main/caffe2_customized_ops"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "configs",
                "sha": "5e3f63e466166b3580175b1af6bbff8d4aebb1bf",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/facebookresearch/video-nonlocal-net/tree/main/configs"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "data",
                "sha": "0bba254fe0fe6f0804d355ee5c051d5ffe6bc779",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/facebookresearch/video-nonlocal-net/tree/main/data"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "lib",
                "sha": "6aa5b0cd900ff0862a36e0a11a78c53b6a63193a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/facebookresearch/video-nonlocal-net/tree/main/lib"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "process_data",
                "sha": "817153ad18a3436fee4ed37ccf3cad052f54d543",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/facebookresearch/video-nonlocal-net/tree/main/process_data"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "scripts",
                "sha": "cdc4fbdbedbba3c4d52019b59ba4923245dd3e78",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/facebookresearch/video-nonlocal-net/tree/main/scripts"
                    }
                },
                "num_files": 16
            },
            {
                "type": "code",
                "name": "tools",
                "sha": "843f177da2879a0abe7a30213154ecbcef15b53a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/facebookresearch/video-nonlocal-net/tree/main/tools"
                    }
                },
                "num_files": 2
            }
        ]
    },
    "authors": [
        {
            "name": "Xiaolong Wang",
            "github_id": "xiaolonw"
        },
        {
            "name": "Kaiming He",
            "github_id": "KaimingHe"
        },
        {
            "name": "Wan-Yen Lo",
            "github_id": "wanyenlo"
        }
    ],
    "tags": [],
    "description": "Non-local Neural Networks for Video Classification",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/facebookresearch/video-nonlocal-net",
            "stars": 1857,
            "issues": true,
            "readme": "\n# Non-local Neural Networks for Video Classification\n\nThis code is a re-implementation of the video classification experiments in the paper [Non-local Neural Networks](https://arxiv.org/abs/1711.07971). The code is developed based on the [Caffe2](https://caffe2.ai/) framework.\n\n<div align=\"center\">\n  <img src=\"data/nlnet.jpg\" width=\"700px\" />\n</div>\n\n## License\nThe code and the models in this repo are released under the [CC-BY-NC 4.0 LICENSE](https://github.com/facebookresearch/video-nonlocal-net/blob/master/LICENSE).\n\n## Citation\nIf you use our code in your research or wish to refer to the baseline results, please use the following BibTeX entry.\n```\n@article{NonLocal2018,\n  author =   {Xiaolong Wang and Ross Girshick and Abhinav Gupta and Kaiming He},\n  title =    {Non-local Neural Networks},\n  journal =  {CVPR},\n  year =     {2018}\n}\n```\n\n## Installation\nPlease find installation instructions for Caffe2 in [`INSTALL.md`](INSTALL.md). We also suggest to check the [Detectron installation](https://github.com/facebookresearch/Detectron/blob/master/INSTALL.md) and its issues if you had problems.\n\n## Pre-trained Models for Downloads\n\nFirst go into the data folder:\n```Shell\ncd data\nmkdir pretrained_model\nmkdir checkpoints\n```\n#### ImageNet pre-trained models\nThey can be downloaded from: [pretrained_model.tar.gz](https://dl.fbaipublicfiles.com/video-nonlocal/pretrained_model.tar.gz). Extract the models to the current folder:\n```Shell\nwget https://dl.fbaipublicfiles.com/video-nonlocal/pretrained_model.tar.gz\ntar xzf pretrained_model.tar.gz\n```\n\n## Dataset Preparation\n\nPlease read [`DATASET.md`](DATASET.md) for downloading and preparing the Kinetics dataset.\n\n**Note:** In this repo, we release the model which are trained with the same data as our paper.\n\n## Main Results\nAll the training scripts with ResNet-50 backbone are here:\n```Shell\ncd scripts\n```\n\nWe report the benchmarks with ResNet-50 backbone as below. All the numbers are obtain via fully-convolutional testing. All the models and training logs are available for download (some logs might not contain the fully-convolutional testing numbers):\n\n\n| <sub>script</sub> | <sub>input frames</sub> | <sub>freeze bn?</sub> | <sub>3D conv?</sub> | <sub>non-local?</sub> | <sub>top1</sub> | <sub>in paper</sub> | <sub>top5</sub> | <sub>model</sub> | <sub>logs</sub> |\n| ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- |\n| <sub>run_c2d_baseline_400k_32f.sh</sub> | 32 | - | - | - | 72.0 | <sub>71.8</sub> | 90.0 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/c2d_baseline_32x2_IN_pretrain_400k.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/c2d_baseline_32x2_IN_pretrain_400k.log) |\n| <sub>run_c2d_nlnet_400k_32f.sh</sub> | 32 | - | - | Yes | 73.9 | <sub>73.8</sub> | 91.0 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/c2d_nonlocal_32x2_IN_pretrain_400k.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/c2d_nonlocal_32x2_IN_pretrain_400k.log) |\n| <sub>run_i3d_baseline_400k_32f.sh</sub> | 32 | - | Yes | - | 73.6 | <sub>73.3</sub> | 90.8 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_baseline_32x2_IN_pretrain_400k.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_baseline_32x2_IN_pretrain_400k.log) |\n| <sub>run_i3d_nlnet_400k_32f.sh</sub> | 32 | - | Yes | Yes | 74.9 | <sub>74.9</sub> | 91.6 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_nonlocal_32x2_IN_pretrain_400k.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_nonlocal_32x2_IN_pretrain_400k.log) |\n| <sub>run_i3d_baseline_affine_400k_128f.sh</sub> | 128 | Yes | Yes | - | 75.2 | <sub>74.9</sub> | 92.0 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_baseline_128x1_I3D_pretrain_400k.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_baseline_128x1_I3D_pretrain_400k.log) |\n| <sub>run_i3d_nlnet_affine_400k_128f.sh</sub> | 128 | Yes | Yes | Yes | 76.5 | <sub>76.5</sub> | 92.7 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_nonlocal_128x1_I3D_pretrain_400k.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_nonlocal_128x1_I3D_pretrain_400k.log) |\n\n#### Modifications for improving speed\n\nBesides releasing the models following the exact parameter settings in the paper, we ablate a few different training settings which can significantly improve training/testing speed with almost the same performance.\n\n* **Sparser sampling of inputs**. We sample N frames with a stride of M frames (so covering N * M frames in the raw view). In the paper we used (N, M) = (32, 2) for short clips and (N, M) = (128, 1) for long clips. The following experiments use (N, M) = (8, 8) for short clips and (N, M) = (32, 4) for long clips. The temporal strides are adjusted accordingly such that the feature map sizes are unchanged in res2 to res5. This modification is to reduce data I/O, which can significantly improve the speed.\n\n\n| <sub>script</sub> | <sub>input frames</sub> | <sub>freeze bn?</sub> | <sub>3D conv?</sub> | <sub>non-local?</sub> | <sub>top1</sub> | <sub>top5</sub> | <sub>model</sub> | <sub>logs</sub> |\n| ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- |\n| <sub>run_c2d_baseline_400k.sh</sub> | 8 | - |  - | - | 71.9 | 90.0 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/c2d_baseline_8x8_IN_pretrain_400k.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/c2d_baseline_8x8_IN_pretrain_400k.log) |\n| <sub>run_c2d_nlnet_400k.sh</sub> | 8 | - |  - | Yes | 74.4 | 91.4 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/c2d_nonlocal_8x8_IN_pretrain_400k.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/c2d_nonlocal_8x8_IN_pretrain_400k.log)|\n| <sub>run_i3d_baseline_400k.sh</sub> | 8 | - |  Yes | - | 73.4 | 90.9 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_baseline_8x8_IN_pretrain_400k.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_baesline_8x8_IN_pretrain_400k.log) |\n| <sub>run_i3d_nlnet_400k.sh</sub> | 8 | - |  Yes | Yes | 74.7 | 91.6 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_nonlocal_8x8_IN_pretrain_400k.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_nonlocal_8x8_IN_pretrain_400k.log) |\n| <sub>run_i3d_baseline_affine_400k.sh</sub> | 32 | Yes |  Yes | - | 75.5 | 92.0 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_baseline_32x4_I3D_pretrain_400k.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_baseline_32x4_I3D_pretrain_400k.log) |\n| <sub>run_i3d_nlnet_affine_400k.sh</sub> | 32 | Yes |  Yes | Yes | 76.5 | 92.6 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_nonlocal_32x4_I3D_pretrain_400k.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_nonlocal_32x4_I3D_pretrain_400k.log) |\n\n\n* **Fewer training iterations**.  With sparser sampling of inputs, we further reduce the training time by reducing the training iterations. Instead of training for 400K iterations in the paper, we can train our model with 300K iterations. This reduces training epochs by 25% without losing much performance.\n\n| <sub>script</sub> | <sub>input frames</sub> | <sub>freeze bn?</sub> | <sub>3D conv?</sub> | <sub>non-local?</sub> | <sub>top1</sub> | <sub>top5</sub> | <sub>model</sub> | <sub>logs</sub> |\n| ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- |\n| <sub>run_i3d_baseline_300k.sh</sub> | 8 | - | Yes | - | 73.2 | 90.8 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_baseline_8x8_IN_pretrain_300k.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_baseline_8x8_IN_pretrain_300k.log) |\n\n#### Training with fewer GPUs\n\n* The following two models were run by Xiaolong Wang with 4-GPU (GTX 1080) machines outside of Facebook after the internship. The training data is downloaded on 12/20/2017 (see [`DATASET.md`](DATASET.md)), which misses some videos due to invalid urls. The training schedule is shorter\u00a0(4-GPU 600k vs. 8-GPU 400k above). These changes lead to a slight accuracy drop.\n\n* We also provide training scripts/models with half iterations (300K with 4 GPUs) and less regularization. This baseline is fast and for sanity check: it only takes less than 3 days training on a machine with 4 GPUs (see \"run_i3d_baseline_300k_4gpu.sh\").\n\n| <sub>script</sub> | <sub>input frames</sub> | <sub>GPUs</sub> | <sub>freeze bn?</sub> | <sub>3D conv?</sub> | <sub>non-local?</sub> | <sub>top1</sub> | <sub>top5</sub> | <sub>model</sub> | <sub>logs</sub> |\n| ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- |\n| <sub>run_i3d_baseline_600k_4gpu.sh</sub> | 8 | 4 | - | Yes | -  | 73.0 | 90.4 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_baseline_8x8_IN_pretrain_600k_4gpu.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_baseline_8x8_IN_pretrain_600k_4gpu.log) |\n| <sub>run_i3d_baseline_300k_4gpu.sh</sub> | 8 | 4 | - | Yes | -  | 72.0 | 90.1 | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_baseline_8x8_IN_pretrain_300k_4gpu.pkl) | [`link`](https://dl.fbaipublicfiles.com/video-nonlocal/i3d_baseline_8x8_IN_pretrain_300k_4gpu.log) |\n\n\n\n#### Script details\n\nWe now explain the scripts taking the ones trained with 3D convolutions, 400k iterations, 8GPUs, and sparser inputs as examples (in [`Modifications for improving speed`](#modifications-for-improving-speed)).\n\n1. The following script is the baseline i3d methods with ImageNet pre-trained network:\n    ```Shell\n    run_i3d_baseline_400k.sh\n    ```\n\n2. The following script trains the i3d model with 5 Non-local layers with ImageNet pre-trained network:\n    ```Shell\n    run_i3d_nlnet_400k.sh\n    ```\n\n3. To train the i3d Non-local Networks with longer clips (32-frame input), we first need to obtain the model trained from \"run_i3d_baseline_400k.sh\" as a pre-trained model. Then we convert the Batch Normalization layers into Affine layers by running:\n    ```Shell\n    cd ../process_data/convert_models\n    python modify_caffe2_ftvideo.py ../../data/checkpoints/run_i3d_baseline_400k/checkpoints/c2_model_iter400000.pkl  ../../data/pretrained_model/run_i3d_baseline_400k/affine_model_400k.pkl\n    ```\n\n    Note that we have provided one example model (run_i3d_baseline_400k/affine_model_400k.pkl) in [pretrained_model.tar.gz](https://dl.fbaipublicfiles.com/video-nonlocal/pretrained_model.tar.gz). Given this converted model, we run the script for training the i3d Non-local Networks with longer clips:\n    ```Shell\n    run_i3d_nlnet_affine_400k.sh\n    ```\n\n4. The models with ResNet-101 backbone can be trained by setting:\n    ```Shell\n    TRAIN.PARAMS_FILE ../data/pretrained_model/r101_pretrain_c2_model_iter450450_clean.pkl\n    MODEL.DEPTH 101\n    MODEL.VIDEO_ARC_CHOICE 4 # 3 for c2d, and 4 for i3d\n    ```\n\n## Testing\n\nThe models are tested immediately after training. For each video, we sample 10 clips along the temporal dimension as in the paper. For each video clip, we resize the shorter side to 256 pixels and use 3 crops to cover the entire spatial size. We use fully-convolutional testing on each of the 256x256 crops. This is a slower approximation of the fully convolutional testing (on the variable full size, e.g., 256x320) done in the paper, which requires specific implementation not provided in this repo.\n\nTaking the model trained with \"run_i3d_nlnet_400k.sh\" as an example, we can run testing by specifying:\n```Shell\nTEST.TEST_FULLY_CONV True\n```\nas in the script:\n```Shell\nrun_test_multicrop.sh\n```\n\n## Fine-tuning\n\nThe fine-tuning process is almost exactly the same as the training process. The only difference is that you need to first modify our Kinectis pre-trained model by removing the iteration number, momentum and last layer parameters, which is done with\n```Shell\nprocess_data/convert_models/modify_blob_rm.py\n```\n\n## Acknowledgement\n\nThe authors would like to thank [Haoqi Fan](https://research.fb.com/people/fan-haoqi/) for training the models and re-producing the results at FAIR with this code.\n",
            "readme_url": "https://github.com/facebookresearch/video-nonlocal-net",
            "frameworks": [
                "Caffe2"
            ]
        }
    ],
    "references": [
        {
            "title": "Non-local Neural Networks",
            "arxiv": "1711.07971",
            "year": 2017,
            "url": "http://arxiv.org/abs/1711.07971v3",
            "abstract": "Both convolutional and recurrent operations are building blocks that process\none local neighborhood at a time. In this paper, we present non-local\noperations as a generic family of building blocks for capturing long-range\ndependencies. Inspired by the classical non-local means method in computer\nvision, our non-local operation computes the response at a position as a\nweighted sum of the features at all positions. This building block can be\nplugged into many computer vision architectures. On the task of video\nclassification, even without any bells and whistles, our non-local models can\ncompete or outperform current competition winners on both Kinetics and Charades\ndatasets. In static image recognition, our non-local models improve object\ndetection/segmentation and pose estimation on the COCO suite of tasks. Code is\navailable at https://github.com/facebookresearch/video-nonlocal-net .",
            "authors": [
                "Xiaolong Wang",
                "Ross Girshick",
                "Abhinav Gupta",
                "Kaiming He"
            ]
        },
        {
            "year": "2018",
            "journal": "CVPR",
            "title": "Non-local Neural Networks",
            "author": [
                "Wang, Xiaolong",
                "Girshick, Ross",
                "Gupta, Abhinav",
                "He, Kaiming"
            ],
            "ENTRYTYPE": "article",
            "ID": "NonLocal2018",
            "authors": [
                "Wang, Xiaolong",
                "Girshick, Ross",
                "Gupta, Abhinav",
                "He, Kaiming"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "`DATASET.md`",
                "connection": {
                    "name": "url",
                    "source": {
                        "url": "https://github.com/facebookresearch/video-nonlocal-net/blob/main/DATASET.md"
                    }
                }
            },
            {
                "name": "`DATASET.md`",
                "connection": {
                    "name": "url",
                    "source": {
                        "url": "https://github.com/facebookresearch/video-nonlocal-net/blob/main/DATASET.md"
                    }
                }
            },
            {
                "name": "ImageNet"
            },
            {
                "name": "COCO"
            },
            {
                "name": "Charades"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999012537231661,
        "task": "Object Detection",
        "task_prob": 0.9810222056610356
    }
}
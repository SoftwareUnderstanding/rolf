{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Multi-class Focal Loss",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "AdeelH",
                "owner_type": "User",
                "name": "pytorch-multi-class-focal-loss",
                "url": "https://github.com/AdeelH/pytorch-multi-class-focal-loss",
                "stars": 81,
                "pushed_at": "2021-10-04 12:13:08+00:00",
                "created_at": "2020-09-03 09:08:36+00:00",
                "language": "Python",
                "description": "An (unofficial) implementation of Focal Loss, as described in the RetinaNet paper, generalized to the multi-class case.",
                "license": "MIT License",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "c77b7a2336aee4777164cc7cb1c886816bafd4a5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AdeelH/pytorch-multi-class-focal-loss/blob/master/.gitignore"
                    }
                },
                "size": 17
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "514079d0e33aa3060209b72272126b34f1d28622",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AdeelH/pytorch-multi-class-focal-loss/blob/master/LICENSE"
                    }
                },
                "size": 1069
            },
            {
                "type": "code",
                "name": "focal_loss.py",
                "sha": "e126d5a30a27135d0f77b912f2872539159a9d0f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AdeelH/pytorch-multi-class-focal-loss/blob/master/focal_loss.py"
                    }
                },
                "size": 4405
            },
            {
                "type": "code",
                "name": "hubconf.py",
                "sha": "4afdfa383647f87d1307da42b1ada1260c01b5fa",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AdeelH/pytorch-multi-class-focal-loss/blob/master/hubconf.py"
                    }
                },
                "size": 127
            },
            {
                "type": "code",
                "name": "setup.cfg",
                "sha": "15b9d54d3276bccf64433cdf29749599a6bf52ca",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AdeelH/pytorch-multi-class-focal-loss/blob/master/setup.cfg"
                    }
                },
                "size": 121
            }
        ]
    },
    "authors": [
        {
            "name": "Adeel Hassan",
            "github_id": "AdeelH"
        }
    ],
    "tags": [
        "pytorch",
        "deep-learning",
        "loss-functions",
        "classification",
        "neural-network",
        "retinanet",
        "multiclass-classification",
        "imbalanced-classes",
        "pytorch-implementation",
        "implementation-of-research-paper",
        "machine-learning"
    ],
    "description": "An (unofficial) implementation of Focal Loss, as described in the RetinaNet paper, generalized to the multi-class case.",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/AdeelH/pytorch-multi-class-focal-loss",
            "stars": 81,
            "issues": true,
            "readme": "[![DOI](https://zenodo.org/badge/292520399.svg)](https://zenodo.org/badge/latestdoi/292520399)\n\n# Multi-class Focal Loss\n\nAn (unofficial) implementation of Focal Loss, as described in the RetinaNet paper, https://arxiv.org/abs/1708.02002, generalized to the multi-class case.\n\nIt is essentially an enhancement to cross-entropy loss and is useful for classification tasks when there is a large class imbalance. It has the effect of underweighting easy examples.\n\n# Usage\n- `FocalLoss` is an `nn.Module` and behaves very much like `nn.CrossEntropyLoss()` i.e.\n    - supports the `reduction` and `ignore_index` params, and\n    - is able to work with 2D inputs of shape `(N, C)` as well as K-dimensional inputs of shape `(N, C, d1, d2, ..., dK)`.\n\n- Example usage\n    ```python3\n    focal_loss = FocalLoss(alpha, gamma)\n\t...\n\tinp, targets = batch\n    out = model(inp)\n\tloss = focal_loss(out, targets)\n    ```\n\n# Loading through torch.hub\nThis repo supports importing modules through `torch.hub`. `FocalLoss` can be easily imported into your code via, for example:\n```python3\nfocal_loss = torch.hub.load(\n\t'adeelh/pytorch-multi-class-focal-loss',\n\tmodel='FocalLoss',\n\talpha=torch.tensor([.75, .25]),\n\tgamma=2,\n\treduction='mean',\n\tforce_reload=False\n)\nx, y = torch.randn(10, 2), (torch.rand(10) > .5).long()\nloss = focal_loss(x, y)\n```\nOr:\n```python3\nfocal_loss = torch.hub.load(\n\t'adeelh/pytorch-multi-class-focal-loss',\n\tmodel='focal_loss',\n\talpha=[.75, .25],\n\tgamma=2,\n\treduction='mean',\n\tdevice='cpu',\n\tdtype=torch.float32,\n\tforce_reload=False\n)\nx, y = torch.randn(10, 2), (torch.rand(10) > .5).long()\nloss = focal_loss(x, y)\n```\n",
            "readme_url": "https://github.com/AdeelH/pytorch-multi-class-focal-loss",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Focal Loss for Dense Object Detection",
            "arxiv": "1708.02002",
            "year": 2017,
            "url": "http://arxiv.org/abs/1708.02002v2",
            "abstract": "The highest accuracy object detectors to date are based on a two-stage\napproach popularized by R-CNN, where a classifier is applied to a sparse set of\ncandidate object locations. In contrast, one-stage detectors that are applied\nover a regular, dense sampling of possible object locations have the potential\nto be faster and simpler, but have trailed the accuracy of two-stage detectors\nthus far. In this paper, we investigate why this is the case. We discover that\nthe extreme foreground-background class imbalance encountered during training\nof dense detectors is the central cause. We propose to address this class\nimbalance by reshaping the standard cross entropy loss such that it\ndown-weights the loss assigned to well-classified examples. Our novel Focal\nLoss focuses training on a sparse set of hard examples and prevents the vast\nnumber of easy negatives from overwhelming the detector during training. To\nevaluate the effectiveness of our loss, we design and train a simple dense\ndetector we call RetinaNet. Our results show that when trained with the focal\nloss, RetinaNet is able to match the speed of previous one-stage detectors\nwhile surpassing the accuracy of all existing state-of-the-art two-stage\ndetectors. Code is at: https://github.com/facebookresearch/Detectron.",
            "authors": [
                "Tsung-Yi Lin",
                "Priya Goyal",
                "Ross Girshick",
                "Kaiming He",
                "Piotr Doll\u00e1r"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9804475609972089,
        "task": "Object Detection",
        "task_prob": 0.8943311289681569
    }
}
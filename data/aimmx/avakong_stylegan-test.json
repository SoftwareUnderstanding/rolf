{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Style-Based GAN in PyTorch",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "avakong",
                "owner_type": "User",
                "name": "stylegan-test",
                "url": "https://github.com/avakong/stylegan-test",
                "stars": 0,
                "pushed_at": "2022-03-12 00:09:05+00:00",
                "created_at": "2019-12-20 22:34:56+00:00",
                "language": "Python",
                "license": "MIT License",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "46bf0291583c32ca31b1448391046ed69fcb7afa",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/avakong/stylegan-test/blob/master/.gitignore"
                    }
                },
                "size": 1252
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "915ca760bc639695e152e784d9dc2dbf71369b67",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/avakong/stylegan-test/blob/master/LICENSE"
                    }
                },
                "size": 1071
            },
            {
                "type": "code",
                "name": "checkpoint",
                "sha": "771b35fdfe1540127c90c06e440fa6d87b1e5658",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/avakong/stylegan-test/tree/master/checkpoint"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "create_image_sequence.py",
                "sha": "323888faa7e13d3d8541f1d26fa8987a498e3f42",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/avakong/stylegan-test/blob/master/create_image_sequence.py"
                    }
                },
                "size": 2867
            },
            {
                "type": "code",
                "name": "dataset.py",
                "sha": "af143ba20979ee9cd52609c285a167efb77b6947",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/avakong/stylegan-test/blob/master/dataset.py"
                    }
                },
                "size": 1049
            },
            {
                "type": "code",
                "name": "doc",
                "sha": "fb8145ae4e6683e6819fe003278323aedcb36f4c",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/avakong/stylegan-test/tree/master/doc"
                    }
                },
                "num_files": 7
            },
            {
                "type": "code",
                "name": "generate.py",
                "sha": "bf9d539e6c195d70a1a69d69d5efee58068d6e34",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/avakong/stylegan-test/blob/master/generate.py"
                    }
                },
                "size": 2967
            },
            {
                "type": "code",
                "name": "model.py",
                "sha": "cc92dfc3444ec8716a7b515ddd69e70c34f1bb99",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/avakong/stylegan-test/blob/master/model.py"
                    }
                },
                "size": 17448
            },
            {
                "type": "code",
                "name": "prepare_data.py",
                "sha": "e7505958a9bda794f4a544e2e3b5e29c3bdca3b6",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/avakong/stylegan-test/blob/master/prepare_data.py"
                    }
                },
                "size": 1994
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "b86b6eb65f04302675efee7d65e435660dbce123",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/avakong/stylegan-test/blob/master/requirements.txt"
                    }
                },
                "size": 119
            },
            {
                "type": "code",
                "name": "runway.yml",
                "sha": "46d6c38a1dc9250187332650726ff4442fb9b679",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/avakong/stylegan-test/blob/master/runway.yml"
                    }
                },
                "size": 1664
            },
            {
                "type": "code",
                "name": "runway_model.py",
                "sha": "bbda7c11864cd7ba80475675e5870bbf58ae34f5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/avakong/stylegan-test/blob/master/runway_model.py"
                    }
                },
                "size": 3651
            },
            {
                "type": "code",
                "name": "sample",
                "sha": "e8e00d3943b88d73116a6ac38e9d05c2216b9db1",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/avakong/stylegan-test/tree/master/sample"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "a886c91d1c49e789d1ea8cdc1f0b74b815f15f5a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/avakong/stylegan-test/blob/master/train.py"
                    }
                },
                "size": 11258
            }
        ]
    },
    "authors": [
        {
            "name": "Kim Seonghyeon",
            "email": "kim.seonghyeon@navercorp.com",
            "github_id": "rosinality"
        },
        {
            "name": "Marian Kleineberg",
            "github_id": "marian42"
        },
        {
            "name": "Michael Monashev",
            "github_id": "MichaelMonashev"
        },
        {
            "name": "avakong",
            "github_id": "avakong"
        },
        {
            "name": "Bing Penguin",
            "github_id": "penguinbing"
        }
    ],
    "tags": [],
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/avakong/stylegan-test",
            "stars": 0,
            "issues": true,
            "readme": "# Style-Based GAN in PyTorch\r\n\r\n##### Update (2019/09/01)\r\n\r\nI found bugs in the implementation thanks to @adambielski and @TropComplique! (https://github.com/rosinality/style-based-gan-pytorch/issues/33, https://github.com/rosinality/style-based-gan-pytorch/issues/34) I have fixed this and updated checkpoints\r\n\r\n##### Update (2019/07/04)\r\n\r\n* Now trainer uses pre-resized lmdb dataset for more stable data loading and training.\r\n* Model architecture is now more closely matches with official implementation.\r\n\r\nImplementation of A Style-Based Generator Architecture for Generative Adversarial Networks (https://arxiv.org/abs/1812.04948) in PyTorch\r\n\r\nUsage:\r\n\r\nYou should prepare lmdb dataset\r\n\r\n> python prepare_data.py --out LMDB_PATH --n_worker N_WORKER DATASET_PATH\r\n\r\nThis will convert images to jpeg and pre-resizes it. (For example, 8/16/32/64/128/256/512/1024) Then you can train StyleGAN.\r\n\r\nfor celebA\r\n\r\n> python train.py --mixing LMDB_PATH\r\n\r\nfor FFHQ\r\n\r\n> python train.py --mixing --loss r1 --sched LMDB_PATH\r\n\r\nResolution | Model & Optimizer \r\n-----------|-------------------\r\n256px      | [Link](https://drive.google.com/open?id=1QlXFPIOFzsJyjZ1AtfpnVhqW4Z0r8GLZ)\r\n512px      | [Link](https://drive.google.com/open?id=13f0tXPX0EfHdac0zcudfC8osD4OdsxZQ)\r\n1024px      | [Link](https://drive.google.com/open?id=1NJMqp2AN1de8cPXTBzYC7mX2wXF9ox-i)\r\n\r\nModel & Optimizer checkpoints saved at the end of phases of each resolution. (that is, 512px checkpoint saved at the end of 512px training.)\r\n\r\n## Sample\r\n\r\n![Sample of the model trained on FFHQ](doc/sample_ffhq_new.png)\r\n![Style mixing sample of the model trained on FFHQ](doc/sample_mixing_ffhq_new.png)\r\n\r\n512px sample from the generator trained on FFHQ.\r\n\r\n## Old Checkpoints\r\n\r\nResolution | Model & Optimizer | Running average of generator\r\n-----------|-------------------|------------------------------\r\n128px      | [Link](https://drive.google.com/open?id=1Fc0d8tTjS7Fcmr8gyHk8M0P-VMiRNeMl) | 100k iter [Link](https://drive.google.com/open?id=1b4MKSVTbWoY15NkzsM58T0QCvTE9d_Ch)\r\n256px      | [Link](https://drive.google.com/open?id=1K2G1p-m1BQNoTEKJDBGAtFI1fC4eBjcd) | 140k iter [Link](https://drive.google.com/open?id=1n01mlc1mPpQyeUnnWNGeZiY7vp6JgakM)\r\n512px      | [Link](https://drive.google.com/open?id=1Ls8NA56UnJWGJkRXXyJoDdz4a7uizBtw) | 180k iter [Link](https://drive.google.com/open?id=15lnKHnldIidQnXAlQ8PHo2W4XUTaIfq-)\r\n\r\nOld version of checkpoints. As gradient penalty and discriminator activations are different, it is better to use new checkpoints to do some training. But you can use these checkpoints to make samples as generator architecture is not changed.\r\n\r\nRunning average of generator is saved at the specified iterations. So these two are saved at different iterations. (Yes, this is my mistake.)",
            "readme_url": "https://github.com/avakong/stylegan-test",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "A Style-Based Generator Architecture for Generative Adversarial Networks",
            "arxiv": "1812.04948",
            "year": 2018,
            "url": "http://arxiv.org/abs/1812.04948v3",
            "abstract": "We propose an alternative generator architecture for generative adversarial\nnetworks, borrowing from style transfer literature. The new architecture leads\nto an automatically learned, unsupervised separation of high-level attributes\n(e.g., pose and identity when trained on human faces) and stochastic variation\nin the generated images (e.g., freckles, hair), and it enables intuitive,\nscale-specific control of the synthesis. The new generator improves the\nstate-of-the-art in terms of traditional distribution quality metrics, leads to\ndemonstrably better interpolation properties, and also better disentangles the\nlatent factors of variation. To quantify interpolation quality and\ndisentanglement, we propose two new, automated methods that are applicable to\nany generator architecture. Finally, we introduce a new, highly varied and\nhigh-quality dataset of human faces.",
            "authors": [
                "Tero Karras",
                "Samuli Laine",
                "Timo Aila"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "CelebA"
            },
            {
                "name": "FFHQ"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9994219348213255,
        "task": "Image Generation",
        "task_prob": 0.9747980149131433
    }
}
{
    "visibility": {
        "visibility": "public"
    },
    "name": "Experiments of batch normalization using TF 2.0",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "minoring",
                "owner_type": "User",
                "name": "batch-norm-visualize",
                "url": "https://github.com/minoring/batch-norm-visualize",
                "stars": 2,
                "pushed_at": "2020-01-10 08:57:00+00:00",
                "created_at": "2020-01-10 02:11:09+00:00",
                "language": "Python",
                "description": "Experiments of batch normalization in TF 2.0",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "7b62f12d5a8d4c6748d03cb47e3a05b7e7ed6516",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/minoring/batch-norm-visualize/blob/master/.gitignore"
                    }
                },
                "size": 19
            },
            {
                "type": "code",
                "name": "docs",
                "sha": "5380e340b82023c6c91a51057cc64defc02d488b",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/minoring/batch-norm-visualize/tree/master/docs"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "flags.py",
                "sha": "2d7f4805921f177cbf199b9cdfd61e3612fde268",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/minoring/batch-norm-visualize/blob/master/flags.py"
                    }
                },
                "size": 434
            },
            {
                "type": "code",
                "name": "logs",
                "sha": "da65455146e34eea8384d3bf6935a6753581b1df",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/minoring/batch-norm-visualize/tree/master/logs"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "main.py",
                "sha": "38e497710be64d4356441c41e686e35adaa6f1fb",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/minoring/batch-norm-visualize/blob/master/main.py"
                    }
                },
                "size": 3410
            },
            {
                "type": "code",
                "name": "model.py",
                "sha": "6e010677f7cc25db3b6ba049a0d3d72b598157d3",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/minoring/batch-norm-visualize/blob/master/model.py"
                    }
                },
                "size": 2066
            }
        ]
    },
    "authors": [
        {
            "name": "Minho Heo",
            "github_id": "minoring"
        }
    ],
    "tags": [],
    "description": "Experiments of batch normalization in TF 2.0",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/minoring/batch-norm-visualize",
            "stars": 2,
            "issues": true,
            "readme": "# Experiments of batch normalization using TF 2.0\n## Results\nExperiment using MNIST dataset using the model paper suggested.\n![](https://github.com/minoring/batch-norm-visualize/blob/master/docs/accuracy.png)\n## Usage\nUsing batch normalization.\n```\npython main.py --epochs=300 --steps_per_epoch=600 --bn=True\n```\nWithout batch normalization.\n```\npython main.py --epochs=300 --steps_per_epoch=600 --bn=False\n```\nTensorboard to visualize\n```\ntensorboard --logdir=logs\n```\n\n## References\n### paper\n- https://arxiv.org/abs/1502.03167\n",
            "readme_url": "https://github.com/minoring/batch-norm-visualize",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
            "arxiv": "1502.03167",
            "year": 2015,
            "url": "http://arxiv.org/abs/1502.03167v3",
            "abstract": "Training Deep Neural Networks is complicated by the fact that the\ndistribution of each layer's inputs changes during training, as the parameters\nof the previous layers change. This slows down the training by requiring lower\nlearning rates and careful parameter initialization, and makes it notoriously\nhard to train models with saturating nonlinearities. We refer to this\nphenomenon as internal covariate shift, and address the problem by normalizing\nlayer inputs. Our method draws its strength from making normalization a part of\nthe model architecture and performing the normalization for each training\nmini-batch. Batch Normalization allows us to use much higher learning rates and\nbe less careful about initialization. It also acts as a regularizer, in some\ncases eliminating the need for Dropout. Applied to a state-of-the-art image\nclassification model, Batch Normalization achieves the same accuracy with 14\ntimes fewer training steps, and beats the original model by a significant\nmargin. Using an ensemble of batch-normalized networks, we improve upon the\nbest published result on ImageNet classification: reaching 4.9% top-5\nvalidation error (and 4.8% test error), exceeding the accuracy of human raters.",
            "authors": [
                "Sergey Ioffe",
                "Christian Szegedy"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "MNIST"
            },
            {
                "name": "ImageNet"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9987688627669068,
        "task": "Image Classification",
        "task_prob": 0.8294429667095131
    }
}
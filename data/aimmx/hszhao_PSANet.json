{
    "visibility": {
        "visibility": "public"
    },
    "name": "PSANet: Point-wise Spatial Attention Network for Scene Parsing (in construction)",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "hszhao",
                "owner_type": "User",
                "name": "PSANet",
                "url": "https://github.com/hszhao/PSANet",
                "stars": 214,
                "pushed_at": "2019-09-09 13:37:42+00:00",
                "created_at": "2018-04-19 12:18:49+00:00",
                "language": "C++",
                "description": "PSANet: Point-wise Spatial Attention Network for Scene Parsing, ECCV2018.",
                "frameworks": []
            },
            {
                "type": "code",
                "name": ".gitmodules",
                "sha": "e388db5eaaf7d5a3b396d13b49a769fb02c3c780",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hszhao/PSANet/blob/master/.gitmodules"
                    }
                },
                "size": 80
            },
            {
                "type": "code",
                "name": "evaluation",
                "sha": "9bfb4a2b68850950a41b3cba637567f42df88c55",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hszhao/PSANet/tree/master/evaluation"
                    }
                },
                "num_files": 12
            },
            {
                "type": "code",
                "name": "include",
                "sha": "5d204aa69e662c8a0c3ed6f4cfbcc58fa8c17d65",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hszhao/PSANet/tree/master/include"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "src",
                "sha": "e3c02a75bded3a95cb89a299d674fd79a660dac3",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hszhao/PSANet/tree/master/src"
                    }
                },
                "num_files": 1
            }
        ]
    },
    "authors": [
        {
            "name": "Hengshuang Zhao",
            "github_id": "hszhao"
        }
    ],
    "tags": [],
    "description": "PSANet: Point-wise Spatial Attention Network for Scene Parsing, ECCV2018.",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/hszhao/PSANet",
            "stars": 214,
            "issues": true,
            "readme": "## PSANet: Point-wise Spatial Attention Network for Scene Parsing (in construction)\r\n\r\nby Hengshuang Zhao\\*, Yi Zhang\\*, Shu Liu, Jianping Shi, Chen Change Loy, Dahua Lin, Jiaya Jia, details are in [project page](https://hszhao.github.io/projects/psanet).\r\n\r\n### Introduction\r\n\r\nThis repository is build for PSANet, which contains source code for PSA module and related evaluation code. For installation, please merge the related layers and follow the description in [PSPNet](https://github.com/hszhao/PSPNet) repository (test with CUDA 7.0/7.5 + cuDNN v4).\r\n\r\n### PyTorch Version\r\n\r\nHighly optimized PyTorch codebases available for semantic segmentation in repo: [semseg](https://github.com/hszhao/semseg), including full training and testing codes for [PSPNet](https://hszhao.github.io/projects/pspnet) and [PSANet](https://hszhao.github.io/projects/psanet).\r\n\r\n### Usage\r\n\r\n1. Clone the repository recursively:\r\n\r\n   ```shell\r\n   git clone --recursive https://github.com/hszhao/PSANet.git\r\n   ```\r\n\r\n2. Merge the caffe layers into PSPNet repository:\r\n\r\n   Point-wise spatial attention: pointwise_spatial_attention_layer.hpp/cpp/cu and caffe.proto.\r\n\r\n3. Build Caffe and matcaffe:\r\n\r\n   ```shell\r\n   cd $PSANET_ROOT/PSPNet\r\n   cp Makefile.config.example Makefile.config\r\n   vim Makefile.config\r\n   make -j8 && make matcaffe\r\n   cd ..\r\n   ```\r\n\r\n4. Evaluation:\r\n\r\n   - Evaluation code is in folder 'evaluation'.\r\n   - Download trained models and put them in related dataset folder under 'evaluation/model', refer '[README.md](evaluation/model/README.md)'.\r\n   - Modify the related paths in 'eval_all.m':\r\n\r\n     Mainly variables 'data_root' and 'eval_list', and your image list for evaluation should be similarity to that in folder 'evaluation/samplelist' if you use this evaluation code structure.\r\n\r\n   ```shell\r\n   cd evaluation\r\n   vim eval_all.m\r\n   ```\r\n\r\n   - Run the evaluation scripts:\r\n\r\n   ```\r\n   ./run.sh\r\n   ```\r\n\r\n5. Results: \r\n\r\n   Predictions will show in folder 'evaluation/mc_result' and the expected scores are listed as below:\r\n\r\n   (mIoU/pAcc. stands for mean IoU and pixel accuracy, 'ss' and 'ms' denote single scale and multiple scale testing.)\r\n\r\n   ADE20K:\r\n\r\n   |  network  | training data | testing data | mIoU/pAcc.(ss) | mIoU/pAcc.(ms) |                            md5sum                            |\r\n   | :-------: | :-----------: | :----------: | :------------: | :------------: | :----------------------------------------------------------: |\r\n   | PSANet50  |     train     |     val      |  41.92/80.17   |  42.97/80.92   | [a8e884](https://drive.google.com/file/d/1F1A-ddhhppAQxSaTRWgIlQL8NMa4VMLV/view?usp=sharing) |\r\n   | PSANet101 |     train     |     val      |  42.75/80.71   |  43.77/81.51   | [ab5e56](https://drive.google.com/file/d/1u8ntKfkNgxmrBjH3U_3zbGKvLndpxwtk/view?usp=sharing) |\r\n\r\n   VOC2012:\r\n\r\n   |  network  |     training data      | testing data | mIoU/pAcc.(ss) | mIoU/pAcc.(ms) |                            md5sum                            |\r\n   | :-------: | :--------------------: | :----------: | :------------: | :------------: | :----------------------------------------------------------: |\r\n   | PSANet50  |       train_aug        |     val      |  77.24/94.88   |  78.14/95.12   | [d5fc37](https://drive.google.com/file/d/1uZLdv-1ReOJuRau06VEib0FOUb0I-fpl/view?usp=sharing) |\r\n   | PSANet101 |       train_aug        |     val      |  78.51/95.18   |  79.77/95.43   | [5d8c0f](https://drive.google.com/file/d/11dGNxh4nzoiV4fscJPcRD-OG9YsKSoaI/view?usp=sharing) |\r\n   | PSANet101 | COCO + train_aug + val |     test     |      -/-       |     85.7/-     | [3c6a69](https://drive.google.com/file/d/19sBwiQJh3pOj9LoFGhMnzpBA-pmDtmP3/view?usp=sharing) |\r\n\r\n   Cityscapes:\r\n\r\n   |  network  |     training data     | testing data | mIoU/pAcc.(ss) | mIoU/pAcc.(ms) |                            md5sum                            |\r\n   | :-------: | :-------------------: | :----------: | :------------: | :------------: | :----------------------------------------------------------: |\r\n   | PSANet50  |      fine_train       |   fine_val   |  76.65/95.99   |  77.79/96.24   | [25c06a](https://drive.google.com/file/d/1nr73jW42eWf5Xy1_Ch1RwpjwC4f5tCUk/view?usp=sharing) |\r\n   | PSANet101 |      fine_train       |   fine_val   |  77.94/96.10   |  79.05/96.30   | [3ac1bf](https://drive.google.com/file/d/1uaNZl7HgqYWwtPsKVREKIoo7Ib9jXxB2/view?usp=sharing) |\r\n   | PSANet101 |      fine_train       |  fine_test   |      -/-       |     78.6/-     | [3ac1bf](https://drive.google.com/file/d/1uaNZl7HgqYWwtPsKVREKIoo7Ib9jXxB2/view?usp=sharing) |\r\n   | PSANet101 | fine_train + fine_val |  fine_test   |      -/-       |     80.1/-     | [1dfc91](https://drive.google.com/file/d/1ZUT8g_Lx5Iih4lkZk3meAC6dpNk-ZJxT/view?usp=sharing) |\r\n\r\n6. Demo video:\r\n\r\n   - Video processed by PSANet (with PSPNet) on [BDD](http://bdd-data.berkeley.edu) dataset for drivable area segmentation: [Video](https://youtu.be/l5xu1DI6pDk).\r\n\r\n### Citation\r\n\r\nIf PSANet is useful for your research, please consider citing:\r\n\r\n    @inproceedings{zhao2018psanet,\r\n      title={{PSANet}: Point-wise Spatial Attention Network for Scene Parsing},\r\n      author={Zhao, Hengshuang and Zhang, Yi and Liu, Shu and Shi, Jianping and Loy, Chen Change and Lin, Dahua and Jia, Jiaya},\r\n      booktitle={ECCV},\r\n      year={2018}\r\n    }\r\n\r\n### Questions\r\n\r\nPlease contact 'hszhao@cse.cuhk.edu.hk' or 'zy217@ie.cuhk.edu.hk'\r\n",
            "readme_url": "https://github.com/hszhao/PSANet",
            "frameworks": []
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "ADE20K"
            },
            {
                "name": "Cityscapes"
            },
            {
                "name": "CUHK"
            },
            {
                "name": "COCO"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9991832302596748,
        "task": "Semantic Segmentation",
        "task_prob": 0.983418848784641
    }
}
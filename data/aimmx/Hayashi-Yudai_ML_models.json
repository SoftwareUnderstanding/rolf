{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "ML Models",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "Hayashi-Yudai",
                "owner_type": "User",
                "name": "ML_models",
                "url": "https://github.com/Hayashi-Yudai/ML_models",
                "stars": 5,
                "pushed_at": "2022-03-12 00:56:14+00:00",
                "created_at": "2019-04-21 11:52:01+00:00",
                "language": "Python",
                "description": "Implementation of machine learning models by Python with Tensorflow. ArcFace/UNet/ACoL",
                "license": "MIT License",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".github",
                "sha": "d336b04d850b10d2503fdd8ca30d5ab7d8a08018",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Hayashi-Yudai/ML_models/tree/master/.github"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "6e71e3ce954939e3324777d1c2e9525127b22df1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Hayashi-Yudai/ML_models/blob/master/.gitignore"
                    }
                },
                "size": 45
            },
            {
                "type": "code",
                "name": "ACoL",
                "sha": "f01fa12274c036de22005e274c7d73a779b79ca5",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Hayashi-Yudai/ML_models/tree/master/ACoL"
                    }
                },
                "num_files": 7
            },
            {
                "type": "code",
                "name": "ArcFace",
                "sha": "e903070df2af32b75659645ea6d4744a9d34adb1",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Hayashi-Yudai/ML_models/tree/master/ArcFace"
                    }
                },
                "num_files": 6
            },
            {
                "type": "code",
                "name": "Images",
                "sha": "aad6ba8278a841f98d1701a294415612054cd33d",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Hayashi-Yudai/ML_models/tree/master/Images"
                    }
                },
                "num_files": 8
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "63b4b681cb65bcf92db3d26bc3664a1298cbeea8",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Hayashi-Yudai/ML_models/blob/master/LICENSE"
                    }
                },
                "size": 1068
            },
            {
                "type": "code",
                "name": "Pipfile",
                "sha": "f4c8f7f84a35f89aeee3d6d3827e2924205ae54c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Hayashi-Yudai/ML_models/blob/master/Pipfile"
                    }
                },
                "size": 373
            },
            {
                "type": "code",
                "name": "Pipfile.lock",
                "sha": "abd50e2a56e9357f3633a6e1f290a493918f0306",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Hayashi-Yudai/ML_models/blob/master/Pipfile.lock"
                    }
                },
                "size": 64890
            },
            {
                "type": "code",
                "name": "UNet",
                "sha": "4e1a727893ffa097d39a2a1fa0ba9465907677e5",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Hayashi-Yudai/ML_models/tree/master/UNet"
                    }
                },
                "num_files": 8
            }
        ]
    },
    "authors": [
        {
            "name": "Yudai Hayashi",
            "github_id": "Hayashi-Yudai"
        }
    ],
    "tags": [
        "machine-learning",
        "image-processing",
        "python3",
        "python",
        "tensorflow",
        "pipenv",
        "keras-tensorflow"
    ],
    "description": "Implementation of machine learning models by Python with Tensorflow. ArcFace/UNet/ACoL",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/Hayashi-Yudai/ML_models",
            "stars": 5,
            "issues": true,
            "readme": "# ML Models\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nThis repository implements various machine learning models with Python/Tensorflow. I treat mainly \"Image processing\" in it.\n\n|  Model  |              Paper               |       Status       |\n| :-----: | :------------------------------: | :----------------: |\n|  U-Net  | https://arxiv.org/abs/1505.04597 | :white_check_mark: |\n|  ACoL   | https://arxiv.org/abs/1804.06962 | :white_check_mark: |\n| Arcface | https://arxiv.org/abs/1801.07698 | :white_check_mark: |\n\nYou can use these models for training or validation.\n\n## Requirements\n\n- Python 3.6>=\n- Tensorflow 2.4.0>=\n- PIL\n- Imgaug\n- Numpy\n- Scipy\n- Matplotlib\n\nI am managing these libraries with pipenv. If you do not have pipenv, install with pip\n```bash\npip install pipenv\n```\nYou can see [latest document](https://docs.pipenv.org/en/latest/) to understand the usage more\n\nTo install all libraries, you run\n```\n$ pipenv install\n```\n\n## Usage\n\nHow to use each model is written in README in the each model. Basically you can training with\n\n```\n$ pipenv run python -m $(MODEL_NAME)/train $(options)\n```\n\n## Future Plans\n- Modularize this repository to enable users to import whole models\n\n## Licence\n\n\"ML models\" is licenced under the MIT licence.\n\n(C) Copyright 2021, Yudai Hayashi\n",
            "readme_url": "https://github.com/Hayashi-Yudai/ML_models",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
            "arxiv": "1505.04597",
            "year": 2015,
            "url": "http://arxiv.org/abs/1505.04597v1",
            "abstract": "There is large consent that successful training of deep networks requires\nmany thousand annotated training samples. In this paper, we present a network\nand training strategy that relies on the strong use of data augmentation to use\nthe available annotated samples more efficiently. The architecture consists of\na contracting path to capture context and a symmetric expanding path that\nenables precise localization. We show that such a network can be trained\nend-to-end from very few images and outperforms the prior best method (a\nsliding-window convolutional network) on the ISBI challenge for segmentation of\nneuronal structures in electron microscopic stacks. Using the same network\ntrained on transmitted light microscopy images (phase contrast and DIC) we won\nthe ISBI cell tracking challenge 2015 in these categories by a large margin.\nMoreover, the network is fast. Segmentation of a 512x512 image takes less than\na second on a recent GPU. The full implementation (based on Caffe) and the\ntrained networks are available at\nhttp://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .",
            "authors": [
                "Olaf Ronneberger",
                "Philipp Fischer",
                "Thomas Brox"
            ]
        },
        {
            "title": "ArcFace: Additive Angular Margin Loss for Deep Face Recognition",
            "arxiv": "1801.07698",
            "year": 2018,
            "url": "http://arxiv.org/abs/1801.07698v3",
            "abstract": "One of the main challenges in feature learning using Deep Convolutional\nNeural Networks (DCNNs) for large-scale face recognition is the design of\nappropriate loss functions that enhance discriminative power. Centre loss\npenalises the distance between the deep features and their corresponding class\ncentres in the Euclidean space to achieve intra-class compactness. SphereFace\nassumes that the linear transformation matrix in the last fully connected layer\ncan be used as a representation of the class centres in an angular space and\npenalises the angles between the deep features and their corresponding weights\nin a multiplicative way. Recently, a popular line of research is to incorporate\nmargins in well-established loss functions in order to maximise face class\nseparability. In this paper, we propose an Additive Angular Margin Loss\n(ArcFace) to obtain highly discriminative features for face recognition. The\nproposed ArcFace has a clear geometric interpretation due to the exact\ncorrespondence to the geodesic distance on the hypersphere. We present arguably\nthe most extensive experimental evaluation of all the recent state-of-the-art\nface recognition methods on over 10 face recognition benchmarks including a new\nlarge-scale image database with trillion level of pairs and a large-scale video\ndataset. We show that ArcFace consistently outperforms the state-of-the-art and\ncan be easily implemented with negligible computational overhead. We release\nall refined training data, training codes, pre-trained models and training\nlogs, which will help reproduce the results in this paper.",
            "authors": [
                "Jiankang Deng",
                "Jia Guo",
                "Niannan Xue",
                "Stefanos Zafeiriou"
            ]
        },
        {
            "title": "Adversarial Complementary Learning for Weakly Supervised Object Localization",
            "arxiv": "1804.06962",
            "year": 2018,
            "url": "http://arxiv.org/abs/1804.06962v1",
            "abstract": "In this work, we propose Adversarial Complementary Learning (ACoL) to\nautomatically localize integral objects of semantic interest with weak\nsupervision. We first mathematically prove that class localization maps can be\nobtained by directly selecting the class-specific feature maps of the last\nconvolutional layer, which paves a simple way to identify object regions. We\nthen present a simple network architecture including two parallel-classifiers\nfor object localization. Specifically, we leverage one classification branch to\ndynamically localize some discriminative object regions during the forward\npass. Although it is usually responsive to sparse parts of the target objects,\nthis classifier can drive the counterpart classifier to discover new and\ncomplementary object regions by erasing its discovered regions from the feature\nmaps. With such an adversarial learning, the two parallel-classifiers are\nforced to leverage complementary object regions for classification and can\nfinally generate integral object localization together. The merits of ACoL are\nmainly two-fold: 1) it can be trained in an end-to-end manner; 2) dynamically\nerasing enables the counterpart classifier to discover complementary object\nregions more effectively. We demonstrate the superiority of our ACoL approach\nin a variety of experiments. In particular, the Top-1 localization error rate\non the ILSVRC dataset is 45.14%, which is the new state-of-the-art.",
            "authors": [
                "Xiaolin Zhang",
                "Yunchao Wei",
                "Jiashi Feng",
                "Yi Yang",
                "Thomas Huang"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9925900034343094,
        "task": "Image Classification",
        "task_prob": 0.5504494025500835
    }
}
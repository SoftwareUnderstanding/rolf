{
    "visibility": {
        "visibility": "public",
        "license": "GNU General Public License v3.0"
    },
    "name": "Gan_Architecture",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "VitoRazor",
                "owner_type": "User",
                "name": "Gan_Architecture",
                "url": "https://github.com/VitoRazor/Gan_Architecture",
                "stars": 1,
                "pushed_at": "2018-10-24 07:26:43+00:00",
                "created_at": "2018-10-18 12:48:00+00:00",
                "language": "Python",
                "license": "GNU General Public License v3.0",
                "frameworks": [
                    "Keras",
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "894a44cc066a027465cd26d634948d56d13af9af",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/VitoRazor/Gan_Architecture/blob/master/.gitignore"
                    }
                },
                "size": 1203
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "f288702d2fa16d3cdf0035b15a9fcbc552cd88e7",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/VitoRazor/Gan_Architecture/blob/master/LICENSE"
                    }
                },
                "size": 35149
            },
            {
                "type": "code",
                "name": "data_loader.py",
                "sha": "f029ac96fd56fe8278e7a1fddbb8eb128b5fb727",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/VitoRazor/Gan_Architecture/blob/master/data_loader.py"
                    }
                },
                "size": 2310
            },
            {
                "type": "code",
                "name": "model",
                "sha": "f64e999988d1b1d93446596bc128b64d9fbd2eaf",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/VitoRazor/Gan_Architecture/tree/master/model"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "myGan_info.py",
                "sha": "2c1097e943a3b006f285b064d5b2e66f235c0214",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/VitoRazor/Gan_Architecture/blob/master/myGan_info.py"
                    }
                },
                "size": 9972
            },
            {
                "type": "code",
                "name": "myGan_w_sn.py",
                "sha": "abb4134c5dd8d03270c02b8fb266d6410422aeaf",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/VitoRazor/Gan_Architecture/blob/master/myGan_w_sn.py"
                    }
                },
                "size": 8452
            },
            {
                "type": "code",
                "name": "result",
                "sha": "4bd588aa40257c9d74f89f0a410876465dd57f0d",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/VitoRazor/Gan_Architecture/tree/master/result"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "tools",
                "sha": "31c5b74a311ed210e3090d03b492cb3ac29c02f8",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/VitoRazor/Gan_Architecture/tree/master/tools"
                    }
                },
                "num_files": 2
            }
        ]
    },
    "authors": [
        {
            "name": "VitoRazor",
            "github_id": "VitoRazor"
        }
    ],
    "tags": [],
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/VitoRazor/Gan_Architecture",
            "stars": 1,
            "issues": true,
            "readme": "# Gan_Architecture\ncreate an architecture for Generative Adversarial Networks.\nimplementations \n## Table of Contents\n  * [Installation](#installation)\n  * [Implementations](#implementations)\n    + [Spectral Normalization](#GAN-SN)  \n    + [GAN with Info](#GAN-info)\n\n## Installation\n    $ git clone https://github.com/VitoRazor/Gan_Architecture.git\n    $ cd Gan_Architecture-master/\n    $ pip install keras\n\n## Implementations   \n### GAN-SN\nImplementation of Generative Adversarial Network with Spectral Normalization for Wasserstein-divergence \n\n[Code](myGan_w_sn.py)\n\nReference Paper:\n\nSpectral normalization for generative adversarial networks:https://arxiv.org/abs/1802.05957\n\nWasserstein GAN: https://arxiv.org/abs/1701.07875\n\nResult:\nTrain fro cartoon characters 64x64 \n <p align=\"center\">\n    <img src=\"https://github.com/VitoRazor/Gan_Architecture/blob/master/result/Gan/example_100000.png\" width=\"650\"\\>\n</p>\nTrain fro aerial image 64x64[iteration=150000] and 256x256[iteration=34800]\n <p align=\"center\">\n    <img src=\"https://github.com/VitoRazor/Gan_Architecture/blob/master/result/Gan/example_150000.png\" width=\"400\"\\>\n    <img src=\"https://github.com/VitoRazor/Gan_Architecture/blob/master/result/Gan/example_34800.png\" width=\"400\"\\>\n</p>\n\n### GAN-info\nImplementation of Generative Adversarial Network with InfoGAN and ACGAN, simultaneously using Spectral Normalization for Wasserstein-divergence.\n\n[Code](myGan_info.py)\n\nReference Paper:\n\nAuxiliary Classifier Generative Adversarial Network: https://arxiv.org/abs/1610.09585\n\nInterpretable Representation Learning by Information Maximizing Generative Adversarial Nets: https://arxiv.org/abs/1606.03657                                             \n                 \nResult:\nfrom iteration 10 to iteration 15000\n<p align=\"left\">\n    <img src=\"https://github.com/VitoRazor/Gan_Architecture/blob/master/result/Gan_info/example_100.png\" width=\"400\"\\>\n    <img src=\"https://github.com/VitoRazor/Gan_Architecture/blob/master/result/Gan_info/example_10000.png\" width=\"400\"\\>\n</p>\n<p align=\"center\">\n    <img src=\"https://github.com/VitoRazor/Gan_Architecture/blob/master/result/Gan_info/example_15000.png\" width=\"400\"\\>\n</p>\n\n",
            "readme_url": "https://github.com/VitoRazor/Gan_Architecture",
            "frameworks": [
                "Keras",
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets",
            "arxiv": "1606.03657",
            "year": 2016,
            "url": "http://arxiv.org/abs/1606.03657v1",
            "abstract": "This paper describes InfoGAN, an information-theoretic extension to the\nGenerative Adversarial Network that is able to learn disentangled\nrepresentations in a completely unsupervised manner. InfoGAN is a generative\nadversarial network that also maximizes the mutual information between a small\nsubset of the latent variables and the observation. We derive a lower bound to\nthe mutual information objective that can be optimized efficiently, and show\nthat our training procedure can be interpreted as a variation of the Wake-Sleep\nalgorithm. Specifically, InfoGAN successfully disentangles writing styles from\ndigit shapes on the MNIST dataset, pose from lighting of 3D rendered images,\nand background digits from the central digit on the SVHN dataset. It also\ndiscovers visual concepts that include hair styles, presence/absence of\neyeglasses, and emotions on the CelebA face dataset. Experiments show that\nInfoGAN learns interpretable representations that are competitive with\nrepresentations learned by existing fully supervised methods.",
            "authors": [
                "Xi Chen",
                "Yan Duan",
                "Rein Houthooft",
                "John Schulman",
                "Ilya Sutskever",
                "Pieter Abbeel"
            ]
        },
        {
            "title": "Wasserstein GAN",
            "arxiv": "1701.07875",
            "year": 2017,
            "url": "http://arxiv.org/abs/1701.07875v3",
            "abstract": "We introduce a new algorithm named WGAN, an alternative to traditional GAN\ntraining. In this new model, we show that we can improve the stability of\nlearning, get rid of problems like mode collapse, and provide meaningful\nlearning curves useful for debugging and hyperparameter searches. Furthermore,\nwe show that the corresponding optimization problem is sound, and provide\nextensive theoretical work highlighting the deep connections to other distances\nbetween distributions.",
            "authors": [
                "Martin Arjovsky",
                "Soumith Chintala",
                "L\u00e9on Bottou"
            ]
        },
        {
            "title": "Conditional Image Synthesis With Auxiliary Classifier GANs",
            "arxiv": "1610.09585",
            "year": 2016,
            "url": "http://arxiv.org/abs/1610.09585v4",
            "abstract": "Synthesizing high resolution photorealistic images has been a long-standing\nchallenge in machine learning. In this paper we introduce new methods for the\nimproved training of generative adversarial networks (GANs) for image\nsynthesis. We construct a variant of GANs employing label conditioning that\nresults in 128x128 resolution image samples exhibiting global coherence. We\nexpand on previous work for image quality assessment to provide two new\nanalyses for assessing the discriminability and diversity of samples from\nclass-conditional image synthesis models. These analyses demonstrate that high\nresolution samples provide class information not present in low resolution\nsamples. Across 1000 ImageNet classes, 128x128 samples are more than twice as\ndiscriminable as artificially resized 32x32 samples. In addition, 84.7% of the\nclasses have samples exhibiting diversity comparable to real ImageNet data.",
            "authors": [
                "Augustus Odena",
                "Christopher Olah",
                "Jonathon Shlens"
            ]
        },
        {
            "title": "Spectral Normalization for Generative Adversarial Networks",
            "arxiv": "1802.05957",
            "year": 2018,
            "url": "http://arxiv.org/abs/1802.05957v1",
            "abstract": "One of the challenges in the study of generative adversarial networks is the\ninstability of its training. In this paper, we propose a novel weight\nnormalization technique called spectral normalization to stabilize the training\nof the discriminator. Our new normalization technique is computationally light\nand easy to incorporate into existing implementations. We tested the efficacy\nof spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we\nexperimentally confirmed that spectrally normalized GANs (SN-GANs) is capable\nof generating images of better or equal quality relative to the previous\ntraining stabilization techniques.",
            "authors": [
                "Takeru Miyato",
                "Toshiki Kataoka",
                "Masanori Koyama",
                "Yuichi Yoshida"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999999306000799,
        "task": "Image Generation",
        "task_prob": 0.9874427990385293
    },
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            },
            {
                "name": "MNIST"
            },
            {
                "name": "CelebA"
            },
            {
                "name": "SVHN"
            },
            {
                "name": "STL-10"
            }
        ]
    }
}
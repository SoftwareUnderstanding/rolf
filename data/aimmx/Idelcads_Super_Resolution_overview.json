{
    "visibility": {
        "visibility": "public"
    },
    "name": "Super Resolution Overview: Personal Project (July 2020)",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "Idelcads",
                "owner_type": "User",
                "name": "Super_Resolution_overview",
                "url": "https://github.com/Idelcads/Super_Resolution_overview",
                "stars": 2,
                "pushed_at": "2021-03-18 17:25:33+00:00",
                "created_at": "2020-10-22 13:34:27+00:00",
                "language": "Python",
                "frameworks": [
                    "Lasagne",
                    "Theano",
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": "Code",
                "sha": "f1f1d46f8fbe545a22b6535cbf8683eda47b813a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Idelcads/Super_Resolution_overview/tree/main/Code"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "Publication",
                "sha": "9d5efa46312f26bc59cbe3c5a17bde57fad93e33",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Idelcads/Super_Resolution_overview/tree/main/Publication"
                    }
                },
                "num_files": 3
            }
        ]
    },
    "authors": [
        {
            "name": "Idelcads",
            "github_id": "Idelcads"
        }
    ],
    "tags": [],
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/Idelcads/Super_Resolution_overview",
            "stars": 2,
            "issues": true,
            "readme": "# Super Resolution Overview: Personal Project (July 2020)\n[***Project-1***](https://github.com/Idelcads/Super_Resolution_overview#Project-1) \\\n[***Project-2***](https://github.com/Idelcads/Super_Resolution_overview#Project-2) \n\n---\n\nI'm using `PyTorch-cpu 1.1.0`, `Scipy 1.5.2`, `Lasagne 0.2.dev1` and `Tensorflow 2.1.0` in `Python 3.7`.\n\n---\n# Project-1\nThe Aim of this personal project is to make a survey of the principal methods used for increase the resolution of images using deep-learning (DL) algorithms and test few programs available.\n\nAs a Head start in understanding GAN algorithms, some links are suggested in the last section.\n\n[***Survey***](https://github.com/Idelcads/Super_Resolution_overview#Survey) \\\n[***Existing_codes***](https://github.com/Idelcads/Super_Resolution_overview#Existing_codes) \\\n[***Remarks***](https://github.com/Idelcads/Super_Resolution_overview#Remarks) \\\n[***Problems***](https://github.com/Idelcads/Super_Resolution_overview#Problems) \n\n\n## Survey\n\nFirst of all, it is important to specify that it seems to emerge 2 main methods allowing to increase the quality of an image via Deep Learning methods (DL) : \n\n* **1st Method (CNN & GAN):** tTis method is based on the use on DL methods including CNN and GAN. This can also be found in literature, one publication [1] \u201cSurvey_SR.pdf\u201d summarizes the different steps allowing the use of DL for Super-Resolution (SR). Another publication [2] \u201cGAN_for_SR.pdf\u201d is dedicated to the use of GANs in SR applications. The codes tested and provided during this project are based the methods detailed in these two publications and particularly the architecture of GANs.\n\n* **2nd Method (without GAN):** another method, that seems to be possible without the use of GAN, is given in details in the following article [3] (https://towardsdatascience.com/deep-learning-based-super-resolution-without-using-a-gan-11c9bb5b6cd5). The author actually justifies the use of this method by stating that \u00ab  One of the limitations of GANs is that they are effectively a lazy approach as their loss function, the critic, is trained as part of the process and not specifically engineered for this purpose. This could be one of the reasons many models are only good at super resolution and not image repair \u00bb. In this article, the author goes into details about the different implemented steps:\nUne autre m\u00e9thode semble \u00eatre possible sans l\u2019utilisation d\u2019un GAN et est d\u00e9taill\u00e9e dans cet article [3] (https://towardsdatascience.com/deep-learning-based-super-resolution-without-using-a-gan-11c9bb5b6cd5). L\u2019auteur justifie l\u2019utilisation de la m\u00e9thode de la mani\u00e8re suivante :   \u00ab  One of the limitations of GANs is that they are effectively a lazy approach as their loss function, the critic, is trained as part of the process and not specifically engineered for this purpose. This could be one of the reasons many models are only good at super resolution and not image repair \u00bb. Dans cet article, l\u2019auteur d\u00e9taille les diff\u00e9rentes \u00e9tapes mises en \u0153uvre dont voicis la liste :\n  * A U-Net architecture with cross connections similar to a DenseNet\n  * A ResNet-34 based encoder and a decoder based on ResNet-34\n  * Pixel Shuffle upscaling with ICNR initialisation\n  * Transfer learning from pretrained ImageNet models\n  * A loss function based on activations from a VGG-16 model, pixel loss and gram matrix loss\n  * Discriminative learning rates\n  * Progressive resizing \n \nThough I did not dive into the details of the second method, seeing that i could not find a \u201cready to use\u201d code. Also considering the given time frame it does not seem like the appropriate solution for the short term. \n\n\n## Existing_codes\n\n3 different codes were tested. All three of them based on the GAN method. They allow the use of pre-trained models. These models are generated using databases (via image banks) containing high quality images (HQ) that are voluntarily degraded then used as entries for the generator model. The advantage of testing several codes is to be able to test and generate models from different frameworks.\n\n* **Code n\u00b01:** \\\nCode developed by Sagar Vinodabadu available on Github: (https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Super-Resolution#some-more-examples) \\\n*Allows the reading of pre-trained models. **.pth** (models generated via  the **PyTorch** framework) and the generating of new models. It also permits the comparison of three methods, GAN, RestNet and Bicubic interpolation.*\\\nThe checkpoint_srgan.pth model was trained using the MS COCO database from 120K images (people, dog, landscape ...) \n\n* **Code n\u00b02:** \\\nCode developed by Alex J. Champandard available on Github: (https://github.com/alexjc/neural-enhance#1-examples--usage) \\\n*Allows the reading of pre-trained models. **.pth.bz2** (models generated via  the **Lasagne** framework) and the generating of new models*\\\nWe are not aware of the Data bank of images used to generate the provided pre-trained models.\n\n* **Code n\u00b03:** \\\n*Allows the reading of pre-trained models. **.pb** (models generated via  the **tensorflow** framework)*\\\nIt is possible to train a new ESPCN model using the following works: https://github.com/fannymonori/TF-ESPCN. Though I did not go into the details of this possibility. \n\n## Remarks\n\n1. Not owning a powerful enough PC, it was impossible for me to traim my own models using the provided codes.\n\n2. All calculation were made using the CPU.\n\n3. In order to not overload the memory (RAM) of my PC, only low resolution images were used for the tests (ali.jpg and lowres.jpg).\n\n## Results\n\nThe test was performed with a low resolution image (ali.png). The obtained results are shown in the results section for each code.\n\nIn view of the details given for each code, the one with the best result for our study (SR on an image of Mohammed Ali) is n \u00b0 1, which also makes it possible to easily compare the methods. This is most likely due to the fact that the model was learned with images that are somewhat consistent with our subject. However, to generate a model that is truly specific to our expectations (improving the quality of an image of Mohammed Ali), our model would need to be able to learn by using the celebrity portrait image database available on DockerHub for example. We can observe the following result:  \n\n![alt text](https://github.com/Idelcads/Super_Resolution_overview/blob/main/Images_readme/result_code1.bmp)\n\nThe second code makes it possible to attain results that are currently not usable in view of the obtained images. However, we can recognize that the magnification function is well respected. The issue is most likely due to a poor reading of the image after processing or to a poor conversion. \n\n![alt text](https://github.com/Idelcads/Super_Resolution_overview/blob/main/Images_readme/result_code2.png)\n\nThe third code is very basic and it simply allows to charge a model to be tested. In view of the model used for the test, the result remains correct. \n\n**Concerning the learning of a new model or the possibily to develop our own application the code n\u00b01 seems to be the best option. Furthermore if we need to modify the architecture of the generetor or the discriminator we can easily start from the file `models.py`**\n\n---\n\n# Project-2\n\nWe are now interested in the possibility of applying the Super Resolution method to a video and no longer to a single image. A publication [4] \"SR_for_video.pdf\" addresses the subject.\n\nIt is interesting to note that for the case of an image, the low resolution image (shown in the following image) is the only entry for the GAN.\n\n![alt text](https://github.com/Idelcads/Super_Resolution_overview/blob/main/Images_readme/1.png)\n\nIn the case of a video, the GAN receives, as entry,  multiple low resolution images  t-1, t, t+1 taken from the video, in order to generate a new high resolution image t shown in the following example.\n\n![alt text](https://github.com/Idelcads/Super_Resolution_overview/blob/main/Images_readme/2.png)\n\n---\n\n# Tutorial to better understand GAN generation\n\nhttps://www.youtube.com/watch?v=5RYETbFFQ7s \\\nhttps://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html \\\nhttps://towardsdatascience.com/build-a-super-simple-gan-in-pytorch-54ba349920e4 \\\n\n\\\nReferences\n\n[1] Zhilao W., Jian Chen., Steven C.H. Hoi, Fellow, IEEE \\\nDeep Learning for Image Super-resolution: A Survey \\\nScientific publication available at : https://arxiv.org/abs/1902.06068 \\\n[2] Christian Ledig, Lucas Theis, Ferenc Husz\u00b4ar, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi \\\nPhoto-Realistic Single Image Super-Resolution Using a Generative Adversarial Network \\\nScientific publication available at : https://arxiv.org/abs/1609.04802 \\\n[3] Christopher Thomas \\\nWeb article available at : https://towardsdatascience.com/deep-learning-based-super-resolution-without-using-a-gan-11c9bb5b6cd5 \\\n[4] Santiago L\u00f3pez-Tapia, Alice Lucas, Rafael Molina and Aggelos K. Katsaggelos. \\\nA Single Video Super-Resolution GAN for Multiple Downsampling Operators based on Pseudo-Inverse Image Formation Models \\\nScientific publication available at : https://arxiv.org/ftp/arxiv/papers/1907/1907.01399.pdf \\\n",
            "readme_url": "https://github.com/Idelcads/Super_Resolution_overview",
            "frameworks": [
                "Lasagne",
                "Theano",
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Deep Learning for Image Super-resolution: A Survey",
            "arxiv": "1902.06068",
            "year": 2019,
            "url": "http://arxiv.org/abs/1902.06068v2",
            "abstract": "Image Super-Resolution (SR) is an important class of image processing\ntechniques to enhance the resolution of images and videos in computer vision.\nRecent years have witnessed remarkable progress of image super-resolution using\ndeep learning techniques. This article aims to provide a comprehensive survey\non recent advances of image super-resolution using deep learning approaches. In\ngeneral, we can roughly group the existing studies of SR techniques into three\nmajor categories: supervised SR, unsupervised SR, and domain-specific SR. In\naddition, we also cover some other important issues, such as publicly available\nbenchmark datasets and performance evaluation metrics. Finally, we conclude\nthis survey by highlighting several future directions and open issues which\nshould be further addressed by the community in the future.",
            "authors": [
                "Zhihao Wang",
                "Jian Chen",
                "Steven C. H. Hoi"
            ]
        },
        {
            "title": "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network",
            "arxiv": "1609.04802",
            "year": 2016,
            "url": "http://arxiv.org/abs/1609.04802v5",
            "abstract": "Despite the breakthroughs in accuracy and speed of single image\nsuper-resolution using faster and deeper convolutional neural networks, one\ncentral problem remains largely unsolved: how do we recover the finer texture\ndetails when we super-resolve at large upscaling factors? The behavior of\noptimization-based super-resolution methods is principally driven by the choice\nof the objective function. Recent work has largely focused on minimizing the\nmean squared reconstruction error. The resulting estimates have high peak\nsignal-to-noise ratios, but they are often lacking high-frequency details and\nare perceptually unsatisfying in the sense that they fail to match the fidelity\nexpected at the higher resolution. In this paper, we present SRGAN, a\ngenerative adversarial network (GAN) for image super-resolution (SR). To our\nknowledge, it is the first framework capable of inferring photo-realistic\nnatural images for 4x upscaling factors. To achieve this, we propose a\nperceptual loss function which consists of an adversarial loss and a content\nloss. The adversarial loss pushes our solution to the natural image manifold\nusing a discriminator network that is trained to differentiate between the\nsuper-resolved images and original photo-realistic images. In addition, we use\na content loss motivated by perceptual similarity instead of similarity in\npixel space. Our deep residual network is able to recover photo-realistic\ntextures from heavily downsampled images on public benchmarks. An extensive\nmean-opinion-score (MOS) test shows hugely significant gains in perceptual\nquality using SRGAN. The MOS scores obtained with SRGAN are closer to those of\nthe original high-resolution images than to those obtained with any\nstate-of-the-art method.",
            "authors": [
                "Christian Ledig",
                "Lucas Theis",
                "Ferenc Huszar",
                "Jose Caballero",
                "Andrew Cunningham",
                "Alejandro Acosta",
                "Andrew Aitken",
                "Alykhan Tejani",
                "Johannes Totz",
                "Zehan Wang",
                "Wenzhe Shi"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            },
            {
                "name": "COCO"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999994372641565,
        "task": "Image Generation",
        "task_prob": 0.9711432841321416
    }
}
{
    "visibility": {
        "visibility": "public"
    },
    "name": "Transferring GANs generating images from limited data",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "DevashishJoshi",
                "owner_type": "User",
                "name": "Transferring-GANs-FYP",
                "url": "https://github.com/DevashishJoshi/Transferring-GANs-FYP",
                "stars": 0,
                "pushed_at": "2019-03-19 11:46:52+00:00",
                "created_at": "2019-02-23 10:52:21+00:00",
                "language": "Python",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "0c5dcf1729beabf56bcd72e1e2f3c128b760ae4b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DevashishJoshi/Transferring-GANs-FYP/blob/master/.gitignore"
                    }
                },
                "size": 67
            },
            {
                "type": "code",
                "name": "config.py",
                "sha": "3037c7c49faa8ab8b8ea0a850e3e03eb026899da",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DevashishJoshi/Transferring-GANs-FYP/blob/master/config.py"
                    }
                },
                "size": 216
            },
            {
                "type": "code",
                "name": "config.pyc",
                "sha": "1a070bc5d1bfb570a2383a274e4dcab12d1cd756",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DevashishJoshi/Transferring-GANs-FYP/blob/master/config.pyc"
                    }
                },
                "size": 353
            },
            {
                "type": "code",
                "name": "hello.txt",
                "sha": "ce013625030ba8dba906f756967f9e9ca394464a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DevashishJoshi/Transferring-GANs-FYP/blob/master/hello.txt"
                    }
                },
                "size": 6
            },
            {
                "type": "code",
                "name": "tflib",
                "sha": "b61bd9f1d85862a79fd2e047dcd1b8a6b50c57d8",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DevashishJoshi/Transferring-GANs-FYP/tree/master/tflib"
                    }
                },
                "num_files": 18
            },
            {
                "type": "code",
                "name": "transfer_gan.py",
                "sha": "3263caa67a70b5fba2f0d463c654f388ad65d907",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DevashishJoshi/Transferring-GANs-FYP/blob/master/transfer_gan.py"
                    }
                },
                "size": 20038
            }
        ]
    },
    "authors": [
        {
            "name": "DevashishJoshi",
            "github_id": "DevashishJoshi"
        },
        {
            "name": "aagam97",
            "github_id": "aagam97"
        }
    ],
    "tags": [],
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/DevashishJoshi/Transferring-GANs-FYP",
            "stars": 0,
            "issues": true,
            "readme": "# Transferring GANs generating images from limited data\n# Abstract: \nTransferring the knowledge of pretrained networks to new domains by means of finetuning is a widely used practice for applications based on discriminative models. To the best of our knowledge this practice has not been studied within the context of generative deep networks. Therefore, we study domain adaptation applied to image generation with generative adversarial networks. We evaluate several aspects of domain adaptation, including the impact of target domain size, the relative distance between source and target domain, and the initialization of conditional GANs. Our results show that using knowledge from pretrained networks can shorten the convergence time and can significantly improve the quality of the generated images, especially when the target data is limited. We show that these conclusions can also be drawn for conditional GANs even when the pretrained model was trained without conditioning. Our results also suggest that density may be more important than diversity and a dataset with one or few densely sampled classes may be a better source model than more diverse datasets such as ImageNet or Places.\n\n# Overview \n- [Dependences](#dependences)\n- [Installation](#installtion)\n- [Instructions](#instructions)\n- [Results](#results)\n- [References](#references)\n- [Contact](#contact)\n# Dependences \n- Python2.7, NumPy, SciPy, NVIDIA GPU\n- **Tensorflow:** the version should be more 1.0(https://www.tensorflow.org/)\n- **Dataset:** lsun-bedroom(http://lsun.cs.princeton.edu/2017/) or your dataset \n\n# Installation \n- Install tensorflow\n- Opencv \n# Instructions\n- Using 'git clone https://github.com/yaxingwang/Transferring-GANs'\n\n    You will get new folder whose name is 'Transferring-GANs' in your current path, then  use 'cd Transferring-GANs' to enter the downloaded new folder\n    \n- Download pretrain models[Google driver](https://drive.google.com/file/d/1e7Pw-m-DgAiB_aQnNUUwBRVFc2izRiRw/view?usp=sharing); [Tencent qcloud](https://share.weiyun.com/5mBsISh)\n\n    Uncompressing downloaded folder to current folder, then you have new folder 'transfer_model'  which contains two folders: 'conditional', 'unconditional', each of which has four folders: 'imagenet', 'places', 'celebA', 'bedroom'\n\n- Download dataset or use your dataset.\n\n    I have shown one example and you could make it with same same form.\n\n- Run 'python transfer_gan.py'\n\n   Runing code with default setting. The pretrained model can be seleted by changing the parameter 'TARGET_DOMAIN'\n \n- Conditional GAN \n  If you are interested in using conditional model, just setting parameter 'ACGAN = True'\n# Results \nUsing pretrained models not only get high performance, but fastly attach convergence. In following figure, we show conditional and unconditional settings.\n<br>\n<p align=\"center\"><img width=\"100%\" height='60%'src=\"results/FID.png\" /></p>\n\n\n\n# References \n- \\[1\\] 'Improved Training of Wasserstein GANs' by Ishaan Gulrajani et. al, https://arxiv.org/abs/1704.00028, (https://github.com/igul222/improved_wgan_training)[code] \n- \\[2\\] 'GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium' by Martin Heusel  et. al, https://arxiv.org/abs/1706.08500, (https://github.com/bioinf-jku/TTUR)[code]\n# Contact\n\nIf you run into any problems with this code, please submit a bug report on the Github site of the project. For another inquries pleace contact with me: yaxing@cvc.uab.es\n",
            "readme_url": "https://github.com/DevashishJoshi/Transferring-GANs-FYP",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium",
            "arxiv": "1706.08500",
            "year": 2017,
            "url": "http://arxiv.org/abs/1706.08500v6",
            "abstract": "Generative Adversarial Networks (GANs) excel at creating realistic images\nwith complex models for which maximum likelihood is infeasible. However, the\nconvergence of GAN training has still not been proved. We propose a two\ntime-scale update rule (TTUR) for training GANs with stochastic gradient\ndescent on arbitrary GAN loss functions. TTUR has an individual learning rate\nfor both the discriminator and the generator. Using the theory of stochastic\napproximation, we prove that the TTUR converges under mild assumptions to a\nstationary local Nash equilibrium. The convergence carries over to the popular\nAdam optimization, for which we prove that it follows the dynamics of a heavy\nball with friction and thus prefers flat minima in the objective landscape. For\nthe evaluation of the performance of GANs at image generation, we introduce the\n\"Fr\\'echet Inception Distance\" (FID) which captures the similarity of generated\nimages to real ones better than the Inception Score. In experiments, TTUR\nimproves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP)\noutperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN\nBedrooms, and the One Billion Word Benchmark.",
            "authors": [
                "Martin Heusel",
                "Hubert Ramsauer",
                "Thomas Unterthiner",
                "Bernhard Nessler",
                "Sepp Hochreiter"
            ]
        },
        {
            "title": "Improved Training of Wasserstein GANs",
            "arxiv": "1704.00028",
            "year": 2017,
            "url": "http://arxiv.org/abs/1704.00028v3",
            "abstract": "Generative Adversarial Networks (GANs) are powerful generative models, but\nsuffer from training instability. The recently proposed Wasserstein GAN (WGAN)\nmakes progress toward stable training of GANs, but sometimes can still generate\nonly low-quality samples or fail to converge. We find that these problems are\noften due to the use of weight clipping in WGAN to enforce a Lipschitz\nconstraint on the critic, which can lead to undesired behavior. We propose an\nalternative to clipping weights: penalize the norm of gradient of the critic\nwith respect to its input. Our proposed method performs better than standard\nWGAN and enables stable training of a wide variety of GAN architectures with\nalmost no hyperparameter tuning, including 101-layer ResNets and language\nmodels over discrete data. We also achieve high quality generations on CIFAR-10\nand LSUN bedrooms.",
            "authors": [
                "Ishaan Gulrajani",
                "Faruk Ahmed",
                "Martin Arjovsky",
                "Vincent Dumoulin",
                "Aaron Courville"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            },
            {
                "name": "CelebA"
            },
            {
                "name": "One Billion Word"
            },
            {
                "name": "SVHN"
            },
            {
                "name": "CIFAR-10"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999995010040493,
        "task": "Image Generation",
        "task_prob": 0.9895585724159417
    }
}
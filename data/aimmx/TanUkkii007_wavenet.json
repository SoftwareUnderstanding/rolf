{
    "visibility": {
        "visibility": "public",
        "license": "Other"
    },
    "name": "WaveNet ![CircleCI](https://circleci.com/gh/TanUkkii007/wavenet)",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "TanUkkii007",
                "owner_type": "User",
                "name": "wavenet",
                "url": "https://github.com/TanUkkii007/wavenet",
                "stars": 6,
                "pushed_at": "2018-09-17 10:56:13+00:00",
                "created_at": "2018-07-29 05:20:54+00:00",
                "language": "Python",
                "description": " An implementation of WaveNet: A Generative Model for Raw Audio https://arxiv.org/abs/1609.03499",
                "license": "Other",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".circleci",
                "sha": "1f6bea8f42b131f968e96737e31c4263318f1b07",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/tree/master/.circleci"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "9b284d76bd4e9a92525aaac9eff25ce3c0626ade",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/blob/master/.gitignore"
                    }
                },
                "size": 1290
            },
            {
                "type": "code",
                "name": "BUILD",
                "sha": "3d1a6ae8adf1ea8df710524da214dd9241c84de5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/blob/master/BUILD"
                    }
                },
                "size": 1310
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "fd8e89b1a04156e11d0a3ec7059f1b69fe181659",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/blob/master/LICENSE"
                    }
                },
                "size": 2213
            },
            {
                "type": "code",
                "name": "WORKSPACE",
                "sha": "5789e587aaa01be523ddaf7f080a5c9c28e210fa",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/blob/master/WORKSPACE"
                    }
                },
                "size": 27
            },
            {
                "type": "code",
                "name": "datasets",
                "sha": "986d6c212314de97b545a935ab73cf85624c201c",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/tree/master/datasets"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "docs",
                "sha": "9fb7fdb3b026d3ca5a82c754ff9722ef10a8475a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/tree/master/docs"
                    }
                },
                "num_files": 6
            },
            {
                "type": "code",
                "name": "environment.yml",
                "sha": "ae0fb8d2282800fbfa38b98745cdba2419358277",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/blob/master/environment.yml"
                    }
                },
                "size": 1724
            },
            {
                "type": "code",
                "name": "hparams.py",
                "sha": "939442cb06f9c0e47cd423da1606b4ef83d0d376",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/blob/master/hparams.py"
                    }
                },
                "size": 1732
            },
            {
                "type": "code",
                "name": "layers",
                "sha": "0f49d6b8f77dc58aa1d7a6f5b98e95ef73e34d20",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/tree/master/layers"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "models",
                "sha": "5f9c889594bac7f257fe642199bc2d332c73a59b",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/tree/master/models"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "ops",
                "sha": "7fa5ce5b04056600d14d13f9793e03cf05cca95e",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/tree/master/ops"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "predict.py",
                "sha": "b89faee72faa45e5bb0610f4c8998835c2145e3e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/blob/master/predict.py"
                    }
                },
                "size": 3327
            },
            {
                "type": "code",
                "name": "preprocess.py",
                "sha": "74544e2e11c0413cc787b1389acaba9cec81f62e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/blob/master/preprocess.py"
                    }
                },
                "size": 694
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "89037f663b42d181d3ed161a7c35336e285089a3",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/blob/master/train.py"
                    }
                },
                "size": 4809
            },
            {
                "type": "code",
                "name": "utils",
                "sha": "c7529e63df2cc102003f79b2419b0862a2eac012",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/TanUkkii007/wavenet/tree/master/utils"
                    }
                },
                "num_files": 3
            }
        ]
    },
    "authors": [
        {
            "name": "Yusuke Yasuda",
            "email": "yusuke.007.yasud@gmail.com",
            "github_id": "TanUkkii007"
        }
    ],
    "tags": [],
    "description": " An implementation of WaveNet: A Generative Model for Raw Audio https://arxiv.org/abs/1609.03499",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/TanUkkii007/wavenet",
            "stars": 6,
            "issues": true,
            "readme": "# WaveNet [![CircleCI](https://circleci.com/gh/TanUkkii007/wavenet.svg?style=svg)](https://circleci.com/gh/TanUkkii007/wavenet)\n\nAn implementation of WaveNet: A Generative Model for Raw Audio https://arxiv.org/abs/1609.03499 .\n\nThis project is originated from the hands-on lecture of SPCC 2018.\nThis project rewrote codes of the lecture with following criteria:\n\n- Simple, modular and easy to read\n- Using high level tensorflow APIs: `tf.layers.Layer`, `tf.data.Dataset`, `tf.estimator.Estimator`.\n- Fix discrepancy of the results between training and inference that causes workaround to dispose wrong results at early steps of inference samples.\n- Review the lecture and deepen my understandings\n\nThis project has following limitations.\n\n- Supported data set is [LJSpeech](https://keithito.com/LJ-Speech-Dataset) only\n- No sophisticated initialization, optimization and regularization techniques that was in the lecture\n- Lack of hyper-parameter tuning.\n- Confirmed generated audio are low quality\n\nFor research-ready implementations, please refer to\n\n- [CURRENNT_MODIFIED](https://github.com/TonyWangX/CURRENNT_MODIFIED)\n\n\nThis implementation was tested with Tesla K20c (4.94GiB GPU memory).\n\n# Installing dependencies\n\nThis project requires python >= 3.6 and tensorflow >= 1.8.\n\nThe other dependencies can be installed with `conda`.\n\n```bash\nconda env create -f=environment.yml\n```\n\nThe following packages are installed.\n\n- pyspark=2.3.1\n- librosa==0.6.1 \n- matplotlib=2.2.2\n- hypothesis=3.59.1\n- docopt=0.6.2\n\n# Pre-processing\n\nThe following pre-processing command executes mel-spectrogram extraction and serialize waveforms, mel-spectrograms and the other meta data into TFRecord (protocol buffer with content hash header) format.\n\n```bash\npython preprocess.py ljspeech /path/to/input/corpus/dir /path/to/output/dir/of/preprocessed/data\n```\n\nAfter pre-processing, split data into training, validation, and test sets.\n\nA simple method to create list files is using `ls` command.\n\n```bash\nls /path/to/output/dir/of/preprocessed/data | sed s/.tfrecord// > list.txt\n```\n\nThen split the `list.txt` into three files.\n\n# Training\n\n```bash\npython train.py --data-root=/path/to/output/dir/of/preprocessed/data --checkpoint-dir=/path/to/checkpoint/dir --dataset=ljspeech --training-list-file=/path/to/file/listing/training/data --validation-list-file=/path/to/file/listing/validation/data --log-file=/path/to/log/file\n```\n\nYou can see training and validation losses in a log file and on `tensorboard`.\n\n```bash\ntensorboard --logdir=/path/to/checkpoint/dir\n```\n\n(orange line: training loss, blue line: validation loss)\n\n![training and validation loss on tensorboard](./docs/Screen_Shot_2018-08-05_at_16.35.41.png)\n\nAt validation time, predicted waveforms with teacher forcing are generated as images in the checkpoint directory.\n\n(above: natural, below: predicted)\n\nEpoch 1\n![training and validation loss on tensorboard](./docs/14RDE666_R2xcc3VWmYFTKX1qW5s8OchRFN24AayQuQ.png)\n\nEpoch 2\n![training and validation loss on tensorboard](./docs/1QNbsJlzSqbda-LCOXh-cVFvgq1FMH4gto0g1IrP0Mg.png)\n\nEpoch 6\n![training and validation loss on tensorboard](./docs/18d-eCZcZkfvdVgw7PG-PwBTRRYxyQNpwNCLxuHx6Ow.png)\n\nEpoch 10\n![training and validation loss on tensorboard](./docs/1JsFL_Bde3BTbRIFKoNN_VWEItyEt5qgpcmXO5Ar6mw.png)\n\n\n# Prediction\n\n```bash\npython predict.py --data-root=/path/to/output/dir/of/preprocessed/data --checkpoint-dir=/path/to/checkpoint/dir --dataset=ljspeech --test-list-file=/path/to/file/listing/test/data --output-dir=/path/to/output/dir\n```\n\nAt prediction time, predicted samples are generated as audio files and image files.\n\n(above: natural, below: predicted)\n\n![training and validation loss on tensorboard](./docs/1xXE8saljiILaKtMkfIJfdMJws8PWdywzZtN4YQAFFA.png)\n\n\n# Testing\n\nCausal convolution is implemented in two different ways. At training time, causal convolution is executed in parallel with optimized cuda kernel.\nAt inference time, causal convolution is executed sequentially with matrix multiplication. The result of two implementation should be same. \nThis project checks the equality of the two implementation with property based test.\n\n```bash\npython -m unittest ops/convolutions_test.py\n\npython -m unittest layers/modules_test.py\n```",
            "readme_url": "https://github.com/TanUkkii007/wavenet",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "WaveNet: A Generative Model for Raw Audio",
            "arxiv": "1609.03499",
            "year": 2016,
            "url": "http://arxiv.org/abs/1609.03499v2",
            "abstract": "This paper introduces WaveNet, a deep neural network for generating raw audio\nwaveforms. The model is fully probabilistic and autoregressive, with the\npredictive distribution for each audio sample conditioned on all previous ones;\nnonetheless we show that it can be efficiently trained on data with tens of\nthousands of samples per second of audio. When applied to text-to-speech, it\nyields state-of-the-art performance, with human listeners rating it as\nsignificantly more natural sounding than the best parametric and concatenative\nsystems for both English and Mandarin. A single WaveNet can capture the\ncharacteristics of many different speakers with equal fidelity, and can switch\nbetween them by conditioning on the speaker identity. When trained to model\nmusic, we find that it generates novel and often highly realistic musical\nfragments. We also show that it can be employed as a discriminative model,\nreturning promising results for phoneme recognition.",
            "authors": [
                "Aaron van den Oord",
                "Sander Dieleman",
                "Heiga Zen",
                "Karen Simonyan",
                "Oriol Vinyals",
                "Alex Graves",
                "Nal Kalchbrenner",
                "Andrew Senior",
                "Koray Kavukcuoglu"
            ]
        }
    ],
    "domain": {
        "domain_type": "Speech",
        "domain_prob": 0.9865651613274168
    }
}
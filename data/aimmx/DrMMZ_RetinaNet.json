{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "RetinaNet for Object Detection",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "DrMMZ",
                "owner_type": "User",
                "name": "RetinaNet",
                "url": "https://github.com/DrMMZ/RetinaNet",
                "stars": 4,
                "pushed_at": "2022-01-17 19:03:09+00:00",
                "created_at": "2021-07-06 19:17:22+00:00",
                "language": "Jupyter Notebook",
                "description": "RetinaNet for Object Detection in TensorFlow2 and Applications",
                "license": "MIT License",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "837ba5a833c34292949c43504d9182777928991c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DrMMZ/RetinaNet/blob/main/LICENSE"
                    }
                },
                "size": 1072
            },
            {
                "type": "code",
                "name": "model",
                "sha": "ecb480f0f4cc5cae082cd81b8d183d57ac7778b4",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DrMMZ/RetinaNet/tree/main/model"
                    }
                },
                "num_files": 12
            },
            {
                "type": "code",
                "name": "tutorial",
                "sha": "1364bab778580c22aa946f8459ba9abb235b8e56",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DrMMZ/RetinaNet/tree/main/tutorial"
                    }
                },
                "num_files": 1
            }
        ]
    },
    "authors": [
        {
            "name": "Ming Ming Zhang",
            "github_id": "DrMMZ"
        }
    ],
    "tags": [
        "retinanet",
        "object-detection",
        "focal-loss",
        "nuclei-detection",
        "sku-110k",
        "tensorflow",
        "widerface-dataset",
        "global-wheat-detection"
    ],
    "description": "RetinaNet for Object Detection in TensorFlow2 and Applications",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/DrMMZ/RetinaNet",
            "stars": 4,
            "issues": true,
            "readme": "# RetinaNet for Object Detection\n\n[RetinaNet](https://arxiv.org/abs/1708.02002) is an efficient one-stage object detector trained with the focal loss. This repository is a TensorFlow2 implementation of RetinaNet and its applications, aiming for creating a tool in object detection task that can be easily extended to other datasets or used in building projects. It includes\n\n1. source code of RetinaNet and its configuration (multiple GPUs training and detecting);\n2. source code of data (RetinaNet's inputs) generator using multiple CPU cores; \n3. source code of utilities such as image/mask preprocessing, augmetation, average precision (AP) metric, visualization and so on;\n4. jupyter notebook demonstration using RetinaNet in training and real-time detection on some datasets. \n\n\n### Updates\n* soon/2022: Will have an update to clean up some mess and provide a tutorial on how to generate a customized dataset and then train.\n* 10/2/2021: Solve OOM problem when inferencing by fixing resnet_fpn.compute_fmap().\n\n### Applications\n\nThe following are example detections.\n\n* [The Global Wheat Challenge 2021](https://www.aicrowd.com/challenges/global-wheat-challenge-2021) is a detection and counting challenge of wheat head. By using this implementation and trained only on the given training set, we are able to achieve the following result (evaluated on the test set used for competition submission):\n\n|GPU| size| detection time (second per image)| evaluation metric (ADA)|\n|---|---|---|---|\n|GeForce RTX 2070 SUPER|1024x1024|0.11|0.478|\n\nwhere the evaluation metric ADA is Average Domain Accuracy defined in [here](https://www.aicrowd.com/challenges/global-wheat-challenge-2021#evaluation-criteria). \n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/DrMMZ/drmmz.github.io/master/images/wheat_movie.gif\" width='360' height='360'/>\n</p>\n\n\n* Video detection in human faces: \n\nhttps://user-images.githubusercontent.com/38026940/132159211-6951ba51-9d59-4d38-b13e-259504195ebc.mp4\n\nScenes are taken from *The Bourne Ultimatum (2007 film)* and the cover page is from *The Bourne Identity (2002 film)*. It was trained on the [wider face](http://shuoyang1213.me/WIDERFACE/) dataset. \n\nMoveover, it can be used to recognize Jason Bourne. See the next video and [ProtoNet for Few-Shot Learning in TensorFlow2 and Applications](https://github.com/DrMMZ/ProtoNet) for details.\n\nhttps://user-images.githubusercontent.com/38026940/132160401-ee1f22ca-0b0f-4471-8b62-6144c76cf21c.mp4\n\n\n* My own dataset, *empty returns operations (ERO-CA)*, is a collection of images such that each contains empty beer, wine and liquor cans or bottles in densely packed scenes that can be returned for refunds in Canada. The goal is to count the number of returns fast and accurately, instead of manually checking by human (specially for some people like me who is bad on counting). The dataset (as of July 15 2021) consists of 47 labeled cellphone images in cans, variety of positions. If you are interested in contributing to this dataset or project, please [email](mailto:mmzhangist@gmail.com) me.\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/DrMMZ/drmmz.github.io/master/images/ero_movie.gif\" width='360' height='360'/>\n</p> \n\n\n* The [SKU-110K](https://github.com/eg4000/SKU110K_CVPR19) dataset, focusing on detection in densely packed scenes. Indeed, our ERO-CA detection above used transfer learning from SKU-110K.\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/DrMMZ/drmmz.github.io/master/images/sku_movie.gif\" width='360' height='360'/>\n</p>\n\n\n* The [nuclei](https://www.kaggle.com/c/data-science-bowl-2018) dataset, identifying the cells\u2019 nuclei. \n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/DrMMZ/drmmz.github.io/master/images/nuclei_movie.gif\" width='360' height='360'/>\n</p> \n\n\n### Requirements\n`python 3.7.9`, `tensorflow 2.3.1`, `matplotlib 3.3.4`, `numpy 1.19.2`, `opencv 4.5.1`, `scipy 1.6.0`, `scikit-image 0.17.2` and `tensorflow-addons 0.13.0`\n\n### References\n1. Lin et al., *Focal Loss for Dense Object Detection*, https://arxiv.org/abs/1708.02002, 2018\n2. *Mask R-CNN for Object Detection and Segmentation*, https://github.com/matterport/Mask_RCNN, 2018\n",
            "readme_url": "https://github.com/DrMMZ/RetinaNet",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Focal Loss for Dense Object Detection",
            "arxiv": "1708.02002",
            "year": 2017,
            "url": "http://arxiv.org/abs/1708.02002v2",
            "abstract": "The highest accuracy object detectors to date are based on a two-stage\napproach popularized by R-CNN, where a classifier is applied to a sparse set of\ncandidate object locations. In contrast, one-stage detectors that are applied\nover a regular, dense sampling of possible object locations have the potential\nto be faster and simpler, but have trailed the accuracy of two-stage detectors\nthus far. In this paper, we investigate why this is the case. We discover that\nthe extreme foreground-background class imbalance encountered during training\nof dense detectors is the central cause. We propose to address this class\nimbalance by reshaping the standard cross entropy loss such that it\ndown-weights the loss assigned to well-classified examples. Our novel Focal\nLoss focuses training on a sparse set of hard examples and prevents the vast\nnumber of easy negatives from overwhelming the detector during training. To\nevaluate the effectiveness of our loss, we design and train a simple dense\ndetector we call RetinaNet. Our results show that when trained with the focal\nloss, RetinaNet is able to match the speed of previous one-stage detectors\nwhile surpassing the accuracy of all existing state-of-the-art two-stage\ndetectors. Code is at: https://github.com/facebookresearch/Detectron.",
            "authors": [
                "Tsung-Yi Lin",
                "Priya Goyal",
                "Ross Girshick",
                "Kaiming He",
                "Piotr Doll\u00e1r"
            ]
        },
        {
            "title": "The Global Wheat Challenge 2021",
            "url": "https://www.aicrowd.com/challenges/global-wheat-challenge-2021"
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "SKU-110K"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9998539015560935,
        "task": "Object Detection",
        "task_prob": 0.9837255401985052
    }
}
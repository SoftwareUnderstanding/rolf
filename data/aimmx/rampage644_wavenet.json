{
    "visibility": {
        "visibility": "public",
        "license": "Apache License 2.0"
    },
    "name": "Description",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "rampage644",
                "owner_type": "User",
                "name": "wavenet",
                "url": "https://github.com/rampage644/wavenet",
                "stars": 54,
                "pushed_at": "2017-08-09 11:20:32+00:00",
                "created_at": "2017-01-09 16:01:08+00:00",
                "language": "Python",
                "description": "WaveNet implementation with chainer",
                "license": "Apache License 2.0",
                "frameworks": []
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "72364f99fe4bf8d5262df3b19b33102aeaa791e5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rampage644/wavenet/blob/master/.gitignore"
                    }
                },
                "size": 1045
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "8dada3edaf50dbc082c9a125058f25def75e625a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rampage644/wavenet/blob/master/LICENSE"
                    }
                },
                "size": 11357
            },
            {
                "type": "code",
                "name": "assets",
                "sha": "d1ec1d2a45adc46874c6a48f90503f9b5f251052",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rampage644/wavenet/tree/master/assets"
                    }
                },
                "num_files": 13
            },
            {
                "type": "code",
                "name": "infer.py",
                "sha": "099227e45b91a9abb3a376efb748ad053e38bd55",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rampage644/wavenet/blob/master/infer.py"
                    }
                },
                "size": 3499
            },
            {
                "type": "code",
                "name": "infer_wavenet.py",
                "sha": "427ad9f2f48164dfdd47001905d27d687df2f3bd",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rampage644/wavenet/blob/master/infer_wavenet.py"
                    }
                },
                "size": 3523
            },
            {
                "type": "code",
                "name": "playground.py",
                "sha": "1c395899f2d06b79960dea76b6bff52cd5cf4895",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rampage644/wavenet/blob/master/playground.py"
                    }
                },
                "size": 6573
            },
            {
                "type": "code",
                "name": "preprocess.py",
                "sha": "acf5bd2c8e121293831eeaad0aa42d57d1df2738",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rampage644/wavenet/blob/master/preprocess.py"
                    }
                },
                "size": 1927
            },
            {
                "type": "code",
                "name": "server.py",
                "sha": "caea75d1f0a978af3f5e9204042371847a0c4ff8",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rampage644/wavenet/blob/master/server.py"
                    }
                },
                "size": 4955
            },
            {
                "type": "code",
                "name": "tests",
                "sha": "4f466acc3d90cbd4ea2103bd1733ede6b3b3c817",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rampage644/wavenet/tree/master/tests"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "54831372f7a435905b855c3b7dc83494cf0a3c6a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rampage644/wavenet/blob/master/train.py"
                    }
                },
                "size": 5328
            },
            {
                "type": "code",
                "name": "train_wavenet.py",
                "sha": "c52b616c150de010902bcc0cffacf7b3df07cb0e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rampage644/wavenet/blob/master/train_wavenet.py"
                    }
                },
                "size": 3803
            },
            {
                "type": "code",
                "name": "wavenet",
                "sha": "3b854c8e1cadafa1772e3dec2d660e4e8b50d165",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/rampage644/wavenet/tree/master/wavenet"
                    }
                },
                "num_files": 6
            }
        ]
    },
    "authors": [
        {
            "name": "Sergei Turukin",
            "email": "rampage644@gmail.com",
            "github_id": "rampage644"
        }
    ],
    "tags": [
        "wavenet",
        "pixelcnn",
        "pixelrnn",
        "chainer"
    ],
    "description": "WaveNet implementation with chainer",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/rampage644/wavenet",
            "stars": 54,
            "issues": true,
            "readme": "# Description\n\nWaveNet replication study. Before stepping up to WaveNet implementation it was decided to implement PixelCNN first as WaveNet based on its architecture.\n\nThis repository contains two modes: [Gated PixelCNN][pixelcnn-paper] and [WaveNet][wavenet-paper], see class definitions in `wavenet/models.py`.\n\nFor detailed explanation of how these model work see [my blog post](http://sergeiturukin.com/2017/02/22/pixelcnn.html).\n\n## Gated PixelCNN\n\n```\n$ python3 train.py --help\nusage: train.py [-h] [--batchsize BATCHSIZE] [--epoch EPOCH] [--gpu GPU]\n                [--resume RESUME] [--out OUT] [--hidden_dim HIDDEN_DIM]\n                [--out_hidden_dim OUT_HIDDEN_DIM] [--blocks_num BLOCKS_NUM]\n                [--gradclip GRADCLIP] [--learning_rate LEARNING_RATE]\n                [--levels LEVELS] [--dataset DATASET] [--stats STATS]\n\nPixelCNN\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --batchsize BATCHSIZE, -b BATCHSIZE\n                        Number of images in each mini-batch\n  --epoch EPOCH, -e EPOCH\n                        Number of sweeps over the dataset to train\n  --gpu GPU, -g GPU     GPU ID (negative value indicates CPU)\n  --resume RESUME, -r RESUME\n                        Resume the training from snapshot\n  --out OUT, -o OUT     Output directory\n  --hidden_dim HIDDEN_DIM, -d HIDDEN_DIM\n                        Number of hidden dimensions\n  --out_hidden_dim OUT_HIDDEN_DIM\n                        Number of hidden dimensions\n  --blocks_num BLOCKS_NUM, -n BLOCKS_NUM\n                        Number of layers\n  --gradclip GRADCLIP   Bound for gradient hard clipping\n  --learning_rate LEARNING_RATE\n                        Bound for gradient hard clipping\n  --levels LEVELS       Level number to quantisize pixel values\n  --dataset DATASET     Dataset for training. Either mnist or cifar.\n  --stats STATS         Collect layerwise statistics\n```\n\nCommand to train model on GPU with MNIST dataset (will be downloaded automatically):\n\n    python train.py -g0 --levels 256 --out data/\n\nTo train with CIFAR-10 dataset use `--dataset` switch:\n\n    python train.py -g0 --levels 256 --out data/ --dataset cifar\n\nTo save training time simplifying architecture is useful:\n * Reduce number of blocks (`--blocks_num 4`)\n * Reduce hidden dimensionality (`--hidden_dim 32`)\n * Reduce output softmax cardinality (`--levels 16`)\n\nOnce you have model trained you can generate samples.\n```\npython3 infer.py --help\nusage: infer.py [-h] [--gpu GPU] [--model MODEL] [--hidden_dim HIDDEN_DIM]\n                [--out_hidden_dim OUT_HIDDEN_DIM] [--blocks_num BLOCKS_NUM]\n                [--levels LEVELS] [--output OUTPUT] [--label LABEL]\n                [--count COUNT] [--height HEIGHT] [--width WIDTH]\n\nPixelCNN\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --gpu GPU, -g GPU     GPU ID (negative value indicates CPU)\n  --model MODEL, -m MODEL\n                        Path to model for generation\n  --hidden_dim HIDDEN_DIM, -d HIDDEN_DIM\n                        Number of hidden dimensions\n  --out_hidden_dim OUT_HIDDEN_DIM\n                        Number of hidden dimensions\n  --blocks_num BLOCKS_NUM, -n BLOCKS_NUM\n                        Number of layers\n  --levels LEVELS       Level number to quantisize pixel values\n  --output OUTPUT, -o OUTPUT\n                        Output filename\n  --label LABEL, -l LABEL\n                        Class label to generate\n  --count COUNT, -c COUNT\n                        Number of images to generate (woulld be squared: so\n                        for 10 it would generate 100)\n  --height HEIGHT       Output image height\n  --width WIDTH         Output image width\n```\n\nCommand for samples generation (you should specify exactly the same architecture for generation as you used for training otherwise you'd get weird results):\n\n    python infer.py -g0 --levels 256 -m data/pixecnn_XXXXX --output samples.jpg\n\n## WaveNet\n\nWaveNet model is still in 'work in progress' state, some minor changes could happen. Also, it wasn't trained end-to-end on any dataset yet (only very small ones).\n\nWaveNet expects input data to be preprocessed with `preprocess.py`.\n\n```\nusage: preprocess.py [-h] [--data DATA] [--output OUTPUT] [--workers WORKERS]\n                     [--rate RATE] [--stacks_num STACKS_NUM]\n                     [--layers_num LAYERS_NUM] [--target_length TARGET_LENGTH]\n                     [--flush_every FLUSH_EVERY]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --data DATA\n  --output OUTPUT\n  --workers WORKERS\n  --rate RATE\n  --stacks_num STACKS_NUM\n  --layers_num LAYERS_NUM\n  --target_length TARGET_LENGTH\n  --flush_every FLUSH_EVERY\n```\n\nYou specify path to your wav files and it recursively searches the path, subsamples it and split into chunks. Note that you need to specify number of stacks and number of layers per stack in order to calculate receptive field size.\n\nExample of data preprocessing step:\n\n    python preprocess.py --data vctk/wav/p225 --rate 16000 --stacks_num 4 --layers_num 10\n\nIt will generate several files named `vctk_*` (names are hard-coded) that are expected by WaveNet model data loader.\n\n```\n$ python3 train_wavenet.py --help\nusage: train_wavenet.py [-h] [--batchsize BATCHSIZE] [--epoch EPOCH]\n                        [--gpu GPU] [--resume RESUME] [--out OUT]\n                        [--data DATA] [--hidden_dim HIDDEN_DIM]\n                        [--out_hidden_dim OUT_HIDDEN_DIM]\n                        [--stacks_num STACKS_NUM] [--layers_num LAYERS_NUM]\n                        [--learning_rate LEARNING_RATE] [--clip CLIP]\n                        [--weight_decay WEIGHT_DECAY] [--levels LEVELS]\n                        [--stats]\n\nPixelCNN\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --batchsize BATCHSIZE, -b BATCHSIZE\n                        Number of images in each mini-batch\n  --epoch EPOCH, -e EPOCH\n                        Number of sweeps over the dataset to train\n  --gpu GPU, -g GPU     GPU ID (negative value indicates CPU)\n  --resume RESUME, -r RESUME\n                        Resume the training from snapshot\n  --out OUT, -o OUT     Output directory\n  --data DATA, -d DATA  Input data directory\n  --hidden_dim HIDDEN_DIM\n                        Number of hidden dimensions\n  --out_hidden_dim OUT_HIDDEN_DIM\n                        Number of hidden dimensions\n  --stacks_num STACKS_NUM, -s STACKS_NUM\n                        Number of stacks\n  --layers_num LAYERS_NUM, -l LAYERS_NUM\n                        Number of layers per stack\n  --learning_rate LEARNING_RATE\n                        Learning rate\n  --clip CLIP           L2 norm gradient clipping\n  --weight_decay WEIGHT_DECAY\n                        Weight decay rate (L2 regularization)\n  --levels LEVELS       Level number to quantisize values\n  --stats               Collect layerwise statistics\n```\n\nCommand for model training:\n\n    python train_wavenet.py -g0 --out data/ --stacks_num 4 --layers_num 10\n\n```\n$ python3 infer_wavenet.py --help\nusage: infer_wavenet.py [-h] [--gpu GPU] [--model MODEL]\n                        [--hidden_dim HIDDEN_DIM]\n                        [--out_hidden_dim OUT_HIDDEN_DIM]\n                        [--stacks_num STACKS_NUM] [--layers_num LAYERS_NUM]\n                        [--levels LEVELS] [--output OUTPUT] [--label LABEL]\n                        [--count COUNT] [--rate RATE] [--length LENGTH]\n\nPixelCNN\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --gpu GPU, -g GPU     GPU ID (negative value indicates CPU)\n  --model MODEL, -m MODEL\n                        Path to model for generation\n  --hidden_dim HIDDEN_DIM\n                        Number of hidden dimensions\n  --out_hidden_dim OUT_HIDDEN_DIM\n                        Number of hidden dimensions\n  --stacks_num STACKS_NUM, -s STACKS_NUM\n                        Number of stacks\n  --layers_num LAYERS_NUM, -l LAYERS_NUM\n                        Number of layers per stack\n  --levels LEVELS       Level number to quantisize pixel values\n  --output OUTPUT, -o OUTPUT\n                        Output sample directory\n  --label LABEL         Class label to generate\n  --count COUNT, -c COUNT\n                        Number of samples to generate\n  --rate RATE           Samples rate\n  --length LENGTH       Output sample length\n```\n\nAfter model had been trained samples could be generated using:\n\n    python infer_wavenet.py -g0 --stacks_num 4 --layers_num 10 -m data/wavenet_XXXX --output samples/\n\nTo speed up training and generation process one could simplify architecture:\n * Reduce number of stacks (reduces receptive field size)\n * Reduce number of layers per stack (also reduces receptive field size)\n * Reduce sampling rate (i.e. set it to 4000 or 8000)\n * Reduce hidden layers cardinality\n\n## Some results\n\nEither model wasn't trained long enough to produce good-looking-to-human results. However, here are results for simplified settings.\n\n#### PixelCNN 8-way, MNIST\n\n![8way mnist](assets/samples_8way_rgb_mnist.jpg)\n\n#### PixelCNN 2-way, MNIST\n\n![2way mnist](assets/samples_binarized_mnist.jpg)\n\n#### PixelCNN, CIFAR\n\n![CIFAR](assets/samples_cifar_100epoch.jpg)\n\n#### Gated PixelCNN, 4-way, 5 blocks, label `1`\n\n![Label 1](assets/samples_gc_25epoch_4level_5depth.jpg)\n\n#### Gated PixelCNN, 4-way, 5 blocks, label `7`\n\n![Label 7](assets/samples_4way_5blocks.jpg)\n\n#### Gated PixelCNN, 256-way, 8 blocks, label `8`, 100k iterations\n\n![label 8, 100k](assets/mnist_256way_8blocks_100k.jpg)\n\n#### Gated PixelCNN, 256-way, 8 blocks, label `8`, 500k iterations\n\n![label 8, 100k](assets/mnist_256way_8blocks_500k.jpg)\n\n#### WaveNet, overfit on 500Hz tone\n\n[Download](assets/sample_sine500Hz.wav)\n\n#### WaveNet, overfit on VCTK speaker id 225, 4 stacks, 24 hour training\n\n[Download](assets/sample_225.wav)\n\n\n\n# Links\n\n 1. [Website](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)\n 1. [WaveNet][wavenet-paper]\n 1. [PixelRNN](https://arxiv.org/pdf/1601.06759v3.pdf)\n 1. [Conditional PixelCNN][pixelcnn-paper]\n 1. [PixelCNN++ repo](https://github.com/openai/pixel-cnn)\n 1. [PixelCNN++ paper](https://openreview.net/pdf?id=BJrFC6ceg)\n\n# Other implementations\n\n 1. [tensorflow](https://github.com/ibab/tensorflow-wavenet)\n 1. [chainer](https://github.com/monthly-hack/chainer-wavenet)\n 1. [keras #1](https://github.com/usernaamee/keras-wavenet)\n 1. [keras #2](https://github.com/basveeling/wavenet/)\n\n# Other resources\n\n 1. [Fast wavenet](https://github.com/tomlepaine/fast-wavenet)\n\n[pixelcnn-paper]: https://arxiv.org/pdf/1606.05328v2.pdf\n[wavenet-paper]: https://arxiv.org/pdf/1609.03499.pdf\n",
            "readme_url": "https://github.com/rampage644/wavenet",
            "frameworks": []
        }
    ],
    "references": [
        {
            "title": "WaveNet: A Generative Model for Raw Audio",
            "arxiv": "1609.03499",
            "year": 2016,
            "url": "http://arxiv.org/abs/1609.03499v2",
            "abstract": "This paper introduces WaveNet, a deep neural network for generating raw audio\nwaveforms. The model is fully probabilistic and autoregressive, with the\npredictive distribution for each audio sample conditioned on all previous ones;\nnonetheless we show that it can be efficiently trained on data with tens of\nthousands of samples per second of audio. When applied to text-to-speech, it\nyields state-of-the-art performance, with human listeners rating it as\nsignificantly more natural sounding than the best parametric and concatenative\nsystems for both English and Mandarin. A single WaveNet can capture the\ncharacteristics of many different speakers with equal fidelity, and can switch\nbetween them by conditioning on the speaker identity. When trained to model\nmusic, we find that it generates novel and often highly realistic musical\nfragments. We also show that it can be employed as a discriminative model,\nreturning promising results for phoneme recognition.",
            "authors": [
                "Aaron van den Oord",
                "Sander Dieleman",
                "Heiga Zen",
                "Karen Simonyan",
                "Oriol Vinyals",
                "Alex Graves",
                "Nal Kalchbrenner",
                "Andrew Senior",
                "Koray Kavukcuoglu"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "MNIST"
            },
            {
                "name": "CIFAR-10"
            }
        ]
    },
    "domain": {
        "domain_type": "Unknown"
    }
}
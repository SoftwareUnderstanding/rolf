{
    "visibility": {
        "visibility": "public"
    },
    "name": "ObjectLocalizer",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "hershd23",
                "owner_type": "User",
                "name": "ObjectLocalizer",
                "url": "https://github.com/hershd23/ObjectLocalizer",
                "stars": 2,
                "pushed_at": "2019-06-17 16:12:16+00:00",
                "created_at": "2019-03-02 12:14:53+00:00",
                "language": "Jupyter Notebook",
                "description": "An object localizer made for the Flipkart grid ML challenge",
                "frameworks": [
                    "Keras",
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": "173.png",
                "sha": "0d0de3c792f86e861c371c04b2f3af4b72ca165d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hershd23/ObjectLocalizer/blob/master/173.png"
                    }
                },
                "size": 75607
            },
            {
                "type": "code",
                "name": "DatMan.ipynb",
                "sha": "7cb025ad63cd0521f413d58ac79e12d9271df4f1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hershd23/ObjectLocalizer/blob/master/DatMan.ipynb"
                    }
                },
                "size": 9676
            },
            {
                "type": "code",
                "name": "FChal.ipynb",
                "sha": "e17207ee2df5dc7a18e63c259807b9e9bcb6fb88",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hershd23/ObjectLocalizer/blob/master/FChal.ipynb"
                    }
                },
                "size": 64460
            },
            {
                "type": "code",
                "name": "FChal2.ipynb",
                "sha": "819cff1c9dc5c0f80e596a389353d18c64de1a10",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hershd23/ObjectLocalizer/blob/master/FChal2.ipynb"
                    }
                },
                "size": 73904
            },
            {
                "type": "code",
                "name": "TestCreator.ipynb",
                "sha": "1d5005e1e0ff5ad55e54857107ac77d4231c5006",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hershd23/ObjectLocalizer/blob/master/TestCreator.ipynb"
                    }
                },
                "size": 62515
            },
            {
                "type": "code",
                "name": "test5.csv",
                "sha": "f8848cc38f58bef5dc3f5a7a56c04b323cadb56e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hershd23/ObjectLocalizer/blob/master/test5.csv"
                    }
                },
                "size": 1120805
            },
            {
                "type": "code",
                "name": "training.csv",
                "sha": "fd12721b124e4ba90fb4ee65ef09ceceaf99c81f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/hershd23/ObjectLocalizer/blob/master/training.csv"
                    }
                },
                "size": 717902
            }
        ]
    },
    "authors": [
        {
            "name": "Hersh Dhillon",
            "email": "hershdhillon23@gmail.com",
            "github_id": "hershd23"
        }
    ],
    "tags": [],
    "description": "An object localizer made for the Flipkart grid ML challenge",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/hershd23/ObjectLocalizer",
            "stars": 2,
            "issues": true,
            "readme": "# ObjectLocalizer\nAn object localizer made for the Flipkart grid ML challenge. We achieved 86% accuracy(approx), and had a rank of 124 in the contest.\n\n## Getting Started\nThese notbooks were made and imported from Google Colab. The following notebooks would run as it is in colab. To run the same in your own machine, download the datasets into a directory and provide and change the path variable to that directory and you are good to go.\n\n## Dataset\nLink to the Google drive link for the train dataset :- https://drive.google.com/open?id=1NsrEIkevefVZ0hlYfE1Qw6GnPHww5jg7\nLink to the Google drive link for the test dataset :- https://drive.google.com/open?id=1pYBoAE5-35s8So9agyh3qMOGUeR0dINe\n\nUse the image names in the CSV files in the repository to access the images.\n\n## Example\n![alt text](173.png)\n\n## HOW TO RUN\n\nNOTE: If running natively on your machine set the path to the directory where the images are stored.\n\nRun the cells in the DatMan.ipynb file. This file takes 3500 images from the training dataset and stores it as a .np file.\nUse this file in the FChal2.ipynb file, to train the model and save the model.\nUsing this saved model, generate a .csv file using the TestGenerator.ipynb.\n\nIn order to check your predictions on the images itself, run the designated cells in the FChal2.ipynb file.\n\nThe code, in particular was tested in the steps given above. To run a train and test generator based model (would run faster natively in your machines but slower on Google Colab).\n\n## Model\n\nIn the given problem, the Resnet-5 model has been used where the input is an array of 244x244x3 numpy array and we map it to 4 output cells, each denoting the coordinates (x, y, width, height) of the bounding box.\n\n## Reference\nThe model is inspired by:- https://arxiv.org/pdf/1512.03385.pdf\n\n## Author\n\nHersh Dhillon, Harshit Malik, Shreekanth Ajith\n",
            "readme_url": "https://github.com/hershd23/ObjectLocalizer",
            "frameworks": [
                "Keras",
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Deep Residual Learning for Image Recognition",
            "arxiv": "1512.03385",
            "year": 2015,
            "url": "http://arxiv.org/abs/1512.03385v1",
            "abstract": "Deeper neural networks are more difficult to train. We present a residual\nlearning framework to ease the training of networks that are substantially\ndeeper than those used previously. We explicitly reformulate the layers as\nlearning residual functions with reference to the layer inputs, instead of\nlearning unreferenced functions. We provide comprehensive empirical evidence\nshowing that these residual networks are easier to optimize, and can gain\naccuracy from considerably increased depth. On the ImageNet dataset we evaluate\nresidual nets with a depth of up to 152 layers---8x deeper than VGG nets but\nstill having lower complexity. An ensemble of these residual nets achieves\n3.57% error on the ImageNet test set. This result won the 1st place on the\nILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100\nand 1000 layers.\n  The depth of representations is of central importance for many visual\nrecognition tasks. Solely due to our extremely deep representations, we obtain\na 28% relative improvement on the COCO object detection dataset. Deep residual\nnets are foundations of our submissions to ILSVRC & COCO 2015 competitions,\nwhere we also won the 1st places on the tasks of ImageNet detection, ImageNet\nlocalization, COCO detection, and COCO segmentation.",
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999946116540476,
        "task": "Object Detection",
        "task_prob": 0.9692802754762097
    },
    "training": {
        "datasets": [
            {
                "name": "ILSVRC 2015"
            },
            {
                "name": "COCO"
            },
            {
                "name": "ImageNet Detection"
            },
            {
                "name": "CIFAR-10"
            },
            {
                "name": "ImageNet"
            }
        ]
    }
}
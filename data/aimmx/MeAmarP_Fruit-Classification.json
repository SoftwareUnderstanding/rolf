{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Fruit-Classification: Work-In-Progress",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "MeAmarP",
                "owner_type": "User",
                "name": "Fruit-Classification",
                "url": "https://github.com/MeAmarP/Fruit-Classification",
                "stars": 1,
                "pushed_at": "2019-09-20 12:26:19+00:00",
                "created_at": "2019-07-17 14:12:22+00:00",
                "language": "Python",
                "description": "Fruit Classification using TensorFlow-Keras on Fruits 360 dataset",
                "license": "MIT License",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "fddabcbcdb75adb288219b3d2b914d8633ae8163",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/MeAmarP/Fruit-Classification/blob/master/.gitignore"
                    }
                },
                "size": 75
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "c0c40f3048a4c2df0956f047a945677bd9250b90",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/MeAmarP/Fruit-Classification/blob/master/LICENSE"
                    }
                },
                "size": 1068
            },
            {
                "type": "code",
                "name": "results",
                "sha": "ccc794b5d7abe3ce2b2dbc582d234ae9b8725b29",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/MeAmarP/Fruit-Classification/tree/master/results"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "v15_fruit_classify_with_pretrainedmodel.py",
                "sha": "68c00951779eb5460d8140ed147d547c39f51d28",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/MeAmarP/Fruit-Classification/blob/master/v15_fruit_classify_with_pretrainedmodel.py"
                    }
                },
                "size": 5897
            },
            {
                "type": "code",
                "name": "v16_fruit_classify_with_pretrainedmodel.py",
                "sha": "15ad20395a9d0ccd99b62aeb31b7bac0139daf6b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/MeAmarP/Fruit-Classification/blob/master/v16_fruit_classify_with_pretrainedmodel.py"
                    }
                },
                "size": 8970
            },
            {
                "type": "code",
                "name": "v17_fruit_classify_with_pretrainedmodel.py",
                "sha": "8167c6e30d2a578d7d6a7c2856af6bbd64142a1f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/MeAmarP/Fruit-Classification/blob/master/v17_fruit_classify_with_pretrainedmodel.py"
                    }
                },
                "size": 11364
            }
        ]
    },
    "authors": [
        {
            "name": "AMAR POTDAR",
            "github_id": "MeAmarP"
        }
    ],
    "tags": [
        "image-classification",
        "keras-tensorflow",
        "fruit-recognition"
    ],
    "description": "Fruit Classification using TensorFlow-Keras on Fruits 360 dataset",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/MeAmarP/Fruit-Classification",
            "stars": 1,
            "issues": true,
            "readme": "# Fruit-Classification: Work-In-Progress\nFruit Classification/Identififcation using TensorFlow-Keras on Fruits 360 dataset\n\n## Understand Dataset:\n![Understanding Dataset][EDA_Img]\n\n[EDA_Img]: https://github.com/MeAmarP/Fruit-Classification/blob/master/results/EDA_images_v22.png\n\n### Step 1 - EDA:\n\n__Method/Code Snippet:__\n```python\n#get path to root dir\nbase_dir_path = os.getcwd()\n\n#build path to train dir\ntrain_dir_path = os.path.join(base_dir_path,'train')\n\n#build path to test dir\ntest_dir_path = os.path.join(base_dir_path,'test')\n\nreadData(base_dir_path)\n```\n__Console Output:__\n```console\nTotal Number of Classes in train DataSet:  95\nTotal Number of Classes in test DataSet:  95\nTotal Number of train samples:  48905\nTotal Number of test samples: 16421\n```\n__Method/Code Snippet:__\n```python\nunderstandData(base_dir_path,'train')\n```\n__Console Output:__\n```console\nCLASS NAME          NUMBER OF IMAGES\nApple Braeburn      492\nApple Golden 1      492\nApple Golden 2      492\nApple Golden 3      481\nApple Granny Smith  492\n.\n.\n.\n```\n\n## Build Model and Train Dataset:\n\n### Approch:\n+ I used MobileNetV2 architecutre, pre-trained on ImageNet dataset for feature extraction.\n+ Next I use these features and ran through a new classifier, which is trained from scratch.\n+ As stated in my Favourite Book: __Deep Learning with Python__. \nWe took convolutional base(conv_base) of MobileNetV2, ran new data through it and trained a new classifier on top of\nthe output.\n+ So basically, I extended the conv_base by adding Dense layer followed by DropOut layer, and running \nwhole network on input data with data augmentation. \n+ Well!! this is computationally bit expensive, but meh!! I have enough processing power.\n+ Important Thing, I freeze the convolutional base so as to avoid updating their weights.\n\n### Step 2 - Compiling Model:\n__Method/Code Snippet:__\n```python\n#Get list of All classes\nAllClassNames = getAllClassNames(train_dir_path)\nnum_of_classes = len(AllClassNames)\n\n#build dict of clas_id and classname\nDictOfClasses = {i : AllClassNames[i] for i in range(0, len(AllClassNames))}\n\n#Compile classification model\nclassifyModel=compileClassifyModel(num_of_classes)\n```\n__Console Output:__\n```console\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmobilenetv2_1.00_224 (Model) (None, 1280)              2257984   \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 1280)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               655872    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 95)                48735     \n=================================================================\nTotal params: 2,962,591\nTrainable params: 704,607\nNon-trainable params: 2,257,984\n_________________________________________________________________\n```\n\n### Step 3 - Training compiled Model:\n__Method/Code Snippet:__\n```python\n#Start training model on train dataset\ntrainingHistory,trainedModel_filename = trainClassifyModel(classifyModel)\n\n#Plot the training results\nplotTrainResults(trainingHistory)\n```\n### Training Results:\n**Epcohs:20**\n\n![train_valid_acc][plot_acc]\n\n[plot_acc]: https://github.com/MeAmarP/Fruit-Classification/blob/master/results/train_valid_acc_16JUL_20epochs.png\n\n![train_valid_loss][plot_loss]\n\n[plot_loss]: https://github.com/MeAmarP/Fruit-Classification/blob/master/results/train_valid_Loss_16JUL_20epochs.png\n\n\n### Step 4 - Prediction:\n__Method/Code Snippet:__\n```python\n#path to test image\nImagePath = 'test/Banana Red/99_100.jpg'\n\n#path to trained-saved model\npath_trained_model = os.path.abspath(trainedModel_filename)\n\n#load trained model\ntrainedModel = getTrainedModel(path_trained_model)\n\n#perform predictions\nAllProbs = predictFruitClass(ImagePath,trainedModel,DictOfClasses)\n```\n__Console Output:__\n```console\nBanana\n```\n\n## Issues and Challenges:\n+ Need more diverse data for each fruit class.\n+ It is really hard for model to infer the type of fruit, this may be due to closer properties(shape,color etc) of the object.\nI mean, it is easier for model to recognise Banana compared to other fruit class.\n+ For Example, model predicts Grape White as Guava. __Refer Above grid image__. This has been observed with several\nother fruit classes. \n\n### TODO:\n- [ ] Test with more epochs.\n- [ ] Test with ResNet, InveptionV3,Xception models\n- [ ] Add method to print Top-K predicted categories/classes.\n- [ ] Add method to Evaluate prediction accuracy and loss on whole test dataset.\n\n\n## Refrences:\n+ MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\n <https://arxiv.org/abs/1704.04861>\n+ <https://keras.io/applications/#resnet>\n+ Deep Learning with Python, Fran\u00e7ois Chollet.",
            "readme_url": "https://github.com/MeAmarP/Fruit-Classification",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications",
            "arxiv": "1704.04861",
            "year": 2017,
            "url": "http://arxiv.org/abs/1704.04861v1",
            "abstract": "We present a class of efficient models called MobileNets for mobile and\nembedded vision applications. MobileNets are based on a streamlined\narchitecture that uses depth-wise separable convolutions to build light weight\ndeep neural networks. We introduce two simple global hyper-parameters that\nefficiently trade off between latency and accuracy. These hyper-parameters\nallow the model builder to choose the right sized model for their application\nbased on the constraints of the problem. We present extensive experiments on\nresource and accuracy tradeoffs and show strong performance compared to other\npopular models on ImageNet classification. We then demonstrate the\neffectiveness of MobileNets across a wide range of applications and use cases\nincluding object detection, finegrain classification, face attributes and large\nscale geo-localization.",
            "authors": [
                "Andrew G. Howard",
                "Menglong Zhu",
                "Bo Chen",
                "Dmitry Kalenichenko",
                "Weijun Wang",
                "Tobias Weyand",
                "Marco Andreetto",
                "Hartwig Adam"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9956332180400627,
        "task": "Image Classification",
        "task_prob": 0.9684549455642668
    }
}
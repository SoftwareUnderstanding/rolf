{
    "visibility": {
        "visibility": "public"
    },
    "name": "Light UNet for Satellite Image Segmentation",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "YudeWang",
                "owner_type": "User",
                "name": "UNet-Satellite-Image-Segmentation",
                "url": "https://github.com/YudeWang/UNet-Satellite-Image-Segmentation",
                "stars": 107,
                "pushed_at": "2020-07-06 02:46:03+00:00",
                "created_at": "2017-12-15 06:37:13+00:00",
                "language": "Python",
                "description": "A Tensorflow implentation of light UNet framework for remote sensing semantic segmentation task.",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": "dataset.py",
                "sha": "e886473cbff72332f99d26511ffb1544b6ddbea3",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/YudeWang/UNet-Satellite-Image-Segmentation/blob/master/dataset.py"
                    }
                },
                "size": 5781
            },
            {
                "type": "code",
                "name": "factory.py",
                "sha": "66f7ff149788884750c12f06f8716376f01c0699",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/YudeWang/UNet-Satellite-Image-Segmentation/blob/master/factory.py"
                    }
                },
                "size": 6476
            },
            {
                "type": "code",
                "name": "sample_result.png",
                "sha": "4177eb23f236ffd8fe618fe9524ab4545fc79ed4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/YudeWang/UNet-Satellite-Image-Segmentation/blob/master/sample_result.png"
                    }
                },
                "size": 534520
            },
            {
                "type": "code",
                "name": "sample_visible.png",
                "sha": "02c034184259853a35008ce18a7e712d566ff5ef",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/YudeWang/UNet-Satellite-Image-Segmentation/blob/master/sample_visible.png"
                    }
                },
                "size": 10393369
            },
            {
                "type": "code",
                "name": "test.py",
                "sha": "f2187ddd562fa7801696f5d203c4f569e907be2f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/YudeWang/UNet-Satellite-Image-Segmentation/blob/master/test.py"
                    }
                },
                "size": 6692
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "6d41fca7dac3b2ba93cd571c5a867909995bdb5e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/YudeWang/UNet-Satellite-Image-Segmentation/blob/master/train.py"
                    }
                },
                "size": 3491
            },
            {
                "type": "code",
                "name": "utils.py",
                "sha": "2e7f2c315736951ece3a02e30349dddaa4092c89",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/YudeWang/UNet-Satellite-Image-Segmentation/blob/master/utils.py"
                    }
                },
                "size": 3055
            }
        ]
    },
    "authors": [
        {
            "name": "Hibercraft",
            "email": "yude.wang@outlook.com",
            "github_id": "YudeWang"
        }
    ],
    "tags": [],
    "description": "A Tensorflow implentation of light UNet framework for remote sensing semantic segmentation task.",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/YudeWang/UNet-Satellite-Image-Segmentation",
            "stars": 107,
            "issues": true,
            "readme": "# Light UNet for Satellite Image Segmentation\n\nA Tensorflow implentation of light UNet semantic segmentation framework.\n\nThe framework was used in 2017 CCF BDCI remote sensing image semantic segmentation challenge and achieved 0.891 accuracy.\n\n\n\n## Configuration Environment\n\nUbuntu 16.04 + python2.7 + tensorflow1.3 + opencv3.2 + cuda8.0 \n\nThis project implement by gpu version of tensorflow1.3. Therefore a Nvidia GPU is needed.\n\n## Installation\n\n1. Clone the repository\n\n   ```shell\n   git clone https://github.com/YudeWang/UNet-Satellite-Image-Segmentation.git\n   ```\n\n2. Install PyDenseCRF\n\n   You can follow the install instruction of [PyDenseCRF](https://github.com/lucasb-eyer/pydensecrf)\n\n   If you **do not have the permission of sudo**, you can download the source code by:\n\n   ```shell\n   git clone https://github.com/lucasb-eyer/pydensecrf.git\n   ```\n\n   Follow the instruction and install:\n\n   ```shell\n   cd pydensecrf-master\n   python setup.py install\n   ```\n\n3. Download dataset and model\n\n   You can download 2017 CCF BDCI remote sensing challenge dataset and our pre-trained model from [here](https://drive.google.com/file/d/1FMRMe4qSI-JS6AzrO8kASO3BfHOLoUfM/view). Please unzip package in this repository folder and change the ckpt file name to **UNet_ResNet_itr100000.ckpt**(I used to call it FPN, while the structure of network is symmetrical and then rename it).\n\n\n## Network Structure\n\nThis network use Feature Pyramid Network architecture, each up-sampling layer use linear interpolation instead of de-convolution. Convolution structure we use residual-block, which including convolution and down-sampling (convolution with stride=2). A condition random field(CRF) is added at the end of network with size 256\\*256\\*512. The loss function is soft-max cross-entropy.\n\nThe detail of network architecture can be found in factory.py\n\n\n\n## Dataset\n\nThe dataset can be found in [here](https://github.com/linsong8208/Satellite-image-segment/tree/master/BDCI/0_data).\n\nOriginal training data and label is given by png format, each pixel has RGB information. \n\nIn **BDCI-jiage** folder, the labels are plane(1), **road(2), building(3), water(4)**, and the other(0);\n\nIn **BDCI-jiage-Semi** folder, the labels are plane(1), **building(2), water(3), road(4)**, and  the other(0).\n\nTo generate training dataset, we random select 1024\\*1024 patch of original map and scale it into 256\\*256. For data augmentation, four kinds of rotation transformation( 0, 90, 180, 270 degree) and minor transformation are applied. You can use following instruction to generate TFRecord format dataset.\n\n```shell\npython dataset.py\n```\n\n\n\n## Train\n\nYou can run train.py for training, but **please check training parameters at first**. This code can run on single GPU by following instruction:\n\n```shell\npython train.py --gpu=0\n```\n\nTraining result model will be saved in model folder with name UNet\\_ResNet\\_itrxxxxxx.ckpt\n\n\n\n## Test\n\nWe provide pre-trained model **UNet_ResNet_itr100000.ckpt**.\n\nYou can use test.py to generate segmentation result.\n\n```shell\npython test.py --gpu=0\n```\n\nThe test result picture can be found in BDCI2017-jiage-Semi/test/x_result.png\n\n\n\n<div align=\"left\"> \n\n<img src=\"https://github.com/YudeWang/UNet-Satellite-Image-Segmentation/blob/master/sample_visible.png?raw=true\" height=\"40%\" width=\"40%\">    <img src=\"https://github.com/YudeWang/UNet-Satellite-Image-Segmentation/blob/master/sample_result.png?raw=true\" height=\"40%\" width=\"40%\">\n\n</div>\n\n## References\n1. K. He, X. Zhang, S. Ren, and J. Sun, \u201c[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385),\u201d arXiv:1512.03385, 2015.\n2. Tsung-Yi Lin, Piotr Doll\u00e1r, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie,\"[Feature Pyramid Networks for Object Detection](https://arxiv.org/abs/1612.03144),\" arXiv:1612.03144,2016. \n3. Olaf Ronneberger, Philipp Fischer, Thomas Brox, \"[U-Net: Convolutional Networks for Biomedical Image Segmentation.]( https://arxiv.org/abs/1505.04597),\" arXiv:1505.04597.\n",
            "readme_url": "https://github.com/YudeWang/UNet-Satellite-Image-Segmentation",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
            "arxiv": "1505.04597",
            "year": 2015,
            "url": "http://arxiv.org/abs/1505.04597v1",
            "abstract": "There is large consent that successful training of deep networks requires\nmany thousand annotated training samples. In this paper, we present a network\nand training strategy that relies on the strong use of data augmentation to use\nthe available annotated samples more efficiently. The architecture consists of\na contracting path to capture context and a symmetric expanding path that\nenables precise localization. We show that such a network can be trained\nend-to-end from very few images and outperforms the prior best method (a\nsliding-window convolutional network) on the ISBI challenge for segmentation of\nneuronal structures in electron microscopic stacks. Using the same network\ntrained on transmitted light microscopy images (phase contrast and DIC) we won\nthe ISBI cell tracking challenge 2015 in these categories by a large margin.\nMoreover, the network is fast. Segmentation of a 512x512 image takes less than\na second on a recent GPU. The full implementation (based on Caffe) and the\ntrained networks are available at\nhttp://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .",
            "authors": [
                "Olaf Ronneberger",
                "Philipp Fischer",
                "Thomas Brox"
            ]
        },
        {
            "title": "Feature Pyramid Networks for Object Detection",
            "arxiv": "1612.03144",
            "year": 2016,
            "url": "http://arxiv.org/abs/1612.03144v2",
            "abstract": "Feature pyramids are a basic component in recognition systems for detecting\nobjects at different scales. But recent deep learning object detectors have\navoided pyramid representations, in part because they are compute and memory\nintensive. In this paper, we exploit the inherent multi-scale, pyramidal\nhierarchy of deep convolutional networks to construct feature pyramids with\nmarginal extra cost. A top-down architecture with lateral connections is\ndeveloped for building high-level semantic feature maps at all scales. This\narchitecture, called a Feature Pyramid Network (FPN), shows significant\nimprovement as a generic feature extractor in several applications. Using FPN\nin a basic Faster R-CNN system, our method achieves state-of-the-art\nsingle-model results on the COCO detection benchmark without bells and\nwhistles, surpassing all existing single-model entries including those from the\nCOCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU\nand thus is a practical and accurate solution to multi-scale object detection.\nCode will be made publicly available.",
            "authors": [
                "Tsung-Yi Lin",
                "Piotr Doll\u00e1r",
                "Ross Girshick",
                "Kaiming He",
                "Bharath Hariharan",
                "Serge Belongie"
            ]
        },
        {
            "title": "Deep Residual Learning for Image Recognition",
            "arxiv": "1512.03385",
            "year": 2015,
            "url": "http://arxiv.org/abs/1512.03385v1",
            "abstract": "Deeper neural networks are more difficult to train. We present a residual\nlearning framework to ease the training of networks that are substantially\ndeeper than those used previously. We explicitly reformulate the layers as\nlearning residual functions with reference to the layer inputs, instead of\nlearning unreferenced functions. We provide comprehensive empirical evidence\nshowing that these residual networks are easier to optimize, and can gain\naccuracy from considerably increased depth. On the ImageNet dataset we evaluate\nresidual nets with a depth of up to 152 layers---8x deeper than VGG nets but\nstill having lower complexity. An ensemble of these residual nets achieves\n3.57% error on the ImageNet test set. This result won the 1st place on the\nILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100\nand 1000 layers.\n  The depth of representations is of central importance for many visual\nrecognition tasks. Solely due to our extremely deep representations, we obtain\na 28% relative improvement on the COCO object detection dataset. Deep residual\nnets are foundations of our submissions to ILSVRC & COCO 2015 competitions,\nwhere we also won the 1st places on the tasks of ImageNet detection, ImageNet\nlocalization, COCO detection, and COCO segmentation.",
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9975762865934504,
        "task": "Object Detection",
        "task_prob": 0.7408243901272414
    },
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            },
            {
                "name": "ImageNet Detection"
            },
            {
                "name": "COCO"
            },
            {
                "name": "CIFAR-10"
            },
            {
                "name": "ILSVRC 2015"
            }
        ]
    }
}
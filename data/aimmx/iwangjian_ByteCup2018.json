{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "\ufeff# ByteCup2018",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "iwangjian",
                "owner_type": "User",
                "name": "ByteCup2018",
                "url": "https://github.com/iwangjian/ByteCup2018",
                "stars": 76,
                "pushed_at": "2019-01-29 08:33:31+00:00",
                "created_at": "2018-08-30 14:06:27+00:00",
                "language": "Python",
                "description": "Byte Cup 2018 International Machine Learning Contest (3rd prize)",
                "license": "MIT License",
                "frameworks": [
                    "NLTK",
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "3186eca9e1a17037ca2371403be573a923926e8e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/LICENSE"
                    }
                },
                "size": 1070
            },
            {
                "type": "code",
                "name": "commit_data.py",
                "sha": "519e7cc48cab3c9573d007ce00af528a04335789",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/commit_data.py"
                    }
                },
                "size": 1322
            },
            {
                "type": "code",
                "name": "data",
                "sha": "475d019ee4f866636bbdf0069f861f02d8c5e867",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/tree/master/data"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "decode_full_model.py",
                "sha": "fd8064b5d500f7bcd4996a795e543ebd772aa3d7",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/decode_full_model.py"
                    }
                },
                "size": 6911
            },
            {
                "type": "code",
                "name": "decoding.py",
                "sha": "ca024fe2aaa417af99d3c42680cae7daa49127c2",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/decoding.py"
                    }
                },
                "size": 7038
            },
            {
                "type": "code",
                "name": "eval_full_model.py",
                "sha": "8c0b29a97803971b41b218f0eedeff5b1eea439a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/eval_full_model.py"
                    }
                },
                "size": 1608
            },
            {
                "type": "code",
                "name": "evaluate.py",
                "sha": "8d6060d68d977b573dee38aa1446e1b0077cb7fa",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/evaluate.py"
                    }
                },
                "size": 2682
            },
            {
                "type": "code",
                "name": "make_datafiles.py",
                "sha": "6dad6740de8931a131baf9559cf5edfef350c683",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/make_datafiles.py"
                    }
                },
                "size": 10205
            },
            {
                "type": "code",
                "name": "make_eval_references.py",
                "sha": "811e4be6a7dd113013e9c91c83f1f538c11f202a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/make_eval_references.py"
                    }
                },
                "size": 1438
            },
            {
                "type": "code",
                "name": "make_extraction_labels.py",
                "sha": "2be66890ff1da50e5d0888dd9adec9f3061b6ee5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/make_extraction_labels.py"
                    }
                },
                "size": 3269
            },
            {
                "type": "code",
                "name": "metric.py",
                "sha": "4575194c98119af8f2721f589dcfd9de080b6131",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/metric.py"
                    }
                },
                "size": 4013
            },
            {
                "type": "code",
                "name": "model",
                "sha": "5a95cdf1724f433c266831b241b1ad72a7897007",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/tree/master/model"
                    }
                },
                "num_files": 11
            },
            {
                "type": "code",
                "name": "rl_utils.py",
                "sha": "0b424e1c4c035643aad07512c0b913ddcb3d2306",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/rl_utils.py"
                    }
                },
                "size": 6475
            },
            {
                "type": "code",
                "name": "train_abstractor.py",
                "sha": "9d97dae35dd0c2be16bc088900fcdf2abd433a55",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/train_abstractor.py"
                    }
                },
                "size": 8701
            },
            {
                "type": "code",
                "name": "train_extractor.py",
                "sha": "278785af0e1986ce08efefb18ad9bfbf458c2b78",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/train_extractor.py"
                    }
                },
                "size": 9653
            },
            {
                "type": "code",
                "name": "train_full_rl.py",
                "sha": "ee4c0365fe975d6e447592730300efb3e8aa22be",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/train_full_rl.py"
                    }
                },
                "size": 8309
            },
            {
                "type": "code",
                "name": "train_word2vec.py",
                "sha": "9a4f24edf8158943090ae65f6b383b51d6463830",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/train_word2vec.py"
                    }
                },
                "size": 2121
            },
            {
                "type": "code",
                "name": "training.py",
                "sha": "ab4eaceb24790e30b28daaa450f51d73c20eb404",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/training.py"
                    }
                },
                "size": 7411
            },
            {
                "type": "code",
                "name": "utils.py",
                "sha": "f410d33fff35b893060a811870de68ddd248ee6e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/iwangjian/ByteCup2018/blob/master/utils.py"
                    }
                },
                "size": 1480
            }
        ]
    },
    "authors": [
        {
            "name": "Jian Wang",
            "email": "jwanglvy@gmail.com",
            "github_id": "iwangjian"
        },
        {
            "name": "Whoolly",
            "github_id": "Whoolly"
        }
    ],
    "tags": [
        "title-generation",
        "abstractive-summarization"
    ],
    "description": "Byte Cup 2018 International Machine Learning Contest (3rd prize)",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/iwangjian/ByteCup2018",
            "stars": 76,
            "issues": true,
            "readme": "\ufeff# ByteCup2018\n\nThe topic of [Byte Cup 2018 International Machine Learning Contest](https://biendata.com/competition/bytecup2018/) is to  automatically generate titles of given articles. All data for training, validation and testing are from TopBuzz, a Bytedance's product, and other open sources.\n  In this competition, we build a hybrid extractive-abstractive architecture with reinforcement learning (RL) based policy. The model first employs an extractor agent to select salient sentences or highlights, and then employs an abstractive network to rewrite the extracted sentences, using actor-critic policy gradient to learn the sentence saliency with dropout policy to avoid over-fitting.\n\n## Dependencies\n* Python3 (tested on Python 3.6)\n* PyTorch 0.4\n* gensim\n* tensorboardX\n* cytoolz\n* pyrouge\n\n## Quick Start\n* Dataset\n\n    We follow the instructions [here](https://github.com/ChenRocks/cnn-dailymail) for preprocessing the dataset. Meanwhile, we conduct data cleaning by removing duplicates (i.e., both content and title of 2 articles are the same) and cleaning some invalid characters (e.g., URLs, image comments, javascript strings, etc.). After that, all data files ```train```, ```val```, ```test``` and vocabulary file ```vocab_cnt.pkl``` are located in a specified data directory, e.g. ```./bytecup/finished_files/```.\n\n* Pretrain word embeddings\n```\npython3 train_word2vec.py --data=./bytecup/finished_files --path=./bytecup/models/word2vec\n```\n* Make the pseudo-labels\n```\npython3 make_extraction_labels.py --data=./bytecup/finished_files\n```\n* Train abstractor and extractor\n```\npython3 train_abstractor.py --data=./bytecup/finished_files --path=./bytecup/models/abstractor --w2v=./bytecup/models/word2vec/word2vec.300d.332k.bin\npython3 train_extractor.py --data=./bytecup/finished_files --path=./bytecup/models/extractor --w2v=./bytecup/models/word2vec/word2vec.300d.332k.bin\n```\n* Train the RL guided model\n```\npython3 train_full_rl.py --data=./bytecup/finished_files --path=./bytecup/models/save --abs_dir=./bytecup/models/abstractor --ext_dir=./bytecup/models/extractor\n```\n* Decode process\n```\npython3 decode_full_model.py --data=./bytecup/finished_files --path=./bytecup/output --model_dir=./bytecup/models/save --[val/test] \n```\n* Convert decoded results for submission\n```\npython3 commit_data.py --decode_dir=./bytecup/output --result_dir=./bytecup/result\n```\n\n## References\n[1] [\"Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting\"](http://aclweb.org/anthology/P18-1063) (ACL-18)\n\n[2] [\"Global Encoding for Abstractive Summarization\"](http://aclweb.org/anthology/P18-2027) (ACL-18)\n\n[3] [\"Regularizing and Optimizing LSTM Language Models\"](https://arxiv.org/pdf/1708.02182.pdf) (arXiv 2017)\n\n[4] https://github.com/ChenRocks/fast_abs_rl\n",
            "readme_url": "https://github.com/iwangjian/ByteCup2018",
            "frameworks": [
                "NLTK",
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Regularizing and Optimizing LSTM Language Models",
            "arxiv": "1708.02182",
            "year": 2017,
            "url": "http://arxiv.org/abs/1708.02182v1",
            "abstract": "Recurrent neural networks (RNNs), such as long short-term memory networks\n(LSTMs), serve as a fundamental building block for many sequence learning\ntasks, including machine translation, language modeling, and question\nanswering. In this paper, we consider the specific problem of word-level\nlanguage modeling and investigate strategies for regularizing and optimizing\nLSTM-based models. We propose the weight-dropped LSTM which uses DropConnect on\nhidden-to-hidden weights as a form of recurrent regularization. Further, we\nintroduce NT-ASGD, a variant of the averaged stochastic gradient method,\nwherein the averaging trigger is determined using a non-monotonic condition as\nopposed to being tuned by the user. Using these and other regularization\nstrategies, we achieve state-of-the-art word level perplexities on two data\nsets: 57.3 on Penn Treebank and 65.8 on WikiText-2. In exploring the\neffectiveness of a neural cache in conjunction with our proposed model, we\nachieve an even lower state-of-the-art perplexity of 52.8 on Penn Treebank and\n52.0 on WikiText-2.",
            "authors": [
                "Stephen Merity",
                "Nitish Shirish Keskar",
                "Richard Socher"
            ]
        }
    ],
    "domain": {
        "domain_type": "Natural Language Processing",
        "domain_prob": 0.9999938078577093,
        "task": "Language Modelling",
        "task_prob": 0.968430161431932
    },
    "training": {
        "datasets": [
            {
                "name": "Penn Treebank"
            },
            {
                "name": "WikiText-2"
            }
        ]
    }
}
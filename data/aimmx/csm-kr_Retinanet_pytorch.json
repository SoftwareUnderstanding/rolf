{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Retinanet pytorch",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "csm-kr",
                "owner_type": "User",
                "name": "Retinanet_pytorch",
                "url": "https://github.com/csm-kr/Retinanet_pytorch",
                "stars": 4,
                "pushed_at": "2021-09-06 00:20:40+00:00",
                "created_at": "2021-04-12 00:10:43+00:00",
                "language": "Python",
                "license": "MIT License",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "32f50f743265af3aef214973d9b1e0f336fd4d72",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/blob/master/.gitignore"
                    }
                },
                "size": 1795
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "d2abd83c1a8ef88fd1adbf9b590172e636719556",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/blob/master/LICENSE"
                    }
                },
                "size": 1067
            },
            {
                "type": "code",
                "name": "anchor.py",
                "sha": "8235c6ef5fee8e0f5544b10f577595e7fb453d99",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/blob/master/anchor.py"
                    }
                },
                "size": 4202
            },
            {
                "type": "code",
                "name": "coco_test_dev",
                "sha": "a472bd6d73593ef90e1a584a59820ca90c18f8c2",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/tree/master/coco_test_dev"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "coder.py",
                "sha": "faa8f01dbc5f8b885fb306f86610fe53233cba20",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/blob/master/coder.py"
                    }
                },
                "size": 6038
            },
            {
                "type": "code",
                "name": "config.py",
                "sha": "d36321a51a98fd7a4326ec21239b0e0428a382bc",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/blob/master/config.py"
                    }
                },
                "size": 2002
            },
            {
                "type": "code",
                "name": "dataset",
                "sha": "cb1e6bd9d44ab03637a4767c02dd79611be14e16",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/tree/master/dataset"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "demo.py",
                "sha": "b647d24dc3c3c2a803eb4cfd1b5079e43e633c97",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/blob/master/demo.py"
                    }
                },
                "size": 5757
            },
            {
                "type": "code",
                "name": "evaluation",
                "sha": "c15e8a957ba2ad50274e88b4f0d2988e998bb1e9",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/tree/master/evaluation"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "figure",
                "sha": "0b06c3be2f121fd29f26cf94bbaa8a01cb122426",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/tree/master/figure"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "loss.py",
                "sha": "b943a02b4d7399327a89a4cfa1f32316d38d1b13",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/blob/master/loss.py"
                    }
                },
                "size": 3422
            },
            {
                "type": "code",
                "name": "main.py",
                "sha": "a81ebb5179b5c8c46387cd89ef39e92c8b972149",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/blob/master/main.py"
                    }
                },
                "size": 6109
            },
            {
                "type": "code",
                "name": "model.py",
                "sha": "3de64aab449bddf72e653901434c735a1050c248",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/blob/master/model.py"
                    }
                },
                "size": 7347
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "59e43428b5acfd9f3b68f82cdce26199cd33a71b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/blob/master/requirements.txt"
                    }
                },
                "size": 16
            },
            {
                "type": "code",
                "name": "test.py",
                "sha": "d3fad32338f50abbf48d63269f9f09a7c8d1e267",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/blob/master/test.py"
                    }
                },
                "size": 6267
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "1fda8241a4ea193a7cf384d5284b58892cdb2341",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/blob/master/train.py"
                    }
                },
                "size": 3107
            },
            {
                "type": "code",
                "name": "utils.py",
                "sha": "6e231f8476131ddb04947fd70f95596ea2b12b13",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/csm-kr/Retinanet_pytorch/blob/master/utils.py"
                    }
                },
                "size": 8317
            }
        ]
    },
    "authors": [
        {
            "name": "csm-kr",
            "email": "csm8167@naver.com",
            "github_id": "csm-kr"
        }
    ],
    "tags": [
        "object-detection",
        "pytorch",
        "retinanet"
    ],
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/csm-kr/Retinanet_pytorch",
            "stars": 4,
            "issues": true,
            "readme": "# Retinanet pytorch\n\nre-implementation of Retinanet detection : https://arxiv.org/abs/1708.02002\n\n### Setting\n\n- Python 3.7\n- Numpy\n- pytorch >= 1.5.0 \n\n### TODO List\n\n- [x] Dataset\n- [x] Model\n- [x] Loss (Focal loss and smooth l1 loss)\n- [x] Coder\n- [x] Distributed training (distributed data parallel)\n\n### Experiment\n- [x] COCO \n- [ ] VOC \n\nCOCO\n\n- quantitative results\n\n|methods     | Traning Dataset   |    Testing Dataset     | Resolution | AP        |AP50     |AP75    |Time | Fps  |\n|------------|-------------------| ---------------------- | ---------- | --------- |---------|--------| ----| ---- |\n|papers      | COCOtrain2017     |  COCO test-dev         | 600 x 600  |  34.0     |52.5     |36.5    |98   |10.20 |\n|papers      | COCOtrain2017     |  COCOval2017(minival)  | 600 x 600  |  34.3     |53.2     |36.9    |98   |10.20 |\n|ours        | COCOtrain2017     |  COCOval2017(minival)  | 600 x 600  |  31.9     |50.0     |34.0    |67   |14.85 |\n\n<!-- |ours*       | COCOtrain2017     |  COCO test-dev         | 600 x 600  |**34.7**   |**53.6** |**37.3**|67   |14.85 | -->\n<!-- |ours*       | COCOtrain2017     |  COCOval2017(minival)  | 600 x 600  |**34.7**   |**53.5** |**37.1**|67   |14.85 | -->\n\n- qualitative results\n\n![](./figure/qualitative_results/1.JPG)\n![](./figure/qualitative_results/2.JPG)\n![](./figure/qualitative_results/3.JPG)\n![](./figure/qualitative_results/4.JPG)\n\n### scheduler\n\n- we use step LR scheduler scheme.\n\n- whole training epoch is 13 and learning rate decay is at 9, 11\n\n```\npapers trained for 90k iterations with 16 batch.\nwhen it comes to 1 epoch, number of training image(117266) / batch(16) = 7329.125 iterations (7.3k)\nso 90k is about 13 epoch due to 7.3K * 13 = 94.9k \nand at 60k, 80k learning rate is divided by 10 to 1e-3, 1e-4\n\nIn this repo, for convinience of calculation to epochs, \nwhole training epoch 13 (about 94.9k iterations)\nlearning rate decay at after 8 (65k), 11 (87k) epoch each\n\n paper     | this repo  | Learning Rate  \n0k ~ 60K   | 0K ~ 65k   | 1e-2\n60K ~ 80K  | 65k ~ 87k  | 1e-3\n80K ~ 90K  | 87k ~ 95k  | 1e-4\n``` \n\n<!-- - whole training epoch is 60 and learning rate decay is at 30, 45 -->\n\n### training options\n\n- batch : 16\n- scheduler : step LR\n- loss : focal loss and smooth l1 loss\n- dataset : coco\n- epoch : 13\n- gpu : nvidia geforce rtx 3090 * 2EA\n- lr : 1e-2\n\n### training\n\n- dataset\n\n    train : trainval35k == train2017\n\n    test : minval2014 == val2017\n\n- data augmentation\n\n    only use horizontal flipping same as papers.\n\n- trained weight can get at [here](https://livecauac-my.sharepoint.com/:u:/g/personal/csm8167_cau_ac_kr/EUDJTzLdWyxNjoGfYapaGCUBwsrjK6R5yr77Uk4YnHubBw?e=nQRtMH)\n\n\n<!-- 2. this repo uses data augmentation (random crop, expand, flip, photometric distortion, resize) refers to https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py -->\n\n- results\n\n    minival eval\n    \n```\nLoading and preparing results...\nDONE (t=5.93s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=67.32s).\nAccumulating evaluation results...\nDONE (t=13.30s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.500\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.340\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.462\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.285\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.458\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.273\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.564\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.682\n0.3185735964212328\nEval Time : 342.2677\n```\n\n- Distributed Data Parallel for fully using the gpu memory and decreasing training time\n```\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n| 72%   69C    P2   328W / 350W |  14395MiB / 24268MiB |     98%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA GeForce ...  Off  | 00000000:21:00.0 Off |                  N/A |\n| 65%   65C    P2   325W / 350W |  13394MiB / 24268MiB |     99%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n```\n 2800~2900 s/epoch \n \n--------------\n\n```\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n| 70%   69C    P2   298W / 350W |  11154MiB / 24268MiB |     98%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA GeForce ...  Off  | 00000000:21:00.0 Off |                  N/A |\n| 62%   63C    P2   291W / 350W |   8764MiB / 24268MiB |     83%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n```\n 240x s/epoch\ntraining time : 285x s/epoch -> 240x s/epoch (improvement about 15 %)\n\n### Reference\n\nssd tutorial : data augmentation and detection structure\n\nhttps://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection\n\nretina net pytorch\n\nhttps://github.com/NVIDIA/retinanet-examples\n\nhttps://github.com/yhenon/pytorch-retinanet\n\nhttps://github.com/liangheming/retinanetv1\n\n<!-- ### Start Guide --> \n<!--1. --> \n\n",
            "readme_url": "https://github.com/csm-kr/Retinanet_pytorch",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Focal Loss for Dense Object Detection",
            "arxiv": "1708.02002",
            "year": 2017,
            "url": "http://arxiv.org/abs/1708.02002v2",
            "abstract": "The highest accuracy object detectors to date are based on a two-stage\napproach popularized by R-CNN, where a classifier is applied to a sparse set of\ncandidate object locations. In contrast, one-stage detectors that are applied\nover a regular, dense sampling of possible object locations have the potential\nto be faster and simpler, but have trailed the accuracy of two-stage detectors\nthus far. In this paper, we investigate why this is the case. We discover that\nthe extreme foreground-background class imbalance encountered during training\nof dense detectors is the central cause. We propose to address this class\nimbalance by reshaping the standard cross entropy loss such that it\ndown-weights the loss assigned to well-classified examples. Our novel Focal\nLoss focuses training on a sparse set of hard examples and prevents the vast\nnumber of easy negatives from overwhelming the detector during training. To\nevaluate the effectiveness of our loss, we design and train a simple dense\ndetector we call RetinaNet. Our results show that when trained with the focal\nloss, RetinaNet is able to match the speed of previous one-stage detectors\nwhile surpassing the accuracy of all existing state-of-the-art two-stage\ndetectors. Code is at: https://github.com/facebookresearch/Detectron.",
            "authors": [
                "Tsung-Yi Lin",
                "Priya Goyal",
                "Ross Girshick",
                "Kaiming He",
                "Piotr Doll\u00e1r"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "COCO"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9965215810445689,
        "task": "Object Detection",
        "task_prob": 0.9856997688685899
    }
}
{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "srresnet4x",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "itsuki8914",
                "owner_type": "User",
                "name": "srresnet4x",
                "url": "https://github.com/itsuki8914/srresnet4x",
                "stars": 1,
                "pushed_at": "2019-04-13 14:09:24+00:00",
                "created_at": "2019-03-01 07:22:54+00:00",
                "language": "Python",
                "description": "Super resolution with srresnet using TnsorFlow",
                "license": "MIT License",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "894a44cc066a027465cd26d634948d56d13af9af",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/itsuki8914/srresnet4x/blob/master/.gitignore"
                    }
                },
                "size": 1203
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "7a7adb2623460370df662f0da4bcc904ae8f9c9d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/itsuki8914/srresnet4x/blob/master/LICENSE"
                    }
                },
                "size": 1067
            },
            {
                "type": "code",
                "name": "hist.png",
                "sha": "7bc1ddb5e0bc7db4802755e3a511f4cebb95cfda",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/itsuki8914/srresnet4x/blob/master/hist.png"
                    }
                },
                "size": 50303
            },
            {
                "type": "code",
                "name": "model.py",
                "sha": "60133afcc429aec44ca206cb052c60aeae95e73f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/itsuki8914/srresnet4x/blob/master/model.py"
                    }
                },
                "size": 5555
            },
            {
                "type": "code",
                "name": "output",
                "sha": "5a6d475b4f297fa9095c9017530be49b66062600",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/itsuki8914/srresnet4x/tree/master/output"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "pred.py",
                "sha": "a872d583582c1c186c0107593ac6bbe193683c7a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/itsuki8914/srresnet4x/blob/master/pred.py"
                    }
                },
                "size": 3198
            },
            {
                "type": "code",
                "name": "srres.py",
                "sha": "8bc07daa9567ac4c5f1953405cecde9bd5513d11",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/itsuki8914/srresnet4x/blob/master/srres.py"
                    }
                },
                "size": 7588
            },
            {
                "type": "code",
                "name": "test",
                "sha": "7f812878f70357c75ddfa97c12751e36bad29d93",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/itsuki8914/srresnet4x/tree/master/test"
                    }
                },
                "num_files": 2
            }
        ]
    },
    "authors": [
        {
            "name": "itk",
            "github_id": "itsuki8914"
        }
    ],
    "tags": [],
    "description": "Super resolution with srresnet using TnsorFlow",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/itsuki8914/srresnet4x",
            "stars": 1,
            "issues": true,
            "readme": "# srresnet4x\nSuper resolution with srresnet using TensorFlow.\nthe attached model is supesialized in cartoons.\n\nI referrd this paper:https://arxiv.org/abs/1609.04802\n\nThis implementation substitutes subpixel-convolution with deconvolution because building model time is very slow with subpixel-convolution.\n\nthis implementation is not GAN.\n\n## Usage\nput the images in the folder named \"data\". They are used for training. \n       \nput the image in a folder named \"val\". They are used for validation.\n\nwhen you set folders, training runs \"python main.py\". \n\nafter training, test runs \"python pred.py\" It is executed on the images in the folder named \"test\". \n\n\nlike this\n```\nmain.py\npred.py\ndata\n  \u251c 000.png\n  \u251c aaa.png\n  ...\n  \u2514 zzz.png\nval\n  \u251c 111.png\n  \u251c bbb.png\n  ...\n  \u2514 xxx.png\ntest\n  \u251c 222.png\n  \u251c ccc.png\n  ...\n  \u2514 yyy.png\n```\n\n\n## example\nleft:nearest right:output\n\n<img src = 'output/115_val.png' >\n\n\n",
            "readme_url": "https://github.com/itsuki8914/srresnet4x",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network",
            "arxiv": "1609.04802",
            "year": 2016,
            "url": "http://arxiv.org/abs/1609.04802v5",
            "abstract": "Despite the breakthroughs in accuracy and speed of single image\nsuper-resolution using faster and deeper convolutional neural networks, one\ncentral problem remains largely unsolved: how do we recover the finer texture\ndetails when we super-resolve at large upscaling factors? The behavior of\noptimization-based super-resolution methods is principally driven by the choice\nof the objective function. Recent work has largely focused on minimizing the\nmean squared reconstruction error. The resulting estimates have high peak\nsignal-to-noise ratios, but they are often lacking high-frequency details and\nare perceptually unsatisfying in the sense that they fail to match the fidelity\nexpected at the higher resolution. In this paper, we present SRGAN, a\ngenerative adversarial network (GAN) for image super-resolution (SR). To our\nknowledge, it is the first framework capable of inferring photo-realistic\nnatural images for 4x upscaling factors. To achieve this, we propose a\nperceptual loss function which consists of an adversarial loss and a content\nloss. The adversarial loss pushes our solution to the natural image manifold\nusing a discriminator network that is trained to differentiate between the\nsuper-resolved images and original photo-realistic images. In addition, we use\na content loss motivated by perceptual similarity instead of similarity in\npixel space. Our deep residual network is able to recover photo-realistic\ntextures from heavily downsampled images on public benchmarks. An extensive\nmean-opinion-score (MOS) test shows hugely significant gains in perceptual\nquality using SRGAN. The MOS scores obtained with SRGAN are closer to those of\nthe original high-resolution images than to those obtained with any\nstate-of-the-art method.",
            "authors": [
                "Christian Ledig",
                "Lucas Theis",
                "Ferenc Huszar",
                "Jose Caballero",
                "Andrew Cunningham",
                "Alejandro Acosta",
                "Andrew Aitken",
                "Alykhan Tejani",
                "Johannes Totz",
                "Zehan Wang",
                "Wenzhe Shi"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999888297532412,
        "task": "Image Generation",
        "task_prob": 0.8161543901544922
    }
}
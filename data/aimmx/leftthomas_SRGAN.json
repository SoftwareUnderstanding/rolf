{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "SRGAN",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "leftthomas",
                "owner_type": "User",
                "name": "SRGAN",
                "url": "https://github.com/leftthomas/SRGAN",
                "stars": 815,
                "pushed_at": "2021-10-07 15:00:06+00:00",
                "created_at": "2017-11-05 00:40:07+00:00",
                "language": "Python",
                "description": "A PyTorch implementation of SRGAN based on CVPR 2017 paper \"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\"",
                "license": "MIT License",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "1e0290dc8039968c8ffc957e76476888fcd230c4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/blob/master/LICENSE"
                    }
                },
                "size": 1064
            },
            {
                "type": "code",
                "name": "benchmark_results",
                "sha": "d564d0bc3dd917926892c55e3706cc116d5b165e",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/tree/master/benchmark_results"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "data",
                "sha": "d564d0bc3dd917926892c55e3706cc116d5b165e",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/tree/master/data"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "data_utils.py",
                "sha": "ff41d512339808ce9a1ffd2c166667da6371ea3d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/blob/master/data_utils.py"
                    }
                },
                "size": 3689
            },
            {
                "type": "code",
                "name": "epochs",
                "sha": "d564d0bc3dd917926892c55e3706cc116d5b165e",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/tree/master/epochs"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "images",
                "sha": "33816b70cb3ea35b0edd08567625436d094bd314",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/tree/master/images"
                    }
                },
                "num_files": 15
            },
            {
                "type": "code",
                "name": "loss.py",
                "sha": "ab304728bdf544e2723de6c462fde08bcffcaf4c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/blob/master/loss.py"
                    }
                },
                "size": 1778
            },
            {
                "type": "code",
                "name": "model.py",
                "sha": "261f0d059b58abf79a5752ce281fe1062942f9e5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/blob/master/model.py"
                    }
                },
                "size": 3730
            },
            {
                "type": "code",
                "name": "pytorch_ssim",
                "sha": "957277e357db472b649cb580411c9b2c430bc974",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/tree/master/pytorch_ssim"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "statistics",
                "sha": "d564d0bc3dd917926892c55e3706cc116d5b165e",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/tree/master/statistics"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "test_benchmark.py",
                "sha": "0bd9870d7679ba38479831b110d950f0ae16a2c4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/blob/master/test_benchmark.py"
                    }
                },
                "size": 3044
            },
            {
                "type": "code",
                "name": "test_image.py",
                "sha": "ef7df582a7aca87be144b708f6885842391d4f04",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/blob/master/test_image.py"
                    }
                },
                "size": 1431
            },
            {
                "type": "code",
                "name": "test_video.py",
                "sha": "38a3d908ce753b278677c81cda8ac661402dab1c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/blob/master/test_video.py"
                    }
                },
                "size": 4719
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "920ab3d950206f4005bf4fba1622ad5280c2367e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/blob/master/train.py"
                    }
                },
                "size": 7821
            },
            {
                "type": "code",
                "name": "training_results",
                "sha": "d564d0bc3dd917926892c55e3706cc116d5b165e",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/leftthomas/SRGAN/tree/master/training_results"
                    }
                },
                "num_files": 1
            }
        ]
    },
    "authors": [
        {
            "name": "Hao Ren",
            "email": "leftthomas@qq.com",
            "github_id": "leftthomas"
        },
        {
            "name": "Yonghye Kwon",
            "email": "developer.0hye@gmail.com",
            "github_id": "developer0hye"
        },
        {
            "name": "Anant Mittal",
            "email": "ai.with.anant@gmail.com",
            "github_id": "anant15"
        },
        {
            "name": "Jashaswimalya Acharjee",
            "github_id": "jash-maester"
        },
        {
            "name": "Mukul Khanna",
            "email": "mukul18khanna@gmail.com",
            "github_id": "mukulkhanna"
        }
    ],
    "tags": [
        "pytorch",
        "srgan",
        "super-resolution"
    ],
    "description": "A PyTorch implementation of SRGAN based on CVPR 2017 paper \"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\"",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/leftthomas/SRGAN",
            "stars": 815,
            "issues": true,
            "readme": "# SRGAN\nA PyTorch implementation of SRGAN based on CVPR 2017 paper \n[Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network](https://arxiv.org/abs/1609.04802).\n\n## Requirements\n- [Anaconda](https://www.anaconda.com/download/)\n- PyTorch\n```\nconda install pytorch torchvision -c pytorch\n```\n- opencv\n```\nconda install opencv\n```\n\n## Datasets\n\n### Train\u3001Val Dataset\nThe train and val datasets are sampled from [VOC2012](http://cvlab.postech.ac.kr/~mooyeol/pascal_voc_2012/).\nTrain dataset has 16700 images and Val dataset has 425 images.\nDownload the datasets from [here](https://pan.baidu.com/s/1xuFperu2WiYc5-_QXBemlA)(access code:5tzp), and then extract it into `data` directory.\n\n### Test Image Dataset\nThe test image dataset are sampled from \n| **Set 5** |  [Bevilacqua et al. BMVC 2012](http://people.rennes.inria.fr/Aline.Roumy/results/SR_BMVC12.html)\n| **Set 14** |  [Zeyde et al. LNCS 2010](https://sites.google.com/site/romanzeyde/research-interests)\n| **BSD 100** | [Martin et al. ICCV 2001](https://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/)\n| **Sun-Hays 80** | [Sun and Hays ICCP 2012](http://cs.brown.edu/~lbsun/SRproj2012/SR_iccp2012.html)\n| **Urban 100** | [Huang et al. CVPR 2015](https://sites.google.com/site/jbhuang0604/publications/struct_sr).\nDownload the image dataset from [here](https://pan.baidu.com/s/1vGosnyal21wGgVffriL1VQ)(access code:xwhy), and then extract it into `data` directory.\n\n### Test Video Dataset\nThe test video dataset are three trailers. Download the video dataset from \n[here](https://pan.baidu.com/s/1HB1u-2rkMjX7cVtwNtfWjQ)(access code:956d).\n\n## Usage\n\n### Train\n```\npython train.py\n\noptional arguments:\n--crop_size                   training images crop size [default value is 88]\n--upscale_factor              super resolution upscale factor [default value is 4](choices:[2, 4, 8])\n--num_epochs                  train epoch number [default value is 100]\n```\nThe output val super resolution images are on `training_results` directory.\n\n### Test Benchmark Datasets\n```\npython test_benchmark.py\n\noptional arguments:\n--upscale_factor              super resolution upscale factor [default value is 4]\n--model_name                  generator model epoch name [default value is netG_epoch_4_100.pth]\n```\nThe output super resolution images are on `benchmark_results` directory.\n\n### Test Single Image\n```\npython test_image.py\n\noptional arguments:\n--upscale_factor              super resolution upscale factor [default value is 4]\n--test_mode                   using GPU or CPU [default value is 'GPU'](choices:['GPU', 'CPU'])\n--image_name                  test low resolution image name\n--model_name                  generator model epoch name [default value is netG_epoch_4_100.pth]\n```\nThe output super resolution image are on the same directory.\n\n### Test Single Video\n```\npython test_video.py\n\noptional arguments:\n--upscale_factor              super resolution upscale factor [default value is 4]\n--video_name                  test low resolution video name\n--model_name                  generator model epoch name [default value is netG_epoch_4_100.pth]\n```\nThe output super resolution video and compared video are on the same directory.\n\n## Benchmarks\n**Upscale Factor = 2**\n\nEpochs with batch size of 64 takes ~2 minute 30 seconds on a NVIDIA GTX 1080Ti GPU. \n\n> Image Results\n\nThe left is bicubic interpolation image, the middle is high resolution image, and \nthe right is super resolution image(output of the SRGAN).\n\n- BSD100_070(PSNR:32.4517; SSIM:0.9191)\n\n![BSD100_070](images/1.png)\n\n- Set14_005(PSNR:26.9171; SSIM:0.9119)\n\n![Set14_005](images/2.png)\n\n- Set14_013(PSNR:30.8040; SSIM:0.9651)\n\n![Set14_013](images/3.png)\n\n- Urban100_098(PSNR:24.3765; SSIM:0.7855)\n\n![Urban100_098](images/4.png)\n\n> Video Results\n\nThe left is bicubic interpolation video, the right is super resolution video(output of the SRGAN).\n\n[![Watch the video](images/video_SRF_2.png)](https://youtu.be/05vx-vOJOZs)\n\n**Upscale Factor = 4**\n\nEpochs with batch size of 64 takes ~4 minute 30 seconds on a NVIDIA GTX 1080Ti GPU. \n\n> Image Results\n\nThe left is bicubic interpolation image, the middle is high resolution image, and \nthe right is super resolution image(output of the SRGAN).\n\n- BSD100_035(PSNR:32.3980; SSIM:0.8512)\n\n![BSD100_035](images/5.png)\n\n- Set14_011(PSNR:29.5944; SSIM:0.9044)\n\n![Set14_011](images/6.png)\n\n- Set14_014(PSNR:25.1299; SSIM:0.7406)\n\n![Set14_014](images/7.png)\n\n- Urban100_060(PSNR:20.7129; SSIM:0.5263)\n\n![Urban100_060](images/8.png)\n\n> Video Results\n\nThe left is bicubic interpolation video, the right is super resolution video(output of the SRGAN).\n\n[![Watch the video](images/video_SRF_4.png)](https://youtu.be/tNR2eiMeoQs)\n\n**Upscale Factor = 8**\n\nEpochs with batch size of 64 takes ~3 minute 30 seconds on a NVIDIA GTX 1080Ti GPU. \n\n> Image Results\n\nThe left is bicubic interpolation image, the middle is high resolution image, and \nthe right is super resolution image(output of the SRGAN).\n\n- SunHays80_027(PSNR:29.4941; SSIM:0.8082)\n\n![SunHays80_027](images/9.png)\n\n- SunHays80_035(PSNR:32.1546; SSIM:0.8449)\n\n![SunHays80_035](images/10.png)\n\n- SunHays80_043(PSNR:30.9716; SSIM:0.8789)\n\n![SunHays80_043](images/11.png)\n\n- SunHays80_078(PSNR:31.9351; SSIM:0.8381)\n\n![SunHays80_078](images/12.png)\n\n> Video Results\n\nThe left is bicubic interpolation video, the right is super resolution video(output of the SRGAN).\n\n[![Watch the video](images/video_SRF_8.png)](https://youtu.be/EuvXTKCRr8I)\n\nThe complete test results could be downloaded from [here](https://pan.baidu.com/s/1tpi-X6KMrUM15zKTH7f_WQ)(access code:nkh9).\n\n",
            "readme_url": "https://github.com/leftthomas/SRGAN",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network",
            "arxiv": "1609.04802",
            "year": 2016,
            "url": "http://arxiv.org/abs/1609.04802v5",
            "abstract": "Despite the breakthroughs in accuracy and speed of single image\nsuper-resolution using faster and deeper convolutional neural networks, one\ncentral problem remains largely unsolved: how do we recover the finer texture\ndetails when we super-resolve at large upscaling factors? The behavior of\noptimization-based super-resolution methods is principally driven by the choice\nof the objective function. Recent work has largely focused on minimizing the\nmean squared reconstruction error. The resulting estimates have high peak\nsignal-to-noise ratios, but they are often lacking high-frequency details and\nare perceptually unsatisfying in the sense that they fail to match the fidelity\nexpected at the higher resolution. In this paper, we present SRGAN, a\ngenerative adversarial network (GAN) for image super-resolution (SR). To our\nknowledge, it is the first framework capable of inferring photo-realistic\nnatural images for 4x upscaling factors. To achieve this, we propose a\nperceptual loss function which consists of an adversarial loss and a content\nloss. The adversarial loss pushes our solution to the natural image manifold\nusing a discriminator network that is trained to differentiate between the\nsuper-resolved images and original photo-realistic images. In addition, we use\na content loss motivated by perceptual similarity instead of similarity in\npixel space. Our deep residual network is able to recover photo-realistic\ntextures from heavily downsampled images on public benchmarks. An extensive\nmean-opinion-score (MOS) test shows hugely significant gains in perceptual\nquality using SRGAN. The MOS scores obtained with SRGAN are closer to those of\nthe original high-resolution images than to those obtained with any\nstate-of-the-art method.",
            "authors": [
                "Christian Ledig",
                "Lucas Theis",
                "Ferenc Huszar",
                "Jose Caballero",
                "Andrew Cunningham",
                "Alejandro Acosta",
                "Andrew Aitken",
                "Alykhan Tejani",
                "Johannes Totz",
                "Zehan Wang",
                "Wenzhe Shi"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999652743725788,
        "task": "Image Generation",
        "task_prob": 0.8954278009712883
    }
}
{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "Wasserstein GAN with Gradient penalty",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "EmilienDupont",
                "owner_type": "User",
                "name": "wgan-gp",
                "url": "https://github.com/EmilienDupont/wgan-gp",
                "stars": 157,
                "pushed_at": "2020-12-04 18:04:40+00:00",
                "created_at": "2018-01-12 03:07:50+00:00",
                "language": "Python",
                "description": "Pytorch implementation of Wasserstein GANs with Gradient Penalty",
                "license": "MIT License",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "396ea273ff511f6cf2bcb2c83fee8b7bd1e75113",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/EmilienDupont/wgan-gp/blob/master/LICENSE"
                    }
                },
                "size": 1071
            },
            {
                "type": "code",
                "name": "dataloaders.py",
                "sha": "4b1e525698e2745fe11d3d921bb8d93d702682fd",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/EmilienDupont/wgan-gp/blob/master/dataloaders.py"
                    }
                },
                "size": 2282
            },
            {
                "type": "code",
                "name": "gifs",
                "sha": "bc0fb8615cb3b0412f73dea7a9a4cf2b7ba6a0bf",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/EmilienDupont/wgan-gp/tree/master/gifs"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "imgs",
                "sha": "391df21ad1c9fb9b305aa3caa837729b883bd1e1",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/EmilienDupont/wgan-gp/tree/master/imgs"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "main.py",
                "sha": "915d98854d0b5a4bc97670062ee5448bfc4271c8",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/EmilienDupont/wgan-gp/blob/master/main.py"
                    }
                },
                "size": 983
            },
            {
                "type": "code",
                "name": "models.py",
                "sha": "fe7f7e7b26a4bec88ebacfe9602cb0b6a1e2189d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/EmilienDupont/wgan-gp/blob/master/models.py"
                    }
                },
                "size": 2813
            },
            {
                "type": "code",
                "name": "training.py",
                "sha": "810cc05d85511344713f99e6ea25bbce5d7be4ec",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/EmilienDupont/wgan-gp/blob/master/training.py"
                    }
                },
                "size": 6166
            }
        ]
    },
    "authors": [
        {
            "name": "Emilien Dupont",
            "github_id": "EmilienDupont"
        }
    ],
    "tags": [
        "wgan-gp",
        "pytorch",
        "wasserstein-gan",
        "gradient-penalty",
        "gan"
    ],
    "description": "Pytorch implementation of Wasserstein GANs with Gradient Penalty",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/EmilienDupont/wgan-gp",
            "stars": 157,
            "issues": true,
            "readme": "# Wasserstein GAN with Gradient penalty\n\nPytorch implementation of [Improved Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028) by Gulrajani et al.\n\n## Examples\n\n### MNIST\n\nParameters used were `lr=1e-4`, `betas=(.9, .99)`, `dim=16`, `latent_dim=100`. Note that the images were resized from (28, 28) to (32, 32).\n\n#### Training (200 epochs)\n![mnist_gif](https://github.com/EmilienDupont/wgan-gp/raw/master/gifs/mnist_200_epochs.gif)\n\n#### Samples\n![mnist_samples](https://github.com/EmilienDupont/wgan-gp/raw/master/imgs/mnist_samples.png)\n\n\n### Fashion MNIST\n\n#### Training (200 epochs)\n![fashion_mnist_gif](https://github.com/EmilienDupont/wgan-gp/raw/master/gifs/training_200_epochs_fashion_mnist.gif)\n\n#### Samples\n![fashion_mnist_samples](https://github.com/EmilienDupont/wgan-gp/raw/master/imgs/fashion_mnist_samples.png)\n\n### LSUN Bedrooms\n\nGif [work in progress]\n\nSamples [work in progress]\n\n## Usage\n\nSet up a generator and discriminator model\n\n```python\nfrom models import Generator, Discriminator\ngenerator = Generator(img_size=(32, 32, 1), latent_dim=100, dim=16)\ndiscriminator = Discriminator(img_size=(32, 32, 1), dim=16)\n```\n\nThe generator and discriminator are built to automatically scale with image sizes, so you can easily use images from your own dataset.\n\nTrain the generator and discriminator with the WGAN-GP loss\n\n```python\nimport torch\n# Initialize optimizers\nG_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-4, betas=(.9, .99))\nD_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-4, betas=(.9, .99))\n\n# Set up trainer\nfrom training import Trainer\ntrainer = Trainer(generator, discriminator, G_optimizer, D_optimizer,\n                  use_cuda=torch.cuda.is_available())\n\n# Train model for 200 epochs\ntrainer.train(data_loader, epochs=200, save_training_gif=True)\n```\n\nThis will train the models and generate a gif of the training progress.\n\nNote that WGAN-GPs take a *long* time to converge. Even on MNIST it takes about 50 epochs to start seeing decent results. For more information and a full example on MNIST, check out `main.py`.\n\n## Sources and inspiration\n\n* https://github.com/caogang/wgan-gp\n* https://github.com/kuc2477/pytorch-wgan-gp\n",
            "readme_url": "https://github.com/EmilienDupont/wgan-gp",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Improved Training of Wasserstein GANs",
            "arxiv": "1704.00028",
            "year": 2017,
            "url": "http://arxiv.org/abs/1704.00028v3",
            "abstract": "Generative Adversarial Networks (GANs) are powerful generative models, but\nsuffer from training instability. The recently proposed Wasserstein GAN (WGAN)\nmakes progress toward stable training of GANs, but sometimes can still generate\nonly low-quality samples or fail to converge. We find that these problems are\noften due to the use of weight clipping in WGAN to enforce a Lipschitz\nconstraint on the critic, which can lead to undesired behavior. We propose an\nalternative to clipping weights: penalize the norm of gradient of the critic\nwith respect to its input. Our proposed method performs better than standard\nWGAN and enables stable training of a wide variety of GAN architectures with\nalmost no hyperparameter tuning, including 101-layer ResNets and language\nmodels over discrete data. We also achieve high quality generations on CIFAR-10\nand LSUN bedrooms.",
            "authors": [
                "Ishaan Gulrajani",
                "Faruk Ahmed",
                "Martin Arjovsky",
                "Vincent Dumoulin",
                "Aaron Courville"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "MNIST"
            },
            {
                "name": "GPS"
            },
            {
                "name": "CIFAR-10"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999970439084401,
        "task": "Image Generation",
        "task_prob": 0.9818335921806619
    }
}
{
    "visibility": {
        "visibility": "public"
    },
    "name": "Deep-Atrous-CNN-Text-Network: End-to-end word level model for sentiment analysis and other text classifications",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "randomrandom",
                "owner_type": "User",
                "name": "deep-atrous-cnn-sentiment",
                "url": "https://github.com/randomrandom/deep-atrous-cnn-sentiment",
                "stars": 66,
                "pushed_at": "2017-09-27 14:14:36+00:00",
                "created_at": "2017-06-23 11:50:52+00:00",
                "language": "Python",
                "description": "Deep-Atrous-CNN-Text-Network: End-to-end word level model for sentiment analysis and other text classifications",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "b9743104c26e8e11e5e36c1cff4dc4c129c984ab",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/randomrandom/deep-atrous-cnn-sentiment/blob/master/.gitignore"
                    }
                },
                "size": 448
            },
            {
                "type": "code",
                "name": "data",
                "sha": "0ee632a3013add6250729b6bb57b9243bb5aed85",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/randomrandom/deep-atrous-cnn-sentiment/tree/master/data"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "launch_tensorboard.sh",
                "sha": "5416b860294282b6f43b45e5d6461e62b6da40e7",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/randomrandom/deep-atrous-cnn-sentiment/blob/master/launch_tensorboard.sh"
                    }
                },
                "size": 64
            },
            {
                "type": "code",
                "name": "model",
                "sha": "8317f4c1241cc29f86df28f5d54de50ae4d12d6a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/randomrandom/deep-atrous-cnn-sentiment/tree/master/model"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "png",
                "sha": "f7f813fbf67e2565f39509d5abf647e1b71de8c6",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/randomrandom/deep-atrous-cnn-sentiment/tree/master/png"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "preprocess.py",
                "sha": "bbb46ff99039402e006ce4e5f50efaed2ecf4f35",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/randomrandom/deep-atrous-cnn-sentiment/blob/master/preprocess.py"
                    }
                },
                "size": 469
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "203d6ee1390417c68eb3ed71d39387f0dbcc4801",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/randomrandom/deep-atrous-cnn-sentiment/blob/master/requirements.txt"
                    }
                },
                "size": 278
            },
            {
                "type": "code",
                "name": "test.py",
                "sha": "1438b99965a154fcb71c989f7e7bf91210baf130",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/randomrandom/deep-atrous-cnn-sentiment/blob/master/test.py"
                    }
                },
                "size": 1530
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "e5c69a2834e0f532f248c3dc948761c4a5491b53",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/randomrandom/deep-atrous-cnn-sentiment/blob/master/train.py"
                    }
                },
                "size": 2525
            }
        ]
    },
    "authors": [
        {
            "name": "George Stoyanov",
            "github_id": "randomrandom"
        }
    ],
    "tags": [
        "convolutional-neural-networks",
        "movie-reviews",
        "classification",
        "sentiment-analysis",
        "text-classification",
        "deep-learning",
        "deep-neural-networks",
        "bytenet",
        "tensorflow",
        "tensorflow-library",
        "imdb"
    ],
    "description": "Deep-Atrous-CNN-Text-Network: End-to-end word level model for sentiment analysis and other text classifications",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/randomrandom/deep-atrous-cnn-sentiment",
            "stars": 66,
            "issues": true,
            "readme": "# Deep-Atrous-CNN-Text-Network: End-to-end word level model for sentiment analysis and other text classifications\n\nA Deep Atrous CNN architecture suitable for text (sentiment) classification with variable length.\n\nThe architecture substitutes the typical CONV->POOL->CONV->POOL->...->CONV->POOL->SOFTMAX architectures, instead to speed up computations it uses atrous convolutions which are resolution perserving. Another great property of these type of networks is the short travel distance between the first and last words, where the path between them is bounded by C*log(d) steps, where C is a constant and d is the length of the input sequence.\n\nThe architecture is inspired by the [Neural Machine Translation in Linear Time](https://arxiv.org/abs/1610.10099) and [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882).\n\nWhere the Atrous CNN layers are similar to the ones in the bytenet encoder in [Neural Machine Translation in Linear Time](https://arxiv.org/abs/1610.10099) and the max-over-time pooling idea was inspired from the [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882) paper.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/randomrandom/deep-atrous-cnn-sentiment/master/png/architecture.png\" width=\"1024\"/>\n</p>\n\nThe network support embedding initialization with pre-trained GloVe vectors ([GloVe: Gloval Vectors for Word Representations](https://nlp.stanford.edu/pubs/glove.pdf)) which handle even rare words quite well compared to word2vec.\n\nTo speed up training the model pre-processes any input into \"clean\" file, which then utilizes for training. The data is read by line from the \"clean\" files for better memory management. All input data is split into the appropriate buckets and dynamic padding is applied, which provides better accuracy and speed up during training. The input pipeline can read from multiple data sources which makes addition of more data sources easy as long as they are preprocessed in the right format. The model can be trained on multiple GPUs if the hardware provides this capability.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/randomrandom/deep-atrous-cnn-sentiment/master/png/queue_example.gif\" width=\"1024\"/>\n</p>\n\n(Some images are cropped from [WaveNet: A Generative Model for Raw Audio](https://arxiv.org/abs/1609.03499), [Neural Machine Translation in Linear Time](https://arxiv.org/abs/1610.10099) and [Tensorflow's Reading Data Tutorial](https://www.tensorflow.org/programmers_guide/reading_data)) \n\n## Version\n\nCurrent version : __***0.0.0.1***__\n\n## Dependencies ( VERSION MUST BE MATCHED EXACTLY! )\n1. python3.5\n1. arrow==0.10.0\n1. numpy==1.13.0\n1. pandas==0.20.2\n1. protobuf==3.3.0\n1. python-dateutil==2.6.0\n1. pytz==2017.2\n1. six==1.10.0\n1. sugartensor==1.0.0.2\n1. tensorflow==1.2.0\n1. tqdm==4.14.0\n\n## Installation\n1. python3.5 -m pip install -r requirements.txt\n1. install tensorflow or tensorflow-gpu, depending on whether your machine supports GPU configurations\n\n## Dataset & Preprocessing \nCurrently the only supported dataset is the one provided by the [Bag of Words Meets Bags of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial/rules) challenge, instructions how to obtain and preprocess it can be found [here](https://github.com/randomrandom/deep-atrous-cnn-sentiment/tree/master/data/datasets/kaggle_popcorn_challenge)\n\nThe Kaggle dataset contains 25,000 labeled examples of movie reviews. Positive movie reviews are labeled with 1, while negative movie reviews are labeled with 0. The dataset is split into 20,000 training and 5,000 validation examples.\n## Training the network\n\nThe model can be trained across multiple GPUs to speed up the computations. In order to start the training:\n\nExecute\n<pre><code>\npython train.py ( <== Use all available GPUs )\nor\nCUDA_VISIBLE_DEVICES=0,1 python train.py ( <== Use only GPU 0, 1 )\n</code></pre>\n\nCurrently the model achieves up to 97% accuracy on the validation set.\n\n## Monitoring and Debugging the training\nIn order to monitor the training, validation losses and accuracy and other interesting metrics like gradients, activations, distributions, etc. across layers do the following:\n\n\n```\n# when in the project's root directory\nbash launch_tensorboard.sh\n```\n\nthen open your browser [http://localhost:6008/](http://localhost:6008/)\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/randomrandom/deep-atrous-cnn-sentiment/master/png/tensorboard.png\" width=\"1024\"/>\n</p>\n\n(kudos to [sugartensor](https://github.com/buriburisuri/sugartensor) for the great tf wrapper which handles all the monitoring out of the box)\n\n## Testing\nThis version of the model provides interactive testing, in order to start it, execute:\n\n<pre><code>\npython test.py ( <== Use all available GPUs )\nor\nCUDA_VISIBLE_DEVICES=0,1 python test.py ( <== Use only GPU 0, 1 )\n</code></pre>\n\nThe console will ask for input, some sample manual test over examples of the dataset:\n\n```\n>this is an intimate movie of a sincere girl in the real world out of hollywoods cheap fantasy is a very good piece of its class , and ashley judd fills the role impeccably . it may appear slo\nw for thrill seekers though . cool movie for a calm night . br br\n> Sentiment score:  0.538484\n\n>the silent one - panel cartoon henry comes to fleischer studios , billed as the worlds funniest human in this dull little cartoon . betty , long past her prime , thanks to the production code\n , is running a pet shop and leaves henry in charge for far too long - - five minutes . a bore .\n> Sentiment score:  0.0769837\n\n>in her first nonaquatic role , esther williams plays a school teacher whos the victim of sexual assault . she gives a fine performance , proving she could be highly effective out of the swimm\ning pool . as the detective out to solve the case , george nader gives perhaps his finest performance . and he is so handsome it hurts ! john saxon is the student under suspicion , and althoug\nh he gets impressive billing in the credits , its edward andrews as his overly - protective father who is the standout . br br bathed in glorious technicolor , the unguarded moment is irresist\nible hokum and at times compelling drama .\n> Sentiment score:  0.832277\n```\n\n## Future works\n1. Increase the number of supported datasets\n1. Put everything into Docker\n1. Create a REST API for an easy deploy as a service\n\n## My other repositories\n1. [Deep-Atrous-CNN-NER](https://github.com/randomrandom/deep-atrous-ner)\n\n## Citation\n\nIf you find this code useful please cite me in your work:\n\n<pre><code>\nGeorge Stoyanov. Deep-Atrous-CNN-Text-Network. 2017. GitHub repository. https://github.com/randomrandom.\n</code></pre>\n\n## Authors\nGeorge Stoyanov (georgi.val.stoyan0v@gmail.com)\n",
            "readme_url": "https://github.com/randomrandom/deep-atrous-cnn-sentiment",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Convolutional Neural Networks for Sentence Classification",
            "arxiv": "1408.5882",
            "year": 2014,
            "url": "http://arxiv.org/abs/1408.5882v2",
            "abstract": "We report on a series of experiments with convolutional neural networks (CNN)\ntrained on top of pre-trained word vectors for sentence-level classification\ntasks. We show that a simple CNN with little hyperparameter tuning and static\nvectors achieves excellent results on multiple benchmarks. Learning\ntask-specific vectors through fine-tuning offers further gains in performance.\nWe additionally propose a simple modification to the architecture to allow for\nthe use of both task-specific and static vectors. The CNN models discussed\nherein improve upon the state of the art on 4 out of 7 tasks, which include\nsentiment analysis and question classification.",
            "authors": [
                "Yoon Kim"
            ]
        },
        {
            "title": "WaveNet: A Generative Model for Raw Audio",
            "arxiv": "1609.03499",
            "year": 2016,
            "url": "http://arxiv.org/abs/1609.03499v2",
            "abstract": "This paper introduces WaveNet, a deep neural network for generating raw audio\nwaveforms. The model is fully probabilistic and autoregressive, with the\npredictive distribution for each audio sample conditioned on all previous ones;\nnonetheless we show that it can be efficiently trained on data with tens of\nthousands of samples per second of audio. When applied to text-to-speech, it\nyields state-of-the-art performance, with human listeners rating it as\nsignificantly more natural sounding than the best parametric and concatenative\nsystems for both English and Mandarin. A single WaveNet can capture the\ncharacteristics of many different speakers with equal fidelity, and can switch\nbetween them by conditioning on the speaker identity. When trained to model\nmusic, we find that it generates novel and often highly realistic musical\nfragments. We also show that it can be employed as a discriminative model,\nreturning promising results for phoneme recognition.",
            "authors": [
                "Aaron van den Oord",
                "Sander Dieleman",
                "Heiga Zen",
                "Karen Simonyan",
                "Oriol Vinyals",
                "Alex Graves",
                "Nal Kalchbrenner",
                "Andrew Senior",
                "Koray Kavukcuoglu"
            ]
        },
        {
            "title": "Neural Machine Translation in Linear Time",
            "arxiv": "1610.10099",
            "year": 2016,
            "url": "http://arxiv.org/abs/1610.10099v2",
            "abstract": "We present a novel neural network for processing sequences. The ByteNet is a\none-dimensional convolutional neural network that is composed of two parts, one\nto encode the source sequence and the other to decode the target sequence. The\ntwo network parts are connected by stacking the decoder on top of the encoder\nand preserving the temporal resolution of the sequences. To address the\ndiffering lengths of the source and the target, we introduce an efficient\nmechanism by which the decoder is dynamically unfolded over the representation\nof the encoder. The ByteNet uses dilation in the convolutional layers to\nincrease its receptive field. The resulting network has two core properties: it\nruns in time that is linear in the length of the sequences and it sidesteps the\nneed for excessive memorization. The ByteNet decoder attains state-of-the-art\nperformance on character-level language modelling and outperforms the previous\nbest results obtained with recurrent networks. The ByteNet also achieves\nstate-of-the-art performance on character-to-character machine translation on\nthe English-to-German WMT translation task, surpassing comparable neural\ntranslation models that are based on recurrent networks with attentional\npooling and run in quadratic time. We find that the latent alignment structure\ncontained in the representations reflects the expected alignment between the\ntokens.",
            "authors": [
                "Nal Kalchbrenner",
                "Lasse Espeholt",
                "Karen Simonyan",
                "Aaron van den Oord",
                "Alex Graves",
                "Koray Kavukcuoglu"
            ]
        }
    ],
    "domain": {
        "domain_type": "Natural Language Processing",
        "domain_prob": 0.9998595283904691,
        "task": "Machine Translation",
        "task_prob": 0.9248712490804156
    }
}
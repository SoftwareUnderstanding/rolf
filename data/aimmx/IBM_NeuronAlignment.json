{
    "visibility": {
        "visibility": "public",
        "license": "Apache License 2.0"
    },
    "name": "(Optimizing Mode Connectivity via) NeuronAlignment",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "IBM",
                "owner_type": "Organization",
                "name": "NeuronAlignment",
                "url": "https://github.com/IBM/NeuronAlignment",
                "stars": 2,
                "pushed_at": "2020-12-10 01:11:18+00:00",
                "created_at": "2020-09-02 21:15:08+00:00",
                "language": "Python",
                "description": "Codes for the paper \"Optimizing Mode Connectivity via Neuron Alignment\" from NeurIPS 2020.",
                "license": "Apache License 2.0",
                "frameworks": [
                    "TensorFlow",
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "261eeb9e9f8b2b4b0d119366dda99c6fd7d35c64",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/IBM/NeuronAlignment/blob/master/LICENSE"
                    }
                },
                "size": 11357
            },
            {
                "type": "code",
                "name": "__init__.py",
                "sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/IBM/NeuronAlignment/blob/master/__init__.py"
                    }
                },
                "size": 0
            },
            {
                "type": "code",
                "name": "alignment",
                "sha": "27abc1e3e96feb48989fbf11f46da56c41bb8cc9",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/IBM/NeuronAlignment/tree/master/alignment"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "definitions.py",
                "sha": "19f7de05c20dce382e7ec517974eca266f4031e8",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/IBM/NeuronAlignment/blob/master/definitions.py"
                    }
                },
                "size": 130
            },
            {
                "type": "code",
                "name": "evaluation",
                "sha": "58e40007124cc525e4015ad3c8792a344890e55a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/IBM/NeuronAlignment/tree/master/evaluation"
                    }
                },
                "num_files": 4
            },
            {
                "type": "code",
                "name": "images",
                "sha": "d4268bdd8411fec6a16ba18d359357a2b0e01e1b",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/IBM/NeuronAlignment/tree/master/images"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "models",
                "sha": "afcea10ddb0b4843d5597f1b5203575d56c9a65a",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/IBM/NeuronAlignment/tree/master/models"
                    }
                },
                "num_files": 6
            },
            {
                "type": "code",
                "name": "requirements.txt",
                "sha": "a5d597928e8bb0c42f39825c0d227cf4d519b82d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/IBM/NeuronAlignment/blob/master/requirements.txt"
                    }
                },
                "size": 149
            },
            {
                "type": "code",
                "name": "training",
                "sha": "93d435ef595c49022b01556d82316f4b7652d742",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/IBM/NeuronAlignment/tree/master/training"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "utils",
                "sha": "e2120866984fc20e562a91a199fa378e822f5347",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/IBM/NeuronAlignment/tree/master/utils"
                    }
                },
                "num_files": 11
            },
            {
                "type": "code",
                "name": "visualization",
                "sha": "7b9a1eedd1bd40c594f69be2cf8f832457352db3",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/IBM/NeuronAlignment/tree/master/visualization"
                    }
                },
                "num_files": 5
            }
        ]
    },
    "authors": [
        {
            "name": "Joseph Tatro",
            "github_id": "tatron"
        },
        {
            "name": "Steve Martinelli",
            "github_id": "stevemar"
        }
    ],
    "tags": [],
    "description": "Codes for the paper \"Optimizing Mode Connectivity via Neuron Alignment\" from NeurIPS 2020.",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/IBM/NeuronAlignment",
            "stars": 2,
            "issues": true,
            "readme": "# (Optimizing Mode Connectivity via) NeuronAlignment\n\n![Accuracy along Bezier curves trained on CIFAR100.](images/img01.png)\n\nThis repo contains the official code for *Optimizing Mode Connectivity via Neuron Alignment (2020)* by *N.J. Tatro et al.* \nThis code is used \nfor learning a curve on the loss surface between two neural networks that minimizes the average loss along the curve, \nwhere the models are connected up to a permutation of their weights. This includes methods for training networks, \ncomputing the neuron alignment between a network pair, and learning the curve between the networks up to a weight \nsymmetry.\n\n## Abstract\n*The loss landscapes of deep neural networks are not well understood due to their high nonconvexity. Empirically, the \nlocal minima of these loss functions can be connected by a learned curve in model space, along which the loss remains \nnearly constant; a feature known as mode connectivity. Yet, current curve finding algorithms do not consider the \ninfluence of symmetry in the loss surface created by model weight permutations. We propose a more general framework to \ninvestigate the effect of symmetry on landscape connectivity by accounting for the weight permutations of the networks \nbeing connected. To approximate the optimal permutation, we introduce an inexpensive heuristic referred to as neuron \nalignment. Neuron alignment promotes similarity between the distribution of intermediate activations of models along the\ncurve. We provide theoretical analysis establishing the benefit of alignment to mode connectivity based on this simple \nheuristic. We empirically verify that the permutation given by alignment is locally optimal via a proximal alternating \nminimization scheme. Empirically, optimizing the weight permutation is critical for efficiently learning a simple, \nplanar, low-loss curve between networks that successfully generalizes. Our alignment method can significantly alleviate \nthe recently identified robust loss barrier on the path connecting two adversarial robust models and find more robust \nand accurate models on the path.*\n\nIf you find this code helpful in your research, please consider citing our work:\n\n> @article{tatro2020optimizing,\n  title={Optimizing Mode Connectivity via Neuron Alignment},\n  author={Tatro, Norman and Chen, Pin-Yu and Das, Payel and Melnyk, Igor and Sattigeri, Prasanna and Lai, Rongjie},\n  journal={Advances in Neural Information Processing Systems},\n  volume={33},\n  year={2020}\n}\n\n\n## Requirements\n\nTo use this repo, the requirements can be found in *[requirements.txt](requirements.txt)*.\n\n## Workflow\nBelow we describe the basic workflow that is needed to use this code. \n### Training the networks\nFirst, we train a pair of neural networks so that we can explore their connectivity. The following script trains a \nnetwork for the given dataset and architecture. \n```bash\npython training/train_model.py \\\n    --dataset 'CIFAR10' \\\n    --model 'TinyTen' \\\n    --seed 1 \\\n    --batch_size 64 \\\n    --lr 1E-1 \\\n    --wd 5E-4 \\\n    --transform 'TinyTen' \\\n    --epochs 250\npython training/train_model.py \\\n    --dataset 'CIFAR100' \\\n    --model 'TinyTen' \\\n    --seed 1 \\\n    --batch_size 128 \\\n    --lr 1E-1 \\\n    --wd 5E-4 \\\n    --transform 'TinyTen' \\\n    --epochs 250\npython training/train_model.py \\\n    --dataset 'TINY-IMAGENET-200' \\\n    --model 'TinyTen' \\\n    --seed 1 \\\n    --batch_size 128 \\\n    --lr 1E-1 \\\n    --wd 5E-4 \\\n    --transform 'TinyTen' \\\n    --epochs 250\n```\nThe other architectures can be trained with the model arguments `'ResNet32'` and `'GoogLeNet'`. In the case that the \ndataset is Tiny ImageNet and the architecture is GoogLeNet, we set `--transform 'GoogLeNet'`. For the results of the \npaper, we train 6 random seeds for each configuration. \n\nOur code supports the following datasets:\n- [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)\n- [CIFAR100](https://www.cs.toronto.edu/~kriz/cifar.html)\n- [Tiny ImageNet](https://tiny-imagenet.herokuapp.com/)\n\nAdditionally, it supports the following architectures:\n- [TinyTen](https://arxiv.org/abs/1905.00414)\n- [ResNet32](https://arxiv.org/abs/1512.03385)\n- [GoogLeNet](https://github.com/pytorch/vision/blob/master/torchvision/models/googlenet.py)\n\n### Aligning the networks\nNeuron alignment is a technique for finding the correspondence between the activations of different networks. For this \nresults, we determine alignment by maximizing cross-correlation of post-activations. We can exploit this technique to \nalign the weights of two given neural networks of the same architecture. The following code does just that for two \nnetworks of the TinyTen architecture trained on CIFAR100 for 250 epochs with seeds 1 and 2 respectively. \n```bash\npython alignment/align_models.py \\\n    --model 'TinyTen' \\\n    --dataset 'CIFAR100' \\\n    --seed_a 1 \\\n    --seed_b 2 \\\n    --batch_size 512 \\\n    --transform 'TinyTen' \\\n    --epochs 250\n```\nTo align ResNet models, the model argument `'ResNet32` can be used in the above code. For aligning GoogLeNet models, \ncall the following code. \n```bash\npython alignment/align_googlenet.py \\\n    --dataset 'CIFAR100' \\\n    --seed_a 1 \\\n    --seed_b 2 \\\n    --batch_size 512 \\\n    --transform 'TinyTen' \\\n    --epochs 250\n```\nWe emphasize that *align_models* does not return a neural network, as this is very space inefficient for large \narchitectures. Instead, the function saves a numpy array that contains the matching indices for each \nlayer. Here the second network neurons are treated as the source and the first network neurons are treated as the target \nof the matching. \n\n### Training the curve between networks\nThe training of the curve between two networks was largely adapted from \n[dnn-mode-connectivity](https://github.com/timgaripov/dnn-mode-connectivity). The code for training the curve between \nthe same pair of networks is displayed below. Whether the code learns the path between the models before or after \nalignment is determined by whether `-- alignment ''` or `--alignment 'corr'` is passed in the arguments. Here `--seed` \ncontrols the random number generator associated with the actual learning of the curve. \n\nEmpirically, we note that curves\nlearned between different model pairs will be similar if they share the same curve seed. Curves trained between the same\npair of network models with different curve seeds will produce a curve that is different mainly due to symmetry. To \nthis end, tables in the paper are generated from curves trained with different random seeds, while figures are generated\nusing curves trained with the same random seed. \n```bash\npython training/train_curve.py \\\n    --model 'TinyTen' \\\n    --dataset 'CIFAR100' \\\n    --epochs_model 250 \\\n    --seed_a 1 \\\n    --seed_b 2 \\\n    --seed 1 \\\n    --batch_size 128 \\\n    --lr 1E-1 \\\n    --wd 5E-4 \\\n    --alignment 'corr' \\\n    --val_freq 10 \\\n    --lr_drop 20 \\\n    --epochs 250\n```\nIt is important to note that the current version of the code is tailored to learning quadratic Bezier curves between two\ngiven models. As it stands *train_curve.py* saves out the turning point of the learned quadratic Bezier curve. More \ncomplex curves of course would require more parameters to be saved. This should be an easy fix. However, \n*visualization/viz_curve_on_plane.py* and similar methods depend on the learned curve being planar. \n\n#### Using Proximal Alternating Minimization (PAM) to train the curve\n\nThe previous code assumes a correspondence between the network weights based on neuron alignment. We can also attempt to \nlearn the optimal correspondence. We attempt this using proximal alternating minimization. Here we iteratively optimize \nfor the permutation matrices for the second network weights and for the curve parameters. In the example below, we \nperform 1 iteration of PAM (enough for convergence) where the permutation matrices are trained for 20 epochs followed by \nthe training of the curve parameters for 250 epochs for each iteration of PAM. \n```bash\npython training/train_curve_pam.py \\\n    --model 'TinyTen' \\\n    --dataset 'CIFAR100' \\\n    --epochs_model 250 \\\n    --seed_a 1 \\\n    --seed_b 2 \\\n    --seed 1 \\\n    --batch_size 128 \\\n    --lr 1E-1 \\\n    --wd 5E-4 \\\n    --alignment '' \\\n    --val_freq 10 \\\n    --outer_iters 1 \\\n    --inner_iters_perm 20 \\\n    --inner_iters_phi 250\n```\n\n### Evaluating the curve\n\nThe following script evaluates the curve learned from running the training curve script. \n```bash\npython evaluation/eval_curve.py \\\n    --dataset 'CIFAR100' \\\n    --model 'TinyTen' \\\n    --epochs_model 250 \\\n    --epochs_curve 250 \\\n    --alignment 'corr' \\\n    --seed_a 1 \\\n    --seed_b 2 \\\n    --batch_size 512 \\\n    --epochs 250\n```\n\n### Robust Adversarial Models and Curves\n\nThis package also contains code for training the aforementioned models and curves such that they are robust to \nadversarial attacks. Currently, only Projected Gradient Descent (PGD) attacks are supported. The workflow is similar for \nstandard models and curves. To train robust versions, use the following functions instead:\n- *[training/train_model_adversarial.py](training/train_model_adversarial.py)* \n- *[training/train_curve_adversarial.py](training/train_curve_adversarial.py)* \n- *[evaluation/eval_adversarial_curve.py](evaluation/eval_adversarial_curve.py)*\n\nThe most notable change is the use of the transform `--transform 'Adversarial'`. For the configuration of Tiny ImageNet\nand GoogLeNet, this flag is `--transform 'Adversarial_GoogLeNet'`. \n\n### Additional Functionality\n\nThe scripts listed above are the most important to the workflow of our paper. For brevity, we briefly describe other \nrelevant scripts in this repo. \n- *[alignment/align_along_curve.py](alignment/align_along_curve.py)* Separately aligns the midpoint of a given curve \nbetween two models to each endpoint.\n\nThe directory, [visualization](visualization), contains the scripts used to generate all figures in the paper.  \n\nThe table below summarizes the main result of the paper. \n\n| **Model**                 | **Acc\\. Along the Curve**         |                               |   |                               |                               |   |                               |                               |\n|-----------------------|-------------------------------|-------------------------------|---|-------------------------------|-------------------------------|---|-------------------------------|-------------------------------|\n|                       | CIFAR10                       |                               |   | CIFAR100                      |                               |   | Tiny ImageNet                 |                               |\n|                       | Avg\\.                         | Min\\.                         |   | Avg\\.                         | Min\\.                         |   | Avg\\.                         | Min\\.                         |\n| **TinyTen** \\(0\\.09M\\)    | 89\\.0 +/- 0\\.1             |                               |   | 58\\.1 +/- 0\\.5             |                               |   | 34\\.2 +/- 0\\.2             |                               |\n| Unaligned             | 87\\.4 +/- 0\\.1             | 82\\.8 +/- 0\\.5             |   | 56\\.0 +/- 0\\.2             | 53\\.2 +/- 1\\.1             |   | 32\\.5 +/- 0\\.1             | 30\\.0 +/- 0\\.3             |\n| PAM Unaligned         | 87\\.6 +/- 0\\.1             | 84\\.0 +/- 0\\.3             |   | 57\\.3 +/- 0\\.2             | 55\\.9 +/- 0\\.9             |   | 33\\.6 +/- 0\\.1             | 32\\.5 +/- 0\\.1             |\n| PAM Aligned           | 88\\.4 +/- 0\\.1             | 87\\.6 +/- 0\\.2           |   | **58\\.8 +/- 0\\.1** | **57\\.7 +/- 0\\.3** |   | 34\\.2 +/- 0\\.1             | 33\\.4 +/- 0\\.2             |\n| Aligned               | **88\\.5 +/- 0\\.1** | **87\\.8 +/- 0\\.1** |   | 58\\.7 +/- 0\\.2             | **57\\.7 +/- 0\\.4** |   | **34\\.4 +/- 0\\.1** | **33\\.7 +/- 0\\.1** |\n| **ResNet32** \\(0\\.47M\\)   | 92\\.9 +/- 0\\.1             |                               |   | 67\\.1 +/- 0\\.5             |                               |   | 50\\.2 +/- 0\\.0             |                               |\n| Unaligned             | 92\\.2 +/- 0\\.1             | 89\\.1 +/- 0\\.2             |   | 66\\.5 +/- 0\\.2             | 64\\.7 +/- 0\\.4             |   | 48\\.2 +/- 0\\.1             | 45\\.2 +/- 0\\.1             |\n| PAM Unaligned         | 92\\.4 +/- 0\\.1             | 89\\.9 +/- 0\\.2             |   | 67\\.0 +/- 0\\.1             | 66\\.1 +/- 0\\.1             |   | 48\\.5 +/- 0\\.1             | 46\\.6 +/- 0\\.1             |\n| PAM Aligned           | **92\\.7 +/- 0\\.0** | 92\\.1 +/- 0\\.1             |   | 67\\.6 +/- 0\\.4             | **66\\.8 +/- 0\\.1** |   | 49\\.2 +/- 0\\.4             | 47\\.9 +/- 0\\.6             |\n| Aligned               | **92\\.7 +/- 0\\.1** | **92\\.2 +/- 0\\.0** |   | **67\\.7 +/- 0\\.1** | 66\\.6 +/- 0\\.1             |   | **49\\.5 +/- 0\\.3** | **48\\.8 +/- 0\\.4** |\n| **GoogLeNet** \\(10\\.24M\\) | 93\\.4 +/- 0\\.0             |                               |   | 73\\.2 +/- 0\\.4             |                               |   | 51\\.6 +/- 0\\.2             |                               |\n| Unaligned             | 93\\.3 +/- 0\\.0             | 92\\.1 +/- 0\\.1             |   | 73\\.1 +/- 0\\.4             | 69\\.8 +/- 0\\.3             |   | 51\\.9 +/- 0\\.1             | 48\\.7 +/- 0\\.4             |\n| Aligned               | **93\\.4 +/- 0\\.0** | **93\\.1 +/- 0\\.0** |   | **73\\.4 +/- 0\\.3** | **72\\.9 +/- 0\\.3** |   | **52\\.4 +/- 0\\.2** | **51\\.4 +/- 0\\.3** |\n",
            "readme_url": "https://github.com/IBM/NeuronAlignment",
            "frameworks": [
                "TensorFlow",
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Deep Residual Learning for Image Recognition",
            "arxiv": "1512.03385",
            "year": 2015,
            "url": "http://arxiv.org/abs/1512.03385v1",
            "abstract": "Deeper neural networks are more difficult to train. We present a residual\nlearning framework to ease the training of networks that are substantially\ndeeper than those used previously. We explicitly reformulate the layers as\nlearning residual functions with reference to the layer inputs, instead of\nlearning unreferenced functions. We provide comprehensive empirical evidence\nshowing that these residual networks are easier to optimize, and can gain\naccuracy from considerably increased depth. On the ImageNet dataset we evaluate\nresidual nets with a depth of up to 152 layers---8x deeper than VGG nets but\nstill having lower complexity. An ensemble of these residual nets achieves\n3.57% error on the ImageNet test set. This result won the 1st place on the\nILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100\nand 1000 layers.\n  The depth of representations is of central importance for many visual\nrecognition tasks. Solely due to our extremely deep representations, we obtain\na 28% relative improvement on the COCO object detection dataset. Deep residual\nnets are foundations of our submissions to ILSVRC & COCO 2015 competitions,\nwhere we also won the 1st places on the tasks of ImageNet detection, ImageNet\nlocalization, COCO detection, and COCO segmentation.",
            "authors": [
                "Kaiming He",
                "Xiangyu Zhang",
                "Shaoqing Ren",
                "Jian Sun"
            ]
        },
        {
            "title": "Similarity of Neural Network Representations Revisited",
            "arxiv": "1905.00414",
            "year": 2019,
            "url": "http://arxiv.org/abs/1905.00414v4",
            "abstract": "Recent work has sought to understand the behavior of neural networks by\ncomparing representations between layers and between different trained models.\nWe examine methods for comparing neural network representations based on\ncanonical correlation analysis (CCA). We show that CCA belongs to a family of\nstatistics for measuring multivariate similarity, but that neither CCA nor any\nother statistic that is invariant to invertible linear transformation can\nmeasure meaningful similarities between representations of higher dimension\nthan the number of data points. We introduce a similarity index that measures\nthe relationship between representational similarity matrices and does not\nsuffer from this limitation. This similarity index is equivalent to centered\nkernel alignment (CKA) and is also closely connected to CCA. Unlike CCA, CKA\ncan reliably identify correspondences between representations in networks\ntrained from different initializations.",
            "authors": [
                "Simon Kornblith",
                "Mohammad Norouzi",
                "Honglak Lee",
                "Geoffrey Hinton"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            },
            {
                "name": "ImageNet Detection"
            },
            {
                "name": "ILSVRC 2015"
            },
            {
                "name": "CIFAR-10"
            },
            {
                "name": "COCO"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9994397427634572,
        "task": "Image Classification",
        "task_prob": 0.9476170186043307
    }
}
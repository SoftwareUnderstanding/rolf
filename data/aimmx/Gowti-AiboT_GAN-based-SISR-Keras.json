{
    "visibility": {
        "visibility": "public"
    },
    "name": "GAN-based-SISR---Keras",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "Gowti-AiboT",
                "owner_type": "User",
                "name": "GAN-based-SISR-Keras",
                "url": "https://github.com/Gowti-AiboT/GAN-based-SISR-Keras",
                "stars": 1,
                "pushed_at": "2019-10-09 17:44:12+00:00",
                "created_at": "2019-10-09 05:02:20+00:00",
                "language": "Python",
                "description": "GAN based Single Image Super Resolution Implementation in Keras with Tensorflow backend",
                "frameworks": [
                    "Keras",
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": "3000epochs.png",
                "sha": "73bd9c8e5f1466dde54da1f33b6fc834f06257d6",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/blob/master/3000epochs.png"
                    }
                },
                "size": 104121
            },
            {
                "type": "code",
                "name": "900epochs.png",
                "sha": "cdcf1691291131865f4faf6fba3acfa84784fe88",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/blob/master/900epochs.png"
                    }
                },
                "size": 125886
            },
            {
                "type": "code",
                "name": "Architecture_Images",
                "sha": "61da4fb4b0b455770bd5e230ed15f3639d83be9f",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/tree/master/Architecture_Images"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "Network.py",
                "sha": "9346bd1702a1b0b7a94154003f71af09e1ad0034",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/blob/master/Network.py"
                    }
                },
                "size": 4306
            },
            {
                "type": "code",
                "name": "Utils.py",
                "sha": "ef5cc176916c99e43afc200815bc8cc90390f837",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/blob/master/Utils.py"
                    }
                },
                "size": 7887
            },
            {
                "type": "code",
                "name": "Utils_model.py",
                "sha": "7caa0a4a3da461b1a032f966fc8354392fca7251",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/blob/master/Utils_model.py"
                    }
                },
                "size": 853
            },
            {
                "type": "code",
                "name": "pre_trained_model",
                "sha": "70592002d12c7dbdef1e8219a955e8e2a4d2fd01",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/tree/master/pre_trained_model"
                    }
                },
                "num_files": 1
            },
            {
                "type": "code",
                "name": "table.png",
                "sha": "272d80c1845b0dbe2ede50c016ab03f4b2abd573",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/blob/master/table.png"
                    }
                },
                "size": 9053
            },
            {
                "type": "code",
                "name": "test.py",
                "sha": "46d7928d9612eb886190d7868d3ef4c777c48ab0",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/blob/master/test.py"
                    }
                },
                "size": 2637
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "a9af4ebd98ddbaa9a2398454d015c4f8d32dcd9a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/blob/master/train.py"
                    }
                },
                "size": 5729
            },
            {
                "type": "code",
                "name": "weights",
                "sha": "c9ebdc6e06ac8bed92d06f8b38631dfcf9be579c",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/tree/master/weights"
                    }
                },
                "num_files": 3
            }
        ]
    },
    "authors": [
        {
            "name": "Gowtham Ganesan",
            "github_id": "Gowti-AiboT"
        }
    ],
    "tags": [],
    "description": "GAN based Single Image Super Resolution Implementation in Keras with Tensorflow backend",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/Gowti-AiboT/GAN-based-SISR-Keras",
            "stars": 1,
            "issues": true,
            "readme": "# GAN-based-SISR---Keras\n\n**Target:**\n\nGenerate the Photorealistic high resolution images(image size -196x196) from a single low resolution image (implemented image size-49x49).\n\n**For detailed Information on concepts:**\n\nhttps://drive.google.com/file/d/1w_C4LDSzgiqpDMArdcvPZtYz3gDNFGE_/view?usp=sharing\n\n\n**GAN based SISR Architecture:**\n![Image of Architecture](https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/blob/master/Architecture_Images/architecture.jpg)\n\n**Generator and Discriminator Network:**\n![Image of Network](https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/blob/master/Architecture_Images/network.jpg)\n\n**Attachment Structure**\n\n1.Network.py : Contains Generator and Discriminator Network\n\n2.Utils.py   : Contains utilities to process images\n\n3.Utils_model.py : Contains optimizer and content loss code\n\n4.train.py   : Used for training the model\n\n5.test.py    : To test the model\n\n\n**Working Enivornment**\n\n1.Training dataset \u2013 COCO2019\n\n2.Test dataset \u2013 Set5\n\n3.Training size \u2013 800 images\n\n4.Scale \u2013 4x\n\n5.LR Image size \u2013 49 * 49 , HR Image size  - 196*196\n\n6.Batch size \u2013 16\n\n7.GPU used \u2013 Nvidia Tesla K80(colab Allocation)\n\n8.Platform Used : Google colab , Spyder (Local Machine-Laptop)\n\n9.Tools Used : Keras ,Backend \u2013 Tensorflow , numpy,PIL ,os, argparse , skimage\n\n10.Time Taken \u2013 3 hours /100 epochs.\n\n**Output:**\n\nImage Result format - (LR , SR , HR)\n\n**900epochs**\n\nTest results are not satisfactory when trained for 900 epochs and batch size-16\n![Image of 900epochs](https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/blob/master/900epochs.png)\n\n**3000epochs**\n\nTest results are satisfactory when trained for 3000 epochs and batch size-64\n![Image of 3000epochs](https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/blob/master/3000epochs.png)\n\n**Evaluation_table**\n\n![Image of table](https://github.com/Gowti-AiboT/GAN-based-SISR-Keras/blob/master/table.png)\n\n**Paper Reference**\n\nhttps://arxiv.org/abs/1609.04802\n\n**Reference:**\n\n1.\thttps://medium.com/@birla.deepak26/single-image-super-resolution-using-gans-keras-aca310f33112\n2.\thttps://github.com/deepak112/Keras-SRGAN\n3.\thttps://github.com/leftthomas/SRGAN\n4.\thttps://www.slideshare.net/reachquadri/what-is-spatial-resolution\n5.\thttps://medium.com/@jonathan_hui/gan-whats-generative-adversarial-networks-and-its-application-f39ed278ef09\n6.\thttps://www.cambridgeincolour.com/tutorials/image-interpolation.htm\n7.\thttps://medium.com/beyondminds/an-introduction-to-super-resolution-using-deep-learning-f60aff9a499d\n8.\thttps://arxiv.org/abs/1609.04802\n9.\thttp://www.ee.iisc.ac.in/people/faculty/soma.biswas/AIP_pdf/SBiswas_ImageSuperresolution_2016.pdf \n10.\thttps://download.atlantis-press.com/article/4822.pdf\n11.\thttp://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/AV1011/Super_Resolution_CVonline.pdf\n12.\thttp://people.csail.mit.edu/billf/publications/Example-Based_Super_Resolution.pdf\n13.\thttps://www.researchgate.net/publication/260737170_Performance_evaluation_of_image_quality_metrics_with_respect_to_their_use_for_super-resolution_enhancement\n14.\thttps://arxiv.org/abs/1501.00092\n15.\thttps://slideplayer.com/slide/4838896/\n16.\thttps://arxiv.org/pdf/1502.03167.pdf\n17.\thttps://arxiv.org/abs/1809.00219\n18.\thttps://ieeexplore.ieee.org/document/8517442\n\n\n\n\n\n\n\n\n\n",
            "readme_url": "https://github.com/Gowti-AiboT/GAN-based-SISR-Keras",
            "frameworks": [
                "Keras",
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks",
            "arxiv": "1809.00219",
            "year": 2018,
            "url": "http://arxiv.org/abs/1809.00219v2",
            "abstract": "The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work\nthat is capable of generating realistic textures during single image\nsuper-resolution. However, the hallucinated details are often accompanied with\nunpleasant artifacts. To further enhance the visual quality, we thoroughly\nstudy three key components of SRGAN - network architecture, adversarial loss\nand perceptual loss, and improve each of them to derive an Enhanced SRGAN\n(ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block\n(RRDB) without batch normalization as the basic network building unit.\nMoreover, we borrow the idea from relativistic GAN to let the discriminator\npredict relative realness instead of the absolute value. Finally, we improve\nthe perceptual loss by using the features before activation, which could\nprovide stronger supervision for brightness consistency and texture recovery.\nBenefiting from these improvements, the proposed ESRGAN achieves consistently\nbetter visual quality with more realistic and natural textures than SRGAN and\nwon the first place in the PIRM2018-SR Challenge. The code is available at\nhttps://github.com/xinntao/ESRGAN .",
            "authors": [
                "Xintao Wang",
                "Ke Yu",
                "Shixiang Wu",
                "Jinjin Gu",
                "Yihao Liu",
                "Chao Dong",
                "Chen Change Loy",
                "Yu Qiao",
                "Xiaoou Tang"
            ]
        },
        {
            "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
            "arxiv": "1502.03167",
            "year": 2015,
            "url": "http://arxiv.org/abs/1502.03167v3",
            "abstract": "Training Deep Neural Networks is complicated by the fact that the\ndistribution of each layer's inputs changes during training, as the parameters\nof the previous layers change. This slows down the training by requiring lower\nlearning rates and careful parameter initialization, and makes it notoriously\nhard to train models with saturating nonlinearities. We refer to this\nphenomenon as internal covariate shift, and address the problem by normalizing\nlayer inputs. Our method draws its strength from making normalization a part of\nthe model architecture and performing the normalization for each training\nmini-batch. Batch Normalization allows us to use much higher learning rates and\nbe less careful about initialization. It also acts as a regularizer, in some\ncases eliminating the need for Dropout. Applied to a state-of-the-art image\nclassification model, Batch Normalization achieves the same accuracy with 14\ntimes fewer training steps, and beats the original model by a significant\nmargin. Using an ensemble of batch-normalized networks, we improve upon the\nbest published result on ImageNet classification: reaching 4.9% top-5\nvalidation error (and 4.8% test error), exceeding the accuracy of human raters.",
            "authors": [
                "Sergey Ioffe",
                "Christian Szegedy"
            ]
        },
        {
            "title": "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network",
            "arxiv": "1609.04802",
            "year": 2016,
            "url": "http://arxiv.org/abs/1609.04802v5",
            "abstract": "Despite the breakthroughs in accuracy and speed of single image\nsuper-resolution using faster and deeper convolutional neural networks, one\ncentral problem remains largely unsolved: how do we recover the finer texture\ndetails when we super-resolve at large upscaling factors? The behavior of\noptimization-based super-resolution methods is principally driven by the choice\nof the objective function. Recent work has largely focused on minimizing the\nmean squared reconstruction error. The resulting estimates have high peak\nsignal-to-noise ratios, but they are often lacking high-frequency details and\nare perceptually unsatisfying in the sense that they fail to match the fidelity\nexpected at the higher resolution. In this paper, we present SRGAN, a\ngenerative adversarial network (GAN) for image super-resolution (SR). To our\nknowledge, it is the first framework capable of inferring photo-realistic\nnatural images for 4x upscaling factors. To achieve this, we propose a\nperceptual loss function which consists of an adversarial loss and a content\nloss. The adversarial loss pushes our solution to the natural image manifold\nusing a discriminator network that is trained to differentiate between the\nsuper-resolved images and original photo-realistic images. In addition, we use\na content loss motivated by perceptual similarity instead of similarity in\npixel space. Our deep residual network is able to recover photo-realistic\ntextures from heavily downsampled images on public benchmarks. An extensive\nmean-opinion-score (MOS) test shows hugely significant gains in perceptual\nquality using SRGAN. The MOS scores obtained with SRGAN are closer to those of\nthe original high-resolution images than to those obtained with any\nstate-of-the-art method.",
            "authors": [
                "Christian Ledig",
                "Lucas Theis",
                "Ferenc Huszar",
                "Jose Caballero",
                "Andrew Cunningham",
                "Alejandro Acosta",
                "Andrew Aitken",
                "Alykhan Tejani",
                "Johannes Totz",
                "Zehan Wang",
                "Wenzhe Shi"
            ]
        },
        {
            "title": "Image Super-Resolution Using Deep Convolutional Networks",
            "arxiv": "1501.00092",
            "year": 2014,
            "url": "http://arxiv.org/abs/1501.00092v3",
            "abstract": "We propose a deep learning method for single image super-resolution (SR). Our\nmethod directly learns an end-to-end mapping between the low/high-resolution\nimages. The mapping is represented as a deep convolutional neural network (CNN)\nthat takes the low-resolution image as the input and outputs the\nhigh-resolution one. We further show that traditional sparse-coding-based SR\nmethods can also be viewed as a deep convolutional network. But unlike\ntraditional methods that handle each component separately, our method jointly\noptimizes all layers. Our deep CNN has a lightweight structure, yet\ndemonstrates state-of-the-art restoration quality, and achieves fast speed for\npractical on-line usage. We explore different network structures and parameter\nsettings to achieve trade-offs between performance and speed. Moreover, we\nextend our network to cope with three color channels simultaneously, and show\nbetter overall reconstruction quality.",
            "authors": [
                "Chao Dong",
                "Chen Change Loy",
                "Kaiming He",
                "Xiaoou Tang"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999996104965424,
        "task": "Image Generation",
        "task_prob": 0.9262475207835649
    },
    "training": {
        "datasets": [
            {
                "name": "ImageNet"
            }
        ]
    }
}
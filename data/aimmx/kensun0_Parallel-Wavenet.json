{
    "visibility": {
        "visibility": "public"
    },
    "name": "Parallel-Wavenet",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "kensun0",
                "owner_type": "User",
                "name": "Parallel-Wavenet",
                "url": "https://github.com/kensun0/Parallel-Wavenet",
                "stars": 52,
                "pushed_at": "2018-08-24 03:52:01+00:00",
                "created_at": "2018-01-29 09:36:35+00:00",
                "language": "Python",
                "description": "It is a Tutorial, not a complete implement",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": "h512_bo16.py",
                "sha": "5b4c4c0961f09206a21433332fe81724dc38a9a4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kensun0/Parallel-Wavenet/blob/master/h512_bo16.py"
                    }
                },
                "size": 19046
            },
            {
                "type": "code",
                "name": "loss.py",
                "sha": "03857842e7aebc101c71f5cc846d89ba278723d9",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kensun0/Parallel-Wavenet/blob/master/loss.py"
                    }
                },
                "size": 7014
            },
            {
                "type": "code",
                "name": "masked.py",
                "sha": "6f2034cabc3cd3efdd468865dd6581fcc1755727",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/kensun0/Parallel-Wavenet/blob/master/masked.py"
                    }
                },
                "size": 2939
            }
        ]
    },
    "authors": [
        {
            "name": "kensun0",
            "github_id": "kensun0"
        }
    ],
    "tags": [
        "tensorflow"
    ],
    "description": "It is a Tutorial, not a complete implement",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/kensun0/Parallel-Wavenet",
            "stars": 52,
            "issues": true,
            "readme": "# Parallel-Wavenet\n\nParallel wavenet has been implemented, partial codes will be placed here soon.\n\n# Citings\n\nCiting 1: Parallel WaveNet: Fast High-Fidelity Speech Synthesis\n\nCiting 2: WAVENET: A GENERATIVE MODEL FOR RAW AUDIO\n\nCiting 3: Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders\n\nCiting 4: TACOTRON: TOWARDS END-TO-END SPEECH SYNTHESIS \n\nCiting 5: PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications\n\nCiting 6: https://github.com/tensorflow/magenta/tree/master/magenta/models/nsynth\n\nCiting 7: https://github.com/keras-team/keras/blob/master/keras/backend/tensorflow_backend.py#L3254\n\nCiting 8: https://github.com/openai/pixel-cnn\n\nCiting 9: https://github.com/keithito/tacotron\n\n# Notes\n\nYou should read citing6's codes first, then you can implement the original wavenet.\n\nWe use mel-scale spectrogram transforming from real wav as local conditions for convenience. You can train a tacotron model to get predicted mel-scale spectrogram.\n\nA good teacher network is VERY VERY VERY important for training the student network.\n\n# Teacher training Step\n\n1. Replace casual conv1d in citing6(masked.py) with Keras's implement. Refer to citing7.\n\n2. Implement a datafeeder to provide mel and wav. Refer to citing9's datafeeder.py.\n\n3. Using discretized mixture of logistics distribution instead of 256-way categorical distribution. Refer ro citing8's nn.py.\n\n4. Modify citing6's h512_bo16.py to build original wavenet with local condition.\n\n5. Training with Adam.\n\n# Student training Step\n\n1. Modify Teacher's datafeeder to provider white noises Z. One mixture logistic, np.random.logistic(size=wav.shape)\n\n2. Modify teacher's h512_bo16.py to build parallel wavenet.\n\n3. Add power loss, cross entropy loss and etc...\n\n4. Restore teacher weights, and then train student.\n\n\n# Pseudo-code of original wavenet\n  \n  Data:\n  \n        encoding: mel-scale spectrogram  \n  \n        x: real wav\n        \n        \u03b8e: encoding's parameters\n        \n        \u03b8t: teacher's parameters\n        \n  Result:\n        \n        mu_t: teacher's output\n        \n        scale_t: teacher's output\n  \n  Procedure:\n        \n        for x,encoding in X,ENCODING\uff1a\n  \t\t\t  \n            new_x = shiftright(x)\n  \t\t\t\t\n            new_enc = F(encoding,\u03b8e)\n  \t\t\t\t\n            for i in layers-1:\n  \t\t\t\t\t\n                new_x_i = H_i(new_x_i,\u03b8t_i)\n  \t\t\t\t\t\n                new_x_i += new_enc\n  \t\t\t\t\n            mu_t, scale_t = H_i(new_x_i,\u03b8t_i)   #last layer\n  \t\t\t\t\n            predict_x = logistic(mu_t,scale_t)  #citing8\n  \t\t\t\t\n            loss = cross_entropy(predict_x,x)   #citing8\n        \n  \n  \n        \n# Pseudo-code of parallel wavenet\n  \n  Data: \n        \n        encoding: mel-scale spectrogram \n        \n        z: white noise, z~logistic distribution L\uff080,1\uff09, one mixture \n        \n        x: real wav\n        \n        \u03b8e: encoding's parameters\n        \n        \u03b8t: teacher's parameters\n        \n        \u03b8s: student's parameters\n        \n        mu_t: teacher's output\n        \n        scale_t: teacher's output\n  \n  Result: \n        \n        mu_tot: student's output\n        \n        scale_tot: student's output\n  \n  Procedure:\n  \n        for x,z,encoding in X,Z,ENCODING:\n    \n            new_enc = F(encoding,\u03b8e)\n\t\t\t\t\n\t\t### student ###\n\t\t\t\t\n\t\tmu_tot=0\n\t\t\t\t\n\t\tscale_tot=1\n\t\t\n\t\tfor f in flow:\t\t\t\t\t\n\t\t    new_z = shiftright(z)  \n\t\t    for i in layers-1:\n\t\t\t\n\t\t\t    new_z_i = H_i(new_z_i,\u03b8s_i)\n  \t\t\t\t\t\t\t\n  \t\t\t    new_z_i += new_enc\n  \t\t\t\t\t\n  \t\t    mu_s_f, scale_s_f = H_i(new_z_i,\u03b8s_i)\t\t#last layer\n\t\t\t\t\t\t\n\t\t    mu_tot = mu_s_f + mu_tot*scale_s_f\n\t\t\t\t\t\t\n\t\t    scale_tot = scale_tot*scale_s_f\n\t\t\t\n\t\t    z = z*scale_s_f + mu_s_f \n\t\t\t\t\n\t\tsample_x = logistic(mu_tot,scale_tot)\n\t\t\t\t\n\t\tPower_loss = (|stft(z)|-|stft(x)|)**2\n\t\t\t\t\n\t\tH(Ps)_loss = log(scale_tot) + 2\n\t\t\t\t\n\t\t### teacher ###\n\t\t\t\t\n\t\tnew_z = shiftright(z)\n  \t\t\t\n  \t\tfor i in layers-1:\n  \t\t\t\n \t\t    new_z_i = H_i(new_z_i,\u03b8t_i)\n  \t\t\t\t\t\n  \t\t    new_z_i += new_enc\n  \t\t\t\n  \t\tmu_t, scale_t = H_i(new_z_i,\u03b8t_i)  #last layer\n  \t\t\t\n  \t\tpredict_x = logistic(mu_t,scale_t) \n  \t\t\t\n  \t\tH(Ps,Pt)_loss = cross_entropy(predict_x,sample_x)\t \n  \t\t\t\n  \t\tloss = H(Ps,Pt) - H(Ps) + Power_loss\n\n",
            "readme_url": "https://github.com/kensun0/Parallel-Wavenet",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "domain": {
        "domain_type": "Speech",
        "domain_prob": 0.9659110071419942
    }
}
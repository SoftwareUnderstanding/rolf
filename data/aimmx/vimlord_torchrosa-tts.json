{
    "visibility": {
        "visibility": "public"
    },
    "name": "TorchRosa TTS",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "vimlord",
                "owner_type": "User",
                "name": "torchrosa-tts",
                "url": "https://github.com/vimlord/torchrosa-tts",
                "stars": 0,
                "pushed_at": "2020-06-03 05:06:02+00:00",
                "created_at": "2020-06-03 05:04:41+00:00",
                "language": "Python",
                "description": "A text-to-speech program using VAE on Mel spectrograms of phonemes.",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "a0e1ce10c07c0251afab156b26c37ed6e613401d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/vimlord/torchrosa-tts/blob/master/.gitignore"
                    }
                },
                "size": 41
            },
            {
                "type": "code",
                "name": "generate.py",
                "sha": "15c9a7a2e465550836d92ef0f22251873d6a5aeb",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/vimlord/torchrosa-tts/blob/master/generate.py"
                    }
                },
                "size": 796
            },
            {
                "type": "code",
                "name": "generate_spectrograms.py",
                "sha": "e77f1845af23762919a584690906516781b7a73f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/vimlord/torchrosa-tts/blob/master/generate_spectrograms.py"
                    }
                },
                "size": 2937
            },
            {
                "type": "code",
                "name": "mdoel.py",
                "sha": "71d2df912db76996d9e987cd9fa0c9f86e9a576f",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/vimlord/torchrosa-tts/blob/master/mdoel.py"
                    }
                },
                "size": 3468
            },
            {
                "type": "code",
                "name": "model.pt",
                "sha": "8d5a93b0ad9d038dcb7d81b031b4f2faa6cd6658",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/vimlord/torchrosa-tts/blob/master/model.pt"
                    }
                },
                "size": 215256
            },
            {
                "type": "code",
                "name": "phoneme_handler.py",
                "sha": "4d7a10dda8b64fc6cb226fbd85e5c97522c76f54",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/vimlord/torchrosa-tts/blob/master/phoneme_handler.py"
                    }
                },
                "size": 4033
            },
            {
                "type": "code",
                "name": "phoneme_samples.csv",
                "sha": "7cadbd9e59b75022c3bc673e5edec77b42c90a4c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/vimlord/torchrosa-tts/blob/master/phoneme_samples.csv"
                    }
                },
                "size": 1348
            },
            {
                "type": "code",
                "name": "samples",
                "sha": "556912f8829c6caced20e364e3d60a42371d2e18",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/vimlord/torchrosa-tts/tree/master/samples"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "train.py",
                "sha": "b21e62be8da7f8f6d48594a9b802d56958d633c3",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/vimlord/torchrosa-tts/blob/master/train.py"
                    }
                },
                "size": 369
            },
            {
                "type": "code",
                "name": "util",
                "sha": "37246ec995a0070d0c33326283feb19d44a1a8c1",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/vimlord/torchrosa-tts/tree/master/util"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "vae",
                "sha": "dfeaacd92c3e69612188b6103f0532aabb308a76",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/vimlord/torchrosa-tts/tree/master/vae"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "word_list.txt",
                "sha": "285b26b7ed9b79bf7145a837ddc372d123ee4315",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/vimlord/torchrosa-tts/blob/master/word_list.txt"
                    }
                },
                "size": 268
            }
        ]
    },
    "authors": [
        {
            "name": "Christopher Hittner",
            "github_id": "vimlord"
        }
    ],
    "tags": [
        "tts",
        "librosa",
        "vae",
        "pytorch",
        "mel-spectrogram"
    ],
    "description": "A text-to-speech program using VAE on Mel spectrograms of phonemes.",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/vimlord/torchrosa-tts",
            "stars": 0,
            "issues": true,
            "readme": "\n# TorchRosa TTS\n\n## What is this?\n\nThis project contains files I put together to try out creating a text-to-speech\nsystem from scratch. The system uses a PyTorch model to learn a VAE that is\nused to learn an embedding that plugs into the decoder. The result is something\nthat vaguely resembles my voice if it was sent through a blender.\n\n## Installation\n\nI will try to get around to writing a requirements.txt, but I will summarize the\nrequirements as best as possible. For this project, I installed:\n\n```\npython3\npytorch\nlibrosa\npyaudio\ng2p_en\nscipy\nnumpy\n```\n\n## Usage\n\nI will provide the PyTorch model I generated for my own voice for free. To use\nthis model, the interface is provided through generate.py. I designed it so\nadditional models could be setup for the class if desired. The simplest way to\nuse it is to run\n\n```\npython3 generate.py --text \"Hello world\"\n```\n\nThat's it! It should cobble together a speech sample in `output.wav`\n\n### What if I want to use my own voice?\n\nSo this is the fun part. So in order to do this, you will need to record\nyourself speaking the majority of the phonemes. Some of the phonemes were\nfiltered out because they didn't provide continuous sounds, and are replaced\nby ones that do provide continuous sounds that are placed in sequence.\nThese can be seen in `util/preprocess.py`. For a full list of phonemes, run\n\n```\npython phoneme_handler.py list-phonemes\n```\n\nWhen I recorded my voice, I practiced making the phoneme sounds. To actually\nrecord, I provide a convenient utility for this.\n\n```\npython phoneme_handler.py record-phoneme AA\n```\n\nThis will record the phoneme AA. When you run it, it will prompt you to press\nenter when you are ready. I recommend beginning to make the phoneme sound\nimmediately after the button press, and continuing until the program terminates\nfor best results. I do not recommend this if you have pre-existing health\nissues that impact your breathing or lung capacity. It is possible to reduce\nthe recording length in the program, as there is a constant where I se the\nutterance length to five seconds.\n\nIf you have issues with missing directories, creating them should resolve most\nissues.\n\nOnce the phonemes are recorded, you need to generate the spectrograms. This is\ndone by running ```python generate_spectrograms.py```. This will create Mel\nspectrograms of each audio file recorded and save them as numpy files within\nthe package.\n\nFinally, you need to train the model. Running `python train.py` will train the\nVAE model by default. If you wish to do hyperparameter tuning, you can edit\n`vae/hyperparameters.py`. Note that I was lazy with my train-test split setup,\nso there will be contamination. But I found that the hyperparameters there\nworked okay for my files.\n\nOnce `train.py` has been run, it will save `model.pt` in your directory. If\nthis file already exists, it will be overwritten. Once it exists, you can\nuse the model.\n\n### What if I want to add my own words?\n\nI have already provided words that cover all of the phonemes. However, it may\nbe useful to provide your own to help you figure out the pronounciations.\nTo do this, edit the word list, and then run\n\n```\npython generate-metadata.py\n```\n\nThis will generate the CSV file in the current directory.\n\n## Future Ideas\n\nIn the future, I might want to mess with using GAN to improve the results.\nI have a couple of ideas here:\n\n- Improving the quality of the phoneme sound bites by training a discriminator to learn realness of phoneme sounds\n- Learning a model that converts the generated spectrogram to a more realistic sounding audio\n\nI do also wonder if there is a way to speed up the WAV generation process, as\nit is quite slow on a laptop. One investigation that could be done would be to\nsee if FFT can be used to generate better results.\n\n## References\n\nVAE: https://arxiv.org/abs/1312.6114\n\nInspiration for Mel spectrogram use: https://ai.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html\n\n",
            "readme_url": "https://github.com/vimlord/torchrosa-tts",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Auto-Encoding Variational Bayes",
            "arxiv": "1312.6114",
            "year": 2013,
            "url": "http://arxiv.org/abs/1312.6114v10",
            "abstract": "How can we perform efficient inference and learning in directed probabilistic\nmodels, in the presence of continuous latent variables with intractable\nposterior distributions, and large datasets? We introduce a stochastic\nvariational inference and learning algorithm that scales to large datasets and,\nunder some mild differentiability conditions, even works in the intractable\ncase. Our contributions is two-fold. First, we show that a reparameterization\nof the variational lower bound yields a lower bound estimator that can be\nstraightforwardly optimized using standard stochastic gradient methods. Second,\nwe show that for i.i.d. datasets with continuous latent variables per\ndatapoint, posterior inference can be made especially efficient by fitting an\napproximate inference model (also called a recognition model) to the\nintractable posterior using the proposed lower bound estimator. Theoretical\nadvantages are reflected in experimental results.",
            "authors": [
                "Diederik P Kingma",
                "Max Welling"
            ]
        }
    ],
    "domain": {
        "domain_type": "Unknown"
    }
}
{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "page_type:",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "RajdeepBiswas",
                "owner_type": "User",
                "name": "Manufacturing-Quality-Inspection",
                "url": "https://github.com/RajdeepBiswas/Manufacturing-Quality-Inspection",
                "stars": 2,
                "pushed_at": "2021-09-12 15:02:35+00:00",
                "created_at": "2021-09-09 15:09:26+00:00",
                "language": "Jupyter Notebook",
                "description": "I have built the computer vision models in 3 different ways addressing different personas, because not all companies will have a resolute data science team.",
                "license": "MIT License",
                "frameworks": [
                    "scikit-learn",
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "f804e6c9618748a9120d194d6ede8b453c0b5e22",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/RajdeepBiswas/Manufacturing-Quality-Inspection/blob/main/LICENSE"
                    }
                },
                "size": 1071
            },
            {
                "type": "code",
                "name": "data",
                "sha": "e495dee28c4ef8b72ed11427f7ece602d93d87f1",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/RajdeepBiswas/Manufacturing-Quality-Inspection/tree/main/data"
                    }
                },
                "num_files": 2
            },
            {
                "type": "code",
                "name": "images",
                "sha": "e2ffac4cc1de841e0036d4cf41e4677db22b8b3c",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/RajdeepBiswas/Manufacturing-Quality-Inspection/tree/main/images"
                    }
                },
                "num_files": 3
            },
            {
                "type": "code",
                "name": "notebook",
                "sha": "87940bf44a20de2d6ebc8ebbeee8136e3ac4e202",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/RajdeepBiswas/Manufacturing-Quality-Inspection/tree/main/notebook"
                    }
                },
                "num_files": 4
            }
        ]
    },
    "authors": [
        {
            "name": "Rajdeep Biswas",
            "email": "clickrajdeep@gmail.com",
            "github_id": "RajdeepBiswas"
        }
    ],
    "tags": [],
    "description": "I have built the computer vision models in 3 different ways addressing different personas, because not all companies will have a resolute data science team.",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/RajdeepBiswas/Manufacturing-Quality-Inspection",
            "stars": 2,
            "issues": true,
            "readme": "---\npage_type: \n- Complete Solution\nlanguages:\n- Python | REST\nproducts:\n- Azure Machine Learning | Computer Vision | Custom Vision | Keras Tensdorflow | AML Designer\ndescription: \n-  Computer vision models in 3 different ways addressing different personas.\nurlFragment: \"https://github.com/RajdeepBiswas/Manufacturing-Quality-Inspection\"\n---\n\n# Manufacturing-Quality-Inspection\n![Title_Pic](images/Title_Pic.jpg)\n\n## EXECUTIVE SUMMARY\nManufacturing is becoming automated on a broad scale. The technology enables manufacturers to affordably boost their throughput, improve quality and become nimbler as they respond to customer demands. Automation is a revolution in manufacturing quality control. It allows the companies to set certain bars or criteria for the products being manufactured. Then it also aids in real-time tracking of the manufacturing process through machine vision cameras and/or recordings.  \nThe core deliverable for this project is building deep learning image classification models which can automate the process of inspection for casting defects. I have produced a rest endpoint which can accept a cast image and subsequently run a tuned model to classify if the cast is acceptable or not.  \n\nAs part of this project, I have built the computer vision models in 3 different ways addressing different personas, because not all companies will have a resolute data science team.  \n1.\tUsing Keras Tensorflow model (convolution2d) what a trained team of data scientists would do.\n2.\tUsing Azure Machine Learning Designer (designer) which enables AI engineers and Data scientists use a drag and drop prebuilt model DenseNet (densenet). \n3.\tUsing Azure custom vision (custom-vision) which democratizes the process of building the computer vision model with little to no training.\n\n## Contents\n| File/folder       | Description                                |\n|-------------------|--------------------------------------------|\n| `notebook`        | Python Notebooks.                          |\n| `data`            | images for  casting manufacturing product.                        |\n| `images`          | Sample images used for documentation.      |\n| `.gitignore`      | Define what to ignore at commit time.      |\n| `CHANGELOG.md`    | List of changes to the sample.             |\n| `CONTRIBUTING.md` | Guidelines for contributing to the sample. |\n| `README.md`       | This README file.                          |\n| `LICENSE`         | The license for the sample.                |\n\n## GUIDING PRINCIPLES\nThe work that will be subsequently done as part of this paper will have at the very least embody the following principles (ai/responsible-ai, n.d.):  \n\u2022\tFair - AI must maximize efficiencies without destroying dignity and guard against bias.  \n\u2022\tAccountable - AI must have algorithmic accountability.  \n\u2022\tTransparent - AI systems must be transparent and understandable.  \n\u2022\tEthical - AI must assist humanity and be designed for intelligent privacy.  \n\n## DATA SOURCES\nFor this project, the data is sourced from Kaggle. The dataset is a collection of images for  casting manufacturing product. More specifically all photos are top view of submersible pump impeller.  \nThe dataset contains total 7348 image data. These all are the size of (300*300) pixels grey-scaled images. In all images, augmentation already applied. There are also images of size of 512x512 grayscale. This data set is without Augmentation. This contains 519 okfront and 781 deffront impeller images.  \nThe data is already labelled and split. Both train and test folder contain deffront and okfront subfolders.  \ntrain:- deffront have 3758 and okfront have 2875 images.  \ntest:- deffront have:- deffront have 453 and ok_front have 262 images.  \n\n## ARCHITECTURE\nGiven below is the architecture that this solution is using. \n![Casting_Arch](images/Casting_Arch.jpg)\n\n\n**Synopsis:** Raw data in jpeg format will be ingested into Azure Data Lake store. The raw folder in azure data lake store will be mounted as a dataset in Azure Machine Learning Services. Further featurization and model building is done in Azure Machine Learning Platform using Python code + Azure Machine Learning APIs. After the best model is selected, it is registered in Azure Container Registry and finally hosted in Azure Kubernetes Services for scoring new images.\n\n## ACKNOWLEDGEMENTS\n* I am grateful to Ravirajsinh Dabhi for compiling the data. https://www.kaggle.com/ravirajsinh45/real-life-industrial-dataset-of-casting-product\nLicense information: https://creativecommons.org/licenses/by-nc-nd/4.0/\n* Also would like to thank my Professor, Dr. Brett Werner, whose expertise was invaluable in formulating the research questions and methodology. His insightful feedbacks helped me course correct my deliverables and the structure of the lessons he has planned kept me focused and engaged.\n\n## DISCLAIMER\nThis project is purely academic in nature.\n\n## REFERENCES\nai/responsible-ai. (n.d.). Retrieved from microsoft.com: https://www.microsoft.com/en-us/ai/responsible-ai  \nBova, T. (n.d.). busin. Retrieved from gallup: http://linkis.com/www.gallup.com/busin/M4Mmc  \ncomputer-vision. (n.d.). Retrieved from sas: https://www.sas.com/en_us/insights/analytics/computer-vision.html  \nconcept-automated-ml. (n.d.). Retrieved from https://docs.microsoft.com/en-us/azure: https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml  \nconvolution2d. (n.d.). Retrieved from https://keras.io: https://keras.io/api/layers/convolution_layers/convolution2d/  \ncustom-vision. (n.d.). Retrieved from https://docs.microsoft.com: https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/overview  \ndeep-asteroid. (n.d.). Retrieved from open.nasa.gov: https://open.nasa.gov/innovation-space/deep-asteroid/  \ndensenet. (n.d.). Retrieved from arxiv.org: https://arxiv.org/abs/1608.06993  \ndesigner. (n.d.). Retrieved from https://docs.microsoft.com: https://docs.microsoft.com/en-us/azure/machine-learning/concept-designer  \nImageDataGenerator. (n.d.). Retrieved from https://www.tensorflow.org: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator  \nKeras. (n.d.). Retrieved from en.wikipedia.org: https://en.wikipedia.org/wiki/Keras  \nTensorFlow. (n.d.). Retrieved from en.wikipedia.org: https://en.wikipedia.org/wiki/TensorFlow  \nTransfer_learning. (n.d.). Retrieved from en.wikipedia.org: https://en.wikipedia.org/wiki/Transfer_learning  \n\n\n",
            "readme_url": "https://github.com/RajdeepBiswas/Manufacturing-Quality-Inspection",
            "frameworks": [
                "scikit-learn",
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Densely Connected Convolutional Networks",
            "arxiv": "1608.06993",
            "year": 2016,
            "url": "http://arxiv.org/abs/1608.06993v5",
            "abstract": "Recent work has shown that convolutional networks can be substantially\ndeeper, more accurate, and efficient to train if they contain shorter\nconnections between layers close to the input and those close to the output. In\nthis paper, we embrace this observation and introduce the Dense Convolutional\nNetwork (DenseNet), which connects each layer to every other layer in a\nfeed-forward fashion. Whereas traditional convolutional networks with L layers\nhave L connections - one between each layer and its subsequent layer - our\nnetwork has L(L+1)/2 direct connections. For each layer, the feature-maps of\nall preceding layers are used as inputs, and its own feature-maps are used as\ninputs into all subsequent layers. DenseNets have several compelling\nadvantages: they alleviate the vanishing-gradient problem, strengthen feature\npropagation, encourage feature reuse, and substantially reduce the number of\nparameters. We evaluate our proposed architecture on four highly competitive\nobject recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet).\nDenseNets obtain significant improvements over the state-of-the-art on most of\nthem, whilst requiring less computation to achieve high performance. Code and\npre-trained models are available at https://github.com/liuzhuang13/DenseNet .",
            "authors": [
                "Gao Huang",
                "Zhuang Liu",
                "Laurens van der Maaten",
                "Kilian Q. Weinberger"
            ]
        }
    ],
    "training": {
        "datasets": [
            {
                "name": "Wikipedia"
            },
            {
                "name": "ImageNet"
            },
            {
                "name": "SVHN"
            },
            {
                "name": "CIFAR-100"
            },
            {
                "name": "CIFAR-10"
            }
        ]
    },
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9562984382748777,
        "task": "Object Detection",
        "task_prob": 0.6015980851972004
    }
}
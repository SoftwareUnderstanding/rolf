{
    "visibility": {
        "visibility": "public"
    },
    "name": "Transformer and pointer-generator transformer models for the morphological inflection task",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "AssafSinger94",
                "owner_type": "User",
                "name": "sigmorphon-2020-inflection",
                "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection",
                "stars": 0,
                "pushed_at": "2020-05-31 08:54:29+00:00",
                "created_at": "2020-02-01 00:35:06+00:00",
                "language": "Python",
                "description": "Transformer and pointer-generator transformer models for morphological inflection. Submission of the NYU-CUBoulder team to the SIGMORPHON 2020 shared task.",
                "frameworks": [
                    "PyTorch"
                ]
            },
            {
                "type": "code",
                "name": "Makefile",
                "sha": "f91e96e03934cf833caec55a0e761099576df103",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/Makefile"
                    }
                },
                "size": 152
            },
            {
                "type": "code",
                "name": "low_res_exp-pg.sh",
                "sha": "f850c562c57c9d370aa245991942e568b674b2c0",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/low_res_exp-pg.sh"
                    }
                },
                "size": 1026
            },
            {
                "type": "code",
                "name": "low_res_exp-trm.sh",
                "sha": "036eade3475e7755a6573072c318ef8a84001a99",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/low_res_exp-trm.sh"
                    }
                },
                "size": 1010
            },
            {
                "type": "code",
                "name": "src",
                "sha": "6830347e317248bbeb27de8b36894cf8d7b76099",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/tree/master/src"
                    }
                },
                "num_files": 21
            },
            {
                "type": "code",
                "name": "task0-launch-pg-aug.sh",
                "sha": "f427391a7974491f16f338a1fea2864547d18972",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-launch-pg-aug.sh"
                    }
                },
                "size": 549
            },
            {
                "type": "code",
                "name": "task0-launch-pg-pretrain_hall.sh",
                "sha": "78c7767656c6a812e0ec75a5948334a7ef96fcc8",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-launch-pg-pretrain_hall.sh"
                    }
                },
                "size": 300
            },
            {
                "type": "code",
                "name": "task0-launch-pg-trn.sh",
                "sha": "d1aa7e558676cfccb75b2fe507a951c6cecc8e0c",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-launch-pg-trn.sh"
                    }
                },
                "size": 549
            },
            {
                "type": "code",
                "name": "task0-launch-trm-aug.sh",
                "sha": "5cd4bda241174015deb5629f0b4f6d3d4b69dd06",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-launch-trm-aug.sh"
                    }
                },
                "size": 532
            },
            {
                "type": "code",
                "name": "task0-launch-trm-pretrain_hall.sh",
                "sha": "08ca50cf7b61c94de40ef2f94957132f4b43a76a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-launch-trm-pretrain_hall.sh"
                    }
                },
                "size": 283
            },
            {
                "type": "code",
                "name": "task0-launch-trm-trn.sh",
                "sha": "eafeef3f43cd6686c725f76a11b15ec4381e5194",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-launch-trm-trn.sh"
                    }
                },
                "size": 532
            },
            {
                "type": "code",
                "name": "task0-pg-aug-from_pretrain.sh",
                "sha": "96fea1a38c0424043b8212bb395181ebaaa5c6bf",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-pg-aug-from_pretrain.sh"
                    }
                },
                "size": 1077
            },
            {
                "type": "code",
                "name": "task0-pg-aug.sh",
                "sha": "1e16600751d45b33b6e33d48e62913633ed90b01",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-pg-aug.sh"
                    }
                },
                "size": 1017
            },
            {
                "type": "code",
                "name": "task0-pg-pretrain_hall.sh",
                "sha": "96a48ad0b3d2216b6d988a3412c5203bf23e6ba5",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-pg-pretrain_hall.sh"
                    }
                },
                "size": 1012
            },
            {
                "type": "code",
                "name": "task0-pg-trn-from_pretrain.sh",
                "sha": "1f18403f72ad5244feff507ab0cc6372eeaf3d66",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-pg-trn-from_pretrain.sh"
                    }
                },
                "size": 1055
            },
            {
                "type": "code",
                "name": "task0-pg-trn.sh",
                "sha": "1fb73c984dbb04fe0c778cf56caefc67646f1b6b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-pg-trn.sh"
                    }
                },
                "size": 995
            },
            {
                "type": "code",
                "name": "task0-trm-aug-from_pretrain.sh",
                "sha": "6b0aae8b6d565d2e75fae2b1516b02f6c35adcc1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-trm-aug-from_pretrain.sh"
                    }
                },
                "size": 1061
            },
            {
                "type": "code",
                "name": "task0-trm-aug.sh",
                "sha": "19ec0d75396de4cb00b91e38990fe9d3ea7abbfd",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-trm-aug.sh"
                    }
                },
                "size": 1001
            },
            {
                "type": "code",
                "name": "task0-trm-pretrain_hall.sh",
                "sha": "1191add0ce8a3cad65361d46b84e45e095c70ed6",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-trm-pretrain_hall.sh"
                    }
                },
                "size": 996
            },
            {
                "type": "code",
                "name": "task0-trm-trn-from_pretrain.sh",
                "sha": "fe8e50e7e3455eed09074be42038fcf7b3a0c0a6",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-trm-trn-from_pretrain.sh"
                    }
                },
                "size": 1039
            },
            {
                "type": "code",
                "name": "task0-trm-trn.sh",
                "sha": "1c0e42110a7682656a33b1e77e919b9081b95fd1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection/blob/master/task0-trm-trn.sh"
                    }
                },
                "size": 979
            }
        ]
    },
    "authors": [
        {
            "name": "Assaf Singer",
            "github_id": "AssafSinger94"
        }
    ],
    "tags": [],
    "description": "Transformer and pointer-generator transformer models for morphological inflection. Submission of the NYU-CUBoulder team to the SIGMORPHON 2020 shared task.",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection",
            "stars": 0,
            "issues": true,
            "readme": "# Transformer and pointer-generator transformer models for the morphological inflection task\n\n## Submission - NYUCUBoulder, Task 0 and Task 2\n\nFirst download Task 0 data, and build the dataset\n```bash\ngit clone https://github.com/sigmorphon2020/task0-data.git\npython src/data/task0-build-dataset.py\n```\n\nApply multitask training augmentation for all languages, and data hallucination augmentation by [(Anastasopoulos and Neubig, 2019)](https://arxiv.org/abs/1908.05838) for all low-resource languages\n```bash\npython src/data/multitask-augment.py\nbash src/data/hallucinate.sh\n```\n\nSample training sets of low-resource languages, to use for low-resource experiment\n```bash\npython src/data/downsample.py\n```\n\nRun pointer-generator transformer on original datatset and multitask training augmented set (for Task 0).\n```bash\nbash task0-launch-pg-trn.sh\nbash task0-launch-pg-aug.sh\n```\nRun transformer [(Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762) on original datatset and multitask training augmented set (for Task 0).\n```bash\nbash task0-launch-trm-trn.sh\nbash task0-launch-trm-aug.sh\n```\n\nPretrain pointer-generator transformer on hallucinated training set (for Task 0).\n```bash\nbash task0-launch-pg-pretrain_hall.sh\n```\nPretrain transformer [(Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762) on hallucinated training set (for Task 0).\n```bash\nbash task0-launch-pg-pretrain_hall.sh\n```\n\nCode built on top of the baseline code for Task 0 for the SIGMORPHON 2020 Shared Tasks [(Vylomova, 2020)](https://github.com/shijie-wu/neural-transducer.git)\nData hallucination augmentation by [(Anastasopoulos and Neubig, 2019)](https://arxiv.org/abs/1908.05838)\nYou can also run hard monotonic attention [(Wu and Cotterell, 2019)](https://arxiv.org/abs/1905.06319).\n\n## Dependencies\n\n- python 3\n- pytorch==1.4\n- numpy\n- tqdm\n- fire\n\n\n## Install\n\n```bash\nmake\n```\n",
            "readme_url": "https://github.com/AssafSinger94/sigmorphon-2020-inflection",
            "frameworks": [
                "PyTorch"
            ]
        }
    ],
    "references": [
        {
            "title": "Pushing the Limits of Low-Resource Morphological Inflection",
            "arxiv": "1908.05838",
            "year": 2019,
            "url": "http://arxiv.org/abs/1908.05838v2",
            "abstract": "Recent years have seen exceptional strides in the task of automatic\nmorphological inflection generation. However, for a long tail of languages the\nnecessary resources are hard to come by, and state-of-the-art neural methods\nthat work well under higher resource settings perform poorly in the face of a\npaucity of data. In response, we propose a battery of improvements that greatly\nimprove performance under such low-resource conditions. First, we present a\nnovel two-step attention architecture for the inflection decoder. In addition,\nwe investigate the effects of cross-lingual transfer from single and multiple\nlanguages, as well as monolingual data hallucination. The macro-averaged\naccuracy of our models outperforms the state-of-the-art by 15 percentage\npoints. Also, we identify the crucial factors for success with cross-lingual\ntransfer for morphological inflection: typological similarity and a common\nrepresentation across languages.",
            "authors": [
                "Antonios Anastasopoulos",
                "Graham Neubig"
            ]
        },
        {
            "title": "Exact Hard Monotonic Attention for Character-Level Transduction",
            "arxiv": "1905.06319",
            "year": 2019,
            "url": "http://arxiv.org/abs/1905.06319v2",
            "abstract": "Many common character-level, string-to-string transduction tasks, e.g.\ngraphemeto-phoneme conversion and morphological inflection, consist almost\nexclusively of monotonic transduction. Neural sequence-to-sequence models with\nsoft attention, which are non-monotonic, often outperform popular monotonic\nmodels. In this work, we ask the following question: Is monotonicity really a\nhelpful inductive bias in these tasks? We develop a hard attention\nsequence-to-sequence model that enforces strict monotonicity and learns a\nlatent alignment jointly while learning to transduce. With the help of dynamic\nprogramming, we are able to compute the exact marginalization over all\nmonotonic alignments. Our models achieve state-of-the-art performance on\nmorphological inflection. Furthermore, we find strong performance on two other\ncharacter-level transduction tasks. Code is available at\nhttps://github.com/shijie-wu/neural-transducer.",
            "authors": [
                "Shijie Wu",
                "Ryan Cotterell"
            ]
        },
        {
            "title": "Attention Is All You Need",
            "arxiv": "1706.03762",
            "year": 2017,
            "url": "http://arxiv.org/abs/1706.03762v5",
            "abstract": "The dominant sequence transduction models are based on complex recurrent or\nconvolutional neural networks in an encoder-decoder configuration. The best\nperforming models also connect the encoder and decoder through an attention\nmechanism. We propose a new simple network architecture, the Transformer, based\nsolely on attention mechanisms, dispensing with recurrence and convolutions\nentirely. Experiments on two machine translation tasks show these models to be\nsuperior in quality while being more parallelizable and requiring significantly\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\nEnglish-to-German translation task, improving over the existing best results,\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\ntranslation task, our model establishes a new single-model state-of-the-art\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\nof the training costs of the best models from the literature. We show that the\nTransformer generalizes well to other tasks by applying it successfully to\nEnglish constituency parsing both with large and limited training data.",
            "authors": [
                "Ashish Vaswani",
                "Noam Shazeer",
                "Niki Parmar",
                "Jakob Uszkoreit",
                "Llion Jones",
                "Aidan N. Gomez",
                "Lukasz Kaiser",
                "Illia Polosukhin"
            ]
        }
    ],
    "domain": {
        "domain_type": "Natural Language Processing",
        "domain_prob": 0.9995508918789711,
        "task": "Machine Translation",
        "task_prob": 0.9782789786425663
    }
}
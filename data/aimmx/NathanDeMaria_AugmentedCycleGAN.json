{
    "visibility": {
        "visibility": "public"
    },
    "name": "Augmented CycleGAN",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "NathanDeMaria",
                "owner_type": "User",
                "name": "AugmentedCycleGAN",
                "url": "https://github.com/NathanDeMaria/AugmentedCycleGAN",
                "stars": 11,
                "pushed_at": "2018-12-03 00:53:35+00:00",
                "created_at": "2018-12-03 00:35:35+00:00",
                "language": "Jupyter Notebook",
                "description": "A presentation on Augmented CycleGAN and the papers that lead up to it",
                "frameworks": []
            },
            {
                "type": "code",
                "name": ".gitignore",
                "sha": "9951b7ccb4f0464a50da4ee5ce5e4725e9bcf817",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/NathanDeMaria/AugmentedCycleGAN/blob/master/.gitignore"
                    }
                },
                "size": 41
            },
            {
                "type": "code",
                "name": "augmented_cyclegan.ipynb",
                "sha": "995b494d65698b927c2b6ea825486acb1586f861",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/NathanDeMaria/AugmentedCycleGAN/blob/master/augmented_cyclegan.ipynb"
                    }
                },
                "size": 692356
            },
            {
                "type": "code",
                "name": "docker-compose.yml",
                "sha": "b1ae3c7471a9784b0bae7be6dd44ae1a6f5f507b",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/NathanDeMaria/AugmentedCycleGAN/blob/master/docker-compose.yml"
                    }
                },
                "size": 255
            },
            {
                "type": "code",
                "name": "extra",
                "sha": "692854d99d152f10fac0b178727e91faa2267f56",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/NathanDeMaria/AugmentedCycleGAN/tree/master/extra"
                    }
                },
                "num_files": 5
            },
            {
                "type": "code",
                "name": "images",
                "sha": "dced602d42eadec47bc3d8bdfcfb68a89d4fd372",
                "filetype": "dir",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/NathanDeMaria/AugmentedCycleGAN/tree/master/images"
                    }
                },
                "num_files": 12
            }
        ]
    },
    "trained_model": {
        "binaries": [
            {
                "type": "binary",
                "name": "Dockerfile",
                "sha": "f07d003997eabeac68bb1e6792ad479752897074",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/NathanDeMaria/AugmentedCycleGAN/blob/master/Dockerfile"
                    }
                },
                "size": 276
            }
        ]
    },
    "authors": [
        {
            "name": "Nathan DeMaria",
            "github_id": "NathanDeMaria"
        }
    ],
    "tags": [],
    "description": "A presentation on Augmented CycleGAN and the papers that lead up to it",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/NathanDeMaria/AugmentedCycleGAN",
            "stars": 11,
            "issues": true,
            "readme": "# Augmented CycleGAN\n\nPresentation on learning domain <-> domain mappings \nmade via [RISE](https://github.com/damianavila/RISE) combining ideas/code from:\n- Conditional GAN\n    - https://arxiv.org/pdf/1411.1784.pdf\n    - https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n- CycleGAN\n    - https://arxiv.org/abs/1703.10593\n    - code from same as above\n- Augmented CycleGAN\n    - https://arxiv.org/pdf/1802.10151.pdf\n    -  https://github.com/aalmah/augmented_cyclegan\n    ",
            "readme_url": "https://github.com/NathanDeMaria/AugmentedCycleGAN",
            "frameworks": []
        }
    ],
    "references": [
        {
            "title": "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks",
            "arxiv": "1703.10593",
            "year": 2017,
            "url": "http://arxiv.org/abs/1703.10593v7",
            "abstract": "Image-to-image translation is a class of vision and graphics problems where\nthe goal is to learn the mapping between an input image and an output image\nusing a training set of aligned image pairs. However, for many tasks, paired\ntraining data will not be available. We present an approach for learning to\ntranslate an image from a source domain $X$ to a target domain $Y$ in the\nabsence of paired examples. Our goal is to learn a mapping $G: X \\rightarrow Y$\nsuch that the distribution of images from $G(X)$ is indistinguishable from the\ndistribution $Y$ using an adversarial loss. Because this mapping is highly\nunder-constrained, we couple it with an inverse mapping $F: Y \\rightarrow X$\nand introduce a cycle consistency loss to push $F(G(X)) \\approx X$ (and vice\nversa). Qualitative results are presented on several tasks where paired\ntraining data does not exist, including collection style transfer, object\ntransfiguration, season transfer, photo enhancement, etc. Quantitative\ncomparisons against several prior methods demonstrate the superiority of our\napproach.",
            "authors": [
                "Jun-Yan Zhu",
                "Taesung Park",
                "Phillip Isola",
                "Alexei A. Efros"
            ]
        },
        {
            "title": "Augmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data",
            "arxiv": "1802.10151",
            "year": 2018,
            "url": "http://arxiv.org/abs/1802.10151v2",
            "abstract": "Learning inter-domain mappings from unpaired data can improve performance in\nstructured prediction tasks, such as image segmentation, by reducing the need\nfor paired data. CycleGAN was recently proposed for this problem, but\ncritically assumes the underlying inter-domain mapping is approximately\ndeterministic and one-to-one. This assumption renders the model ineffective for\ntasks requiring flexible, many-to-many mappings. We propose a new model, called\nAugmented CycleGAN, which learns many-to-many mappings between domains. We\nexamine Augmented CycleGAN qualitatively and quantitatively on several image\ndatasets.",
            "authors": [
                "Amjad Almahairi",
                "Sai Rajeswar",
                "Alessandro Sordoni",
                "Philip Bachman",
                "Aaron Courville"
            ]
        },
        {
            "title": "Conditional Generative Adversarial Nets",
            "arxiv": "1411.1784",
            "year": 2014,
            "url": "http://arxiv.org/abs/1411.1784v1",
            "abstract": "Generative Adversarial Nets [8] were recently introduced as a novel way to\ntrain generative models. In this work we introduce the conditional version of\ngenerative adversarial nets, which can be constructed by simply feeding the\ndata, y, we wish to condition on to both the generator and discriminator. We\nshow that this model can generate MNIST digits conditioned on class labels. We\nalso illustrate how this model could be used to learn a multi-modal model, and\nprovide preliminary examples of an application to image tagging in which we\ndemonstrate how this approach can generate descriptive tags which are not part\nof training labels.",
            "authors": [
                "Mehdi Mirza",
                "Simon Osindero"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.999512479764438,
        "task": "Image-to-Image Translation",
        "task_prob": 0.9911114136303569
    },
    "training": {
        "datasets": [
            {
                "name": "MNIST"
            }
        ]
    }
}
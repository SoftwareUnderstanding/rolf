{
    "visibility": {
        "visibility": "public",
        "license": "MIT License"
    },
    "name": "CycleGAN-Unpaired-Image-translation",
    "definition": {
        "code": [
            {
                "type": "repo",
                "repo_type": "github",
                "owner": "DeepikaKaranji",
                "owner_type": "User",
                "name": "CycleGAN-Unpaired-Image-translation",
                "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation",
                "stars": 0,
                "pushed_at": "2020-08-10 16:00:24+00:00",
                "created_at": "2020-04-30 09:54:45+00:00",
                "language": "Python",
                "description": "Unpaired image translation with Cycle GAN using Tensorflow 1.0.0",
                "license": "MIT License",
                "frameworks": [
                    "TensorFlow"
                ]
            },
            {
                "type": "code",
                "name": "CycleGAN_report.pdf",
                "sha": "53cb205e5fcbe7a4f07c8eeb0b2e87d91921983a",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation/blob/master/CycleGAN_report.pdf"
                    }
                },
                "size": 404948
            },
            {
                "type": "code",
                "name": "LICENSE",
                "sha": "f558e5eba199a57c407a8759d80af18bb2025a33",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation/blob/master/LICENSE"
                    }
                },
                "size": 1072
            },
            {
                "type": "code",
                "name": "build.py",
                "sha": "2979b51854f82856ef77e4f62ec7c4731060efd1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation/blob/master/build.py"
                    }
                },
                "size": 2132
            },
            {
                "type": "code",
                "name": "build_data.py",
                "sha": "6bcfc912481dd6ea8a64f7ae702a5d1ee2c22037",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation/blob/master/build_data.py"
                    }
                },
                "size": 2161
            },
            {
                "type": "code",
                "name": "depend.txt",
                "sha": "21e578956df1f6269c29a76230139d0217d741ff",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation/blob/master/depend.txt"
                    }
                },
                "size": 48
            },
            {
                "type": "code",
                "name": "disc.png",
                "sha": "8aedf8b07e3602fd5674a5e2d540e13e579df15d",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation/blob/master/disc.png"
                    }
                },
                "size": 49544
            },
            {
                "type": "code",
                "name": "discriminator.py",
                "sha": "8ad5224630e3072f987de934a27f244c16f817f6",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation/blob/master/discriminator.py"
                    }
                },
                "size": 2473
            },
            {
                "type": "code",
                "name": "gen.png",
                "sha": "b7efc025f45d5acdd20ecf6b1158075a27f16cf1",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation/blob/master/gen.png"
                    }
                },
                "size": 44513
            },
            {
                "type": "code",
                "name": "generator.py",
                "sha": "76721b1ca5095b605cc7cc8b374e541e221141a4",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation/blob/master/generator.py"
                    }
                },
                "size": 5215
            },
            {
                "type": "code",
                "name": "main.py",
                "sha": "049be4aaa2499c3213853c3f22b43d70a1297bf3",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation/blob/master/main.py"
                    }
                },
                "size": 3604
            },
            {
                "type": "code",
                "name": "model.py",
                "sha": "67a5874de54c36230b4460182de4f7b72c5af448",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation/blob/master/model.py"
                    }
                },
                "size": 3782
            },
            {
                "type": "code",
                "name": "reader.py",
                "sha": "38398b3e7c5caafa5f37a59c7ece9b17740fe2f7",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation/blob/master/reader.py"
                    }
                },
                "size": 1497
            },
            {
                "type": "code",
                "name": "results.png",
                "sha": "064131d4ec7211d33e2d6df3917fda52e04c489e",
                "filetype": "file",
                "connection": {
                    "name": "github_url",
                    "source": {
                        "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation/blob/master/results.png"
                    }
                },
                "size": 192761
            }
        ]
    },
    "authors": [
        {
            "name": "Deepika Karanji",
            "email": "deeps.karanji2@gmail.com",
            "github_id": "DeepikaKaranji"
        }
    ],
    "tags": [],
    "description": "Unpaired image translation with Cycle GAN using Tensorflow 1.0.0",
    "extraction": [
        {
            "type": "github",
            "url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation",
            "stars": 0,
            "issues": true,
            "readme": "# CycleGAN-Unpaired-Image-translation    \n[![GitHub license](https://img.shields.io/github/license/DeepikaKaranji/CycleGAN-Unpaired-Image-translation)](https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation/blob/master/LICENSE)\n[![Generic badge](https://img.shields.io/badge/tensorflow-1.0.0-blue.svg)](https://shields.io/)  \n\nImage to Image translation involves generating a new synthetic version of a given image with some modifications. Obtaining and constructing paired image datasets is  expensive and sometimes impossible. This project implements Cycle GAN to achieve image translation from Apple to Orange with Tensorflow 1.0.0 and Python3. \n\n## Introduction\n\nTraining a model for image-to-image translation typically requires a large dataset of paired examples.These datasets can be difficult and expensive to prepare, and in some cases impossible, such as photographs of paintings by long dead artists. The CycleGAN is a technique that involves the automatic training of image-to-image translation models without paired examples. The models are trained in an unsupervised manner using a collection of images from the source and target domain that do not need to be related in any way.\n\nPix2Pix GAN, a popular image to image translation uses paired images. Paired images dataset is small and hence it is hard to implement object transformation. Cycle GANs use unpaired images for training for image to image transformation.\n\n## Architecture\n \n### **Generator (G)**\nInput: Takes photos from Domain X (Apple/Horse)    \nOutput: Generates photos of Domain Y (Orange/Zebra).  \n![generator](gen.png)\n\nThe Generator layers are:\n- **Encoder**   \n3 Convolution Layers with Relu as the activation function.\n    - 7x7 with 1 stride and 32 filters \n    - 3x3 with 2 stride and 64 filters\n    - 3x3 with 2 stride 128 filters  along\n- **Transformer**   \n6 resnet layers (residual block) each of which consists of 2 Convolution Layers (3x3 convolution) with 128 filters and 2 strides and relu as the activation function. \n- **Decoder**\n    - 2 deconvolution layers fractionally strided with stride \u00bd with relu activation function\n        - 3x3 with 64 filters \n        - 3x3 with 32 filters \n    - 1 conv - tanh 7x7 1 stride 3 filters\n\n### **Discriminator (Dy)**\nInput: Takes photos from  Domain Y (Orange/Zebra) and output generated from F.                                         \nOutput: Likelihood that the image is from Domain Y.   \n\n![discriminator](disc.png)\n\nThe Discriminator layers are:\n- 4 Convolution layers 4x4 with 2 strides each with a leaky relu activation function\n    - 64 filters\n    - 128 filters\n    - 256 filters\n    - 512 filters\n- 1 last convolution layer 4x4 with 1 stride and 512 filters\n\n\n## Results\n\n`CycleGAN_report.pdf` contains a detailed report on the approach, implementation, code modules and results and references. \n\n![results](results.png)\n\n## Applications\nCycleGAN has several important applications:\n\n- Generating a realistic rendering of what a building would look like based on its blueprints.\n- Rendering a realistic representation of how a suspect\u2019s face would look based on police sketch.\n- Creating an image of how a location would look in each different season.\n- Enhancing aspects of photos to make them look more professional.\n- Conversion of MRI Scans into CT Scans\n- Photo generation from paintings\n\n## References\n[1]https://arxiv.org/pdf/1703.10593.pdf   \n[2]https://machinelearningmastery.com/what-is-cyclegan/   \n[3]https://www.youtube.com/watch?v=NyAosnNQv_U&t=553s   \n[4]https://machinelearningmastery.com/what-is-cyclegan/   \n",
            "readme_url": "https://github.com/DeepikaKaranji/CycleGAN-Unpaired-Image-translation",
            "frameworks": [
                "TensorFlow"
            ]
        }
    ],
    "references": [
        {
            "title": "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks",
            "arxiv": "1703.10593",
            "year": 2017,
            "url": "http://arxiv.org/abs/1703.10593v7",
            "abstract": "Image-to-image translation is a class of vision and graphics problems where\nthe goal is to learn the mapping between an input image and an output image\nusing a training set of aligned image pairs. However, for many tasks, paired\ntraining data will not be available. We present an approach for learning to\ntranslate an image from a source domain $X$ to a target domain $Y$ in the\nabsence of paired examples. Our goal is to learn a mapping $G: X \\rightarrow Y$\nsuch that the distribution of images from $G(X)$ is indistinguishable from the\ndistribution $Y$ using an adversarial loss. Because this mapping is highly\nunder-constrained, we couple it with an inverse mapping $F: Y \\rightarrow X$\nand introduce a cycle consistency loss to push $F(G(X)) \\approx X$ (and vice\nversa). Qualitative results are presented on several tasks where paired\ntraining data does not exist, including collection style transfer, object\ntransfiguration, season transfer, photo enhancement, etc. Quantitative\ncomparisons against several prior methods demonstrate the superiority of our\napproach.",
            "authors": [
                "Jun-Yan Zhu",
                "Taesung Park",
                "Phillip Isola",
                "Alexei A. Efros"
            ]
        }
    ],
    "domain": {
        "domain_type": "Computer Vision",
        "domain_prob": 0.9999993676724014,
        "task": "Image-to-Image Translation",
        "task_prob": 0.9862785582821109
    }
}
# Machine_Translation

1. Andrew Ng's Sequence Modeling Course at deeplearning.ai
2. Attention Model:
    2.1 Jay Alammar: https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
    2.2 Bahdanau Attention: https://arxiv.org/pdf/1409.0473.pdf
    2.3 Self Attention in Transformer - by Jay Alammar: http://jalammar.github.io/illustrated-transformer/
3. Attention is all you need - Transformer (Paper): https://arxiv.org/abs/1706.03762
4. Transformer Architecture Blog by Google: https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html
5. Annotated Transformer: http://nlp.seas.harvard.edu/2018/04/03/attention.html

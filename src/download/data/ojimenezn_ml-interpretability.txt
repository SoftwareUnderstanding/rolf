# Machine Learning Interpretability with LIME and SHAP

Project done as part of the ESMA4016 Machine Learning and Data Mining course at UPRM in the Spring 2020 Semester. Main focus was on studying [LIME](https://doi.org/10.1145/2939672.2939778) and [SHAP](https://arxiv.org/pdf/1705.07874.pdf) interpretability methods to analyze the predictions of classification and regression models. Project is available as [Google Colab](https://colab.research.google.com/) notebooks to make installation of software dependencies and code usage easier, as well as enabling use of GPUs for Convolutional Neural Network (CNN) training. 

## What is interpretability?
<div align="center">
<img src="https://github.com/ojimenezn/ml-interpretability/blob/main/images/interpretability-cartoon.png" alt="logo"></img>
</div>
<div align="center">
<img src="https://github.com/ojimenezn/ml-interpretability/blob/main/images/models-cartoon.png" alt="logo"></img>
</div>

[LIME](https://doi.org/10.1145/2939672.2939778) and [SHAP](https://arxiv.org/pdf/1705.07874.pdf) are both methods that can be used to extract interpretability from complex (accurate) methods.

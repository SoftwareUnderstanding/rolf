[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/18lQT0Wy_hPQe2oxk3WtvHUPj1MzD2IL-?usp=sharing)

# Graph Attention Networks

![Graph Attention Networks](https://camo.githubusercontent.com/4fe1a90e67d17a2330d7cfcddc930d5f7501750c/68747470733a2f2f7777772e64726f70626f782e636f6d2f732f71327a703170366b37396a6a6431352f6761745f6c617965722e706e673f7261773d31)

This is a simple implementation of Graph Attention Networks (GATs) using the `tf.keras` subclassing API.
The code provided is a single layer. Stack many of them if you want to use multiple layers.

**Note**: For a mature library for graph neural networks in TensorFlow 2, check out [Spektral](https://github.com/danielegrattarola/spektral).

## Resources

[arXiv paper](https://arxiv.org/abs/1710.10903v3)

[Blog post by first author](https://petar-v.com/GAT/)

[GAT page on my research wiki](https://blog.noahtren.com/%F0%9F%8C%B1/38358b75-cbc6-4c66-bb0c-e9829a293f2f/)

# NLP on IMDB Dataset for sentimental analysis 


### Blogs

* Finally machines that can finish your sentences: https://www.nytimes.com/2018/11/18/technology/artificial-intelligence-language.html
* Introducing state of the art text classification with universal language models: http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html

### Dataset 

Large Movie Review Dataset
This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well. Raw text and already processed bag of words formats are provided. See the README file contained in the release for more details. :http://ai.stanford.edu/~amaas/data/sentiment/

### Research Papers

Universal Language Model Fine-tuning for Text Classification: https://arxiv.org/abs/1801.06146

### Pretrained model that we used for Transfer Learning

WikiText-2(SalesForce) by Stephen Merity

The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia. The dataset is available under the Creative Commons Attribution-ShareAlike License.

https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/

### Implementation of RNN
* Swift Key Keyboard: https://blog.swiftkey.com/swiftkey-debuts-worlds-first-smartphone-keyboard-powered-by-neural-networks/
* Andrej Karpathy(Genrate Latex paper with RNN): http://karpathy.github.io/2015/05/21/rnn-effectiveness/

### Machine Info

Trained on: AWS Instance p2.xlarge
16 GIGS vRAM
64 GB RAM

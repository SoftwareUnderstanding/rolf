# Deep Learning Final Project Report
**Stefan Generalao**<br/>stefan.generalao@gmail.com<br/>RMIT University, Melbourne<br/>Data Mining, Semester 2, 2019<br/>

**Course Coordinator**: Assoc. Prof. Vic Ciesielski

## 1 Introduction
Classifying unlabeled data is generally the final purpose of supervised learning problems. Fitting a classifier for accurate predictions of unlabeled data can not be achieved with supervised learning, unsupervised learning may be considered instead. The typical purpose of unsupervised learning is to find relations between datapoints but compared to supervised learning they do not output any target predictions.

Semi-supervised learning includes the challange to classify a large unlabeled dataset using a small labeled dataset for training the classifier. Reasons of pursuing semi-supervised learning rather than supervised may be to reduce the manual labour of having a domain expert label every datapoint.

## 2 Dataset
<div style="float:right; width:175px; margin-left:30px; page-break-inside:avoid;">
  <div style="margin-bottom:30px; margin-top:7px;">
    <img src="report_images/sample-interior.jpg" alt="interior example"/>
    <p style="font-size:90%; font-style:italic; text-align:center; margin:0;">
      Figure 1: Interior image
    </p>      
  </div>
  <div style="margin-bottom:30px; margin-top:7px;">
    <img src="report_images/sample-exterior.jpg" alt="exterior example"/>
    <p style="font-size:90%; font-style:italic; text-align:center; margin:0;">
      Figure 2: Exterior image
    </p>
  </div>
</div>

Upon this project a large unlabeled dataset of images was presented which had been generated by webscraping of various Australian real estate agents. The images consisted of exterior, interior, floor plan and aerial images of presumably Australian homes. All of the observed images had good levels of exposure and none were significally noisy. The depth of field was large on most of the observed images and high dynamic range seems to be an apparent choice by the majority of real estate photographers. Some images included watermarks of the real estate agent.

## 3 Initial Planning
Both me and my coordinator agreed on analysing the dataset using some kind of semi-supervised learning to classify images to either exterior or interior. Besides building an image classifier some additional work was required for the project. Our discussions included numerous approaches such as:
- Estimating the accuracy of the unlabeled dataset
- Generative Adversarial Networks to augment a bigger training set
- Introducing a third class for images hard to classify or neither interior nor exterior
- Threshold of uncertainty for incorporating classified images into training
- Class Activation Maps and occlusion
- Transfer Learning

### 3.1 Estimating the Error Rate of the Unlabeled Dataset
This has been attempted by uncredible sources and I decided not to pursue it at this time. It is suspected to be a very advanced field of mathematics and data analysis. Assessing my current experience in the field, I am afraid I would not be able nor approariate to produce any credible results.

### 3.2 Generative Adversarial Networks (GAN) for Image Augmentation
GANs proves to be an effective way of increasing the volume of the training set. Using a variant of GAN, Yulia Arzhaeva et. al. managed to increase the accuracy of their classifier for classifying a certain medical condition: "In this work, we train a CycleGAN using our 56 normal and 56 pneumoconiosis images to generate 1,000 normal and 1,000 pneumoconiosis images, respectively. Experiments show that overall good accuracy is achieved when using the synthetic images generated by CycleGAN trained for 30 epochs." [1]. Although somewhat relevant for this study, it was decided to not be implemented due to speculative advanced implementations of GAN.

### 3.3 Threshold of Certainty (ToC)
ToC is a classification strategy that lets predictions between a set lower and upper threshold be classified to unknown. The unknown label is a way for the classifier to indicate that further domain assistance is required. The ToC strategy also infers that the accuracy of the classifier would be increased as predictions with low certainty will be excluded. The idea is that when the range of unknown increases so will the accuracy and also the number of unknown classifications.
<div style="background-color:#f8f8f8; padding:30px; page-break-inside:avoid;">
  <div style="width:100%; display:grid; grid-template-columns: 1fr 1fr; grid-gap:25px; margin-bottom:10px;">
    <div>
      <img src="report_images/toc_1.jpg" alt="Threshold of certainty example 1"/>
      <p style="font-size:90%; font-style:italic; text-align:center; margin:0;">
        (a) Lower threshold=0.1, upper threshold=0.9
      </p>
    </div>
    <div>
      <img src="report_images/toc_2.jpg" alt="Threshold of certainty example 2"/>
      <p style="font-size:90%; font-style:italic; text-align:center; margin:0;">
        (b) Lower threshold=0.4, upper threshold=0.6
      </p>
    </div>
  </div>
  <p style="font-size:90%; font-style:italic; text-align:center; margin:0 30px;">
    Figure 3: Respresentations of ToC for two different variants
  </p>
</div>

The strategy can be further developed to incoperate images with high certainty to the training set, instead of letting a domain expert label every unlabeled image. Letting a domain expert label the unknown classified images will further provide more training data. The importance of either high accuracy or low rate of unknown classifications depends on the upper and lower thresholds. The decision can be considered based on the business goals and limits of the project.

Studies about approaches similar to ToC could not be found being used as a semi-supervised learning fashion. Therefore it was decided to investigate the possibilities with ToC. I would also appreciate any input or findings about prior research.

### 3.4 Class Activation Maps
Generating class activation maps is a way of interpreting and sometimes debugging a convolutional neural network. It was decided that class activation maps would be tested on the trained classifier.

## 4 Manual Labeling
<div style="float:right; width:175px; margin-left:30px; page-break-inside:avoid;">
  <div style="margin-bottom:30px; margin-top:7px;">
    <img src="report_images/labeling-app.jpg" alt="Manual labeling application"/>
    <p style="font-size:90%; font-style:italic; text-align:center; margin:0;">
      Figure 4: Screenshot of manual labeling web application for Android
    </p>
  </div>
</div>

The size of the initial training set was decided to 512 interior and 512 exterior together with a validation set of 256 interior and 256 exterior images. In other words, 768 interior and 768 exterior images had to be manually labeled at minimum, or 1536 in total. All images being neither an interior nor exterior image was simply classified as <i>skipped</i> and would not be used in the training sessions. Although 1024 datapoints is relatively small it was thought to be enough for semi-supervised learning.

A small sample was manually labeled by placing images in folders of the corresponding label. It was then discovered that the unlabeled dataset was unbalanced by around 1:7 ratio of interior to exterior and the skipped images consisted of around 6%. Using this information and solving the equation for `(interior>768)AND(exterior>768)` meant that around 6500 images had to be manually labeled in order to achieve a 1:1 ratio between interior and exterior.

The duration of opening an image, analysing and placing it to the corresponding folder (interior/exterior/skip) was estimated to take around five seconds. Labelling 6500 images would therefore require around nine hours. To alleviate the tedious manual labour of classifying the initial dataset it was decided to develop a web application as a tool. Being an experienced full-stack web developer, the process of building a complete application took around two hours. Using the web application a sufficient dataset for training was extracted after 6383 images and around three hours. Having an application for manual labelling at disposal also means that additional labelling will be effortless and also increasing scalability of future progress.

## 5 Classifier
The architecture of the classifier is a convolutional neural network, also known as ConvNet. The model consists of five trainable layers, two of which are convolutional and the rest are fully connected. The rather unconventional activation function called <i>Exponential Linear Unit</i> (ELU) was used for every layer except the output. For many image datasets, ELUs shows to be superior in training time and accuracy compared to the more common <i>Rectified Linear Units</i> (ReLUs) and <i>Leaky Rectified Linear Units</i> (LeakyReLUs) [2]. For the output layer, the activation function Softmax was applied instead of ELU.
<div style="padding:10px; background-color:#f8f8f8; text-align:center; page-break-inside: avoid;">
	<pre style="font-size:90%">
Layer (type)                        Output Shape                    Param #     
================================================================================
conv2d_1 (Conv2D)                   (None, 124, 124, 64)            1664        
________________________________________________________________________________
elu_1 (ELU)                         (None, 124, 124, 64)            0           
________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)      (None, 62, 62, 64)              0           
________________________________________________________________________________
conv2d_2 (Conv2D)                   (None, 58, 58, 32)              51232       
________________________________________________________________________________
elu_2 (ELU)                         (None, 58, 58, 32)              0           
________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)      (None, 29, 29, 32)              0           
________________________________________________________________________________
flatten_1 (Flatten)                 (None, 26912)                   0           
________________________________________________________________________________
dense_1 (Dense)                     (None, 32)                      861216      
________________________________________________________________________________
elu_3 (ELU)                         (None, 32)                      0           
________________________________________________________________________________
dropout_1 (Dropout)                 (None, 32)                      0           
________________________________________________________________________________
dense_2 (Dense)                     (None, 16)                      528         
________________________________________________________________________________
elu_4 (ELU)                         (None, 16)                      0           
________________________________________________________________________________
dense_3 (Dense)                     (None, 2)                       34          
================================================================================
Total params: 914,674
Trainable params: 914,674
Non-trainable params: 0
________________________________________________________________________________
  </pre>
  <p style="font-size:90%; font-style:italic; text-align:center;">
    Figure 5: Architecure of the classifier
  </p>
</div>

The classifier was built using Keras version 2.2.5 for Python 3.6.8 and trained using GPU (Tesla K80) provided by Google Colab  [3], [4].

## 6 Image Augmentation

A clever way of extracting more data from small datasets is to generate multiple images from one. For this project multiple parameters for image augmentation was used including horizontal flip, rotation and zooming. Every training batch is randomly generated based on the set parameters of the image augmentation.

Initially, image transformation was applied for all RGB-channels but in later stages of the project grayscale manipulation was applied as well as it proved to yield more reliable results.
<div style="background-color:#f8f8f8; padding:30px; page-break-inside:avoid;">
  <div style="width:100%; margin-bottom:10px;">
    <div>
      <img src="report_images/image_augmentation_samples.jpg" alt="Image augmentation samples"/>
      <p style="font-size:90%; font-style:italic; text-align:center; margin-top:20px;">
        Figure 6: Image augmentation samples
      </p>
    </div>
  </div>
</div>

## 7 Training and Evaluation
Categorical crossentropy loss function was used for fitting the classifier as it is suitable for determining the likelihood of a certain category using ConvNets. The classifier trained for 512 epochs but the validation loss reached convergence after about 360 epochs. The optimisation was achieved by stochastic gradient descent with learning rate of 0.01. The training session ended with a validation accuracy of 94.5%.
<div style="background-color:#f8f8f8; padding:30px; page-break-inside:avoid;">
  <div style="width:100%; display:grid; grid-template-columns: 1fr 1fr; grid-gap:25px; margin-bottom:10px;">
    <div>
      <img src="report_images/loss_history.jpg" alt="training loss history"/>
      <p style="font-size:90%; font-style:italic; text-align:center; margin:0;">
        (a) Loss over epochs
      </p>
    </div>
    <div>
      <img src="report_images/accuracy_history.jpg" alt="training accuracy history"/>
      <p style="font-size:90%; font-style:italic; text-align:center; margin:0;">
        (b) Accuracy over epochs
      </p>
    </div>
  </div>
  <p style="font-size:90%; font-style:italic; text-align:center; margin:0 30px;">
    Figure 7: The distinct colored line represents the moving average whereas the faded colored line represents the true history.
  </p>
</div>

### 7.1 Evaluation using ToC
In this section the results of the ToC-strategy is revealed. The lower threshold (LT) and upper threshold (UT) was configured at various settings. The results also includes a confusion matrix providing further insights. During the evaluation, 512 validation images were each augmented 10 times creating a total of 5120 data points.

#### 7.1.1 LT=0.5, UT=0.5
As expected, for LT and UT both set at 0.5, the rate of unknowns is 0% while the accuracy is 94.5% as seen in section 7. These thresholds means that unknowns are completely excluded from the range resulting in classifications of interior and exterior only.
<div style="padding:10px; background-color:#f8f8f8; text-align:center; page-break-inside:avoid;">
	<pre style="font-size:90%">
Lower threshold: 0.5                                                           
Upper threshold: 0.5                                                           
____________________________________________________________                   
n=5120       | Exterior       Interior       Unknown        <---Classified as  
=============|==============================================                   
Exterior     | 2409           151            0                                 
_____________|______________________________________________                   
Interior     | 116            2444           0                                 
============================================================                   
Accuracy (unknown excl.): 94.5%                                                
Rate of unknowns: 0.0%                                                         
____________________________________________________________                   
  </pre>
  <p style="font-size:90%; font-style:italic; text-align:center;">
    Figure 8: Results of ToC for LT=0.5 and UT=0.5
  </p>
</div>

<div style="page-break-after: always;"></div>
#### 7.1.2 LT=0.1, UT=0.9

As discussed in section 3.3, the accuracy is expected to increase if the range of unknown classifications is increased as well. Setting the LT at 0.1 and UT at 0.9 increases the accuracy to 98.3% but also increases the rate of unknowns to 10.9%.
<div style="padding:10px; background-color:#f8f8f8; text-align:center; page-break-inside: avoid;">
	<pre style="font-size:90%">
Lower threshold: 0.1                                                           
Upper threshold: 0.9                                                           
____________________________________________________________                   
n=5120       | Exterior       Interior       Unknown        <---Classified as  
=============|==============================================                   
Exterior     | 2210           38             312                               
_____________|______________________________________________                   
Interior     | 40             2273           247                               
============================================================                   
Accuracy (unknown excl.): 98.3%                                                
Rate of unknowns: 10.9%                                                        
____________________________________________________________                   
  </pre>
  <p style="font-size:90%; font-style:italic; text-align:center;">
    Figure 9: Results of ToC for LT=0.1 and UT=0.9
  </p>
</div>

#### 7.1.3 LT=0.01, UT=0.99
Increasing the thresholds to LT at 0.01 and UT at 0.99 further increases the accuracy to 99.4% and rate of unknowns to 28.3%
<div style="padding:10px; background-color:#f8f8f8; text-align:center; page-break-inside: avoid;">
	<pre style="font-size:90%">
Lower threshold: 0.01                                                          
Upper threshold: 0.99                                                          
____________________________________________________________                   
n=5120       | Exterior       Interior       Unknown        <---Classified as  
=============|==============================================                   
Exterior     | 1841           10             709                               
_____________|______________________________________________                   
Interior     | 10             1782           768                               
============================================================                   
Accuracy (unknown excl.): 99.4%                                                
Rate of unknowns: 28.8%                                                        
____________________________________________________________                   
  </pre>
  <p style="font-size:90%; font-style:italic; text-align:center;">
    Figure 10: Results of ToC for LT=0.01 and UT=0.99
  </p>
</div>

<div style="page-break-after: always;"></div>
#### 7.1.4 LT=0.0001, UT=0.9999

Extreme thresholds yields 100% accuracy for this classifier and 78.6% rate of unknowns. Whether extreme thresholds such as LT at 0.0001 and UT at 0.9999 actually provides any value for semi-supervised learning is questionable. Notice how exterior images seem to be easier to classify at this point.
<div style="padding:10px; background-color:#f8f8f8; text-align:center; page-break-inside: avoid;">
	<pre style="font-size:90%">
Lower threshold: 0.0001                                                        
Upper threshold: 0.9999                                                        
____________________________________________________________                   
n=5120       | Exterior       Interior       Unknown        <---Classified as  
=============|==============================================                   
Exterior     | 805            0              1755                              
_____________|______________________________________________                   
Interior     | 0              291            2269                              
============================================================                   
Accuracy (unknown excl.): 100.0%                                               
Rate of unknowns: 78.6%                                                        
____________________________________________________________                   
  </pre>
  <p style="font-size:90%; font-style:italic; text-align:center;">
  	Figure 11: Results of ToC for LT=0.0001 and UT=0.9999
  </p>
</div>

## 8 Class Activation Maps
Class activations maps was successfully applied to the trained classifier as seen in figure 12 and 13. As discussed in section 11.2, the heat maps may or may not be arbitrary and/or prone to confirmation bias.

Masking the parts of the image with high focus shows to slightly affect predictions. The process simply masks the parts of the images with the heat map generated from the class activation map. Class activation maps created from the occluded images shows that the focus shifts to other parts of the image. In many cases the classifier manages to do correct classifications even though occlusion is applied.

<div style="background-color:#f8f8f8; padding:10px; page-break-inside:avoid;">
  <div style="width:100%; display:grid; grid-template-columns: 1fr 1fr 1fr; grid-gap:25px; margin-bottom:10px;">
    <div>
      <img src="report_images/cam_original_1.jpg" alt="class activation map original 1"/>
      <img src="report_images/cam_heatmap_1.jpg" alt="class activation map 1"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (a) Classified as:<br/>
        Exterior: 100.0%<br/>
        Interior: 0.0%
      </p>
    </div>
    <div>
      <img src="report_images/cam_original_4.jpg" alt="class activation map original 4"/>
      <img src="report_images/cam_heatmap_4.jpg" alt="class activation map 4"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (b) Classified as:<br/>
        Exterior: 100.0%<br/>
        Interior: 0.0%
      </p>
    </div>
    <div>
      <img src="report_images/cam_original_5.jpg" alt="class activation map original 5"/>
      <img src="report_images/cam_heatmap_5.jpg" alt="class activation map 5"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (c) Classified as:<br/>
        Exterior: 100.0%<br/>
        Interior: 0.0%
      </p>
    </div>
  </div>
  <p style="font-size:90%; font-style:italic; text-align:center; margin:0 30px;">
    Figure 12: Exterior images from the test set with class activation maps
  </p>
</div>

<div style="background-color:#f8f8f8; padding:10px; page-break-inside:avoid;">
  <div style="width:100%; display:grid; grid-template-columns: 1fr 1fr 1fr; grid-gap:25px; margin-bottom:10px;">
    <div>
      <img src="report_images/occ_ext_1.jpg" alt="Occlusion sample 1"/>
      <img src="report_images/occ_heatmap_1.jpg" alt="Occlusion sample 1"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (a) Classified as:<br/>
        Exterior: 100.0%<br/>
        Interior: 0.0%
      </p>
    </div>
    <div>
      <img src="report_images/occ_ext_4.jpg" alt="Occlusion sample 4"/>
      <img src="report_images/occ_heatmap_4.jpg" alt="Occlusion sample 4"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (b) Classified as:<br/>
        Exterior: 100.0%<br/>
        Interior: 0.0%
      </p>
    </div>
    <div>
      <img src="report_images/occ_ext_5.jpg" alt="Occlusion sample 5"/>
      <img src="report_images/occ_heatmap_5.jpg" alt="Occlusion sample 5"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (c) Classified as:<br/>
        Exterior: 100.0%<br/>
        Interior: 0.0%
      </p>
    </div>
  </div>
  <p style="font-size:90%; font-style:italic; text-align:center; margin:0 30px;">
    Figure 13: Occluded exterior images with corresponding heat maps generated from the occluded image
  </p>
</div>

<div style="background-color:#f8f8f8; padding:10px; page-break-inside:avoid;">
  <div style="width:100%; display:grid; grid-template-columns: 1fr 1fr 1fr; grid-gap:25px; margin-bottom:10px;">
    <div>
      <img src="report_images/cam_original_2.jpg" alt="class activation map original 2"/>
      <img src="report_images/cam_heatmap_2.jpg" alt="class activation map 2"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (a) Classified as:<br/>
        Exterior: 0.0%<br/>
        Interior: 100.0%
      </p>
    </div>
    <div>
      <img src="report_images/cam_original_3.jpg" alt="class activation map original 3"/>
      <img src="report_images/cam_heatmap_3.jpg" alt="class activation map 3"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (b) Classified as:<br/>
        Exterior: 0.0%<br/>
        Interior: 100.0%
      </p>
    </div>
    <div>
      <img src="report_images/cam_original_6.jpg" alt="class activation map original 6"/>
      <img src="report_images/cam_heatmap_6.jpg" alt="class activation map 6"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (c) Classified as:<br/>
        Exterior: 0.0%<br/>
        Interior: 100.0%
      </p>
    </div>
  </div>
  <p style="font-size:90%; font-style:italic; text-align:center; margin:0 30px;">
    Figure 14: Interior images from the test set with class activation maps
  </p>
</div>

<div style="background-color:#f8f8f8; padding:10px; page-break-inside:avoid;">
	<div style="width:100%; display:grid; grid-template-columns: 1fr 1fr 1fr; grid-gap:25px; margin-bottom:10px;">
    <div>
      <img src="report_images/occ_int_2.jpg" alt="Occlusion sample 2"/>
      <img src="report_images/occ_heatmap_2.jpg" alt="Occlusion sample 2"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (d) Classified as:<br/>
        Exterior: 10.1%<br/>
        Interior: 89.9%
      </p>
    </div>
    <div>
      <img src="report_images/occ_int_3.jpg" alt="Occlusion sample 3"/>
      <img src="report_images/occ_heatmap_3.jpg" alt="Occlusion sample 3"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (e) Classified as:<br/>
        Exterior: 0.0%<br/>
        Interior: 100.0%
      </p>
    </div>
    <div>
      <img src="report_images/occ_int_6.jpg" alt="Occlusion sample 6"/>
      <img src="report_images/occ_heatmap_6.jpg" alt="Occlusion sample 6"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (f) Classified as:<br/>
        Exterior: 3.8%<br/>
        Interior: 96.2%
      </p>
    </div>
  </div>
  <p style="font-size:90%; font-style:italic; text-align:center; margin:0 30px;">
    Figure 15: Occluded interior images with corresponding heat maps generated from the occluded image
  </p>
</div>

<div style="page-break-after: always;"></div>

### 8.1 Assumption of Classifier Focuses More on Interior

<div style="float:right; width:175px; margin-left:30px; page-break-inside:avoid;">
  <div style="margin-bottom:30px; margin-top:7px;">
    <img src="report_images/noise.jpg" alt="Noise"/>
    <p style="font-size:90%; font-style:italic; text-align:center; margin:0;">
      Figure 16: Random noise classified as:<br/>
      Exterior: 100.0%<br/>
      Interior: 0.0%
    </p>      
  </div>
</div>

As occlusion on the interior images affects the prediction more than the exterior images, it seems that the prediction is barely affected by the output of the exterior class. This assumption is based on these samples and multiple others. It means that the classifier predicts interior if features of interior are detected, in all other cases it predicts exterior. The classifier was tested on noise images to strengthen the assumption. All noise images were predicted as exterior with very high certainty reinforcing the assumption. 

## 9 Incorrect Classifications

Although relatively uncommon, incorrect classifications does occur. Many of which may be difficult to classify due to the nature of the image augmentation. In figure 17, cases of highly certain incorrect classifications are presented.
<div style="background-color:#f8f8f8; padding:10px; page-break-inside:avoid;">
  <div style="width:100%; display:grid; grid-template-columns: 1fr 1fr 1fr 1fr; grid-gap:5px; margin-bottom:10px;">
    <div>
      <img src="report_images/fp_1.jpg" alt="Incorrect classification example 1"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (a) Exterior classified as:<br/>
        Exterior: 0.0%<br/>
        Interior: 100.0%
      </p>
    </div>
    <div>
      <img src="report_images/fp_4.jpg" alt="Incorrect classification example 4"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (b) Exterior classified as:<br/>
        Exterior: 0.0%<br/>
        Interior: 100.0%
      </p>
    </div>
    <div>
      <img src="report_images/fp_2.jpg" alt="Incorrect classification example 2"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (c) Interior classified as:<br/>
        Exterior: 100.0%<br/>
        Interior: 0.0%
      </p>
    </div>
    <div>
      <img src="report_images/fp_3.jpg" alt="Incorrect classification example 3"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (d) Interior classified as:<br/>
        Exterior: 100.0%<br/>
        Interior: 0.0%
      </p>
    </div>
  </div>
  <p style="font-size:90%; font-style:italic; text-align:center; margin:0 30px;">
    Figure 17: Samples of extremely bad predictions
  </p>
</div>

<div style="page-break-after: always;"></div>

## 10 Early stages

Early versions of the classifier was horribly overfitted on blue color and classified many images with blue color as exterior. Confirmation of the assumption was made by taking an interior image, which was also classified as interior, and then coloring the ceiling blue in an editing software. The modified image was then classified as exterior. At this part it was decided that the classifier would be trained on grayscale images instead of colored.
<div style="background-color:#f8f8f8; padding:30px; page-break-inside:avoid;">
  <div style="width:100%; display:grid; grid-template-columns: 1fr 1fr; grid-gap:25px; margin-bottom:10px;">
    <div>
      <img src="report_images/blue_ceiling_original.jpg" alt="Blue ceiling before editing "/>
      <p style="font-size:90%; font-style:italic; text-align:center; margin:0;">
        (a) Sample image of interior before editing
      </p>
    </div>
    <div>
      <img src="report_images/blue_ceiling.jpg" alt="Blue ceiling edited with blue ceiling"/>
      <p style="font-size:90%; font-style:italic; text-align:center; margin:0;">
        (b) Sample image of interior edited with blue ceiling
      </p>
    </div>
  </div>
  <p style="font-size:90%; font-style:italic; text-align:center; margin:0 30px;">
    Figure 18: Images before and after editing of blue ceiling
  </p>
</div>

## 11 Discussion

### 11.1 Low Light Environments

Many interior environments are worse lit than exterior environments. Low light environments forces the photographer to compensate the conditions in order to take an image with good exposure. Camera settings to compensate these conditions often creates noise, artefacts and other side effects. Changes are that the classifier might pick up on specific, or a combination of, side effects due to low light environments and therefore classify those images as interior or exterior based on the side effects.

#### 11.1.1 ISO

Increased ISO-value increases the exposure of an image but also increases noise and artefacts. Whether interior images in the dataset had higher noise compared to exterior environments was not investigated.

#### 11.1.2 Aperture

Low light environments may also force the photographer to increase the size of the aperture. A side effect of a bigger aperture is a shallower depth of field creating blurry areas.

<div style="page-break-after: always;"></div>
### 11.2 Class Activation Maps

The generated heat maps does not entirely reveal the insides of the classifier. Interestingly though, occlusion seem to be effective, although partially. Whether the partial effectiveness of occlusion is due to a solid classifier or other factors needs more research to determine. To interpret the classifiers decision objectively and avoiding human confirmation bias, other techniques should be implemented.

## 12 Uncommented Classifications

Various interesting classifications are presented in this section. The classifications are consciously left uncommented inviting conversations and opinions from readers of this report.

<div style="background-color:#f8f8f8; padding:10px; page-break-inside:avoid;">
  <div style="width:100%; display:grid; grid-template-columns: 1fr 1fr 1fr 1fr; grid-template-rows: 1fr 1fr; grid-gap:5px; margin-bottom:10px;">
    <div>
      <img src="report_images/southpark_ext.jpg" alt="Southpark exterior"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (a) Classified as:<br/>
        Exterior: 99.9%<br/>
        Interior: 0.1%
      </p>
    </div>
    <div>
      <img src="report_images/southpark_int.jpg" alt="Southpark interior"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (b) Classified as:<br/>
        Exterior: 2.0%<br/>
        Interior: 98.0%
      </p>
    </div>
    <div>
      <img src="report_images/xmastree_int.jpg" alt="Christmas tree interior"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (c) Classified as:<br/>
        Exterior: 51.1%<br/>
        Interior: 48.9%
      </p>
    </div>
    <div>
      <img src="report_images/window_int.jpg" alt="Window from inside"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (d) Classified as:<br/>
        Exterior: 99.4%<br/>
        Interior: 0.6%
      </p>
    </div>
    <div>
      <img src="report_images/painting_int.jpg" alt="Painting on wall"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (e) Classified as:<br/>
        Exterior: 0.1%<br/>
        Interior: 99.9%
      </p>
    </div>
    <div>
      <img src="report_images/painting_int_2.jpg" alt="Painting on wall"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (f) Classified as:<br/>
        Exterior: 66.7%<br/>
        Interior: 33.3%
      </p>
    </div>
    <div>
      <img src="report_images/rmit.jpg" alt="Rmit"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (g) Classified as:<br/>
        Exterior: 96.9%<br/>
        Interior: 3.1%
      </p>
    </div>
    <div>
      <img src="report_images/victoria_state_library.jpg" alt="Victoria state library"/>
      <p style="font-size:90%; font-style:italic; margin:0; margin-left:15px; text-align:center;">
        (h) Classified as:<br/>
        Exterior: 0.1%<br/>
        Interior: 99.9%
      </p>
    </div>
  </div>
  <p style="font-size:90%; font-style:italic; text-align:center; margin:0 30px;">
    Figure 19: Samples of classifications
  </p>
</div>

## Acknowledgement

I thank Vic Ciesielski, Prince Hemrajani, Kendall Taylor and fellow students for providing valuable material and comments for various parts of this project. I also thank graphic designer student Jenna Knuuti for automating the process of creating occlusion based on the class activation maps.

<div style="page-break-after: always;"></div>

## References

[1] Arzhaeva, Y., Wang, D., Devnath, L., Amirgholipour, S., McBean, R., Hillhouse, J., Luo, S., Meredith, D., Newbigin, K. and Yates, D. (2019). *Development of Automated Diagnostic Tools for Pneumoconiosis Detection from Chest X-Ray Radiographs*. Available at: https://www.coalservices.com.au/wp-content/uploads/2017/11/Project-No.-20647-Final-Report.pdf [Accessed 18 Oct. 2019].

[2] Clevert, D., Unterthiner, T. and Hochreiter, S. (2016). *FAST AND ACCURATE DEEP NETWORK LEARNING BY EXPONENTIAL LINEAR UNITS (ELUS)*. Johannes Kepler University, Linz, Austria. Available at: https://arxiv.org/pdf/1511.07289.pdf [Accessed 18 Oct. 2019].

[3] Keras.io. (n.d.). *Home - Keras Documentation*. [online] Available at: https://keras.io/ [Accessed 18 Oct. 2019].

[4] Docs.python.org. (n.d.). *The Python Language Reference — Python 3.6.9 documentation*. [online] Available at: https://docs.python.org/3.6/reference/ [Accessed 18 Oct. 2019].

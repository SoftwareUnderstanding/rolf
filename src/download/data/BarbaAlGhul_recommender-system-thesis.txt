![license](https://img.shields.io/github/license/mashape/apistatus.svg)

# Recommender System Thesis
Deep Learning Recommender System

This is my bachelor thesis project. The project's objective is to develop a recommender system using Deep Learning with [unsupervised learning](https://en.wikipedia.org/wiki/Unsupervised_learning), based on a system described by Zhuang et al. (2017). The project will start with a recommender system created by (BATRA, 2018), using [non-negative matrix factorization](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization).

# Dataset
The initial datasets for training will be [MovieLens Latest Datasets](https://grouplens.org/datasets/movielens/latest/), and later I will try to use the [MovieLens 20M Dataset](https://grouplens.org/datasets/movielens/20m/)

# References
The references are in ABNT format (most of them were used only on the written work)

ABDOLLAHI, Behnoush; NASRAOUI, Olfa. A cross-modal warm-up solution for the cold-start problem in collaborative filtering recommender systems. In: ACM WEB SCIENCE 2014 CONFERENCE, 6., 2014, Bloomington, Indiana, Usa. Proceedings... . [s. L.]: Acm, 2014. p. 257 - 258.

ADOMAVICIUS, G.; TUZHILIN, A.. Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions. Ieee Transactions On Knowledge And Data Engineering, [s.l.], v. 17, n. 6, p.734-749, jun. 2005. Institute of Electrical and Electronics Engineers (IEEE). http://dx.doi.org/10.1109/tkde.2005.99.

BARBIERI, Julio et al. Autoencoders and recommender systems: COFILS approach. Expert Systems With Applications, [s.l.], v. 89, p.81-90, dez. 2017. Elsevier BV. http://dx.doi.org/10.1016/j.eswa.2017.07.030.

BATRA, Nipun. Nipun Batra. 2017. Disponível em: <https://nipunbatra.github.io>. Acesso em: 27 mar. 2018.

CHAI, T.; DRAXLER, R. R.. Root mean square error (RMSE) or mean absolute error (MAE)? – Arguments against avoiding RMSE in the literature. Geoscientific Model Development, [s.l.], v. 7, n. 3, p.1247-1250, 30 jun. 2014. Copernicus GmbH. http://dx.doi.org/10.5194/gmd-7-1247-2014.

CHEN, Wei et al. Ranking Measures and Loss Functions in Learning to Rank. 2009. Disponível em: <https://papers.nips.cc/paper/3708-ranking-measures-and-loss-functions-in-learning-to-rank.pdf>. Acesso em: 27 maio 2018.

CHOLLET, François. Deep Learning with Python. [s. L.]: Manning Publications, 2017. 384 p.

DENG, Li. Deep Learning: Methods and Applications. Foundations And Trends® In Signal Processing, [s.l.], v. 7, n. 3-4, p.197-387, 2014. Now Publishers. http://dx.doi.org/10.1561/2000000039.

DOUZI, Samira; AMAR, Meryem; OUAHIDI, Bouabid El. Advanced Phishing Filter Using Autoencoder and Denoising Autoencoder. In: 2017 INTERNATIONAL CONFERENCE ON BIG DATA AND INTERNET OF THINGS, 1., 2017, London, United Kingdom. Proceedings... . New York, Ny, Usa: Acm, 2017. p. 125 - 129.

GOOGLE. Using large-scale brain simulations for machine learning and A.I. 2012. Disponível em: <https://googleblog.blogspot.com/2012/06/using-large-scale-brain-simulations-for.html>. Acesso em: 15 jun. 2018.

HERMANS, Alexander; BEYER, Lucas; LEIBE, Bastian. In Defense of the Triplet Loss for Person Re-Identification. 2017. Disponível em: <https://arxiv.org/pdf/1703.07737v4.pdf>. Acesso em: 08 jun. 2018.

HINTON, Geoffrey E.; OSINDERO, Simon; TEH, Yee-whye. A fast lear ning algorithm for deep belief nets. 2006. Disponível em: <https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf>. Acesso em: 15 jun. 2018.

İRSOY, Ozan; ALPAYDIN, Ethem. Unsupervised feature extraction with autoencoder trees. Neurocomputing, [s.l.], v. 258, p.63-73, out. 2017. Elsevier BV. http://dx.doi.org/10.1016/j.neucom.2017.02.075.

ISHFAQ, Haque; LIU, Ruishan. TVAE: Deep Metric Learning Approach for Variational Autoencoder. 2017. Disponível em: <http://cs231n.stanford.edu/reports/2017/pdfs/108.pdf>. Acesso em: 15 jun. 2018.

ISINKAYE, F.o.; FOLAJIMI, Y.o.; OJOKOH, B.a.. Recommendation systems: Principles, methods and evaluation. Egyptian Informatics Journal, [s.l.], v. 16, n. 3, p.261-273, nov. 2015. Elsevier BV. http://dx.doi.org/10.1016/j.eij.2015.06.005.

KINGMA, Diederik; BA, Jimmy. Adam: A Method for Stochastic Optimization. 2014. Disponível em: <https://arxiv.org/pdf/1412.6980v8.pdf>. Acesso em: 09 jun. 2018.

KULA, Maciej. Recommendations in Keras using triplet loss. 2016. Disponível em: <https://github.com/maciejkula/triplet_recommendations_keras>. Acesso em: 28 jun. 2018.

LAVRAKAS, Paul J. (Ed.). Encyclopedia of Survey Research Methods. [s. L.]: Sage Publications, 2008. 1041 p.

MCCARTHY, Joe. Ranking Metrics. 2017. Disponível em: <https://gist.github.com/gumption/b54278ec9bab2c0e0472816d1d7663be>. Acesso em: 27 maio 2018.

MCDONALD, Conor. Machine learning fundamentals (II): Neural networks. 2017. Disponível em: <https://towardsdatascience.com/machine-learning-fundamentals-ii-neural-networks-f1e7b2cb3eef>. Acesso em: 15 jun. 2018.

MOVIELENS. MovieLens Latest Datasets. 2016. Disponível em: <https://grouplens.org/datasets/movielens/latest/>. Acesso em: 15 jun. 2018.

NETFLIX (Org.). Netflix Prize. 2009. Disponível em: <https://netflixprize.com/>. Acesso em: 15 jun. 2018.

OLLION, Charles; GRISEL, Olivier. Deep Learning course: lecture slides and lab notebooks. 2018. Disponível em: <https://github.com/m2dsupsdlclass/lectures-labs>. Acesso em: 05 maio 2018.

OLLION, Charles; GRISEL, Olivier. Triplet Loss for Implicit Feedback Neural Recommender Systems. 2018. Disponível em: <https://github.com/m2dsupsdlclass/lectures-labs/blob/master/labs/03_neural_recsys/Implicit_Feedback_Recsys_with_the_triplet_loss_rendered.ipynb>. Acesso em: 28 maio 2018.

PORTUGAL, Ivens; ALENCAR, Paulo; COWAN, Donald. The use of machine learning algorithms in recommender systems: A systematic review. Expert Systems With Applications, [s.l.], v. 97, p.205-227, maio 2018. Elsevier BV. http://dx.doi.org/10.1016/j.eswa.2017.12.020.

RICCI, Francesco. Recommender Systems Handbook. [s. L.]: Springer Us, 2011. 842 p.

SCHMIDHUBER, Jürgen. Deep learning in neural networks: An overview. Neural Networks, [s.l.], v. 61, p.85-117, jan. 2015. Elsevier BV. http://dx.doi.org/10.1016/j.neunet.2014.09.003.

SCHROFF, Florian; KALENICHENKO, Dmitry; PHILBIN, James. FaceNet: A unified embedding for face recognition and clustering. In: 2015 IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), 28., 2015, Boston, Ma, Usa. 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2015). [s. L.]: Ieee, 2015. p. 815 - 823.

SUGOMORI, Yusuke et al. Deep Learning: Practical Neural Networks with Java. [s. L.]: Packt Publishing, 2017. 721 p.

SYMEONIDIS, Panagiotis. Matrix and Tensor Decomposition in Recommender Systems. In: 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, 10., 2016, Boston, Ma, Usa. Proceedings... . [s. L.]: Acm, 2016. p. 429 - 430.

THE INTERNET SOCIETY (Org.). Common Format and MIME Type for Comma-Separated Values (CSV) Files. 2005. Disponível em: <https://tools.ietf.org/html/rfc4180>. Acesso em: 09 jun. 2018.

WEIMER, Markus; KARATZOGLOU, Alexandros; BRUCH, Marcel. Maximum margin matrix factorization for code recommendation. Proceedings Of The Third Acm Conference On Recommender Systems - Recsys '09, [s.l.], p.309-312, 2009. ACM Press. http://dx.doi.org/10.1145/1639714.1639775.

ZHUANG, Fuzhen et al. Representation learning via Dual-Autoencoder for recommendation. Neural Networks, [s.l.], v. 90, p.83-89, jun. 2017. Elsevier BV. http://dx.doi.org/10.1016/j.neunet.2017.03.009.


{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgi import print_environ\n",
    "from time import time\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from Preprocessor import Preprocessor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from ResultStorage import ResultStorage\n",
    "from tqdm import tqdm\n",
    "import fasttext\n",
    "\n",
    "from Vectorizing.CountVectorizer import getCountVectorizer\n",
    "from Vectorizing.TF_IDF_Vectorizer import getWordLevelVectorizer, getNGramLevelVectorizer\n",
    "from Embedding.WordEmbedding import createWordEmbedding\n",
    "from Report import Report\n",
    "from Report.CrossValidateNN import cross_validate_NN\n",
    "from lstmModel import create_lstm_model, create_bidirec_lstm_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_fscore_support, make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "TEXT = \"Text\"\n",
    "LABEL = \"Label\"\n",
    "CV_splits = 5\n",
    "sample = True\n",
    "nb_sample = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe(df, cat):\n",
    "\tcount = 0\n",
    "\tfor ind, row in df.iterrows():\n",
    "\t\tif cat != str(row[LABEL]):\n",
    "\t\t\tcount += 1\n",
    "\t\t\trow[LABEL] = 'Other'\n",
    "\tprint(f'{cat} filtered {count} rows in training dataset')\n",
    "\n",
    "def get_sampling_strategy(df_train, cat):\n",
    "\tsizes = df_train.groupby(LABEL).size()\n",
    "\tindexes = list(sizes.index)\n",
    "\tcat_size = sizes[indexes.index(cat)]\n",
    "\tother_cat_size = int(cat_size/(len(df_train[LABEL].unique())-2))+1\n",
    "\tsampling_stratgy = {}\n",
    "\tfor c in df_train[LABEL].unique():\n",
    "\t\tif c == cat:\n",
    "\t\t\tsampling_stratgy[c] = cat_size\n",
    "\t\telif c == 'General':\n",
    "\t\t\tsampling_stratgy[c] = 0\n",
    "\t\telse:\n",
    "\t\t\tsampling_stratgy[c] = min(other_cat_size, sizes[indexes.index(c)])\n",
    "\tprint('Sampling strategy: ', sampling_stratgy)\n",
    "\treturn sampling_stratgy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gantts pytorch implementation gantts high fidelity speech synthesis adversarial imagesganttsjpg prepare dataset download dataset training wav file sample rate 24000hz edit configuration utilsaudiopy hoplength must remain unchanged process data python processpy wavdirwavs outputdata train tensorboard python trainpy inputdatatrain tensorboard logdir logdir inference python generatepy inputdatatest result find result sample directory attention use loss function mentioned paper modified loss function learn use linguistic feature use mel spectrogram model considered vocoder note official implementation detail necessarily correct order accelerate convergence modified network structure loss function reference parallel gantts high fidelity speech synthesis\n",
      "gantts pytorch gantts high fidelity speech synthesis adversarial imagesganttsjpg prepare dataset download dataset wav sample rate 24000hz edit configuration utilsaudiopy hoplength must remain unchanged process data processpy wavdirwavs outputdata train tensorboard trainpy inputdatatrain tensorboard logdir logdir inference generatepy inputdatatest find sample directory attention loss function mentioned modified loss function learn linguistic feature mel spectrogram considered vocoder note official detail necessarily correct order accelerate convergence modified structure loss function parallel gantts high fidelity speech synthesis\n"
     ]
    }
   ],
   "source": [
    "df_readme = pd.read_csv('../data/readme_semantic_web.csv', sep=';')\n",
    "print(df_readme[TEXT][0])\n",
    "Preprocessor(df_readme).run()\n",
    "print(df_readme[TEXT][0])\n",
    "df_readme.drop(df_readme['Text'] == '\\0', inplace=True)\n",
    "df_readme.to_csv('../data/readme_semantic_web_preprocessed.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Repo  Text\n",
      "Label                                  \n",
      "Audio                         123   123\n",
      "Computer Vision              3647  3647\n",
      "General                      2809  2809\n",
      "Graphs                        154   154\n",
      "Natural Language Processing   871   871\n",
      "Reinforcement Learning        452   452\n",
      "Sequential                    221   221\n",
      "['Audio' 'Computer Vision' 'General' 'Graphs'\n",
      " 'Natural Language Processing' 'Reinforcement Learning' 'Sequential']\n",
      "[ 123 3647 2809  154  871  452  221]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('../data/readme.csv', sep=';')\n",
    "distribution = df.groupby('Label').count()\n",
    "print(df.groupby('Label').count())\n",
    "\n",
    "labels = df['Label'].unique()\n",
    "labels.sort()\n",
    "print(labels)\n",
    "vals = distribution['Repo'].values\n",
    "print(vals)\n",
    "\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.bar(labels, vals, color='#00c7c3')\n",
    "plt.title(f'Distribution of samples between classes', size=18, weight='bold')\n",
    "plt.xlabel('Words', size=16, weight='bold')\n",
    "plt.ylabel('Frequency', size=16, weight='bold')\n",
    "plt.xticks(rotation=40, size=16)\n",
    "plt.yticks(size=14)\n",
    "plt.legend(prop={'size': 14})\n",
    "plt.savefig('../results/pics/class_distribution.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_readme.to_csv('../data/readme_preprocessed.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categories = [\"Sequential\", \"Natural Language Processing\", \"Audio\", \"Computer Vision\", \"Graphs\", \"Reinforcement Learning\", 'Semantic Web']\n",
    "categories = ['Audio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [('readme_train.csv', 'readme_test.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train: (7703, 3)\n",
      "df_test: (856, 3)\n",
      "df_train: (3435, 3)\n",
      "df_test: (741, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/'+datasets[0][0], sep=';')\n",
    "df_test = pd.read_csv('../data/'+datasets[0][1], sep = ';')\n",
    "\n",
    "print(f'df_train: {df_train.shape}')\n",
    "print(f'df_test: {df_test.shape}')\n",
    "df_train.drop_duplicates(subset=['Text'], inplace=True, keep=False)\n",
    "df_test.drop_duplicates(subset=['Text'], inplace=True, keep=False)\n",
    "print(f'df_train: {df_train.shape}')\n",
    "print(f'df_test: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessor(df_train).run()\n",
    "#Preprocessor(df_test).run()\n",
    "df_train.drop( df_train[ df_train[TEXT] == \"\" ].index , inplace=True)\n",
    "df_test.drop( df_test[ df_test[TEXT] == \"\" ].index , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns = 'Repo')\n",
    "x_train = df_train[TEXT]\n",
    "y_train = df_train[LABEL]\n",
    "x_test = df_test[TEXT]\n",
    "y_test = df_test[LABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling strategy:  {'Computer Vision': 9, 'Natural Language Processing': 9, 'General': 0, 'Reinforcement Learning': 9, 'Audio': 44, 'Graphs': 9, 'Sequential': 9}\n"
     ]
    }
   ],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy=get_sampling_strategy(df_train, 'Audio'))\n",
    "x_train, y_train = undersample.fit_resample(x_train.to_frame(TEXT), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio filtered 45 rows in training dataset\n",
      "Audio filtered 729 rows in training dataset\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.to_frame(LABEL)\n",
    "filter_dataframe(y_train, 'Audio')\n",
    "y_test = y_test.to_frame(LABEL)\n",
    "filter_dataframe(y_test, 'Audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=1000)\n",
    "tfidf_vect.fit(x_train[TEXT])\n",
    "xtrain_tfidf = tfidf_vect.transform(x_train[TEXT])\n",
    "xtest_tfidf = tfidf_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "['0', '1', '10', '100', '1000', '11', '110m', '12', '128', '12heads', '12layer', '13', '14', '15', '16', '18', '19', '1blyrics', '2', '20', '2007', '2014', '2017', '20170118', '2018', '2019', '2020', '2021', '22050', '24', '24layer', '25', '256', '3', '30', '32', '36', '37', '3d', '4', '40', '5', '50', '512', '51m', '5b', '5blyrics', '6', '64', '7', '768hidden', '8', '9', '900k1190k', 'able', 'access', 'according', 'accuracy', 'achieve', 'achieves', 'action', 'activate', 'activation', 'active', 'adapted', 'add', 'added', 'adding', 'additional', 'ae', 'aev2a', 'agent', 'al', 'algorithm', 'algoritmo', 'align', 'aligncenter', 'alignment', 'allows', 'almost', 'along', 'already', 'also', 'although', 'always', 'amount', 'anaconda', 'analysis', 'annotation', 'another', 'answer', 'answering', 'apache', 'apex', 'api', 'app', 'application', 'apply', 'approach', 'aprendizado', 'architecture', 'argument', 'around', 'array', 'article', 'artificial', 'arxiv', 'attention', 'audio', 'author', 'autoencoders', 'automatic', 'automatically', 'autoregressive', 'available', 'average', 'b', 'back', 'banana', 'bart', 'base', 'based', 'baseline', 'bash', 'basic', 'batch', 'batchsize', 'benchmark', 'bert', 'bertbase', 'bertlarge', 'best', 'better', 'bibtex', 'bidirectional', 'biencoder', 'bilm', 'bin', 'bit', 'blind', 'block', 'book', 'boolean', 'bottom', 'br', 'branch', 'build', 'c', 'caffe', 'called', 'card', 'case', 'cased', 'causal', 'cause', 'cd', 'challenge', 'change', 'changed', 'channel', 'character', 'check', 'checkpoint', 'chen', 'chinese', 'choice', 'choose', 'chunk', 'citation', 'cite', 'class', 'classification', 'classificação', 'clean', 'click', 'clip', 'clone', 'cloud', 'cluster', 'coco', 'code', 'colab', 'collaborative', 'com', 'command', 'common', 'compare', 'comparison', 'compatible', 'competition', 'component', 'computational', 'compute', 'computed', 'conda', 'conditioning', 'conference', 'config', 'configuration', 'consists', 'console', 'contain', 'container', 'containing', 'contains', 'content', 'context', 'continue', 'control', 'controllability', 'controllable', 'conversion', 'convert', 'convolution', 'convolutional', 'convtasnet', 'copy', 'cora', 'core', 'corpus', 'correctly', 'corresponding', 'could', 'cpu', 'create', 'created', 'creating', 'creation', 'crfrnn', 'crime', 'crimename', 'cuda', 'current', 'currently', 'curve', 'custom', 'da', 'dado', 'darknet', 'data', 'dataset', 'datasets', 'ddsp', 'de', 'decoder', 'decrease', 'deep', 'default', 'define', 'defined', 'demo', 'demucs', 'denoising', 'dependency', 'deploy', 'described', 'detail', 'detailed', 'detection', 'development', 'devtest', 'dictionary', 'different', 'differentiable', 'diffusion', 'dilation', 'dimension', 'directly', 'directory', 'discriminator', 'distributed', 'distribution', 'docker', 'doi', 'domain', 'done', 'dont', 'double', 'download', 'downloaded', 'drive', 'due', 'duration', 'e', 'easily', 'easy', 'edge', 'edit', 'effective', 'efficient', 'eg', 'either', 'element', 'elmo', 'em', 'embedding', 'embeddings', 'encoder', 'encoding', 'end', 'endtoend', 'english', 'enough', 'entire', 'entropy', 'entry', 'environment', 'episode', 'epoch', 'equal', 'error', 'especially', 'esse', 'estimation', 'et', 'etc', 'evaluate', 'evaluating', 'evaluation', 'even', 'event', 'every', 'example', 'execute', 'existing', 'expected', 'experience', 'experiment', 'extra', 'extract', 'extracted', 'f0', 'facebookbartlarge', 'factor', 'fairseq', 'false', 'far', 'fashion', 'fast', 'faster', 'fastspeech', 'feature', 'feel', 'female', 'field', 'figure', 'file', 'fill', 'filter', 'final', 'finally', 'find', 'finetune', 'finetuned', 'finetuning', 'first', 'fix', 'fixed', 'flag', 'float', 'folder', 'follow', 'following', 'follows', 'format', 'forward', 'found', 'four', 'frame', 'framework', 'free', 'frequency', 'full', 'function', 'furniture', 'future', 'game', 'gan', 'gat', 'gb', 'gcn', 'general', 'generate', 'generated', 'generating', 'generation', 'generative', 'generator', 'get', 'getting', 'gin', 'git', 'github', 'give', 'given', 'gln', 'go', 'goal', 'good', 'google', 'gpu', 'gpus', 'gradient', 'graph', 'grid', 'h', 'hand', 'harp', 'hdf5', 'head', 'help', 'hereafter', 'hidden', 'high', 'higher', 'highly', 'highquality', 'hour', 'however', 'hp', 'hparamspy', 'human', 'hybrid', 'hyperparameters', 'icassp', 'id', 'idea', 'ideal', 'ie', 'ieee', 'image', 'img', 'implement', 'implementation', 'implemented', 'important', 'improve', 'improvement', 'include', 'included', 'includes', 'including', 'increase', 'inference', 'information', 'initial', 'input', 'inside', 'installation', 'installed', 'installing', 'instance', 'instead', 'instruction', 'instrument', 'int', 'interest', 'interesting', 'interface', 'international', 'introduction', 'issue', 'iteration', 'ive', 'john', 'joint', 'json', 'jupyter', 'k', 'keep', 'kernel', 'key', 'khz', 'know', 'knowledge', 'label', 'language', 'large', 'larger', 'last', 'later', 'latest', 'layer', 'le', 'lead', 'learn', 'learnable', 'learned', 'learning', 'least', 'left', 'length', 'let', 'level', 'library', 'license', 'licenselicense', 'like', 'likely', 'line', 'linear', 'link', 'linux', 'list', 'listen', 'lj', 'ljspeech', 'load', 'located', 'log', 'logging', 'long', 'longer', 'look', 'loss', 'lot', 'loudness', 'lower', 'lr', 'lstm', 'lyric', 'mac', 'machine', 'made', 'main', 'mainpy', 'make', 'making', 'many', 'mario', 'mask', 'masked', 'masking', 'match', 'matlab', 'matrix', 'max', 'maximum', 'may', 'mcts', 'mdx', 'mean', 'mel', 'melspectrogram', 'melspectrograms', 'memory', 'method', 'metric', 'mfa', 'might', 'mind', 'minival', 'minute', 'mit', 'mixed', 'mixture', 'mo', 'mode', 'model', 'modeling', 'modelname', 'modelos', 'modification', 'modify', 'module', 'move', 'mp3', 'much', 'multigpu', 'multilingual', 'multiple', 'multispeaker', 'musdb', 'music', 'must', 'n', 'name', 'named', 'natural', 'nctx', 'necessary', 'need', 'needed', 'neighborhood', 'network', 'neural', 'neurips', 'new', 'next', 'nlp', 'node', 'noise', 'noisy', 'none', 'normalization', 'note', 'notebook', 'nsamples', 'number', 'numpy', 'nvidia', 'o', 'object', 'obtain', 'obtained', 'official', 'onde', 'one', 'open', 'operation', 'optimizer', 'option', 'optional', 'order', 'original', 'otherwise', 'outofmemory', 'output', 'overview', 'p', 'package', 'padding', 'panopticpolarnet', 'paper', 'para', 'parallel', 'parameter', 'part', 'particular', 'pas', 'passage', 'path', 'per', 'perform', 'performance', 'performs', 'phoneme', 'pick', 'pickle', 'pimc', 'pip', 'pitch', 'place', 'plain', 'play', 'played', 'player', 'playing', 'please', 'plot', 'point', 'policy', 'polyencoder', 'positional', 'possible', 'pp', 'ppi', 'ppo', 'precision', 'predict', 'prediction', 'preparation', 'prepare', 'preprocess', 'preprocessed', 'preprocessing', 'preprocesspy', 'prerequisite', 'present', 'presented', 'pretrained', 'pretraining', 'previous', 'prior', 'probability', 'probably', 'problem', 'process', 'processing', 'processor', 'processorgroup', 'produce', 'product', 'project', 'prompt', 'properly', 'proposal', 'propose', 'provide', 'provided', 'provides', 'public', 'published', 'purpose', 'put', 'python3', 'pytorch', 'q', 'qa', 'quality', 'que', 'question', 'r', 'ram', 'random', 'randomly', 'range', 'rate', 'ratio', 'raw', 'rcnn', 'read', 'realtime', 'recent', 'receptive', 'recognition', 'recommend', 'recommended', 'reconstruction', 'reduce', 'refer', 'reference', 'region', 'reinforcement', 'release', 'released', 'replace', 'repo', 'report', 'reported', 'repository', 'representation', 'reproduce', 'require', 'required', 'requirement', 'requirementstxt', 'requires', 'research', 'residual', 'resource', 'respectively', 'rest', 'result', 'resume', 'retrieval', 'return', 'reuse', 'reward', 'right', 'rl', 'robust', 'root', 'roughly', 'rule', 'run', 'running', 'runsh', 'runtime', 'sample', 'sampling', 'save', 'saved', 'schafkopf', 'schedule', 'scheme', 'score', 'scratch', 'script', 'sdr', 'search', 'second', 'section', 'see', 'segment', 'segmentation', 'select', 'selected', 'semantic', 'sentence', 'separate', 'separated', 'separately', 'separation', 'sequence', 'server', 'set', 'setting', 'setup', 'several', 'shape', 'shift', 'short', 'show', 'shown', 'signal', 'similar', 'simple', 'simply', 'since', 'singing', 'single', 'singlespeaker', 'site', 'size', 'skipgram', 'small', 'smaller', 'software', 'solo', 'something', 'song', 'sound', 'source', 'space', 'sparse', 'speaker', 'special', 'specific', 'specifically', 'specified', 'specifies', 'specify', 'spectrogram', 'speech', 'speed', 'split', 'squad', 'src', 'stable', 'stage', 'standard', 'start', 'started', 'starting', 'state', 'stateoftheart', 'step', 'still', 'storage', 'store', 'stored', 'string', 'structure', 'study', 'style', 'submanifold', 'subtask', 'summary', 'support', 'supported', 'sure', 'surpassing', 'synthesis', 'synthesize', 'synthesized', 'system', 'são', 'table', 'tacotron', 'tacotron2', 'take', 'talk', 'target', 'task', 'tasnet', 'tcn', 'temos', 'template', 'temporal', 'tensor', 'tensorboard', 'tensorflow', 'terminal', 'test', 'tested', 'testing', 'testsplitname', 'teststd', 'text', 'texttospeech', 'thanks', 'thats', 'thing', 'three', 'thus', 'timbre', 'time', 'timefrequency', 'todo', 'together', 'token', 'tokenization', 'tokenized', 'tool', 'top', 'toplevel', 'total', 'towards', 'tpu', 'tr', 'track', 'train', 'trained', 'trainpy', 'trainval35k', 'transfer', 'transformer', 'tree', 'trick', 'true', 'try', 'tt', 'turn', 'two', 'type', 'u', 'ubuntu', 'um', 'uma', 'uncased', 'understand', 'understanding', 'unet', 'unzip', 'update', 'upsample', 'us', 'usage', 'useful', 'user', 'usually', 'utterance', 'v', 'v100', 'vae', 'validation', 'value', 'variable', 'variant', 'various', 'vctk', 'vector', 'version', 'via', 'video', 'view', 'visit', 'visualization', 'visualize', 'voc', 'vocab', 'vocabulary', 'vocal', 'vocoder', 'voice', 'voicefilter', 'vqvae', 'w', 'wang', 'want', 'wav', 'waveform', 'wavegan', 'waveglow', 'wavegrad', 'wavenet', 'wavs', 'way', 'web', 'website', 'weight', 'well', 'whether', 'whole', 'width400', 'window', 'wish', 'without', 'word', 'wordpiece', 'work', 'working', 'workshop', 'would', 'wrapper', 'write', 'written', 'wsj0', 'x', 'yield', 'youll', 'é', '中国', '小', '市场', '的', '龙虾', '기사를', '해당']\n"
     ]
    }
   ],
   "source": [
    "features = tfidf_vect.get_feature_names()\n",
    "print(len(features))\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "   Label\n",
      "0  Audio\n",
      "{'Audio': 0, 'Other': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jenifer/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/jenifer/.local/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "trainy_count = encoder.fit_transform(y_train)\n",
    "testy_count = encoder.transform(y_test)\n",
    "print(trainy_count[0])\n",
    "print(y_train.head(1))\n",
    "\n",
    "trainy_tfidf = encoder.fit_transform(y_train)\n",
    "testy_tfidf = encoder.transform(y_test)\n",
    "\n",
    "print(dict(zip(encoder.classes_, encoder.transform(encoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, model_audio = Report.report(LogisticRegression(max_iter=10000), 'readme_train', 'readme_test', xtrain_tfidf, trainy_tfidf, xtest_tfidf, testy_tfidf, 'Audio', name='LR_TFIDF_RandomUnder', cv=CV_splits, dict_scoring=Report.score_metrics, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[[0.58698519 0.41301481]]\n"
     ]
    }
   ],
   "source": [
    "#text = 'dcgan implement dcgan scratch mnist dataset read dcgan refer origin implement script jyupter notebook faster effici result implement person comput high end gpu servic includ script cpu work edit get start packag tensorflow version 20 kera tensorflow backend import layer numpi mathemat comput pil imag manipul matplotlib plot imag tfutil util kera tensorflow break line 46 gener block origin dcgan input diment vector 128 simplif line 51 gener block 1 channel inform line 66 tensor reshap remov channel blackwhit imag pyplot line 90 batch size divid half one half exampl true half go gener line 109 110 respect gener train get output 1 imag find accuraci batch gener well accuraci discrimin reduc built author nikita kodkani student refer unsupervis represent learn deep convolut gener adversari network'\n",
    "text = ' audio cat speech cat cat cat image image yolo yolo'\n",
    "print(model_audio.predict(tfidf_vect.transform([text])))\n",
    "print(model_audio.predict_proba(tfidf_vect.transform([text])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_audio.predict(xtest_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9284750337381916\n",
      "Precision: 0.985182208982861 \n",
      "Recall: 0.9284750337381916 \n",
      "F1-score: 0.9514972275694978\n"
     ]
    }
   ],
   "source": [
    "y_unique = [0, 1]\n",
    "cm = confusion_matrix(testy_tfidf, y_pred, labels=y_unique)\n",
    "cm_df = pd.DataFrame(cm, index = [y_unique], columns = [y_unique])\n",
    "print(f\"Accuracy: {accuracy_score(testy_tfidf, y_pred)}\")\n",
    "m = precision_recall_fscore_support(testy_tfidf, y_pred, average='weighted')\n",
    "precision = m[0]\n",
    "recall = m[1]\n",
    "f1score = m[2]\n",
    "print(f\"Precision: {m[0]} \\nRecall: {m[1]} \\nF1-score: {m[2]}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d5a85906b5019a95b914e054e1849c800da3b42d1a581ee9f65c61f2a58cefa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "citation": [
    {
      "confidence": [
        0.8520815120463098
      ],
      "excerpt": "Research Institutions \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9195926162616405
      ],
      "excerpt": "Machine Learning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8202342109601906
      ],
      "excerpt": "eccenca Corporate Memory - build, explore and consume Knowledge Graphs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9330586062571771,
        0.8820087806311313,
        0.9754687259365097
      ],
      "excerpt": "Semantic Web Journal \nJournal of Web Semantics \nInternational Journal of Web and Semantic Technology \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8654671031158477
      ],
      "excerpt": "Lehigh University Benchmark (LUBM) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9414616401702977
      ],
      "excerpt": "visu - Visual SPARQL query tool. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9988461346356616,
        0.9988461346356616
      ],
      "excerpt": "International Semantic Web Conference (ISWC 2019) \nEuropean Semantic Web Conference (ESWC 2019) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.895082974841411
      ],
      "excerpt": "Metaphacts - ($) End-to-end platform to create and utilize enterprise knowledge graphs. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8202342109601906
      ],
      "excerpt": "eccenca Corporate Memory - build, explore and consume Knowledge Graphs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9274384332336776
      ],
      "excerpt": "LOV - Linked Open Vocabularies. Portal / search tool for vocabularies. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8435930078762399
      ],
      "excerpt": "org - The Organization Ontology. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8356013927728488
      ],
      "excerpt": "cyber-ontology - Cyber Intelligence Ontology. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9283183835609227
      ],
      "excerpt": "RDFSharp.Semantics - .NET library for OWL-DL/SKOS ontology modeling, validation and reasoning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8422862053358879
      ],
      "excerpt": "ocaml-rdf - Manipulate RDF graphs and execute Sparql queries. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8944178096468923
      ],
      "excerpt": "Visual SPARQL Builder \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8820807460429729
      ],
      "excerpt": "VOWL - Visual Notation for OWL Ontologies. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9963953642271064
      ],
      "excerpt": "rocker - key A Refinement Operator Approach for Key Discovery. http://aksw.org/projects/Rocker \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8482272440258808
      ],
      "excerpt": "vsb - Visual SPARQL Builder - Model SPARQL-Select-Queries in a browser https://leipert.github.io/vsb/ \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8520815120463098,
        0.8356013927728488
      ],
      "excerpt": "dione - Khoaos Research Group \nTrOWL - Tractable OWL 2 Reasoning Infrastructure \n",
      "technique": "Supervised classification"
    }
  ],
  "codeRepository": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/semantalytics/awesome-semantic-web",
    "technique": "GitHub API"
  },
  "dateCreated": {
    "confidence": [
      1.0
    ],
    "excerpt": "2016-10-18T16:00:59Z",
    "technique": "GitHub API"
  },
  "dateModified": {
    "confidence": [
      1.0
    ],
    "excerpt": "2021-11-15T09:57:38Z",
    "technique": "GitHub API"
  },
  "description": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [The Smart Data Analytics (SDA)](http://sda.tech/) - Research group, Institute for Computer Science at the University of Bonn, the Fraunhofer Institute for Intelligent Analysis and Information Systems (IAIS) and the Institute for Applied Computer Science Leipzig.\n- [Agile Knowledge Engineering and Semantic Web (AKSW)](http://aksw.org) - The Research Group Agile Knowledge Engineering and Semantic Web (AKSW) is hosted by the Chair of Business Information Systems (BIS) of the Institute of Computer Science (IfI) / University of Leipzig as well as the Institute for Applied Informatics (InfAI).\n- [University of Zurich Dynamic and Distributed Information Systems Group](http://www.ifi.uzh.ch/en/ddis.html)\n- [WESO](http://www.weso.es/) - WESO is a research group at the University of Oviedo founded in 2004.\n- [Max Planck Institute for Informatics](https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/) - Department D5 of the Max Planck Institute for Informatics.\n- [DICE: Data Science Group](http://dice.cs.uni-paderborn.de/about/) - Universit\u00e4t Paderborn.\n- [Ontology Engineering Group (OEG)](http://www.oeg-upm.net/) - The Ontology Engineering Group (OEG) is based at the Computer Science School at Universidad Polit\u00e9cnica de Madrid (UPM).\n- [Knowledge Representation and Reasoning Group (KRR)](https://krr.cs.vu.nl/) - Research group is based at the Vrije Universiteit Amsterdam (VU).\n- [eXascale Infolab](https://exascale.info/) - eXascale Infolab, University of Fribourg, Switzerland.\n- [Wimmics](http://wimmics.inria.fr/corese) - Wimmics stands for Web-Instrumented Man-Machine Interactions, Communities, and Semantics, a joint research team between INRIA Sophia Antipolis - M\u00e9diterran\u00e9e and I3S (CNRS and Universit\u00e9 C\u00f4te d'Azur).\n- [Data Semantics Lab](https://dase.cs.wright.edu/) - Data Semantics Lab, Wright State University\n- [Stanford BMIR](https://bmir.stanford.edu) - Stanford University Center for Biomedical Informatics Research\n- [Exascale Infolab](https://exascale.info/projects/research/) - University of Fribourg, Switzerland\n- [IDLAB](https://www.ugent.be/ea/idlab/en/research/semantic-intelligence/semantic-knowledge-generation-and-publication-at-scale.htm) - Ghent University, Belgium\n- [Data Semantics Lab](https://daselab.cs.ksu.edu/) - Kansas State University, USA\n\n",
      "technique": "Header extraction"
    },
    {
      "confidence": [
        0.921165307243141,
        0.9306861044260017
      ],
      "excerpt": "A curated list of various semantic web and linked data resources. \nTo add something to the list please either submit a pull request or add a comment with a link to issues/awesomelets. Pull requests will be evaluated immediately for inclusion while posts while awesomelets will be evaluated at some indeterminate time in the future. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8869338046081205
      ],
      "excerpt": "Linked Data Fragments \nLinked Data Platform \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8379800584984572
      ],
      "excerpt": "Knowledge Graph Management \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "Linked Data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.923948005372906
      ],
      "excerpt": "SKOS Tools \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.978852817986473
      ],
      "excerpt": "RDF 1.1: On Semantics of RDF Datasets \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8376856279601179,
        0.8621839127131752
      ],
      "excerpt": "OWL 2 Web Ontology Language Document Overview \nOWL 2 Web Ontology Language Primer \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.803585792376817
      ],
      "excerpt": "SHACL Shapes Constraint Language \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9901074941323801,
        0.9095008199984523,
        0.8989384341728851,
        0.9308749589276025
      ],
      "excerpt": "Model for Tabular Data and Metadata on the Web \nMetadata Vocabulary for Tabular Data \nGenerating JSON from Tabular Data on the Web \nGenerating RDF from Tabular Data on the Web \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9513493846414374
      ],
      "excerpt": "Web Annotation Data Model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259,
        0.8869338046081205,
        0.8816699900658941,
        0.8869338046081205
      ],
      "excerpt": "Linked Data Notifications \nLinked Data Platform 1.0 Primer \nLinked Data Platform Best Practices and Guidelines \nLinked Data Platform 1.0 \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8979411005071259
      ],
      "excerpt": "Linked Data Fragments \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9008520622457938
      ],
      "excerpt": "| HDT | Binary RDF Representation for Publication and Exchange. | application/x-binary-rdf | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9827222487608361
      ],
      "excerpt": "| YARRML | YARRRML is a human readable text-based representation for declarative generation rules. It is a subset of [YAML], a widely used data serialization language designed to be  | | human-friendly. | | \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9990659366666624,
        0.8887465698247522,
        0.9508468766405168
      ],
      "excerpt": "RDF Datatyping - This document summarizes the common understanding of the RDF Core Working Group (further referred to as WG) with regards to the theoretical foundation for datatyping of literal values and serves as a basis of definition, discussion, and comparison of all proposed schemes for achieving a complete datatyping solution which are to be considered by the WG. \nCompanies or businesses selling products with a primary focus on semantic web technology \nStardog Union - Knowledge Graph Platform for the Enterprise. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8719814116710993
      ],
      "excerpt": "Semantic Arts - Enterprise information systems based on flexible data structures and deep semantics. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9737891997691791
      ],
      "excerpt": "Swirrl - Linked-data publishing for Government organisations \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8510768870960539,
        0.8187640100034149
      ],
      "excerpt": "SURROUND Australia - Semantic Web consulting and enterprise semantics platform provision \nCompanies or businesses using semantic web technologies \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8151958263943421
      ],
      "excerpt": "DarkLight - DarkLight is an Artificial Intelligence Expert System for Active Cyber Defense and           Trusted Information Sharing. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9262370385751695
      ],
      "excerpt": "Elsevier - Global information analytics business that helps institutions and professionals advance healthcare, open science and improve performance for the benefit of humanity \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9677236991948869,
        0.9839649413574195,
        0.9690636227457511
      ],
      "excerpt": "Perfect Memory - DAM-as-a-Brain, a Platform that collects, interprets and makes any data and content actionable. \nAustralian Government Linked Data Workign Group - Australian government's community of practice for Linked Data & Semantic Web  \nW3C's Gov enrment Linked Data Working Group archived wiki - \"Developing standards which help governments publish their data as effective and usable Linked Data, using Semantic Web technologies\" \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8253672773134583
      ],
      "excerpt": "International Journal of Web and Semantic Technology \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9479446717978608
      ],
      "excerpt": "BrightstarDB - (OS) A native RDF database for the .NET platform written in C#. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8910938480146054
      ],
      "excerpt": "Node-Quadstore - (OS) A LevelDB-backed graph database for Node.js supporting quads, SPARQL queries and the RDF/JS interface. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9103660334035396
      ],
      "excerpt": "levelgraph - (OS) Graph database JS style for Node.js and the Browser. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8454430723499161
      ],
      "excerpt": "QuitStore - Quads in Git - Git versioned RDF Triple Store with support for branching and mergin and more. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8748875876067262,
        0.9673686529834025
      ],
      "excerpt": "Dydra - ($) A cloud-based graph database. \nredstore - (OS) RedStore is a lightweight RDF triplestore written in C using the Redland library. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9275066327218905,
        0.934413735953467
      ],
      "excerpt": "neptune - ($) Amazon Neptune is a fast, reliable, fully managed graph database service that makes it easy to build and run applications that work with highly connected datasets. \nfabric - (OS) Fabric is a simple triplestore written in Golang. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8145191933020692,
        0.8956754077933761
      ],
      "excerpt": "Fluree - (OS) Blockchain based triplestore. \nOxigraph - (OS) a graph database implementing the SPARQL standard and written in Rust. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9806450363714233,
        0.9805895234544496
      ],
      "excerpt": "Atomic-Server - (OS) Graph database + HTTP(S) server with authorization and versioning. Supports a strict subset of RDF. \n(Note: this classification is somewhat arbitrary and is meant to capture databases that only have a published paper or were developed for that purpose and are not actively maintained) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.988631603981079
      ],
      "excerpt": "RIQ - RIQ is a new software tool for fast processing of SPARQL queries on RDF quadruples. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9891785691729262
      ],
      "excerpt": "Katts - Katts is A Triple Torrent Sieve. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9611534774996503
      ],
      "excerpt": "sepa - A JAVA implementation of the SPARQL Event Processing Architecture including the engine, APIs and tools. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8886622591707615
      ],
      "excerpt": "luposdate - A Semantic Web Database Management System developed by IFIS at the University of L\u00fcbeck. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9415819618060711
      ],
      "excerpt": "dice-group/triplestore-benchmarks - An Evaluation of Triplestore Benchamrks. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.803634348188669
      ],
      "excerpt": "Hobbit - Holistic Benchmarking of Big Linked Data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8838056294342982
      ],
      "excerpt": "IGUANA - IGUANA is a benchmark execution framework for triple stores. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9643993451513082,
        0.8602986763697322
      ],
      "excerpt": "GTFS-Madrid-Bench - A benchmark for performance and scalability of knowledge graph construction from heterogeneous data sources \nSPARQL2Git - Easily store and curate SPARQL queries (and their associated Linked Data APIs) in GitHub. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "sparqlab - Lab for exercising SPARQL. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.961275726126898,
        0.9199900277630821
      ],
      "excerpt": "d3-sparql - Query a SPARQL endpoint with a SELECT query and get the data ready to be used with d3js \nd3sparql - JavaScript library for executing SPARQL query and transforming resulted JSON for visualization in D3.js. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9038789525037687,
        0.9512098371430345,
        0.8054535285810236
      ],
      "excerpt": "odata2sparql - An OData proxy server that takes data from SPARQL endpoints or RDF graphs and publishes as OData V4 endpoint. \nlens2odata - A GUI for discovery, search, and graph of RDF sources. \nsparql2xquery - SPARQL to XQuery Translator for use with MarkLogic Semantic Toolkit. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9737891997691791
      ],
      "excerpt": "pubby - A Linked Data frontend for SPARQL endpoints. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9244495653383725
      ],
      "excerpt": "Trifid - Lightweight Linked Data Server and Proxy \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8280394713816734
      ],
      "excerpt": "datastudio-sparql-connector - SPARQL Connector for Google Data Studio. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9611534774996503,
        0.9268712879757378
      ],
      "excerpt": "SEPA - A JAVA implementation of the SPARQL Event Processing Architecture including the engine, APIs and tools. \nProcessor - Ontology-driven Linked Data processor and server for SPARQL backends. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9919936183185099,
        0.8587781409843553
      ],
      "excerpt": "Sparklis - natural language query builder to explore and query endpoints with all the power of SPARQL yet without any knowledge of SPARQL. \njson-rql - SPARQL with a JSON-LD super-set syntax (like GraphQL for the semantic web) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9743475046682208,
        0.8979411005071259
      ],
      "excerpt": "hypergraphql - GraphQL interface for querying and serving linked data on the Web. \nLinked Data Fragments \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9793939458399393,
        0.9788290780272703,
        0.9804185511611561
      ],
      "excerpt": "LDFlex - A JavaScript DSL for querying Linked Data on the Web. \ncommunica - A modular framework for querying Linked Data on the Web. \nfedora - Repository platform with native linked data support. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9085250747944672,
        0.8156357936503952
      ],
      "excerpt": "Marmotta - Apache linked data platform implementation. \nElda - Linked data platform from Epimorphics. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.875621117268708
      ],
      "excerpt": "gold - Linked Data server for Go. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9135037697714311
      ],
      "excerpt": "ldp-coap-framework - Linked Data Platform for the Constrained Application Protocol \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8275228131696827
      ],
      "excerpt": "Bob DuCharme's weblog technology for representing and linking information \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8963828448912807
      ],
      "excerpt": "Ontola Linked Data Blog \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8738646573417058
      ],
      "excerpt": "RDF-DEV - RDF-DEV COMMUNITY GROUP. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8778972499144756
      ],
      "excerpt": "KG-Construction - KG-Construction W3C Community Group \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9284091350952476,
        0.8309237997764126
      ],
      "excerpt": "Metaphacts - ($) End-to-end platform to create and utilize enterprise knowledge graphs. \nOntoWiki - (OS) Semantic data wiki as well as Linked Data publishing engine. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9738994108673527
      ],
      "excerpt": "Wikibase - (OS) Collection of applications and libraries for creating, managing and sharing structured data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8478472775238436
      ],
      "excerpt": "Atomic Data Browser - (OS) Create, model, edit, view and share Linked Data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.860059181823877
      ],
      "excerpt": "annotation model \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.918216581428547,
        0.8904111540804226
      ],
      "excerpt": "Karma - Transform data expressed in multiple data formats into RDF. \nMapeathor - Definition of Excel-based mappings and translation to [R2]RML mappings \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9528637983705089,
        0.9303949290724463
      ],
      "excerpt": "TripleGeo - TripleGeo utility for converting geospatial data into triples. \nGeoSPARQL - Major Open Geospatial Consortium Semantic Web spatial data stadard \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8460890577697281
      ],
      "excerpt": "VocExcel - A Excel -> SKOS RDF tool, based on RDFlib \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9066247308688775
      ],
      "excerpt": "Morph-CSV - Exploitation of RML+FnO and CSVW for ensuring the effectiveness of SPARQL-to-SQL systems. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9689482451320052,
        0.8873849289810084,
        0.8905977438407835
      ],
      "excerpt": "PA4RDF - functionality on top of an RDF store while accounting for and exploiting the fundamental differences between graph storage and relational storage. \nEmpire - JPA implementation for RDF \nPinto - A lightweight framework for mapping Java Beans into RDF and back again \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9066301949361375,
        0.868135313828318
      ],
      "excerpt": "XML2RDF-DataTransformation-MappingTool - XML2RDF Data Transformation Tool (Mapping Tool): This generic data transformation tool maps XML data files to RDF files, given a schema matching definition, based on this Mapping Language Schema. \nd2rq - Database to RDF mapping engine and SPARQL server. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9011252655708295,
        0.9245374190896217
      ],
      "excerpt": "quetzal - SPARQL to SQL translation engine for multiple backends, such as DB2, PostgreSQL and Apache Spark. \nsparql-gremlin - SPARQL to Gremlin Translator available as a plugin of the popular Apache TinkerPop graph computing framework. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9547978079065338
      ],
      "excerpt": "ontmalizer - Comprehensive transformations of XML Schemas (XSD) and XML data to RDF/OWL automatically. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9915806869463645,
        0.93686234849693
      ],
      "excerpt": "ontop - Ontop is a platform to query relational databases as Virtual RDF Graphs using SPARQL. It's fast and is packed with features. \ndb2triples - Antidot implementations of R2RML and Direct Mapping specifications. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9689764775882955
      ],
      "excerpt": "Juma - Juma, jigsaw puzzles for representing mapping, is a method that applies the block metaphor to mapping languages. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9451629987148598
      ],
      "excerpt": "Map-On - A web-based editor for visual ontology mapping for R2RML documents. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8130386729059573
      ],
      "excerpt": "RML - RDF Mapping language for mapping JSON, CSV and XML to RDF. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8297413417159459,
        0.8693661131312737
      ],
      "excerpt": "SDM-RDFizer - RML engine for efficient transformation of CSV, RDB, XML and JSON to RDF \nFuMap - Efficient preprocessing of transformation rules described in RML+FnO mappings. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9508355442894111
      ],
      "excerpt": "SPARQL Anything - A system for Semantic Web re-engineering that allows users to query anything with SPARQL. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8395404549391278
      ],
      "excerpt": "J2RM - A tool to process mappings from JSON data to RDF triples guided by an OWL2 ontology structure. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9865498255970665,
        0.8198680997129335
      ],
      "excerpt": "BioPortal - Open repository with tools for ontologies and SKOS vocabularies; biomedical content dominates but all research domains welcome \nprefix.zazuko.com - Similar to LOV, but with a richer search interface \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9793717292837308,
        0.9872195638626101
      ],
      "excerpt": "dcat - DCAT is an RDF vocabulary designed to facilitate interoperability between data catalogs published on the Web. \nprof The Profiles Ontology is an RDF vocabulary to describe profiles of (one or more) standards for information resources. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9968029537584643
      ],
      "excerpt": "foaf - Friend of a Friend (FOAF) ontology. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8804034139714311
      ],
      "excerpt": "juso-ontology - Vocabulary for describing geographical addresses and features. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8616579958630276
      ],
      "excerpt": "qb4olap - A Vocabulary for Business Intelligence over Linked Data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9737891997691791
      ],
      "excerpt": "vocab-transit - RDF Schema for transit data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8686559044364601
      ],
      "excerpt": "schema.org - Structured data on the Internet (Google, Microsoft, Yahoo and Yandex). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9502093631161177
      ],
      "excerpt": "VIVO ISF - Researchers and the full context in which they work. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9810844038600864,
        0.9554446269901129,
        0.9561689469182258,
        0.8596661618326704,
        0.986167864011763
      ],
      "excerpt": "MMOntologies - Multimedia ontologies studied for the paper \"The Landscape of Multimedia Ontologies in the last Decade\". \nWine - Wine Ontology is a popular example of an OWL ontology. \nPizza - A step-by-step guide to modelling in OWL using the popular Prot\u00e9g\u00e9 OWL tools. \nW3C Best Practices for Publishing Linked Data \nCoursera - Web of Data - A joint initiative between EIT Digital, Universit\u00e9 de Nice Sophia-Antipolis / Universit\u00e9 C\u00f4te d'Azur and INRIA - introduces the Linked Data standards and principles that provide the foundation of the Semantic web. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9799430308647098
      ],
      "excerpt": "OntoVerbal - OntoVerbal is a Protege 4.2 plugin that generates natural language descriptions for classes for an ontology written in OWL. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8123569540503283,
        0.8073173393922083
      ],
      "excerpt": "dosdp-tools - dead simple owl design patterns (template tool) \nRDFSharp.Semantics - .NET library for OWL-DL/SKOS ontology modeling, validation and reasoning \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8773799513841588,
        0.8814232490193153
      ],
      "excerpt": "OOPS! (Ontology Pitfall Scanner!) - a web application to detect (semi)automatically 33 pitfalls or errors in ontologies. A web service is also provided. \nCameo Concept Modeler - a cross-platform app for OWL ontology modeling, visualization, and natural-language validation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8999531193718416
      ],
      "excerpt": "Manchester List of Reasoners \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9109340605672717,
        0.9711798305639942,
        0.9730562501602691,
        0.8979411005071259,
        0.8908514333445693
      ],
      "excerpt": "Sequoia - Sequoia is a consequence-based OWL 2 DL Reasoner supporting multithreaded reasoning. \nkonclude - Konclude is a high-performance reasoner for large and expressive ontologies. \nowlproofs - Extension to the OWL API to request proofs of entailments from the reasoner. \nLinked Data \nExplorer's Guide to the Semantic Web \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9684915575131307
      ],
      "excerpt": "Demystifying OWL for the Enterprise \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.837795223921704,
        0.8979411005071259
      ],
      "excerpt": "Structures for Organizing Knowledge: Exploring Taxonomies, Ontologies, and Other Schema \nValidating RDF Data \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.951232532257774
      ],
      "excerpt": "The Data-Centric Revolution \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9323404161762547
      ],
      "excerpt": "sord - Sord is a lightweight C library for storing RDF statements in memory.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8196385675120378
      ],
      "excerpt": "cowl - A lightweight C API for working with OWL ontologies. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9796637136271108,
        0.9631769093384164
      ],
      "excerpt": "grafter - Linked Data & RDF Manufacturing Tools in Clojure. \nkr - Clojure API for RDF and SPARQL - provides consistent access to APIs including Jena and Sesame. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9360315644015724,
        0.978027802044922,
        0.9101667306825715,
        0.9019881302127164
      ],
      "excerpt": "seabass - A library for working with RDF with Jena in Clojure. \naristotle - RDF, SPARQL and OWL for Clojure \naesopica -  A Clojure library designed to help create Semantic Web based applications. \nigraph -  IGraph defines a protocol which aims to provide a general interface to a variety of graph-based representations. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8490339639772068,
        0.9535783491455914
      ],
      "excerpt": "matcha - :tea: SPARQL-like DSL for querying in-memory Linked Data Models \ntable2qb - A generic pipeline for converting tabular data into rdf data cubes using csvw \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8946731846229107
      ],
      "excerpt": "nxparser - Java parsers for different RDF serialisations + API + tools + JAX-RS integration. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8564001849740202,
        0.8536258822754558
      ],
      "excerpt": "Jessa - JAvascript Suite for Sparql Access. \nRDFJS - Github Organization that maintains modern JavaScript RDF libraries based on open, maintained standards \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9122200533829993,
        0.9910904170261974,
        0.9613379308890659,
        0.9693233393948762
      ],
      "excerpt": "rdflib.js - Linked Data API for JavaScript. \nsparks - Sparks is a set of JavaScript libraries designed for simplifying the access to RDF data. \nSPARQL.js - A parser for the SPARQL query language in JavaScript. \nsparqlalgebrajs - SPARQL to SPARQL Algebra converter. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9809215737564295,
        0.9155612846584052
      ],
      "excerpt": "graphy.js - A collection of RDF libraries for JavaScript developers with a focus on performance and usability. \n@zazuko/rdf-vocabularies - Library of common vocabularies \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8426213040376184,
        0.9435042574281465
      ],
      "excerpt": "@ontologies - Like @types, but for ontologies \nrdfdev-js - Collection of libraries to ease in JavaScript RDF development. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9884064062612828
      ],
      "excerpt": "SPARQLKit - An implementation of the SPARQL 1.1 query language in Objective-C. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8393343957134951
      ],
      "excerpt": "SPARQLWrapper - A wrapper for a remote SPARQL endpoint. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "PyShEx - ShEx interpreter for ShEx 2.0. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9754965533244071
      ],
      "excerpt": "Djubby - Linked Data frontend for SPARQL endpoints for Django. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9049777422571106,
        0.8251056119919167
      ],
      "excerpt": "rdftools - Simple collection of python RDF tools. \ncysparql - CySparql is a python wrapper over the excellent rasqal RDF library for parsing SPARQL queries. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9818974148100683
      ],
      "excerpt": "gastrodon - Toolkit to display, analyze, and visualize data and documents based on RDF graphs and the SPARQL query language using Pandas, Jupyter, and other Python ecosystem tools. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8793483626258847,
        0.9937044309958413
      ],
      "excerpt": "rcsvw - R package that implements the candidate recommendations from the W3C CSV on the Web Working Group \nLinked Data Frames - Work with linked-data idiomatically in R using data frames (expresses RDF resources and descriptions as S3 objects) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9065778901273241,
        0.9823975210596145,
        0.9095973090010941,
        0.942387160314205,
        0.9122315151013309,
        0.9757663195781346,
        0.9421097673730053,
        0.9736551904676558,
        0.9454349975159474
      ],
      "excerpt": "rdf-serializers - Adds RDF serialization to Ruby on Rails active model serializers \nHorned OWL - Horned-OWL is a library for manipulating OWL data. \nOxigraph - Oxigraph is a graph database implementing the SPARQL standard. \nsophia_rs - Sophia: a Rust toolkit for RDF and Linked Data. \nrio - Rio is a low level library which provides conformant and fast parsers and formatters for RDF related file formats. \nrdf-rs - rdf is a library for the Resource Description Framework (RDF) and SPARQL implemented in Rust. \nrome - Rome is an RDF library written in safe Rust. \natomic-lib - Library for managing and (de)serializaing Atomic Data, a strict subset of RDF. \nbanana-rdf - A library for RDF, SPARQL and Linked Data technologies in Scala. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9196526181699751
      ],
      "excerpt": "scowl - A Scala DSL for programming with the OWL API. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9100657217107402
      ],
      "excerpt": "URITemplate - Swift implementation of URI Template (RFC6570). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8322587671474787
      ],
      "excerpt": "kineo - A SPARQL endpoint and quadstore written in Swift. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8195194961798424,
        0.9728823973997709
      ],
      "excerpt": "sparql4idea - SPARQL language plugin for IntelliJ IDEA. \nRDF and SPARQL - RDF and SPARQL plugin for JetBrains IDEs \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8001913686732727,
        0.961359250726299
      ],
      "excerpt": "Turtle and SPARQL syntax highlighter \nLinked Data syntaxes - Syntax highlighting for SPARQL 1.1/SPARQL, Turtle/Turtle, TriG, N-Triples, N-Quads, Notation3, and ShExC. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8622699962836651
      ],
      "excerpt": "rdfdot - Tools for drawing graphs from RDF files with GraphViz. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8814232490193153
      ],
      "excerpt": "Cameo Concept Modeler - a cross-platform app for OWL ontology modeling, visualization, and natural-language validation \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9535783491455914,
        0.9692683845868322
      ],
      "excerpt": "table2qb - a pipeline for converting tabular data into rdf data cubes using csvw \nBBC - Ontologies - The ontologies the BBC is using to support its audience facing applications such as BBC Sport, BBC Education, BBC Music, News projects and more. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9488834954818955
      ],
      "excerpt": "permid - PermID: Connecting Data to the World. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8980874773229589
      ],
      "excerpt": "lod-cloud - The Linked Open Data Cloud. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.908653424376495,
        0.9134459888952035
      ],
      "excerpt": "rdfagents - Real-time messaging for the Semantic Web. \nr43ples - Revision Management for the Semantic Web. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9223584207994705,
        0.8016813936964694,
        0.9561930834839922
      ],
      "excerpt": "rdf-toolkit - RDF Serializer, to be used in a git commit-hook to force automatic correct rewrite of every OWL ontology. \nTripleChecker - Look for common errors in an RDF Document. \nowl2vcs - owl2vcs is a set of tools designed to facilitate version control of OWL 2 ontologies using version control systems. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8783746451152653
      ],
      "excerpt": "shi3ld-http - Shi3ld for HTTP: Access control for HTTP operations on Linked Data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9741595323049927
      ],
      "excerpt": "trinity - An application development platform for Microsoft .NET and Mono. It allows to easily build Linked Data and Semantic Web applications based on RDF. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.952913348603956
      ],
      "excerpt": "rww-play - An implementation in Play of a number of tools to build a Read-Write-Web server using Play2.x and akka. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9481220351940889,
        0.8558493948599043,
        0.9886687226029834,
        0.9309357105760581
      ],
      "excerpt": "lodspeakr - Framework to create Linked Data-based applications. \ncomunica - Flexible meta query engine for the Web. \nimagesnippets - ImageSnippets is a complete metadata editing interface that enables someone who knows little to nothing about RDF, OWL, ontologies, or even URIs to create descriptions for images using Linked Data which is written in RDF. \nLinked Data Reactor (LD-R) - A full-stack platform for building adaptive component-based Linked Data applications in NodeJS and React. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.844834843296414
      ],
      "excerpt": "pyLDAPI - A Python rdflib-based API framework for Linked Data via the W3C's Content Negotiation by Profile \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.982270736146481
      ],
      "excerpt": "Widoco - A Wizard for documenting and publishing ontologies on the Web. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8613511274462321
      ],
      "excerpt": "schema_salad - Semantic Annotations for Linked Avro Data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9693233393948762
      ],
      "excerpt": "How to diff RDF \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8548619058031817,
        0.8108000137526687,
        0.9394449182630016,
        0.8062040822986006,
        0.8446976026031613,
        0.9557356880089521,
        0.9581396377917192,
        0.8020241993057988
      ],
      "excerpt": "Openlink Structured Data Sniffer - Browser extension for Google Chrome, Microsoft Edge, Mozilla Firefox, Opera, and Vivaldi that unveils structured metadata embedded within HTML documents and web pages. \nShacShifter - Shapes Constraint Language (SHACL) to various other format. \nprefix.cc - namespace lookup for RDF developers \nrdf2rdf - Tool for converting between different RDF serialization formats. \nWeb-Client - Generic Linked Data browser and UX component framework. \nCEDAR Workbench - Center for Expanded Data Annotation and Retrieval offers full life cycle management for semantically linked metadata \nOnToology - A system for collaborative ontology development. Given a GitHub repository with an OWL file, OnToology will survey it and produce diagrams, a complete documentation and validation based on common pitfalls. \nOBA - Automatically create OpenAPI specifications from OWL and launch a server that serves JSON objects according to your ontology. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8779733501918201
      ],
      "excerpt": "pyLODE - A Python rdflib-based implementation of the LODE ontology documentation tool \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9184967628330425
      ],
      "excerpt": "SolRDF - An RDF plugin for Solr. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9116938522307169,
        0.9995844212521221,
        0.9409430363896409,
        0.9848165224793299,
        0.911465926303079,
        0.8515055467743247,
        0.9015939971851441
      ],
      "excerpt": "SARQ - Free Text Indexing for SPARQL using a remote Solr server. \nEARQ - EARQ is a combination of ARQ and ElasticSearch. \nsesametools - A collection of utilities for use with OpenRDF Sesame. \nImperium - Imperium is a plugin for the Play! framework similar to the existing JPA plugin that allows the use of Empire seamlessly in a Play! based application. \njekyll-rdf - A Jekyll plugin for including RDF data in your static site. \nRightField - RightField is an open-source tool for adding ontology term selection to Excel spreadsheets. \nmu-semtech - An Ecosystem of User-facing Microservices supported by Semantic Models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8002538560306359
      ],
      "excerpt": "gm-sparql - Graph Mining Using SPARQL. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8331510933930537,
        0.9521590401080677,
        0.9842872057724863,
        0.8275592168647727
      ],
      "excerpt": "tdbloader4 - Prototype to show how TDB indexes can be generated using MapReduce. \njena-grande - Jena Grande is a collection of utilities, experiments and examples on how to use MapReduce, Pig, HBase or Giraph to process data in RDF format. \nmrlin - MapReduce processing of Linked Data. \ninfovore - RDF-Centric Map/Reduce Framework and Freebase data conversion tool. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8585914263423507,
        0.9271583128228887
      ],
      "excerpt": "Duke - Duke is a fast and flexible deduplication engine written in Java. \nODCS - The tool uses data processing pipelines for obtaining, processing, and storing RDF data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9901074941323801,
        0.9095008199984523,
        0.9308749589276025,
        0.8408339787395366
      ],
      "excerpt": "Model for Tabular Data and Metadata on the Web \nMetadata Vocabulary for Tabular Data \nGenerating RDF from Tabular Data on the Web (csv2rdf) \nRDF::Tabular - Ruby gem to parse CSV or other Tabular Data into RDF and JSON \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9116162437712744,
        0.8793483626258847,
        0.9535783491455914,
        0.8391721826799569
      ],
      "excerpt": "csvwr - R package for reading and writing CSVW tables and metadata \nrcsvw - R package that implements the candidate recommendations from the W3C CSV on the Web Working Group \ntable2qb - A generic pipeline for converting tabular data into rdf data cubes using csvw \nxwiki - Xwiki related code for WebID. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8590836307081317
      ],
      "excerpt": "TopQuadrant/shacl - SHACL API in Java based on Apache Jena. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9228539459893343,
        0.8667215348178281
      ],
      "excerpt": "Sch\u00edmatos - A SHACL-based Web-Form Generator for Knowledge Graph Editing. \niQvoc - SKOS(-XL) Vocabulary Management System for the Semantic Web. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9393398879644357
      ],
      "excerpt": "skosprovider - Skosprovider provides an interface that can be included in an application to allow it to talk to different SKOS vocabularies. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9282400028148509,
        0.8571524359537862
      ],
      "excerpt": "VocPrez - A Linked Data API for SKOS data presentation \nfred - a machine reader for the Semantic Web \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9775265914507184
      ],
      "excerpt": "Lemon - The Lexicon Model for Ontologies \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.877693996657191
      ],
      "excerpt": "PreMOn - Predicate Model for Ontologies (PreMOn) - VerbNet ontology module \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9239190790850581
      ],
      "excerpt": "TNNT - (The NLP/NER Toolkit) - A tool that automates the extraction of categorised named entities from the unstructured information encoded in the source documents, using diverse NLP tools and NER models. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8850927762763295,
        0.943720503160803,
        0.9737891997691791,
        0.8024371911616264,
        0.9936033513096375
      ],
      "excerpt": "m-ld - Real-time information sharing component using RDF and conflict-free replicated data types (CRDTs) \nn3pygments - Pygments lexer to perform syntax highlighting for N3, Turtle and SPARQL. \nlevelgraph-n3 - LevelGraph plugin for storing N3/Turtle/RDF data. \npsps - Personal Structured Publishing Space. \nswrlapi - The SWRLAPI is a Java API for working with the OWL-based SWRL rule and SQWRL query languages. It includes graphical tools for editing and executing rules and queries. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9514251850748832
      ],
      "excerpt": "Git2PROV - Unleash the potential of Git in the new W3C standard for provenance. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9700073481975878
      ],
      "excerpt": "jqudt - Java library for working with the QUDT ontology and data using it. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8092610016087947
      ],
      "excerpt": "cassa - SPARQL 1.1 Graph Store HTTP Protocol implementation with plugable backends. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9508225305334009,
        0.8913056630328849,
        0.8559675958051688,
        0.8514943471400606
      ],
      "excerpt": "owlapitools - Set of independent add-ons for OWL API. \nLD-FusionTool - Data Fusion & Conflict Resolution tool for Linked Data. \nprefix.cc - Source code to the prefix.cc website. \nLSD-Dimensions - All dimension values of Linked Statistical Data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9892902670948353
      ],
      "excerpt": "mediation - Jena based framework to implement ontological mediation of SPARQL queries. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.911127218700715
      ],
      "excerpt": "SemanticPingback - This small vocabulary defines resources which are used in the context of Semantic Pingback. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9877544080099607,
        0.8913056630328849,
        0.9768968118212837,
        0.9814360768824297,
        0.9674252226428679
      ],
      "excerpt": "grefine-rdf-extension - An extension to Google Refine that enables graphical mapping of Google Refine project data to an RDF skeleton and then exporting it in RDF format. \nLD-FusionTool - Data Fusion & Conflict Resolution tool for Linked Data. \nxodx - An implementation of Semantic Pingback and PuSH for a DSSN. \nmorph-starter - this project is a simple Java (and Scala) demo of how to use morph. \nsesametools - A collection of utilities for use with OpenRDF Sesame (as of recently, Eclipse RDF4J). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8561170333831045,
        0.8390149357750405
      ],
      "excerpt": "levelgraph-jsonld - The Object Document Mapper for LevelGraph based on JSON-LD \nOWL-API - The OWL API is a Java API for creating, manipulating and serialising OWL Ontologies. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.995995242814336
      ],
      "excerpt": "balloon - A tool-suite for Linked Data consumption. balloon aims in offering public services and tools to take advantage of the semantic web with less effort. The basic motivation is to establish a foundation for Linked Data as a Service (LDaaS). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9866865597354428
      ],
      "excerpt": "semargl - Highly performant, lightweight framework for linked data processing. Supports RDFa, JSON-LD, RDF/XML and plain text formats, runs on Android and GAE, provides integration with Jena, Sesame and Clerezza. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8641231333418992
      ],
      "excerpt": "rabel - Program for reading and writing linked data in various formats. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8027503424682361
      ],
      "excerpt": "jsonld-streaming-parser.js - A fast and lightweight streaming JSON-LD parser for JavaScript. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9420374109678618,
        0.8474215464696421
      ],
      "excerpt": "sparql-ld - SPARQL-LD: A SPARQL Extension for Fetching and Querying Linked Data. \njena-sparql-api - A collection of Jena-extensions for hiding SPARQL-complexity from the application layer. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8024371911616264,
        0.958645247719953,
        0.9311335819015948,
        0.9502206746510556
      ],
      "excerpt": "psps - Personal Structured Publishing Space. \nCSO - The Computer Science Ontology (CSO) is a large-scale ontology of research areas that was automatically generated using the Klink-2 algorithm on the Rexplore dataset, which consists of about 16 million publications, mainly in the field of Computer Science. \nmetreeca - The model-driven linked data platform. \nOLGA - OLGA (Ontology Library GenerAtor) is a generic tool aiming to accelerate the adoption of Standard W3C Semantic technology among developers. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9883719394650515,
        0.9420374109678618,
        0.9582408328432815
      ],
      "excerpt": "amazon-neptune-tools - Tools and utilities to enable loading data and building graph applications with Amazon Neptune. \nsparql-ld - SPARQL-LD: A SPARQL Extension for Fetching and Querying Linked Data. \ngenealogical-trees - Semantic Web Exercise: Reasoning and Visualization of the Genealogical Ontologies. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9822777671873387,
        0.8064486181332755
      ],
      "excerpt": "LodLive - browse the web of data - a SPARQL navigator http://lodlive.it \nfbrs - Facebook RDF Sync \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9629714334792362
      ],
      "excerpt": "ontmalizer - A tool that performs comprehensive transformations of XML Schemas (XSD) and XML data to RDF/OWL automatically \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9881954326712546
      ],
      "excerpt": "ML-Schema/core - CORE ontology of ML-Schema schema. It's the mapping to others machine learning vocabularies and ontologies (DMOP, Expose, OntoDM and MEX) \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9658585946843461,
        0.9010956798869101
      ],
      "excerpt": "Mandolin - sparkle Markov Logic Networks for the Discovery of Links \ndocker2rdf - Mapper to represent Dockerfiles as RDF triples \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9707512695392654,
        0.9843703414119188,
        0.9970088446313093,
        0.9611534774996503
      ],
      "excerpt": "Linked-Data-Studio - The Linked Data Studio is an extension to the Linked Data Theatre for the creation of Linked Data. \ncanonical_rdf - Proof-of-concept implementation of Aidan Hogan's RDF canonicalization algorithm in node.js. \nLinked-Data-Theatre - The Linked Data Theatre is a platform for an optimal presentation of Linked Data. \nSEPA - A JAVA implementation of the SPARQL Event Processing Architecture including the engine, APIs and tools. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8390512109783544,
        0.8350073118423977
      ],
      "excerpt": "psparql - PSPARQL (for Path SPARQL) is a query language for RDF. \nrdf2h - Render resources described in RDF using logicless templates. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.976010431925601,
        0.9554825584673026,
        0.9420374109678618
      ],
      "excerpt": "spdx - Software Package Data Exchange\u00ae (SPDX\u00ae) is an open standard for communicating software bill of material information (including components, licenses, copyrights, and security references). \nCostFed - Cost-Based Query Optimization for SPARQL Endpoint Federation. \nsparql-ld - SPARQL-LD: A SPARQL Extension for Fetching and Querying Linked Data. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8537105148906656,
        0.959961309707981,
        0.9783851780665145
      ],
      "excerpt": "knowledgecubes - Efficient RDF Data Management over Spark. \npremon - PREdicate Model for ONtologies \neso-and-ceo - Event and Implied Situation Ontology (ESO) and the Circumstantial Event Ontology for Calamities (CEO). \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9918536307816999
      ],
      "excerpt": "umls2rdf - These python scripts connect to the Unified Medical Language System (UMLS) database and translate the ontologies into RDF/OWL files. This is part of the BioPortal project. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9611534774996503
      ],
      "excerpt": "SEPA - A JAVA implementation of the SPARQL Event Processing Architecture including the engine, APIs and tools. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.949856062313115
      ],
      "excerpt": "solr-ontology-tagger - Automatic tagging and analysis of documents in an Apache Solr index for faceted search by RDF(S) Ontologies & SKOS thesauri. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9394449182630016
      ],
      "excerpt": "rdf4a - RDF4J for Android. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.9488157303857548
      ],
      "excerpt": "wsml2reasoner - a highly modular framework that combines various validation, normalization and transformation algorithms that enable the translation of ontology descriptions in WSML to the appropriate syntax of several underlying reasoning engines.  \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        1.0
      ],
      "excerpt": "A curated list of various semantic web and linked data resources.",
      "technique": "GitHub API"
    }
  ],
  "documentation": [
    {
      "confidence": [
        1.0
      ],
      "excerpt": "https://skosprovider.readthedocs.io/",
      "technique": "Regular expression"
    }
  ],
  "downloadUrl": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/semantalytics/awesome-semantic-web/releases",
    "technique": "GitHub API"
  },
  "forks_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 148,
      "date": "Mon, 15 Nov 2021 11:28:12 GMT"
    },
    "technique": "GitHub API"
  },
  "forks_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/semantalytics/awesome-semantic-web/forks",
    "technique": "GitHub API"
  },
  "fullName": {
    "confidence": [
      1.0
    ],
    "excerpt": "semantalytics/awesome-semantic-web",
    "technique": "GitHub API"
  },
  "installation": [
    {
      "confidence": [
        0.8261077122102032
      ],
      "excerpt": "sparql/turtle extension \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8036646015477263
      ],
      "excerpt": "QuitDiff - Git diff into SparQL / Eccrev vocabulary. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.944222377628984
      ],
      "excerpt": "tawny-owl - Build OWL Ontologies in a Programmatic Environment. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8426389588631202
      ],
      "excerpt": "prefix.cc - namespace lookup for RDF developers \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8142402087472481
      ],
      "excerpt": "pySHACL - A Python validator for SHACL. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8346698224763932
      ],
      "excerpt": "rdf3x_path - RDF3X with path queries. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8986547206287678
      ],
      "excerpt": "prefix.cc - Source code to the prefix.cc website. \n",
      "technique": "Supervised classification"
    }
  ],
  "invocation": [
    {
      "confidence": [
        0.8360852081957076
      ],
      "excerpt": "Data Cube \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8574379098039897
      ],
      "excerpt": "SPARQL 1.1 Query Results JSON Format \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.806815209533912
      ],
      "excerpt": "guide-o-matic - Xquery scripts to convert fielded text (CSV) files to RDF serialized as XML, Turtle, and JSON-LD. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8320494709257085
      ],
      "excerpt": "data-cube - The RDF Data Cube Vocabulary. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8107587636078171
      ],
      "excerpt": "BFO - Basic Formal Ontology. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8594142235991984
      ],
      "excerpt": "rdfpuml - True RDF Diagrams. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.823895404352499
      ],
      "excerpt": "The RDF Data Cube Vocabulary \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8007494523455807,
        0.8569227709760742
      ],
      "excerpt": "csv2rdf (ruby) - Ruby gem to convert CSV to RDF \ncsv2json - Ruby gem to convert CSV to JSON \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8074841313705832
      ],
      "excerpt": "linked-csv - A souped-up CSV-based data format. \n",
      "technique": "Supervised classification"
    },
    {
      "confidence": [
        0.8059125659475288
      ],
      "excerpt": "csvw-template - Document the semantics of your csv file. \n",
      "technique": "Supervised classification"
    }
  ],
  "issueTracker": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://api.github.com/repos/semantalytics/awesome-semantic-web/issues{/number}",
    "technique": "GitHub API"
  },
  "license": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "name": "Creative Commons Zero v1.0 Universal",
      "url": "https://api.github.com/licenses/cc0-1.0"
    },
    "technique": "GitHub API"
  },
  "licenseText": {
    "confidence": [
      1.0
    ],
    "excerpt": "b'CC0 1.0 Universal\\n\\nStatement of Purpose\\n\\nThe laws of most jurisdictions throughout the world automatically confer\\nexclusive Copyright and Related Rights (defined below) upon the creator and\\nsubsequent owner(s) (each and all, an \"owner\") of an original work of\\nauthorship and/or a database (each, a \"Work\").\\n\\nCertain owners wish to permanently relinquish those rights to a Work for the\\npurpose of contributing to a commons of creative, cultural and scientific\\nworks (\"Commons\") that the public can reliably and without fear of later\\nclaims of infringement build upon, modify, incorporate in other works, reuse\\nand redistribute as freely as possible in any form whatsoever and for any\\npurposes, including without limitation commercial purposes. These owners may\\ncontribute to the Commons to promote the ideal of a free culture and the\\nfurther production of creative, cultural and scientific works, or to gain\\nreputation or greater distribution for their Work in part through the use and\\nefforts of others.\\n\\nFor these and/or other purposes and motivations, and without any expectation\\nof additional consideration or compensation, the person associating CC0 with a\\nWork (the \"Affirmer\"), to the extent that he or she is an owner of Copyright\\nand Related Rights in the Work, voluntarily elects to apply CC0 to the Work\\nand publicly distribute the Work under its terms, with knowledge of his or her\\nCopyright and Related Rights in the Work and the meaning and intended legal\\neffect of CC0 on those rights.\\n\\n1. Copyright and Related Rights. A Work made available under CC0 may be\\nprotected by copyright and related or neighboring rights (\"Copyright and\\nRelated Rights\"). Copyright and Related Rights include, but are not limited\\nto, the following:\\n\\n  i. the right to reproduce, adapt, distribute, perform, display, communicate,\\n  and translate a Work;\\n\\n  ii. moral rights retained by the original author(s) and/or performer(s);\\n\\n  iii. publicity and privacy rights pertaining to a person\\'s image or likeness\\n  depicted in a Work;\\n\\n  iv. rights protecting against unfair competition in regards to a Work,\\n  subject to the limitations in paragraph 4(a), below;\\n\\n  v. rights protecting the extraction, dissemination, use and reuse of data in\\n  a Work;\\n\\n  vi. database rights (such as those arising under Directive 96/9/EC of the\\n  European Parliament and of the Council of 11 March 1996 on the legal\\n  protection of databases, and under any national implementation thereof,\\n  including any amended or successor version of such directive); and\\n\\n  vii. other similar, equivalent or corresponding rights throughout the world\\n  based on applicable law or treaty, and any national implementations thereof.\\n\\n2. Waiver. To the greatest extent permitted by, but not in contravention of,\\napplicable law, Affirmer hereby overtly, fully, permanently, irrevocably and\\nunconditionally waives, abandons, and surrenders all of Affirmer\\'s Copyright\\nand Related Rights and associated claims and causes of action, whether now\\nknown or unknown (including existing as well as future claims and causes of\\naction), in the Work (i) in all territories worldwide, (ii) for the maximum\\nduration provided by applicable law or treaty (including future time\\nextensions), (iii) in any current or future medium and for any number of\\ncopies, and (iv) for any purpose whatsoever, including without limitation\\ncommercial, advertising or promotional purposes (the \"Waiver\"). Affirmer makes\\nthe Waiver for the benefit of each member of the public at large and to the\\ndetriment of Affirmer\\'s heirs and successors, fully intending that such Waiver\\nshall not be subject to revocation, rescission, cancellation, termination, or\\nany other legal or equitable action to disrupt the quiet enjoyment of the Work\\nby the public as contemplated by Affirmer\\'s express Statement of Purpose.\\n\\n3. Public License Fallback. Should any part of the Waiver for any reason be\\njudged legally invalid or ineffective under applicable law, then the Waiver\\nshall be preserved to the maximum extent permitted taking into account\\nAffirmer\\'s express Statement of Purpose. In addition, to the extent the Waiver\\nis so judged Affirmer hereby grants to each affected person a royalty-free,\\nnon transferable, non sublicensable, non exclusive, irrevocable and\\nunconditional license to exercise Affirmer\\'s Copyright and Related Rights in\\nthe Work (i) in all territories worldwide, (ii) for the maximum duration\\nprovided by applicable law or treaty (including future time extensions), (iii)\\nin any current or future medium and for any number of copies, and (iv) for any\\npurpose whatsoever, including without limitation commercial, advertising or\\npromotional purposes (the \"License\"). The License shall be deemed effective as\\nof the date CC0 was applied by Affirmer to the Work. Should any part of the\\nLicense for any reason be judged legally invalid or ineffective under\\napplicable law, such partial invalidity or ineffectiveness shall not\\ninvalidate the remainder of the License, and in such case Affirmer hereby\\naffirms that he or she will not (i) exercise any of his or her remaining\\nCopyright and Related Rights in the Work or (ii) assert any associated claims\\nand causes of action with respect to the Work, in either case contrary to\\nAffirmer\\'s express Statement of Purpose.\\n\\n4. Limitations and Disclaimers.\\n\\n  a. No trademark or patent rights held by Affirmer are waived, abandoned,\\n  surrendered, licensed or otherwise affected by this document.\\n\\n  b. Affirmer offers the Work as-is and makes no representations or warranties\\n  of any kind concerning the Work, express, implied, statutory or otherwise,\\n  including without limitation warranties of title, merchantability, fitness\\n  for a particular purpose, non infringement, or the absence of latent or\\n  other defects, accuracy, or the present or absence of errors, whether or not\\n  discoverable, all to the greatest extent permissible under applicable law.\\n\\n  c. Affirmer disclaims responsibility for clearing rights of other persons\\n  that may apply to the Work or any use thereof, including without limitation\\n  any person\\'s Copyright and Related Rights in the Work. Further, Affirmer\\n  disclaims responsibility for obtaining any necessary consents, permissions\\n  or other rights required for any use of the Work.\\n\\n  d. Affirmer understands and acknowledges that Creative Commons is not a\\n  party to this document and has no duty or obligation with respect to this\\n  CC0 or use of the Work.\\n\\nFor more information, please see\\nhttp://creativecommons.org/publicdomain/zero/1.0/\\n'",
    "technique": "GitHub API"
  },
  "long_title": {
    "confidence": [
      1.0
    ],
    "excerpt": "Awesome Semantic Web",
    "technique": "Regular expression"
  },
  "name": {
    "confidence": [
      1.0
    ],
    "excerpt": "awesome-semantic-web",
    "technique": "GitHub API"
  },
  "owner": {
    "confidence": [
      1.0
    ],
    "excerpt": "semantalytics",
    "technique": "GitHub API"
  },
  "ownerType": {
    "confidence": [
      1.0
    ],
    "excerpt": "Organization",
    "technique": "GitHub API"
  },
  "readme_url": {
    "confidence": [
      1.0
    ],
    "excerpt": "https://github.com/semantalytics/awesome-semantic-web/blob/master/README.md",
    "technique": "GitHub API"
  },
  "stargazers_count": {
    "confidence": [
      1.0
    ],
    "excerpt": {
      "count": 787,
      "date": "Mon, 15 Nov 2021 11:28:12 GMT"
    },
    "technique": "GitHub API"
  },
  "topics": {
    "confidence": [
      1.0
    ],
    "excerpt": [
      "semantic-web",
      "sparql",
      "owl",
      "rdf",
      "r2rml",
      "awesome",
      "awesome-list"
    ],
    "technique": "GitHub API"
  },
  "usage": [
    {
      "confidence": [
        1
      ],
      "excerpt": "- [rdf2go](https://github.com/deiu/rdf2go) - Native golang library for RDF.\n- [knakk/rdf](https://github.com/knakk/rdf) - RDF library for Go.\n\n",
      "technique": "Header extraction"
    }
  ]
}